{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_9dr83fgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "My Rack. It's a mixture of servers running mostly TrueNAS. One running EXSi 7 and another running Windows 10 Pro. The main server is a 36 drive Supermicro chassis. It has a X11DPH-T with two Xeon Gold 6138 CPUs, 512GB RAM, 8 intel 800GB SSD, 2 Optane 900P drives, SAS3 HBAs and HGST 8TB Ent drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vvmq6ysmu0hc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/vvmq6ysmu0hc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de6b3620993cd7f0a5bce97017cda982e7bd28b3"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/vvmq6ysmu0hc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=858d9ae71d07e96c02c8b533d3ddf3265e43af1f"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/vvmq6ysmu0hc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0bee38f6d06580515d96614414c2b446df2f4385"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/vvmq6ysmu0hc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=591436e63628e0565dcf7cd974ea7bc503ba22eb"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/vvmq6ysmu0hc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8ddf2649bd1fd2ac7505a9ba4c20b4c70cbe9984"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/vvmq6ysmu0hc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d59181d08e02d1c7f72f8741c8340b3a5c150da1"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/vvmq6ysmu0hc1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=c5ea409659904817da502e57d40d35874053a609"}, "id": "vvmq6ysmu0hc1"}, "up2z70tmu0hc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/up2z70tmu0hc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e126a485c58ad34eb421419e7b68bbf70c10d47c"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/up2z70tmu0hc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=82b8bd139c217ffd079fce509a5126de48bcb529"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/up2z70tmu0hc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=462db9335f04a59d01d0a1164ab2495fc6463598"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/up2z70tmu0hc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=572bc392dceee4b8f14dccfa3d3cb617da274ece"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/up2z70tmu0hc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9da5fcb271bf90e7c345aee455de2011c80e0181"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/up2z70tmu0hc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=24663a1882e3e51159a57fa2ffe6e2e1c3ca731d"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/up2z70tmu0hc1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=7536b91da0a31432afcb9970787c0ae0132fc527"}, "id": "up2z70tmu0hc1"}}, "name": "t3_1akk5ky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 499, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "My Rack", "media_id": "vvmq6ysmu0hc1", "id": 401215511}, {"media_id": "up2z70tmu0hc1", "id": 401215512}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 499, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aiv7F3ykJy1_a-6Drrp0VL43X0fYAfsHfvFYz0BIgAw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707252410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1akk5ky", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akk5ky", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Koothrappalli", "discussion_type": null, "num_comments": 153, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akk5ky/my_rack_its_a_mixture_of_servers_running_mostly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1akk5ky", "subreddit_subscribers": 731075, "created_utc": 1707252410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Short version with no context for the content of the videos: I have 4.5 TB of .mkv files on my hard drive, and a bunch of people who want to download some of them. I have a TrueNAS Scale server that runs 24/7 but only has 22 Mbp/s upload. I don't really know what the best way to share them to people are. I'm thinking of putting up a torrent, but I don't know where. Another site known for hosting an archive of this kind of content exists, but I've reached out to the owners and they're pretty much certain that they're going to get a DMCA and have to remove them. Maybe the Internet Archive, but I suspect they might get a DMCA too. Any guidance is appreciated.\n\n\n\nThis is the yt-dlp command  I used. Cunningham's law me and tell me how awful it is so that I know what I should use next time:\n\n    yt-dlp \\\n            -a yt-dlp-list.txt \\\n            -o \"%(uploader)s (%(uploader_id)s)/%(upload_date)s - %(title)s - (%(duration)ss) [%(resolution)s] [%(id)s].%(ext)s\" \\\n            --download-archive yt-dlp-archive.txt \\\n            --cookies-from-browser firefox \\\n            --ignore-errors \\\n            --merge-output-format mkv \\\n            --sub-langs all \\\n            --write-subs \\\n            --embed-subs \\\n            --add-metadata \\\n            --write-description \\\n            --write-thumbnail \\\n            --write-comments \\\n            --embed-thumbnail \\\n            --embed-info-json \\\n            --write-info-json \\\n            --windows-filenames \\\n\nSelen Tatsuki was a Vtuber who was employed by vtuber company Nijisanji's English branch. When she was terminated, she had the highest subscriber count of  any of their female members in the English branch (and 5th highest overall). She was extremely popular and beloved by her community. She was best known for her FPS gaming skills, being top 500 in Apex Legends at one point, her contagious laughter.  If you want to get a feel for what she was like, this is a good video: https://www.youtube.com/watch?v=elnFh8VpeKQ\n\n\nI don't have time to go into all the details, unfortunately, Nijisanji has shown itself to be either cartoonishly evil or cartoonishly incompetent, and have terminated Selen's contract. Nijisanji had Selen terminated (fired) for reasons I (and many others) consider to be completely unjust, especially considering the way they went about doing it. As Nijisanji owns the rights to the character of Nijisanji, and that changing a Vtuber's performer is considered an unforgivable sin in this industry, the character is gone forever now, especially since all the videos on her channel were deleted too. I could go over a laundry list of of awful things that Nijisanji has done in the past year, but all YOU guys need to know is that they deleted all of Selen's videos from her channel with ZERO warning. In this subreddit, I think that qualifies as an unforgivable sin. Thankfully, I had the foresight to back everything up beforehand (I had a feeling that this was going to happen).\n\nFor comparison on how this kind of thing should be handled, look up how Yozora Mel's termination was handled.\n\n\nThankfully, Selen's story seems to have a happy ending. She's moved back to her old account named Dokibird, and is planning to return to streaming tomorrow. Normally, talking about this kind of thing is a HUGE sin in the vtubing community, but when she said \"Please let everyone know that this is where I am now, I hope you all find me again and we can laugh together again.\" and people realized how Nijisanji did her dirty, the community said \"You know what? Fuck this rule\" and spread her name far and wide.\n\nThat said, DO NOT harass any of the other vtubers working for Nijisanji. Some people have already done so, and it's awful. Basically all of them announced that they were taking a break the day the news was released. To put it mildly, they aren't having a good time right now. I have a bad feeling that I'm going to end up in this situation again soon (even though I hope I don't have to).", "author_fullname": "t2_jefiy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Yesterday, all the videos on Selen Tatsuki's youtube channel were deleted when her contract with her employers was terminated. A few days earlier, I downloaded them all with yt-dlp. Now I have 4.5 TB of videos on my hard drive and I want to share them with her fans. WTF do I do now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akrawr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 437, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 437, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707270663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Short version with no context for the content of the videos: I have 4.5 TB of .mkv files on my hard drive, and a bunch of people who want to download some of them. I have a TrueNAS Scale server that runs 24/7 but only has 22 Mbp/s upload. I don&amp;#39;t really know what the best way to share them to people are. I&amp;#39;m thinking of putting up a torrent, but I don&amp;#39;t know where. Another site known for hosting an archive of this kind of content exists, but I&amp;#39;ve reached out to the owners and they&amp;#39;re pretty much certain that they&amp;#39;re going to get a DMCA and have to remove them. Maybe the Internet Archive, but I suspect they might get a DMCA too. Any guidance is appreciated.&lt;/p&gt;\n\n&lt;p&gt;This is the yt-dlp command  I used. Cunningham&amp;#39;s law me and tell me how awful it is so that I know what I should use next time:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;yt-dlp \\\n        -a yt-dlp-list.txt \\\n        -o &amp;quot;%(uploader)s (%(uploader_id)s)/%(upload_date)s - %(title)s - (%(duration)ss) [%(resolution)s] [%(id)s].%(ext)s&amp;quot; \\\n        --download-archive yt-dlp-archive.txt \\\n        --cookies-from-browser firefox \\\n        --ignore-errors \\\n        --merge-output-format mkv \\\n        --sub-langs all \\\n        --write-subs \\\n        --embed-subs \\\n        --add-metadata \\\n        --write-description \\\n        --write-thumbnail \\\n        --write-comments \\\n        --embed-thumbnail \\\n        --embed-info-json \\\n        --write-info-json \\\n        --windows-filenames \\\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Selen Tatsuki was a Vtuber who was employed by vtuber company Nijisanji&amp;#39;s English branch. When she was terminated, she had the highest subscriber count of  any of their female members in the English branch (and 5th highest overall). She was extremely popular and beloved by her community. She was best known for her FPS gaming skills, being top 500 in Apex Legends at one point, her contagious laughter.  If you want to get a feel for what she was like, this is a good video: &lt;a href=\"https://www.youtube.com/watch?v=elnFh8VpeKQ\"&gt;https://www.youtube.com/watch?v=elnFh8VpeKQ&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have time to go into all the details, unfortunately, Nijisanji has shown itself to be either cartoonishly evil or cartoonishly incompetent, and have terminated Selen&amp;#39;s contract. Nijisanji had Selen terminated (fired) for reasons I (and many others) consider to be completely unjust, especially considering the way they went about doing it. As Nijisanji owns the rights to the character of Nijisanji, and that changing a Vtuber&amp;#39;s performer is considered an unforgivable sin in this industry, the character is gone forever now, especially since all the videos on her channel were deleted too. I could go over a laundry list of of awful things that Nijisanji has done in the past year, but all YOU guys need to know is that they deleted all of Selen&amp;#39;s videos from her channel with ZERO warning. In this subreddit, I think that qualifies as an unforgivable sin. Thankfully, I had the foresight to back everything up beforehand (I had a feeling that this was going to happen).&lt;/p&gt;\n\n&lt;p&gt;For comparison on how this kind of thing should be handled, look up how Yozora Mel&amp;#39;s termination was handled.&lt;/p&gt;\n\n&lt;p&gt;Thankfully, Selen&amp;#39;s story seems to have a happy ending. She&amp;#39;s moved back to her old account named Dokibird, and is planning to return to streaming tomorrow. Normally, talking about this kind of thing is a HUGE sin in the vtubing community, but when she said &amp;quot;Please let everyone know that this is where I am now, I hope you all find me again and we can laugh together again.&amp;quot; and people realized how Nijisanji did her dirty, the community said &amp;quot;You know what? Fuck this rule&amp;quot; and spread her name far and wide.&lt;/p&gt;\n\n&lt;p&gt;That said, DO NOT harass any of the other vtubers working for Nijisanji. Some people have already done so, and it&amp;#39;s awful. Basically all of them announced that they were taking a break the day the news was released. To put it mildly, they aren&amp;#39;t having a good time right now. I have a bad feeling that I&amp;#39;m going to end up in this situation again soon (even though I hope I don&amp;#39;t have to).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vDy14nrb4QFcyTcUgcXVOXgU6u3i1nwM_N2DA3gqkqM.jpg?auto=webp&amp;s=b61786931862de181cd20e2baba0fd40d4b09a78", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/vDy14nrb4QFcyTcUgcXVOXgU6u3i1nwM_N2DA3gqkqM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa9e0d22c18a02859550ea44ac2ab87e9d878382", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/vDy14nrb4QFcyTcUgcXVOXgU6u3i1nwM_N2DA3gqkqM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4290bd52953f1c2eae4295eb6f41c461688cb350", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/vDy14nrb4QFcyTcUgcXVOXgU6u3i1nwM_N2DA3gqkqM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2eba07a7efe1660c42cbff275b7a2a90d13cfb11", "width": 320, "height": 240}], "variants": {}, "id": "z7UHxQmgUy5SZyK8FpsCrDiX9gAR0bCSt0ts4s8nxIk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "50TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akrawr", "is_robot_indexable": true, "report_reasons": null, "author": "ajshell1", "discussion_type": null, "num_comments": 108, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1akrawr/yesterday_all_the_videos_on_selen_tatsukis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akrawr/yesterday_all_the_videos_on_selen_tatsukis/", "subreddit_subscribers": 731075, "created_utc": 1707270663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So this is a tale of a rookie mistake..\n\nI decided to resize my movie's partition so i could allocate a bit of space to a scratch partition... no problem.. Spin up IM-Magic and just steal back some of that space..\n\nLittle did I know that by doing this my movies drive would come back completely empty.. 8Tb of movies gone.. whoops.\n\nLuckily i have a local copy on another system and it's only 2 days old so i'll just jump on goodsync, set up a new job and copy everything back. It'll take about 20 hours but that's fine.. and it was.. until i rebooted for an unrelated reason and then went to start the Goodsync job again..\n\nExcept what i did was run the normal job that syncs my live drive to the backup drive.. thus deleting abotu 120GB of stuff before i realised why it was running quite so quickly..\n\nthankfully my Backblaze B2 backup (which isn't actually complete yet) was far enough along that i could recover what i needed to a B2 zip file and then pull it down using Rclone.\n\nEveryone always says.. a backup isn't a backup until it's been tested and.. well i think i've pretty much tested my strategy (unintentionally) quite well here :)\n\nEdit : Kudos to backblaze for having a service that actually adhere's to the \"unlimited\" statement.. OK so the restore process using the official app is less than perfect for subscribers here, but they offer a workaround using their B2 storage.. i'm happy to pay the short term cost of using B2 to get some of my data back using rclone.\n\nEdit2 : maybe we need a /r/talesofdataloss", "author_fullname": "t2_4cfky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whoops.... 8TB gone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akpke9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707266408.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707265787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So this is a tale of a rookie mistake..&lt;/p&gt;\n\n&lt;p&gt;I decided to resize my movie&amp;#39;s partition so i could allocate a bit of space to a scratch partition... no problem.. Spin up IM-Magic and just steal back some of that space..&lt;/p&gt;\n\n&lt;p&gt;Little did I know that by doing this my movies drive would come back completely empty.. 8Tb of movies gone.. whoops.&lt;/p&gt;\n\n&lt;p&gt;Luckily i have a local copy on another system and it&amp;#39;s only 2 days old so i&amp;#39;ll just jump on goodsync, set up a new job and copy everything back. It&amp;#39;ll take about 20 hours but that&amp;#39;s fine.. and it was.. until i rebooted for an unrelated reason and then went to start the Goodsync job again..&lt;/p&gt;\n\n&lt;p&gt;Except what i did was run the normal job that syncs my live drive to the backup drive.. thus deleting abotu 120GB of stuff before i realised why it was running quite so quickly..&lt;/p&gt;\n\n&lt;p&gt;thankfully my Backblaze B2 backup (which isn&amp;#39;t actually complete yet) was far enough along that i could recover what i needed to a B2 zip file and then pull it down using Rclone.&lt;/p&gt;\n\n&lt;p&gt;Everyone always says.. a backup isn&amp;#39;t a backup until it&amp;#39;s been tested and.. well i think i&amp;#39;ve pretty much tested my strategy (unintentionally) quite well here :)&lt;/p&gt;\n\n&lt;p&gt;Edit : Kudos to backblaze for having a service that actually adhere&amp;#39;s to the &amp;quot;unlimited&amp;quot; statement.. OK so the restore process using the official app is less than perfect for subscribers here, but they offer a workaround using their B2 storage.. i&amp;#39;m happy to pay the short term cost of using B2 to get some of my data back using rclone.&lt;/p&gt;\n\n&lt;p&gt;Edit2 : maybe we need a &lt;a href=\"/r/talesofdataloss\"&gt;/r/talesofdataloss&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "64TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akpke9", "is_robot_indexable": true, "report_reasons": null, "author": "d4nm3d", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1akpke9/whoops_8tb_gone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akpke9/whoops_8tb_gone/", "subreddit_subscribers": 731075, "created_utc": 1707265787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was checking out Microsoft's Project Silica lately.\n\nVERY cool stuff. But I saw that they're already decided that it's going to be a product for datacenters (and of course Azure is primed to launch the tech when it is ready). \n\nFolio Photonics looks interesting ... they're talking about 1TB optical discs. But the drives are going to be $3-5K, the R&amp;D noise has been going on for a while now, and .. it seems like it's going to be a very proprietary tech (only their discs, only their drives).\n\nMy question is whether anybody else has turned their attention to long term cold/archival storage? And if so whether any of the stuff in the pipeline is actually intended for consumers (in the manner that the M-Disc of old was)?\n\n&amp;#x200B;", "author_fullname": "t2_poc45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone developing \"permanent\" digital storage intended for consumers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al46x4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707316173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was checking out Microsoft&amp;#39;s Project Silica lately.&lt;/p&gt;\n\n&lt;p&gt;VERY cool stuff. But I saw that they&amp;#39;re already decided that it&amp;#39;s going to be a product for datacenters (and of course Azure is primed to launch the tech when it is ready). &lt;/p&gt;\n\n&lt;p&gt;Folio Photonics looks interesting ... they&amp;#39;re talking about 1TB optical discs. But the drives are going to be $3-5K, the R&amp;amp;D noise has been going on for a while now, and .. it seems like it&amp;#39;s going to be a very proprietary tech (only their discs, only their drives).&lt;/p&gt;\n\n&lt;p&gt;My question is whether anybody else has turned their attention to long term cold/archival storage? And if so whether any of the stuff in the pipeline is actually intended for consumers (in the manner that the M-Disc of old was)?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1al46x4", "is_robot_indexable": true, "report_reasons": null, "author": "danielrosehill", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1al46x4/is_anyone_developing_permanent_digital_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1al46x4/is_anyone_developing_permanent_digital_storage/", "subreddit_subscribers": 731075, "created_utc": 1707316173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have several folders of Godot game project, where some of them are exact duplicates, whereas others are ones which I have continued working on.\n\nIs there a tool I can use to find exact duplicates so I can delete them?", "author_fullname": "t2_l20rgpzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a tool to check if folders have the same content?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akj96c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707250261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have several folders of Godot game project, where some of them are exact duplicates, whereas others are ones which I have continued working on.&lt;/p&gt;\n\n&lt;p&gt;Is there a tool I can use to find exact duplicates so I can delete them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akj96c", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Record951", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akj96c/is_there_a_tool_to_check_if_folders_have_the_same/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akj96c/is_there_a_tool_to_check_if_folders_have_the_same/", "subreddit_subscribers": 731075, "created_utc": 1707250261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to transfer a folder that is 30GB+ but every file sharing site I can find automatically zips the file when downloading, are there any sites that don't do this?\n\nThanks", "author_fullname": "t2_foj4ohr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best file sharing site that doesn't automatically ZIP files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akwivv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707287102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to transfer a folder that is 30GB+ but every file sharing site I can find automatically zips the file when downloading, are there any sites that don&amp;#39;t do this?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akwivv", "is_robot_indexable": true, "report_reasons": null, "author": "GazF1888", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akwivv/best_file_sharing_site_that_doesnt_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akwivv/best_file_sharing_site_that_doesnt_automatically/", "subreddit_subscribers": 731075, "created_utc": 1707287102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm setting up an OpenMediaVault NAS this week and since this is my first time working with ZFS, I thought I'd ask the pros for some advice.  So the hard drives I have available are:\n\n* 4x 10TB (empty)\n* 2x 12TB (1 full, 1 empty)\n* 1x 14TB (full)\n* 1x 16TB (about 1/2 full)\n\nMy plan is to put the empty 12TB drive into a vdev with the 10TB drives for 40TB capacity after single redundancy. Then I'll put it in a pool, migrate all of my data, and create a second vdev with the remaining 12, 14, and 16TB drives, for an additional 24TB of single-redundancy capacity.\n\nIf none of that sounds off, I'm also curious as to whether I should consider ZLOG/L2ARC drives. The system is primarily a Plex server (maybe 5 concurrent users tops, runs a handful of other services). I have several SSDs laying around: 256, 500, 2x120, 240, 128. And I suppose if there's any of those left over I should set up some fast storage set aside for metadata / transcoding / config / etc. Operating system will be on a 500 GB NVME drive.\n\nAnd of course if there's anything else I might be missing, please let me know that too. I thought I was good at computers, but some of this ZFS stuff gets complicated!", "author_fullname": "t2_due19f7ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up NAS, need some ZFS guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akjrg2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707251458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m setting up an OpenMediaVault NAS this week and since this is my first time working with ZFS, I thought I&amp;#39;d ask the pros for some advice.  So the hard drives I have available are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;4x 10TB (empty)&lt;/li&gt;\n&lt;li&gt;2x 12TB (1 full, 1 empty)&lt;/li&gt;\n&lt;li&gt;1x 14TB (full)&lt;/li&gt;\n&lt;li&gt;1x 16TB (about 1/2 full)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My plan is to put the empty 12TB drive into a vdev with the 10TB drives for 40TB capacity after single redundancy. Then I&amp;#39;ll put it in a pool, migrate all of my data, and create a second vdev with the remaining 12, 14, and 16TB drives, for an additional 24TB of single-redundancy capacity.&lt;/p&gt;\n\n&lt;p&gt;If none of that sounds off, I&amp;#39;m also curious as to whether I should consider ZLOG/L2ARC drives. The system is primarily a Plex server (maybe 5 concurrent users tops, runs a handful of other services). I have several SSDs laying around: 256, 500, 2x120, 240, 128. And I suppose if there&amp;#39;s any of those left over I should set up some fast storage set aside for metadata / transcoding / config / etc. Operating system will be on a 500 GB NVME drive.&lt;/p&gt;\n\n&lt;p&gt;And of course if there&amp;#39;s anything else I might be missing, please let me know that too. I thought I was good at computers, but some of this ZFS stuff gets complicated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akjrg2", "is_robot_indexable": true, "report_reasons": null, "author": "DrivewayAvalanch", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akjrg2/setting_up_nas_need_some_zfs_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akjrg2/setting_up_nas_need_some_zfs_guidance/", "subreddit_subscribers": 731075, "created_utc": 1707251458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using JDownloader 2 without any problems, but after the UMG dispute with TikTok, itself and other common downloaders aren't able to download videos with muted sounds. The only workaround I found on JDownloader 2 works, but it is slower, has watermarks, and doesn't get photo slideshows. Does anyone know of a better alternative?", "author_fullname": "t2_glticrhal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download TikTok profiles after UMG dispute?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al168y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707306652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using JDownloader 2 without any problems, but after the UMG dispute with TikTok, itself and other common downloaders aren&amp;#39;t able to download videos with muted sounds. The only workaround I found on JDownloader 2 works, but it is slower, has watermarks, and doesn&amp;#39;t get photo slideshows. Does anyone know of a better alternative?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1al168y", "is_robot_indexable": true, "report_reasons": null, "author": "sipaddict", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1al168y/how_to_download_tiktok_profiles_after_umg_dispute/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1al168y/how_to_download_tiktok_profiles_after_umg_dispute/", "subreddit_subscribers": 731075, "created_utc": 1707306652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My current setup is using my router (RT-AC88U) for an SMB share. Although, when I try to compress a backup folder, the router CPU goes to 100 and it disable my SMB share temporarily. So I have to download it, compress it on my laptop and then upload it again. \n\nI did some research on both of these dell wyse and here what I got:\n\n5060:\n* It has a Quad core GX-424 (No hyper-threading or AMD-equivalent)\n* 2 USB 3.1 ports (I need at least one to connect my dock)\n* Idle: 8W and Running: 17W (25W max)\n\n3030\n* 10 Dollars cheaper\n* Intel Celeron N2807 (Dual core and significantly slower than the AMD when I looked at online benchmarks)\n* 1 USB 3.1 ports\n* Idle: 3W and Running: 4W (Which is amazing)\n\nThis is where i got the power consumption data from:\nhttps://www.parkytowers.me.uk/thin/wyse/5060/\nhttps://www.parkytowers.me.uk/thin/wyse/3030/n03d.shtml", "author_fullname": "t2_43triabl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Need help with choosing system for SMB sharing (for beginners)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bb9wk474z6hc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/bb9wk474z6hc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e032ce4c7421d78a1efdc39c4c6534d4ebe1893"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/bb9wk474z6hc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d97da7b6d97e1a450022034b2fa20115141203ea"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/bb9wk474z6hc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0cff4d85c9a8c81fca24e0c5830dcb1e6ef924ad"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/bb9wk474z6hc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d786c180a81cdc0a7db064934cbb8c2bf7bdec0c"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/bb9wk474z6hc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=425db4177c4bd7e1cebf9e6a87fc5ce25c71832e"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/bb9wk474z6hc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=626efb3f637851a8307891ae50717cb49a673248"}], "s": {"y": 2532, "x": 1170, "u": "https://preview.redd.it/bb9wk474z6hc1.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=d30d856df6ca222bf67c4acb71472aee3f82ba71"}, "id": "bb9wk474z6hc1"}, "m9uuhv64z6hc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/m9uuhv64z6hc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a711092b03c24bd8def7c0de8907789e60217118"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/m9uuhv64z6hc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a7fbdce180999820ebfeb32d707e6451ca217fd1"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/m9uuhv64z6hc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a0e43f4dc2357d9d073549629d9d34433c47cfe4"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/m9uuhv64z6hc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e5d5863af5cd0941fd7ac8054c774fb3303bb4b"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/m9uuhv64z6hc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1478cdab91835ee9de60d8ce50543460e01920e2"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/m9uuhv64z6hc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5c8bf83fcad14f7de36652a1916aa44df3d8ae1f"}], "s": {"y": 2532, "x": 1170, "u": "https://preview.redd.it/m9uuhv64z6hc1.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=25c7d39d662f5d9db36385c06adea9a86d4677d9"}, "id": "m9uuhv64z6hc1"}}, "name": "t3_1al78sa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "bb9wk474z6hc1", "id": 401602081}, {"media_id": "m9uuhv64z6hc1", "id": 401602082}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z1wCr3tu7uTdIwIH_lhj6hET75sLRC7YZ_5ZWUo4qKo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707324106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My current setup is using my router (RT-AC88U) for an SMB share. Although, when I try to compress a backup folder, the router CPU goes to 100 and it disable my SMB share temporarily. So I have to download it, compress it on my laptop and then upload it again. &lt;/p&gt;\n\n&lt;p&gt;I did some research on both of these dell wyse and here what I got:&lt;/p&gt;\n\n&lt;p&gt;5060:\n* It has a Quad core GX-424 (No hyper-threading or AMD-equivalent)\n* 2 USB 3.1 ports (I need at least one to connect my dock)\n* Idle: 8W and Running: 17W (25W max)&lt;/p&gt;\n\n&lt;p&gt;3030\n* 10 Dollars cheaper\n* Intel Celeron N2807 (Dual core and significantly slower than the AMD when I looked at online benchmarks)\n* 1 USB 3.1 ports\n* Idle: 3W and Running: 4W (Which is amazing)&lt;/p&gt;\n\n&lt;p&gt;This is where i got the power consumption data from:\n&lt;a href=\"https://www.parkytowers.me.uk/thin/wyse/5060/\"&gt;https://www.parkytowers.me.uk/thin/wyse/5060/&lt;/a&gt;\n&lt;a href=\"https://www.parkytowers.me.uk/thin/wyse/3030/n03d.shtml\"&gt;https://www.parkytowers.me.uk/thin/wyse/3030/n03d.shtml&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1al78sa", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1al78sa", "is_robot_indexable": true, "report_reasons": null, "author": "Com3dy_Gold", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1al78sa/need_help_with_choosing_system_for_smb_sharing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1al78sa", "subreddit_subscribers": 731075, "created_utc": 1707324106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So this is my first go with JBODs I have a disk array with Truenas installed dont have any issues with it but what im trying to do is connect the EMC to my DL360 G9 to pass through the disks to vmware. \n\nNow Ive installed an LSI 9200-8e and flashed it to P20 IT firmware, when the server boots up and initializes the LSI card I can see all the hard drives in it, but in smart storage app i dont see the LSI card. In VMWare 7 I can see the LSI card but it says there are no disks that i can add to a data store. \n\nAnyone been through this and have any ideas? Oh and in the HP Smart storage app when i run a diagnosis it sees the drives and the LSI card, but i cant configure anything it only sees it when running the report. ", "author_fullname": "t2_cnda7z3f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dell EMC KTN-STL3 JBOD with an HP DL360 G9 and VMware?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akwfzp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707286803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So this is my first go with JBODs I have a disk array with Truenas installed dont have any issues with it but what im trying to do is connect the EMC to my DL360 G9 to pass through the disks to vmware. &lt;/p&gt;\n\n&lt;p&gt;Now Ive installed an LSI 9200-8e and flashed it to P20 IT firmware, when the server boots up and initializes the LSI card I can see all the hard drives in it, but in smart storage app i dont see the LSI card. In VMWare 7 I can see the LSI card but it says there are no disks that i can add to a data store. &lt;/p&gt;\n\n&lt;p&gt;Anyone been through this and have any ideas? Oh and in the HP Smart storage app when i run a diagnosis it sees the drives and the LSI card, but i cant configure anything it only sees it when running the report. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akwfzp", "is_robot_indexable": true, "report_reasons": null, "author": "Koldenshitzen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akwfzp/dell_emc_ktnstl3_jbod_with_an_hp_dl360_g9_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akwfzp/dell_emc_ktnstl3_jbod_with_an_hp_dl360_g9_and/", "subreddit_subscribers": 731075, "created_utc": 1707286803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two folders:\n\n\\- One we will call /REFERENCE/\n\n\\- Another we call /SECOND\\_F/\n\nThe script will compare /REFERENCE/(Subdirectory\\_path)/file1.xxx ***VS*** /SECOND\\_F/(Subdirectory\\_path)/file1.xxx\n\nIf the PATH for subdirectory, and file\\_name is the same, then ignore, otherwise copy it to /SOURCE/(Subdirectory)/file1.xxx\n\nUPDATE: Solved with ***rsync*** \n\nThank you!", "author_fullname": "t2_ewrqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Script to compare two directories (and Childs). If file is missing in REFERENCE folder then copy.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aku2id", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707286056.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707278891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two folders:&lt;/p&gt;\n\n&lt;p&gt;- One we will call /REFERENCE/&lt;/p&gt;\n\n&lt;p&gt;- Another we call /SECOND_F/&lt;/p&gt;\n\n&lt;p&gt;The script will compare /REFERENCE/(Subdirectory_path)/file1.xxx &lt;strong&gt;&lt;em&gt;VS&lt;/em&gt;&lt;/strong&gt; /SECOND_F/(Subdirectory_path)/file1.xxx&lt;/p&gt;\n\n&lt;p&gt;If the PATH for subdirectory, and file_name is the same, then ignore, otherwise copy it to /SOURCE/(Subdirectory)/file1.xxx&lt;/p&gt;\n\n&lt;p&gt;UPDATE: Solved with &lt;strong&gt;&lt;em&gt;rsync&lt;/em&gt;&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aku2id", "is_robot_indexable": true, "report_reasons": null, "author": "david007co", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1aku2id/script_to_compare_two_directories_and_childs_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1aku2id/script_to_compare_two_directories_and_childs_if/", "subreddit_subscribers": 731075, "created_utc": 1707278891.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a long one, apologies.\u00a0\n\nHoping to get some suggestions from you smart folks. I'm looking to build a solution for several tasks.\n\n**Primarily:**\u00a0\n\n* Local data backup &amp; recovery - regular, automatic onsite for PC &amp; mobile phone, potentially more devices in the future\n* Cloud storage/file server - access files locally or remotely, 24/7\n* Media server - manage, organize, and stream my media locally or remotely 24/7 - speed and latency are key\n* Local torrent server for downloading &amp; seeding Linux ISOs 24/7 - very low power consumption is key\n\n**Planned upgrades for later:**\u00a0\n\n* Secure shared access to files/folders &amp; guest accounts for friends/family\n* NVR for up to 4 security cameras (not purchased yet)\n\n**Notes**\n\nRelatively low noise and power consumption are considerations. Electricity is expensive in my area. Currently on a PC running Win 10 Pro (soon dual boot w/Linux) with a few HDDs for media and personal files, transitioning to SSDs for all files I interact with directly. Debating putting the SSDs on the local network instead of inside the PC. I realize this may add complexity and require upgrading to 10GbE NIC\u00a0+ router to get access speeds &amp; latency (across the local network to my PC) approaching the internal SATA connection.\n\nBackups don't need to be fast, so considering getting a few 20tb HDDs for the lower cost.\n\nCurrently torrenting on a tiny, dedicated headless server based on Raspberry Pi 3 with a 3TB portable USB drive that's been nearly full for several years. It's rock solid, runs cool, completely silent, and sips less than 1W of power. However, I'll want to upgrade to a faster box, which is not as urgent and may come at a later date.\n\nNot interested in a seedbox service or other ongoing subscription.Not interested in a prebuilt NAS like Qnap or Synology. They look beautiful, super simple, reliable, and can do a lot, but I'd prefer to build it myself for increased privacy (self hosted), security, flexibility, upgradeability, and affordability relative to the specs.\n\n**Questions:**\u00a0\n\n1. Would it make sense for one box to do the first 3 (the torrent server would be separate so it can run very low power)? If not, what might be a smart setup?\n2. If I put my 4 unused 2.5\" SATA SSDs (total 32TB) in RAID 0 inside the PC now (managed by the BIOS I guess), how easy would it be to move the array to a NAS or enclosure later? Is it as simple as installing them in the same order and choosing the same RAID type?\n3. Is it possible or wise to have the torrent folders (torrent files, downloading, completed, and a watch folder) be on the same SSD pool/array as the rest of the content, or is this just complicating things? I always copy completed torrents to my personal media folders to organize/rename/delete things, and leave the originals to seed. It's annoying having duplicates, but not sure there is a way to streamline this.\n4. I don't necessarily need RAID 0 for added speed, I just want a single volume for all SSDs - not 4, without losing any expensive storage space to parity, as with RAID 5. Are there better options?\n\nAppreciate any feedback.", "author_fullname": "t2_nh2ls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for first NAS/backup solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akt8ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707308985.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707276298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a long one, apologies.\u00a0&lt;/p&gt;\n\n&lt;p&gt;Hoping to get some suggestions from you smart folks. I&amp;#39;m looking to build a solution for several tasks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Primarily:&lt;/strong&gt;\u00a0&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Local data backup &amp;amp; recovery - regular, automatic onsite for PC &amp;amp; mobile phone, potentially more devices in the future&lt;/li&gt;\n&lt;li&gt;Cloud storage/file server - access files locally or remotely, 24/7&lt;/li&gt;\n&lt;li&gt;Media server - manage, organize, and stream my media locally or remotely 24/7 - speed and latency are key&lt;/li&gt;\n&lt;li&gt;Local torrent server for downloading &amp;amp; seeding Linux ISOs 24/7 - very low power consumption is key&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Planned upgrades for later:&lt;/strong&gt;\u00a0&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Secure shared access to files/folders &amp;amp; guest accounts for friends/family&lt;/li&gt;\n&lt;li&gt;NVR for up to 4 security cameras (not purchased yet)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Relatively low noise and power consumption are considerations. Electricity is expensive in my area. Currently on a PC running Win 10 Pro (soon dual boot w/Linux) with a few HDDs for media and personal files, transitioning to SSDs for all files I interact with directly. Debating putting the SSDs on the local network instead of inside the PC. I realize this may add complexity and require upgrading to 10GbE NIC\u00a0+ router to get access speeds &amp;amp; latency (across the local network to my PC) approaching the internal SATA connection.&lt;/p&gt;\n\n&lt;p&gt;Backups don&amp;#39;t need to be fast, so considering getting a few 20tb HDDs for the lower cost.&lt;/p&gt;\n\n&lt;p&gt;Currently torrenting on a tiny, dedicated headless server based on Raspberry Pi 3 with a 3TB portable USB drive that&amp;#39;s been nearly full for several years. It&amp;#39;s rock solid, runs cool, completely silent, and sips less than 1W of power. However, I&amp;#39;ll want to upgrade to a faster box, which is not as urgent and may come at a later date.&lt;/p&gt;\n\n&lt;p&gt;Not interested in a seedbox service or other ongoing subscription.Not interested in a prebuilt NAS like Qnap or Synology. They look beautiful, super simple, reliable, and can do a lot, but I&amp;#39;d prefer to build it myself for increased privacy (self hosted), security, flexibility, upgradeability, and affordability relative to the specs.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;\u00a0&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Would it make sense for one box to do the first 3 (the torrent server would be separate so it can run very low power)? If not, what might be a smart setup?&lt;/li&gt;\n&lt;li&gt;If I put my 4 unused 2.5&amp;quot; SATA SSDs (total 32TB) in RAID 0 inside the PC now (managed by the BIOS I guess), how easy would it be to move the array to a NAS or enclosure later? Is it as simple as installing them in the same order and choosing the same RAID type?&lt;/li&gt;\n&lt;li&gt;Is it possible or wise to have the torrent folders (torrent files, downloading, completed, and a watch folder) be on the same SSD pool/array as the rest of the content, or is this just complicating things? I always copy completed torrents to my personal media folders to organize/rename/delete things, and leave the originals to seed. It&amp;#39;s annoying having duplicates, but not sure there is a way to streamline this.&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t necessarily need RAID 0 for added speed, I just want a single volume for all SSDs - not 4, without losing any expensive storage space to parity, as with RAID 5. Are there better options?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Appreciate any feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akt8ho", "is_robot_indexable": true, "report_reasons": null, "author": "sakuba", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akt8ho/suggestions_for_first_nasbackup_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akt8ho/suggestions_for_first_nasbackup_solution/", "subreddit_subscribers": 731075, "created_utc": 1707276298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Used to use Amoei (spelling) for backing up a harddrive disk image, but these days, the free version is significantly reduced in functions that I basically don't use it anymore. \n\nAny good free option for Windows users currently?", "author_fullname": "t2_11ezwt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a good harddrive image backup these days?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akq2w0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707267222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Used to use Amoei (spelling) for backing up a harddrive disk image, but these days, the free version is significantly reduced in functions that I basically don&amp;#39;t use it anymore. &lt;/p&gt;\n\n&lt;p&gt;Any good free option for Windows users currently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akq2w0", "is_robot_indexable": true, "report_reasons": null, "author": "eviLocK", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akq2w0/what_is_a_good_harddrive_image_backup_these_days/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akq2w0/what_is_a_good_harddrive_image_backup_these_days/", "subreddit_subscribers": 731075, "created_utc": 1707267222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is this a good brand for refurbs? Just seeing if anyone has tried them.", "author_fullname": "t2_9ztvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Water Panther", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al4dlr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707316682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is this a good brand for refurbs? Just seeing if anyone has tried them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1al4dlr", "is_robot_indexable": true, "report_reasons": null, "author": "cobracommander13", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1al4dlr/water_panther/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1al4dlr/water_panther/", "subreddit_subscribers": 731075, "created_utc": 1707316682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\n&amp;#x200B;\n\nSo I haven't really done this before much with TV Shows but I was trying to use MakeMKV to remux these ISO files for this TV Show. It's split across 4 ISOS and when I put one of them into MakeMKV it spits out 1 MKV for like 3-4 episodes. I mounted the ISOS and found that that all episodes are their own VOB files more or less.  \n\n\nI don't really know how to proceed... is there something I'm missing in terms of MakeMKV? Do I just convert the vob files?  ", "author_fullname": "t2_g85w9v3fx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TV Show spread across multiple ISOs...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akqt7a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707269286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I haven&amp;#39;t really done this before much with TV Shows but I was trying to use MakeMKV to remux these ISO files for this TV Show. It&amp;#39;s split across 4 ISOS and when I put one of them into MakeMKV it spits out 1 MKV for like 3-4 episodes. I mounted the ISOS and found that that all episodes are their own VOB files more or less.  &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really know how to proceed... is there something I&amp;#39;m missing in terms of MakeMKV? Do I just convert the vob files?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akqt7a", "is_robot_indexable": true, "report_reasons": null, "author": "gaydevi", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akqt7a/tv_show_spread_across_multiple_isos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akqt7a/tv_show_spread_across_multiple_isos/", "subreddit_subscribers": 731075, "created_utc": 1707269286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hello everyone,\n\nI recently purchased a 2TB external hard drive where I want to save all my important memories. I would like to get another one of another brand but the same size and I would like to make a 1:1 copy of the first one. Is there any way to automatically copy the contents of the first hard drive to the second one automatically? I mean, every time I add a file on the first hard disk, it will also automatically copy to the second one when it will be connected to the computer. I use a Mac with Apple Silicon. \n\n&amp;#x200B;\n\nThank you for your attention,\n\nhave a nice day", "author_fullname": "t2_kedbpo10r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatic 1:1 copy between two hard drives on Mac", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akiv6r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707249336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently purchased a 2TB external hard drive where I want to save all my important memories. I would like to get another one of another brand but the same size and I would like to make a 1:1 copy of the first one. Is there any way to automatically copy the contents of the first hard drive to the second one automatically? I mean, every time I add a file on the first hard disk, it will also automatically copy to the second one when it will be connected to the computer. I use a Mac with Apple Silicon. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your attention,&lt;/p&gt;\n\n&lt;p&gt;have a nice day&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akiv6r", "is_robot_indexable": true, "report_reasons": null, "author": "ottocent0", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akiv6r/automatic_11_copy_between_two_hard_drives_on_mac/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akiv6r/automatic_11_copy_between_two_hard_drives_on_mac/", "subreddit_subscribers": 731075, "created_utc": 1707249336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Normally I would post this in /sysadmin, but you gents are pretty keen on the HDD/SDD market, so I hope this is appropriate here.\n\nHave a SMB project coming up, quoted customer 6x 1TB Iron Wolf SATA 2.5 drives for a server running RAID 5, I saw these were available nearly everywhere a week or so ago, fast forward today and now they're no where to be found. Few places I was able to get a hold of informed me they've pulled stock--Amazon, CDW, BH Photo, all echo'd the same thing.\n\nSpecific model is the ZA1000NM1A002\n\nAnyone know what's going on, refresh coming, or have we've moved on from 1TB at this point?", "author_fullname": "t2_ggs59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did Seagate Silently Kill Off Some Iron Wolf SSD Models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al6vme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707323205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Normally I would post this in /sysadmin, but you gents are pretty keen on the HDD/SDD market, so I hope this is appropriate here.&lt;/p&gt;\n\n&lt;p&gt;Have a SMB project coming up, quoted customer 6x 1TB Iron Wolf SATA 2.5 drives for a server running RAID 5, I saw these were available nearly everywhere a week or so ago, fast forward today and now they&amp;#39;re no where to be found. Few places I was able to get a hold of informed me they&amp;#39;ve pulled stock--Amazon, CDW, BH Photo, all echo&amp;#39;d the same thing.&lt;/p&gt;\n\n&lt;p&gt;Specific model is the ZA1000NM1A002&lt;/p&gt;\n\n&lt;p&gt;Anyone know what&amp;#39;s going on, refresh coming, or have we&amp;#39;ve moved on from 1TB at this point?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1al6vme", "is_robot_indexable": true, "report_reasons": null, "author": "Bluetooth_Sandwich", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1al6vme/did_seagate_silently_kill_off_some_iron_wolf_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1al6vme/did_seagate_silently_kill_off_some_iron_wolf_ssd/", "subreddit_subscribers": 731075, "created_utc": 1707323205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am just starting to look into building a 300tb+ NAS build with everything done from scratch.  I am currently close to maxing out my main home computer that has been slowly transformed into a franken storage machine over the years.  I could do more upgrades to give me more room for expansion, but I'd rather just build a proper NAS from scratch.\n\nIf you could do everything over again from scratch, how would you build your perfect NAS? Even down to the chassis, which could be completely custom (I have access to a fab shop). Looking for ideas and complete parts lists if you're willing.", "author_fullname": "t2_ywu72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your perfect NAS build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akpxzf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707266840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am just starting to look into building a 300tb+ NAS build with everything done from scratch.  I am currently close to maxing out my main home computer that has been slowly transformed into a franken storage machine over the years.  I could do more upgrades to give me more room for expansion, but I&amp;#39;d rather just build a proper NAS from scratch.&lt;/p&gt;\n\n&lt;p&gt;If you could do everything over again from scratch, how would you build your perfect NAS? Even down to the chassis, which could be completely custom (I have access to a fab shop). Looking for ideas and complete parts lists if you&amp;#39;re willing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akpxzf", "is_robot_indexable": true, "report_reasons": null, "author": "alpha976", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akpxzf/what_is_your_perfect_nas_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akpxzf/what_is_your_perfect_nas_build/", "subreddit_subscribers": 731075, "created_utc": 1707266840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have searched on this sub, and there seems to be no way to bulk download. The only way to download protected pictures and videos is by doing it one by one. The best method I could find is using the Telegram Web download method. Link here: https://github.com/neet-nestor/telegram-media-downloader\n\nI have to individually open each picture and video and then download individually. Is there any method I can use to bulk download? Some channels I want to download from have hundreds of pictures and videos. It is doable using the above method, but I'm hoping there is a faster way.\n\n[This comment](https://np.reddit.com/r/DataHoarder/comments/12qjefj/how_can_i_download_videos_from_a_private_telegram/jgqjzog/) mentioned to you can create your own Telegram API token and then use a python script to download. I found the Telegram API authorization website [here](https://core.telegram.org/api/), but I'm not sure how to proceed. I found a comment that linked a github repository that's supposed to do this: https://github.com/Nekmo/telegram-upload This looks very promising, but I haven't tried it out yet. Has anyone tried this before? \n\nAnd to reiterate, the channels I want to download from have content protection; the \"export chat history\" method is not an option.\n\nI am using my Windows 10 PC. Please let me know if anyone knows of other methods. Thanks.", "author_fullname": "t2_qulcas15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to bulk download from content protected Telegram channels?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akos4k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707263709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have searched on this sub, and there seems to be no way to bulk download. The only way to download protected pictures and videos is by doing it one by one. The best method I could find is using the Telegram Web download method. Link here: &lt;a href=\"https://github.com/neet-nestor/telegram-media-downloader\"&gt;https://github.com/neet-nestor/telegram-media-downloader&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have to individually open each picture and video and then download individually. Is there any method I can use to bulk download? Some channels I want to download from have hundreds of pictures and videos. It is doable using the above method, but I&amp;#39;m hoping there is a faster way.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://np.reddit.com/r/DataHoarder/comments/12qjefj/how_can_i_download_videos_from_a_private_telegram/jgqjzog/\"&gt;This comment&lt;/a&gt; mentioned to you can create your own Telegram API token and then use a python script to download. I found the Telegram API authorization website &lt;a href=\"https://core.telegram.org/api/\"&gt;here&lt;/a&gt;, but I&amp;#39;m not sure how to proceed. I found a comment that linked a github repository that&amp;#39;s supposed to do this: &lt;a href=\"https://github.com/Nekmo/telegram-upload\"&gt;https://github.com/Nekmo/telegram-upload&lt;/a&gt; This looks very promising, but I haven&amp;#39;t tried it out yet. Has anyone tried this before? &lt;/p&gt;\n\n&lt;p&gt;And to reiterate, the channels I want to download from have content protection; the &amp;quot;export chat history&amp;quot; method is not an option.&lt;/p&gt;\n\n&lt;p&gt;I am using my Windows 10 PC. Please let me know if anyone knows of other methods. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fpsEMceJB_ZNKA3UaqibTk2IdHaqDEtTcXvkWOYe5lY.jpg?auto=webp&amp;s=0d329fc2c6047f70244bafb87f92873fd8fac6d3", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/fpsEMceJB_ZNKA3UaqibTk2IdHaqDEtTcXvkWOYe5lY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a271964331d0a3676f4731567727b8ab7af42691", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/fpsEMceJB_ZNKA3UaqibTk2IdHaqDEtTcXvkWOYe5lY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a51e6869bc93642b3cda2c8c2bb2db5e36845dc8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/fpsEMceJB_ZNKA3UaqibTk2IdHaqDEtTcXvkWOYe5lY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43839ca8b907db9705716864d8f8f7465010e7ce", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/fpsEMceJB_ZNKA3UaqibTk2IdHaqDEtTcXvkWOYe5lY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e0fd170a587af6925cc1174bf52ae05b785b5654", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/fpsEMceJB_ZNKA3UaqibTk2IdHaqDEtTcXvkWOYe5lY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=06d35562b459c4351b24afb15ba081e9f2fa1697", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/fpsEMceJB_ZNKA3UaqibTk2IdHaqDEtTcXvkWOYe5lY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc6a661f256f0fcc43116f7edd3a8d6f6ec207f9", "width": 1080, "height": 540}], "variants": {}, "id": "0UTj1B2nQbSZN1XT3gMcXxExzXjxUO_93KBsWPxvR4U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1akos4k", "is_robot_indexable": true, "report_reasons": null, "author": "IHateReddit_1153151", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akos4k/is_there_a_way_to_bulk_download_from_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akos4k/is_there_a_way_to_bulk_download_from_content/", "subreddit_subscribers": 731075, "created_utc": 1707263709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just got my Asustor Flashstor 6-bay unit, and am dumping content into it from a handful of old storage drives. I have about 7tb of full dvd disc rips, and am trying to source something like Plex or Jellyfin to stream the content, but am coming up blank. \n\nAny suggestions on something that can read/stream the content, or do I need to work on transcoding all of the content so it can be read by the Plex's/Jellyfins of the world?", "author_fullname": "t2_mj5dqg8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transcoding VIDEO_TS Files into something workable for NAS Streaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akl6dv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707254843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got my Asustor Flashstor 6-bay unit, and am dumping content into it from a handful of old storage drives. I have about 7tb of full dvd disc rips, and am trying to source something like Plex or Jellyfin to stream the content, but am coming up blank. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions on something that can read/stream the content, or do I need to work on transcoding all of the content so it can be read by the Plex&amp;#39;s/Jellyfins of the world?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1akl6dv", "is_robot_indexable": true, "report_reasons": null, "author": "HistoricalReturn6468", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1akl6dv/transcoding_video_ts_files_into_something/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1akl6dv/transcoding_video_ts_files_into_something/", "subreddit_subscribers": 731075, "created_utc": 1707254843.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys. I want to get a new small SSD and transfer only my Win11 OS there while keeping all my apps and games on the current drive and be able to boot up later and still have everything working. Is there a quick and easy way to do this?", "author_fullname": "t2_7mk1z6l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transferring JUST the OS to a new drive.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al6ofj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.14, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707322719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. I want to get a new small SSD and transfer only my Win11 OS there while keeping all my apps and games on the current drive and be able to boot up later and still have everything working. Is there a quick and easy way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1al6ofj", "is_robot_indexable": true, "report_reasons": null, "author": "discoreapor", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1al6ofj/transferring_just_the_os_to_a_new_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1al6ofj/transferring_just_the_os_to_a_new_drive/", "subreddit_subscribers": 731075, "created_utc": 1707322719.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}