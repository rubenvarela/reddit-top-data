{"kind": "Listing", "data": {"after": null, "dist": 3, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Perhaps some imposter syndrome, or perhaps not...**basically--how complex ARE your models, realistically, for industry purposes?** \n\n\"Industry Purposes\" in the sense of answering business questions, such as:\n\n* Build me a model that can predict whether a free user is going to convert to a paid user. (Prediction)\n* Here's data from our experiment on Button A vs. Button B, which Button should we use? (Inference)\n* Based on our data from clicks on our website, should we market towards Demographic A? (Inference)\n\nI guess inherently I'm approaching this scenario from a prediction or inference perspective, and not from like a \"building for GenAI or Computer Vision\" perspective.\n\n------------------\n\nI know (and have experienced) that a lot of the work in Data Science is prepping and cleaning the data, but I always feel a little imposter syndrome when I spend the bulk of my time doing that, and then throw the data into a package that creates like a \"black-box\" Random Forest model that spits out the model we ultimately use or deploy.\n\nSure, along the way I spend time tweaking the model parameters (for a Random Forest example--tuning # of trees or depth) and checking my train/test splits, communicating with stakeholders, gaining more domain knowledge, etc., but \"creating the model\" once the data is cleaned to a reasonable degree is just loading things into a package and letting it do the rest. Feels a little too simple and cheap in some respects...especially for the salaries commanded as you go up the chain.\n\nAnd since a lot of money is at stake based on the model performance, it's always a little nerve-wracking to hinge yourself on some black-box model that performed well on your train/test data and \"hope\" it generalizes to unseen data and makes the company some money.\n\nDefinitely much less stressful when it's just projects for academics or hypotheticals where there's no real-world repercussions...there's always that voice in the back of my head saying \"surely, something as simple as this needs to be improved for the company to deem it worth investing so much time/money/etc. into, right?\"\n\n------------------\n\nAnyone else feel this way? Normal feeling--get used to it over time? Or is it that the more experience you gain, the bulk of \"what you are paid for\" isn't necessarily developing complex or novel algorithms for a business question, but rather how you communicate with stakeholders and deal with data-related issues, or similar stuff like that...?\n\n------------------\n\n**EDIT: Some good discussion about what types of models people use on a daily basis for work, but beyond saying \"I use Random Forest/XGBoost/etc.\", do you incorporate more complexity besides the \"simple\" pipeline of: Clean Data -&gt; Import into Package and do basic Train/Test + Hyperparameter Tuning + etc., -&gt; Output Model for Use?**", "author_fullname": "t2_6a2b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How complex ARE your models in Industry, really? (Imposter Syndrome)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akjw7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 167, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 167, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707255673.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707251775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Perhaps some imposter syndrome, or perhaps not...&lt;strong&gt;basically--how complex ARE your models, realistically, for industry purposes?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Industry Purposes&amp;quot; in the sense of answering business questions, such as:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Build me a model that can predict whether a free user is going to convert to a paid user. (Prediction)&lt;/li&gt;\n&lt;li&gt;Here&amp;#39;s data from our experiment on Button A vs. Button B, which Button should we use? (Inference)&lt;/li&gt;\n&lt;li&gt;Based on our data from clicks on our website, should we market towards Demographic A? (Inference)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I guess inherently I&amp;#39;m approaching this scenario from a prediction or inference perspective, and not from like a &amp;quot;building for GenAI or Computer Vision&amp;quot; perspective.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;I know (and have experienced) that a lot of the work in Data Science is prepping and cleaning the data, but I always feel a little imposter syndrome when I spend the bulk of my time doing that, and then throw the data into a package that creates like a &amp;quot;black-box&amp;quot; Random Forest model that spits out the model we ultimately use or deploy.&lt;/p&gt;\n\n&lt;p&gt;Sure, along the way I spend time tweaking the model parameters (for a Random Forest example--tuning # of trees or depth) and checking my train/test splits, communicating with stakeholders, gaining more domain knowledge, etc., but &amp;quot;creating the model&amp;quot; once the data is cleaned to a reasonable degree is just loading things into a package and letting it do the rest. Feels a little too simple and cheap in some respects...especially for the salaries commanded as you go up the chain.&lt;/p&gt;\n\n&lt;p&gt;And since a lot of money is at stake based on the model performance, it&amp;#39;s always a little nerve-wracking to hinge yourself on some black-box model that performed well on your train/test data and &amp;quot;hope&amp;quot; it generalizes to unseen data and makes the company some money.&lt;/p&gt;\n\n&lt;p&gt;Definitely much less stressful when it&amp;#39;s just projects for academics or hypotheticals where there&amp;#39;s no real-world repercussions...there&amp;#39;s always that voice in the back of my head saying &amp;quot;surely, something as simple as this needs to be improved for the company to deem it worth investing so much time/money/etc. into, right?&amp;quot;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Anyone else feel this way? Normal feeling--get used to it over time? Or is it that the more experience you gain, the bulk of &amp;quot;what you are paid for&amp;quot; isn&amp;#39;t necessarily developing complex or novel algorithms for a business question, but rather how you communicate with stakeholders and deal with data-related issues, or similar stuff like that...?&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT: Some good discussion about what types of models people use on a daily basis for work, but beyond saying &amp;quot;I use Random Forest/XGBoost/etc.&amp;quot;, do you incorporate more complexity besides the &amp;quot;simple&amp;quot; pipeline of: Clean Data -&amp;gt; Import into Package and do basic Train/Test + Hyperparameter Tuning + etc., -&amp;gt; Output Model for Use?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1akjw7t", "is_robot_indexable": true, "report_reasons": null, "author": "Joe10112", "discussion_type": null, "num_comments": 123, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1akjw7t/how_complex_are_your_models_in_industry_really/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1akjw7t/how_complex_are_your_models_in_industry_really/", "subreddit_subscribers": 1314955, "created_utc": 1707251775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I really liked the simplicity of the [One Billion Row Challenge (1BRC)](https://github.com/gunnarmorling/1brc) that took off last month.  It was fun to see lots of people apply different tools to the same simple-yet-clear problem \u201cHow do you parse, process, and aggregate a large CSV file as quickly as possible?\u201d\n\nFor fun, my colleagues and I made a One Trillion Row Challenge (1TRC) dataset \ud83d\ude42.  Data lives on S3 in Parquet format (CSV made zero sense here) in a public bucket at s3://coiled-datasets-rp/1trc and is roughly 12 TiB uncompressed.\n\nWe (the Dask team) were able to complete the TRC query in around six minutes for around $1.10.For more information see [this blogpost](https://medium.com/coiled-hq/one-trillion-row-challenge-5bfd4c3b8aef) and [this repository](https://github.com/coiled/1trc/)", "author_fullname": "t2_ay1q1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One Trillion Row Challenge (1 TRC)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al2rly", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Challenges", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707312684.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707312045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really liked the simplicity of the &lt;a href=\"https://github.com/gunnarmorling/1brc\"&gt;One Billion Row Challenge (1BRC)&lt;/a&gt; that took off last month.  It was fun to see lots of people apply different tools to the same simple-yet-clear problem \u201cHow do you parse, process, and aggregate a large CSV file as quickly as possible?\u201d&lt;/p&gt;\n\n&lt;p&gt;For fun, my colleagues and I made a One Trillion Row Challenge (1TRC) dataset \ud83d\ude42.  Data lives on S3 in Parquet format (CSV made zero sense here) in a public bucket at s3://coiled-datasets-rp/1trc and is roughly 12 TiB uncompressed.&lt;/p&gt;\n\n&lt;p&gt;We (the Dask team) were able to complete the TRC query in around six minutes for around $1.10.For more information see &lt;a href=\"https://medium.com/coiled-hq/one-trillion-row-challenge-5bfd4c3b8aef\"&gt;this blogpost&lt;/a&gt; and &lt;a href=\"https://github.com/coiled/1trc/\"&gt;this repository&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?auto=webp&amp;s=558d446820ecd10674797b0e6f49fdc49856cf1e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da65835d0e6cbeef974df8d596e45ac5dc483843", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b51501ef584c9420dcd557eeb630dae5484b90f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2dec7f7846841361ae42f1ff5a57c5c64305bbfa", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac5329409c2cd1ff7938f6f90ffc364fe33e65d9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=91ddd2cd259cedfb6aed6c8a05275dab5dff7375", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4ac4b5bfa44aaa021bee7aa7a99a716955fb1674", "width": 1080, "height": 540}], "variants": {}, "id": "G7IWiakRJ9OfkjMXOnB1vYS7kjkkSa22LpbV5hcjxvA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "417296a0-70eb-11ee-8c58-122e95e91c4c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffd635", "id": "1al2rly", "is_robot_indexable": true, "report_reasons": null, "author": "mrocklin", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1al2rly/one_trillion_row_challenge_1_trc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1al2rly/one_trillion_row_challenge_1_trc/", "subreddit_subscribers": 1314955, "created_utc": 1707312045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been developing NIR spectroscopy model for tablet film coating growth however it required correlation based feature slection and lasso as preprocessing steps as well as orthogonal signal correction. Are these valid approaches to selecting important regions from a nir considering my use cade of not please explain theoretically why jot and if possible provide journal articles i need to publish this journal article soon snd these preprocessing steps were crucial for a low error RMSE RMSEP and high r2 and q2\n\nany opinion will be appreciated sPLS, mwPLS, GA-PLS have been attempted\n\nany other suggestions or justifications for their use will be appreciated\n\nr2 0.808 q2 0.71 error below 5% (not from the start of the coating process so even less)\n\n&amp;#x200B;\n\nplease comment and give even half baked opinions. I just need something to guide my further work.", "author_fullname": "t2_7dv06hd2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OSC (orthogonal signal correction), CFS (correlation based feature selection), Lasso prior to PLS model building", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al0wfh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707308886.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707305605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been developing NIR spectroscopy model for tablet film coating growth however it required correlation based feature slection and lasso as preprocessing steps as well as orthogonal signal correction. Are these valid approaches to selecting important regions from a nir considering my use cade of not please explain theoretically why jot and if possible provide journal articles i need to publish this journal article soon snd these preprocessing steps were crucial for a low error RMSE RMSEP and high r2 and q2&lt;/p&gt;\n\n&lt;p&gt;any opinion will be appreciated sPLS, mwPLS, GA-PLS have been attempted&lt;/p&gt;\n\n&lt;p&gt;any other suggestions or justifications for their use will be appreciated&lt;/p&gt;\n\n&lt;p&gt;r2 0.808 q2 0.71 error below 5% (not from the start of the coating process so even less)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;please comment and give even half baked opinions. I just need something to guide my further work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1al0wfh", "is_robot_indexable": true, "report_reasons": null, "author": "Smart-Firefighter509", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1al0wfh/osc_orthogonal_signal_correction_cfs_correlation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1al0wfh/osc_orthogonal_signal_correction_cfs_correlation/", "subreddit_subscribers": 1314955, "created_utc": 1707305605.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}