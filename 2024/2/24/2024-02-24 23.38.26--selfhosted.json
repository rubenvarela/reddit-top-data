{"kind": "Listing", "data": {"after": "t3_1az3ekf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello!\n\nI\u2019d like to introduce a new open-source project management platform that can be self-hosted on a Kubernetes cluster or with Docker Compose. [Huly](https://huly.io) started as an issue tracker, intended to be an alternative to Jira or Linear, but later evolved into a full process management and collaboration solution. It now includes integrated chats, wikis, GitHub integration, and more.\n\n[Huly User Interface](https://preview.redd.it/26721gi8ckkc1.png?width=2552&amp;format=png&amp;auto=webp&amp;s=34629767bc58f76bf6969b400c7a03f62cf83d2e)\n\nFor those looking to host it, we\u2019re also seeking suggestions to improve the hosting experience. Please share your thoughts [here](https://www.reddit.com/r/selfhosted/comments/1aypth5/seeking_help_to_enhance_products_selfhosting/).\n\n**Links:**\n\n* \ud83d\udc69\ud83c\udffb\u200d\ud83d\udcbb Huly Source Code (EPL-2.0 licensed): Visit our [GitHub repository](https://github.com/hcengineering/platform) for deployment instructions. If you like what we're building, consider giving us a star! \ud83c\udf1f\n* \ud83c\udf0e Huly Website: Learn more about Huly at [https://huly.io](https://huly.io).\n* \ud83d\udda5\ufe0f Huly Live Demo: Experience Huly in action by signing up [here](https://app.huly.io/login/signup).\n* \ud83c\udf99\ufe0f Huly Community Slack: Join our [Slack community](https://join.slack.com/t/hulycommunity/shared_invite/zt-29kl7zmwz-2b3RRVTiWhhtAwzHjBm3Wg) to discuss hosting options, deployment assistance, and more.\n\nKind regards,  \nThe Huly Team", "author_fullname": "t2_8okoad9nw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Huly \u2014 All-in-One Project Management Platform (Alternative to Linear, Jira, Slack, Notion, Motion)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"26721gi8ckkc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/26721gi8ckkc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=819608d9cf2af96fc87c6940ec3b2cf270618634"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/26721gi8ckkc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c0a1aab46a2d10e4a13a6f9405a606bc600489c"}, {"y": 163, "x": 320, "u": "https://preview.redd.it/26721gi8ckkc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=353a33a60bf66d42bd6f81903a1e4c3f5e84b427"}, {"y": 327, "x": 640, "u": "https://preview.redd.it/26721gi8ckkc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9167cf1963b9fc44242b91aec3cec9aec1c2de65"}, {"y": 490, "x": 960, "u": "https://preview.redd.it/26721gi8ckkc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a25c5cd150ca60ab8b0b5666766753f7c384a7a0"}, {"y": 551, "x": 1080, "u": "https://preview.redd.it/26721gi8ckkc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=34e0fb473e37174fa9c3730049353a7a3ceb0082"}], "s": {"y": 1304, "x": 2552, "u": "https://preview.redd.it/26721gi8ckkc1.png?width=2552&amp;format=png&amp;auto=webp&amp;s=34629767bc58f76bf6969b400c7a03f62cf83d2e"}, "id": "26721gi8ckkc1"}}, "name": "t3_1ayz8ty", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 102, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 102, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rzf3kW6Z54mc4sxmtLlrQSulodQf1-P_h6Qior7u4yI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708793672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to introduce a new open-source project management platform that can be self-hosted on a Kubernetes cluster or with Docker Compose. &lt;a href=\"https://huly.io\"&gt;Huly&lt;/a&gt; started as an issue tracker, intended to be an alternative to Jira or Linear, but later evolved into a full process management and collaboration solution. It now includes integrated chats, wikis, GitHub integration, and more.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/26721gi8ckkc1.png?width=2552&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=34629767bc58f76bf6969b400c7a03f62cf83d2e\"&gt;Huly User Interface&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For those looking to host it, we\u2019re also seeking suggestions to improve the hosting experience. Please share your thoughts &lt;a href=\"https://www.reddit.com/r/selfhosted/comments/1aypth5/seeking_help_to_enhance_products_selfhosting/\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\ud83d\udc69\ud83c\udffb\u200d\ud83d\udcbb Huly Source Code (EPL-2.0 licensed): Visit our &lt;a href=\"https://github.com/hcengineering/platform\"&gt;GitHub repository&lt;/a&gt; for deployment instructions. If you like what we&amp;#39;re building, consider giving us a star! \ud83c\udf1f&lt;/li&gt;\n&lt;li&gt;\ud83c\udf0e Huly Website: Learn more about Huly at &lt;a href=\"https://huly.io\"&gt;https://huly.io&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;\ud83d\udda5\ufe0f Huly Live Demo: Experience Huly in action by signing up &lt;a href=\"https://app.huly.io/login/signup\"&gt;here&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;\ud83c\udf99\ufe0f Huly Community Slack: Join our &lt;a href=\"https://join.slack.com/t/hulycommunity/shared_invite/zt-29kl7zmwz-2b3RRVTiWhhtAwzHjBm3Wg\"&gt;Slack community&lt;/a&gt; to discuss hosting options, deployment assistance, and more.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Kind regards,&lt;br/&gt;\nThe Huly Team&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayz8ty", "is_robot_indexable": true, "report_reasons": null, "author": "andreyplatoff", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayz8ty/huly_allinone_project_management_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayz8ty/huly_allinone_project_management_platform/", "subreddit_subscribers": 324361, "created_utc": 1708793672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Currently using Jellyfin, just wondering if there is a better experience?\n\n(Mainly using android and Web player)", "author_fullname": "t2_tf4fsmwxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What server/client do you use for music?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayzlty", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708794559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently using Jellyfin, just wondering if there is a better experience?&lt;/p&gt;\n\n&lt;p&gt;(Mainly using android and Web player)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayzlty", "is_robot_indexable": true, "report_reasons": null, "author": "RathdrumRain", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayzlty/what_serverclient_do_you_use_for_music/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayzlty/what_serverclient_do_you_use_for_music/", "subreddit_subscribers": 324361, "created_utc": 1708794559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "My mother lives a few hundred miles away. I am considering putting a raspberry pi with syncthing on it, just so I have an offsite backup location for my important files in case my house burns down, etc. \n\nIt would essentially only be for backups. I would simply have an external hard drive plugged in via USB, and take up nearly no space in her closet. \n\nDo you have something similar set up? Any additional services which help you be their tech support, something that's helpful for them to have, etc? \n\n&amp;#x200B;\n\nThe other thing I would love is potentially putting a VPN on there so I could watch local shows if necessary. What I mean is sometimes there's a college football game that's only available there, and if I could VPN to that, Fubo might work \"locally\", whereas it'll only show my current location now. ", "author_fullname": "t2_5n0pc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a backup server at someone else's house, like your parents? Considering sending a raspberry pi with my mom.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "remote-access", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayg1j3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Remote Access", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708732978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My mother lives a few hundred miles away. I am considering putting a raspberry pi with syncthing on it, just so I have an offsite backup location for my important files in case my house burns down, etc. &lt;/p&gt;\n\n&lt;p&gt;It would essentially only be for backups. I would simply have an external hard drive plugged in via USB, and take up nearly no space in her closet. &lt;/p&gt;\n\n&lt;p&gt;Do you have something similar set up? Any additional services which help you be their tech support, something that&amp;#39;s helpful for them to have, etc? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The other thing I would love is potentially putting a VPN on there so I could watch local shows if necessary. What I mean is sometimes there&amp;#39;s a college football game that&amp;#39;s only available there, and if I could VPN to that, Fubo might work &amp;quot;locally&amp;quot;, whereas it&amp;#39;ll only show my current location now. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0a45032a-0de1-11ed-997f-0a924a5694f9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayg1j3", "is_robot_indexable": true, "report_reasons": null, "author": "Ptizzl", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayg1j3/do_you_have_a_backup_server_at_someone_elses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayg1j3/do_you_have_a_backup_server_at_someone_elses/", "subreddit_subscribers": 324361, "created_utc": 1708732978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "This is for people who are either new to using docker or who haven't been bitten by this issue yet.\n\nWhen you create a network in docker it's default size is /20. That's 4,094 usable addresses. Now obviously that is overkill for a home network. By default it will use the [172.16.0.0/12](https://172.16.0.0/12) address range but when that runs out, it will eat into the [192.168.0.0/16](https://192.168.0.0/16) range which a lot of home networks use, including mine.\n\nMy recommendation is to adjust the default pool size to something more sane like /24 (254 usable addresses). You can do this by editing the /etc/docker/daemon.json file and restarting the docker service.\n\nThe file will look something like this:\n\n    {\n      \"log-level\": \"warn\",\n      \"log-driver\": \"json-file\",\n      \"log-opts\": {\n        \"max-size\": \"10m\",\n        \"max-file\": \"5\"\n      },\n      \"default-address-pools\": [\n        {\n          \"base\" : \"172.16.0.0/12\",\n          \"size\" : 24\n        }\n      ]\n    }\n\nYou will need to \"down\" any compose files already active and bring them up again in order for the networks to be recreated.", "author_fullname": "t2_cfhrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Adjust your docker default-address-pool size", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1az6mqa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708811847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is for people who are either new to using docker or who haven&amp;#39;t been bitten by this issue yet.&lt;/p&gt;\n\n&lt;p&gt;When you create a network in docker it&amp;#39;s default size is /20. That&amp;#39;s 4,094 usable addresses. Now obviously that is overkill for a home network. By default it will use the &lt;a href=\"https://172.16.0.0/12\"&gt;172.16.0.0/12&lt;/a&gt; address range but when that runs out, it will eat into the &lt;a href=\"https://192.168.0.0/16\"&gt;192.168.0.0/16&lt;/a&gt; range which a lot of home networks use, including mine.&lt;/p&gt;\n\n&lt;p&gt;My recommendation is to adjust the default pool size to something more sane like /24 (254 usable addresses). You can do this by editing the /etc/docker/daemon.json file and restarting the docker service.&lt;/p&gt;\n\n&lt;p&gt;The file will look something like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n  &amp;quot;log-level&amp;quot;: &amp;quot;warn&amp;quot;,\n  &amp;quot;log-driver&amp;quot;: &amp;quot;json-file&amp;quot;,\n  &amp;quot;log-opts&amp;quot;: {\n    &amp;quot;max-size&amp;quot;: &amp;quot;10m&amp;quot;,\n    &amp;quot;max-file&amp;quot;: &amp;quot;5&amp;quot;\n  },\n  &amp;quot;default-address-pools&amp;quot;: [\n    {\n      &amp;quot;base&amp;quot; : &amp;quot;172.16.0.0/12&amp;quot;,\n      &amp;quot;size&amp;quot; : 24\n    }\n  ]\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;You will need to &amp;quot;down&amp;quot; any compose files already active and bring them up again in order for the networks to be recreated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az6mqa", "is_robot_indexable": true, "report_reasons": null, "author": "ANDROID_16", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az6mqa/psa_adjust_your_docker_defaultaddresspool_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az6mqa/psa_adjust_your_docker_defaultaddresspool_size/", "subreddit_subscribers": 324361, "created_utc": 1708811847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi,\n\nI've been dabbling in homelab for over a  year now, and I'm trying to improve things around to rely less on closed software and improve security and privacy.\n\nMy current issue is with my NAS (Synology DS218+), on which I hold a lot of content that I would like to share easily with family and friends, and which is mostly photos (20-50 MB per file) and videos (5-10 GB per file) from holidays and family reunions.\n\nThe core of my question is: is there a decent alternative to Synology Quick connect that meets the following criteria?\n\n1) No technical know-how or software installation required on the client side\n2) The solution is self hosted or locally manageable (no VPS*)\n3) Must allow high bandwidth traffic for file sharing, and ideally for video streaming\n4) Secure and private, ideally FOSS\n*Unless such solution is free and compliant with 3).\n\nSo far I've tested CloudFlare tunnels, they work great to access non-critical services, they match 1 and 2 but fail 3 and 4. I also have Tailscale configured for other purposes, which I think matches 2, 3 and 4-ish (headscale could solve 4). The rest of the solutions I have read about here and elsewhere on the internet usually fail at 1 or 2, which are major to me, or sometimes the compliance with 3 is unclear.\n\nDoes anyone know about another solution that would be a match to all my criteria? I very well know it might not exist (yet?) but it doesn't hurt to ask.\n\nFor additional info, I have a dedicated proxmox server from where I can run things, and I own a domain from CloudFlare.\n\nMany thanks in advance!\n", "author_fullname": "t2_57sil3sk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Secure, self hosted, and FOSS way to expose NAS content with high bandwidth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayu5dm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708780136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been dabbling in homelab for over a  year now, and I&amp;#39;m trying to improve things around to rely less on closed software and improve security and privacy.&lt;/p&gt;\n\n&lt;p&gt;My current issue is with my NAS (Synology DS218+), on which I hold a lot of content that I would like to share easily with family and friends, and which is mostly photos (20-50 MB per file) and videos (5-10 GB per file) from holidays and family reunions.&lt;/p&gt;\n\n&lt;p&gt;The core of my question is: is there a decent alternative to Synology Quick connect that meets the following criteria?&lt;/p&gt;\n\n&lt;p&gt;1) No technical know-how or software installation required on the client side\n2) The solution is self hosted or locally manageable (no VPS*)\n3) Must allow high bandwidth traffic for file sharing, and ideally for video streaming\n4) Secure and private, ideally FOSS\n*Unless such solution is free and compliant with 3).&lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;ve tested CloudFlare tunnels, they work great to access non-critical services, they match 1 and 2 but fail 3 and 4. I also have Tailscale configured for other purposes, which I think matches 2, 3 and 4-ish (headscale could solve 4). The rest of the solutions I have read about here and elsewhere on the internet usually fail at 1 or 2, which are major to me, or sometimes the compliance with 3 is unclear.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know about another solution that would be a match to all my criteria? I very well know it might not exist (yet?) but it doesn&amp;#39;t hurt to ask.&lt;/p&gt;\n\n&lt;p&gt;For additional info, I have a dedicated proxmox server from where I can run things, and I own a domain from CloudFlare.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayu5dm", "is_robot_indexable": true, "report_reasons": null, "author": "Xiaoh_123", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayu5dm/secure_self_hosted_and_foss_way_to_expose_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayu5dm/secure_self_hosted_and_foss_way_to_expose_nas/", "subreddit_subscribers": 324361, "created_utc": 1708780136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey folks,\n\nI have been lurking here for quite some time, saw a few posts ppl asking how do you backup your container data, so I'm sharing the script I use to take daily backups of my containers.\n\nFew prerequisites\n\n* I create all my stacks using docker compose\n* I only use bind mounts and not docker volumes\n* I have setup object expiry on AWS S3 side\n\nI'm no bash expert but here goes. \n\n```\n#!/bin/bash\n\n# System\nNOW=$(date +\"%Y-%m-%d\")\nUSER=\"joeldroid\"\nAPPDATA_FOLDER=\"/home/joeldroid/appdata\"\nBACKUP_FOLDER=\"/mnt/ssd2/backup\"\nNAS_BACKUP_FOLDER=\"/mnt/backups/docker\"\nSLEEP_DURATION_SECS=30\nSEPERATOR=\"-------------------------------------------\"\n# S3\nS3_BUCKET=\"s3://my-docker-s3-bucket/\"\nPASSWORD=$(cat /mnt/ssd2/backup/.encpassword)\n# string array seperated by spaces\n# https://stackoverflow.com/questions/8880603/loop-through-an-array-of-strings-in-bash\ndeclare -a dockerApps=(\"gitea\" \"portainer\" \"freshrss\" \"homer\" \"sqlserver\")\n\necho \"Backup started at $(date)\"\necho $SEPERATOR\n\n# stopping apps\necho \"Stopping apps\"\necho $SEPERATOR\nfor dockerApp in \"${dockerApps[@]}\"\ndo\n  echo \"Stopping $dockerApp\"\n  cd \"$APPDATA_FOLDER/$dockerApp\"\n  docker compose stop\ndone\necho $SEPERATOR\n\n#sleeping\necho \"Sleeping for $SLEEP_DURATION_SECS seconds for graceful shutdown\"\nsleep $SLEEP_DURATION_SECS\necho $SEPERATOR\n\n# backing up\necho \"Backing up apps\"\necho $SEPERATOR\nfor dockerApp in \"${dockerApps[@]}\"\ndo\n  echo \"Backing up $dockerApp\"\n  cd \"$APPDATA_FOLDER/$dockerApp\"\n  mkdir -p \"$BACKUP_FOLDER/backup/$dockerApp\"\n  rsync -a . \"$BACKUP_FOLDER/backup/$dockerApp\"\ndone\necho $SEPERATOR\n\n# starting apps\necho \"Starting apps\"\necho $SEPERATOR\nfor dockerApp in \"${dockerApps[@]}\"\ndo\n  echo \"Starting up $dockerApp\"\n  cd \"$APPDATA_FOLDER/$dockerApp\"\n  docker compose start\ndone\necho $SEPERATOR\n\n#go into rsynced backup directory and then archive for nicer paths\ncd \"$BACKUP_FOLDER/backup\"\n\necho \"Creating archive $NOW.tar.gz\"\ntar -czf \"$BACKUP_FOLDER/$NOW.tar.gz\" .\necho $SEPERATOR\n\n# important make sure you switch to main backup folder\ncd $BACKUP_FOLDER\n\necho \"Encrypting archive\"\ngpg --batch --output \"$NOW.gpg\" --passphrase $PASSWORD --symmetric \"$NOW.tar.gz\"\n# gpg cleanup\necho RELOADAGENT | gpg-connect-agent\necho $SEPERATOR\n\necho \"Copying to NAS\"\ncp \"$NOW.tar.gz\" \"$NAS_BACKUP_FOLDER/$NOW.tar.gz\"\necho $SEPERATOR\n\necho \"Deleteting backups older than 30 days on NAS\"\nfind $NAS_BACKUP_FOLDER -mtime +30 -type f -delete\necho $SEPERATOR\n\necho \"Uploading to S3\"\nsudo -u $USER aws s3 cp \"$NOW.gpg\" $S3_BUCKET --storage-class STANDARD_IA\necho $SEPERATOR\n\necho \"Cleaning up archives\"\nrm \"$NOW.tar.gz\"\nrm \"$NOW.gpg\"\necho $SEPERATOR\n\necho \"Backup Completed\"\necho $SEPERATOR\n```", "author_fullname": "t2_1219tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker backup script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aymgjt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708751773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I have been lurking here for quite some time, saw a few posts ppl asking how do you backup your container data, so I&amp;#39;m sharing the script I use to take daily backups of my containers.&lt;/p&gt;\n\n&lt;p&gt;Few prerequisites&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I create all my stacks using docker compose&lt;/li&gt;\n&lt;li&gt;I only use bind mounts and not docker volumes&lt;/li&gt;\n&lt;li&gt;I have setup object expiry on AWS S3 side&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m no bash expert but here goes. &lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;h1&gt;!/bin/bash&lt;/h1&gt;\n\n&lt;h1&gt;System&lt;/h1&gt;\n\n&lt;p&gt;NOW=$(date +&amp;quot;%Y-%m-%d&amp;quot;)\nUSER=&amp;quot;joeldroid&amp;quot;\nAPPDATA_FOLDER=&amp;quot;/home/joeldroid/appdata&amp;quot;\nBACKUP_FOLDER=&amp;quot;/mnt/ssd2/backup&amp;quot;\nNAS_BACKUP_FOLDER=&amp;quot;/mnt/backups/docker&amp;quot;\nSLEEP_DURATION_SECS=30\nSEPERATOR=&amp;quot;-------------------------------------------&amp;quot;&lt;/p&gt;\n\n&lt;h1&gt;S3&lt;/h1&gt;\n\n&lt;p&gt;S3_BUCKET=&amp;quot;s3://my-docker-s3-bucket/&amp;quot;\nPASSWORD=$(cat /mnt/ssd2/backup/.encpassword)&lt;/p&gt;\n\n&lt;h1&gt;string array seperated by spaces&lt;/h1&gt;\n\n&lt;h1&gt;&lt;a href=\"https://stackoverflow.com/questions/8880603/loop-through-an-array-of-strings-in-bash\"&gt;https://stackoverflow.com/questions/8880603/loop-through-an-array-of-strings-in-bash&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;declare -a dockerApps=(&amp;quot;gitea&amp;quot; &amp;quot;portainer&amp;quot; &amp;quot;freshrss&amp;quot; &amp;quot;homer&amp;quot; &amp;quot;sqlserver&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;echo &amp;quot;Backup started at $(date)&amp;quot;\necho $SEPERATOR&lt;/p&gt;\n\n&lt;h1&gt;stopping apps&lt;/h1&gt;\n\n&lt;p&gt;echo &amp;quot;Stopping apps&amp;quot;\necho $SEPERATOR\nfor dockerApp in &amp;quot;${dockerApps[@]}&amp;quot;\ndo\n  echo &amp;quot;Stopping $dockerApp&amp;quot;\n  cd &amp;quot;$APPDATA_FOLDER/$dockerApp&amp;quot;\n  docker compose stop\ndone\necho $SEPERATOR&lt;/p&gt;\n\n&lt;h1&gt;sleeping&lt;/h1&gt;\n\n&lt;p&gt;echo &amp;quot;Sleeping for $SLEEP_DURATION_SECS seconds for graceful shutdown&amp;quot;\nsleep $SLEEP_DURATION_SECS\necho $SEPERATOR&lt;/p&gt;\n\n&lt;h1&gt;backing up&lt;/h1&gt;\n\n&lt;p&gt;echo &amp;quot;Backing up apps&amp;quot;\necho $SEPERATOR\nfor dockerApp in &amp;quot;${dockerApps[@]}&amp;quot;\ndo\n  echo &amp;quot;Backing up $dockerApp&amp;quot;\n  cd &amp;quot;$APPDATA_FOLDER/$dockerApp&amp;quot;\n  mkdir -p &amp;quot;$BACKUP_FOLDER/backup/$dockerApp&amp;quot;\n  rsync -a . &amp;quot;$BACKUP_FOLDER/backup/$dockerApp&amp;quot;\ndone\necho $SEPERATOR&lt;/p&gt;\n\n&lt;h1&gt;starting apps&lt;/h1&gt;\n\n&lt;p&gt;echo &amp;quot;Starting apps&amp;quot;\necho $SEPERATOR\nfor dockerApp in &amp;quot;${dockerApps[@]}&amp;quot;\ndo\n  echo &amp;quot;Starting up $dockerApp&amp;quot;\n  cd &amp;quot;$APPDATA_FOLDER/$dockerApp&amp;quot;\n  docker compose start\ndone\necho $SEPERATOR&lt;/p&gt;\n\n&lt;h1&gt;go into rsynced backup directory and then archive for nicer paths&lt;/h1&gt;\n\n&lt;p&gt;cd &amp;quot;$BACKUP_FOLDER/backup&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;echo &amp;quot;Creating archive $NOW.tar.gz&amp;quot;\ntar -czf &amp;quot;$BACKUP_FOLDER/$NOW.tar.gz&amp;quot; .\necho $SEPERATOR&lt;/p&gt;\n\n&lt;h1&gt;important make sure you switch to main backup folder&lt;/h1&gt;\n\n&lt;p&gt;cd $BACKUP_FOLDER&lt;/p&gt;\n\n&lt;p&gt;echo &amp;quot;Encrypting archive&amp;quot;\ngpg --batch --output &amp;quot;$NOW.gpg&amp;quot; --passphrase $PASSWORD --symmetric &amp;quot;$NOW.tar.gz&amp;quot;&lt;/p&gt;\n\n&lt;h1&gt;gpg cleanup&lt;/h1&gt;\n\n&lt;p&gt;echo RELOADAGENT | gpg-connect-agent\necho $SEPERATOR&lt;/p&gt;\n\n&lt;p&gt;echo &amp;quot;Copying to NAS&amp;quot;\ncp &amp;quot;$NOW.tar.gz&amp;quot; &amp;quot;$NAS_BACKUP_FOLDER/$NOW.tar.gz&amp;quot;\necho $SEPERATOR&lt;/p&gt;\n\n&lt;p&gt;echo &amp;quot;Deleteting backups older than 30 days on NAS&amp;quot;\nfind $NAS_BACKUP_FOLDER -mtime +30 -type f -delete\necho $SEPERATOR&lt;/p&gt;\n\n&lt;p&gt;echo &amp;quot;Uploading to S3&amp;quot;\nsudo -u $USER aws s3 cp &amp;quot;$NOW.gpg&amp;quot; $S3_BUCKET --storage-class STANDARD_IA\necho $SEPERATOR&lt;/p&gt;\n\n&lt;p&gt;echo &amp;quot;Cleaning up archives&amp;quot;\nrm &amp;quot;$NOW.tar.gz&amp;quot;\nrm &amp;quot;$NOW.gpg&amp;quot;\necho $SEPERATOR&lt;/p&gt;\n\n&lt;p&gt;echo &amp;quot;Backup Completed&amp;quot;\necho $SEPERATOR\n```&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?auto=webp&amp;s=a70d21ce9f01f64670d2200ca9fc3f39b94a7e48", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aad06750c23b98c9b7595343a8b54a42dc18851", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b66126834977e269be586d07464046049ed09138", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1aymgjt", "is_robot_indexable": true, "report_reasons": null, "author": "joeldroid", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1aymgjt/docker_backup_script/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1aymgjt/docker_backup_script/", "subreddit_subscribers": 324361, "created_utc": 1708751773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Just thought I should share this since I went through a fair amount of pain:\n\nI have wanted an email archive system for a long time. Client mail copies are unreliable and provider storage starts to cost.\n\nNow that I have proxmox setup on a Dell Poweredge 610, seemed like a good opportunity.\n\nRequirements:\n- Incremental fetch from existing imap/pop3/g.ail mailboxes\n- Store in searchable form - but the less separate databases etc, the better\n- Have a web interface for searching\n- Good performance as volumes grow\n- Authentication for multiple users\n- Ideally can run as an lxc\n\nStrangely, there doesn't really seem to be a good complete solution for this but settled on mailarchiva. Like many though, it seems to rely on the idea that it will have a source of emails that it can consume and destroy - they talk about bcc-ing emails to a special separate journal mailbox fire example. I just want it to go and get any emails or hasn't already from the place they already are - you know, like all the non-archiving email clients out there.\n\nThe solution I ended up with works really well and comprises:\n- getmail - to read from the remote mailboxes, which then streams them to...\n- msmtp - to forward the emails to an SMTP listener which is part of...\n- mailarchiva - which archives the emails - used good old fashioned data and index files so nothing extra like mysql you deal with and backup\n\nAll this is running and working in a debian 12 lxc.\n\nStrangely - the middle one was the most difficult bit: \n\nMost obvious first choice would be sendmail - but that seems to come from the primordial ooze of the early internet - it insists on validating email address against DNS for example which is not remotely useful in this little relay requirement (and don't get me started on the bizarre config file which mixes quotes and backticks).\n\nNext stop: ssmtp - nice and simple with none of the nonsense until I saw the message that it is no longer maintained, so on to...\n\nMsmtp: really easy and straightforward - just does the job.\n\nGetmail - had to run that as a non root user (i know, I'm lazy) or it won't run msmtp/sendmail. I started with pop3 access but realised that the only way that getmail can remember what emails it has already fetched since last time is to store them all in an oldmail file. Didn't fancy that, so switched to imap which, I was pleased to discover (and of course when I think about it) won't delete locally when deleted in the remote mailbox or vice versa, because it's just a relay. It remembers where it was with just a simple high watermark stored in the oldmail file.\n\nYou basically configure each mailbox with the receive protocol, server, port, credentials information and the destination protocol, command, arguments - on my case that's to run msmtp to send the fetched email to the mailarchive smtp listener.\n\nMailarchiva config is a bit confusing: there's an smtp client, an smtp listener, an smtp route and what documentation I felt matched best said to use a milter connection instead which can also listen to smtp (but then they said that smtp was better somewhere else).\n\nSo what worked was setting smtp listener, nothing else, no certificates, unsecured, no login etc (maybe I will tighten that later) which listens on poet 8092 by default - which is the port you tell getmail to use with msmtp.\n\nWorks great and had finished arguing 20k+ emails from my mail mailbox.\n\nI can post more details of the exact config if anyone is interested, but briefly I:\n- created a debian 12 vanilla lxc - 4G ram, 2 cores, 8gb root partition and a 64gb mount point at /mnt/mailarchiva.\n- did the usual apt update &amp;&amp; apt full-upgrade\n- apt install for: curl, getmail6, msmtp\n- followed the debian install instructions for mailarchiva\n- had to enable and start the systemd mailarchiva service\n- adduser getmail\n- created ~/.getmail and a config file for each mailbox in there.\n- configured mailarchiva (web admin)\n    - I set the volume, index and appdatd paths to be under /mnt/mailarchiva\n    - one weird thing is that it ignored the appdata path and left it at the default, so I moved the contents of the default directory when I was done and replaced it with a symlink\n    - configured the smtp listener as above\n- ran getmail --rcfile=(configfile) for each mailbox\n\nAnd it worked!\n\nConfigured my nginx reverse proxy to point to it with an external sub domain (you need to enable websockets which some of the pages need)\n\nIt also can work with Authentik via OpenID which is nice and it recognises the email address there and uses it (I manage who can access the mailarchiva in authentik).\n\nAnother strange thing - you can assign all users the role \"users\" which means that it should use the email field from authentik to mean they get access to any email in the archive where their email address is in any of the email fields. But that doesn't work (hard coding the email address on the role works fine). So I ended up creating a role per user and mapping that role in the openid role assignment - I only have a few users so no big deal, and I can also extend access to other email addresses they use.\n\nOnly thing I have to do now is set this up to run say every hour as part of the getmail crontab.\n\nJust typed this on my phone while I remember - let me know if your want more specifics.", "author_fullname": "t2_165rtw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Email archiving &amp; external mailboxes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "emailmanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az198n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Email Management", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708798572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just thought I should share this since I went through a fair amount of pain:&lt;/p&gt;\n\n&lt;p&gt;I have wanted an email archive system for a long time. Client mail copies are unreliable and provider storage starts to cost.&lt;/p&gt;\n\n&lt;p&gt;Now that I have proxmox setup on a Dell Poweredge 610, seemed like a good opportunity.&lt;/p&gt;\n\n&lt;p&gt;Requirements:\n- Incremental fetch from existing imap/pop3/g.ail mailboxes\n- Store in searchable form - but the less separate databases etc, the better\n- Have a web interface for searching\n- Good performance as volumes grow\n- Authentication for multiple users\n- Ideally can run as an lxc&lt;/p&gt;\n\n&lt;p&gt;Strangely, there doesn&amp;#39;t really seem to be a good complete solution for this but settled on mailarchiva. Like many though, it seems to rely on the idea that it will have a source of emails that it can consume and destroy - they talk about bcc-ing emails to a special separate journal mailbox fire example. I just want it to go and get any emails or hasn&amp;#39;t already from the place they already are - you know, like all the non-archiving email clients out there.&lt;/p&gt;\n\n&lt;p&gt;The solution I ended up with works really well and comprises:\n- getmail - to read from the remote mailboxes, which then streams them to...\n- msmtp - to forward the emails to an SMTP listener which is part of...\n- mailarchiva - which archives the emails - used good old fashioned data and index files so nothing extra like mysql you deal with and backup&lt;/p&gt;\n\n&lt;p&gt;All this is running and working in a debian 12 lxc.&lt;/p&gt;\n\n&lt;p&gt;Strangely - the middle one was the most difficult bit: &lt;/p&gt;\n\n&lt;p&gt;Most obvious first choice would be sendmail - but that seems to come from the primordial ooze of the early internet - it insists on validating email address against DNS for example which is not remotely useful in this little relay requirement (and don&amp;#39;t get me started on the bizarre config file which mixes quotes and backticks).&lt;/p&gt;\n\n&lt;p&gt;Next stop: ssmtp - nice and simple with none of the nonsense until I saw the message that it is no longer maintained, so on to...&lt;/p&gt;\n\n&lt;p&gt;Msmtp: really easy and straightforward - just does the job.&lt;/p&gt;\n\n&lt;p&gt;Getmail - had to run that as a non root user (i know, I&amp;#39;m lazy) or it won&amp;#39;t run msmtp/sendmail. I started with pop3 access but realised that the only way that getmail can remember what emails it has already fetched since last time is to store them all in an oldmail file. Didn&amp;#39;t fancy that, so switched to imap which, I was pleased to discover (and of course when I think about it) won&amp;#39;t delete locally when deleted in the remote mailbox or vice versa, because it&amp;#39;s just a relay. It remembers where it was with just a simple high watermark stored in the oldmail file.&lt;/p&gt;\n\n&lt;p&gt;You basically configure each mailbox with the receive protocol, server, port, credentials information and the destination protocol, command, arguments - on my case that&amp;#39;s to run msmtp to send the fetched email to the mailarchive smtp listener.&lt;/p&gt;\n\n&lt;p&gt;Mailarchiva config is a bit confusing: there&amp;#39;s an smtp client, an smtp listener, an smtp route and what documentation I felt matched best said to use a milter connection instead which can also listen to smtp (but then they said that smtp was better somewhere else).&lt;/p&gt;\n\n&lt;p&gt;So what worked was setting smtp listener, nothing else, no certificates, unsecured, no login etc (maybe I will tighten that later) which listens on poet 8092 by default - which is the port you tell getmail to use with msmtp.&lt;/p&gt;\n\n&lt;p&gt;Works great and had finished arguing 20k+ emails from my mail mailbox.&lt;/p&gt;\n\n&lt;p&gt;I can post more details of the exact config if anyone is interested, but briefly I:\n- created a debian 12 vanilla lxc - 4G ram, 2 cores, 8gb root partition and a 64gb mount point at /mnt/mailarchiva.\n- did the usual apt update &amp;amp;&amp;amp; apt full-upgrade\n- apt install for: curl, getmail6, msmtp\n- followed the debian install instructions for mailarchiva\n- had to enable and start the systemd mailarchiva service\n- adduser getmail\n- created ~/.getmail and a config file for each mailbox in there.\n- configured mailarchiva (web admin)\n    - I set the volume, index and appdatd paths to be under /mnt/mailarchiva\n    - one weird thing is that it ignored the appdata path and left it at the default, so I moved the contents of the default directory when I was done and replaced it with a symlink\n    - configured the smtp listener as above\n- ran getmail --rcfile=(configfile) for each mailbox&lt;/p&gt;\n\n&lt;p&gt;And it worked!&lt;/p&gt;\n\n&lt;p&gt;Configured my nginx reverse proxy to point to it with an external sub domain (you need to enable websockets which some of the pages need)&lt;/p&gt;\n\n&lt;p&gt;It also can work with Authentik via OpenID which is nice and it recognises the email address there and uses it (I manage who can access the mailarchiva in authentik).&lt;/p&gt;\n\n&lt;p&gt;Another strange thing - you can assign all users the role &amp;quot;users&amp;quot; which means that it should use the email field from authentik to mean they get access to any email in the archive where their email address is in any of the email fields. But that doesn&amp;#39;t work (hard coding the email address on the role works fine). So I ended up creating a role per user and mapping that role in the openid role assignment - I only have a few users so no big deal, and I can also extend access to other email addresses they use.&lt;/p&gt;\n\n&lt;p&gt;Only thing I have to do now is set this up to run say every hour as part of the getmail crontab.&lt;/p&gt;\n\n&lt;p&gt;Just typed this on my phone while I remember - let me know if your want more specifics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0690f484-7e68-11e9-80db-0eb480af1d48", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az198n", "is_robot_indexable": true, "report_reasons": null, "author": "AndyMarden", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az198n/email_archiving_external_mailboxes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az198n/email_archiving_external_mailboxes/", "subreddit_subscribers": 324361, "created_utc": 1708798572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I don't think this exists, but asking in case. \n\n[Excludarr](https://github.com/haijeploeg/excludarr) *\"is a CLI that interacts with Radarr and Sonarr instances. It completely manages your library in Sonarr and Radarr to only consist out of movies and series that are not present on any of the configured streaming providers. Excludarr can also re-monitor movies and series if it is not available anymore on any of the configured streaming providers. You can also configure to delete the already downloaded files of the excluded entry to keep your storage happy! \"*\n\nMy wife has a habit of Overseerring stuff that's already on netflix, which is annoying.\n\nWhat I'm fantasising about is a version of Excludarr that\n\n1) Has a nice, simple web UI rather than CLI\n\n2) Auto-runs every night / week / month / whatever, scans radarr / sonarr and makes a list of items that already appear on netflix / prime etc\n\n 3) Sends me that list via a slack message / email / other selectable channels so I can consider what to keep and what to delete\n\n4) When I go back to the web UI the found list is there, and i can tick / untick what to keep or delete\n\n5) Has a nice docker compose to do all the above\n\nGuessing that doesn't exist, does it?\n\n*Edit: maybe a question for* u/haijep *I guess* ", "author_fullname": "t2_24kozc82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Excludarr extended?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayy7eq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708791123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t think this exists, but asking in case. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/haijeploeg/excludarr\"&gt;Excludarr&lt;/a&gt; &lt;em&gt;&amp;quot;is a CLI that interacts with Radarr and Sonarr instances. It completely manages your library in Sonarr and Radarr to only consist out of movies and series that are not present on any of the configured streaming providers. Excludarr can also re-monitor movies and series if it is not available anymore on any of the configured streaming providers. You can also configure to delete the already downloaded files of the excluded entry to keep your storage happy! &amp;quot;&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;My wife has a habit of Overseerring stuff that&amp;#39;s already on netflix, which is annoying.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m fantasising about is a version of Excludarr that&lt;/p&gt;\n\n&lt;p&gt;1) Has a nice, simple web UI rather than CLI&lt;/p&gt;\n\n&lt;p&gt;2) Auto-runs every night / week / month / whatever, scans radarr / sonarr and makes a list of items that already appear on netflix / prime etc&lt;/p&gt;\n\n&lt;p&gt;3) Sends me that list via a slack message / email / other selectable channels so I can consider what to keep and what to delete&lt;/p&gt;\n\n&lt;p&gt;4) When I go back to the web UI the found list is there, and i can tick / untick what to keep or delete&lt;/p&gt;\n\n&lt;p&gt;5) Has a nice docker compose to do all the above&lt;/p&gt;\n\n&lt;p&gt;Guessing that doesn&amp;#39;t exist, does it?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit: maybe a question for&lt;/em&gt; &lt;a href=\"/u/haijep\"&gt;u/haijep&lt;/a&gt; &lt;em&gt;I guess&lt;/em&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayy7eq", "is_robot_indexable": true, "report_reasons": null, "author": "CrispyBegs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayy7eq/excludarr_extended/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayy7eq/excludarr_extended/", "subreddit_subscribers": 324361, "created_utc": 1708791123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have kept all the boxes that the PC's I have built family members over the years, along with server parts, harddrives, etc.. and I would love to get rid of them, and track  information in some self hosted application. I know about Snipe IT, but just wondering if there are other options that people have implemented and have opinions on...\n\n**A few Requirements**\n\nSelf hosted, docker preferred\n\nCan store various levels of detail for the assets (for exampe: UPC, Item name, manufacturer, where it is installed, warranty information if any, purchase date, etc.. not all of these are as important as others)\n\nCan integrate with Authentik", "author_fullname": "t2_c517o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to get rid of some boxes from computer parts, server parts; looking for a solution to self host that info", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aywg6h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708786651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have kept all the boxes that the PC&amp;#39;s I have built family members over the years, along with server parts, harddrives, etc.. and I would love to get rid of them, and track  information in some self hosted application. I know about Snipe IT, but just wondering if there are other options that people have implemented and have opinions on...&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;A few Requirements&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Self hosted, docker preferred&lt;/p&gt;\n\n&lt;p&gt;Can store various levels of detail for the assets (for exampe: UPC, Item name, manufacturer, where it is installed, warranty information if any, purchase date, etc.. not all of these are as important as others)&lt;/p&gt;\n\n&lt;p&gt;Can integrate with Authentik&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1aywg6h", "is_robot_indexable": true, "report_reasons": null, "author": "TheePorkchopExpress", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1aywg6h/looking_to_get_rid_of_some_boxes_from_computer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1aywg6h/looking_to_get_rid_of_some_boxes_from_computer/", "subreddit_subscribers": 324361, "created_utc": 1708786651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Dear r/selfhosted community,\n\nWe're developing Huly, an open-source product designed for on-premises installation by end users. Simplified, Huly serves as an \"All-in-One Replacement for Linear/Jira, Slack, Notion, Motion, and more.\" You can explore the source code for Huly here: [https://github.com/hcengineering/platform](https://github.com/hcengineering/platform).\n\nAs we've entered production mode, our next goal is to refine the self-hosting capabilities of our product. To this end, we're reaching out to the community for advice on optimal packaging strategies and to address various self-hosting scenarios.\n\nCurrently, we support deployment through docker-compose, which our developers use daily for local testing. Additionally, we offer configurations for deploying Huly into a Kubernetes cluster. These two methods are our primary focus, but we're open to expanding our support based on your feedback.\n\nHuly deployment comprises several components, including:\n\n* Multiple stateless services (within docker containers)\n* Integration-specific stateless services (e.g., for Google Mail, Google Calendar, Slack)\n* MongoDB instance(s)\n* Elasticsearch instance(s)\n* Minio instance(s)\n\nDeploying these components with docker-compose is straightforward, but we're eager to learn from both seasoned and novice self-hosters about best practices, especially for managing stateful services like MongoDB, Elasticsearch, and Minio.\n\nOur questions revolve around two main areas:\n\n1. **Shared Services**: Is there interest in a setup where multiple self-hosted products share instances of services like Minio or Elasticsearch to use resources more efficiently? Is this approach still relevant?\n2. **Stateful Services Hosting**: Managing stateful services involves complexities related to persistent data, such as ensuring data availability after restarts and implementing backup strategies. How do you manage these challenges, and what best practices can you share? For example we manage stateful services in separate VMs out of Kubernetes cluster. I would not like to say this is a way to go, but is this a scenario some people would love to use as well?\n\nAlso, we're addressing the complexities of integrating with external services, for example Google Calendar, which is vital for Huly's Personal and Team planning features. Integrating with Google Calendar necessitates Google's permission to use their APIs\u2014a process that is straightforward for our main deployment at [https://huly.io](https://huly.io). However, this integration might present challenges for self-hosted instances, including navigating legal and usage terms. We're interested in understanding how the self-hosting community approaches these scenarios.\n\nLastly, we're considering email notification services. Currently, we use AWS SES, but we understand the need for flexibility in self-hosted environments. Would support for multiple email services be beneficial (because sending email is quite complicated this days), or is an SMTP server sufficient?\n\nAlso what you guys think about supporting services like *elestio* in addition to docker-compose and Kubernetes options for deployment?\n\nWe're committed to making Huly an excellent option for self-hosting and eagerly await your insights and suggestions.\n\nThank you! -- The Huly Team", "author_fullname": "t2_8okoad9nw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Help to Enhance Product's Self-Hosting Capabilities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aypth5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708764040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt; community,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re developing Huly, an open-source product designed for on-premises installation by end users. Simplified, Huly serves as an &amp;quot;All-in-One Replacement for Linear/Jira, Slack, Notion, Motion, and more.&amp;quot; You can explore the source code for Huly here: &lt;a href=\"https://github.com/hcengineering/platform\"&gt;https://github.com/hcengineering/platform&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;As we&amp;#39;ve entered production mode, our next goal is to refine the self-hosting capabilities of our product. To this end, we&amp;#39;re reaching out to the community for advice on optimal packaging strategies and to address various self-hosting scenarios.&lt;/p&gt;\n\n&lt;p&gt;Currently, we support deployment through docker-compose, which our developers use daily for local testing. Additionally, we offer configurations for deploying Huly into a Kubernetes cluster. These two methods are our primary focus, but we&amp;#39;re open to expanding our support based on your feedback.&lt;/p&gt;\n\n&lt;p&gt;Huly deployment comprises several components, including:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Multiple stateless services (within docker containers)&lt;/li&gt;\n&lt;li&gt;Integration-specific stateless services (e.g., for Google Mail, Google Calendar, Slack)&lt;/li&gt;\n&lt;li&gt;MongoDB instance(s)&lt;/li&gt;\n&lt;li&gt;Elasticsearch instance(s)&lt;/li&gt;\n&lt;li&gt;Minio instance(s)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Deploying these components with docker-compose is straightforward, but we&amp;#39;re eager to learn from both seasoned and novice self-hosters about best practices, especially for managing stateful services like MongoDB, Elasticsearch, and Minio.&lt;/p&gt;\n\n&lt;p&gt;Our questions revolve around two main areas:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Shared Services&lt;/strong&gt;: Is there interest in a setup where multiple self-hosted products share instances of services like Minio or Elasticsearch to use resources more efficiently? Is this approach still relevant?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Stateful Services Hosting&lt;/strong&gt;: Managing stateful services involves complexities related to persistent data, such as ensuring data availability after restarts and implementing backup strategies. How do you manage these challenges, and what best practices can you share? For example we manage stateful services in separate VMs out of Kubernetes cluster. I would not like to say this is a way to go, but is this a scenario some people would love to use as well?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Also, we&amp;#39;re addressing the complexities of integrating with external services, for example Google Calendar, which is vital for Huly&amp;#39;s Personal and Team planning features. Integrating with Google Calendar necessitates Google&amp;#39;s permission to use their APIs\u2014a process that is straightforward for our main deployment at &lt;a href=\"https://huly.io\"&gt;https://huly.io&lt;/a&gt;. However, this integration might present challenges for self-hosted instances, including navigating legal and usage terms. We&amp;#39;re interested in understanding how the self-hosting community approaches these scenarios.&lt;/p&gt;\n\n&lt;p&gt;Lastly, we&amp;#39;re considering email notification services. Currently, we use AWS SES, but we understand the need for flexibility in self-hosted environments. Would support for multiple email services be beneficial (because sending email is quite complicated this days), or is an SMTP server sufficient?&lt;/p&gt;\n\n&lt;p&gt;Also what you guys think about supporting services like &lt;em&gt;elestio&lt;/em&gt; in addition to docker-compose and Kubernetes options for deployment?&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re committed to making Huly an excellent option for self-hosting and eagerly await your insights and suggestions.&lt;/p&gt;\n\n&lt;p&gt;Thank you! -- The Huly Team&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6nKm9X0sAAmt3c8ZdpQsZjE4uLuE4cIel9Crbi3DBXw.jpg?auto=webp&amp;s=3ca33cf2c9145b9fcf065486ad82eef6a05f0ab5", "width": 3000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/6nKm9X0sAAmt3c8ZdpQsZjE4uLuE4cIel9Crbi3DBXw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ccc4f04b664e215ff36356b1bd74e11930b2553", "width": 108, "height": 36}, {"url": "https://external-preview.redd.it/6nKm9X0sAAmt3c8ZdpQsZjE4uLuE4cIel9Crbi3DBXw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef68edabf3ac054d30e479f1c43f33af7b9ea5b8", "width": 216, "height": 72}, {"url": "https://external-preview.redd.it/6nKm9X0sAAmt3c8ZdpQsZjE4uLuE4cIel9Crbi3DBXw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3bbe7eba9cde31b976195613856afa7ae2cf6e9f", "width": 320, "height": 106}, {"url": "https://external-preview.redd.it/6nKm9X0sAAmt3c8ZdpQsZjE4uLuE4cIel9Crbi3DBXw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6b628a56e8f17241b34fe288e352523c64564a52", "width": 640, "height": 213}, {"url": "https://external-preview.redd.it/6nKm9X0sAAmt3c8ZdpQsZjE4uLuE4cIel9Crbi3DBXw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ff98be4dc1636f353ca1ea5132b86ab460d01e02", "width": 960, "height": 320}, {"url": "https://external-preview.redd.it/6nKm9X0sAAmt3c8ZdpQsZjE4uLuE4cIel9Crbi3DBXw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ea3cdf020193370fae93697944a835b827749e4", "width": 1080, "height": 360}], "variants": {}, "id": "QJzHwCnatTQDDowuT_uVW3ZDdPSbuURX239zJV8ZebM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1aypth5", "is_robot_indexable": true, "report_reasons": null, "author": "andreyplatoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1aypth5/seeking_help_to_enhance_products_selfhosting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1aypth5/seeking_help_to_enhance_products_selfhosting/", "subreddit_subscribers": 324361, "created_utc": 1708764040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Any self hosted solution like gihub codespaces? For source code isolation\n", "author_fullname": "t2_e72rq5jg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Codespaces", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayz7ep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708793574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any self hosted solution like gihub codespaces? For source code isolation&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayz7ep", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic-Sound7496", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayz7ep/codespaces/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayz7ep/codespaces/", "subreddit_subscribers": 324361, "created_utc": 1708793574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "My issue is that I have a folder of individual mp3 tracks, but Jellyfin treats them as one big album.\nIs there a way to specify folders as singles only?", "author_fullname": "t2_tf4fsmwxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jellyfin music, how do I get it to treat singles differently than albums?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayt7z9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708777105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My issue is that I have a folder of individual mp3 tracks, but Jellyfin treats them as one big album.\nIs there a way to specify folders as singles only?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayt7z9", "is_robot_indexable": true, "report_reasons": null, "author": "RathdrumRain", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayt7z9/jellyfin_music_how_do_i_get_it_to_treat_singles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayt7z9/jellyfin_music_how_do_i_get_it_to_treat_singles/", "subreddit_subscribers": 324361, "created_utc": 1708777105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello World!\n\n&amp;#x200B;\n\nI am looking to create a photo gallery of all the (\\~300 GB) family photos i have so everyone in the family can have access to these photos to look at and download easily.\n\n&amp;#x200B;\n\nTwo important requirements:\n\n1- The software to be used must have the ability to be linked to the photos folder i already have on the server.\n\n2- Must organize the photos via Albums and timeline. (Having Face detection is a huge plus too)\n\nNote: I prefer to use TrueCharts stuff to easily use ingress to revirse proxy all my stuff.\n\nI have tried installing [Immich](https://github.com/immich-app/immich)but looks like it was removed from TrueCharts and the one in TrueNAS chart in stuck at \"Deploying\" for hours. Also, I have tried [PhotoView](https://github.com/photoview/photoview) which unfortunately gets stuck halfway while scanning my photos folder and fails to load the rest.\n\n&amp;#x200B;\n\nCan you guys suggest something to fit my needs?\n\n&amp;#x200B;\n\nEdit: spelling.", "author_fullname": "t2_119ikn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a photo gallery software to install on my TrueNAS server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "phototools", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayoxad", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Photo Tools", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708760539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello World!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am looking to create a photo gallery of all the (~300 GB) family photos i have so everyone in the family can have access to these photos to look at and download easily.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Two important requirements:&lt;/p&gt;\n\n&lt;p&gt;1- The software to be used must have the ability to be linked to the photos folder i already have on the server.&lt;/p&gt;\n\n&lt;p&gt;2- Must organize the photos via Albums and timeline. (Having Face detection is a huge plus too)&lt;/p&gt;\n\n&lt;p&gt;Note: I prefer to use TrueCharts stuff to easily use ingress to revirse proxy all my stuff.&lt;/p&gt;\n\n&lt;p&gt;I have tried installing &lt;a href=\"https://github.com/immich-app/immich\"&gt;Immich&lt;/a&gt;but looks like it was removed from TrueCharts and the one in TrueNAS chart in stuck at &amp;quot;Deploying&amp;quot; for hours. Also, I have tried &lt;a href=\"https://github.com/photoview/photoview\"&gt;PhotoView&lt;/a&gt; which unfortunately gets stuck halfway while scanning my photos folder and fails to load the rest.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can you guys suggest something to fit my needs?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: spelling.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mDtvmBI9fkbg8Dpr63WqaTEk1qlueXUN3heQ8xEacL4.jpg?auto=webp&amp;s=c2599b510f65328c3fa65bc2e8d19bcdde3bbfae", "width": 1024, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/mDtvmBI9fkbg8Dpr63WqaTEk1qlueXUN3heQ8xEacL4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=34a248e42afda0d01cc0667e416cf92d8497cd69", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/mDtvmBI9fkbg8Dpr63WqaTEk1qlueXUN3heQ8xEacL4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9a01f6689cb8059645feb84a7b208ef93d5a89b", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/mDtvmBI9fkbg8Dpr63WqaTEk1qlueXUN3heQ8xEacL4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6f063566d7c8da88afae1055f644128192eff71", "width": 320, "height": 156}, {"url": "https://external-preview.redd.it/mDtvmBI9fkbg8Dpr63WqaTEk1qlueXUN3heQ8xEacL4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=67ee721c84131774dd42d38c88dfb8b59b70753c", "width": 640, "height": 312}, {"url": "https://external-preview.redd.it/mDtvmBI9fkbg8Dpr63WqaTEk1qlueXUN3heQ8xEacL4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d8af63627a335d23033bcd175992e9d69c1d6158", "width": 960, "height": 468}], "variants": {}, "id": "ZScm166yLedqFeqCCAktAdaYu3GlCHXIUEsFb3OLb00"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4474b0e2-7e68-11e9-96f8-0e01fac4c7aa", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayoxad", "is_robot_indexable": true, "report_reasons": null, "author": "aajaas", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayoxad/looking_for_a_photo_gallery_software_to_install/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayoxad/looking_for_a_photo_gallery_software_to_install/", "subreddit_subscribers": 324361, "created_utc": 1708760539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm planning to install several CCTV in my neighborhood, I want to view the live cam through web interface like Shinobi hosted in VPS (meaning no local server), is this possible ? For this to works I think the camera has to push the video to VPS right ? Would that work with regular RTSP/onvif camera ? I'm new in this so bear with me.\n\nEdit: No it was for security purpose, I got permit from house owner to monitor the neighborhood. The point is how would the CCTV push the live cam to the VPS.", "author_fullname": "t2_gwhg90une", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self hosted CCTV management in VPS ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayodqd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708768462.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708758402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planning to install several CCTV in my neighborhood, I want to view the live cam through web interface like Shinobi hosted in VPS (meaning no local server), is this possible ? For this to works I think the camera has to push the video to VPS right ? Would that work with regular RTSP/onvif camera ? I&amp;#39;m new in this so bear with me.&lt;/p&gt;\n\n&lt;p&gt;Edit: No it was for security purpose, I got permit from house owner to monitor the neighborhood. The point is how would the CCTV push the live cam to the VPS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayodqd", "is_robot_indexable": true, "report_reasons": null, "author": "L1so", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayodqd/self_hosted_cctv_management_in_vps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayodqd/self_hosted_cctv_management_in_vps/", "subreddit_subscribers": 324361, "created_utc": 1708758402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello guys,\n\nfor some time i am trying to get hostnames (or local domains) working so i can access my http(s)/tcp/udp services and servers, but only with partial success.\n\nBecause i am using OPNsense as router, i have tried to set Unbound DNS override to something like proxmox.on.lan =&gt; [192.168.1.2](https://192.168.1.2) which was working in the end after some hassle with configurations and mappings, only to find out, i still need to use ports in url (e.g. 8006 for proxmox, so proxmox.on.lan:8006) which is quite ugly and inconvinient.\n\nAlso i have been trying to check out some tutorials about Dnsmasq and bind9 only to find out that i wont be able to use DNS overrides with ports.\n\nSo i am asking for help, is there some easy way how to basically make my services/servers accessible on LAN via simple hostname or short domain so i dont need to use IP:PORT?\n\nRight now i am looking at reverse proxies, if those would be suitable basically just for redirect, but it seems those wont handle tcp/udp protocols very well (for private game servers for example).\n\nThanks for tips", "author_fullname": "t2_91ddnllj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use hostnames (local domains) to access self hosted services/servers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az0oyo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708797193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;for some time i am trying to get hostnames (or local domains) working so i can access my http(s)/tcp/udp services and servers, but only with partial success.&lt;/p&gt;\n\n&lt;p&gt;Because i am using OPNsense as router, i have tried to set Unbound DNS override to something like proxmox.on.lan =&amp;gt; &lt;a href=\"https://192.168.1.2\"&gt;192.168.1.2&lt;/a&gt; which was working in the end after some hassle with configurations and mappings, only to find out, i still need to use ports in url (e.g. 8006 for proxmox, so proxmox.on.lan:8006) which is quite ugly and inconvinient.&lt;/p&gt;\n\n&lt;p&gt;Also i have been trying to check out some tutorials about Dnsmasq and bind9 only to find out that i wont be able to use DNS overrides with ports.&lt;/p&gt;\n\n&lt;p&gt;So i am asking for help, is there some easy way how to basically make my services/servers accessible on LAN via simple hostname or short domain so i dont need to use IP:PORT?&lt;/p&gt;\n\n&lt;p&gt;Right now i am looking at reverse proxies, if those would be suitable basically just for redirect, but it seems those wont handle tcp/udp protocols very well (for private game servers for example).&lt;/p&gt;\n\n&lt;p&gt;Thanks for tips&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az0oyo", "is_robot_indexable": true, "report_reasons": null, "author": "CZ-DannyK", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az0oyo/how_to_use_hostnames_local_domains_to_access_self/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az0oyo/how_to_use_hostnames_local_domains_to_access_self/", "subreddit_subscribers": 324361, "created_utc": 1708797193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello,\n\nUptime Kuma is a great tool. Very simple and effective. However, when running at another node in docker (Swarm), it runs at default data, it does not replicate the data from another hose. Whenever I copy these files to the other node, its fixed:  \n\\- kuma.db  \n\\- kuma.db-shm  \n\\- kuma.db-wal  \n\n\nIs this normal behavior or should I config Docker different?", "author_fullname": "t2_p2tmbt05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uptime Kuma replicate data docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayx27p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708788226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Uptime Kuma is a great tool. Very simple and effective. However, when running at another node in docker (Swarm), it runs at default data, it does not replicate the data from another hose. Whenever I copy these files to the other node, its fixed:&lt;br/&gt;\n- kuma.db&lt;br/&gt;\n- kuma.db-shm&lt;br/&gt;\n- kuma.db-wal  &lt;/p&gt;\n\n&lt;p&gt;Is this normal behavior or should I config Docker different?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1ayx27p", "is_robot_indexable": true, "report_reasons": null, "author": "AccomplishedLet5782", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1ayx27p/uptime_kuma_replicate_data_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1ayx27p/uptime_kuma_replicate_data_docker/", "subreddit_subscribers": 324361, "created_utc": 1708788226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "When updating docker images i had the following thought: I have mostly the latest tag set in the containers. When something breaks now, I don't know what was latest tag corresponding to before updating. Wouldn't it be a good idea to keep track of what version was installed at what point, so you can roll back to the last working version?\n\nMaybe I am missing something but I couldn't find out a good way to do that. Do either it's super easy or the idea doesn't make sense.\n\nBeen you elaborate?", "author_fullname": "t2_6g5g1he", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker updating strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1az7ju8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708814115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When updating docker images i had the following thought: I have mostly the latest tag set in the containers. When something breaks now, I don&amp;#39;t know what was latest tag corresponding to before updating. Wouldn&amp;#39;t it be a good idea to keep track of what version was installed at what point, so you can roll back to the last working version?&lt;/p&gt;\n\n&lt;p&gt;Maybe I am missing something but I couldn&amp;#39;t find out a good way to do that. Do either it&amp;#39;s super easy or the idea doesn&amp;#39;t make sense.&lt;/p&gt;\n\n&lt;p&gt;Been you elaborate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az7ju8", "is_robot_indexable": true, "report_reasons": null, "author": "momsi91", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az7ju8/docker_updating_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az7ju8/docker_updating_strategy/", "subreddit_subscribers": 324361, "created_utc": 1708814115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Now that I have got quite a number of containers running manual updating is starting to wear a little thin, but I read a few posts where auto updates have not always gone as hoped. What has the self-hosting community at large found to be the best method up handling container updates. TIA", "author_fullname": "t2_6xdf2vsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "updating containers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1az7bh2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708813529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Now that I have got quite a number of containers running manual updating is starting to wear a little thin, but I read a few posts where auto updates have not always gone as hoped. What has the self-hosting community at large found to be the best method up handling container updates. TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az7bh2", "is_robot_indexable": true, "report_reasons": null, "author": "VE3VVS", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az7bh2/updating_containers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az7bh2/updating_containers/", "subreddit_subscribers": 324361, "created_utc": 1708813529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi selfhosters,\n\nmany of you may run the beautiful [homepage dashboard](https://github.com/gethomepage/homepage).\n\nFor all of you that also run [Plausible](https://github.com/plausible/analytics), here is an example configuration to get Plausible website statistics into your homepage dashboard. We will use homepage's [custom API](https://gethomepage.dev/latest/widgets/services/customapi/) to get things working.\n\nAll you need is a Plausible API token, which you can create on Plausible in your user profile's settings area.\n\nHere is the relevant code for homepage's `services.yaml`:\n\n````\n    - Web Analytics:\n        href: https://analytics.example.com\n        description: Plausible\n        icon: plausible.png\n        siteMonitor: https://analytics.example.com\n        widget:\n          type: customapi\n          url: https://analytics.example.com/api/v1/stats/aggregate?site_id=mysite.example.com&amp;period=30d&amp;metrics=visitors,pageviews,bounce_rate,visit_duration\n          method: GET\n          headers: \n            Authorization: Bearer &lt;YOUR-API-TOKEN&gt;\n          mappings:\n            - field:\n                results: \n                    visitors: value\n              label: visitors\n            - field:\n                results: \n                    pageviews: value\n              label: page views\n            - field:\n                results: \n                    visit_duration: value\n              label: visit duration\n            - field:\n                results: \n                    bounce_rate: value\n              label: bounce rate\n````\nJust ensure to replace `&lt;YOUR-API-TOKEN&gt;` with your Plausible API token and `mysite.example.com` with the site_id of your monitored website on Plausible. Last but not least, adjust the url `analytics.example.com` to your Plausible FQDN.\n\nHere is an example screenshot how it will look like.\n\nhttps://ibb.co/NSR0JNM\n\nEnjoy!", "author_fullname": "t2_92wut60p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plausible Stats in Homepage Dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "selfhelp", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1az7aro", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Self Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708813480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi selfhosters,&lt;/p&gt;\n\n&lt;p&gt;many of you may run the beautiful &lt;a href=\"https://github.com/gethomepage/homepage\"&gt;homepage dashboard&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;For all of you that also run &lt;a href=\"https://github.com/plausible/analytics\"&gt;Plausible&lt;/a&gt;, here is an example configuration to get Plausible website statistics into your homepage dashboard. We will use homepage&amp;#39;s &lt;a href=\"https://gethomepage.dev/latest/widgets/services/customapi/\"&gt;custom API&lt;/a&gt; to get things working.&lt;/p&gt;\n\n&lt;p&gt;All you need is a Plausible API token, which you can create on Plausible in your user profile&amp;#39;s settings area.&lt;/p&gt;\n\n&lt;p&gt;Here is the relevant code for homepage&amp;#39;s &lt;code&gt;services.yaml&lt;/code&gt;:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\n    - Web Analytics:\n        href: https://analytics.example.com\n        description: Plausible\n        icon: plausible.png\n        siteMonitor: https://analytics.example.com\n        widget:\n          type: customapi\n          url: https://analytics.example.com/api/v1/stats/aggregate?site_id=mysite.example.com&amp;amp;period=30d&amp;amp;metrics=visitors,pageviews,bounce_rate,visit_duration\n          method: GET\n          headers: \n            Authorization: Bearer &amp;lt;YOUR-API-TOKEN&amp;gt;\n          mappings:\n            - field:\n                results: \n                    visitors: value\n              label: visitors\n            - field:\n                results: \n                    pageviews: value\n              label: page views\n            - field:\n                results: \n                    visit_duration: value\n              label: visit duration\n            - field:\n                results: \n                    bounce_rate: value\n              label: bounce rate\n&lt;/code&gt;\nJust ensure to replace &lt;code&gt;&amp;lt;YOUR-API-TOKEN&amp;gt;&lt;/code&gt; with your Plausible API token and &lt;code&gt;mysite.example.com&lt;/code&gt; with the site_id of your monitored website on Plausible. Last but not least, adjust the url &lt;code&gt;analytics.example.com&lt;/code&gt; to your Plausible FQDN.&lt;/p&gt;\n\n&lt;p&gt;Here is an example screenshot how it will look like.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ibb.co/NSR0JNM\"&gt;https://ibb.co/NSR0JNM&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Enjoy!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LK86WzP_bblOg6OvWj5E7vUAWMBb1APKTbMcjdDYZhM.jpg?auto=webp&amp;s=5fc828f29ddd314a593931201791efabfcef37be", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/LK86WzP_bblOg6OvWj5E7vUAWMBb1APKTbMcjdDYZhM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1d9ceaaa6c6c3ab8ff8be030f9e52a275a28a5a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/LK86WzP_bblOg6OvWj5E7vUAWMBb1APKTbMcjdDYZhM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f56c74ee05f85b1f8968ca26ddcb25099ec1e1c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/LK86WzP_bblOg6OvWj5E7vUAWMBb1APKTbMcjdDYZhM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=23398533affead80bcea49620ba382c2788a1c99", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/LK86WzP_bblOg6OvWj5E7vUAWMBb1APKTbMcjdDYZhM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b92a55a6f35cea68a0ee636a9fa82b871095ee2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/LK86WzP_bblOg6OvWj5E7vUAWMBb1APKTbMcjdDYZhM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cac4da37f57a2d56eea5c8a8099e89de7f2d2b37", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/LK86WzP_bblOg6OvWj5E7vUAWMBb1APKTbMcjdDYZhM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b0b4bb64aa1e155c1b29c55b0bc66506080d85ff", "width": 1080, "height": 540}], "variants": {}, "id": "SBUpTLFb07IXIc2XFYMeXp9j9ikHJjKxtNbTe8Pk0a8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8bac67fc-7e68-11e9-afdb-0e9d14028e18", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az7aro", "is_robot_indexable": true, "report_reasons": null, "author": "sk1nT7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az7aro/plausible_stats_in_homepage_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az7aro/plausible_stats_in_homepage_dashboard/", "subreddit_subscribers": 324361, "created_utc": 1708813480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey, I'm really new to this, so sorry in advance.  \n\nI've set up wiki.js on my Raspberry Pi. It works great at home, which is cool, but I need to be able to access it from other wifis. \n\nHow can I do this? I don't have a purchased webserver or anything. I would be the only person accessing the wiki. ", "author_fullname": "t2_5tzuhdwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making my hosted docker container available to other networks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "wikis", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1az684u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Wiki's", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708810832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m really new to this, so sorry in advance.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve set up wiki.js on my Raspberry Pi. It works great at home, which is cool, but I need to be able to access it from other wifis. &lt;/p&gt;\n\n&lt;p&gt;How can I do this? I don&amp;#39;t have a purchased webserver or anything. I would be the only person accessing the wiki. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "78dcb492-7e68-11e9-b4e7-0e296f55dc70", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az684u", "is_robot_indexable": true, "report_reasons": null, "author": "DramaticProtogen", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az684u/making_my_hosted_docker_container_available_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az684u/making_my_hosted_docker_container_available_to/", "subreddit_subscribers": 324361, "created_utc": 1708810832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Looking at the possibility of upgrading from a pair of raspberry pi\u2019s to a server for virtualization. Does anyone have any suggestions for a short/shallow depth server? Prefer a pre made one but it isn\u2019t a requirement by any means. I have a small network rack that I\u2019d like it to fit in, I think I have 15-17\u201d deep. It\u2019s a navepoint 12u  rack with glass door if that helps", "author_fullname": "t2_7210prkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shallow depth servers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az63ly", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708810521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking at the possibility of upgrading from a pair of raspberry pi\u2019s to a server for virtualization. Does anyone have any suggestions for a short/shallow depth server? Prefer a pre made one but it isn\u2019t a requirement by any means. I have a small network rack that I\u2019d like it to fit in, I think I have 15-17\u201d deep. It\u2019s a navepoint 12u  rack with glass door if that helps&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az63ly", "is_robot_indexable": true, "report_reasons": null, "author": "happyjackassiam", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az63ly/shallow_depth_servers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az63ly/shallow_depth_servers/", "subreddit_subscribers": 324361, "created_utc": 1708810521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello.\n\nI\u2019m opening a small car/scooter rental business. I have looked into commercial solutions, but most seem like a total overkill for my use case - I don\u2019t need online bookings by customers, payment portal and so on.\n\nBasically, I would like some simple self-hosted solution that would let me do the following:\n\n- keep track of inventory - including details like brand, model, vin, registration number etc.\n\n- making sure road tax and insurance are up to date - write down policy information, with reminders when they are up to renewal. Similar with routine maintenance like oil change\n\n- ability to attach photos and notes to each car, for example to keep track of scratches and overall state of assets\n\n- some kind of calendar, where I can mark which car is booked and for how long. Ability to check which cars are available at a glance\n\n- customer management - for internal use only, staff should be able to make a file on each customer, writing down data like names, contact information, attach scans of documents like driving license or signed rental agreement \n\n- ability to generate and print rental agreements using the data from car inventory and customer profile would be nice to have, but not mandatory \n\n\nIs there any self-hosted software that would fit the criteria? I think it falls under \u201cInventory management\u201d software, but I\u2019m really not familiar with this kind of offering. Any recommendations?\n\nTIA", "author_fullname": "t2_6pw7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Car rental business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "business", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az5nbs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Business Tools", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708809414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m opening a small car/scooter rental business. I have looked into commercial solutions, but most seem like a total overkill for my use case - I don\u2019t need online bookings by customers, payment portal and so on.&lt;/p&gt;\n\n&lt;p&gt;Basically, I would like some simple self-hosted solution that would let me do the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;keep track of inventory - including details like brand, model, vin, registration number etc.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;making sure road tax and insurance are up to date - write down policy information, with reminders when they are up to renewal. Similar with routine maintenance like oil change&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;ability to attach photos and notes to each car, for example to keep track of scratches and overall state of assets&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;some kind of calendar, where I can mark which car is booked and for how long. Ability to check which cars are available at a glance&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;customer management - for internal use only, staff should be able to make a file on each customer, writing down data like names, contact information, attach scans of documents like driving license or signed rental agreement &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;ability to generate and print rental agreements using the data from car inventory and customer profile would be nice to have, but not mandatory &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is there any self-hosted software that would fit the criteria? I think it falls under \u201cInventory management\u201d software, but I\u2019m really not familiar with this kind of offering. Any recommendations?&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0ac01dca-53ce-11ed-9fce-c6cd629e2d85", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az5nbs", "is_robot_indexable": true, "report_reasons": null, "author": "Ivanow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az5nbs/car_rental_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az5nbs/car_rental_business/", "subreddit_subscribers": 324361, "created_utc": 1708809414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi all,\n\nI'm about to setup a proxmox server that is going to run 2 or 3 VMs (Debian) each with their own purpose (Home automation, Media the -arr, System Utils).\n\nLet\u00b4s take 1 VM that is going to run Home Assistant, MQTT and zigbee2MQTT.  \nAll three will be running in docker containers.\n\n1. Besides root, I have 1 user created for all the VMs (I'm the only one accessing these).  \nTo my understanding using this users UID/PUID will mitigate and permission issues with shared data between the containers. Am I correct on this one?\n2. For these containers, I've created separated folders in this users home-folder to bind the containers persistent data to. Could this practice become problematic at some point and should this data be stored in a different folder, for convenience/standards/etc.\n\nI've looked this up online but still I'm confused/uncertain.  \nI appreciate your help on this one.", "author_fullname": "t2_73mpwjce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker data in user home folder and UID in compose file", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az50c5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708807873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to setup a proxmox server that is going to run 2 or 3 VMs (Debian) each with their own purpose (Home automation, Media the -arr, System Utils).&lt;/p&gt;\n\n&lt;p&gt;Let\u00b4s take 1 VM that is going to run Home Assistant, MQTT and zigbee2MQTT.&lt;br/&gt;\nAll three will be running in docker containers.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Besides root, I have 1 user created for all the VMs (I&amp;#39;m the only one accessing these).&lt;br/&gt;\nTo my understanding using this users UID/PUID will mitigate and permission issues with shared data between the containers. Am I correct on this one?&lt;/li&gt;\n&lt;li&gt;For these containers, I&amp;#39;ve created separated folders in this users home-folder to bind the containers persistent data to. Could this practice become problematic at some point and should this data be stored in a different folder, for convenience/standards/etc.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve looked this up online but still I&amp;#39;m confused/uncertain.&lt;br/&gt;\nI appreciate your help on this one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az50c5", "is_robot_indexable": true, "report_reasons": null, "author": "Patrice_77", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az50c5/docker_data_in_user_home_folder_and_uid_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az50c5/docker_data_in_user_home_folder_and_uid_in/", "subreddit_subscribers": 324361, "created_utc": 1708807873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Can anyone recommend a way of using rclone, or a different way where i can run a webdav server with specific user directories. Id like these user directories to be authenticated to by the user .\n\nA bonus would be an ecrypted backup and restore solution ", "author_fullname": "t2_9ywg9uvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "file server with user directories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az4uy2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708807507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone recommend a way of using rclone, or a different way where i can run a webdav server with specific user directories. Id like these user directories to be authenticated to by the user .&lt;/p&gt;\n\n&lt;p&gt;A bonus would be an ecrypted backup and restore solution &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az4uy2", "is_robot_indexable": true, "report_reasons": null, "author": "daninthetoilet", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az4uy2/file_server_with_user_directories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az4uy2/file_server_with_user_directories/", "subreddit_subscribers": 324361, "created_utc": 1708807507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Wanting to eventually get a Jellyfin server up and running. I\u2019m slowly buying movies I want to add to it. I\u2019m noticing quite a lot of the blue ray movies I\u2019m looking at come with a digital download. How many of you use this? Is it as high quality as just ripping the blue ray disk?\n\nI\u2019m assuming in most cases you probably have to create an account to get the download.", "author_fullname": "t2_172qnn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use the digital downloads that come with your DVDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az3ekf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708803873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanting to eventually get a Jellyfin server up and running. I\u2019m slowly buying movies I want to add to it. I\u2019m noticing quite a lot of the blue ray movies I\u2019m looking at come with a digital download. How many of you use this? Is it as high quality as just ripping the blue ray disk?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m assuming in most cases you probably have to create an account to get the download.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1az3ekf", "is_robot_indexable": true, "report_reasons": null, "author": "X-lem", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1az3ekf/do_you_use_the_digital_downloads_that_come_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1az3ekf/do_you_use_the_digital_downloads_that_come_with/", "subreddit_subscribers": 324361, "created_utc": 1708803873.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}