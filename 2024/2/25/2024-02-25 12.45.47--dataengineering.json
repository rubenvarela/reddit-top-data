{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**\\[Repo\\]** [https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven)\n\n# Hello Data enthusiasts! \ud83d\ude4b\ud83c\udffd\u200d\u2642\ufe0f\n\nhttps://preview.redd.it/70u7nk1sknkc1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=bbe7a09f4e45c4313b6c21b7716e347a54ed8646\n\nI\u2019m an engineer by heart and a data enthusiast by passion. I have been working with data teams for the past 10 years and have seen the data landscape evolve from **traditional databases** to **modern data lakes** and **data warehouses**.\n\nIn previous roles, I\u2019ve been working closely with customers of AdTech, MarTech and Fintech companies. As an engineer, I\u2019ve built features and products that helped marketers, advertisers and B2C companies engage with their customers better. Dealing with vast amounts of data, that either came from online or offline sources, I always found myself in the middle of newer challenges that came with the data.\n\nOne of the biggest challenges I\u2019ve faced is the ability to move data from one system to another. This is a problem that has been around for a long time and is often referred to as **Extract, Transform, Load (ETL)**. Consolidating data from multiple sources and storing it in a single place is a common problem and while working with teams, I have built custom ETL pipelines to solve this problem.\n\nHowever, there were no mature platforms that could solve this problem at scale. Then as **AWS Glue, Google Dataflow and Apache Nifi** came into the picture, I started to see a shift in the way data was being moved around. Many OSS platforms like *Airbyte, Meltano and Dagster* have come up in recent years to solve this problem.\n\nNow that we are at the cusp of a new era in modern data stacks, 7 out of 10 are using cloud data warehouses and data lakes.\n\nThis has now made life easier for data engineers, especially when I was struggling with ETL pipelines. But later in my career, I started to see a new problem emerge. When marketers, sales teams and growth teams operate with top-of-the-funnel data, while most of the data is stored in the data warehouse, it is not accessible to them, which is a big problem.\n\nThen I saw data teams and growth teams operate in silos. Data teams were busy building ETL pipelines and maintaining the data warehouse. In contrast, growth teams were busy using tools like **Braze, Facebook Ads, Google Ads, Salesforce, Hubspot**, etc. to engage with their customers.\n\n# \ud83d\udcab The Genesis of Multiwoven\n\nAt the initial stages of Multiwoven, our initial idea was to build a product notification platform for product teams, to help them send targeted notifications to their users. But as we started to talk to more customers, we realized that the problem of data silos was much bigger than we thought. We realized that the problem of data silos was not just limited to product teams, but was a problem that was faced by every team in the company.\n\nThat\u2019s when we decided to pivot and build Multiwoven, a **reverse ETL** platform that helps companies move data from their data warehouse to their SaaS platforms. We wanted to build a platform that would help companies make their data actionable across different SaaS platforms.\n\n# \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb Why Open Source?\n\nAs a team, we are strong believers in open source, and the reason behind going open source was twofold. Firstly, cost was always a counterproductive aspect for teams using commercial SAAS platforms. Secondly, we wanted to build a flexible and customizable platform that could give companies the control and governance they needed.\n\n***This has been our humble beginning and we are excited to see where this journey takes us. We are excited to see the impact we can make in the data activation landscape.***\n\n&gt;*Please \u2b50 star our* [*repo on Github*](https://github.com/Multiwoven/multiwoven) *and show us some love. We are always looking for feedback and would love to hear from you.*\n\n**\\[Repo\\]** [https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven)", "author_fullname": "t2_rtrd3q97v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why I Decided to Build Multiwoven: an Open-source Reverse ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"70u7nk1sknkc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c6d84875ad9fe5b5384172183347cf448fdcfb0"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd6516d2e51489dc8606d32ec9b79b4fd4e50bd3"}, {"y": 150, "x": 320, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=aae6942bf1338a4b2ce06405ced4fc71a639fad0"}, {"y": 301, "x": 640, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d3e630aa87bd6d294e84b1f5d222023bcd78b0e2"}, {"y": 451, "x": 960, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9f4bf4e36b2298f0e7b75acf8252dfdff2549f62"}, {"y": 507, "x": 1080, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=74ebf30a798c3c304ae8ff369a9d63761e168396"}], "s": {"y": 1204, "x": 2560, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=bbe7a09f4e45c4313b6c21b7716e347a54ed8646"}, "id": "70u7nk1sknkc1"}}, "name": "t3_1aze7db", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ba02ywnsMpACZ9VFplAkrz0QVt53tVe9DKUaRPfiIfE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1708832648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;[Repo]&lt;/strong&gt; &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Hello Data enthusiasts! \ud83d\ude4b\ud83c\udffd\u200d\u2642\ufe0f&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/70u7nk1sknkc1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bbe7a09f4e45c4313b6c21b7716e347a54ed8646\"&gt;https://preview.redd.it/70u7nk1sknkc1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bbe7a09f4e45c4313b6c21b7716e347a54ed8646&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I\u2019m an engineer by heart and a data enthusiast by passion. I have been working with data teams for the past 10 years and have seen the data landscape evolve from &lt;strong&gt;traditional databases&lt;/strong&gt; to &lt;strong&gt;modern data lakes&lt;/strong&gt; and &lt;strong&gt;data warehouses&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;In previous roles, I\u2019ve been working closely with customers of AdTech, MarTech and Fintech companies. As an engineer, I\u2019ve built features and products that helped marketers, advertisers and B2C companies engage with their customers better. Dealing with vast amounts of data, that either came from online or offline sources, I always found myself in the middle of newer challenges that came with the data.&lt;/p&gt;\n\n&lt;p&gt;One of the biggest challenges I\u2019ve faced is the ability to move data from one system to another. This is a problem that has been around for a long time and is often referred to as &lt;strong&gt;Extract, Transform, Load (ETL)&lt;/strong&gt;. Consolidating data from multiple sources and storing it in a single place is a common problem and while working with teams, I have built custom ETL pipelines to solve this problem.&lt;/p&gt;\n\n&lt;p&gt;However, there were no mature platforms that could solve this problem at scale. Then as &lt;strong&gt;AWS Glue, Google Dataflow and Apache Nifi&lt;/strong&gt; came into the picture, I started to see a shift in the way data was being moved around. Many OSS platforms like &lt;em&gt;Airbyte, Meltano and Dagster&lt;/em&gt; have come up in recent years to solve this problem.&lt;/p&gt;\n\n&lt;p&gt;Now that we are at the cusp of a new era in modern data stacks, 7 out of 10 are using cloud data warehouses and data lakes.&lt;/p&gt;\n\n&lt;p&gt;This has now made life easier for data engineers, especially when I was struggling with ETL pipelines. But later in my career, I started to see a new problem emerge. When marketers, sales teams and growth teams operate with top-of-the-funnel data, while most of the data is stored in the data warehouse, it is not accessible to them, which is a big problem.&lt;/p&gt;\n\n&lt;p&gt;Then I saw data teams and growth teams operate in silos. Data teams were busy building ETL pipelines and maintaining the data warehouse. In contrast, growth teams were busy using tools like &lt;strong&gt;Braze, Facebook Ads, Google Ads, Salesforce, Hubspot&lt;/strong&gt;, etc. to engage with their customers.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udcab The Genesis of Multiwoven&lt;/h1&gt;\n\n&lt;p&gt;At the initial stages of Multiwoven, our initial idea was to build a product notification platform for product teams, to help them send targeted notifications to their users. But as we started to talk to more customers, we realized that the problem of data silos was much bigger than we thought. We realized that the problem of data silos was not just limited to product teams, but was a problem that was faced by every team in the company.&lt;/p&gt;\n\n&lt;p&gt;That\u2019s when we decided to pivot and build Multiwoven, a &lt;strong&gt;reverse ETL&lt;/strong&gt; platform that helps companies move data from their data warehouse to their SaaS platforms. We wanted to build a platform that would help companies make their data actionable across different SaaS platforms.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb Why Open Source?&lt;/h1&gt;\n\n&lt;p&gt;As a team, we are strong believers in open source, and the reason behind going open source was twofold. Firstly, cost was always a counterproductive aspect for teams using commercial SAAS platforms. Secondly, we wanted to build a flexible and customizable platform that could give companies the control and governance they needed.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;This has been our humble beginning and we are excited to see where this journey takes us. We are excited to see the impact we can make in the data activation landscape.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;em&gt;Please \u2b50 star our&lt;/em&gt; &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;&lt;em&gt;repo on Github&lt;/em&gt;&lt;/a&gt; &lt;em&gt;and show us some love. We are always looking for feedback and would love to hear from you.&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;[Repo]&lt;/strong&gt; &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?auto=webp&amp;s=7bee046b00e43a80d51ec06b5b03fab8fe50e8a6", "width": 2560, "height": 1280}, "resolutions": [{"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c820e531bd69e73f8ab0a6ae0beacd99c2b46eb", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c80be54ff0c4e74ab2f7726675fcebd3a845b46", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ac265f606906d37f473536da1c0f1402f557f04", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f31b53a48c8d26b2abdbd514797bd69ea9539bcf", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d338fcd1ab24aecad9b1dcf39d5649f7cff2a29", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3be250d32cd9b8a61ac25ca44aa1a3ab73cb70a", "width": 1080, "height": 540}], "variants": {}, "id": "KXdCRFA3PFw6uZLyGfHzBPQBTSPbN50XvrsQE2m5iOI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1aze7db", "is_robot_indexable": true, "report_reasons": null, "author": "nagstler", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aze7db/why_i_decided_to_build_multiwoven_an_opensource/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aze7db/why_i_decided_to_build_multiwoven_an_opensource/", "subreddit_subscribers": 163483, "created_utc": 1708832648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey beautiful people, I recently got a data engineering role after trying for a while. It wouldn't have been possible with the support of this group. I would like to thank you guys for this. \nI would like to know what should my next steps be? Though I got the job, i still have that imposter syndrome even though my team members are super supportive. I want to take my learnings to a next level but I feel that I lack the basics so want to start from the very scratch like learning the alphabets.\nSo if you were to start a job in IT, how you would have started? I want to become an engineer in true sense. I am ready to devote sufficient time along with my job. \nSuggestions are most welcome.\n\nThank you!!\nHave a great day!", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Landing a data engineering role with the help of this group", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1azl4lz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708858006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey beautiful people, I recently got a data engineering role after trying for a while. It wouldn&amp;#39;t have been possible with the support of this group. I would like to thank you guys for this. \nI would like to know what should my next steps be? Though I got the job, i still have that imposter syndrome even though my team members are super supportive. I want to take my learnings to a next level but I feel that I lack the basics so want to start from the very scratch like learning the alphabets.\nSo if you were to start a job in IT, how you would have started? I want to become an engineer in true sense. I am ready to devote sufficient time along with my job. \nSuggestions are most welcome.&lt;/p&gt;\n\n&lt;p&gt;Thank you!!\nHave a great day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azl4lz", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azl4lz/landing_a_data_engineering_role_with_the_help_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azl4lz/landing_a_data_engineering_role_with_the_help_of/", "subreddit_subscribers": 163483, "created_utc": 1708858006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to pick 2 out of the following, please advice on which course(s) packs the most punch.  \n\n\nCurrently a data analyst with no ceritifications to my name. I would like to progress towards a data engineering role but not sure where to start in terms of getting a cert under my name.\n\n**IBM**:\n\n* \"IBM Data Engineering Professional Certificate\" and \"IBM Data Engineering Fundamentals.\"\n* Additionally, IBM provides courses and certifications in specific data-related technologies such as IBM Db2, IBM Cloud Pak for Data, and IBM Watson Studio.\n\n**AWS (Amazon Web Services)**:\n\n* \"AWS Certified Big Data - Specialty\" certification.\n* AWS training covers various data-related services such as Amazon Redshift, Amazon EMR (Elastic MapReduce), AWS Glue, AWS Data Pipeline, and Amazon Kinesis.\n\n**Google Cloud**:\n\n* \"Google Cloud Certified - Professional Data Engineer\" certification.\n* Google Cloud training covers services like Google BigQuery, Google Cloud Dataflow, Google Cloud Dataprep, Google Cloud Pub/Sub, and others.\n\n**Microsoft Azure**:\n\n* \"Microsoft Certified: Azure Data Engineer Associate\" certification.\n* Azure training includes services like Azure SQL Database, Azure Synapse Analytics (formerly Azure SQL Data Warehouse), Azure Data Lake Storage, Azure Databricks, and Azure HDInsight.\n\n**Cloudera**:\n\n* \"Cloudera Certified Associate (CCA) Data Analyst\" and \"Cloudera Certified Professional (CCP) Data Engineer\" certifications.\n* Cloudera training covers Apache Hadoop, Apache Spark, Apache Hive, Apache Impala, and other related technologies.", "author_fullname": "t2_2btsrky1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should be my first ceritificate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayylbi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708792356.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708792077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to pick 2 out of the following, please advice on which course(s) packs the most punch.  &lt;/p&gt;\n\n&lt;p&gt;Currently a data analyst with no ceritifications to my name. I would like to progress towards a data engineering role but not sure where to start in terms of getting a cert under my name.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;IBM&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;IBM Data Engineering Professional Certificate&amp;quot; and &amp;quot;IBM Data Engineering Fundamentals.&amp;quot;&lt;/li&gt;\n&lt;li&gt;Additionally, IBM provides courses and certifications in specific data-related technologies such as IBM Db2, IBM Cloud Pak for Data, and IBM Watson Studio.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;AWS (Amazon Web Services)&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;AWS Certified Big Data - Specialty&amp;quot; certification.&lt;/li&gt;\n&lt;li&gt;AWS training covers various data-related services such as Amazon Redshift, Amazon EMR (Elastic MapReduce), AWS Glue, AWS Data Pipeline, and Amazon Kinesis.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Google Cloud&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;Google Cloud Certified - Professional Data Engineer&amp;quot; certification.&lt;/li&gt;\n&lt;li&gt;Google Cloud training covers services like Google BigQuery, Google Cloud Dataflow, Google Cloud Dataprep, Google Cloud Pub/Sub, and others.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Microsoft Azure&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;Microsoft Certified: Azure Data Engineer Associate&amp;quot; certification.&lt;/li&gt;\n&lt;li&gt;Azure training includes services like Azure SQL Database, Azure Synapse Analytics (formerly Azure SQL Data Warehouse), Azure Data Lake Storage, Azure Databricks, and Azure HDInsight.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Cloudera&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;Cloudera Certified Associate (CCA) Data Analyst&amp;quot; and &amp;quot;Cloudera Certified Professional (CCP) Data Engineer&amp;quot; certifications.&lt;/li&gt;\n&lt;li&gt;Cloudera training covers Apache Hadoop, Apache Spark, Apache Hive, Apache Impala, and other related technologies.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ayylbi", "is_robot_indexable": true, "report_reasons": null, "author": "yungfilly", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ayylbi/what_should_be_my_first_ceritificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ayylbi/what_should_be_my_first_ceritificate/", "subreddit_subscribers": 163483, "created_utc": 1708792077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019ve been working as a Web Developer for 2 years and I would like to change my career in the direction of Data Science/Data Engineering. For now I try to understand in depth what is the difference between those fields and if Data Engineering would be the right choice for me. \n\nCould some data engineers tell me how your working day looks like? Is it more about writing a code or about designing databases? \n\nI like python and have some experience with web development with Django as well as with pandas, numpy and PySpark. Besides I like theoretical mathematics. After reading some short descriptions of Data Science/Machine Learning/AI I feel like I would be the most interested in ML, but maybe Data Engineering would be a good entry point in this direction. ", "author_fullname": "t2_tz7awh8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a position as a Junior Data Engineer a good entry point towards working with data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aytrbb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708778920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019ve been working as a Web Developer for 2 years and I would like to change my career in the direction of Data Science/Data Engineering. For now I try to understand in depth what is the difference between those fields and if Data Engineering would be the right choice for me. &lt;/p&gt;\n\n&lt;p&gt;Could some data engineers tell me how your working day looks like? Is it more about writing a code or about designing databases? &lt;/p&gt;\n\n&lt;p&gt;I like python and have some experience with web development with Django as well as with pandas, numpy and PySpark. Besides I like theoretical mathematics. After reading some short descriptions of Data Science/Machine Learning/AI I feel like I would be the most interested in ML, but maybe Data Engineering would be a good entry point in this direction. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aytrbb", "is_robot_indexable": true, "report_reasons": null, "author": "Wonderful_Affect4004", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aytrbb/is_a_position_as_a_junior_data_engineer_a_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aytrbb/is_a_position_as_a_junior_data_engineer_a_good/", "subreddit_subscribers": 163483, "created_utc": 1708778920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I'm a 25 yo management consultant at a top-tier consulting firm and currently make around $130K per year before bonus. I don't particularly like my job, it can be very daunting working 60-80 hours per week building slides and conducting basic analyses in Excel. However, recently I was staffed on a data strategy study and got exposed on a high level to different data concepts (e.g., data architecture, data governance, etc.) the topics seemed very interesting to me. After that study I requested to get my hands dirty with data so I got staffed on a study that involved deploying a tool that does some geospatial analysis. The tool is a bunch of Jupyter notebooks written as one colleague describes a bunch of \"shitcode\" mainly using pandas and some visualization packages. The study was fun and interesting but it was difficult to learn best practices (e.g., how to write clean code, version control, etc.) as the timelines were tight and there was no mentor to provide guidance.\n\nI think I'm interested in DE as a field and considering investing my time over the next 4-6 months learning DE on the side (after work hours and mainly during weekends) with the ultimate goal of switching to a dedicated data engineering job. I did some research and I think I have a solid understanding of the concepts that I need to learn to break into DE. That being said the only thing holding me back is the pay cut I'm going to take pursuing this transition given the effort I'm going invest over the next months worth it.\n\nWould appreciate your thoughts as DE practitioners on this.\n\nSome context on my background, I graduated with a degree in civil engineering in 2020 and then pursued a master's in transportation engineering graduating in 2021. Been doing consulting work across two different firms.", "author_fullname": "t2_7twkihop", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Management Consulting to Data Engineering? Worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az2aq7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708801121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m a 25 yo management consultant at a top-tier consulting firm and currently make around $130K per year before bonus. I don&amp;#39;t particularly like my job, it can be very daunting working 60-80 hours per week building slides and conducting basic analyses in Excel. However, recently I was staffed on a data strategy study and got exposed on a high level to different data concepts (e.g., data architecture, data governance, etc.) the topics seemed very interesting to me. After that study I requested to get my hands dirty with data so I got staffed on a study that involved deploying a tool that does some geospatial analysis. The tool is a bunch of Jupyter notebooks written as one colleague describes a bunch of &amp;quot;shitcode&amp;quot; mainly using pandas and some visualization packages. The study was fun and interesting but it was difficult to learn best practices (e.g., how to write clean code, version control, etc.) as the timelines were tight and there was no mentor to provide guidance.&lt;/p&gt;\n\n&lt;p&gt;I think I&amp;#39;m interested in DE as a field and considering investing my time over the next 4-6 months learning DE on the side (after work hours and mainly during weekends) with the ultimate goal of switching to a dedicated data engineering job. I did some research and I think I have a solid understanding of the concepts that I need to learn to break into DE. That being said the only thing holding me back is the pay cut I&amp;#39;m going to take pursuing this transition given the effort I&amp;#39;m going invest over the next months worth it.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate your thoughts as DE practitioners on this.&lt;/p&gt;\n\n&lt;p&gt;Some context on my background, I graduated with a degree in civil engineering in 2020 and then pursued a master&amp;#39;s in transportation engineering graduating in 2021. Been doing consulting work across two different firms.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1az2aq7", "is_robot_indexable": true, "report_reasons": null, "author": "socidad", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1az2aq7/management_consulting_to_data_engineering_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1az2aq7/management_consulting_to_data_engineering_worth_it/", "subreddit_subscribers": 163483, "created_utc": 1708801121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "All, \n\n\r  \nI am currently 35yr with 15 years of experience overall and 5 years of data analytics with some data engineering type work, NLP, and strategy.  I have also done database design and app development this is all wrapped up in the title \"Consultant\". I have certifications in Power BI Associate, Azure Data Fundamentals, and Databricks Fundaments. I have manufacturing management experience and a technician background, as well. I also like to dabble in UX/UI events. I have an undergrad in BS Organizational Leadership.\n\n\r  \nI feel that I would like to become a data architect, Senior Data Engineer, or digital transformation type work. To obtain these roles, I feel that my non-STEM degree will hold me back and would like to get a Masters, among other reasons. I am very fortunate to be in a position where money is not an issue with respect to college tuition.  I feel my calling is to go to the next level within the field.\n\n\r  \nI have been accepted into Syracuse Applied Data Science(online) program and UVA MSBA (hybrid). I am conflicted on which program I should pick. Looking at both the curriculums they are both very similar in the topics they cover, and both are complementary to my background.  \n\n\r  \nDoes anyone have any insight or recommendations for which program to pick?", "author_fullname": "t2_8yface1u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSDS or MSBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azc02d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708825944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All, &lt;/p&gt;\n\n&lt;p&gt;I am currently 35yr with 15 years of experience overall and 5 years of data analytics with some data engineering type work, NLP, and strategy.  I have also done database design and app development this is all wrapped up in the title &amp;quot;Consultant&amp;quot;. I have certifications in Power BI Associate, Azure Data Fundamentals, and Databricks Fundaments. I have manufacturing management experience and a technician background, as well. I also like to dabble in UX/UI events. I have an undergrad in BS Organizational Leadership.&lt;/p&gt;\n\n&lt;p&gt;I feel that I would like to become a data architect, Senior Data Engineer, or digital transformation type work. To obtain these roles, I feel that my non-STEM degree will hold me back and would like to get a Masters, among other reasons. I am very fortunate to be in a position where money is not an issue with respect to college tuition.  I feel my calling is to go to the next level within the field.&lt;/p&gt;\n\n&lt;p&gt;I have been accepted into Syracuse Applied Data Science(online) program and UVA MSBA (hybrid). I am conflicted on which program I should pick. Looking at both the curriculums they are both very similar in the topics they cover, and both are complementary to my background.  &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any insight or recommendations for which program to pick?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azc02d", "is_robot_indexable": true, "report_reasons": null, "author": "Benmagz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azc02d/msds_or_msba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azc02d/msds_or_msba/", "subreddit_subscribers": 163483, "created_utc": 1708825944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have many on-premises relational DBMSs.... MS SQL server, MySQL, Postgres and Oracle. Is there a tool that can read the logs of these servers and do the Change Data Capture?\n\nI would like to use the same tool for all DBMSs.\nI'm not sure, but I heard that Fivetran can do it. Is it true?\n\nAre there alternative solutions? So that Fivetran is expensive.", "author_fullname": "t2_rvp7wzgv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best tool to do CDC based on log?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az5wrc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708810043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have many on-premises relational DBMSs.... MS SQL server, MySQL, Postgres and Oracle. Is there a tool that can read the logs of these servers and do the Change Data Capture?&lt;/p&gt;\n\n&lt;p&gt;I would like to use the same tool for all DBMSs.\nI&amp;#39;m not sure, but I heard that Fivetran can do it. Is it true?&lt;/p&gt;\n\n&lt;p&gt;Are there alternative solutions? So that Fivetran is expensive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1az5wrc", "is_robot_indexable": true, "report_reasons": null, "author": "nivlek_miroma", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1az5wrc/what_is_the_best_tool_to_do_cdc_based_on_log/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1az5wrc/what_is_the_best_tool_to_do_cdc_based_on_log/", "subreddit_subscribers": 163483, "created_utc": 1708810043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nI'm working on a personal project to help with learning dimensional modelling and building pipelines with DataBricks and ADF, but things aren't coming together in my head. \n\nMy project is quite basic. I have a single sample 3rd normal form DB, and have designed a Star Schema based around order line items.\n\nI've so far created an ADF pipeline to incrementally extract data on a daily basis into a raw storage area (bronze) as Parquet. Format in Bronze area:\n\n    - Office\n        - 20-03-2024\n        - 21-03-2024\n    - Employee\n        - 20-03-2024\n        - 21-03-2024\n    etc\n\nI'd like to then have a persistent processed/cleaned layer (silver), before then loading into a presentation layer (gold) - which is where I'll have the star schema.\n\nThe schema I've designed involves some tables being joined (e.g., Office &amp; Employee will be joined to form a Sales Rep dimension table). It also involves the use of both SCD1 for some columns, and SCD2 for others.\n\nHowever, not 100% sure on the next steps. \n\nTo take the Office table as an example, I've considered having a single table/area for this in the silver layer, where I just append or update records based on what's coming from Bronze each day. Therefore this table would need to have effective date and end date columns (for SCD2) as well as a surrogate key column. \n\nThen when moving from Silver to Gold, in this example, I would do some kind of join between Office and Employee to form the Sales Rep Dimension, only using records that were updated and appended during current run, and do some kind of upsert to the relevant Gold layer dim table.\n\nI'm just worried I'm either overcomplicating this or missing something, and want to make sure my over-arching idea makes sense. \n\nCan anyone provide some advice, or let me know how you might approach this?", "author_fullname": "t2_osh2xtjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices and rules for moving data through Bonze, Silver, and Gold Layers when a Star Schema &amp; SCD2 are required", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az2ofy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708802038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a personal project to help with learning dimensional modelling and building pipelines with DataBricks and ADF, but things aren&amp;#39;t coming together in my head. &lt;/p&gt;\n\n&lt;p&gt;My project is quite basic. I have a single sample 3rd normal form DB, and have designed a Star Schema based around order line items.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve so far created an ADF pipeline to incrementally extract data on a daily basis into a raw storage area (bronze) as Parquet. Format in Bronze area:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;- Office\n    - 20-03-2024\n    - 21-03-2024\n- Employee\n    - 20-03-2024\n    - 21-03-2024\netc\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;d like to then have a persistent processed/cleaned layer (silver), before then loading into a presentation layer (gold) - which is where I&amp;#39;ll have the star schema.&lt;/p&gt;\n\n&lt;p&gt;The schema I&amp;#39;ve designed involves some tables being joined (e.g., Office &amp;amp; Employee will be joined to form a Sales Rep dimension table). It also involves the use of both SCD1 for some columns, and SCD2 for others.&lt;/p&gt;\n\n&lt;p&gt;However, not 100% sure on the next steps. &lt;/p&gt;\n\n&lt;p&gt;To take the Office table as an example, I&amp;#39;ve considered having a single table/area for this in the silver layer, where I just append or update records based on what&amp;#39;s coming from Bronze each day. Therefore this table would need to have effective date and end date columns (for SCD2) as well as a surrogate key column. &lt;/p&gt;\n\n&lt;p&gt;Then when moving from Silver to Gold, in this example, I would do some kind of join between Office and Employee to form the Sales Rep Dimension, only using records that were updated and appended during current run, and do some kind of upsert to the relevant Gold layer dim table.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just worried I&amp;#39;m either overcomplicating this or missing something, and want to make sure my over-arching idea makes sense. &lt;/p&gt;\n\n&lt;p&gt;Can anyone provide some advice, or let me know how you might approach this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1az2ofy", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataPanda", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1az2ofy/best_practices_and_rules_for_moving_data_through/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1az2ofy/best_practices_and_rules_for_moving_data_through/", "subreddit_subscribers": 163483, "created_utc": 1708802038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a pipeline i use foreachbatch for writing one stream to different sinks. I have the feeling this is not really considered best practice because it kind of feels like perverting streaming principles to enforce a type of batch processing\u2026 what are your experiences with foreaxhbatch or how do you handle such kind of problems? \n", "author_fullname": "t2_q4hy00qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Streaming - foreachBatch bad practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1azlz5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708861221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a pipeline i use foreachbatch for writing one stream to different sinks. I have the feeling this is not really considered best practice because it kind of feels like perverting streaming principles to enforce a type of batch processing\u2026 what are your experiences with foreaxhbatch or how do you handle such kind of problems? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azlz5r", "is_robot_indexable": true, "report_reasons": null, "author": "ShipWild9022", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azlz5r/spark_streaming_foreachbatch_bad_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azlz5r/spark_streaming_foreachbatch_bad_practice/", "subreddit_subscribers": 163483, "created_utc": 1708861221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to working with a data analyst and I want to set my own expectations well as well as support them in their growth.  Is there a good example of what to expect at different levels?  \n\nA bit like the dropbox career framework but for data analysts.\n", "author_fullname": "t2_5gzu4ur4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career ladder for data analyst role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1azlgrk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708859313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to working with a data analyst and I want to set my own expectations well as well as support them in their growth.  Is there a good example of what to expect at different levels?  &lt;/p&gt;\n\n&lt;p&gt;A bit like the dropbox career framework but for data analysts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azlgrk", "is_robot_indexable": true, "report_reasons": null, "author": "bluezebra42", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azlgrk/career_ladder_for_data_analyst_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azlgrk/career_ladder_for_data_analyst_role/", "subreddit_subscribers": 163483, "created_utc": 1708859313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working with a finance reporting queries. Let's say I have one table called 'finance_entries'. I am using python in my codebase. I set up a connection to a postgressql dB set up on gcp. \nI need to query this table to get different information such as no_of_transactions (as an int) , invalid_tractions(as a data frame), etc.\n\nWould it be better to have one giant query extracting a data frame/ or view with all my conditions, where I have separate functions to get the data I need from that data frame. \n\nOR\n\nWould it be better to have each function have its own query to the table. \n\nI personally think option 2 is cleaner. Would like everyone's opinion and if possible some supporting resource for the rationale. Because I'm gonna need to convince my manager. \n", "author_fullname": "t2_ng90q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Single query or split queries by function", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azhvje", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708845228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with a finance reporting queries. Let&amp;#39;s say I have one table called &amp;#39;finance_entries&amp;#39;. I am using python in my codebase. I set up a connection to a postgressql dB set up on gcp. \nI need to query this table to get different information such as no_of_transactions (as an int) , invalid_tractions(as a data frame), etc.&lt;/p&gt;\n\n&lt;p&gt;Would it be better to have one giant query extracting a data frame/ or view with all my conditions, where I have separate functions to get the data I need from that data frame. &lt;/p&gt;\n\n&lt;p&gt;OR&lt;/p&gt;\n\n&lt;p&gt;Would it be better to have each function have its own query to the table. &lt;/p&gt;\n\n&lt;p&gt;I personally think option 2 is cleaner. Would like everyone&amp;#39;s opinion and if possible some supporting resource for the rationale. Because I&amp;#39;m gonna need to convince my manager. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azhvje", "is_robot_indexable": true, "report_reasons": null, "author": "Pooop69", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azhvje/single_query_or_split_queries_by_function/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azhvje/single_query_or_split_queries_by_function/", "subreddit_subscribers": 163483, "created_utc": 1708845228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've had an interesting discussion this week that got me thinking on the utility of feature stores in MLOps. I was wondering how you think about this.\n\nFor a long time I thought feature stores mainly target online (real-time) prediction workloads. You want fast access to the current version of a feature (the \"online\" layer) during inference, bulk access to data during training (offline layer), and wish that your inference and training API are the same so you can share code paths.\n\nHowever, now I realized that feature stores also advertise their \"time-travel\" capability, i.e., they have a built-in SCD mechanism to allow you to train on consistent snapshots of historical data.\n\nDid I missunderstand the purpose of a feature store and the \"killer feature\" isnt the fast cache of the latest version of a record, but rather the built-in SCD? Is CDC capture via SCD a common feature of a feature?", "author_fullname": "t2_frdb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did i missunderstand feature stores?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1azm6q1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708862028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had an interesting discussion this week that got me thinking on the utility of feature stores in MLOps. I was wondering how you think about this.&lt;/p&gt;\n\n&lt;p&gt;For a long time I thought feature stores mainly target online (real-time) prediction workloads. You want fast access to the current version of a feature (the &amp;quot;online&amp;quot; layer) during inference, bulk access to data during training (offline layer), and wish that your inference and training API are the same so you can share code paths.&lt;/p&gt;\n\n&lt;p&gt;However, now I realized that feature stores also advertise their &amp;quot;time-travel&amp;quot; capability, i.e., they have a built-in SCD mechanism to allow you to train on consistent snapshots of historical data.&lt;/p&gt;\n\n&lt;p&gt;Did I missunderstand the purpose of a feature store and the &amp;quot;killer feature&amp;quot; isnt the fast cache of the latest version of a record, but rather the built-in SCD? Is CDC capture via SCD a common feature of a feature?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azm6q1", "is_robot_indexable": true, "report_reasons": null, "author": "FirefoxMetzger", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azm6q1/did_i_missunderstand_feature_stores/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azm6q1/did_i_missunderstand_feature_stores/", "subreddit_subscribers": 163483, "created_utc": 1708862028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, seeking advice on initiating a new Data Engineering project. Our client has tasked us with identifying logs from a third-party application and integrating them into Databricks. The challenge lies in the fact that the client already has established internal processes, including extraction templates, and all jobs are deployed using Terraform. How do you approach projects in environments where the customer has existing governance and established processes?\"", "author_fullname": "t2_iweexjfw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks new project - Seeking Advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1azlquc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708860326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, seeking advice on initiating a new Data Engineering project. Our client has tasked us with identifying logs from a third-party application and integrating them into Databricks. The challenge lies in the fact that the client already has established internal processes, including extraction templates, and all jobs are deployed using Terraform. How do you approach projects in environments where the customer has existing governance and established processes?&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azlquc", "is_robot_indexable": true, "report_reasons": null, "author": "yeager_doug", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azlquc/databricks_new_project_seeking_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azlquc/databricks_new_project_seeking_advice/", "subreddit_subscribers": 163483, "created_utc": 1708860326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im looking to build a system that aims to provide better ability to create and manage schedules in resource-constrained projects.\n\nWhat I mean by \u201cresource-constrained\u201d is actually kind of interesting when you think about the effects. Let\u2019s say you\u2019re building a house: you can get the flooring guys in and out within a day (maybe). Scale that project to a hotel though, now your flooring guys can only complete several units in a day. This constraint to select spaces is what I mean.\n\nFlooring might be a dependancy of walls though. And roofing might depend on walls. So you end up with task dependancies, and on a resource-constrained schedule that has an effect of causing all tasks to sort of cascade to completion throughout the project.\n\nThis produces a natural grouping of spaces. Spaces can now be grouped based on where tasks will be completed. For example, if spaces 1, 2, and 3 get flooring done on day 1, spaces 1, 2, and 3 would be a grouping. Similarly, space 4. 5, and 6 might get flooring done on day 2 while the wall guys are in spaces 1, 2, and 3. Spaces 4, 5, and 6 would be another grouping.\n\nOne advantageous effect of these groupings is that a manager can reassign a not-on-schedule space to a different group\u2026 a group performing tasks which are more downstream\u2026 in order to put that space back on-schedule. Though this has the adverse effect of making the new grouping\u2019s workload larger for the remaining duration of the project. Also, this kind of adjustment would be impossible for any spaces in the most downstream grouping.\n\nTypically, there\u2019s a project level set of tasks that all spaces inherit. This is good for easing the schedule creation process but might not precisely represent the reality of the project.\n\nTypically, this is managed via an Excel spreadsheet where tasks are laid out as column headers, space groupings as indices, and expected start dates as matrix values. The space groupings are just CSV formatted text of the spaces contained, making recognition easy. Cell formatting is used to indicate completion of a task within a space grouping. This encoding for status is unfortunate because if status between spaces within a group are desynchronized, say because one space is late, there is no good way to represent that on the schedule.\n\nOne benefit the guys using this thing don\u2019t want to give up is the ease of status changes though. They can open the Excel file, highlight the necessary cells, and accurately update the status for hundreds of spaces in a given second, forgoing any desynchronized spaces within their groups.\n\nWhatever the solution, they want better reporting into the overall state of completion and tardiness for all spaces, groupings, and tasks. They also want the data recorded for analysis of historical trends.\n\nSo Im mining these details for design requirements, like how spaces can elegantly swap between groups in order to be put \u201cback on-schedule.\u201d That would suggest that spaces are assigned tasks but not due dates for those tasks. Rather, spaces inherit their task due dates from the space grouping they\u2019re assigned to.\n\nAnyhow, I believe I can build the necessary backend logic, such as the application database. Perhaps even some basic forms to input data, as well as dashboards. As I\u2019m going through this though, the scheduling aspect feels like I\u2019m reinventing the wheel a bit. Secondly, I worry that a complex frontend will need to be built and that is not my expertise.\n\nI\u2019ve tested various less data-engineering solutions like MS Project, figuring those should be good enough. They\u2019re not good enough for various reasons but mostly because none are designed to manage thousands of tasks, spaces, etc. in elegant ways. The work to manage the project becomes too much when using many of these existing tools, especially when they don\u2019t have an API.\n\nEffectively, I\u2019m wondering if there\u2019s a tool or framework that\u2019s better suited for engineering these types of solutions. Handling schedule data in ways that I mention, helping users perform schedule changes and update statuses?\n\nI\u2019m about to build the whole thing from scratch. Are there tools out there to lift off segments of this workload and lighten the burden?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools For Schedule Management Systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azhkj0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708845763.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708844100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking to build a system that aims to provide better ability to create and manage schedules in resource-constrained projects.&lt;/p&gt;\n\n&lt;p&gt;What I mean by \u201cresource-constrained\u201d is actually kind of interesting when you think about the effects. Let\u2019s say you\u2019re building a house: you can get the flooring guys in and out within a day (maybe). Scale that project to a hotel though, now your flooring guys can only complete several units in a day. This constraint to select spaces is what I mean.&lt;/p&gt;\n\n&lt;p&gt;Flooring might be a dependancy of walls though. And roofing might depend on walls. So you end up with task dependancies, and on a resource-constrained schedule that has an effect of causing all tasks to sort of cascade to completion throughout the project.&lt;/p&gt;\n\n&lt;p&gt;This produces a natural grouping of spaces. Spaces can now be grouped based on where tasks will be completed. For example, if spaces 1, 2, and 3 get flooring done on day 1, spaces 1, 2, and 3 would be a grouping. Similarly, space 4. 5, and 6 might get flooring done on day 2 while the wall guys are in spaces 1, 2, and 3. Spaces 4, 5, and 6 would be another grouping.&lt;/p&gt;\n\n&lt;p&gt;One advantageous effect of these groupings is that a manager can reassign a not-on-schedule space to a different group\u2026 a group performing tasks which are more downstream\u2026 in order to put that space back on-schedule. Though this has the adverse effect of making the new grouping\u2019s workload larger for the remaining duration of the project. Also, this kind of adjustment would be impossible for any spaces in the most downstream grouping.&lt;/p&gt;\n\n&lt;p&gt;Typically, there\u2019s a project level set of tasks that all spaces inherit. This is good for easing the schedule creation process but might not precisely represent the reality of the project.&lt;/p&gt;\n\n&lt;p&gt;Typically, this is managed via an Excel spreadsheet where tasks are laid out as column headers, space groupings as indices, and expected start dates as matrix values. The space groupings are just CSV formatted text of the spaces contained, making recognition easy. Cell formatting is used to indicate completion of a task within a space grouping. This encoding for status is unfortunate because if status between spaces within a group are desynchronized, say because one space is late, there is no good way to represent that on the schedule.&lt;/p&gt;\n\n&lt;p&gt;One benefit the guys using this thing don\u2019t want to give up is the ease of status changes though. They can open the Excel file, highlight the necessary cells, and accurately update the status for hundreds of spaces in a given second, forgoing any desynchronized spaces within their groups.&lt;/p&gt;\n\n&lt;p&gt;Whatever the solution, they want better reporting into the overall state of completion and tardiness for all spaces, groupings, and tasks. They also want the data recorded for analysis of historical trends.&lt;/p&gt;\n\n&lt;p&gt;So Im mining these details for design requirements, like how spaces can elegantly swap between groups in order to be put \u201cback on-schedule.\u201d That would suggest that spaces are assigned tasks but not due dates for those tasks. Rather, spaces inherit their task due dates from the space grouping they\u2019re assigned to.&lt;/p&gt;\n\n&lt;p&gt;Anyhow, I believe I can build the necessary backend logic, such as the application database. Perhaps even some basic forms to input data, as well as dashboards. As I\u2019m going through this though, the scheduling aspect feels like I\u2019m reinventing the wheel a bit. Secondly, I worry that a complex frontend will need to be built and that is not my expertise.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tested various less data-engineering solutions like MS Project, figuring those should be good enough. They\u2019re not good enough for various reasons but mostly because none are designed to manage thousands of tasks, spaces, etc. in elegant ways. The work to manage the project becomes too much when using many of these existing tools, especially when they don\u2019t have an API.&lt;/p&gt;\n\n&lt;p&gt;Effectively, I\u2019m wondering if there\u2019s a tool or framework that\u2019s better suited for engineering these types of solutions. Handling schedule data in ways that I mention, helping users perform schedule changes and update statuses?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to build the whole thing from scratch. Are there tools out there to lift off segments of this workload and lighten the burden?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azhkj0", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azhkj0/tools_for_schedule_management_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azhkj0/tools_for_schedule_management_systems/", "subreddit_subscribers": 163483, "created_utc": 1708844100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In nutshell, I have an OLTP Oracle 19c database and I want to do massive queries on my data. However, I don't want to overload my OLTP database.\n\nSo, is it possible to use RAID1 for mirroring my OLTP database in another disk and use another Oracle 19c instance in read-only mode connected to the mirrored disk?\n\nI have never used RAID, so I don't know the limitations.", "author_fullname": "t2_rvp7wzgv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I use RAID1 for mirroring an OLTP Oracle 19c to an OLAP Oracle 19c?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az4qli", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708808016.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708807208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In nutshell, I have an OLTP Oracle 19c database and I want to do massive queries on my data. However, I don&amp;#39;t want to overload my OLTP database.&lt;/p&gt;\n\n&lt;p&gt;So, is it possible to use RAID1 for mirroring my OLTP database in another disk and use another Oracle 19c instance in read-only mode connected to the mirrored disk?&lt;/p&gt;\n\n&lt;p&gt;I have never used RAID, so I don&amp;#39;t know the limitations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1az4qli", "is_robot_indexable": true, "report_reasons": null, "author": "nivlek_miroma", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1az4qli/can_i_use_raid1_for_mirroring_an_oltp_oracle_19c/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1az4qli/can_i_use_raid1_for_mirroring_an_oltp_oracle_19c/", "subreddit_subscribers": 163483, "created_utc": 1708807208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, \n\nAnyone has experience with HPE data fabric which he would like to share?  We are trying to build a data platform onpremise and we are evaluting this product. ", "author_fullname": "t2_76ygd12r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HPE Data Fabric", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az24fn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708800693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, &lt;/p&gt;\n\n&lt;p&gt;Anyone has experience with HPE data fabric which he would like to share?  We are trying to build a data platform onpremise and we are evaluting this product. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1az24fn", "is_robot_indexable": true, "report_reasons": null, "author": "SimilarEstimate6234", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1az24fn/hpe_data_fabric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1az24fn/hpe_data_fabric/", "subreddit_subscribers": 163483, "created_utc": 1708800693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Apache Spark RDD is immutable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1az2yy2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/F9F0Ui-ND5wCoAXg5MXlEqVIwRNlyBDPX4vZoFORv6k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708802758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/why-apache-spark-rdd-is-immutable", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vdI9-uUf8gDHTJ36iKJhsqPTcWh3PxhZw6wL1xe7TL0.jpg?auto=webp&amp;s=778cbaf946cd1ba35546ed21f100f5a0b4ece151", "width": 800, "height": 405}, "resolutions": [{"url": "https://external-preview.redd.it/vdI9-uUf8gDHTJ36iKJhsqPTcWh3PxhZw6wL1xe7TL0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f2114b41e78e7996518b8848e91d49d87957616a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/vdI9-uUf8gDHTJ36iKJhsqPTcWh3PxhZw6wL1xe7TL0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=768d3518a8b889053f40550c60b72645d9276ee9", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/vdI9-uUf8gDHTJ36iKJhsqPTcWh3PxhZw6wL1xe7TL0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=949cb9a0ce573df9b25be17a62d6b8b1de5d644e", "width": 320, "height": 162}, {"url": "https://external-preview.redd.it/vdI9-uUf8gDHTJ36iKJhsqPTcWh3PxhZw6wL1xe7TL0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2be4fb11d2c73817ba50d49ffdbd0b27e72001ec", "width": 640, "height": 324}], "variants": {}, "id": "2A-mOdpSZG8F-78tz1XH_l5i-4T-tq7AozjaC9tLotQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1az2yy2", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1az2yy2/why_apache_spark_rdd_is_immutable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/why-apache-spark-rdd-is-immutable", "subreddit_subscribers": 163483, "created_utc": 1708802758.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}