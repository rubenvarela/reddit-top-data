{"kind": "Listing", "data": {"after": "t3_1azeuer", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_irp9492cx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We're gonna need another napster soon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayzbgi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 1150, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1150, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VsFWptsFlVT94CZ6J6v2A_0eqP-Hx-abEbeQ4BstqhQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708793859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wg7c9kvddkkc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wg7c9kvddkkc1.png?auto=webp&amp;s=3d12cd56fa750cd757ed82f143ac637a87dae79b", "width": 598, "height": 374}, "resolutions": [{"url": "https://preview.redd.it/wg7c9kvddkkc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6af6a7ca923266c4c6f4962093531bfb0a46638b", "width": 108, "height": 67}, {"url": "https://preview.redd.it/wg7c9kvddkkc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9aca7609618bd3d01b9f1081e147e2731f411a86", "width": 216, "height": 135}, {"url": "https://preview.redd.it/wg7c9kvddkkc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9f58a19486ec0b44c68e2c3422c07f3ce70fae4", "width": 320, "height": 200}], "variants": {}, "id": "KGxkx-x019U-Pmt5lv8LkJScQ3D8SimsvI8T-jifQo8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ayzbgi", "is_robot_indexable": true, "report_reasons": null, "author": "Scuczu2", "discussion_type": null, "num_comments": 62, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayzbgi/were_gonna_need_another_napster_soon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wg7c9kvddkkc1.png", "subreddit_subscribers": 734298, "created_utc": 1708793859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3f3g8i6e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "&lt;3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 24, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayp6fe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 731, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 731, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ilhv1rJfOky5sXqtMBKCODD476L3Bd8QeQ6q_BgmVq4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708761535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/y4op1eh8phkc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/y4op1eh8phkc1.png?auto=webp&amp;s=bf5313ab3a60b1e03fcfd473463469ffbaac41aa", "width": 1648, "height": 286}, "resolutions": [{"url": "https://preview.redd.it/y4op1eh8phkc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=56405825e947ca8fee2672b860f8413449cc4a13", "width": 108, "height": 18}, {"url": "https://preview.redd.it/y4op1eh8phkc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=071b9fc136620fb1eceb8b07ab4426ddef417401", "width": 216, "height": 37}, {"url": "https://preview.redd.it/y4op1eh8phkc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8df3b9f9cea56f172f8c6724437d8106fe8296ee", "width": 320, "height": 55}, {"url": "https://preview.redd.it/y4op1eh8phkc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4f4fb21569984a201861bc9b2399205166819a0c", "width": 640, "height": 111}, {"url": "https://preview.redd.it/y4op1eh8phkc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=02ea78310a459bebfae4e65c57eb6e89e9739930", "width": 960, "height": 166}, {"url": "https://preview.redd.it/y4op1eh8phkc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa08510b7fe0cd20f31d71d6039a575586ad2dc9", "width": 1080, "height": 187}], "variants": {}, "id": "BKEAwtyijWICH6sQ6m0pUIhLpXEaye8zhPSVg2SSdwI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayp6fe", "is_robot_indexable": true, "report_reasons": null, "author": "theasciibull", "discussion_type": null, "num_comments": 124, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayp6fe/3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/y4op1eh8phkc1.png", "subreddit_subscribers": 734298, "created_utc": 1708761535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Yesterday It has been announced by the system administrator that the site will be shutting down at some point:`\"Hi everyone, im very sorry to be waiting this, but subscene cannot continue for much longer.It has not been paying for itself for several years now, visistors are falling, and maintenance cannot continue. I am amazed of all your administrative work with the content which is the primary reason that I have continued paying for the site for this long.Thank you all for this journey we have been on together. If I can do anything for you let me now.\"`\n\n[https://forum.subscene.com/topic/news-about-the-closure-of-the-subs](https://forum.subscene.com/topic/news-about-the-closure-of-the-subs)\n\nWould it be feasible to archive it?\n\nAFAIK, there's no other subtitle sharing website that has this amount of subs across multiple languages.", "author_fullname": "t2_n6j6n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Subscene.com is about to shutdown soon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayu97p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 201, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 201, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708781826.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708780453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yesterday It has been announced by the system administrator that the site will be shutting down at some point:&lt;code&gt;&amp;quot;Hi everyone, im very sorry to be waiting this, but subscene cannot continue for much longer.It has not been paying for itself for several years now, visistors are falling, and maintenance cannot continue. I am amazed of all your administrative work with the content which is the primary reason that I have continued paying for the site for this long.Thank you all for this journey we have been on together. If I can do anything for you let me now.&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://forum.subscene.com/topic/news-about-the-closure-of-the-subs\"&gt;https://forum.subscene.com/topic/news-about-the-closure-of-the-subs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Would it be feasible to archive it?&lt;/p&gt;\n\n&lt;p&gt;AFAIK, there&amp;#39;s no other subtitle sharing website that has this amount of subs across multiple languages.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayu97p", "is_robot_indexable": true, "report_reasons": null, "author": "ShinigamiDesux", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayu97p/subscenecom_is_about_to_shutdown_soon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ayu97p/subscenecom_is_about_to_shutdown_soon/", "subreddit_subscribers": 734298, "created_utc": 1708780453.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve been using this as my main computer all this time. Mainly for Retroarch!! The things run perfectly, like a dream. Nothing could bother it while it plays the entire Internet of games but it\u2019s space capacity. Really, only 8GB for the lite version is enough for this machine to completely emulate the Nintendo 64 at times. \n\nIt recently got an update that messed up the controller and what do you know!? Everything that worked perfectly before stopped working. I really liked this fire stick lite and this one I tried to set up as a backup firmware but it\u2019ll just update even after I just opened it! So what do I do!? This is horrible! It\u2019s the lowest resource advantage for anybody looking to play retro games, it\u2019s base firmware was perfect for most tasks you wanted to run. The controller was an essential piece to this setup and the system update ruined mostly all of the functionality it once possessed. \n\nI have since reset the device but I don\u2019t have any hopes for the future about this product with these kinds of updates. I might just throw it in\u2026it\u2019s a really huge shame too because it was literally at like 99% support with most cores and probably the lowest power system you can find, I think. \n\nDefinitely take your fire sticks offline or keep them that way if you want to take advantage of the DualShock 4\u2026because I deleted my whole system. ", "author_fullname": "t2_t239zgcn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After years of good service! 1 update screwed up years worth of sideloading! They need an update to stop updates!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayqh42", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zoD8xi6HN2SjovWognQzwt5b3MTUH2BjqY5VQaxFlhM.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708766683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been using this as my main computer all this time. Mainly for Retroarch!! The things run perfectly, like a dream. Nothing could bother it while it plays the entire Internet of games but it\u2019s space capacity. Really, only 8GB for the lite version is enough for this machine to completely emulate the Nintendo 64 at times. &lt;/p&gt;\n\n&lt;p&gt;It recently got an update that messed up the controller and what do you know!? Everything that worked perfectly before stopped working. I really liked this fire stick lite and this one I tried to set up as a backup firmware but it\u2019ll just update even after I just opened it! So what do I do!? This is horrible! It\u2019s the lowest resource advantage for anybody looking to play retro games, it\u2019s base firmware was perfect for most tasks you wanted to run. The controller was an essential piece to this setup and the system update ruined mostly all of the functionality it once possessed. &lt;/p&gt;\n\n&lt;p&gt;I have since reset the device but I don\u2019t have any hopes for the future about this product with these kinds of updates. I might just throw it in\u2026it\u2019s a really huge shame too because it was literally at like 99% support with most cores and probably the lowest power system you can find, I think. &lt;/p&gt;\n\n&lt;p&gt;Definitely take your fire sticks offline or keep them that way if you want to take advantage of the DualShock 4\u2026because I deleted my whole system. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/h3cw5nmn4ikc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/h3cw5nmn4ikc1.jpeg?auto=webp&amp;s=e4b32a067302302d1c77abf13fe2eb3bfee2060f", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/h3cw5nmn4ikc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=acb4299834dbc46179083b77bf264d8c1ab89efa", "width": 108, "height": 144}, {"url": "https://preview.redd.it/h3cw5nmn4ikc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b08980f748df58d48d1c382c67104f30c8f43ee", "width": 216, "height": 288}, {"url": "https://preview.redd.it/h3cw5nmn4ikc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0b7651366e347f98581d3c4f24f61bb3e3e49dc", "width": 320, "height": 426}, {"url": "https://preview.redd.it/h3cw5nmn4ikc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=33ff9819fc96880e9c17185e958fde6faeb02157", "width": 640, "height": 853}, {"url": "https://preview.redd.it/h3cw5nmn4ikc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=64d0ad325140f41deb505a039eb32a2727f16780", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/h3cw5nmn4ikc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f47720529490fd60a26ba9aa56c6f39748fac3a5", "width": 1080, "height": 1440}], "variants": {}, "id": "AUKVbt2Q2qQk8PYwCA_NuQVfJdtMhpKB2pOnkbBgFfg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayqh42", "is_robot_indexable": true, "report_reasons": null, "author": "FinanceFit6474", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1ayqh42/after_years_of_good_service_1_update_screwed_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/h3cw5nmn4ikc1.jpeg", "subreddit_subscribers": 734298, "created_utc": 1708766683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A website I'm remotely interested in is closing soon ; I'd like to keep it, just in case, and I was going to use the usual `wget \"$URL\" --mirror\"` (it is a static website, FYI). But I thought there was maybe a better method. \n\nOf course, I am not talking about making a Wayback machine snapshot.\n\nGiven the purpose of the community, I'm sure many here are familiar with this and so, I was wondering what you were using to archive a website.\n\nIf you have a better method than `wget` + `tar`, I'm eager to know them. And if you have some remarks about \"hoarding\" websites, do not hesitate to share.", "author_fullname": "t2_30esmtm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to archive a website?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayrxl3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708772415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A website I&amp;#39;m remotely interested in is closing soon ; I&amp;#39;d like to keep it, just in case, and I was going to use the usual &lt;code&gt;wget &amp;quot;$URL&amp;quot; --mirror&amp;quot;&lt;/code&gt; (it is a static website, FYI). But I thought there was maybe a better method. &lt;/p&gt;\n\n&lt;p&gt;Of course, I am not talking about making a Wayback machine snapshot.&lt;/p&gt;\n\n&lt;p&gt;Given the purpose of the community, I&amp;#39;m sure many here are familiar with this and so, I was wondering what you were using to archive a website.&lt;/p&gt;\n\n&lt;p&gt;If you have a better method than &lt;code&gt;wget&lt;/code&gt; + &lt;code&gt;tar&lt;/code&gt;, I&amp;#39;m eager to know them. And if you have some remarks about &amp;quot;hoarding&amp;quot; websites, do not hesitate to share.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayrxl3", "is_robot_indexable": true, "report_reasons": null, "author": "edparadox", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayrxl3/best_way_to_archive_a_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ayrxl3/best_way_to_archive_a_website/", "subreddit_subscribers": 734298, "created_utc": 1708772415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First you'll need to install the IA program on your computer, details here [https://archive.org/developers/internetarchive/cli.html#download](https://archive.org/developers/internetarchive/cli.html#download)\n\nThis is a command line tool, not aware of any GUI that exists, and chrome extensions seem to be unobtainable nowadays.\n\nSo lets say I want to download everything from [this](https://archive.org/details/thingiverse?tab=collection&amp;query=lord+of+the+rings) page. There are two things to consider, firstly that we are within a collection, and next that I've searched within this collection, in this case for LOTR.\n\n    ia search 'subject:\"lord of the rings\" collection:thingiverse' --itemlist &gt; lotr.txt\n\nia download --itemlist lotr.txt --no-directories --glob=\\*.zip\n\nThe first line searches for your term within said collection, then outputs it to an item list, in this case `lotr.txt`\n\nThe next line downloads from that list. I added two qualifiers, the first is `--no-directories` which simply dumps all the zip files into a single directory of my choice. This is the way I want it, you can remove that if you want each archive item in a separate directory. Play around with it.\n\nThe next qualifier is the most important thing in this guide, `--glob=\\*.zip` this will only download certain file types, in this case .zip. Without this, it will download all metadata AND all filetypes available. If you are downloading old film reels for example, there may be .avi .mov. mkv .mp4 and so on, which will take forever and is unecessary.\n\nYou can play around with all this, but I highly recommend outputting to a txt file first so that you know what you're getting into. You can for example search for things outside collections, or download an entire collection, and so on.", "author_fullname": "t2_ay7tp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quick guide for downloading from Internet Archive in bulk", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aywx5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708788143.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708787872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First you&amp;#39;ll need to install the IA program on your computer, details here &lt;a href=\"https://archive.org/developers/internetarchive/cli.html#download\"&gt;https://archive.org/developers/internetarchive/cli.html#download&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a command line tool, not aware of any GUI that exists, and chrome extensions seem to be unobtainable nowadays.&lt;/p&gt;\n\n&lt;p&gt;So lets say I want to download everything from &lt;a href=\"https://archive.org/details/thingiverse?tab=collection&amp;amp;query=lord+of+the+rings\"&gt;this&lt;/a&gt; page. There are two things to consider, firstly that we are within a collection, and next that I&amp;#39;ve searched within this collection, in this case for LOTR.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ia search &amp;#39;subject:&amp;quot;lord of the rings&amp;quot; collection:thingiverse&amp;#39; --itemlist &amp;gt; lotr.txt\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;ia download --itemlist lotr.txt --no-directories --glob=*.zip&lt;/p&gt;\n\n&lt;p&gt;The first line searches for your term within said collection, then outputs it to an item list, in this case &lt;code&gt;lotr.txt&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;The next line downloads from that list. I added two qualifiers, the first is &lt;code&gt;--no-directories&lt;/code&gt; which simply dumps all the zip files into a single directory of my choice. This is the way I want it, you can remove that if you want each archive item in a separate directory. Play around with it.&lt;/p&gt;\n\n&lt;p&gt;The next qualifier is the most important thing in this guide, &lt;code&gt;--glob=\\*.zip&lt;/code&gt; this will only download certain file types, in this case .zip. Without this, it will download all metadata AND all filetypes available. If you are downloading old film reels for example, there may be .avi .mov. mkv .mp4 and so on, which will take forever and is unecessary.&lt;/p&gt;\n\n&lt;p&gt;You can play around with all this, but I highly recommend outputting to a txt file first so that you know what you&amp;#39;re getting into. You can for example search for things outside collections, or download an entire collection, and so on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "244TB ZFS and Synology", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aywx5l", "is_robot_indexable": true, "report_reasons": null, "author": "erik530195", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1aywx5l/quick_guide_for_downloading_from_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1aywx5l/quick_guide_for_downloading_from_internet_archive/", "subreddit_subscribers": 734298, "created_utc": 1708787872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For context: I recently purchase an upscaler, sansui vcr and elgato capture card to start digitizing my families home VHS tape collection. I have recorded probably about two videos so far and it went by smooth. After two videos I got bad playback and purchased a vcr head cleaner. \n\nHowever, I still have the problem of some tapes getting the vcr more dirty and want to ensure the longevity of the tapes and less strenuous on the digitizing process. The electronic vcr tape cleaners seem to be rare and not sure the other method to go about cleaning.", "author_fullname": "t2_4kz0kk4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy and best method to clean VHS tapes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1azg3ig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708838838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context: I recently purchase an upscaler, sansui vcr and elgato capture card to start digitizing my families home VHS tape collection. I have recorded probably about two videos so far and it went by smooth. After two videos I got bad playback and purchased a vcr head cleaner. &lt;/p&gt;\n\n&lt;p&gt;However, I still have the problem of some tapes getting the vcr more dirty and want to ensure the longevity of the tapes and less strenuous on the digitizing process. The electronic vcr tape cleaners seem to be rare and not sure the other method to go about cleaning.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1azg3ig", "is_robot_indexable": true, "report_reasons": null, "author": "harshcloud", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1azg3ig/easy_and_best_method_to_clean_vhs_tapes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1azg3ig/easy_and_best_method_to_clean_vhs_tapes/", "subreddit_subscribers": 734298, "created_utc": 1708838838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a couple of terabytes of data i really wouldn't like to loose. Right now i have that data on 1 external hard drive that i check maybe every 6 months or so. Another copy on a external SSD that i access frequently. The last copy is on a HDD that the files were originally on but not its not in use. I check that HDD very rarely (Maybe once a year or less). \n\nSo i have 3 copies on 2 types of storage mediums. Is this enough? If the external hard drive fails i have the ssd, if the ssd fails i have the external hard drive, if both fail i have the hdd. ", "author_fullname": "t2_kht4ovrc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my backup solution sufficient?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az2r7u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708802214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a couple of terabytes of data i really wouldn&amp;#39;t like to loose. Right now i have that data on 1 external hard drive that i check maybe every 6 months or so. Another copy on a external SSD that i access frequently. The last copy is on a HDD that the files were originally on but not its not in use. I check that HDD very rarely (Maybe once a year or less). &lt;/p&gt;\n\n&lt;p&gt;So i have 3 copies on 2 types of storage mediums. Is this enough? If the external hard drive fails i have the ssd, if the ssd fails i have the external hard drive, if both fail i have the hdd. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1az2r7u", "is_robot_indexable": true, "report_reasons": null, "author": "TengokuDaimakyo", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1az2r7u/is_my_backup_solution_sufficient/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1az2r7u/is_my_backup_solution_sufficient/", "subreddit_subscribers": 734298, "created_utc": 1708802214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello\n\nI have Seagate external expansion disk 12TB\n\nDisk sentinel shows disk like st12000ne0008\n\nDid anybody already shucking this disk? Can i expect problems like PWDIS?", "author_fullname": "t2_ptdg2w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Before disk shucking with IronWolf inside", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az0uxj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708797614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I have Seagate external expansion disk 12TB&lt;/p&gt;\n\n&lt;p&gt;Disk sentinel shows disk like st12000ne0008&lt;/p&gt;\n\n&lt;p&gt;Did anybody already shucking this disk? Can i expect problems like PWDIS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1az0uxj", "is_robot_indexable": true, "report_reasons": null, "author": "forplan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1az0uxj/before_disk_shucking_with_ironwolf_inside/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1az0uxj/before_disk_shucking_with_ironwolf_inside/", "subreddit_subscribers": 734298, "created_utc": 1708797614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I finally got another drive to store a backup offline, but man that took like 8 hours to back up 3tb+.\n\nAll I did was drag and drop in the windows explorer.\n\nIf I want to routinely back up my drive every few months, should I be using an application?\n\nI feel like dragging and dropping again after the first transfer is suboptimal. \n\nTIA.", "author_fullname": "t2_iaosze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you guys do your routine offline backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1azgjh5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708840359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally got another drive to store a backup offline, but man that took like 8 hours to back up 3tb+.&lt;/p&gt;\n\n&lt;p&gt;All I did was drag and drop in the windows explorer.&lt;/p&gt;\n\n&lt;p&gt;If I want to routinely back up my drive every few months, should I be using an application?&lt;/p&gt;\n\n&lt;p&gt;I feel like dragging and dropping again after the first transfer is suboptimal. &lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1azgjh5", "is_robot_indexable": true, "report_reasons": null, "author": "TryTurningItOffAgain", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1azgjh5/how_do_you_guys_do_your_routine_offline_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1azgjh5/how_do_you_guys_do_your_routine_offline_backups/", "subreddit_subscribers": 734298, "created_utc": 1708840359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Help! I am trying to understand how SnapRAID works.\n\nI have 4 data disks and 2 parity disks. Say sometime later, lighting  strikes and I lose all 6 disks. But before it struck, I had cloned all 6  disks with rsync (including content files). If I insert all 6 backup  disks into a new PC, redownload SnapRAID and reconfigure to point to the disks, and run a scrub, would the scrub complete with no errors? Or would I lose my 2 disk protection and need to regenerate the content/parity files, thereby making backing up the parity disks useless?", "author_fullname": "t2_e4owahyj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SnapRAID Cloned Disks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1azgdp2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708840213.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708839802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help! I am trying to understand how SnapRAID works.&lt;/p&gt;\n\n&lt;p&gt;I have 4 data disks and 2 parity disks. Say sometime later, lighting  strikes and I lose all 6 disks. But before it struck, I had cloned all 6  disks with rsync (including content files). If I insert all 6 backup  disks into a new PC, redownload SnapRAID and reconfigure to point to the disks, and run a scrub, would the scrub complete with no errors? Or would I lose my 2 disk protection and need to regenerate the content/parity files, thereby making backing up the parity disks useless?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1azgdp2", "is_robot_indexable": true, "report_reasons": null, "author": "x5KSAM", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1azgdp2/snapraid_cloned_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1azgdp2/snapraid_cloned_disks/", "subreddit_subscribers": 734298, "created_utc": 1708839802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know it can be found easily on a desktop browser by using the network tab on inspect element, but apparently the Amazon 3D viewer can only be viewed on mobile phones. The button won\u2019t appear even on mobile browsers.\n\nI have access to both Android and iOS devices. Google wasn\u2019t able to help me. Is there a way to get this file from the app?\n", "author_fullname": "t2_njkbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to extract a 3D model from Amazon mobile app?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1az9vtr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p_LsJCsEoMKI1PilEki20NTNFiTK2iLYRTaigNetu3A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708820090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it can be found easily on a desktop browser by using the network tab on inspect element, but apparently the Amazon 3D viewer can only be viewed on mobile phones. The button won\u2019t appear even on mobile browsers.&lt;/p&gt;\n\n&lt;p&gt;I have access to both Android and iOS devices. Google wasn\u2019t able to help me. Is there a way to get this file from the app?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/mht3a8pgjmkc1.jpeg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/mht3a8pgjmkc1.jpeg?auto=webp&amp;s=185275c6fc53ce522d3d5b01de227b2d822edd78", "width": 1179, "height": 1394}, "resolutions": [{"url": "https://preview.redd.it/mht3a8pgjmkc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1f945ce555eb8eada9180997c86f4577ed5d1df4", "width": 108, "height": 127}, {"url": "https://preview.redd.it/mht3a8pgjmkc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f507582675312b81f1676e345e6d2ab50e67472", "width": 216, "height": 255}, {"url": "https://preview.redd.it/mht3a8pgjmkc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0bb1642f65bc7de163881f75bc835637da9db4ed", "width": 320, "height": 378}, {"url": "https://preview.redd.it/mht3a8pgjmkc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=842e72badbb80e3e0fa41ac08e7ce13045d44afa", "width": 640, "height": 756}, {"url": "https://preview.redd.it/mht3a8pgjmkc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9eca35f300346f389a90732542ed49794151f3b9", "width": 960, "height": 1135}, {"url": "https://preview.redd.it/mht3a8pgjmkc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4ca7903283d6b46986dd5aaafe0c6e7c8b6b4741", "width": 1080, "height": 1276}], "variants": {}, "id": "w4V-ynmE8IG6AShLabZtEMULa3nIkvonUxRcw-AAcKo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1az9vtr", "is_robot_indexable": true, "report_reasons": null, "author": "esteban_agpa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1az9vtr/how_to_extract_a_3d_model_from_amazon_mobile_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/mht3a8pgjmkc1.jpeg", "subreddit_subscribers": 734298, "created_utc": 1708820090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Dear all, I have too much data on my macbook pro and like to move it to an external ssd. isn't the Crucial X9 Pro SSD for Mac  simply a regular Crucial X9 Pro SSD formatted with apfs, or are there differences in the hardware? Surely the pro formatted in APFS will be accessible of iPhone &amp; Co? Am I mkissing something? Many thanks :)  \n[https://uk.crucial.com/products/ssd/portable-ssds](https://uk.crucial.com/products/ssd/portable-ssds)", "author_fullname": "t2_h1vgwvsb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving data to external SSD: Crucial X9 Pro SSD for Mac just a Crucial X9 Pro with APFS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az5gp2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708808973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all, I have too much data on my macbook pro and like to move it to an external ssd. isn&amp;#39;t the Crucial X9 Pro SSD for Mac  simply a regular Crucial X9 Pro SSD formatted with apfs, or are there differences in the hardware? Surely the pro formatted in APFS will be accessible of iPhone &amp;amp; Co? Am I mkissing something? Many thanks :)&lt;br/&gt;\n&lt;a href=\"https://uk.crucial.com/products/ssd/portable-ssds\"&gt;https://uk.crucial.com/products/ssd/portable-ssds&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?auto=webp&amp;s=e2421e6c60b21be472095e594db58bd778600d0f", "width": 1200, "height": 680}, "resolutions": [{"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6a4edc4610d4cb640bedd66be7355faec77ca22", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b80e53c196e0d71cb6768e16b3e461beead737c2", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7e2ed9ebc9833094c4f25cbab410a25e60e8124", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a0791fba73a60e469bde8e51ca7f958d506bf20f", "width": 640, "height": 362}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc93901b52df48149de9e881ac6e469a5c38f02", "width": 960, "height": 544}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e97fc43d31f603e47696b6292579785447d2a4f2", "width": 1080, "height": 612}], "variants": {}, "id": "zby-HJAO_eydDuSwVzafSoulGLhD91dKRo6wSmctlmY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1az5gp2", "is_robot_indexable": true, "report_reasons": null, "author": "eusmile", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1az5gp2/moving_data_to_external_ssd_crucial_x9_pro_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1az5gp2/moving_data_to_external_ssd_crucial_x9_pro_ssd/", "subreddit_subscribers": 734298, "created_utc": 1708808973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After browsing this sub, happy to see I am not the only data hoarder! So I decided to get my My Cloud 2TB up and running again. I have now found out WD no longer support this model as to where I can access my files on the go via their MyCloud App.\n\nMy question is if they have done this with my model, who's to say they won't do this with their next line up? Am I going to forever have to keep updating my model of storage so I can access my files on the go? If I was to stay with WD that is.\n\nThanks!\n\n[This is the model I have. ](https://preview.redd.it/49kgafhh2kkc1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;s=ce02d27b17eebfc8b3df5dd0021d29f5c9bd1e22)", "author_fullname": "t2_8soj9t6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD My Cloud 2TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"49kgafhh2kkc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/49kgafhh2kkc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b796d4f0b9acba53e0328c1431bb7dd3c3d2fc1d"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/49kgafhh2kkc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4374cce7bca7ac7c38faeddcac8cf9e8b48dffa6"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/49kgafhh2kkc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6602c095776ca85c9700326b24f0bf1ae3b8a5ff"}, {"y": 640, "x": 640, "u": "https://preview.redd.it/49kgafhh2kkc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=59ce5c3ba68b042e70d989b606063e5fb7f7b4b3"}, {"y": 960, "x": 960, "u": "https://preview.redd.it/49kgafhh2kkc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=14c66f0e7739c2220f2da17e8d3d0841f751ddea"}, {"y": 1080, "x": 1080, "u": "https://preview.redd.it/49kgafhh2kkc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9d4025cfe1f9d8a3193fe5ba5c690033ca7a1987"}], "s": {"y": 1500, "x": 1500, "u": "https://preview.redd.it/49kgafhh2kkc1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;s=ce02d27b17eebfc8b3df5dd0021d29f5c9bd1e22"}, "id": "49kgafhh2kkc1"}}, "name": "t3_1ayxxoq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u2L6LVrL9wwX1PcvyGms3s8ina7q4yJ8Ua-odcxl5cU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708790458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After browsing this sub, happy to see I am not the only data hoarder! So I decided to get my My Cloud 2TB up and running again. I have now found out WD no longer support this model as to where I can access my files on the go via their MyCloud App.&lt;/p&gt;\n\n&lt;p&gt;My question is if they have done this with my model, who&amp;#39;s to say they won&amp;#39;t do this with their next line up? Am I going to forever have to keep updating my model of storage so I can access my files on the go? If I was to stay with WD that is.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/49kgafhh2kkc1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ce02d27b17eebfc8b3df5dd0021d29f5c9bd1e22\"&gt;This is the model I have. &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayxxoq", "is_robot_indexable": true, "report_reasons": null, "author": "WeepZee", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayxxoq/wd_my_cloud_2tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ayxxoq/wd_my_cloud_2tb/", "subreddit_subscribers": 734298, "created_utc": 1708790458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Quick question:\n\nI needed to test a drive thoroughly, following a failure of another, so I needed to know if the replacement is OK.\n\nFrom everything that I read about testing drives on this reddit I figured that badblocks is the way to go, but unfortunately for the love of mine I could not make it work, neither on a VM in Windows, nor as a live usb. I was running into errors with permissions (that supposedly my user couldn't do sudo commands), unrecognisable directories (even though I checked what the drive directory was in the drives), or badblocks command executing and returning 'completed' result in seconds (on 8TB drive).\n\nBecause I was fed up with this, instead I performed what follows:\n\n1. Quick SMART check using HDDScan app\n2. h2testw test for entire drive (AFAIK this is windows-like equivalent of badblocks, it fills the drive with data and then verifies it) - that took like good 20 hours and came up clean\n3. Extended SMART test using HDDScan - came up clean\n\nIn the meantime I was checking the CrystalDisk info for SMART parameters, after everything I threw at it everything is OK, no reallocated sectors, no pending, no uncorrectable.\n\n&amp;#x200B;\n\nCan I assume that the drive is fine, or should I still perform badblocks, because the aforementioned tests may not be enough to detect a fault?", "author_fullname": "t2_38zesk7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this enough testing, or is badblocks necessary still?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az2y3m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708802699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Quick question:&lt;/p&gt;\n\n&lt;p&gt;I needed to test a drive thoroughly, following a failure of another, so I needed to know if the replacement is OK.&lt;/p&gt;\n\n&lt;p&gt;From everything that I read about testing drives on this reddit I figured that badblocks is the way to go, but unfortunately for the love of mine I could not make it work, neither on a VM in Windows, nor as a live usb. I was running into errors with permissions (that supposedly my user couldn&amp;#39;t do sudo commands), unrecognisable directories (even though I checked what the drive directory was in the drives), or badblocks command executing and returning &amp;#39;completed&amp;#39; result in seconds (on 8TB drive).&lt;/p&gt;\n\n&lt;p&gt;Because I was fed up with this, instead I performed what follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Quick SMART check using HDDScan app&lt;/li&gt;\n&lt;li&gt;h2testw test for entire drive (AFAIK this is windows-like equivalent of badblocks, it fills the drive with data and then verifies it) - that took like good 20 hours and came up clean&lt;/li&gt;\n&lt;li&gt;Extended SMART test using HDDScan - came up clean&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In the meantime I was checking the CrystalDisk info for SMART parameters, after everything I threw at it everything is OK, no reallocated sectors, no pending, no uncorrectable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can I assume that the drive is fine, or should I still perform badblocks, because the aforementioned tests may not be enough to detect a fault?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1az2y3m", "is_robot_indexable": true, "report_reasons": null, "author": "lightbringer0209", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1az2y3m/is_this_enough_testing_or_is_badblocks_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1az2y3m/is_this_enough_testing_or_is_badblocks_necessary/", "subreddit_subscribers": 734298, "created_utc": 1708802699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've heard many good reasons for using both and plan to switch from Duplicati to one of them (probably with Backblaze B2/GDrive combo). I have around 150GB worth of stuff and use Windows 11.\n\nI'm leaning towards Duplicacy for the UI, I'd also prefer to not have to mess with Task Scheduler/PowerShell scripts.", "author_fullname": "t2_1761ul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Duplicacy vs Restic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aysnon", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708775129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve heard many good reasons for using both and plan to switch from Duplicati to one of them (probably with Backblaze B2/GDrive combo). I have around 150GB worth of stuff and use Windows 11.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m leaning towards Duplicacy for the UI, I&amp;#39;d also prefer to not have to mess with Task Scheduler/PowerShell scripts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aysnon", "is_robot_indexable": true, "report_reasons": null, "author": "RazerMoon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1aysnon/duplicacy_vs_restic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1aysnon/duplicacy_vs_restic/", "subreddit_subscribers": 734298, "created_utc": 1708775129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have an Unraid server running 8 ironwolfs as I understand that is the limit due to vibration issues?...\n\nI'm thinking about upgrading soon, so considering enterprise grade disks.  Am I correct in assuming that as these are really for data centres, that the 8 disk limit is no longer an issue?\n\nI would like to be able to actually use the 18 bays I have at some point, lol.\n\n&amp;#x200B;\n\nCheers for any help\n\n&amp;#x200B;\n\nWill.", "author_fullname": "t2_nzlhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there is a limit on drives in an array while using Enterprise disks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayr9fi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708769827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an Unraid server running 8 ironwolfs as I understand that is the limit due to vibration issues?...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about upgrading soon, so considering enterprise grade disks.  Am I correct in assuming that as these are really for data centres, that the 8 disk limit is no longer an issue?&lt;/p&gt;\n\n&lt;p&gt;I would like to be able to actually use the 18 bays I have at some point, lol.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Cheers for any help&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Will.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayr9fi", "is_robot_indexable": true, "report_reasons": null, "author": "will1565", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayr9fi/is_there_is_a_limit_on_drives_in_an_array_while/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ayr9fi/is_there_is_a_limit_on_drives_in_an_array_while/", "subreddit_subscribers": 734298, "created_utc": 1708769827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nGreetings, I'm close to running out of space and need to invest in bigger storage pools. My current needs aren't too complex but may benefit from the use of a HDD enclosure (4 Bay). Below is my current setup and my draft solution that I'd appreciate critiquing - efficiency? Risk? Cost effectiveness? Recommendations? \n\n# Existing Setup # \n\nMac Mini (M1) 500GB Internal SSD\nExt HDD1 = WD 4TB \nExt HDD2 = WD 5TB\n\nInternal SSD contains the OS, apps and currently active files; docs, photos and videos. HDD1 stores archived files and source material for my Plex Server. HDD2 is a Time Machine Backup drive that creates snapshots of my internal SSD and HDD1. This has been my setup since 2018 without fault or fail. \n\n# Proposed Setup # \n\nMac Mini (M1) 500GB Internal SSD\nUSB HDD Enclosure (4 Bay) \nDisk 1 = 4TB\nDisk 2 = 4TB\nDisk 3 = 8TB\nDisk 4 = 16TB \nExternal HDD = 16TB \n\nMaintain current use of internal SSD. Disk 1 to store archived files. Disk 2 to store archived  freelance work (photos and videos). Disk 3 for Plex source material and Disk 4 for Time Machine backup of internal SSD and Disks 1-3. \n\nThe external HDD will manually backup Disk 4;  infrequently and stored away from home for safety and security. \n\nI never exceed more than 300GB of internal  disk use at a time and my Plex library of 10 years is 2.5TB at the moment. However, I'm looking to expand my Plex library following cancellations of all my streaming subs. \n\n\n\n\n\n\n\n", "author_fullname": "t2_ntry7zjfv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hoarding help for a new setup in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayo5ay", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708757506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings, I&amp;#39;m close to running out of space and need to invest in bigger storage pools. My current needs aren&amp;#39;t too complex but may benefit from the use of a HDD enclosure (4 Bay). Below is my current setup and my draft solution that I&amp;#39;d appreciate critiquing - efficiency? Risk? Cost effectiveness? Recommendations? &lt;/p&gt;\n\n&lt;h1&gt;Existing Setup #&lt;/h1&gt;\n\n&lt;p&gt;Mac Mini (M1) 500GB Internal SSD\nExt HDD1 = WD 4TB \nExt HDD2 = WD 5TB&lt;/p&gt;\n\n&lt;p&gt;Internal SSD contains the OS, apps and currently active files; docs, photos and videos. HDD1 stores archived files and source material for my Plex Server. HDD2 is a Time Machine Backup drive that creates snapshots of my internal SSD and HDD1. This has been my setup since 2018 without fault or fail. &lt;/p&gt;\n\n&lt;h1&gt;Proposed Setup #&lt;/h1&gt;\n\n&lt;p&gt;Mac Mini (M1) 500GB Internal SSD\nUSB HDD Enclosure (4 Bay) \nDisk 1 = 4TB\nDisk 2 = 4TB\nDisk 3 = 8TB\nDisk 4 = 16TB \nExternal HDD = 16TB &lt;/p&gt;\n\n&lt;p&gt;Maintain current use of internal SSD. Disk 1 to store archived files. Disk 2 to store archived  freelance work (photos and videos). Disk 3 for Plex source material and Disk 4 for Time Machine backup of internal SSD and Disks 1-3. &lt;/p&gt;\n\n&lt;p&gt;The external HDD will manually backup Disk 4;  infrequently and stored away from home for safety and security. &lt;/p&gt;\n\n&lt;p&gt;I never exceed more than 300GB of internal  disk use at a time and my Plex library of 10 years is 2.5TB at the moment. However, I&amp;#39;m looking to expand my Plex library following cancellations of all my streaming subs. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayo5ay", "is_robot_indexable": true, "report_reasons": null, "author": "DookuDonuts", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayo5ay/hoarding_help_for_a_new_setup_in_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ayo5ay/hoarding_help_for_a_new_setup_in_2024/", "subreddit_subscribers": 734298, "created_utc": 1708757506.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a windows tool that I can set up for specific folders I want to copy every time when I\u2019m doing a backup to a usb stick? Basically I want to make a usb drive with only my essential data, but I don\u2019t want to go and grab it from the various folders every time, because sometimes they may get updated. ", "author_fullname": "t2_t2xqj88b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows tool for usb copying specified folders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azamjv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708822090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a windows tool that I can set up for specific folders I want to copy every time when I\u2019m doing a backup to a usb stick? Basically I want to make a usb drive with only my essential data, but I don\u2019t want to go and grab it from the various folders every time, because sometimes they may get updated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1azamjv", "is_robot_indexable": true, "report_reasons": null, "author": "Signal_Inside3436", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1azamjv/windows_tool_for_usb_copying_specified_folders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1azamjv/windows_tool_for_usb_copying_specified_folders/", "subreddit_subscribers": 734298, "created_utc": 1708822090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am trying to convert my home VHS collection to DVD, but my Sansui VRDVD4005 is no longer able to read disks. I've had it for quite a while and it is not in bad condition by any means. Unfortunately, the literature on this device is not very extensive, and the error code I have received does not seem to apply (or at least I think). The error code it has spit out (at least once) is C-104 which seems to mean the disk is incompatible with the device. However, I have used this device before to convert my tapes. I do have a few disks from when I converted years back that can be read, but it does not want to take new disks at all. Is it possible it cannot take newer disks that record at a higher speed? All disks have been bought in the USA, so it shouldn't be a region issue. The manual states it can record on DVD-R ver 2.0 (4.7 GB). The disks I have used successfully in the past were 8x speed, but only some can be read while others cannot be. Same brand and everything. The disks I have been trying to use are 16x.\n\nI have tried swapping the DVD drive with a new model that was supposedly compatible with it and could write on disks that are capable of writing at a higher speed, but the disks are still not detected.\n\nAny other ideas on how to get this working again?", "author_fullname": "t2_p7alv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sansui VHS to DVD not detecting new disks, anyone have experience with this machine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1az7b50", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708813508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to convert my home VHS collection to DVD, but my Sansui VRDVD4005 is no longer able to read disks. I&amp;#39;ve had it for quite a while and it is not in bad condition by any means. Unfortunately, the literature on this device is not very extensive, and the error code I have received does not seem to apply (or at least I think). The error code it has spit out (at least once) is C-104 which seems to mean the disk is incompatible with the device. However, I have used this device before to convert my tapes. I do have a few disks from when I converted years back that can be read, but it does not want to take new disks at all. Is it possible it cannot take newer disks that record at a higher speed? All disks have been bought in the USA, so it shouldn&amp;#39;t be a region issue. The manual states it can record on DVD-R ver 2.0 (4.7 GB). The disks I have used successfully in the past were 8x speed, but only some can be read while others cannot be. Same brand and everything. The disks I have been trying to use are 16x.&lt;/p&gt;\n\n&lt;p&gt;I have tried swapping the DVD drive with a new model that was supposedly compatible with it and could write on disks that are capable of writing at a higher speed, but the disks are still not detected.&lt;/p&gt;\n\n&lt;p&gt;Any other ideas on how to get this working again?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1az7b50", "is_robot_indexable": true, "report_reasons": null, "author": "Exquisite_Poupon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1az7b50/sansui_vhs_to_dvd_not_detecting_new_disks_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1az7b50/sansui_vhs_to_dvd_not_detecting_new_disks_anyone/", "subreddit_subscribers": 734298, "created_utc": 1708813508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If in its original packaging, is it safe to do this?\n\n[View Poll](https://www.reddit.com/poll/1ayzimr)", "author_fullname": "t2_57pge7h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shipping a Qnap 4 bay with 4 x 6tb drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayzimr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708794333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If in its original packaging, is it safe to do this?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1ayzimr\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayzimr", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic_Bookkeeper", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1708967134013, "options": [{"text": "Yes", "id": "27202975"}, {"text": "No", "id": "27202976"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 44, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayzimr/shipping_a_qnap_4_bay_with_4_x_6tb_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/DataHoarder/comments/1ayzimr/shipping_a_qnap_4_bay_with_4_x_6tb_drives/", "subreddit_subscribers": 734298, "created_utc": 1708794333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know a way to export large WhatsApp Chats with all media and messages. I found a way on here but it is relying on a version of WhatsApp that is not available anymore. Is there a way?", "author_fullname": "t2_695got6a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workaround for Whatsapp 40.000 Messages restriction for exports?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayyurc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708792717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know a way to export large WhatsApp Chats with all media and messages. I found a way on here but it is relying on a version of WhatsApp that is not available anymore. Is there a way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayyurc", "is_robot_indexable": true, "report_reasons": null, "author": "XMRNeighbor", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayyurc/workaround_for_whatsapp_40000_messages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ayyurc/workaround_for_whatsapp_40000_messages/", "subreddit_subscribers": 734298, "created_utc": 1708792717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to migrate away from Google photos because of its one way \"sync\".   I'm looking now at One Drive, as there is a 2-way photo sync with your local photos.  \n\nI have over a hundred photo albums segregated by folder.  It would be great if such a service exists which would create online albums based on the local directory structure.  \n\nKnow of anything which may fit the bill here?", "author_fullname": "t2_l9eq6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A photo sharing site exists which auto creates albums based on folder structure or other metadata?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ayud16", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708780768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to migrate away from Google photos because of its one way &amp;quot;sync&amp;quot;.   I&amp;#39;m looking now at One Drive, as there is a 2-way photo sync with your local photos.  &lt;/p&gt;\n\n&lt;p&gt;I have over a hundred photo albums segregated by folder.  It would be great if such a service exists which would create online albums based on the local directory structure.  &lt;/p&gt;\n\n&lt;p&gt;Know of anything which may fit the bill here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ayud16", "is_robot_indexable": true, "report_reasons": null, "author": "floepie05", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ayud16/a_photo_sharing_site_exists_which_auto_creates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ayud16/a_photo_sharing_site_exists_which_auto_creates/", "subreddit_subscribers": 734298, "created_utc": 1708780768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an old modified mac G5 case for my media server. I need to be able to mount 6 and preferably 8 drives inside it, and could be mounted with rubber grommets and in trays, as some of the Fractal cases have. There is space for it on the left side of the motherboard, but the drives have to be mounted on top of each other. The ones I can find do not decouple the drives mechanically.  \nIt could also be a 5 1/4 cage with 4 bays or something, and then I can mount the drives floating with elastic cord, to decouple them from the case.  \nI cannot find any suitable, but perhaps someone here know of something? What do you do?", "author_fullname": "t2_fmihmn3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HD cage/trays for 6-8 3.5 drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aytzpm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708779662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an old modified mac G5 case for my media server. I need to be able to mount 6 and preferably 8 drives inside it, and could be mounted with rubber grommets and in trays, as some of the Fractal cases have. There is space for it on the left side of the motherboard, but the drives have to be mounted on top of each other. The ones I can find do not decouple the drives mechanically.&lt;br/&gt;\nIt could also be a 5 1/4 cage with 4 bays or something, and then I can mount the drives floating with elastic cord, to decouple them from the case.&lt;br/&gt;\nI cannot find any suitable, but perhaps someone here know of something? What do you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aytzpm", "is_robot_indexable": true, "report_reasons": null, "author": "Schroinx", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1aytzpm/hd_cagetrays_for_68_35_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1aytzpm/hd_cagetrays_for_68_35_drives/", "subreddit_subscribers": 734298, "created_utc": 1708779662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i got 500gb in clips from games and dont want to delete them, so i was thinking to just buy a ssd or usb to transfer them all into.\n\nim looking for something under like 30-40$ thats reliable and wont break lol", "author_fullname": "t2_7lwvjl79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what are some good and cheap 1tb external drives or usb sticks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azeuer", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708834692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i got 500gb in clips from games and dont want to delete them, so i was thinking to just buy a ssd or usb to transfer them all into.&lt;/p&gt;\n\n&lt;p&gt;im looking for something under like 30-40$ thats reliable and wont break lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1azeuer", "is_robot_indexable": true, "report_reasons": null, "author": "flipflip2378562", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1azeuer/what_are_some_good_and_cheap_1tb_external_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1azeuer/what_are_some_good_and_cheap_1tb_external_drives/", "subreddit_subscribers": 734298, "created_utc": 1708834692.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}