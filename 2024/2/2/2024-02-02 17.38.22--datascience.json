{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_rsyojso5r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I built an app to do my data science work faster, and I thought others here may like it too!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "media_metadata": {"j2m2vqrh81gc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/j2m2vqrh81gc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=d1c062832b8debdc1bb30f383fa5f2ee0c2a5bec"}, {"y": 124, "x": 216, "u": "https://preview.redd.it/j2m2vqrh81gc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=750303ceee0624b9edbcc902e34bc6ad2f95a535"}, {"y": 184, "x": 320, "u": "https://preview.redd.it/j2m2vqrh81gc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=e1dd29188b1e997421de8df2ee818daae6407662"}, {"y": 369, "x": 640, "u": "https://preview.redd.it/j2m2vqrh81gc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=8486f02868b67a76518acd5439ea9fc84c401d08"}, {"y": 553, "x": 960, "u": "https://preview.redd.it/j2m2vqrh81gc1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=78a7e41b2ad504aaa05e5923386c39959591565e"}, {"y": 623, "x": 1080, "u": "https://preview.redd.it/j2m2vqrh81gc1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=57bb4cf82080e8357102f182e64e4a8720963e25"}], "s": {"y": 1080, "gif": "https://i.redd.it/j2m2vqrh81gc1.gif", "mp4": "https://preview.redd.it/j2m2vqrh81gc1.gif?format=mp4&amp;s=551d334e83962e54d929990bd9532bd6d85550a3", "x": 1872}, "id": "j2m2vqrh81gc1"}, "jmh961ge81gc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/jmh961ge81gc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=6fdd02337de3f25b08d4e0389703c6264f30877d"}, {"y": 124, "x": 216, "u": "https://preview.redd.it/jmh961ge81gc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=7dfb91aec06c805bd31efd2c7b4e5e9b510f328a"}, {"y": 184, "x": 320, "u": "https://preview.redd.it/jmh961ge81gc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=9cc76d0e1eb4fea14bf5426787f421199b6894dc"}, {"y": 369, "x": 640, "u": "https://preview.redd.it/jmh961ge81gc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=0718ef12068bf6acc71513dff439fc3f8c5ea822"}, {"y": 553, "x": 960, "u": "https://preview.redd.it/jmh961ge81gc1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=6a17fa28a5b68894ae36b253c9ac6f993b12eadd"}, {"y": 623, "x": 1080, "u": "https://preview.redd.it/jmh961ge81gc1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=78d1978ee7bd7b4e9d025e978a71c7837c22a960"}], "s": {"y": 1080, "gif": "https://i.redd.it/jmh961ge81gc1.gif", "mp4": "https://preview.redd.it/jmh961ge81gc1.gif?format=mp4&amp;s=945adbd4e5e2ff4284deda74ecd02d816cfc54aa", "x": 1872}, "id": "jmh961ge81gc1"}, "1zivd85a81gc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/1zivd85a81gc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=900d03f1cd085811db4c1a9316ddbcc6287b874f"}, {"y": 124, "x": 216, "u": "https://preview.redd.it/1zivd85a81gc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=88853315c98d55373fd85f145d4f6d9e1039e449"}, {"y": 184, "x": 320, "u": "https://preview.redd.it/1zivd85a81gc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=a0b23b9040a660397a531498608dab2d8ed43822"}, {"y": 369, "x": 640, "u": "https://preview.redd.it/1zivd85a81gc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=d55f1f276ffa752ea2c811f51c7a8b47c8c3604b"}, {"y": 553, "x": 960, "u": "https://preview.redd.it/1zivd85a81gc1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=8c7fbda89089bac8e768282f78401a057af3bb0e"}, {"y": 623, "x": 1080, "u": "https://preview.redd.it/1zivd85a81gc1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=6f60b04da021a9f1143c3dbb827a3210c8d3dfc7"}], "s": {"y": 1080, "gif": "https://i.redd.it/1zivd85a81gc1.gif", "mp4": "https://preview.redd.it/1zivd85a81gc1.gif?format=mp4&amp;s=5927bcf5d6f4ded67e40c47370c6432a5faaa99f", "x": 1872}, "id": "1zivd85a81gc1"}}, "name": "t3_1agknrn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 196, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "I can generate new visualizations in seconds, without spending time in documentation for visualization libraries like Plotly.", "outbound_url": "https://noterous.com", "media_id": "1zivd85a81gc1", "id": 398669718}, {"caption": "I can select code cells and edit them automatically, fully inline without needing to copy and paste anywhere.", "media_id": "jmh961ge81gc1", "id": 398669719}, {"caption": "I can recover from any error in seconds!", "media_id": "j2m2vqrh81gc1", "id": 398669720}]}, "link_flair_text": "Tools", "can_mod_post": false, "score": 196, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/fa9WeQZVgw9GAuMarp2scKzAGsB4Q_YozdhoS12ljY8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706819098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1agknrn", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1agknrn", "is_robot_indexable": true, "report_reasons": null, "author": "samwisesami", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1agknrn/i_built_an_app_to_do_my_data_science_work_faster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://noterous.com", "subreddit_subscribers": 1299489, "created_utc": 1706819098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There seems to be a big misunderstanding of the t test amongst people on this sub regarding and when/how the test can be used.\n\n* First, unless you're working with binary data (or other data in which the variance is a function of the mean) you never want a z test.  This has nothing to do with the distribution of the data and everything to do with uncertainty introduced by estimating the standard deviation for use in the standard error.\n* Second, your population distribution does not need to be normal to use a t test.  Nothing is normal in practice and I'd go so far as to say all distributions are just convenient fictions, so this point that you need normality is a non-sequitur anyway.\n* What you need in order to derive the t test is the ratio of two independent random variables: a gaussian random variable divided by the square root of a chi-square random variable divided by its degrees of freedom.  When the population distribution is normal then these are automatically satisfied. As sample sizes grow big, the central limit theorem will plausibly provide the guassianity for the numerator (assuming your population distribution has finite variance).  Also, in large samples the sampling distribution for the sample variance is chi square, so that takes care of the denominator of the test statistic.  The independence between these two is typically the thing that fails (long tails drag out the mean _and_ the variance, so when you get a big sample mean you're more than likely also going to have a big sample variance).\n\n* When you don't have normal data, the question becomes how defensible are the assumptions regarding the sampling distributions of the mean and variance.  There is no \"right\" answer -- there is a \"right for you\" answer.\n\n\nNow for my opinions on the matter of the use of a t test in AB tests (these are certainly up for debate):\n\n* The t-test is more useful than you think.  \n\n* The only cases where I would not use a t test is when the population distribution plausibly has infinite variance (because then the CLT doesn't apply).\n\n* Your goal should not be to answer \"is there a difference\" but rather \"what was the difference\" -- that's slightly different.  To that point, non-parametric tests like MWU/KS/KW don't provide estimates of the average treatment effect.", "author_fullname": "t2_131vu3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There seems to be a big misunderstanding of the T Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1agnjxs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": "", "subreddit_type": "public", "ups": 90, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Statistics", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706880353.0, "author_flair_css_class": "modflair", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706826395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There seems to be a big misunderstanding of the t test amongst people on this sub regarding and when/how the test can be used.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;First, unless you&amp;#39;re working with binary data (or other data in which the variance is a function of the mean) you never want a z test.  This has nothing to do with the distribution of the data and everything to do with uncertainty introduced by estimating the standard deviation for use in the standard error.&lt;/li&gt;\n&lt;li&gt;Second, your population distribution does not need to be normal to use a t test.  Nothing is normal in practice and I&amp;#39;d go so far as to say all distributions are just convenient fictions, so this point that you need normality is a non-sequitur anyway.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What you need in order to derive the t test is the ratio of two independent random variables: a gaussian random variable divided by the square root of a chi-square random variable divided by its degrees of freedom.  When the population distribution is normal then these are automatically satisfied. As sample sizes grow big, the central limit theorem will plausibly provide the guassianity for the numerator (assuming your population distribution has finite variance).  Also, in large samples the sampling distribution for the sample variance is chi square, so that takes care of the denominator of the test statistic.  The independence between these two is typically the thing that fails (long tails drag out the mean &lt;em&gt;and&lt;/em&gt; the variance, so when you get a big sample mean you&amp;#39;re more than likely also going to have a big sample variance).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;When you don&amp;#39;t have normal data, the question becomes how defensible are the assumptions regarding the sampling distributions of the mean and variance.  There is no &amp;quot;right&amp;quot; answer -- there is a &amp;quot;right for you&amp;quot; answer.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now for my opinions on the matter of the use of a t test in AB tests (these are certainly up for debate):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;The t-test is more useful than you think.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The only cases where I would not use a t test is when the population distribution plausibly has infinite variance (because then the CLT doesn&amp;#39;t apply).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Your goal should not be to answer &amp;quot;is there a difference&amp;quot; but rather &amp;quot;what was the difference&amp;quot; -- that&amp;#39;s slightly different.  To that point, non-parametric tests like MWU/KS/KW don&amp;#39;t provide estimates of the average treatment effect.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "370e8fc0-70eb-11ee-b58a-86a96bfd3389", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#94e044", "id": "1agnjxs", "is_robot_indexable": true, "report_reasons": null, "author": "__compactsupport__", "discussion_type": null, "num_comments": 82, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/1agnjxs/there_seems_to_be_a_big_misunderstanding_of_the_t/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1agnjxs/there_seems_to_be_a_big_misunderstanding_of_the_t/", "subreddit_subscribers": 1299489, "created_utc": 1706826395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I used to believe that the work of a data scientist is from getting the data to creating models. But if solely web scraping, is that a job for data scientist or are there any discipline to better do that job?", "author_fullname": "t2_ftzx68gnj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Webscraping a work of a data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1agv0xn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706847569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to believe that the work of a data scientist is from getting the data to creating models. But if solely web scraping, is that a job for data scientist or are there any discipline to better do that job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1agv0xn", "is_robot_indexable": true, "report_reasons": null, "author": "medyosuper", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1agv0xn/is_webscraping_a_work_of_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1agv0xn/is_webscraping_a_work_of_a_data_scientist/", "subreddit_subscribers": 1299489, "created_utc": 1706847569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been getting hit by recruiters from there quite frequently. I\u2019m attracted by it being a remote role, but data science can be mature or immature based on the team/area. And I heard of DS layoffs going on.", "author_fullname": "t2_6lukipdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is data science like at Home Depot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aglh3p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706821144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been getting hit by recruiters from there quite frequently. I\u2019m attracted by it being a remote role, but data science can be mature or immature based on the team/area. And I heard of DS layoffs going on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aglh3p", "is_robot_indexable": true, "report_reasons": null, "author": "Much-Focus-1408", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aglh3p/what_is_data_science_like_at_home_depot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aglh3p/what_is_data_science_like_at_home_depot/", "subreddit_subscribers": 1299489, "created_utc": 1706821144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a F50 company. It\u2019s been 2 years (tenure also 2) since I got any raise, even I though my performance reviews have went really well on top my regular great feedback throughout the year. Company says they have less budget this year etc etc. I know there are other people on my team who have not gotten any raise just like me. \n\nIs it likely that if layoffs happen, I will be on the top of the list?", "author_fullname": "t2_bv171ji2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managers of this sub, does no pay raise mean I will be the first one to get laid off if it comes to that?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aghdwc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706810926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a F50 company. It\u2019s been 2 years (tenure also 2) since I got any raise, even I though my performance reviews have went really well on top my regular great feedback throughout the year. Company says they have less budget this year etc etc. I know there are other people on my team who have not gotten any raise just like me. &lt;/p&gt;\n\n&lt;p&gt;Is it likely that if layoffs happen, I will be on the top of the list?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aghdwc", "is_robot_indexable": true, "report_reasons": null, "author": "quite--average", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aghdwc/managers_of_this_sub_does_no_pay_raise_mean_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aghdwc/managers_of_this_sub_does_no_pay_raise_mean_i/", "subreddit_subscribers": 1299489, "created_utc": 1706810926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My question is - can my BI data analyst experience stand as a negative thing in my CV when I go looking for a machine learning related data science job?\n\nI studied physics, did physics in Research and development of a tech/med company (2 years), switched to being a data analyst in BI (6 months) as I could not find a data scientist job in my city. When I got to BI data analyst role, I tried to find interesting work as some of my colleagues only work on \"ad-hoc\" tasks (I think they are quite repetitive, like repeatedly evaluating AB tests). Luckily I got tasks related to interesting things - development of our A/B testing framework which is statistics, sequential tests etc. I asked for statistical tasks to take on a challenge that would move me forward.\n\nMy goal is to find a data scientist role related to machine learning after my DA experience. I did a couple home hobby projects too - the biggest are a game recommendation system from Steam games that I scraped, and a yeast object detector that I trained and integrated into a desktop app (just a prototype though). I realize there is a lot I don't know, but I think I learn rather quickly, math is no problem after I refresh it and I am constantly working on some DS home projects.\n\nWill having a BI data analyst experience make people fit me in the \"DA\" box even though I would like to jump to the \"DS\" box? Because I find people often look down at BI people. I understand that but I try to avoid repetitive tasks and get good at stats instead.", "author_fullname": "t2_a63skydx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can data analyst experience be viewed as a negative?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1agq28z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706832850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My question is - can my BI data analyst experience stand as a negative thing in my CV when I go looking for a machine learning related data science job?&lt;/p&gt;\n\n&lt;p&gt;I studied physics, did physics in Research and development of a tech/med company (2 years), switched to being a data analyst in BI (6 months) as I could not find a data scientist job in my city. When I got to BI data analyst role, I tried to find interesting work as some of my colleagues only work on &amp;quot;ad-hoc&amp;quot; tasks (I think they are quite repetitive, like repeatedly evaluating AB tests). Luckily I got tasks related to interesting things - development of our A/B testing framework which is statistics, sequential tests etc. I asked for statistical tasks to take on a challenge that would move me forward.&lt;/p&gt;\n\n&lt;p&gt;My goal is to find a data scientist role related to machine learning after my DA experience. I did a couple home hobby projects too - the biggest are a game recommendation system from Steam games that I scraped, and a yeast object detector that I trained and integrated into a desktop app (just a prototype though). I realize there is a lot I don&amp;#39;t know, but I think I learn rather quickly, math is no problem after I refresh it and I am constantly working on some DS home projects.&lt;/p&gt;\n\n&lt;p&gt;Will having a BI data analyst experience make people fit me in the &amp;quot;DA&amp;quot; box even though I would like to jump to the &amp;quot;DS&amp;quot; box? Because I find people often look down at BI people. I understand that but I try to avoid repetitive tasks and get good at stats instead.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1agq28z", "is_robot_indexable": true, "report_reasons": null, "author": "sushi_roll_svk", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1agq28z/can_data_analyst_experience_be_viewed_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1agq28z/can_data_analyst_experience_be_viewed_as_a/", "subreddit_subscribers": 1299489, "created_utc": 1706832850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Machine Learning is an important tool in DS. \n\nTrying to learn it better, I came across **PyTorch** and it\u2019s **Autograd Engine**, which computes the backpropagation automatically. \n\nIn [this project](https://github.com/eduardoleao052/Autograd-from-scratch.git), I tried to **reimplement most of PyTorch** (including the Autograd) from scratch in a **well-documented, unit tested, and interpretable** way. This is my first package, so feel free to use it, and to give feedback if possible! \n\nI hope it can help others understand Autograd better as well.\n\nGitHub repository [here](https://github.com/eduardoleao052/Autograd-from-scratch.git)!", "author_fullname": "t2_jxw66snkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Educational Deep Learning from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1agmq0c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706890959.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706824309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Machine Learning is an important tool in DS. &lt;/p&gt;\n\n&lt;p&gt;Trying to learn it better, I came across &lt;strong&gt;PyTorch&lt;/strong&gt; and it\u2019s &lt;strong&gt;Autograd Engine&lt;/strong&gt;, which computes the backpropagation automatically. &lt;/p&gt;\n\n&lt;p&gt;In &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;this project&lt;/a&gt;, I tried to &lt;strong&gt;reimplement most of PyTorch&lt;/strong&gt; (including the Autograd) from scratch in a &lt;strong&gt;well-documented, unit tested, and interpretable&lt;/strong&gt; way. This is my first package, so feel free to use it, and to give feedback if possible! &lt;/p&gt;\n\n&lt;p&gt;I hope it can help others understand Autograd better as well.&lt;/p&gt;\n\n&lt;p&gt;GitHub repository &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;here&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/km2vj8XU-rakOQ6C1wnNRZWfp-j7gkRejngfxceSVtU.jpg?auto=webp&amp;s=daaa2b455daf213bc7204c2c3385403e5462afc6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/km2vj8XU-rakOQ6C1wnNRZWfp-j7gkRejngfxceSVtU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b09889e0f7100bb9dbb4d64dbff4c00a7a4d5323", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/km2vj8XU-rakOQ6C1wnNRZWfp-j7gkRejngfxceSVtU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ab59dc7ebbfe482470b24f64b3e6255626c59db", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/km2vj8XU-rakOQ6C1wnNRZWfp-j7gkRejngfxceSVtU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e40c2fa54ee5a5cb9f669d0a232d931a0b77dc9e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/km2vj8XU-rakOQ6C1wnNRZWfp-j7gkRejngfxceSVtU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=651130edec393df92e8c621380753600ff94afed", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/km2vj8XU-rakOQ6C1wnNRZWfp-j7gkRejngfxceSVtU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c478769674071f8402655da9c5ce8c7eb7000eb4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/km2vj8XU-rakOQ6C1wnNRZWfp-j7gkRejngfxceSVtU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3e890250b5f6c60ffaa75a56e08980bc2051e039", "width": 1080, "height": 540}], "variants": {}, "id": "Xm7AVMMkRJHf81giRrsMNKnf5iEbMuf-GHYbOPrvaAc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1agmq0c", "is_robot_indexable": true, "report_reasons": null, "author": "suspicious_beam", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1agmq0c/educational_deep_learning_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1agmq0c/educational_deep_learning_from_scratch/", "subreddit_subscribers": 1299489, "created_utc": 1706824309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For example:\n\nImagine an eCommerce funnel that constitutes a configuration page, a bag page, a shipping page, a payment page and finally an order confirmation page.\n\nYou plan on running an A/B test in the product configuration page (example: 2 different messaging + control for selecting a financing option in the configuration page). Business wants to measure the impact of this test on downstream KPI: In this case it\u2019s the conversion rate (how many people land on order confirmation page).\n\nHow would you approach this problem? or, are there resources that provide examples of tests that happen upstream and you wish to measure downstream impact. My manager shared that ANCOVA can be used to handle uncontrolled factors (such as drop off points in the funnel). But I cannot find appropriate examples within the field of eCommerce on how one would approach this.\n\nAny help would be appreciated!", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good resources on how to run a multivariate test (A/B test) where the IV is upstream but DV is downstream in a eCommerce funnel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1agzj8s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706864904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;p&gt;Imagine an eCommerce funnel that constitutes a configuration page, a bag page, a shipping page, a payment page and finally an order confirmation page.&lt;/p&gt;\n\n&lt;p&gt;You plan on running an A/B test in the product configuration page (example: 2 different messaging + control for selecting a financing option in the configuration page). Business wants to measure the impact of this test on downstream KPI: In this case it\u2019s the conversion rate (how many people land on order confirmation page).&lt;/p&gt;\n\n&lt;p&gt;How would you approach this problem? or, are there resources that provide examples of tests that happen upstream and you wish to measure downstream impact. My manager shared that ANCOVA can be used to handle uncontrolled factors (such as drop off points in the funnel). But I cannot find appropriate examples within the field of eCommerce on how one would approach this.&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1agzj8s", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1agzj8s/any_good_resources_on_how_to_run_a_multivariate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1agzj8s/any_good_resources_on_how_to_run_a_multivariate/", "subreddit_subscribers": 1299489, "created_utc": 1706864904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was thinking that it wasn\u2019t ok to put credentials on the dockerfile, since I\u2019m planning to deploy it. Talking with chatgpt it recommended to use some password manager, which needed to add my password to this password manager within the dockerfile. Yes, chatgpt is not going to take us all haha So what\u2019s the right way to deal with this?\n\nOf course I know some use .yml or .env, but the application would require to have access to these files anyway, so they are also a vulnerability itself.", "author_fullname": "t2_t4026fbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with credentials in dockerfiles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1agqtyt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706834981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking that it wasn\u2019t ok to put credentials on the dockerfile, since I\u2019m planning to deploy it. Talking with chatgpt it recommended to use some password manager, which needed to add my password to this password manager within the dockerfile. Yes, chatgpt is not going to take us all haha So what\u2019s the right way to deal with this?&lt;/p&gt;\n\n&lt;p&gt;Of course I know some use .yml or .env, but the application would require to have access to these files anyway, so they are also a vulnerability itself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1agqtyt", "is_robot_indexable": true, "report_reasons": null, "author": "chris_813", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1agqtyt/how_to_deal_with_credentials_in_dockerfiles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1agqtyt/how_to_deal_with_credentials_in_dockerfiles/", "subreddit_subscribers": 1299489, "created_utc": 1706834981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I work at non-tech firm, hired as a data analyst. Most of the tools that came with the job are okay for most of the routine tasks. (Things like excel, cognos, a couple in-house tools, etc)\n\nHowever, my IT department said it\u2019s not really doable to push any open-source technologies to my device, especially if the order doesn\u2019t come straight from HQ. So I\u2019m unable to download anything from python to Jupyter notebooks, let alone anything that is necessary to run complex models on my device.\n\nHowever, my supervisor is perfectly okay with me running analyses on my personal laptop, if I just, like, send the file over to myself on that device, and then do it on days I work from home. \n\nIs this normal, or at least somewhat not too uncommon? I virtually never deal with any private data, and if/when I do I always anonymize it first. For the record we\u2019re a wholesale fashion company so the most \u201cconfidential\u201d data is addresses of stores like macy\u2019s or target lol.", "author_fullname": "t2_16cclgpl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it uncommon to do run data science projects on my personal laptop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ah85da", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706892463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I work at non-tech firm, hired as a data analyst. Most of the tools that came with the job are okay for most of the routine tasks. (Things like excel, cognos, a couple in-house tools, etc)&lt;/p&gt;\n\n&lt;p&gt;However, my IT department said it\u2019s not really doable to push any open-source technologies to my device, especially if the order doesn\u2019t come straight from HQ. So I\u2019m unable to download anything from python to Jupyter notebooks, let alone anything that is necessary to run complex models on my device.&lt;/p&gt;\n\n&lt;p&gt;However, my supervisor is perfectly okay with me running analyses on my personal laptop, if I just, like, send the file over to myself on that device, and then do it on days I work from home. &lt;/p&gt;\n\n&lt;p&gt;Is this normal, or at least somewhat not too uncommon? I virtually never deal with any private data, and if/when I do I always anonymize it first. For the record we\u2019re a wholesale fashion company so the most \u201cconfidential\u201d data is addresses of stores like macy\u2019s or target lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ah85da", "is_robot_indexable": true, "report_reasons": null, "author": "OutrageousPressure6", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ah85da/is_it_uncommon_to_do_run_data_science_projects_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ah85da/is_it_uncommon_to_do_run_data_science_projects_on/", "subreddit_subscribers": 1299489, "created_utc": 1706892463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I am trying to get back into the healthcare space after losing my job due to lack of funding. I worked on clinical data projects, which were more intuitive for me than medical claims. I have a few datasets (medicare enrollment, drug spending rate, and drugs purchased) from the [Medicare/Medicaid website](https://data.cms.gov/) and have no idea what business questions to ask and answer.\n\nCould anyone provide guidance or a starting point? My brain is kind of burned out from job hunting.", "author_fullname": "t2_odncb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you analyze healthcare claims data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ah86x7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706892570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am trying to get back into the healthcare space after losing my job due to lack of funding. I worked on clinical data projects, which were more intuitive for me than medical claims. I have a few datasets (medicare enrollment, drug spending rate, and drugs purchased) from the &lt;a href=\"https://data.cms.gov/\"&gt;Medicare/Medicaid website&lt;/a&gt; and have no idea what business questions to ask and answer.&lt;/p&gt;\n\n&lt;p&gt;Could anyone provide guidance or a starting point? My brain is kind of burned out from job hunting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1ah86x7", "is_robot_indexable": true, "report_reasons": null, "author": "mathymate", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ah86x7/how_do_you_analyze_healthcare_claims_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ah86x7/how_do_you_analyze_healthcare_claims_data/", "subreddit_subscribers": 1299489, "created_utc": 1706892570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, data friends. It is my turn to ask for help, I think.\n\nI work developing end-to-end projects for the supply chain department of an industry. I'll spare details to try to stay incognito. Right now I'm in charge of developing a three-fold project: Risk analysis, risk management and strategies to apply it. I have almost the entire year to do this, so plenty of time.\n\nMy problem is that the data are not enough to start a good analysis and also they are very sensible so, for sure, I will not find anything related from any other company. \n\nI know that I didn't give much details, but how to proceed when having poor data to do risk analysis?! Poor in the sense that the information is scarce and the sensible data part to search for anything similar. ", "author_fullname": "t2_hmlahc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do when you have poor data and probably no other way to get better data? (Specifics in comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1agi8tm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706813088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, data friends. It is my turn to ask for help, I think.&lt;/p&gt;\n\n&lt;p&gt;I work developing end-to-end projects for the supply chain department of an industry. I&amp;#39;ll spare details to try to stay incognito. Right now I&amp;#39;m in charge of developing a three-fold project: Risk analysis, risk management and strategies to apply it. I have almost the entire year to do this, so plenty of time.&lt;/p&gt;\n\n&lt;p&gt;My problem is that the data are not enough to start a good analysis and also they are very sensible so, for sure, I will not find anything related from any other company. &lt;/p&gt;\n\n&lt;p&gt;I know that I didn&amp;#39;t give much details, but how to proceed when having poor data to do risk analysis?! Poor in the sense that the information is scarce and the sensible data part to search for anything similar. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1agi8tm", "is_robot_indexable": true, "report_reasons": null, "author": "magikarpa1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1agi8tm/what_to_do_when_you_have_poor_data_and_probably/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1agi8tm/what_to_do_when_you_have_poor_data_and_probably/", "subreddit_subscribers": 1299489, "created_utc": 1706813088.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}