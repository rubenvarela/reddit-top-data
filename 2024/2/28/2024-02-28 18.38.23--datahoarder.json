{"kind": "Listing", "data": {"after": "t3_1b1o6fb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Time to clone the entire Git code repo ASAP. I\u2019m guessing it will be taken down in the next 24 hrs.", "author_fullname": "t2_re8xa8nuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FYI Nintendo is suing the makers of the Switch emulator Yuzu", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b29x7c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709137051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Time to clone the entire Git code repo ASAP. I\u2019m guessing it will be taken down in the next 24 hrs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b29x7c", "is_robot_indexable": true, "report_reasons": null, "author": "ketracellular", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b29x7c/fyi_nintendo_is_suing_the_makers_of_the_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b29x7c/fyi_nintendo_is_suing_the_makers_of_the_switch/", "subreddit_subscribers": 735084, "created_utc": 1709137051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_h6kxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive support is being discontinued in StableBit CloudDrive [check 1.2.6.1700]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1pugk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1709074615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "covecube.download", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://covecube.download/CloudDriveWindows/beta/download/changes.txt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "400TB raw", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1pugk", "is_robot_indexable": true, "report_reasons": null, "author": "It_Is1-24PM", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b1pugk/google_drive_support_is_being_discontinued_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://covecube.download/CloudDriveWindows/beta/download/changes.txt", "subreddit_subscribers": 735084, "created_utc": 1709074615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Google drive, mega, and Dropbox constantly ban public NSFW folders. I want to share a link to a collection of my favorite videos for anyone to find. I was originally going to use terabox, but the share tab says \u201cpornographic, violent, or otherwise objectionable content may not be shared.\u201d\n\nAre there any cloud storage sites that won\u2019t take down my files if I make them public and share them?", "author_fullname": "t2_rhek29v6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any cloud storage sites that allow public sharing of adult content?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1uoa3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709087428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Google drive, mega, and Dropbox constantly ban public NSFW folders. I want to share a link to a collection of my favorite videos for anyone to find. I was originally going to use terabox, but the share tab says \u201cpornographic, violent, or otherwise objectionable content may not be shared.\u201d&lt;/p&gt;\n\n&lt;p&gt;Are there any cloud storage sites that won\u2019t take down my files if I make them public and share them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1uoa3", "is_robot_indexable": true, "report_reasons": null, "author": "Classic_Plankton6293", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1uoa3/are_there_any_cloud_storage_sites_that_allow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1uoa3/are_there_any_cloud_storage_sites_that_allow/", "subreddit_subscribers": 735084, "created_utc": 1709087428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I use [allinonedownloader.com](https://allinonedownloader.com), it's actually pretty great in HD etc but when you tried to DL an old Tiktok usually it doesnt work / can't DL the preview too.  Do you have a recommandations of a website where you DL in full quality the tiktok ? (Maybe the Website itself when you right click and you can DL it) ? Thank you ! ", "author_fullname": "t2_3iixwuk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Tiktok downloader websites in HD online ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1soqr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709081957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I use &lt;a href=\"https://allinonedownloader.com\"&gt;allinonedownloader.com&lt;/a&gt;, it&amp;#39;s actually pretty great in HD etc but when you tried to DL an old Tiktok usually it doesnt work / can&amp;#39;t DL the preview too.  Do you have a recommandations of a website where you DL in full quality the tiktok ? (Maybe the Website itself when you right click and you can DL it) ? Thank you ! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1soqr", "is_robot_indexable": true, "report_reasons": null, "author": "NoMota", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1soqr/best_tiktok_downloader_websites_in_hd_online/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1soqr/best_tiktok_downloader_websites_in_hd_online/", "subreddit_subscribers": 735084, "created_utc": 1709081957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two basic needs: making sure there's at least two copies of any piece of data over around a dozen drives of varying sizes, and parity checking to make sure the data stays good. Is there a single piece of software that can handle that for me?", "author_fullname": "t2_aegeoo1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best software for managing a passel of drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2bera", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709140460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two basic needs: making sure there&amp;#39;s at least two copies of any piece of data over around a dozen drives of varying sizes, and parity checking to make sure the data stays good. Is there a single piece of software that can handle that for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2bera", "is_robot_indexable": true, "report_reasons": null, "author": "Causification", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2bera/best_software_for_managing_a_passel_of_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2bera/best_software_for_managing_a_passel_of_drives/", "subreddit_subscribers": 735084, "created_utc": 1709140460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a mix of internal and external SSDs plus a hard drive. Is it possible to pool them together but still have control over what type of data is stored on each type of drive?", "author_fullname": "t2_cxtr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Drivepool advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b28h8c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709133525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a mix of internal and external SSDs plus a hard drive. Is it possible to pool them together but still have control over what type of data is stored on each type of drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b28h8c", "is_robot_indexable": true, "report_reasons": null, "author": "zuldar", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b28h8c/need_drivepool_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b28h8c/need_drivepool_advice/", "subreddit_subscribers": 735084, "created_utc": 1709133525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 200GB of online storage that my phone automatically backs up to. I'm currently sitting at 90% usage that is mostly photos, and I really don't want to pay for more storage so I'm interested in transcoding all my photos. \n\nI would love to transcode everything to jpegXL, but it's nowhere near being supported by everything yet.  It's 2024, what is the most advanced image coded that currently has wide support? ", "author_fullname": "t2_4ut4u7gi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "transcoding images to save space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b28dsl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709133284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 200GB of online storage that my phone automatically backs up to. I&amp;#39;m currently sitting at 90% usage that is mostly photos, and I really don&amp;#39;t want to pay for more storage so I&amp;#39;m interested in transcoding all my photos. &lt;/p&gt;\n\n&lt;p&gt;I would love to transcode everything to jpegXL, but it&amp;#39;s nowhere near being supported by everything yet.  It&amp;#39;s 2024, what is the most advanced image coded that currently has wide support? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b28dsl", "is_robot_indexable": true, "report_reasons": null, "author": "uname_IsAlreadyTaken", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b28dsl/transcoding_images_to_save_space/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b28dsl/transcoding_images_to_save_space/", "subreddit_subscribers": 735084, "created_utc": 1709133284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I always leave the computer well alone when migrating o.s to a new drive, but I am very interested in whether you can run a game or something.  I wouldn't be surprised if this were possible under linux partitions, sounds like something ntfs wouldn't be capable of.", "author_fullname": "t2_ubnt8yve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you clone your o.s drive while in use, and if so, how are the changes made on that drive protected from being modified while read?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b275ax", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709129996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I always leave the computer well alone when migrating o.s to a new drive, but I am very interested in whether you can run a game or something.  I wouldn&amp;#39;t be surprised if this were possible under linux partitions, sounds like something ntfs wouldn&amp;#39;t be capable of.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b275ax", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Introduction5124", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b275ax/can_you_clone_your_os_drive_while_in_use_and_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b275ax/can_you_clone_your_os_drive_while_in_use_and_if/", "subreddit_subscribers": 735084, "created_utc": 1709129996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to turn my mini pc with Debian into a storage server by (buying and) connecting this unit but need to be able to pull smart values, trim ssds and suspend spinning disks. A lot of usb disk docks don't support these operations. I have no idea how compatible tr-004's controller is. I would set the dip switches to individual disk mode.\n\nCan anyone with this unit or the TR-002 tell me if this is possible?", "author_fullname": "t2_xk53e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Qnap TR-004 expansion unit - can I execute fstrim, smartctl, suspend individual drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1zc7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709102123.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709101939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to turn my mini pc with Debian into a storage server by (buying and) connecting this unit but need to be able to pull smart values, trim ssds and suspend spinning disks. A lot of usb disk docks don&amp;#39;t support these operations. I have no idea how compatible tr-004&amp;#39;s controller is. I would set the dip switches to individual disk mode.&lt;/p&gt;\n\n&lt;p&gt;Can anyone with this unit or the TR-002 tell me if this is possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "always 90% full", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1zc7d", "is_robot_indexable": true, "report_reasons": null, "author": "umataro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b1zc7d/qnap_tr004_expansion_unit_can_i_execute_fstrim/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1zc7d/qnap_tr004_expansion_unit_can_i_execute_fstrim/", "subreddit_subscribers": 735084, "created_utc": 1709101939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for a cheap, but well-working 2-bay DAS for my Mac.\n\nI found the here in Australia local [Simplecom SE482](https://www.simplecom.com.au/simplecom-se482-superspeed-usb-dual-bay-3-5-sata-hard-drive-raid-enclosure-usb-c-raid-0-1-jbod.html).\n\nDoes anybody have experience with it? Does it work well?", "author_fullname": "t2_850k4phh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any erxperience with the 2-bay DAS Simplecom SE482?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1u5l2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709085993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a cheap, but well-working 2-bay DAS for my Mac.&lt;/p&gt;\n\n&lt;p&gt;I found the here in Australia local &lt;a href=\"https://www.simplecom.com.au/simplecom-se482-superspeed-usb-dual-bay-3-5-sata-hard-drive-raid-enclosure-usb-c-raid-0-1-jbod.html\"&gt;Simplecom SE482&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have experience with it? Does it work well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b1u5l2", "is_robot_indexable": true, "report_reasons": null, "author": "jan_aloleo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1u5l2/any_erxperience_with_the_2bay_das_simplecom_se482/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1u5l2/any_erxperience_with_the_2bay_das_simplecom_se482/", "subreddit_subscribers": 735084, "created_utc": 1709085993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Creating a NAS server, but I've never had this many disks in a case before.  Is my cooling sufficient?\n\nFull ATX case with 13x 10TB 3.5\" SATA3 disks right in the front.  3x 120mm fans intake in the front, 2x 120mm on the side.  2x 120mm exhaust on the top, and 1x 120mm in the back.\n\nMy concern is cooling with the drives - anything I should be aware of or recommendations regarding this many drives in a full ATX case?", "author_fullname": "t2_enkwqu0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HD Cooling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2ci54", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709142927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Creating a NAS server, but I&amp;#39;ve never had this many disks in a case before.  Is my cooling sufficient?&lt;/p&gt;\n\n&lt;p&gt;Full ATX case with 13x 10TB 3.5&amp;quot; SATA3 disks right in the front.  3x 120mm fans intake in the front, 2x 120mm on the side.  2x 120mm exhaust on the top, and 1x 120mm in the back.&lt;/p&gt;\n\n&lt;p&gt;My concern is cooling with the drives - anything I should be aware of or recommendations regarding this many drives in a full ATX case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2ci54", "is_robot_indexable": true, "report_reasons": null, "author": "Antique_Paramedic682", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2ci54/hd_cooling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2ci54/hd_cooling/", "subreddit_subscribers": 735084, "created_utc": 1709142927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_12hm7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assistance in the scanning process for 5x5cm color transparency slides? (Epson 4490 Photo Scanner) (Details in Comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2bfpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YWMXJfXE1rG4g8xhPhStDphZoyWKpfnddewFVC2DEfw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709140519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4v38z7640dlc1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4v38z7640dlc1.png?auto=webp&amp;s=5537e4c8215ad385d58dcf73c7997b182f358966", "width": 1053, "height": 742}, "resolutions": [{"url": "https://preview.redd.it/4v38z7640dlc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=32134351f37cf1f1e414f63758b47c6867377564", "width": 108, "height": 76}, {"url": "https://preview.redd.it/4v38z7640dlc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=12422fa113a70ae0566b4a1143d0fc4082e10f78", "width": 216, "height": 152}, {"url": "https://preview.redd.it/4v38z7640dlc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=93311536df35e8e98004c42aa190aa5b8ae848a1", "width": 320, "height": 225}, {"url": "https://preview.redd.it/4v38z7640dlc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=21c40ec457b13d6180cfc3de412cfe42f7fe6c6a", "width": 640, "height": 450}, {"url": "https://preview.redd.it/4v38z7640dlc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=07b00f520dcb3ef1ddbf916e3a62d253f077589f", "width": 960, "height": 676}], "variants": {}, "id": "QWep-NH0evJl6OWCFm5ol6CvDH7HALix-L1h5AO8g3E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2bfpx", "is_robot_indexable": true, "report_reasons": null, "author": "KaiPhotography", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2bfpx/assistance_in_the_scanning_process_for_5x5cm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4v38z7640dlc1.png", "subreddit_subscribers": 735084, "created_utc": 1709140519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Most of my hoard consists of audio files and ebooks, so Mp3tag and Calibre work well for my purposes, but I was wondering if there exists a more generic metadata editor (as an alternative to just using Windows File Explorer on a file-by-file basis).\n\nAny advice is appreciated!", "author_fullname": "t2_a90h9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there such a thing as a general-purpose / bulk metadata editor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2b3yy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709139770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of my hoard consists of audio files and ebooks, so Mp3tag and Calibre work well for my purposes, but I was wondering if there exists a more generic metadata editor (as an alternative to just using Windows File Explorer on a file-by-file basis).&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2b3yy", "is_robot_indexable": true, "report_reasons": null, "author": "Revolvlover", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2b3yy/is_there_such_a_thing_as_a_generalpurpose_bulk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2b3yy/is_there_such_a_thing_as_a_generalpurpose_bulk/", "subreddit_subscribers": 735084, "created_utc": 1709139770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got a new 4TB M2 drive and am looking to consolidate my 1TB ssd and 3TB hdd onto it.\n\nI\u2019ve used Macrium so far to successfully clone the 1TB ssd to the M2, but now I need to figure out how to clone the hdd to the empty space on the M2 without overriding the new 1TB partition cloned onto it.\n\nI know aomei can do it, but the program seems a little sketchy and I\u2019d rather do it within macrium or maybe another program. All suggestions are welcome - thank you!", "author_fullname": "t2_bxnf03z2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to clone a partition from one drive to new drive, not the whole drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2a46s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709137493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a new 4TB M2 drive and am looking to consolidate my 1TB ssd and 3TB hdd onto it.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used Macrium so far to successfully clone the 1TB ssd to the M2, but now I need to figure out how to clone the hdd to the empty space on the M2 without overriding the new 1TB partition cloned onto it.&lt;/p&gt;\n\n&lt;p&gt;I know aomei can do it, but the program seems a little sketchy and I\u2019d rather do it within macrium or maybe another program. All suggestions are welcome - thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2a46s", "is_robot_indexable": true, "report_reasons": null, "author": "Commie_Cactus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2a46s/how_to_clone_a_partition_from_one_drive_to_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2a46s/how_to_clone_a_partition_from_one_drive_to_new/", "subreddit_subscribers": 735084, "created_utc": 1709137493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi!\n\nI use and love my MacBook Air, and I use the paid app DirEqual to compare the contents between my hard drives. One thing I've been doing for years is to copy photos and videos, then do a quick check of a select few images/videos to make sure none of them suffer from data corruption. Until I discovered that bitrot can affect material such as causing deterioration in videos where I might not even check those seconds in those particular videos. I've read MD5 hashes is a way to ensure data integrity, but I find myself really struggling to understand how to generate MD5 hashes for my 21.708 photos and videos.\n\nI read that since DirEqual compares the precise bits of files and folders in two directories, that is enough to 100% make sure bitrot has not occurred. Is that true or am I falling for false promises? Given that my collection of photos/videos is only going to increase, I'd prefer a tool to make this process easy for me while ensuring bitrot does not occur.\n\nSo can I count on DirEqual and its bit-to-bit-comparisons, or do I need to find a way to generate thousands of MD5 hashes? (And if MD5 hashes is the answer, please please pretty please give me some easy instructions, this is all new terrain to me but my data is of vital importance to me).\n\nThank you for answers in advance!", "author_fullname": "t2_jvf4b56ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about bitrot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2a14d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709137298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I use and love my MacBook Air, and I use the paid app DirEqual to compare the contents between my hard drives. One thing I&amp;#39;ve been doing for years is to copy photos and videos, then do a quick check of a select few images/videos to make sure none of them suffer from data corruption. Until I discovered that bitrot can affect material such as causing deterioration in videos where I might not even check those seconds in those particular videos. I&amp;#39;ve read MD5 hashes is a way to ensure data integrity, but I find myself really struggling to understand how to generate MD5 hashes for my 21.708 photos and videos.&lt;/p&gt;\n\n&lt;p&gt;I read that since DirEqual compares the precise bits of files and folders in two directories, that is enough to 100% make sure bitrot has not occurred. Is that true or am I falling for false promises? Given that my collection of photos/videos is only going to increase, I&amp;#39;d prefer a tool to make this process easy for me while ensuring bitrot does not occur.&lt;/p&gt;\n\n&lt;p&gt;So can I count on DirEqual and its bit-to-bit-comparisons, or do I need to find a way to generate thousands of MD5 hashes? (And if MD5 hashes is the answer, please please pretty please give me some easy instructions, this is all new terrain to me but my data is of vital importance to me).&lt;/p&gt;\n\n&lt;p&gt;Thank you for answers in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2a14d", "is_robot_indexable": true, "report_reasons": null, "author": "baltossen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2a14d/question_about_bitrot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2a14d/question_about_bitrot/", "subreddit_subscribers": 735084, "created_utc": 1709137298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI\u2019m having data storage issues at work. We have some networked storage that is a pain in the ass to use, and that isn\u2019t really directly under my groups control. It\u2019s also unclear what redundancy exists in it, or whether deltas are saved or for how long. We\u2019ve got critical raw data distributed between several independent systems as a result. \n\nFor ease of access and use, and to get some extra redundancy that we control directly, I am kicking around creating an offline storage solution for backups of precious raw data. Generally speaking, the files we store are ~200gb-5Tb tarballs. We need about 80tb of storage, and need to be able to scale to somewhere between 200 and 500tb for the future (this depends largely on future technology development that is a bit hard to anticipate). Eventually, these files wind up going to a professionally managed repository and at that point we can remove anything we\u2019re not working with actively from our storage. \n\nI want to do this as cheaply as possible. I have an old iMac running windows and would like to use that as a centralized interface, and I\u2019d like to build two DAS for this, one to attach to that machine, and one to leave airgapped. The plan would be to have users access that machine in person or via ssh, copy data to DAS1, and to periodically disconnect the DAS1, clone DAS1 onto DAS2, and reconnect DAS1. \n\nAny idea how to build something like this? I have my own ideas, but I think they\u2019re probably stupid. \n\nI think I can build a NAS from a mix of new and spare parts for ~$2k. \n\nI was kicking around going to university surplus and ripping drives out of the zillions of old computers for the actual disk space to further cut cost. \n\nWhat are your thoughts? How would you efficiently and cheaply back up this quantity of data (somewhere between 80-200tb)?\n\nThe data are all from genome/transcriptome sequencing. \n\nShould I just say fuck it and have a drawer of hdds and label tape as backup?\n\n\n", "author_fullname": "t2_p8qavydkx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DIY storage solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b27q6y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709131571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having data storage issues at work. We have some networked storage that is a pain in the ass to use, and that isn\u2019t really directly under my groups control. It\u2019s also unclear what redundancy exists in it, or whether deltas are saved or for how long. We\u2019ve got critical raw data distributed between several independent systems as a result. &lt;/p&gt;\n\n&lt;p&gt;For ease of access and use, and to get some extra redundancy that we control directly, I am kicking around creating an offline storage solution for backups of precious raw data. Generally speaking, the files we store are ~200gb-5Tb tarballs. We need about 80tb of storage, and need to be able to scale to somewhere between 200 and 500tb for the future (this depends largely on future technology development that is a bit hard to anticipate). Eventually, these files wind up going to a professionally managed repository and at that point we can remove anything we\u2019re not working with actively from our storage. &lt;/p&gt;\n\n&lt;p&gt;I want to do this as cheaply as possible. I have an old iMac running windows and would like to use that as a centralized interface, and I\u2019d like to build two DAS for this, one to attach to that machine, and one to leave airgapped. The plan would be to have users access that machine in person or via ssh, copy data to DAS1, and to periodically disconnect the DAS1, clone DAS1 onto DAS2, and reconnect DAS1. &lt;/p&gt;\n\n&lt;p&gt;Any idea how to build something like this? I have my own ideas, but I think they\u2019re probably stupid. &lt;/p&gt;\n\n&lt;p&gt;I think I can build a NAS from a mix of new and spare parts for ~$2k. &lt;/p&gt;\n\n&lt;p&gt;I was kicking around going to university surplus and ripping drives out of the zillions of old computers for the actual disk space to further cut cost. &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts? How would you efficiently and cheaply back up this quantity of data (somewhere between 80-200tb)?&lt;/p&gt;\n\n&lt;p&gt;The data are all from genome/transcriptome sequencing. &lt;/p&gt;\n\n&lt;p&gt;Should I just say fuck it and have a drawer of hdds and label tape as backup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b27q6y", "is_robot_indexable": true, "report_reasons": null, "author": "New_Decision_3146", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b27q6y/diy_storage_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b27q6y/diy_storage_solution/", "subreddit_subscribers": 735084, "created_utc": 1709131571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm really curious about this, based on my limited understanding it seems like the answer is quite a lot, but I'm really not sure what the practical number actually is. I've never used expanders before.", "author_fullname": "t2_b0a3k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many drives could a single LSI 9300-8i support by using expanders like the Adaptec 82885T?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b270zp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709129656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m really curious about this, based on my limited understanding it seems like the answer is quite a lot, but I&amp;#39;m really not sure what the practical number actually is. I&amp;#39;ve never used expanders before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "76TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b270zp", "is_robot_indexable": true, "report_reasons": null, "author": "booradleysghost", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b270zp/how_many_drives_could_a_single_lsi_93008i_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b270zp/how_many_drives_could_a_single_lsi_93008i_support/", "subreddit_subscribers": 735084, "created_utc": 1709129656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have Windows 10 and Ubuntu dual booted in my laptop, in a 512GB SSD. I have a free 1TB HDD and I would like to just back up my entire disk so I can just restore everything in case something happens to my laptop. I don't really know a lot about backing up, so I would like to know what would be the easiest way to do this?", "author_fullname": "t2_6b70fv0y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to back up dual boot windows/linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1q6vf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709075432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have Windows 10 and Ubuntu dual booted in my laptop, in a 512GB SSD. I have a free 1TB HDD and I would like to just back up my entire disk so I can just restore everything in case something happens to my laptop. I don&amp;#39;t really know a lot about backing up, so I would like to know what would be the easiest way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1q6vf", "is_robot_indexable": true, "report_reasons": null, "author": "DSousa55", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1q6vf/best_way_to_back_up_dual_boot_windowslinux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1q6vf/best_way_to_back_up_dual_boot_windowslinux/", "subreddit_subscribers": 735084, "created_utc": 1709075432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I apologize in advance if this sound silly to you, but keep in mind that I'm a noob.\n\nLet's say I have three external hard drives with the exact same contents that I've manually copied from drive#1 to drive#2, then from drive#2 to #3.\n\nThe drives are organized in a fairly complex tree of folders and subfolders because I need data categorized and organized.\n\nNow here's the problem: I once in a while have to add new files to drive#1, but I have to put them in the correct folders of the tree so they are spreaded, like say 3 files in folder A, 7 files in folder D subfolder Z and so on.File size is small (10-100mb) but are a lot of files. Take for example 30 files spread into 20 different folders.\n\nNow I have to update drive#2 and drive#3 with just the new files. And here's the question: what's exactly is the best practice here?\n\nCopying again the whole drive#1 to drive#2 and #3 would take an excessive amount of work and time given that we are talking of hundreds of gb to copy the whole thing, while the newly added files are just a small fraction of this.\n\nManually taking notes of all the new files I added to drive#1 and all their paths becomes time consuming to do every time, plus they are a lot (30 files in 20 different folders in the example), doing this every few weeks.\n\nWithout manually taking notes of the new files+path, I don't remember what's new and in which path should be copied in drive#2 and #3.\n\nWhat's the best course of action here?", "author_fullname": "t2_w3dq4usx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to do a partial backup copy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b25shz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709126359.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709126088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I apologize in advance if this sound silly to you, but keep in mind that I&amp;#39;m a noob.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I have three external hard drives with the exact same contents that I&amp;#39;ve manually copied from drive#1 to drive#2, then from drive#2 to #3.&lt;/p&gt;\n\n&lt;p&gt;The drives are organized in a fairly complex tree of folders and subfolders because I need data categorized and organized.&lt;/p&gt;\n\n&lt;p&gt;Now here&amp;#39;s the problem: I once in a while have to add new files to drive#1, but I have to put them in the correct folders of the tree so they are spreaded, like say 3 files in folder A, 7 files in folder D subfolder Z and so on.File size is small (10-100mb) but are a lot of files. Take for example 30 files spread into 20 different folders.&lt;/p&gt;\n\n&lt;p&gt;Now I have to update drive#2 and drive#3 with just the new files. And here&amp;#39;s the question: what&amp;#39;s exactly is the best practice here?&lt;/p&gt;\n\n&lt;p&gt;Copying again the whole drive#1 to drive#2 and #3 would take an excessive amount of work and time given that we are talking of hundreds of gb to copy the whole thing, while the newly added files are just a small fraction of this.&lt;/p&gt;\n\n&lt;p&gt;Manually taking notes of all the new files I added to drive#1 and all their paths becomes time consuming to do every time, plus they are a lot (30 files in 20 different folders in the example), doing this every few weeks.&lt;/p&gt;\n\n&lt;p&gt;Without manually taking notes of the new files+path, I don&amp;#39;t remember what&amp;#39;s new and in which path should be copied in drive#2 and #3.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best course of action here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b25shz", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Today-2429", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b25shz/whats_the_best_way_to_do_a_partial_backup_copy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b25shz/whats_the_best_way_to_do_a_partial_backup_copy/", "subreddit_subscribers": 735084, "created_utc": 1709126088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Ok, so there's rumor, basically, some guy posted part of some two A4 unfilled court papers (no numbers or other legal data, just text) to his Twitter account.. We all know how these absurds with that Japanese corporation end up.. \n\nI'm not having knowledge or resources to make complete dump of their Github page, with logs, issues and other stuff, all i can currently do is to get their releases, but.. Since we're all hoarders.. \nI would like to ask you, who are interested in saving that part of software engineering, to make dumps of Yuzu Github pages, for future generations and our own sake and property. \n\n(yes, I haven't seen it here, so decided to mention).. \nAlso, I don't want to post any link to that rumor, because I have mixed feelings about it.. Especially making traffic on account I barely have idea about, like, you know.. It can be googled, it can be seen. I saw that news among emulation subreddit, decided to confirm and it occurs that actually officially it's confirmed by community of that software.. So it's all in hands of court to decide if we can do anything with stuff we buy, or if big corporations can do whatever they want.\nEven so, let's do everything to preserve past, for future ", "author_fullname": "t2_iwj4pzsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigN sues Yuzu creators?! ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b208ig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709105341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok, so there&amp;#39;s rumor, basically, some guy posted part of some two A4 unfilled court papers (no numbers or other legal data, just text) to his Twitter account.. We all know how these absurds with that Japanese corporation end up.. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not having knowledge or resources to make complete dump of their Github page, with logs, issues and other stuff, all i can currently do is to get their releases, but.. Since we&amp;#39;re all hoarders.. \nI would like to ask you, who are interested in saving that part of software engineering, to make dumps of Yuzu Github pages, for future generations and our own sake and property. &lt;/p&gt;\n\n&lt;p&gt;(yes, I haven&amp;#39;t seen it here, so decided to mention).. \nAlso, I don&amp;#39;t want to post any link to that rumor, because I have mixed feelings about it.. Especially making traffic on account I barely have idea about, like, you know.. It can be googled, it can be seen. I saw that news among emulation subreddit, decided to confirm and it occurs that actually officially it&amp;#39;s confirmed by community of that software.. So it&amp;#39;s all in hands of court to decide if we can do anything with stuff we buy, or if big corporations can do whatever they want.\nEven so, let&amp;#39;s do everything to preserve past, for future &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b208ig", "is_robot_indexable": true, "report_reasons": null, "author": "YousureWannaknow", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b208ig/bign_sues_yuzu_creators/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b208ig/bign_sues_yuzu_creators/", "subreddit_subscribers": 735084, "created_utc": 1709105341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got a new 4TB M2 drive and am looking to consolidate my 1TB ssd and 3TB hdd onto it.\n\nI\u2019ve used Macrium so far to successfully clone the 1TB ssd to the M2, but now I need to figure out how to clone the hdd to the empty space on the M2 without overriding the new 1TB partition cloned onto it.\n\nI know aomei can do it, but the program seems a little sketchy and I\u2019d rather do it within macrium or maybe another program. All suggestions are welcome - thank you!", "author_fullname": "t2_bxnf03z2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to clone a partition from one drive to new drive, not the whole drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2a48x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709137497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a new 4TB M2 drive and am looking to consolidate my 1TB ssd and 3TB hdd onto it.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used Macrium so far to successfully clone the 1TB ssd to the M2, but now I need to figure out how to clone the hdd to the empty space on the M2 without overriding the new 1TB partition cloned onto it.&lt;/p&gt;\n\n&lt;p&gt;I know aomei can do it, but the program seems a little sketchy and I\u2019d rather do it within macrium or maybe another program. All suggestions are welcome - thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2a48x", "is_robot_indexable": true, "report_reasons": null, "author": "Commie_Cactus", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2a48x/how_to_clone_a_partition_from_one_drive_to_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2a48x/how_to_clone_a_partition_from_one_drive_to_new/", "subreddit_subscribers": 735084, "created_utc": 1709137497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anybody havea copy of the old saver2 pandora client? Used to be at ridetheclown.com, but has long since disappeared from the web. I have seen a single thread on reddit that has now dead links as far as I can tell https://old.reddit.com/r/Music/comments/1496c2/saver2free_standalone_pandora_client_which_saves/", "author_fullname": "t2_kw2g7j6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Saver2 Pandora Client?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b23ysg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709120090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anybody havea copy of the old saver2 pandora client? Used to be at ridetheclown.com, but has long since disappeared from the web. I have seen a single thread on reddit that has now dead links as far as I can tell &lt;a href=\"https://old.reddit.com/r/Music/comments/1496c2/saver2free_standalone_pandora_client_which_saves/\"&gt;https://old.reddit.com/r/Music/comments/1496c2/saver2free_standalone_pandora_client_which_saves/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b23ysg", "is_robot_indexable": true, "report_reasons": null, "author": "grzy7316x", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b23ysg/saver2_pandora_client/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b23ysg/saver2_pandora_client/", "subreddit_subscribers": 735084, "created_utc": 1709120090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all. \n\nI've recently found 4 500gb drives that have issues. In Windows Event Viewer, it says the device\\\\device\\\\harddisk1\\\\dr1, has a bad block etc.\n\nThe first machine cloned, but with errors. The second machine had 3 drives, and we were not able to clone any of the drives.\n\nSo I googled Samsung EVO 870 failures and the first result is a techpowerup forum thread about about an issue affecting 2tb and 4tb drives manufactured in JAN 2021\n\nAnother video mentioned issues for drives manufactured before Nov 2021\n\nSo we went into panic mode, as we have installed 100+ drives. I wrote some scripts to gather smart data for all PCs we manage. And filtering through I've found 22 machines that have corectedreaderrors and 3 machines with uncorrectedreaderrors (but they are not EVOs).  So I'm starting to panic less. But 22 drives with corrected errors is still worrying.\n\nI can't seem to find an official statement from Samsung about what is affected. I've found a nice write up from Nas compares [https://nascompares.com/2023/02/02/samsung-980-pro-970-evo-plus-pm9a1-and-more-reporting-failures-everything-we-know-so-far/](https://nascompares.com/2023/02/02/samsung-980-pro-970-evo-plus-pm9a1-and-more-reporting-failures-everything-we-know-so-far/)\n\nAnd skimming through that there is a section on EVO 870. And the 3 drives we replaced on the weekend, were manufactured in may 2021, and the serial numbers do not match the ones listed. I will examine patient 0 on Friday when I'm in the office next.\n\nIs there a way to gleam the manufacture date, from the serial?\n\nWill a firmware update prevent further issues? Is it safe to run it on a live system, one with errors?. \n\nIs there actually a problem? or is it just a coincidence?", "author_fullname": "t2_ryg46", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung EVO 870 failures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b210yp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709108499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently found 4 500gb drives that have issues. In Windows Event Viewer, it says the device\\device\\harddisk1\\dr1, has a bad block etc.&lt;/p&gt;\n\n&lt;p&gt;The first machine cloned, but with errors. The second machine had 3 drives, and we were not able to clone any of the drives.&lt;/p&gt;\n\n&lt;p&gt;So I googled Samsung EVO 870 failures and the first result is a techpowerup forum thread about about an issue affecting 2tb and 4tb drives manufactured in JAN 2021&lt;/p&gt;\n\n&lt;p&gt;Another video mentioned issues for drives manufactured before Nov 2021&lt;/p&gt;\n\n&lt;p&gt;So we went into panic mode, as we have installed 100+ drives. I wrote some scripts to gather smart data for all PCs we manage. And filtering through I&amp;#39;ve found 22 machines that have corectedreaderrors and 3 machines with uncorrectedreaderrors (but they are not EVOs).  So I&amp;#39;m starting to panic less. But 22 drives with corrected errors is still worrying.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t seem to find an official statement from Samsung about what is affected. I&amp;#39;ve found a nice write up from Nas compares &lt;a href=\"https://nascompares.com/2023/02/02/samsung-980-pro-970-evo-plus-pm9a1-and-more-reporting-failures-everything-we-know-so-far/\"&gt;https://nascompares.com/2023/02/02/samsung-980-pro-970-evo-plus-pm9a1-and-more-reporting-failures-everything-we-know-so-far/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And skimming through that there is a section on EVO 870. And the 3 drives we replaced on the weekend, were manufactured in may 2021, and the serial numbers do not match the ones listed. I will examine patient 0 on Friday when I&amp;#39;m in the office next.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to gleam the manufacture date, from the serial?&lt;/p&gt;\n\n&lt;p&gt;Will a firmware update prevent further issues? Is it safe to run it on a live system, one with errors?. &lt;/p&gt;\n\n&lt;p&gt;Is there actually a problem? or is it just a coincidence?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/o2UQy_VDwszJRuoXMDQtRl8raSdYeU4xxIwhWcUFQaw.jpg?auto=webp&amp;s=75c2f3aafd7429bb95201c32e1f3b875bbab64b3", "width": 1280, "height": 624}, "resolutions": [{"url": "https://external-preview.redd.it/o2UQy_VDwszJRuoXMDQtRl8raSdYeU4xxIwhWcUFQaw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7dcc9397282ed0cf346c318fa52cced05c92ae99", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/o2UQy_VDwszJRuoXMDQtRl8raSdYeU4xxIwhWcUFQaw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a4db76115937e34b4d95f7c4e7b40662e3cfde5", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/o2UQy_VDwszJRuoXMDQtRl8raSdYeU4xxIwhWcUFQaw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=05b84f19dcf24cf737773231ff131227a5659db1", "width": 320, "height": 156}, {"url": "https://external-preview.redd.it/o2UQy_VDwszJRuoXMDQtRl8raSdYeU4xxIwhWcUFQaw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bbeaafcc9b493c40abd8bbf24395bccb27f0b437", "width": 640, "height": 312}, {"url": "https://external-preview.redd.it/o2UQy_VDwszJRuoXMDQtRl8raSdYeU4xxIwhWcUFQaw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=234765535bad7349abd0bd6af72aa2549dcbc412", "width": 960, "height": 468}, {"url": "https://external-preview.redd.it/o2UQy_VDwszJRuoXMDQtRl8raSdYeU4xxIwhWcUFQaw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fc9d13779fe90113d05efcafcdf88d1bbced5ef4", "width": 1080, "height": 526}], "variants": {}, "id": "tMfzZh2Gzg4fSoaVKLGiMWMtp8wdDlFaVaZ3y8uvnxo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b210yp", "is_robot_indexable": true, "report_reasons": null, "author": "spacefrog_feds", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b210yp/samsung_evo_870_failures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b210yp/samsung_evo_870_failures/", "subreddit_subscribers": 735084, "created_utc": 1709108499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I came up on a little bit of money and wanted to build a dedicated server and so I asked r/homeserver  to walk me through buying anf building a home server that could handle everything I wanted (Jellyfin, Nextcloud, Immich, Lube Logger, ShinobiCCTV and maybe a gaming server in the future. I also wanted a cas that could allow me to add up to 2 bays. But most comments said that the current laptops I had as severs would be enough so then I turned my attention to a NAS or DAS to have 3 20TB HDD (I need to buy them) but I was wondering. I have 1 iod these \n\nSABRENT USB 3.0 to SATA I/II/III Dual Bay External Hard Drive Docking Station for 2.5 or 3.5in HDD, SSD with Hard Drive Duplicator/Cloner Function [20+TB Support] (EC-HD2B) https://a.co/d/1mzuoPw\n\nAnd 2 of these. \n\nSABRENT USB 3.0 to SATA External Hard Drive Lay-Flat Docking Station for 2.5 or 3.5in HDD, SSD [Support UASP] (EC-DFLT) https://a.co/d/3ApifG\n\nIf I just use a USB hub and connect 4 drives to my laptop I can access all my drives through samba or Jellyfin or Nextcloud. So I reality I don't need a NAS or DAS right? ", "author_fullname": "t2_v9opjyxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wanted a NAS or DAS for me server but do I need it? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1zrh3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709103526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came up on a little bit of money and wanted to build a dedicated server and so I asked &lt;a href=\"/r/homeserver\"&gt;r/homeserver&lt;/a&gt;  to walk me through buying anf building a home server that could handle everything I wanted (Jellyfin, Nextcloud, Immich, Lube Logger, ShinobiCCTV and maybe a gaming server in the future. I also wanted a cas that could allow me to add up to 2 bays. But most comments said that the current laptops I had as severs would be enough so then I turned my attention to a NAS or DAS to have 3 20TB HDD (I need to buy them) but I was wondering. I have 1 iod these &lt;/p&gt;\n\n&lt;p&gt;SABRENT USB 3.0 to SATA I/II/III Dual Bay External Hard Drive Docking Station for 2.5 or 3.5in HDD, SSD with Hard Drive Duplicator/Cloner Function [20+TB Support] (EC-HD2B) &lt;a href=\"https://a.co/d/1mzuoPw\"&gt;https://a.co/d/1mzuoPw&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And 2 of these. &lt;/p&gt;\n\n&lt;p&gt;SABRENT USB 3.0 to SATA External Hard Drive Lay-Flat Docking Station for 2.5 or 3.5in HDD, SSD [Support UASP] (EC-DFLT) &lt;a href=\"https://a.co/d/3ApifG\"&gt;https://a.co/d/3ApifG&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If I just use a USB hub and connect 4 drives to my laptop I can access all my drives through samba or Jellyfin or Nextcloud. So I reality I don&amp;#39;t need a NAS or DAS right? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1zrh3", "is_robot_indexable": true, "report_reasons": null, "author": "iamwhoiwasnow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1zrh3/i_wanted_a_nas_or_das_for_me_server_but_do_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1zrh3/i_wanted_a_nas_or_das_for_me_server_but_do_i_need/", "subreddit_subscribers": 735084, "created_utc": 1709103526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone at DataHoarder,\n\nFor a long while, I've been toying with the idea of transforming an old computer into a dedicated media server for my living room entertainment setup. However, upon diving into the world of network-attached storage (NAS), I decided to invest in a pair of 20 TB Seagate Exos drives. While I was setting up my old PC as an UnRaid system, I received an ASUSTOR DRIVESTOR 2 Lite (AS1102TL) at no cost, but it is severely underpowered and may work for my solo needs. \n\nI've also explored the realms of xpenology, and TrueNAS while considering the possibility of building a custom machine from scratch. I'd like to have expandability for future use. I know UnRaid is better for future expandability, but I am also considering buying a Synology with more drive bays (6-8) when the time comes. \n\nMy storage needs are pretty extensive, encompassing everything from archival photos and videos from past mobile phones to 4K video content for my YouTube channel, along with a substantial collection of movies, TV shows, music, games, and various other digital files. \n\nAt present, my setup includes a mix of SSDs and smaller HDDs actively in use, with additional drives tucked away with who knows what on them.\n\nThe primary roles I envision for the NAS include:\n\n* Serving as a Plex Media Server to organize and stream movies and TV shows at home, and provide access to my music library on the go.\n* Acting as a centralized network file system.\n* Ensuring data redundancy to safeguard against potential loss.\n* Facilitating the consolidation of my scattered data for easier management.\n\nWith these considerations in mind, I'm seeking guidance on how best to proceed, both for my immediate setup and with an eye toward future expansion. \n\nSpecifically, I'm debating whether to configure the ASUSTOR NAS in a RAID 1 setup, utilizing both 20TB drives for mirrored redundancy, or to employ a single drive in the NAS for active data access while dedicating the other to my gaming/personal computer for additional storage or backup purposes. Which would allow me to also use BackBlaze personal account.\n\nI'm eager to hear your thoughts, experiences, and any advice you might have on the matter. Thanks in advance for your help!", "author_fullname": "t2_7stkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS Configuration Dilemma: RAID 1 vs. RAID 0 with Backup Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1o6fb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709070649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone at DataHoarder,&lt;/p&gt;\n\n&lt;p&gt;For a long while, I&amp;#39;ve been toying with the idea of transforming an old computer into a dedicated media server for my living room entertainment setup. However, upon diving into the world of network-attached storage (NAS), I decided to invest in a pair of 20 TB Seagate Exos drives. While I was setting up my old PC as an UnRaid system, I received an ASUSTOR DRIVESTOR 2 Lite (AS1102TL) at no cost, but it is severely underpowered and may work for my solo needs. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also explored the realms of xpenology, and TrueNAS while considering the possibility of building a custom machine from scratch. I&amp;#39;d like to have expandability for future use. I know UnRaid is better for future expandability, but I am also considering buying a Synology with more drive bays (6-8) when the time comes. &lt;/p&gt;\n\n&lt;p&gt;My storage needs are pretty extensive, encompassing everything from archival photos and videos from past mobile phones to 4K video content for my YouTube channel, along with a substantial collection of movies, TV shows, music, games, and various other digital files. &lt;/p&gt;\n\n&lt;p&gt;At present, my setup includes a mix of SSDs and smaller HDDs actively in use, with additional drives tucked away with who knows what on them.&lt;/p&gt;\n\n&lt;p&gt;The primary roles I envision for the NAS include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Serving as a Plex Media Server to organize and stream movies and TV shows at home, and provide access to my music library on the go.&lt;/li&gt;\n&lt;li&gt;Acting as a centralized network file system.&lt;/li&gt;\n&lt;li&gt;Ensuring data redundancy to safeguard against potential loss.&lt;/li&gt;\n&lt;li&gt;Facilitating the consolidation of my scattered data for easier management.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With these considerations in mind, I&amp;#39;m seeking guidance on how best to proceed, both for my immediate setup and with an eye toward future expansion. &lt;/p&gt;\n\n&lt;p&gt;Specifically, I&amp;#39;m debating whether to configure the ASUSTOR NAS in a RAID 1 setup, utilizing both 20TB drives for mirrored redundancy, or to employ a single drive in the NAS for active data access while dedicating the other to my gaming/personal computer for additional storage or backup purposes. Which would allow me to also use BackBlaze personal account.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m eager to hear your thoughts, experiences, and any advice you might have on the matter. Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1o6fb", "is_robot_indexable": true, "report_reasons": null, "author": "stogenbobber", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1o6fb/nas_configuration_dilemma_raid_1_vs_raid_0_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1o6fb/nas_configuration_dilemma_raid_1_vs_raid_0_with/", "subreddit_subscribers": 735084, "created_utc": 1709070649.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}