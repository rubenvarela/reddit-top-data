{"kind": "Listing", "data": {"after": "t3_1b2f88g", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_h6kxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive support is being discontinued in StableBit CloudDrive [check 1.2.6.1700]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1pugk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1709074615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "covecube.download", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://covecube.download/CloudDriveWindows/beta/download/changes.txt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "400TB raw", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1pugk", "is_robot_indexable": true, "report_reasons": null, "author": "It_Is1-24PM", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b1pugk/google_drive_support_is_being_discontinued_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://covecube.download/CloudDriveWindows/beta/download/changes.txt", "subreddit_subscribers": 735123, "created_utc": 1709074615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_12hm7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assistance in the scanning process for 5x5cm color transparency slides? (Epson 4490 Photo Scanner) (Details in Comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2bfpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YWMXJfXE1rG4g8xhPhStDphZoyWKpfnddewFVC2DEfw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709140519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4v38z7640dlc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4v38z7640dlc1.png?auto=webp&amp;s=5537e4c8215ad385d58dcf73c7997b182f358966", "width": 1053, "height": 742}, "resolutions": [{"url": "https://preview.redd.it/4v38z7640dlc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=32134351f37cf1f1e414f63758b47c6867377564", "width": 108, "height": 76}, {"url": "https://preview.redd.it/4v38z7640dlc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=12422fa113a70ae0566b4a1143d0fc4082e10f78", "width": 216, "height": 152}, {"url": "https://preview.redd.it/4v38z7640dlc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=93311536df35e8e98004c42aa190aa5b8ae848a1", "width": 320, "height": 225}, {"url": "https://preview.redd.it/4v38z7640dlc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=21c40ec457b13d6180cfc3de412cfe42f7fe6c6a", "width": 640, "height": 450}, {"url": "https://preview.redd.it/4v38z7640dlc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=07b00f520dcb3ef1ddbf916e3a62d253f077589f", "width": 960, "height": 676}], "variants": {}, "id": "QWep-NH0evJl6OWCFm5ol6CvDH7HALix-L1h5AO8g3E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2bfpx", "is_robot_indexable": true, "report_reasons": null, "author": "KaiPhotography", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2bfpx/assistance_in_the_scanning_process_for_5x5cm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4v38z7640dlc1.png", "subreddit_subscribers": 735123, "created_utc": 1709140519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I always leave the computer well alone when migrating o.s to a new drive, but I am very interested in whether you can run a game or something.  I wouldn't be surprised if this were possible under linux partitions, sounds like something ntfs wouldn't be capable of.", "author_fullname": "t2_ubnt8yve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you clone your o.s drive while in use, and if so, how are the changes made on that drive protected from being modified while read?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b275ax", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709129996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I always leave the computer well alone when migrating o.s to a new drive, but I am very interested in whether you can run a game or something.  I wouldn&amp;#39;t be surprised if this were possible under linux partitions, sounds like something ntfs wouldn&amp;#39;t be capable of.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b275ax", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Introduction5124", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b275ax/can_you_clone_your_os_drive_while_in_use_and_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b275ax/can_you_clone_your_os_drive_while_in_use_and_if/", "subreddit_subscribers": 735123, "created_utc": 1709129996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to turn my mini pc with Debian into a storage server by (buying and) connecting this unit but need to be able to pull smart values, trim ssds and suspend spinning disks. A lot of usb disk docks don't support these operations. I have no idea how compatible tr-004's controller is. I would set the dip switches to individual disk mode.\n\nCan anyone with this unit or the TR-002 tell me if this is possible?", "author_fullname": "t2_xk53e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Qnap TR-004 expansion unit - can I execute fstrim, smartctl, suspend individual drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1zc7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709102123.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709101939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to turn my mini pc with Debian into a storage server by (buying and) connecting this unit but need to be able to pull smart values, trim ssds and suspend spinning disks. A lot of usb disk docks don&amp;#39;t support these operations. I have no idea how compatible tr-004&amp;#39;s controller is. I would set the dip switches to individual disk mode.&lt;/p&gt;\n\n&lt;p&gt;Can anyone with this unit or the TR-002 tell me if this is possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "always 90% full", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1zc7d", "is_robot_indexable": true, "report_reasons": null, "author": "umataro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b1zc7d/qnap_tr004_expansion_unit_can_i_execute_fstrim/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1zc7d/qnap_tr004_expansion_unit_can_i_execute_fstrim/", "subreddit_subscribers": 735123, "created_utc": 1709101939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I use [allinonedownloader.com](https://allinonedownloader.com), it's actually pretty great in HD etc but when you tried to DL an old Tiktok usually it doesnt work / can't DL the preview too.  Do you have a recommandations of a website where you DL in full quality the tiktok ? (Maybe the Website itself when you right click and you can DL it) ? Thank you ! ", "author_fullname": "t2_3iixwuk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Tiktok downloader websites in HD online ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1soqr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709081957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I use &lt;a href=\"https://allinonedownloader.com\"&gt;allinonedownloader.com&lt;/a&gt;, it&amp;#39;s actually pretty great in HD etc but when you tried to DL an old Tiktok usually it doesnt work / can&amp;#39;t DL the preview too.  Do you have a recommandations of a website where you DL in full quality the tiktok ? (Maybe the Website itself when you right click and you can DL it) ? Thank you ! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1soqr", "is_robot_indexable": true, "report_reasons": null, "author": "NoMota", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1soqr/best_tiktok_downloader_websites_in_hd_online/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1soqr/best_tiktok_downloader_websites_in_hd_online/", "subreddit_subscribers": 735123, "created_utc": 1709081957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Most of my hoard consists of audio files and ebooks, so Mp3tag and Calibre work well for my purposes, but I was wondering if there exists a more generic metadata editor (as an alternative to just using Windows File Explorer on a file-by-file basis).\n\nAny advice is appreciated!", "author_fullname": "t2_a90h9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there such a thing as a general-purpose / bulk metadata editor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2b3yy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709139770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of my hoard consists of audio files and ebooks, so Mp3tag and Calibre work well for my purposes, but I was wondering if there exists a more generic metadata editor (as an alternative to just using Windows File Explorer on a file-by-file basis).&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2b3yy", "is_robot_indexable": true, "report_reasons": null, "author": "Revolvlover", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2b3yy/is_there_such_a_thing_as_a_generalpurpose_bulk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2b3yy/is_there_such_a_thing_as_a_generalpurpose_bulk/", "subreddit_subscribers": 735123, "created_utc": 1709139770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi!\n\nI use and love my MacBook Air, and I use the paid app DirEqual to compare the contents between my hard drives. One thing I've been doing for years is to copy photos and videos, then do a quick check of a select few images/videos to make sure none of them suffer from data corruption. Until I discovered that bitrot can affect material such as causing deterioration in videos where I might not even check those seconds in those particular videos. I've read MD5 hashes is a way to ensure data integrity, but I find myself really struggling to understand how to generate MD5 hashes for my 21.708 photos and videos.\n\nI read that since DirEqual compares the precise bits of files and folders in two directories, that is enough to 100% make sure bitrot has not occurred. Is that true or am I falling for false promises? Given that my collection of photos/videos is only going to increase, I'd prefer a tool to make this process easy for me while ensuring bitrot does not occur.\n\nSo can I count on DirEqual and its bit-to-bit-comparisons, or do I need to find a way to generate thousands of MD5 hashes? (And if MD5 hashes is the answer, please please pretty please give me some easy instructions, this is all new terrain to me but my data is of vital importance to me).\n\nThank you for answers in advance!", "author_fullname": "t2_jvf4b56ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about bitrot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2a14d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709137298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I use and love my MacBook Air, and I use the paid app DirEqual to compare the contents between my hard drives. One thing I&amp;#39;ve been doing for years is to copy photos and videos, then do a quick check of a select few images/videos to make sure none of them suffer from data corruption. Until I discovered that bitrot can affect material such as causing deterioration in videos where I might not even check those seconds in those particular videos. I&amp;#39;ve read MD5 hashes is a way to ensure data integrity, but I find myself really struggling to understand how to generate MD5 hashes for my 21.708 photos and videos.&lt;/p&gt;\n\n&lt;p&gt;I read that since DirEqual compares the precise bits of files and folders in two directories, that is enough to 100% make sure bitrot has not occurred. Is that true or am I falling for false promises? Given that my collection of photos/videos is only going to increase, I&amp;#39;d prefer a tool to make this process easy for me while ensuring bitrot does not occur.&lt;/p&gt;\n\n&lt;p&gt;So can I count on DirEqual and its bit-to-bit-comparisons, or do I need to find a way to generate thousands of MD5 hashes? (And if MD5 hashes is the answer, please please pretty please give me some easy instructions, this is all new terrain to me but my data is of vital importance to me).&lt;/p&gt;\n\n&lt;p&gt;Thank you for answers in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2a14d", "is_robot_indexable": true, "report_reasons": null, "author": "baltossen", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2a14d/question_about_bitrot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2a14d/question_about_bitrot/", "subreddit_subscribers": 735123, "created_utc": 1709137298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a mix of internal and external SSDs plus a hard drive. Is it possible to pool them together but still have control over what type of data is stored on each type of drive?", "author_fullname": "t2_cxtr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Drivepool advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b28h8c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709133525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a mix of internal and external SSDs plus a hard drive. Is it possible to pool them together but still have control over what type of data is stored on each type of drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b28h8c", "is_robot_indexable": true, "report_reasons": null, "author": "zuldar", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b28h8c/need_drivepool_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b28h8c/need_drivepool_advice/", "subreddit_subscribers": 735123, "created_utc": 1709133525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Google drive, mega, and Dropbox constantly ban public NSFW folders. I want to share a link to a collection of my favorite videos for anyone to find. I was originally going to use terabox, but the share tab says \u201cpornographic, violent, or otherwise objectionable content may not be shared.\u201d\n\nAre there any cloud storage sites that won\u2019t take down my files if I make them public and share them?", "author_fullname": "t2_rhek29v6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any cloud storage sites that allow public sharing of adult content?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1uoa3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709087428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Google drive, mega, and Dropbox constantly ban public NSFW folders. I want to share a link to a collection of my favorite videos for anyone to find. I was originally going to use terabox, but the share tab says \u201cpornographic, violent, or otherwise objectionable content may not be shared.\u201d&lt;/p&gt;\n\n&lt;p&gt;Are there any cloud storage sites that won\u2019t take down my files if I make them public and share them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1uoa3", "is_robot_indexable": true, "report_reasons": null, "author": "Classic_Plankton6293", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1uoa3/are_there_any_cloud_storage_sites_that_allow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1uoa3/are_there_any_cloud_storage_sites_that_allow/", "subreddit_subscribers": 735123, "created_utc": 1709087428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for a cheap, but well-working 2-bay DAS for my Mac.\n\nI found the here in Australia local [Simplecom SE482](https://www.simplecom.com.au/simplecom-se482-superspeed-usb-dual-bay-3-5-sata-hard-drive-raid-enclosure-usb-c-raid-0-1-jbod.html).\n\nDoes anybody have experience with it? Does it work well?", "author_fullname": "t2_850k4phh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any erxperience with the 2-bay DAS Simplecom SE482?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1u5l2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709085993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a cheap, but well-working 2-bay DAS for my Mac.&lt;/p&gt;\n\n&lt;p&gt;I found the here in Australia local &lt;a href=\"https://www.simplecom.com.au/simplecom-se482-superspeed-usb-dual-bay-3-5-sata-hard-drive-raid-enclosure-usb-c-raid-0-1-jbod.html\"&gt;Simplecom SE482&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have experience with it? Does it work well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b1u5l2", "is_robot_indexable": true, "report_reasons": null, "author": "jan_aloleo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1u5l2/any_erxperience_with_the_2bay_das_simplecom_se482/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1u5l2/any_erxperience_with_the_2bay_das_simplecom_se482/", "subreddit_subscribers": 735123, "created_utc": 1709085993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Retired my 4 year old \"gaming pc\" and am currently futzing around with making it a NAS full time. \nSpecs:\nAMD Ryzen 9 5900X\nAsRock B550M Steel Legend \n32GB DDR4 3200mhz\nNvidia 3060 12GB edition (LHR)\nSeasonic 850 Titanium (PS) \n10G PCIE ethernet card (dual port) \nCurrently 72 TB of HDD storage + 2TB SSD for the OS (could I use one of the other SSD slots as a cache drive?) \nIs there anything else I need for this guy? \nI'm setting it up with TrueNAS after I complete my data transfer(s), any advice would be appreciated Tia. \n\nI know it is over kill but I don't want to just let it grow dust in the oset/garage... It can grow dust with my router\ud83e\udd23\n", "author_fullname": "t2_mu57y3dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just a question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2h6v7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709153784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Retired my 4 year old &amp;quot;gaming pc&amp;quot; and am currently futzing around with making it a NAS full time. \nSpecs:\nAMD Ryzen 9 5900X\nAsRock B550M Steel Legend \n32GB DDR4 3200mhz\nNvidia 3060 12GB edition (LHR)\nSeasonic 850 Titanium (PS) \n10G PCIE ethernet card (dual port) \nCurrently 72 TB of HDD storage + 2TB SSD for the OS (could I use one of the other SSD slots as a cache drive?) \nIs there anything else I need for this guy? \nI&amp;#39;m setting it up with TrueNAS after I complete my data transfer(s), any advice would be appreciated Tia. &lt;/p&gt;\n\n&lt;p&gt;I know it is over kill but I don&amp;#39;t want to just let it grow dust in the oset/garage... It can grow dust with my router\ud83e\udd23&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/zphzppbp3elc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/zphzppbp3elc1.jpeg?auto=webp&amp;s=ae887f6f63fab096bb0a45914b3b0ba3c9f06139", "width": 9000, "height": 12000}, "resolutions": [{"url": "https://preview.redd.it/zphzppbp3elc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5b9015a6df74856f79a5c4450a63991e966f5243", "width": 108, "height": 144}, {"url": "https://preview.redd.it/zphzppbp3elc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3f446b64ae236aa0d69a1af3e4f4dae6afa154f7", "width": 216, "height": 288}, {"url": "https://preview.redd.it/zphzppbp3elc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=448c29fdd17ea6defebaa2031d01ea55d4432f34", "width": 320, "height": 426}, {"url": "https://preview.redd.it/zphzppbp3elc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0edf277de51c6e3c46b2ecd22128356366756e2", "width": 640, "height": 853}, {"url": "https://preview.redd.it/zphzppbp3elc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=94e79c9442668bc120a42b9f456d308c3cb2f4bd", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/zphzppbp3elc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=312808c3083ec4d5c0882ffc3a3a0413aa372e68", "width": 1080, "height": 1440}], "variants": {}, "id": "zphzppbp3elc1"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2h6v7", "is_robot_indexable": true, "report_reasons": null, "author": "ZombieWilling292", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2h6v7/just_a_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/zphzppbp3elc1.jpeg", "subreddit_subscribers": 735123, "created_utc": 1709153784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Might be a dumb question, but lets say you have a 4TB drive on which 3.5TB is used. You buy a second drive with idk, lets say 10TB. You clone your first drive onto the second, but still continue to use the second drive like you normally would. Lets also say you have everything backed up on a cloud somewhere or on some offsite drive, whatever. \n\nIs is wise to continue using the new big drive? I always bought a drive that is similar in size or just slightly bigger and cloned my existing data on that, to then store it in a drawer left there to only be checked every month or so. But now i really just want to clone my data on a really big drive, and continue using it for other purposes. Is that a wise thing to do? I can't see why it should be a problem assuming i don't blast it with data and constantly delete and overwrite stuff. Using the extra couple terabytes to put games on and play off of it should be okay, no?", "author_fullname": "t2_kht4ovrc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you use backup drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2gsix", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709152851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Might be a dumb question, but lets say you have a 4TB drive on which 3.5TB is used. You buy a second drive with idk, lets say 10TB. You clone your first drive onto the second, but still continue to use the second drive like you normally would. Lets also say you have everything backed up on a cloud somewhere or on some offsite drive, whatever. &lt;/p&gt;\n\n&lt;p&gt;Is is wise to continue using the new big drive? I always bought a drive that is similar in size or just slightly bigger and cloned my existing data on that, to then store it in a drawer left there to only be checked every month or so. But now i really just want to clone my data on a really big drive, and continue using it for other purposes. Is that a wise thing to do? I can&amp;#39;t see why it should be a problem assuming i don&amp;#39;t blast it with data and constantly delete and overwrite stuff. Using the extra couple terabytes to put games on and play off of it should be okay, no?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2gsix", "is_robot_indexable": true, "report_reasons": null, "author": "TengokuDaimakyo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2gsix/can_you_use_backup_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2gsix/can_you_use_backup_drives/", "subreddit_subscribers": 735123, "created_utc": 1709152851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all \ud83d\udc4b\n\nWe have some old videos on consumer grade DVD RWs from more than a decade ago. They don\u2019t register as having any data anymore.\n\nWhat can I do to recover data? I understand things have faded to the point that normal passing of the laser won\u2019t register it. I know Linux and low level programming and could figure out modifying a driver to be more sensitive. That being a big task, is that even worth pursuing or are these videos lost to the ether? Has a company already gone to this trouble that I can hire to recover it?", "author_fullname": "t2_ha3mc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can data on old DVD be recovered?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2fl8g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709150070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;We have some old videos on consumer grade DVD RWs from more than a decade ago. They don\u2019t register as having any data anymore.&lt;/p&gt;\n\n&lt;p&gt;What can I do to recover data? I understand things have faded to the point that normal passing of the laser won\u2019t register it. I know Linux and low level programming and could figure out modifying a driver to be more sensitive. That being a big task, is that even worth pursuing or are these videos lost to the ether? Has a company already gone to this trouble that I can hire to recover it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2fl8g", "is_robot_indexable": true, "report_reasons": null, "author": "lumb3rjackZ", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2fl8g/can_data_on_old_dvd_be_recovered/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2fl8g/can_data_on_old_dvd_be_recovered/", "subreddit_subscribers": 735123, "created_utc": 1709150070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On Amazon this 18tb drive is $500 but it doesn't really seem to have good reviews, saying it fails in 5 months and to avoid it. So is this drive any good or if not what is considered a good large multi-terabyte drive for backing up files. I can only buy 1 external drive, so multiple is not an option. I just want one that won't fail.", "author_fullname": "t2_1ss9t1mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good drive? SanDisk Professional 18TB G-Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2fe9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709149617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On Amazon this 18tb drive is $500 but it doesn&amp;#39;t really seem to have good reviews, saying it fails in 5 months and to avoid it. So is this drive any good or if not what is considered a good large multi-terabyte drive for backing up files. I can only buy 1 external drive, so multiple is not an option. I just want one that won&amp;#39;t fail.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2fe9u", "is_robot_indexable": true, "report_reasons": null, "author": "zoelund", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2fe9u/is_this_a_good_drive_sandisk_professional_18tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2fe9u/is_this_a_good_drive_sandisk_professional_18tb/", "subreddit_subscribers": 735123, "created_utc": 1709149617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm in the process of buying parts for my unRAID build which will run Plex. [This is my build](https://ca.pcpartpicker.com/user/Jake09/saved/r7rcMp).\n\nIt's my first time building a PC and all is straightforward to me except choosing the PSU. I need help finding the right one that will support at least 8 SATA HDDs for expandability. Such a system doesn't require more than 500w-550w. What confuses me is the SATA power connector having multiple connectors on it.  I think this is called daisy chaining and I'm wondering if there will be sufficient amount of power to connect say 4 drives on one strip. Wouldn't I need 1 strip per HDD? I don't think such a power supply exists.\n\nI don't really know how to express my concern in a different way but in a nutshell, I need some help choosing a PSU that will be able to power all my components (1 HDD for now in my build but expanding slowly to 8 or more drives through time). Modularity is not a requirement for me so any type of drive works.", "author_fullname": "t2_74e8mz3i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help choosing a PSU", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2dkjw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709145628.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709145380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of buying parts for my unRAID build which will run Plex. &lt;a href=\"https://ca.pcpartpicker.com/user/Jake09/saved/r7rcMp\"&gt;This is my build&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s my first time building a PC and all is straightforward to me except choosing the PSU. I need help finding the right one that will support at least 8 SATA HDDs for expandability. Such a system doesn&amp;#39;t require more than 500w-550w. What confuses me is the SATA power connector having multiple connectors on it.  I think this is called daisy chaining and I&amp;#39;m wondering if there will be sufficient amount of power to connect say 4 drives on one strip. Wouldn&amp;#39;t I need 1 strip per HDD? I don&amp;#39;t think such a power supply exists.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really know how to express my concern in a different way but in a nutshell, I need some help choosing a PSU that will be able to power all my components (1 HDD for now in my build but expanding slowly to 8 or more drives through time). Modularity is not a requirement for me so any type of drive works.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2dkjw", "is_robot_indexable": true, "report_reasons": null, "author": "JakeHa0991", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2dkjw/need_help_choosing_a_psu/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2dkjw/need_help_choosing_a_psu/", "subreddit_subscribers": 735123, "created_utc": 1709145380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two basic needs: making sure there's at least two copies of any piece of data over around a dozen drives of varying sizes, and parity checking to make sure the data stays good. Is there a single piece of software that can handle that for me?", "author_fullname": "t2_aegeoo1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best software for managing a passel of drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2bera", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709140460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two basic needs: making sure there&amp;#39;s at least two copies of any piece of data over around a dozen drives of varying sizes, and parity checking to make sure the data stays good. Is there a single piece of software that can handle that for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2bera", "is_robot_indexable": true, "report_reasons": null, "author": "Causification", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2bera/best_software_for_managing_a_passel_of_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2bera/best_software_for_managing_a_passel_of_drives/", "subreddit_subscribers": 735123, "created_utc": 1709140460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got a new 4TB M2 drive and am looking to consolidate my 1TB ssd and 3TB hdd onto it.\n\nI\u2019ve used Macrium so far to successfully clone the 1TB ssd to the M2, but now I need to figure out how to clone the hdd to the empty space on the M2 without overriding the new 1TB partition cloned onto it.\n\nI know aomei can do it, but the program seems a little sketchy and I\u2019d rather do it within macrium or maybe another program. All suggestions are welcome - thank you!", "author_fullname": "t2_bxnf03z2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to clone a partition from one drive to new drive, not the whole drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2a46s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709137493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a new 4TB M2 drive and am looking to consolidate my 1TB ssd and 3TB hdd onto it.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used Macrium so far to successfully clone the 1TB ssd to the M2, but now I need to figure out how to clone the hdd to the empty space on the M2 without overriding the new 1TB partition cloned onto it.&lt;/p&gt;\n\n&lt;p&gt;I know aomei can do it, but the program seems a little sketchy and I\u2019d rather do it within macrium or maybe another program. All suggestions are welcome - thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2a46s", "is_robot_indexable": true, "report_reasons": null, "author": "Commie_Cactus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2a46s/how_to_clone_a_partition_from_one_drive_to_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2a46s/how_to_clone_a_partition_from_one_drive_to_new/", "subreddit_subscribers": 735123, "created_utc": 1709137493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 200GB of online storage that my phone automatically backs up to. I'm currently sitting at 90% usage that is mostly photos, and I really don't want to pay for more storage so I'm interested in transcoding all my photos. \n\nI would love to transcode everything to jpegXL, but it's nowhere near being supported by everything yet.  It's 2024, what is the most advanced image coded that currently has wide support? ", "author_fullname": "t2_4ut4u7gi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "transcoding images to save space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b28dsl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709133284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 200GB of online storage that my phone automatically backs up to. I&amp;#39;m currently sitting at 90% usage that is mostly photos, and I really don&amp;#39;t want to pay for more storage so I&amp;#39;m interested in transcoding all my photos. &lt;/p&gt;\n\n&lt;p&gt;I would love to transcode everything to jpegXL, but it&amp;#39;s nowhere near being supported by everything yet.  It&amp;#39;s 2024, what is the most advanced image coded that currently has wide support? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b28dsl", "is_robot_indexable": true, "report_reasons": null, "author": "uname_IsAlreadyTaken", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b28dsl/transcoding_images_to_save_space/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b28dsl/transcoding_images_to_save_space/", "subreddit_subscribers": 735123, "created_utc": 1709133284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI\u2019m having data storage issues at work. We have some networked storage that is a pain in the ass to use, and that isn\u2019t really directly under my groups control. It\u2019s also unclear what redundancy exists in it, or whether deltas are saved or for how long. We\u2019ve got critical raw data distributed between several independent systems as a result. \n\nFor ease of access and use, and to get some extra redundancy that we control directly, I am kicking around creating an offline storage solution for backups of precious raw data. Generally speaking, the files we store are ~200gb-5Tb tarballs. We need about 80tb of storage, and need to be able to scale to somewhere between 200 and 500tb for the future (this depends largely on future technology development that is a bit hard to anticipate). Eventually, these files wind up going to a professionally managed repository and at that point we can remove anything we\u2019re not working with actively from our storage. \n\nI want to do this as cheaply as possible. I have an old iMac running windows and would like to use that as a centralized interface, and I\u2019d like to build two DAS for this, one to attach to that machine, and one to leave airgapped. The plan would be to have users access that machine in person or via ssh, copy data to DAS1, and to periodically disconnect the DAS1, clone DAS1 onto DAS2, and reconnect DAS1. \n\nAny idea how to build something like this? I have my own ideas, but I think they\u2019re probably stupid. \n\nI think I can build a NAS from a mix of new and spare parts for ~$2k. \n\nI was kicking around going to university surplus and ripping drives out of the zillions of old computers for the actual disk space to further cut cost. \n\nWhat are your thoughts? How would you efficiently and cheaply back up this quantity of data (somewhere between 80-200tb)?\n\nThe data are all from genome/transcriptome sequencing. \n\nShould I just say fuck it and have a drawer of hdds and label tape as backup?\n\n\n", "author_fullname": "t2_p8qavydkx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DIY storage solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b27q6y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709131571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having data storage issues at work. We have some networked storage that is a pain in the ass to use, and that isn\u2019t really directly under my groups control. It\u2019s also unclear what redundancy exists in it, or whether deltas are saved or for how long. We\u2019ve got critical raw data distributed between several independent systems as a result. &lt;/p&gt;\n\n&lt;p&gt;For ease of access and use, and to get some extra redundancy that we control directly, I am kicking around creating an offline storage solution for backups of precious raw data. Generally speaking, the files we store are ~200gb-5Tb tarballs. We need about 80tb of storage, and need to be able to scale to somewhere between 200 and 500tb for the future (this depends largely on future technology development that is a bit hard to anticipate). Eventually, these files wind up going to a professionally managed repository and at that point we can remove anything we\u2019re not working with actively from our storage. &lt;/p&gt;\n\n&lt;p&gt;I want to do this as cheaply as possible. I have an old iMac running windows and would like to use that as a centralized interface, and I\u2019d like to build two DAS for this, one to attach to that machine, and one to leave airgapped. The plan would be to have users access that machine in person or via ssh, copy data to DAS1, and to periodically disconnect the DAS1, clone DAS1 onto DAS2, and reconnect DAS1. &lt;/p&gt;\n\n&lt;p&gt;Any idea how to build something like this? I have my own ideas, but I think they\u2019re probably stupid. &lt;/p&gt;\n\n&lt;p&gt;I think I can build a NAS from a mix of new and spare parts for ~$2k. &lt;/p&gt;\n\n&lt;p&gt;I was kicking around going to university surplus and ripping drives out of the zillions of old computers for the actual disk space to further cut cost. &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts? How would you efficiently and cheaply back up this quantity of data (somewhere between 80-200tb)?&lt;/p&gt;\n\n&lt;p&gt;The data are all from genome/transcriptome sequencing. &lt;/p&gt;\n\n&lt;p&gt;Should I just say fuck it and have a drawer of hdds and label tape as backup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b27q6y", "is_robot_indexable": true, "report_reasons": null, "author": "New_Decision_3146", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b27q6y/diy_storage_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b27q6y/diy_storage_solution/", "subreddit_subscribers": 735123, "created_utc": 1709131571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm really curious about this, based on my limited understanding it seems like the answer is quite a lot, but I'm really not sure what the practical number actually is. I've never used expanders before.", "author_fullname": "t2_b0a3k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many drives could a single LSI 9300-8i support by using expanders like the Adaptec 82885T?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b270zp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709129656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m really curious about this, based on my limited understanding it seems like the answer is quite a lot, but I&amp;#39;m really not sure what the practical number actually is. I&amp;#39;ve never used expanders before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "76TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b270zp", "is_robot_indexable": true, "report_reasons": null, "author": "booradleysghost", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1b270zp/how_many_drives_could_a_single_lsi_93008i_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b270zp/how_many_drives_could_a_single_lsi_93008i_support/", "subreddit_subscribers": 735123, "created_utc": 1709129656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have Windows 10 and Ubuntu dual booted in my laptop, in a 512GB SSD. I have a free 1TB HDD and I would like to just back up my entire disk so I can just restore everything in case something happens to my laptop. I don't really know a lot about backing up, so I would like to know what would be the easiest way to do this?", "author_fullname": "t2_6b70fv0y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to back up dual boot windows/linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b1q6vf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709075432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have Windows 10 and Ubuntu dual booted in my laptop, in a 512GB SSD. I have a free 1TB HDD and I would like to just back up my entire disk so I can just restore everything in case something happens to my laptop. I don&amp;#39;t really know a lot about backing up, so I would like to know what would be the easiest way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b1q6vf", "is_robot_indexable": true, "report_reasons": null, "author": "DSousa55", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b1q6vf/best_way_to_back_up_dual_boot_windowslinux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b1q6vf/best_way_to_back_up_dual_boot_windowslinux/", "subreddit_subscribers": 735123, "created_utc": 1709075432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "title, basically, apologies if this is off topic for this sub, but it's more active than say r/wikipedia, which appears to not be geared towards developers anyway.\n\nI am scraping some wikitext / calling some of their public APIs and wasn't sure of the standard extension to use when writing to disk, even better if there is one that will trigger appropriate syntax highlighting in a common editor.", "author_fullname": "t2_s6gmscos", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If there a standard file extension for wikitext, in particular the markup language used by Wiktionary, Wikipedia, etc...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2gfnx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709152031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title, basically, apologies if this is off topic for this sub, but it&amp;#39;s more active than say &lt;a href=\"/r/wikipedia\"&gt;r/wikipedia&lt;/a&gt;, which appears to not be geared towards developers anyway.&lt;/p&gt;\n\n&lt;p&gt;I am scraping some wikitext / calling some of their public APIs and wasn&amp;#39;t sure of the standard extension to use when writing to disk, even better if there is one that will trigger appropriate syntax highlighting in a common editor.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2gfnx", "is_robot_indexable": true, "report_reasons": null, "author": "100yearsofsolidtunes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2gfnx/if_there_a_standard_file_extension_for_wikitext/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2gfnx/if_there_a_standard_file_extension_for_wikitext/", "subreddit_subscribers": 735123, "created_utc": 1709152031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Creating a NAS server, but I've never had this many disks in a case before.  Is my cooling sufficient?\n\nFull ATX case with 13x 10TB 3.5\" SATA3 disks right in the front.  3x 120mm fans intake in the front, 2x 120mm on the side.  2x 120mm exhaust on the top, and 1x 120mm in the back.\n\nMy concern is cooling with the drives - anything I should be aware of or recommendations regarding this many drives in a full ATX case?", "author_fullname": "t2_enkwqu0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HD Cooling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2ci54", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709142927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Creating a NAS server, but I&amp;#39;ve never had this many disks in a case before.  Is my cooling sufficient?&lt;/p&gt;\n\n&lt;p&gt;Full ATX case with 13x 10TB 3.5&amp;quot; SATA3 disks right in the front.  3x 120mm fans intake in the front, 2x 120mm on the side.  2x 120mm exhaust on the top, and 1x 120mm in the back.&lt;/p&gt;\n\n&lt;p&gt;My concern is cooling with the drives - anything I should be aware of or recommendations regarding this many drives in a full ATX case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2ci54", "is_robot_indexable": true, "report_reasons": null, "author": "Antique_Paramedic682", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2ci54/hd_cooling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2ci54/hd_cooling/", "subreddit_subscribers": 735123, "created_utc": 1709142927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I apologize in advance if this sound silly to you, but keep in mind that I'm a noob.\n\nLet's say I have three external hard drives with the exact same contents that I've manually copied from drive#1 to drive#2, then from drive#2 to #3.\n\nThe drives are organized in a fairly complex tree of folders and subfolders because I need data categorized and organized.\n\nNow here's the problem: I once in a while have to add new files to drive#1, but I have to put them in the correct folders of the tree so they are spreaded, like say 3 files in folder A, 7 files in folder D subfolder Z and so on.File size is small (10-100mb) but are a lot of files. Take for example 30 files spread into 20 different folders.\n\nNow I have to update drive#2 and drive#3 with just the new files. And here's the question: what's exactly is the best practice here?\n\nCopying again the whole drive#1 to drive#2 and #3 would take an excessive amount of work and time given that we are talking of hundreds of gb to copy the whole thing, while the newly added files are just a small fraction of this.\n\nManually taking notes of all the new files I added to drive#1 and all their paths becomes time consuming to do every time, plus they are a lot (30 files in 20 different folders in the example), doing this every few weeks.\n\nWithout manually taking notes of the new files+path, I don't remember what's new and in which path should be copied in drive#2 and #3.\n\nWhat's the best course of action here?", "author_fullname": "t2_w3dq4usx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to do a partial backup copy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b25shz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709126359.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709126088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I apologize in advance if this sound silly to you, but keep in mind that I&amp;#39;m a noob.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I have three external hard drives with the exact same contents that I&amp;#39;ve manually copied from drive#1 to drive#2, then from drive#2 to #3.&lt;/p&gt;\n\n&lt;p&gt;The drives are organized in a fairly complex tree of folders and subfolders because I need data categorized and organized.&lt;/p&gt;\n\n&lt;p&gt;Now here&amp;#39;s the problem: I once in a while have to add new files to drive#1, but I have to put them in the correct folders of the tree so they are spreaded, like say 3 files in folder A, 7 files in folder D subfolder Z and so on.File size is small (10-100mb) but are a lot of files. Take for example 30 files spread into 20 different folders.&lt;/p&gt;\n\n&lt;p&gt;Now I have to update drive#2 and drive#3 with just the new files. And here&amp;#39;s the question: what&amp;#39;s exactly is the best practice here?&lt;/p&gt;\n\n&lt;p&gt;Copying again the whole drive#1 to drive#2 and #3 would take an excessive amount of work and time given that we are talking of hundreds of gb to copy the whole thing, while the newly added files are just a small fraction of this.&lt;/p&gt;\n\n&lt;p&gt;Manually taking notes of all the new files I added to drive#1 and all their paths becomes time consuming to do every time, plus they are a lot (30 files in 20 different folders in the example), doing this every few weeks.&lt;/p&gt;\n\n&lt;p&gt;Without manually taking notes of the new files+path, I don&amp;#39;t remember what&amp;#39;s new and in which path should be copied in drive#2 and #3.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best course of action here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b25shz", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Today-2429", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b25shz/whats_the_best_way_to_do_a_partial_backup_copy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b25shz/whats_the_best_way_to_do_a_partial_backup_copy/", "subreddit_subscribers": 735123, "created_utc": 1709126088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a way to convert my 8TB HDD that has 1TB free space to XFS without wiping it?\n\nI do have a copy so reformatting and coping over everything is an option but its annoying how long it will take. ", "author_fullname": "t2_175vrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Convert 8TB exFAT drive to XFS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b2f88g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709149231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to convert my 8TB HDD that has 1TB free space to XFS without wiping it?&lt;/p&gt;\n\n&lt;p&gt;I do have a copy so reformatting and coping over everything is an option but its annoying how long it will take. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1b2f88g", "is_robot_indexable": true, "report_reasons": null, "author": "harperthomas", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1b2f88g/convert_8tb_exfat_drive_to_xfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1b2f88g/convert_8tb_exfat_drive_to_xfs/", "subreddit_subscribers": 735123, "created_utc": 1709149231.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}