{"kind": "Listing", "data": {"after": null, "dist": 6, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone qualified for this would obviously be offered at least 4x the salary in the US. Can anyone tell me one reason why someone would take this job?", "author_fullname": "t2_c8s8psg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Really UK? Really?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1as8s52", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 107, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 107, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qWLOG_1996eqZfFdsgsOHpId7Jb851JTakCGxMfQFVI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708090656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone qualified for this would obviously be offered at least 4x the salary in the US. Can anyone tell me one reason why someone would take this job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jrdjg5ahayic1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jrdjg5ahayic1.jpeg?auto=webp&amp;s=a0bed0d3695ed010298eba358c4fee26f4eccd0e", "width": 1124, "height": 2180}, "resolutions": [{"url": "https://preview.redd.it/jrdjg5ahayic1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9054d38425dab6505a8da50fb6c2d2a75273b44", "width": 108, "height": 209}, {"url": "https://preview.redd.it/jrdjg5ahayic1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=21686b80699175ec774cfb578e0b49e9a0dc7fcb", "width": 216, "height": 418}, {"url": "https://preview.redd.it/jrdjg5ahayic1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5be3c7884ac14a3f62d6189c9f257b0305353835", "width": 320, "height": 620}, {"url": "https://preview.redd.it/jrdjg5ahayic1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b607743b2d4059b4a468e7fca44e51881d767e7a", "width": 640, "height": 1241}, {"url": "https://preview.redd.it/jrdjg5ahayic1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=003a79da3eea485e469911f8639f836591aef621", "width": 960, "height": 1861}, {"url": "https://preview.redd.it/jrdjg5ahayic1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dad3d37097838e8206e8922be46beb9b5d3b8daa", "width": 1080, "height": 2094}], "variants": {}, "id": "kKuaVq8Jk0wXrs6j66ji9QbRZl-DbwlsG3Ji6Xh0jSA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1as8s52", "is_robot_indexable": true, "report_reasons": null, "author": "abdulj07", "discussion_type": null, "num_comments": 119, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1as8s52/really_uk_really/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jrdjg5ahayic1.jpeg", "subreddit_subscribers": 1339841, "created_utc": 1708090656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have experience in academia and from reading but not in industry. I only seen label shift during my internship but my internship ended before I could understand what was causing the positive label proportion to decline.\n\nHow do you folks in industry do root cause analysis of model performance decline? Is there some framework you use? How do you know when to retrain a model vs when there\u2019s a bug in the pipeline? Any framework here would help truly appreciated", "author_fullname": "t2_z1sj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do people in industry do root cause analysis when model performance degrades?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1arl1i9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708018488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have experience in academia and from reading but not in industry. I only seen label shift during my internship but my internship ended before I could understand what was causing the positive label proportion to decline.&lt;/p&gt;\n\n&lt;p&gt;How do you folks in industry do root cause analysis of model performance decline? Is there some framework you use? How do you know when to retrain a model vs when there\u2019s a bug in the pipeline? Any framework here would help truly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1arl1i9", "is_robot_indexable": true, "report_reasons": null, "author": "slimsippin", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1arl1i9/how_do_people_in_industry_do_root_cause_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1arl1i9/how_do_people_in_industry_do_root_cause_analysis/", "subreddit_subscribers": 1339841, "created_utc": 1708018488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Been watching a couple of videos and reading some articles / papers but finding it difficult to wrap my head around without spending 5+ hours and hand coding everything\n\nLet\u2019s say we\u2019re doing regression where you map a feature vector to a real number. Would conformal prediction in this setting look like this?\n\n1. Train model on training data\n2. Rank all of the absolute errors between the model prediction and the actuals for a VALIDATION set\n3. Say we want 95% prediction interval\n4. Choose the absolute error value such that 95% of absolute errors are less than or equal to that amount. Say this value is 1.5 for simplicity\n5. Now when I predict on a test set, should I just add 1.5 and subtract 1.5 to each point prediction to create my 95% prediction interval?\n\n\nAny guidance or help here would be really appreciated!!\n\nI know you can do conformal prediction for more complicated cases or even computer vision problems but would like to stick to classical regression to get an intuitive feel for it", "author_fullname": "t2_z1sj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone help explain conformal predictions in simple terms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ariwd1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708013180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been watching a couple of videos and reading some articles / papers but finding it difficult to wrap my head around without spending 5+ hours and hand coding everything&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say we\u2019re doing regression where you map a feature vector to a real number. Would conformal prediction in this setting look like this?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Train model on training data&lt;/li&gt;\n&lt;li&gt;Rank all of the absolute errors between the model prediction and the actuals for a VALIDATION set&lt;/li&gt;\n&lt;li&gt;Say we want 95% prediction interval&lt;/li&gt;\n&lt;li&gt;Choose the absolute error value such that 95% of absolute errors are less than or equal to that amount. Say this value is 1.5 for simplicity&lt;/li&gt;\n&lt;li&gt;Now when I predict on a test set, should I just add 1.5 and subtract 1.5 to each point prediction to create my 95% prediction interval?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any guidance or help here would be really appreciated!!&lt;/p&gt;\n\n&lt;p&gt;I know you can do conformal prediction for more complicated cases or even computer vision problems but would like to stick to classical regression to get an intuitive feel for it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ariwd1", "is_robot_indexable": true, "report_reasons": null, "author": "slimsippin", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ariwd1/can_someone_help_explain_conformal_predictions_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ariwd1/can_someone_help_explain_conformal_predictions_in/", "subreddit_subscribers": 1339841, "created_utc": 1708013180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI have an interesting problem I've not faced before. I have a dataset of timestamps and I need to be able to detect patterns, specifically consistent bursts of timestamp entries. This is the only column I have. I've processed the data and it seems clear that the best way to do this would be to look at the intervals between timestamps.\n\nThe challenge I'm facing is knowing what qualifies as a coherent group.\n\nFor example, \n\n\"Group 1\": 2 seconds, 2 seconds, 3 seconds, 3 seconds\n\n\"Group 2\": 2 seconds, 2 seconds, 3 seconds, 3 seconds\n\n\"Group 3\": 2 seconds, 3 seconds, 3 seconds, 2 seconds\n\n\"Group 4\": 2 seconds, 2 seconds, 1 second, 3 seconds, 2 seconds\n\n&amp;#x200B;\n\nSo, it's clear Group 1 &amp; Group 2 are essentially the same thing but: is group 3 the same? (I think so). Is group 4 the same? (I think so). But maybe I can say group 1 &amp; group 2 are really a part of a bigger group, and group 3 and group 4 another bigger group. I'm not sure how to recognize those.\n\n&amp;#x200B;\n\nI would be grateful for any pointers on how I can analyze that.\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_72auu63j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identifying patterns in timestamps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1arp1fq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Statistics", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708028313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have an interesting problem I&amp;#39;ve not faced before. I have a dataset of timestamps and I need to be able to detect patterns, specifically consistent bursts of timestamp entries. This is the only column I have. I&amp;#39;ve processed the data and it seems clear that the best way to do this would be to look at the intervals between timestamps.&lt;/p&gt;\n\n&lt;p&gt;The challenge I&amp;#39;m facing is knowing what qualifies as a coherent group.&lt;/p&gt;\n\n&lt;p&gt;For example, &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Group 1&amp;quot;: 2 seconds, 2 seconds, 3 seconds, 3 seconds&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Group 2&amp;quot;: 2 seconds, 2 seconds, 3 seconds, 3 seconds&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Group 3&amp;quot;: 2 seconds, 3 seconds, 3 seconds, 2 seconds&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Group 4&amp;quot;: 2 seconds, 2 seconds, 1 second, 3 seconds, 2 seconds&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So, it&amp;#39;s clear Group 1 &amp;amp; Group 2 are essentially the same thing but: is group 3 the same? (I think so). Is group 4 the same? (I think so). But maybe I can say group 1 &amp;amp; group 2 are really a part of a bigger group, and group 3 and group 4 another bigger group. I&amp;#39;m not sure how to recognize those.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would be grateful for any pointers on how I can analyze that.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "370e8fc0-70eb-11ee-b58a-86a96bfd3389", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#94e044", "id": "1arp1fq", "is_robot_indexable": true, "report_reasons": null, "author": "MiyagiJunior", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1arp1fq/identifying_patterns_in_timestamps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1arp1fq/identifying_patterns_in_timestamps/", "subreddit_subscribers": 1339841, "created_utc": 1708028313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm at crossroads in my current position. I'm 26, and I've been working in a data science team for the past couple of years doing a lot of BIE &amp; DE work and some light modeling. I've worked on several projects which included extracting insights from data, creating decks, presenting..etc. I've drawn attention from one of the leaders who's a fan of my soft skills and wants me to be in their team. This position change comes with a nice promotion, but at the cost of less technical work. I noticed that these positions at my work are the positions that lead to high visibility and growth at the company compared to the positions that are strictly technical. \n\nThis \"consulting\" kind of work is not something that I love like coding, but I'm okay with it. Would it make sense for me to accept this opportunity and possibly ask for some additional coding projects on the side to keep my technical skills fresh, or should I only consider data science roles that are mostly technical. I'm trying to think long-term here and for possible future roles at other companies. In your experience, what is the best route for someone in my position to take?\n\n(If it helps, my title would upgrade but would still have data science in it)", "author_fullname": "t2_119u1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I let go of my technical work to grow at my current company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1asa2by", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708094159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m at crossroads in my current position. I&amp;#39;m 26, and I&amp;#39;ve been working in a data science team for the past couple of years doing a lot of BIE &amp;amp; DE work and some light modeling. I&amp;#39;ve worked on several projects which included extracting insights from data, creating decks, presenting..etc. I&amp;#39;ve drawn attention from one of the leaders who&amp;#39;s a fan of my soft skills and wants me to be in their team. This position change comes with a nice promotion, but at the cost of less technical work. I noticed that these positions at my work are the positions that lead to high visibility and growth at the company compared to the positions that are strictly technical. &lt;/p&gt;\n\n&lt;p&gt;This &amp;quot;consulting&amp;quot; kind of work is not something that I love like coding, but I&amp;#39;m okay with it. Would it make sense for me to accept this opportunity and possibly ask for some additional coding projects on the side to keep my technical skills fresh, or should I only consider data science roles that are mostly technical. I&amp;#39;m trying to think long-term here and for possible future roles at other companies. In your experience, what is the best route for someone in my position to take?&lt;/p&gt;\n\n&lt;p&gt;(If it helps, my title would upgrade but would still have data science in it)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1asa2by", "is_robot_indexable": true, "report_reasons": null, "author": "Z_Gunner", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1asa2by/should_i_let_go_of_my_technical_work_to_grow_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1asa2by/should_i_let_go_of_my_technical_work_to_grow_at/", "subreddit_subscribers": 1339841, "created_utc": 1708094159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The\u00a0[\\#Self](https://www.linkedin.com/feed/hashtag/?keywords=self&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488)\\-[\\#RAG](https://www.linkedin.com/feed/hashtag/?keywords=rag&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488) paper\u00a0was released at the end of last year, thrilled to share that this groundbreaking model is now accessible through [LlamaIndex](https://www.linkedin.com/company/llamaindex/)'s [\\#LlamaPack](https://www.linkedin.com/feed/hashtag/?keywords=llamapack&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488).  \nCheck it out! \ud83d\udc47  \n\n\n\ud83d\ude80 More powerful than the basic RAG with:  \n\ud83d\udc10 Adaptive Retrieval  \n\ud83d\udc10 Self-Reflection  \n\n\n\ud83d\udd28 Implementation: LlamaIndex: [https://github.com/run-llama/llama-hu...](https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqa2EteXYxOEljSjBpZTYyWktiMUdma1ozQjlzZ3xBQ3Jtc0tsUGlmLTdQSzAtUk9vbFlkVTBLb2xvZ08wcC12Q0F6Tm51ZmhjOTBSa0lCaHZCc09hRDNPRGduSHNBR3owdXZtRGFHQThVbzJ2dTdBM2lDSlpIWVczSGcxZ0pQUlNaRWpXSDZYTGIwdGZ4Nk5ycXBiQQ&amp;q=https%3A%2F%2Fgithub.com%2Frun-llama%2Fllama-hub%2Fblob%2Fmain%2Fllama_hub%2Fllama_packs%2Fself_rag%2Fself_rag.ipynb%3F__s%3Domq42ucdc5dbdyl62wjm%26utm_source%3Ddrip%26utm_medium%3Demail%26utm_campaign%3DLlamaIndex%2Bnews%252C%2B2024-02-13&amp;v=6MK96ea-3LU) \n\n\ud83c\udf10 Github: [https://github.com/AkariAsai/self-rag](https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbUxPQ1o0SUliQW80TEhZRlJKUFdqTC1QRVVRd3xBQ3Jtc0tseFUxVjJZM1N0QVc0QjBMY0hrNVdoWUZ6dXJPaFE5QldySjRJVjJKRVdSTWpLUFRLcFhVT0hUZ25iNG1WR3pVaGx2bGFNYXk0MGtkejNwbjRCUkJuV0w1ME9IeDdmNVVOYk55UjBHbjhzOUpfbUpzSQ&amp;q=https%3A%2F%2Fgithub.com%2FAkariAsai%2Fself-rag&amp;v=6MK96ea-3LU)\n\n\ud83d\udcdd Paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION [https://arxiv.org/pdf/2310.11511v1.pdf](https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqa2xfVWRmalBSdk1ybXVRNWlPeG51REpJVXNnUXxBQ3Jtc0ttMDVpU0FDbU9pZS1pTzBnb1p0X1RyQXh2dmxnZF9rUE4yY0hxYWpSdDEyRVJtSDFQN3ZWSlhibHFDN1IwNGZtcWFFbkJTTWwyODM0RTNyVWFDWTRMMTZlWHh6VzlOQlZGNzRieXB2MG5helZxb3BDWQ&amp;q=https%3A%2F%2Farxiv.org%2Fpdf%2F2310.11511v1.pdf&amp;v=6MK96ea-3LU)\n\n\ud83d\udcfd\ufe0fSee detailed guide and intuitive explanation: \n\n[https://youtu.be/6MK96ea-3LU?si=pHLpu0x\\_aWNUhX8A](https://youtu.be/6MK96ea-3LU?si=pHLpu0x_aWNUhX8A)", "author_fullname": "t2_c4ul3bfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does self-RAG work (new on llamaindex)!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1arnavt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708024021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The\u00a0&lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=self&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488\"&gt;#Self&lt;/a&gt;-&lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=rag&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488\"&gt;#RAG&lt;/a&gt; paper\u00a0was released at the end of last year, thrilled to share that this groundbreaking model is now accessible through &lt;a href=\"https://www.linkedin.com/company/llamaindex/\"&gt;LlamaIndex&lt;/a&gt;&amp;#39;s &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=llamapack&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488\"&gt;#LlamaPack&lt;/a&gt;.&lt;br/&gt;\nCheck it out! \ud83d\udc47  &lt;/p&gt;\n\n&lt;p&gt;\ud83d\ude80 More powerful than the basic RAG with:&lt;br/&gt;\n\ud83d\udc10 Adaptive Retrieval&lt;br/&gt;\n\ud83d\udc10 Self-Reflection  &lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd28 Implementation: LlamaIndex: &lt;a href=\"https://www.youtube.com/redirect?event=video_description&amp;amp;redir_token=QUFFLUhqa2EteXYxOEljSjBpZTYyWktiMUdma1ozQjlzZ3xBQ3Jtc0tsUGlmLTdQSzAtUk9vbFlkVTBLb2xvZ08wcC12Q0F6Tm51ZmhjOTBSa0lCaHZCc09hRDNPRGduSHNBR3owdXZtRGFHQThVbzJ2dTdBM2lDSlpIWVczSGcxZ0pQUlNaRWpXSDZYTGIwdGZ4Nk5ycXBiQQ&amp;amp;q=https%3A%2F%2Fgithub.com%2Frun-llama%2Fllama-hub%2Fblob%2Fmain%2Fllama_hub%2Fllama_packs%2Fself_rag%2Fself_rag.ipynb%3F__s%3Domq42ucdc5dbdyl62wjm%26utm_source%3Ddrip%26utm_medium%3Demail%26utm_campaign%3DLlamaIndex%2Bnews%252C%2B2024-02-13&amp;amp;v=6MK96ea-3LU\"&gt;https://github.com/run-llama/llama-hu...&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;\ud83c\udf10 Github: &lt;a href=\"https://www.youtube.com/redirect?event=video_description&amp;amp;redir_token=QUFFLUhqbUxPQ1o0SUliQW80TEhZRlJKUFdqTC1QRVVRd3xBQ3Jtc0tseFUxVjJZM1N0QVc0QjBMY0hrNVdoWUZ6dXJPaFE5QldySjRJVjJKRVdSTWpLUFRLcFhVT0hUZ25iNG1WR3pVaGx2bGFNYXk0MGtkejNwbjRCUkJuV0w1ME9IeDdmNVVOYk55UjBHbjhzOUpfbUpzSQ&amp;amp;q=https%3A%2F%2Fgithub.com%2FAkariAsai%2Fself-rag&amp;amp;v=6MK96ea-3LU\"&gt;https://github.com/AkariAsai/self-rag&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcdd Paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION &lt;a href=\"https://www.youtube.com/redirect?event=video_description&amp;amp;redir_token=QUFFLUhqa2xfVWRmalBSdk1ybXVRNWlPeG51REpJVXNnUXxBQ3Jtc0ttMDVpU0FDbU9pZS1pTzBnb1p0X1RyQXh2dmxnZF9rUE4yY0hxYWpSdDEyRVJtSDFQN3ZWSlhibHFDN1IwNGZtcWFFbkJTTWwyODM0RTNyVWFDWTRMMTZlWHh6VzlOQlZGNzRieXB2MG5helZxb3BDWQ&amp;amp;q=https%3A%2F%2Farxiv.org%2Fpdf%2F2310.11511v1.pdf&amp;amp;v=6MK96ea-3LU\"&gt;https://arxiv.org/pdf/2310.11511v1.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcfd\ufe0fSee detailed guide and intuitive explanation: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/6MK96ea-3LU?si=pHLpu0x_aWNUhX8A\"&gt;https://youtu.be/6MK96ea-3LU?si=pHLpu0x_aWNUhX8A&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4PgIzt2dsWk0hsH_pv6fTscUBf4LNxa8vUF1zyE23u0.jpg?auto=webp&amp;s=adf334dabc58b5ccda405f20fe4d11f983c41fe9", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1arnavt", "is_robot_indexable": true, "report_reasons": null, "author": "linamagr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1arnavt/how_does_selfrag_work_new_on_llamaindex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1arnavt/how_does_selfrag_work_new_on_llamaindex/", "subreddit_subscribers": 1339841, "created_utc": 1708024021.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}