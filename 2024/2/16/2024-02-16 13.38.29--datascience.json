{"kind": "Listing", "data": {"after": null, "dist": 5, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Broadly speaking, the job of a data scientist is to use data to understand things, create value, and inform business decisions. It it *not necessarily* to implement and utilize advanced Machine Learning and Artificial Intelligence techniques. That's not to say that you can't or won't use ML/AI to inform business decisions, what I'm saying is that it's not always required to. Obviously this is going to depend on your company, their products, and role, but let's talk about a quintessential DS position at a quintessential company.\n\nI think the problem a lot of newer or prospective Data Scientists run into is that they learn all these advanced techniques and want to start using them right away. They apply them anywhere they can, kind of shoehorning them in and not having a clear idea of what it is they are even trying to accomplish in the first place. In other words, the tools lead the problem. Of course, the way it should be is that the problem leads the tools. I'm coming to find for like 50+% of the things I'm asked to do, a time series visualization, contingency tables, and histograms are sufficient to answer the question to the satisfaction of the business leaders. That's it. We're done, on to the next one. Start simple, if the simple techniques don't answer the question, then move on to the more advanced stuff. I speak from experience, of course.\n\nIn my opinion, understanding when to use simple tools vs when to break out the big guns is way harder then figuring out how to use the big guns. Even harder still is taking your findings and translating them into actual, actionable insights that a business can use. Okay, so you built a multi-layer CNN that models customer behavior? That's great, but what does the business do with it? For example, can you use it to identify customers who might buy more product with more advertising? Can you put a list of those customers on the CEO's desk? Could a simple regression model have done the same in 1/4 of the time? These are skills that take years to learn and so it's totally understandable for newer or prospective DSs to not have them. But they do not seem to be emphasized in a lot of degree programs or MOOCs. It seems to me like they just hand you a dataset and tell you what to do with it. It's great that you can use the tools they tell you to on it, but you're missing out on the identifying which tools to even use part in the first place.\n\nJust my 2c. \n\n&amp;#x200B;", "author_fullname": "t2_abhp8o9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A harsh truth about data science....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1arg0lv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 483, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 483, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708005545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Broadly speaking, the job of a data scientist is to use data to understand things, create value, and inform business decisions. It it &lt;em&gt;not necessarily&lt;/em&gt; to implement and utilize advanced Machine Learning and Artificial Intelligence techniques. That&amp;#39;s not to say that you can&amp;#39;t or won&amp;#39;t use ML/AI to inform business decisions, what I&amp;#39;m saying is that it&amp;#39;s not always required to. Obviously this is going to depend on your company, their products, and role, but let&amp;#39;s talk about a quintessential DS position at a quintessential company.&lt;/p&gt;\n\n&lt;p&gt;I think the problem a lot of newer or prospective Data Scientists run into is that they learn all these advanced techniques and want to start using them right away. They apply them anywhere they can, kind of shoehorning them in and not having a clear idea of what it is they are even trying to accomplish in the first place. In other words, the tools lead the problem. Of course, the way it should be is that the problem leads the tools. I&amp;#39;m coming to find for like 50+% of the things I&amp;#39;m asked to do, a time series visualization, contingency tables, and histograms are sufficient to answer the question to the satisfaction of the business leaders. That&amp;#39;s it. We&amp;#39;re done, on to the next one. Start simple, if the simple techniques don&amp;#39;t answer the question, then move on to the more advanced stuff. I speak from experience, of course.&lt;/p&gt;\n\n&lt;p&gt;In my opinion, understanding when to use simple tools vs when to break out the big guns is way harder then figuring out how to use the big guns. Even harder still is taking your findings and translating them into actual, actionable insights that a business can use. Okay, so you built a multi-layer CNN that models customer behavior? That&amp;#39;s great, but what does the business do with it? For example, can you use it to identify customers who might buy more product with more advertising? Can you put a list of those customers on the CEO&amp;#39;s desk? Could a simple regression model have done the same in 1/4 of the time? These are skills that take years to learn and so it&amp;#39;s totally understandable for newer or prospective DSs to not have them. But they do not seem to be emphasized in a lot of degree programs or MOOCs. It seems to me like they just hand you a dataset and tell you what to do with it. It&amp;#39;s great that you can use the tools they tell you to on it, but you&amp;#39;re missing out on the identifying which tools to even use part in the first place.&lt;/p&gt;\n\n&lt;p&gt;Just my 2c. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1arg0lv", "is_robot_indexable": true, "report_reasons": null, "author": "son_of_tv_c", "discussion_type": null, "num_comments": 100, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1arg0lv/a_harsh_truth_about_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1arg0lv/a_harsh_truth_about_data_science/", "subreddit_subscribers": 1339590, "created_utc": 1708005545.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have experience in academia and from reading but not in industry. I only seen label shift during my internship but my internship ended before I could understand what was causing the positive label proportion to decline.\n\nHow do you folks in industry do root cause analysis of model performance decline? Is there some framework you use? How do you know when to retrain a model vs when there\u2019s a bug in the pipeline? Any framework here would help truly appreciated", "author_fullname": "t2_z1sj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do people in industry do root cause analysis when model performance degrades?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1arl1i9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708018488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have experience in academia and from reading but not in industry. I only seen label shift during my internship but my internship ended before I could understand what was causing the positive label proportion to decline.&lt;/p&gt;\n\n&lt;p&gt;How do you folks in industry do root cause analysis of model performance decline? Is there some framework you use? How do you know when to retrain a model vs when there\u2019s a bug in the pipeline? Any framework here would help truly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1arl1i9", "is_robot_indexable": true, "report_reasons": null, "author": "slimsippin", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1arl1i9/how_do_people_in_industry_do_root_cause_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1arl1i9/how_do_people_in_industry_do_root_cause_analysis/", "subreddit_subscribers": 1339590, "created_utc": 1708018488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Been watching a couple of videos and reading some articles / papers but finding it difficult to wrap my head around without spending 5+ hours and hand coding everything\n\nLet\u2019s say we\u2019re doing regression where you map a feature vector to a real number. Would conformal prediction in this setting look like this?\n\n1. Train model on training data\n2. Rank all of the absolute errors between the model prediction and the actuals for a VALIDATION set\n3. Say we want 95% prediction interval\n4. Choose the absolute error value such that 95% of absolute errors are less than or equal to that amount. Say this value is 1.5 for simplicity\n5. Now when I predict on a test set, should I just add 1.5 and subtract 1.5 to each point prediction to create my 95% prediction interval?\n\n\nAny guidance or help here would be really appreciated!!\n\nI know you can do conformal prediction for more complicated cases or even computer vision problems but would like to stick to classical regression to get an intuitive feel for it", "author_fullname": "t2_z1sj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone help explain conformal predictions in simple terms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ariwd1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708013180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been watching a couple of videos and reading some articles / papers but finding it difficult to wrap my head around without spending 5+ hours and hand coding everything&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say we\u2019re doing regression where you map a feature vector to a real number. Would conformal prediction in this setting look like this?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Train model on training data&lt;/li&gt;\n&lt;li&gt;Rank all of the absolute errors between the model prediction and the actuals for a VALIDATION set&lt;/li&gt;\n&lt;li&gt;Say we want 95% prediction interval&lt;/li&gt;\n&lt;li&gt;Choose the absolute error value such that 95% of absolute errors are less than or equal to that amount. Say this value is 1.5 for simplicity&lt;/li&gt;\n&lt;li&gt;Now when I predict on a test set, should I just add 1.5 and subtract 1.5 to each point prediction to create my 95% prediction interval?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any guidance or help here would be really appreciated!!&lt;/p&gt;\n\n&lt;p&gt;I know you can do conformal prediction for more complicated cases or even computer vision problems but would like to stick to classical regression to get an intuitive feel for it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ariwd1", "is_robot_indexable": true, "report_reasons": null, "author": "slimsippin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ariwd1/can_someone_help_explain_conformal_predictions_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ariwd1/can_someone_help_explain_conformal_predictions_in/", "subreddit_subscribers": 1339590, "created_utc": 1708013180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI have an interesting problem I've not faced before. I have a dataset of timestamps and I need to be able to detect patterns, specifically consistent bursts of timestamp entries. This is the only column I have. I've processed the data and it seems clear that the best way to do this would be to look at the intervals between timestamps.\n\nThe challenge I'm facing is knowing what qualifies as a coherent group.\n\nFor example, \n\n\"Group 1\": 2 seconds, 2 seconds, 3 seconds, 3 seconds\n\n\"Group 2\": 2 seconds, 2 seconds, 3 seconds, 3 seconds\n\n\"Group 3\": 2 seconds, 3 seconds, 3 seconds, 2 seconds\n\n\"Group 4\": 2 seconds, 2 seconds, 1 second, 3 seconds, 2 seconds\n\n&amp;#x200B;\n\nSo, it's clear Group 1 &amp; Group 2 are essentially the same thing but: is group 3 the same? (I think so). Is group 4 the same? (I think so). But maybe I can say group 1 &amp; group 2 are really a part of a bigger group, and group 3 and group 4 another bigger group. I'm not sure how to recognize those.\n\n&amp;#x200B;\n\nI would be grateful for any pointers on how I can analyze that.\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_72auu63j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identifying patterns in timestamps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1arp1fq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Statistics", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708028313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have an interesting problem I&amp;#39;ve not faced before. I have a dataset of timestamps and I need to be able to detect patterns, specifically consistent bursts of timestamp entries. This is the only column I have. I&amp;#39;ve processed the data and it seems clear that the best way to do this would be to look at the intervals between timestamps.&lt;/p&gt;\n\n&lt;p&gt;The challenge I&amp;#39;m facing is knowing what qualifies as a coherent group.&lt;/p&gt;\n\n&lt;p&gt;For example, &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Group 1&amp;quot;: 2 seconds, 2 seconds, 3 seconds, 3 seconds&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Group 2&amp;quot;: 2 seconds, 2 seconds, 3 seconds, 3 seconds&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Group 3&amp;quot;: 2 seconds, 3 seconds, 3 seconds, 2 seconds&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Group 4&amp;quot;: 2 seconds, 2 seconds, 1 second, 3 seconds, 2 seconds&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So, it&amp;#39;s clear Group 1 &amp;amp; Group 2 are essentially the same thing but: is group 3 the same? (I think so). Is group 4 the same? (I think so). But maybe I can say group 1 &amp;amp; group 2 are really a part of a bigger group, and group 3 and group 4 another bigger group. I&amp;#39;m not sure how to recognize those.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would be grateful for any pointers on how I can analyze that.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "370e8fc0-70eb-11ee-b58a-86a96bfd3389", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#94e044", "id": "1arp1fq", "is_robot_indexable": true, "report_reasons": null, "author": "MiyagiJunior", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1arp1fq/identifying_patterns_in_timestamps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1arp1fq/identifying_patterns_in_timestamps/", "subreddit_subscribers": 1339590, "created_utc": 1708028313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The\u00a0[\\#Self](https://www.linkedin.com/feed/hashtag/?keywords=self&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488)\\-[\\#RAG](https://www.linkedin.com/feed/hashtag/?keywords=rag&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488) paper\u00a0was released at the end of last year, thrilled to share that this groundbreaking model is now accessible through [LlamaIndex](https://www.linkedin.com/company/llamaindex/)'s [\\#LlamaPack](https://www.linkedin.com/feed/hashtag/?keywords=llamapack&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488).  \nCheck it out! \ud83d\udc47  \n\n\n\ud83d\ude80 More powerful than the basic RAG with:  \n\ud83d\udc10 Adaptive Retrieval  \n\ud83d\udc10 Self-Reflection  \n\n\n\ud83d\udd28 Implementation: LlamaIndex: [https://github.com/run-llama/llama-hu...](https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqa2EteXYxOEljSjBpZTYyWktiMUdma1ozQjlzZ3xBQ3Jtc0tsUGlmLTdQSzAtUk9vbFlkVTBLb2xvZ08wcC12Q0F6Tm51ZmhjOTBSa0lCaHZCc09hRDNPRGduSHNBR3owdXZtRGFHQThVbzJ2dTdBM2lDSlpIWVczSGcxZ0pQUlNaRWpXSDZYTGIwdGZ4Nk5ycXBiQQ&amp;q=https%3A%2F%2Fgithub.com%2Frun-llama%2Fllama-hub%2Fblob%2Fmain%2Fllama_hub%2Fllama_packs%2Fself_rag%2Fself_rag.ipynb%3F__s%3Domq42ucdc5dbdyl62wjm%26utm_source%3Ddrip%26utm_medium%3Demail%26utm_campaign%3DLlamaIndex%2Bnews%252C%2B2024-02-13&amp;v=6MK96ea-3LU) \n\n\ud83c\udf10 Github: [https://github.com/AkariAsai/self-rag](https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbUxPQ1o0SUliQW80TEhZRlJKUFdqTC1QRVVRd3xBQ3Jtc0tseFUxVjJZM1N0QVc0QjBMY0hrNVdoWUZ6dXJPaFE5QldySjRJVjJKRVdSTWpLUFRLcFhVT0hUZ25iNG1WR3pVaGx2bGFNYXk0MGtkejNwbjRCUkJuV0w1ME9IeDdmNVVOYk55UjBHbjhzOUpfbUpzSQ&amp;q=https%3A%2F%2Fgithub.com%2FAkariAsai%2Fself-rag&amp;v=6MK96ea-3LU)\n\n\ud83d\udcdd Paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION [https://arxiv.org/pdf/2310.11511v1.pdf](https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqa2xfVWRmalBSdk1ybXVRNWlPeG51REpJVXNnUXxBQ3Jtc0ttMDVpU0FDbU9pZS1pTzBnb1p0X1RyQXh2dmxnZF9rUE4yY0hxYWpSdDEyRVJtSDFQN3ZWSlhibHFDN1IwNGZtcWFFbkJTTWwyODM0RTNyVWFDWTRMMTZlWHh6VzlOQlZGNzRieXB2MG5helZxb3BDWQ&amp;q=https%3A%2F%2Farxiv.org%2Fpdf%2F2310.11511v1.pdf&amp;v=6MK96ea-3LU)\n\n\ud83d\udcfd\ufe0fSee detailed guide and intuitive explanation: \n\n[https://youtu.be/6MK96ea-3LU?si=pHLpu0x\\_aWNUhX8A](https://youtu.be/6MK96ea-3LU?si=pHLpu0x_aWNUhX8A)", "author_fullname": "t2_c4ul3bfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does self-RAG work (new on llamaindex)!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1arnavt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708024021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The\u00a0&lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=self&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488\"&gt;#Self&lt;/a&gt;-&lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=rag&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488\"&gt;#RAG&lt;/a&gt; paper\u00a0was released at the end of last year, thrilled to share that this groundbreaking model is now accessible through &lt;a href=\"https://www.linkedin.com/company/llamaindex/\"&gt;LlamaIndex&lt;/a&gt;&amp;#39;s &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=llamapack&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7163940586230591488\"&gt;#LlamaPack&lt;/a&gt;.&lt;br/&gt;\nCheck it out! \ud83d\udc47  &lt;/p&gt;\n\n&lt;p&gt;\ud83d\ude80 More powerful than the basic RAG with:&lt;br/&gt;\n\ud83d\udc10 Adaptive Retrieval&lt;br/&gt;\n\ud83d\udc10 Self-Reflection  &lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd28 Implementation: LlamaIndex: &lt;a href=\"https://www.youtube.com/redirect?event=video_description&amp;amp;redir_token=QUFFLUhqa2EteXYxOEljSjBpZTYyWktiMUdma1ozQjlzZ3xBQ3Jtc0tsUGlmLTdQSzAtUk9vbFlkVTBLb2xvZ08wcC12Q0F6Tm51ZmhjOTBSa0lCaHZCc09hRDNPRGduSHNBR3owdXZtRGFHQThVbzJ2dTdBM2lDSlpIWVczSGcxZ0pQUlNaRWpXSDZYTGIwdGZ4Nk5ycXBiQQ&amp;amp;q=https%3A%2F%2Fgithub.com%2Frun-llama%2Fllama-hub%2Fblob%2Fmain%2Fllama_hub%2Fllama_packs%2Fself_rag%2Fself_rag.ipynb%3F__s%3Domq42ucdc5dbdyl62wjm%26utm_source%3Ddrip%26utm_medium%3Demail%26utm_campaign%3DLlamaIndex%2Bnews%252C%2B2024-02-13&amp;amp;v=6MK96ea-3LU\"&gt;https://github.com/run-llama/llama-hu...&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;\ud83c\udf10 Github: &lt;a href=\"https://www.youtube.com/redirect?event=video_description&amp;amp;redir_token=QUFFLUhqbUxPQ1o0SUliQW80TEhZRlJKUFdqTC1QRVVRd3xBQ3Jtc0tseFUxVjJZM1N0QVc0QjBMY0hrNVdoWUZ6dXJPaFE5QldySjRJVjJKRVdSTWpLUFRLcFhVT0hUZ25iNG1WR3pVaGx2bGFNYXk0MGtkejNwbjRCUkJuV0w1ME9IeDdmNVVOYk55UjBHbjhzOUpfbUpzSQ&amp;amp;q=https%3A%2F%2Fgithub.com%2FAkariAsai%2Fself-rag&amp;amp;v=6MK96ea-3LU\"&gt;https://github.com/AkariAsai/self-rag&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcdd Paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION &lt;a href=\"https://www.youtube.com/redirect?event=video_description&amp;amp;redir_token=QUFFLUhqa2xfVWRmalBSdk1ybXVRNWlPeG51REpJVXNnUXxBQ3Jtc0ttMDVpU0FDbU9pZS1pTzBnb1p0X1RyQXh2dmxnZF9rUE4yY0hxYWpSdDEyRVJtSDFQN3ZWSlhibHFDN1IwNGZtcWFFbkJTTWwyODM0RTNyVWFDWTRMMTZlWHh6VzlOQlZGNzRieXB2MG5helZxb3BDWQ&amp;amp;q=https%3A%2F%2Farxiv.org%2Fpdf%2F2310.11511v1.pdf&amp;amp;v=6MK96ea-3LU\"&gt;https://arxiv.org/pdf/2310.11511v1.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcfd\ufe0fSee detailed guide and intuitive explanation: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/6MK96ea-3LU?si=pHLpu0x_aWNUhX8A\"&gt;https://youtu.be/6MK96ea-3LU?si=pHLpu0x_aWNUhX8A&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4PgIzt2dsWk0hsH_pv6fTscUBf4LNxa8vUF1zyE23u0.jpg?auto=webp&amp;s=adf334dabc58b5ccda405f20fe4d11f983c41fe9", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1arnavt", "is_robot_indexable": true, "report_reasons": null, "author": "linamagr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1arnavt/how_does_selfrag_work_new_on_llamaindex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1arnavt/how_does_selfrag_work_new_on_llamaindex/", "subreddit_subscribers": 1339590, "created_utc": 1708024021.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}