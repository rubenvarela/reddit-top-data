{"kind": "Listing", "data": {"after": "t3_1anbvfi", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Found this one on my parts bin, I don't recall where it came from, but I'm sure I installed some of these when these were considered big disks.", "author_fullname": "t2_wcmls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel old", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1an9sbo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Yztoj3C1nsQS1h_Wzvrc5FDJUZyMor57sNok3RYQMHo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707545969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found this one on my parts bin, I don&amp;#39;t recall where it came from, but I&amp;#39;m sure I installed some of these when these were considered big disks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/nfe2ubiuaphc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/nfe2ubiuaphc1.jpeg?auto=webp&amp;s=b859bd4d27df2295fe2d0eb8be50febdccfcc9ca", "width": 3000, "height": 4000}, "resolutions": [{"url": "https://preview.redd.it/nfe2ubiuaphc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9c0825a11b20889fd1d5cf6d9147bd14cd8f4cf", "width": 108, "height": 144}, {"url": "https://preview.redd.it/nfe2ubiuaphc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4718304591de17b1a2a62c015d8cd98f55b0abe3", "width": 216, "height": 288}, {"url": "https://preview.redd.it/nfe2ubiuaphc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6b5cf66a518eed38ed5a95e536ec02bdbd4d7009", "width": 320, "height": 426}, {"url": "https://preview.redd.it/nfe2ubiuaphc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b98e2a65601e22041579d2a5217e0b03091af10", "width": 640, "height": 853}, {"url": "https://preview.redd.it/nfe2ubiuaphc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=54b83f85f04fb9a8871d9a27ba8ce1ad4adff983", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/nfe2ubiuaphc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9cbddc6818032d6cd27346e4740597c2e41f2d83", "width": 1080, "height": 1440}], "variants": {}, "id": "TslvEJbwjy8yqwv6FIz5HRjfwl4b6FViC7OmG8qukrs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1an9sbo", "is_robot_indexable": true, "report_reasons": null, "author": "ZeeroMX", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an9sbo/i_feel_old/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/nfe2ubiuaphc1.jpeg", "subreddit_subscribers": 732058, "created_utc": 1707545969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long time listener, first time caller.\n\nMy home backup setup was originally just copying stuff to external USB drives on a monthly basis, then I found an LTO6 drive and got a decent deal on 100 LTO5 tapes a couple of years back. Both worked great, but managing that many tapes was a bit of a pain.\n\nGot this within the last week. HP MSL 8096, now fully loaded with the tapes, giving me 144TB capacity. It came with LTO3 drives, but I found an LTO6 FC drive for a decent price (about \u00a3230). Was pleasantly surprised at how little noise it makes and how little power it uses at idle (just a shade under 40W). It keeps all the tapes warm too at a pleasant 20 degrees.\n\nJust waiting on a new FC card for my backup server (the current one causes ESXi to PSOD) and I\u2019ll be able to run regular backups without trying to keep boxes of tapes organised in sets\u2026", "author_fullname": "t2_1uqw6r1q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Joining the backup club\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yjlaua2zeqhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/yjlaua2zeqhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bd22fe57996da11ec12de2e2e52e5f151945e0c0"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/yjlaua2zeqhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d11a0975a03dce3e1f00682be639237f6ee917e8"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/yjlaua2zeqhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c47233021d9addf63ea3016306e9b4e04829bf6c"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/yjlaua2zeqhc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c08b337ea7228930c5c3cec33335147444651af"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/yjlaua2zeqhc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=987ef150e07d6f813495dcc9260bc80af4c3bf20"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/yjlaua2zeqhc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=559e334ba71290cb31afa02908bc8c62347babb3"}], "s": {"y": 4284, "x": 5712, "u": "https://preview.redd.it/yjlaua2zeqhc1.jpg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=f559ae0f7bbd5e692cd0c75f18f02c714a14416a"}, "id": "yjlaua2zeqhc1"}, "1548ob2zeqhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/1548ob2zeqhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9326971b7ede4fce67dbe81445c59e7cf74eba5"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/1548ob2zeqhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a29552d5feabebe41e021c2502b87e919ec0eb8"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/1548ob2zeqhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d3bd6cdca6624a7add7d8ce4d9bb4585ac51c387"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/1548ob2zeqhc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d15337de9fd16cdcc2c7c7de6633a14ea19f61b1"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/1548ob2zeqhc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b4788c395e237e6f0714f937eca87c4cfcc3f33a"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/1548ob2zeqhc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=424bbdb21597454784a08d561e1af399e87546f3"}], "s": {"y": 4284, "x": 5712, "u": "https://preview.redd.it/1548ob2zeqhc1.jpg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=f938f7604c066aaede32dbad493364bf10e0610b"}, "id": "1548ob2zeqhc1"}, "804s3b2zeqhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/804s3b2zeqhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eab7527ace8169b24de9b0fb81770eb2e50d1ebf"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/804s3b2zeqhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=670ed5349d06f73f519f0d2b6965f7aafab8c09b"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/804s3b2zeqhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfc718d232bf60799f3182395b8b3202b298801a"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/804s3b2zeqhc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e53ed5d970a3f83b427ea73a8c2f90bcca707b62"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/804s3b2zeqhc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2b3f3b5527f2c0f559e6ca73e9e50eead8372069"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/804s3b2zeqhc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=846c6e009f80b94574423100a21ef9ab30ceed6f"}], "s": {"y": 5712, "x": 4284, "u": "https://preview.redd.it/804s3b2zeqhc1.jpg?width=4284&amp;format=pjpg&amp;auto=webp&amp;s=c73bb3cbdf3a7b5b0f1fa8bc3a617b05418ed7db"}, "id": "804s3b2zeqhc1"}}, "name": "t3_1and377", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 39, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "804s3b2zeqhc1", "id": 402937509}, {"media_id": "1548ob2zeqhc1", "id": 402937510}, {"media_id": "yjlaua2zeqhc1", "id": 402937511}]}, "link_flair_text": "Backup", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d48ohZaThsYKDdmTaSGNKG4o_kP2o6s9aSgIAk7QlxI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707559486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long time listener, first time caller.&lt;/p&gt;\n\n&lt;p&gt;My home backup setup was originally just copying stuff to external USB drives on a monthly basis, then I found an LTO6 drive and got a decent deal on 100 LTO5 tapes a couple of years back. Both worked great, but managing that many tapes was a bit of a pain.&lt;/p&gt;\n\n&lt;p&gt;Got this within the last week. HP MSL 8096, now fully loaded with the tapes, giving me 144TB capacity. It came with LTO3 drives, but I found an LTO6 FC drive for a decent price (about \u00a3230). Was pleasantly surprised at how little noise it makes and how little power it uses at idle (just a shade under 40W). It keeps all the tapes warm too at a pleasant 20 degrees.&lt;/p&gt;\n\n&lt;p&gt;Just waiting on a new FC card for my backup server (the current one causes ESXi to PSOD) and I\u2019ll be able to run regular backups without trying to keep boxes of tapes organised in sets\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1and377", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1and377", "is_robot_indexable": true, "report_reasons": null, "author": "philnucastle", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1and377/joining_the_backup_club/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1and377", "subreddit_subscribers": 732058, "created_utc": 1707559486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 8x8TB used enterprise drives that only store media for my Plex server. I'm wondering if  there's any real point in maintaining a snapRAID solution if all my filles (32TB at the moment) stay uploaded to Backblaze and can be restored any time. While I understand the basic benefits of RAID, it seems like having a cloud backup would alleviate the need for it. I'd like to be able to use all 64TB of storage from my drives rather than only having 48TB after 2 drives are used for parity.\n\nDoes this line of thinking make sense? If all my files are backed up and recoverable at any time, do I really need RAID?", "author_fullname": "t2_l1ud2si", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I still 'need' RAID if I have a continuous cloud backup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1amxpwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707510359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 8x8TB used enterprise drives that only store media for my Plex server. I&amp;#39;m wondering if  there&amp;#39;s any real point in maintaining a snapRAID solution if all my filles (32TB at the moment) stay uploaded to Backblaze and can be restored any time. While I understand the basic benefits of RAID, it seems like having a cloud backup would alleviate the need for it. I&amp;#39;d like to be able to use all 64TB of storage from my drives rather than only having 48TB after 2 drives are used for parity.&lt;/p&gt;\n\n&lt;p&gt;Does this line of thinking make sense? If all my files are backed up and recoverable at any time, do I really need RAID?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1amxpwf", "is_robot_indexable": true, "report_reasons": null, "author": "purpan-", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1amxpwf/do_i_still_need_raid_if_i_have_a_continuous_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1amxpwf/do_i_still_need_raid_if_i_have_a_continuous_cloud/", "subreddit_subscribers": 732058, "created_utc": 1707510359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been using Samsung's \"fit\" line of USB flashdrives for several tasks where I need a very small form factor USB drive that barely takes up more space than the port itself, these specifically: \n \nhttps://www.amazon.com/gp/product/B07D7Q41PM \n \nThey have been great so far. Reliable, good speeds, don't get too hot, and a good price. Problem is, even the 256GB are starting to become too small for a few of the projects I am using them for, and Samsung does not make a 512GB version. \n \nI tried looking up others, and the only ones I found were by Sandisk, PNY, and Teamgroup. I have no experience with Teamgroup but I have had poor experiences with Sandisk and PNY's flashdrives before. And from reading the reviews on Amazon, I don't appear to be alone in that. On top of both the PNY and Samsung ones apparently being prone to having the casing break, they also run very hot... especially the Sandisk which has apparently burned out some USB ports. They are also slow if the screenshots of CrystalDiskMark in the reviews are anything to go by. I am not expecting NVME speeds, but they are much slower than my current Samsung drives (Many of the user screenshots showed a laughably slow random 4K speed of around 0.01-0.02MBs, my Samsung 256GB drive does around 8.5-9MBs), especially at random 4K writes (and the PNY one is pricy to boot). Considering that I will be handling multiple files that are several gigs and I will need to transfer my 256GB drive to the 512GB one when I get it, these are worrying concerns. \n \nI know these are cheaper USB flash drives and not NVMEs, but some of these are laughably slow while apparently becoming too hot to touch and a threat to your system from the heat if you use them a lot. \n \nI tried to bite the bullet and look for non-slim full size USB drives... but it was mostly the same vendors. Samsung apparently does not even make a full size 512GB drive. The only additional vendor was Micro Center of all things which I am sure is just a rebranded one, and it's advertised speeds are even slower (though in some user tests in CrystalDiskMark tests it was much faster??? But still just barely hitting 1MB/s in 4K random). There are Gen2 drives... but those are mostly USB-C only and expensive, and most of the ports I will be plugging them into are just going to be Gen 1 anyway, as well as USB-A. \n \nAre there no options for a decent 512GB flashdrive? Especially a slim/Fit style one? Surprised Samsung is not making any considering their 256GB slim one, the highest capacity they offer, is a mere $20 now.", "author_fullname": "t2_9njdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there no good options for a 512GB flashdrive? Especially a small form factor one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1amt6q9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707498825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using Samsung&amp;#39;s &amp;quot;fit&amp;quot; line of USB flashdrives for several tasks where I need a very small form factor USB drive that barely takes up more space than the port itself, these specifically: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/product/B07D7Q41PM\"&gt;https://www.amazon.com/gp/product/B07D7Q41PM&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;They have been great so far. Reliable, good speeds, don&amp;#39;t get too hot, and a good price. Problem is, even the 256GB are starting to become too small for a few of the projects I am using them for, and Samsung does not make a 512GB version. &lt;/p&gt;\n\n&lt;p&gt;I tried looking up others, and the only ones I found were by Sandisk, PNY, and Teamgroup. I have no experience with Teamgroup but I have had poor experiences with Sandisk and PNY&amp;#39;s flashdrives before. And from reading the reviews on Amazon, I don&amp;#39;t appear to be alone in that. On top of both the PNY and Samsung ones apparently being prone to having the casing break, they also run very hot... especially the Sandisk which has apparently burned out some USB ports. They are also slow if the screenshots of CrystalDiskMark in the reviews are anything to go by. I am not expecting NVME speeds, but they are much slower than my current Samsung drives (Many of the user screenshots showed a laughably slow random 4K speed of around 0.01-0.02MBs, my Samsung 256GB drive does around 8.5-9MBs), especially at random 4K writes (and the PNY one is pricy to boot). Considering that I will be handling multiple files that are several gigs and I will need to transfer my 256GB drive to the 512GB one when I get it, these are worrying concerns. &lt;/p&gt;\n\n&lt;p&gt;I know these are cheaper USB flash drives and not NVMEs, but some of these are laughably slow while apparently becoming too hot to touch and a threat to your system from the heat if you use them a lot. &lt;/p&gt;\n\n&lt;p&gt;I tried to bite the bullet and look for non-slim full size USB drives... but it was mostly the same vendors. Samsung apparently does not even make a full size 512GB drive. The only additional vendor was Micro Center of all things which I am sure is just a rebranded one, and it&amp;#39;s advertised speeds are even slower (though in some user tests in CrystalDiskMark tests it was much faster??? But still just barely hitting 1MB/s in 4K random). There are Gen2 drives... but those are mostly USB-C only and expensive, and most of the ports I will be plugging them into are just going to be Gen 1 anyway, as well as USB-A. &lt;/p&gt;\n\n&lt;p&gt;Are there no options for a decent 512GB flashdrive? Especially a slim/Fit style one? Surprised Samsung is not making any considering their 256GB slim one, the highest capacity they offer, is a mere $20 now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1amt6q9", "is_robot_indexable": true, "report_reasons": null, "author": "Cyber_Akuma", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1amt6q9/are_there_no_good_options_for_a_512gb_flashdrive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1amt6q9/are_there_no_good_options_for_a_512gb_flashdrive/", "subreddit_subscribers": 732058, "created_utc": 1707498825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "  Hi guys. I\u2019m new here. I\u2019m not sure if this is the right place for me to submit problem but I doubt any other communities can do this. \n\n  I have a daily diary written from 2009 till today. Now it has 5499 entries and about 2 million words also I put every pic from that day into the entry so it\u2019s extra large. \n\nI used to use a blog to post the diaries with pics but it kept getting modified by the website. So I changed into using day one journal and that\u2019s what I\u2019m using now but the change cost me all the pics from the blog. I don\u2019t know how to put years of pics back into the entries now. As the size grows the the app lag is getting way worse. The pics and vids I got in day one for 2 yrs is already 70 gb. 70gb of 50 kb kind of memes is no joke and I still want to put back the missing yrs from backup. I think I should change it to another form now. Is there a better way to write the diaries with pics and vids with auto backup preferably onto the cloud?  \n\n  I used to use html but the files are really fragmented. I do like pdf but it gets unstable too with big size. Also html viewer and all pdf viewers except acrobat crashes if loading the huge single. Is there a better way to view them than a laggy app or a huge pdf? There have to be more efficient ways for it. \n\n  Is there a way to put the pics from my photo backup with possible correct modify date back into the current diary? The diary\u2019s dates are weird. Since I always write before I sleep the date could +1 since it have passed 0 am. Is there a way to put the pics automatically to the correct entry?..\n\nAlso is there a way to let Ai study the diary so I can ask about the things happened in the past? \n\n  Sorry. It\u2019s a lot. Any answer or suggestion are  good. Thanks guys.", "author_fullname": "t2_fnugd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A 15-years-old daily diary storage problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1an4706", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707527697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys. I\u2019m new here. I\u2019m not sure if this is the right place for me to submit problem but I doubt any other communities can do this. &lt;/p&gt;\n\n&lt;p&gt;I have a daily diary written from 2009 till today. Now it has 5499 entries and about 2 million words also I put every pic from that day into the entry so it\u2019s extra large. &lt;/p&gt;\n\n&lt;p&gt;I used to use a blog to post the diaries with pics but it kept getting modified by the website. So I changed into using day one journal and that\u2019s what I\u2019m using now but the change cost me all the pics from the blog. I don\u2019t know how to put years of pics back into the entries now. As the size grows the the app lag is getting way worse. The pics and vids I got in day one for 2 yrs is already 70 gb. 70gb of 50 kb kind of memes is no joke and I still want to put back the missing yrs from backup. I think I should change it to another form now. Is there a better way to write the diaries with pics and vids with auto backup preferably onto the cloud?  &lt;/p&gt;\n\n&lt;p&gt;I used to use html but the files are really fragmented. I do like pdf but it gets unstable too with big size. Also html viewer and all pdf viewers except acrobat crashes if loading the huge single. Is there a better way to view them than a laggy app or a huge pdf? There have to be more efficient ways for it. &lt;/p&gt;\n\n&lt;p&gt;Is there a way to put the pics from my photo backup with possible correct modify date back into the current diary? The diary\u2019s dates are weird. Since I always write before I sleep the date could +1 since it have passed 0 am. Is there a way to put the pics automatically to the correct entry?..&lt;/p&gt;\n\n&lt;p&gt;Also is there a way to let Ai study the diary so I can ask about the things happened in the past? &lt;/p&gt;\n\n&lt;p&gt;Sorry. It\u2019s a lot. Any answer or suggestion are  good. Thanks guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1an4706", "is_robot_indexable": true, "report_reasons": null, "author": "daylightss", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an4706/a_15yearsold_daily_diary_storage_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1an4706/a_15yearsold_daily_diary_storage_problem/", "subreddit_subscribers": 732058, "created_utc": 1707527697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My whole life ive been hoarding trough torrents (mostly its one private tracker that i am using), but heard about this usenet. Is it still relevant as a hoarders source in 2024? I have always perceived usenet as an invite-only elite club, i dont even have any idea how to access it.", "author_fullname": "t2_gww3b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Usenet still a thing? How to get there?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anc27i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707555172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My whole life ive been hoarding trough torrents (mostly its one private tracker that i am using), but heard about this usenet. Is it still relevant as a hoarders source in 2024? I have always perceived usenet as an invite-only elite club, i dont even have any idea how to access it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anc27i", "is_robot_indexable": true, "report_reasons": null, "author": "rudeer_poke", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anc27i/usenet_still_a_thing_how_to_get_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anc27i/usenet_still_a_thing_how_to_get_there/", "subreddit_subscribers": 732058, "created_utc": 1707555172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5gdb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "What do you think about data rotting on NVME and SSD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 116, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hy8no1k67qhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/hy8no1k67qhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2bcb86349efff0ea5db3b5748bd4f4f4c61c4851"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/hy8no1k67qhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b141d1a32dd09e7bc1c19f06f4c3201b36e69f8"}, {"y": 160, "x": 320, "u": "https://preview.redd.it/hy8no1k67qhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3773d1ed9aada0b14b15d93bbc4aa8efe0380dc9"}, {"y": 320, "x": 640, "u": "https://preview.redd.it/hy8no1k67qhc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36fa9a9522de894a670aaa4b2fe21cc9fd8395e8"}], "s": {"y": 400, "x": 800, "u": "https://preview.redd.it/hy8no1k67qhc1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=0f1bf404e950aaabd6a40a7ceaa2873f8a6144f6"}, "id": "hy8no1k67qhc1"}, "lkv971k67qhc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 90, "x": 108, "u": "https://preview.redd.it/lkv971k67qhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a6e41bb605762755734e1fc841a856c4db1631a8"}, {"y": 180, "x": 216, "u": "https://preview.redd.it/lkv971k67qhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f5ab05c56dfb8e57868e445c6547b6fefe00dd9"}, {"y": 266, "x": 320, "u": "https://preview.redd.it/lkv971k67qhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ce289559f7f2b00aa4546fb01567d3c76ca4eac7"}, {"y": 533, "x": 640, "u": "https://preview.redd.it/lkv971k67qhc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=728e5195e1f3898d55abd6e37d82f09a1a636f3f"}], "s": {"y": 667, "x": 800, "u": "https://preview.redd.it/lkv971k67qhc1.png?width=800&amp;format=png&amp;auto=webp&amp;s=15e6e0fed5c12e937826f35259ef7db62ac540ac"}, "id": "lkv971k67qhc1"}, "fwcfc3k67qhc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 90, "x": 108, "u": "https://preview.redd.it/fwcfc3k67qhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7956144918af3f55ab12e24ffd34afef21ba5c94"}, {"y": 180, "x": 216, "u": "https://preview.redd.it/fwcfc3k67qhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=93439b7f5f5c4d129e5d62b3eb1dc5eef03dbf54"}, {"y": 266, "x": 320, "u": "https://preview.redd.it/fwcfc3k67qhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c8c8822b145b3d3a4c74665878140cda09e62985"}, {"y": 533, "x": 640, "u": "https://preview.redd.it/fwcfc3k67qhc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=50d8b23e880b75439de75f61fd470594d58965ea"}], "s": {"y": 667, "x": 800, "u": "https://preview.redd.it/fwcfc3k67qhc1.png?width=800&amp;format=png&amp;auto=webp&amp;s=e113bfa2ce4a2851c48c8a7c2ebba1127d9099bc"}, "id": "fwcfc3k67qhc1"}, "66mzv2k67qhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 96, "x": 108, "u": "https://preview.redd.it/66mzv2k67qhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0bb1d2a592a5435a99d0fbf0b6232538d054c176"}, {"y": 193, "x": 216, "u": "https://preview.redd.it/66mzv2k67qhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ccdff258d3eb94be528dfe4167573527ac80247"}, {"y": 287, "x": 320, "u": "https://preview.redd.it/66mzv2k67qhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=85ea6d3b7284b4d8dab626dd6e5fe38644737deb"}], "s": {"y": 514, "x": 573, "u": "https://preview.redd.it/66mzv2k67qhc1.jpg?width=573&amp;format=pjpg&amp;auto=webp&amp;s=58f21f7432923b0c56731965a1606c0239339995"}, "id": "66mzv2k67qhc1"}, "lavpi2k67qhc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 95, "x": 108, "u": "https://preview.redd.it/lavpi2k67qhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea3307521400a78ebbde43e6bbec73baa940edf7"}, {"y": 191, "x": 216, "u": "https://preview.redd.it/lavpi2k67qhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=14834313cb730732eb8025a2bb8aff7fcbfd0d71"}, {"y": 283, "x": 320, "u": "https://preview.redd.it/lavpi2k67qhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fea1ca1109631a1b491affe233dd3af3c225c069"}, {"y": 567, "x": 640, "u": "https://preview.redd.it/lavpi2k67qhc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3fe8919da36a882300c21336e522f1a481738648"}], "s": {"y": 650, "x": 733, "u": "https://preview.redd.it/lavpi2k67qhc1.png?width=733&amp;format=png&amp;auto=webp&amp;s=64dd36d68a2644da8bf99dd546e8972fa150c2e9"}, "id": "lavpi2k67qhc1"}, "5syk92k67qhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/5syk92k67qhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=20c1f8e296f04f1c911d1165a66a3fa94d12402d"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/5syk92k67qhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a49ebf68a16eabf490fa43fc3b6d30eb24004ee7"}, {"y": 160, "x": 320, "u": "https://preview.redd.it/5syk92k67qhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7bf60803856cd68c524a5f4f4e33fec4920d3c1c"}, {"y": 320, "x": 640, "u": "https://preview.redd.it/5syk92k67qhc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ab202830baafb434a87d7428df0cad388db8236"}], "s": {"y": 400, "x": 800, "u": "https://preview.redd.it/5syk92k67qhc1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=ef95bc9fd24eb1f2f69fcf18c98d48e8a5ea48e9"}, "id": "5syk92k67qhc1"}}, "name": "t3_1ancij4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Freshly written data to NVME are fast to read. But over few months to year they gradually slower to read. When you refresh them it is fast again.", "media_id": "lkv971k67qhc1", "id": 402927832}, {"media_id": "fwcfc3k67qhc1", "id": 402927833}, {"media_id": "66mzv2k67qhc1", "id": 402927834}, {"media_id": "lavpi2k67qhc1", "id": 402927835}, {"media_id": "hy8no1k67qhc1", "id": 402927836}, {"media_id": "5syk92k67qhc1", "id": 402927837}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ic73cd8AqhyN8AHOnvvthrL8qtdzT4G4kGE0W1r_HKY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707557053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1ancij4", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ancij4", "is_robot_indexable": true, "report_reasons": null, "author": "nou_spiro", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ancij4/what_do_you_think_about_data_rotting_on_nvme_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1ancij4", "subreddit_subscribers": 732058, "created_utc": 1707557053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_u9ej52y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't really understand why, but I get faster speeds using syncthing than I do using FTP/SFTP/SMB.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "name": "t3_1an363s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4frvLXmGGGP-nLWoWzAZ-5Lm4NxZFMsuxx0Phv99meE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707524761.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/26b9d4fsjnhc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/26b9d4fsjnhc1.jpeg?auto=webp&amp;s=96943f9a60318ee3d8313af48846e99e5079407b", "width": 1080, "height": 490}, "resolutions": [{"url": "https://preview.redd.it/26b9d4fsjnhc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d23636fcfbe8746042ec2c2ebd37e97c7896e1ab", "width": 108, "height": 49}, {"url": "https://preview.redd.it/26b9d4fsjnhc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fa8d0740953c24cdff97a49a1c10f6aa0ccfb040", "width": 216, "height": 98}, {"url": "https://preview.redd.it/26b9d4fsjnhc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e04d55c7c1a78d5b9c306a8ef26f727e4f57140", "width": 320, "height": 145}, {"url": "https://preview.redd.it/26b9d4fsjnhc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fba8e5ae8a58eea48251c2812f317b3984a75ae9", "width": 640, "height": 290}, {"url": "https://preview.redd.it/26b9d4fsjnhc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=62717d21b365964d7d4b69523e6f43f81bdcd798", "width": 960, "height": 435}, {"url": "https://preview.redd.it/26b9d4fsjnhc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=06836acd01acb4708d0c4f81a8751728bd8dce69", "width": 1080, "height": 490}], "variants": {}, "id": "eQRKltrUctnOP5uMGVuI06uum3w4k_UBJu4y2VUU2Io"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1an363s", "is_robot_indexable": true, "report_reasons": null, "author": "lostinthesauceband", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an363s/i_dont_really_understand_why_but_i_get_faster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/26b9d4fsjnhc1.jpeg", "subreddit_subscribers": 732058, "created_utc": 1707524761.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "At this point, I\u2019ve collected a few terabytes of files that I\u2019d love to share with the world. It\u2019s not a lot, but maybe others will find it useful one day. The problem is that I don\u2019t really know if there are cheap and safe ways for me to do this. Is torrenting the only solution?", "author_fullname": "t2_179jmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I share my collection?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1an6vnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707535951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At this point, I\u2019ve collected a few terabytes of files that I\u2019d love to share with the world. It\u2019s not a lot, but maybe others will find it useful one day. The problem is that I don\u2019t really know if there are cheap and safe ways for me to do this. Is torrenting the only solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1an6vnq", "is_robot_indexable": true, "report_reasons": null, "author": "88sSSSs88", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an6vnq/how_do_i_share_my_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1an6vnq/how_do_i_share_my_collection/", "subreddit_subscribers": 732058, "created_utc": 1707535951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m looking at an 8 drive enclosure and the manual, reviews, and pictures all show different maximum storage sizes. Before buying I want to be sure it can accommodate 22tb drives.", "author_fullname": "t2_asbwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do multi-drive enclosures have a maximum storage size?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1amqbfu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707491523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking at an 8 drive enclosure and the manual, reviews, and pictures all show different maximum storage sizes. Before buying I want to be sure it can accommodate 22tb drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1amqbfu", "is_robot_indexable": true, "report_reasons": null, "author": "godis1coolguy", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1amqbfu/do_multidrive_enclosures_have_a_maximum_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1amqbfu/do_multidrive_enclosures_have_a_maximum_storage/", "subreddit_subscribers": 732058, "created_utc": 1707491523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just had another one drop offline at the office.\n\nBetween home and work we've now lost 9 of 21 Seagate Exos drives that have been purchased from them.  X14, X16, and X18 series drives that were all supposedly new that have died (dozens to thousands of Reallocated Sectors within anywhere from 24hrs to 30 days of use.\n\nI' started running an UnRAID Pre-clear on any drive I got from them as well as their replacements and the results haven't been encouraging to say the least.\n\nWhile they have a 5-year warranty I'm just sick and tired of having to use it and constantly having array's in degraded mode due to drive failures plus the hassle of sending them back for replacement and then starting the testing procedure over again once I receive the replacement.\n\nThe last replacement I got was DOA.  It'd spin up, make a few not right sounding clicks, and then shut off.  I tried it in a couple of machines including my server and a PC with the same results.\n\nToday I was copying a few hundred GB of files to a drive and it gave up the ghost.  I'll have to go into the office to see if it shows any signs of life, however, I'm not hopeful.", "author_fullname": "t2_k35qoa9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I the only one that's had horrible luck with \"New\" Exos drives from GoHardDrive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1an0ke3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707517766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just had another one drop offline at the office.&lt;/p&gt;\n\n&lt;p&gt;Between home and work we&amp;#39;ve now lost 9 of 21 Seagate Exos drives that have been purchased from them.  X14, X16, and X18 series drives that were all supposedly new that have died (dozens to thousands of Reallocated Sectors within anywhere from 24hrs to 30 days of use.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39; started running an UnRAID Pre-clear on any drive I got from them as well as their replacements and the results haven&amp;#39;t been encouraging to say the least.&lt;/p&gt;\n\n&lt;p&gt;While they have a 5-year warranty I&amp;#39;m just sick and tired of having to use it and constantly having array&amp;#39;s in degraded mode due to drive failures plus the hassle of sending them back for replacement and then starting the testing procedure over again once I receive the replacement.&lt;/p&gt;\n\n&lt;p&gt;The last replacement I got was DOA.  It&amp;#39;d spin up, make a few not right sounding clicks, and then shut off.  I tried it in a couple of machines including my server and a PC with the same results.&lt;/p&gt;\n\n&lt;p&gt;Today I was copying a few hundred GB of files to a drive and it gave up the ghost.  I&amp;#39;ll have to go into the office to see if it shows any signs of life, however, I&amp;#39;m not hopeful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1an0ke3", "is_robot_indexable": true, "report_reasons": null, "author": "Firestarter321", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an0ke3/am_i_the_only_one_thats_had_horrible_luck_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1an0ke3/am_i_the_only_one_thats_had_horrible_luck_with/", "subreddit_subscribers": 732058, "created_utc": 1707517766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI was wondering how I could re-use my 8 (4x1To + 4x500GB) drives 2.5\" like in a cheap bay or something like that, I don't want to use them one by one by connecting to my computer.\n\nhttps://preview.redd.it/uz75yz9p0nhc1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=3c81620ec4c56e50e0872d2e42c4565cb2a995f0\n\nMy main computer is fully used and I've already managed to re-use my M2 sata SSD : \n\nhttps://preview.redd.it/4qdlceos0nhc1.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=741ef60b972f325ddcbc4ff83a825e613e9356c8\n\nhttps://preview.redd.it/qsdptjqe0nhc1.png?width=517&amp;format=png&amp;auto=webp&amp;s=761b4c3d613ed3d1af5986bd134f713a509ab5fb", "author_fullname": "t2_268ftf9k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most Effective way to re-use 8 drives 2.5\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4qdlceos0nhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 123, "x": 108, "u": "https://preview.redd.it/4qdlceos0nhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=798198e4a98e4b6429dd815589b322a1b449ce37"}, {"y": 246, "x": 216, "u": "https://preview.redd.it/4qdlceos0nhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=91dbe3b5993c2a8fe682512dc374b9d8805ee0fe"}, {"y": 364, "x": 320, "u": "https://preview.redd.it/4qdlceos0nhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ff6260d1cc10fd89fba77b6a31a262c383d4122"}, {"y": 729, "x": 640, "u": "https://preview.redd.it/4qdlceos0nhc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=181e2bf6d38177831106d89d1c9f7b3cf851de1a"}, {"y": 1094, "x": 960, "u": "https://preview.redd.it/4qdlceos0nhc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=410eacf525e45382ada7e295237760064a708f03"}, {"y": 1231, "x": 1080, "u": "https://preview.redd.it/4qdlceos0nhc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=075faeae0d3fe5cd862282a2a4e8e6f65439dd68"}], "s": {"y": 1231, "x": 1080, "u": "https://preview.redd.it/4qdlceos0nhc1.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=741ef60b972f325ddcbc4ff83a825e613e9356c8"}, "id": "4qdlceos0nhc1"}, "qsdptjqe0nhc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/qsdptjqe0nhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=29bcaa05c414420fe64062778b7d4d627c91e403"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/qsdptjqe0nhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d6014fe7d9ff695d7a98deb630c9487a792eaf77"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/qsdptjqe0nhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=368d3ee90379ef1ac9310d966442c60d1577299c"}], "s": {"y": 288, "x": 517, "u": "https://preview.redd.it/qsdptjqe0nhc1.png?width=517&amp;format=png&amp;auto=webp&amp;s=761b4c3d613ed3d1af5986bd134f713a509ab5fb"}, "id": "qsdptjqe0nhc1"}, "uz75yz9p0nhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/uz75yz9p0nhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85a4cc5a8618a683a39aa5f019a3a9b14684d0e1"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/uz75yz9p0nhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3c23e768950e2a84835724218807b767c1de2233"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/uz75yz9p0nhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ac13b45a390e7ffaf53b86cd6680e4918841d6f"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/uz75yz9p0nhc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a22413e9820b0c06b207b767eef3ce3a5870a750"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/uz75yz9p0nhc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a9a8812e1004a84384c38f42b24ec4d8fe648ba0"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/uz75yz9p0nhc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d1a9c8c603191bae0708118580f325fc5a928940"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/uz75yz9p0nhc1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=3c81620ec4c56e50e0872d2e42c4565cb2a995f0"}, "id": "uz75yz9p0nhc1"}}, "name": "t3_1an0u9f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Zb3M-FHquEpwg3BMuUl4ZVMIYJCEXbN5KsKdmKiCs4g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707518479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I was wondering how I could re-use my 8 (4x1To + 4x500GB) drives 2.5&amp;quot; like in a cheap bay or something like that, I don&amp;#39;t want to use them one by one by connecting to my computer.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uz75yz9p0nhc1.jpg?width=3024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=3c81620ec4c56e50e0872d2e42c4565cb2a995f0\"&gt;https://preview.redd.it/uz75yz9p0nhc1.jpg?width=3024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=3c81620ec4c56e50e0872d2e42c4565cb2a995f0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My main computer is fully used and I&amp;#39;ve already managed to re-use my M2 sata SSD : &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4qdlceos0nhc1.jpg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=741ef60b972f325ddcbc4ff83a825e613e9356c8\"&gt;https://preview.redd.it/4qdlceos0nhc1.jpg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=741ef60b972f325ddcbc4ff83a825e613e9356c8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qsdptjqe0nhc1.png?width=517&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=761b4c3d613ed3d1af5986bd134f713a509ab5fb\"&gt;https://preview.redd.it/qsdptjqe0nhc1.png?width=517&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=761b4c3d613ed3d1af5986bd134f713a509ab5fb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1an0u9f", "is_robot_indexable": true, "report_reasons": null, "author": "limonade25", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an0u9f/most_effective_way_to_reuse_8_drives_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1an0u9f/most_effective_way_to_reuse_8_drives_25/", "subreddit_subscribers": 732058, "created_utc": 1707518479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Like many hoarders i keep all my stuff backed up on my local servers but there was a recent house fire in the neighborhood and got me to thinking i would loose all my data if that happen.\n\nI do not really have any where else to store my data but my own home and i really hate the cloud. I have came across fire proof safes for HDD,SSD they are not cheap but would pay for it self if you considered how much cloud back up cost over time.\n\nI have 1TB of data i would say is priceless and another 20TB that is replaceable but would require years of work to recover.\n\nIf i where to store what i would miss the most in the cloud i would want to encrypt it and brake up the data so it's not so large of a upload.", "author_fullname": "t2_p7449tk5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "offsite data or fire proof safe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1an47ji", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707527737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like many hoarders i keep all my stuff backed up on my local servers but there was a recent house fire in the neighborhood and got me to thinking i would loose all my data if that happen.&lt;/p&gt;\n\n&lt;p&gt;I do not really have any where else to store my data but my own home and i really hate the cloud. I have came across fire proof safes for HDD,SSD they are not cheap but would pay for it self if you considered how much cloud back up cost over time.&lt;/p&gt;\n\n&lt;p&gt;I have 1TB of data i would say is priceless and another 20TB that is replaceable but would require years of work to recover.&lt;/p&gt;\n\n&lt;p&gt;If i where to store what i would miss the most in the cloud i would want to encrypt it and brake up the data so it&amp;#39;s not so large of a upload.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1an47ji", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Luck-545", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an47ji/offsite_data_or_fire_proof_safe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1an47ji/offsite_data_or_fire_proof_safe/", "subreddit_subscribers": 732058, "created_utc": 1707527737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi I;m using Mac and the hard drive is G-TECH. This drive is recently purchased. I'm backing up some files to this driver. However, I noticed that occasionally it disconnected leads to driver not ejected properly. I'm worried is this hardware issue due to the hardware? Should I buy a new one before too late or its my mac OS system", "author_fullname": "t2_5kbv9kfw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External Hard driver occasionally disconnected when open files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1an17mt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707519444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I;m using Mac and the hard drive is G-TECH. This drive is recently purchased. I&amp;#39;m backing up some files to this driver. However, I noticed that occasionally it disconnected leads to driver not ejected properly. I&amp;#39;m worried is this hardware issue due to the hardware? Should I buy a new one before too late or its my mac OS system&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1an17mt", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished-Bill-45", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an17mt/external_hard_driver_occasionally_disconnected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1an17mt/external_hard_driver_occasionally_disconnected/", "subreddit_subscribers": 732058, "created_utc": 1707519444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Forgive me if there is already a thread covering this, I will delete if so. I tried looking but you know, reddit search. Basically, I need to make backups for all of my studio files on some SSD's, and idk where to look for a reliable but economic source. I would end up spending a small fortune if I were to keep buyimg the Samsung T5/T7's from Amazon which are what I currently have. I have seen websites mentioned here before, but now that I am actively looking, I can't find them. TIA for any recommendations!", "author_fullname": "t2_d7pdqlqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Hoarding, looking for multiple TB SSD (the more space the better).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1amthvq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707499577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Forgive me if there is already a thread covering this, I will delete if so. I tried looking but you know, reddit search. Basically, I need to make backups for all of my studio files on some SSD&amp;#39;s, and idk where to look for a reliable but economic source. I would end up spending a small fortune if I were to keep buyimg the Samsung T5/T7&amp;#39;s from Amazon which are what I currently have. I have seen websites mentioned here before, but now that I am actively looking, I can&amp;#39;t find them. TIA for any recommendations!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1amthvq", "is_robot_indexable": true, "report_reasons": null, "author": "47thVision", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1amthvq/new_to_data_hoarding_looking_for_multiple_tb_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1amthvq/new_to_data_hoarding_looking_for_multiple_tb_ssd/", "subreddit_subscribers": 732058, "created_utc": 1707499577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI recently picked up some refurb exos from SPD for my array. To be fair, I've never been a huge fan of seagate after a critical fail 20 years ago, but I thought I'd give them another try. I'm running snapraid with a bash script nightly. One of the drives started reporting errors a couple of days ago. Started with 2 yesterday, and now at 13 today. I've never really had to worry about interpreting the reports because I've never had errors before, but now that I have them, I realize that I don't know how to read them.\n\n1. Which errors are they, and how do I read them in the report for future reference so I don't have to ask this question again?\n2. Should I start an RMA or let it spin?\n\nThank you for your time. Report as follows:\n\n    === START OF INFORMATION SECTION ===\n    Model Family:     Seagate Exos X16\n    Device Model:     ST16000NM001G-2KK103\n    Serial Number:    ZL22QNRM\n    LU WWN Device Id: 5 000c50 0c41bb535\n    Firmware Version: SN04\n    User Capacity:    16,000,900,661,248 bytes [16.0 TB]\n    Sector Sizes:     512 bytes logical, 4096 bytes physical\n    Rotation Rate:    7200 rpm\n    Form Factor:      3.5 inches\n    Device is:        In smartctl database [for details use: -P show]\n    ATA Version is:   ACS-4 (minor revision not indicated)\n    SATA Version is:  SATA 3.3, 6.0 Gb/s (current: 6.0 Gb/s)\n    Local Time is:    Sat Feb 10 04:34:02 2024 CST\n    SMART support is: Available - device has SMART capability.\n    SMART support is: Enabled\n    \n    === START OF READ SMART DATA SECTION ===\n    SMART overall-health self-assessment test result: PASSED\n    \n    General SMART Values:\n    Offline data collection status:  (0x82) Offline data collection activity\n                                            was completed without error.\n                                            Auto Offline Data Collection: Enabled.\n    Self-test execution status:      (   0) The previous self-test routine completed\n                                            without error or no self-test has ever\n                                            been run.\n    Total time to complete Offline\n    data collection:                (  567) seconds.\n    Offline data collection\n    capabilities:                    (0x7b) SMART execute Offline immediate.\n                                            Auto Offline data collection on/off support.\n                                            Suspend Offline collection upon new\n                                            command.\n                                            Offline surface scan supported.\n                                            Self-test supported.\n                                            Conveyance Self-test supported.\n                                            Selective Self-test supported.\n    SMART capabilities:            (0x0003) Saves SMART data before entering\n                                            power-saving mode.\n                                            Supports SMART auto save timer.\n    Error logging capability:        (0x01) Error logging supported.\n                                            General Purpose Logging supported.\n    Short self-test routine\n    recommended polling time:        (   1) minutes.\n    Extended self-test routine\n    recommended polling time:        (1415) minutes.\n    Conveyance self-test routine\n    recommended polling time:        (   2) minutes.\n    SCT capabilities:              (0x70bd) SCT Status supported.\n                                            SCT Error Recovery Control supported.\n                                            SCT Feature Control supported.\n                                            SCT Data Table supported.\n    \n    SMART Attributes Data Structure revision number: 10\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x000f   074   064   044    Pre-fail  Always       -       27047936\n      3 Spin_Up_Time            0x0003   089   089   000    Pre-fail  Always       -       0\n      4 Start_Stop_Count        0x0032   100   100   020    Old_age   Always       -       35\n      5 Reallocated_Sector_Ct   0x0033   100   100   010    Pre-fail  Always       -       40\n      7 Seek_Error_Rate         0x000f   077   061   045    Pre-fail  Always       -       49487364\n      9 Power_On_Hours          0x0032   100   100   000    Old_age   Always       -       406\n     10 Spin_Retry_Count        0x0013   100   100   097    Pre-fail  Always       -       0\n     12 Power_Cycle_Count       0x0032   100   100   020    Old_age   Always       -       7\n     18 Head_Health             0x000b   100   100   050    Pre-fail  Always       -       0\n    187 Reported_Uncorrect      0x0032   087   087   000    Old_age   Always       -       13\n    188 Command_Timeout         0x0032   100   100   000    Old_age   Always       -       0\n    190 Airflow_Temperature_Cel 0x0022   068   047   040    Old_age   Always       -       32 (Min/Max 20/32)\n    192 Power-Off_Retract_Count 0x0032   100   100   000    Old_age   Always       -       1\n    193 Load_Cycle_Count        0x0032   100   100   000    Old_age   Always       -       553\n    194 Temperature_Celsius     0x0022   032   053   000    Old_age   Always       -       32 (0 20 0 0 0)\n    197 Current_Pending_Sector  0x0012   100   100   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0010   100   100   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x003e   200   200   000    Old_age   Always       -       0\n    200 Pressure_Limit          0x0023   100   100   001    Pre-fail  Always       -       0\n    240 Head_Flying_Hours       0x0000   100   253   000    Old_age   Offline      -       215h+57m+05.227s\n    241 Total_LBAs_Written      0x0000   100   253   000    Old_age   Offline      -       30579256740\n    242 Total_LBAs_Read         0x0000   100   253   000    Old_age   Offline      -       79888687517\n    \n    SMART Error Log Version: 1\n    ATA Error Count: 13 (device log contains only the most recent five errors)\n            CR = Command Register [HEX]\n            FR = Features Register [HEX]\n            SC = Sector Count Register [HEX]\n            SN = Sector Number Register [HEX]\n            CL = Cylinder Low Register [HEX]\n            CH = Cylinder High Register [HEX]\n            DH = Device/Head Register [HEX]\n            DC = Device Command Register [HEX]\n            ER = Error register [HEX]\n            ST = Status register [HEX]\n    Powered_Up_Time is measured from power on, and printed as\n    DDd+hh:mm:SS.sss where DD=days, hh=hours, mm=minutes,\n    SS=sec, and sss=millisec. It \"wraps\" after 49.710 days.\n    \n    Error 13 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n      When the command that caused the error occurred, the device was active or idle.\n    \n      After command completion occurred, registers were:\n      ER ST SC SN CL CH DH\n      -- -- -- -- -- -- --\n      40 53 00 ff ff ff 0f  Error: UNC at LBA = 0x0fffffff = 268435455\n    \n      Commands leading to the command that caused the error were:\n      CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n      -- -- -- -- -- -- -- --  ----------------  --------------------\n      60 00 00 ff ff ff 4f 00   3d+22:18:04.309  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:18:04.309  READ FPDMA QUEUED\n      60 00 08 ff ff ff 4f 00   3d+22:18:04.295  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:18:04.295  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:18:04.295  READ FPDMA QUEUED\n    \n    Error 12 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n      When the command that caused the error occurred, the device was active or idle.\n    \n      After command completion occurred, registers were:\n      ER ST SC SN CL CH DH\n      -- -- -- -- -- -- --\n      40 53 00 ff ff ff 0f  Error: UNC at LBA = 0x0fffffff = 268435455\n    \n      Commands leading to the command that caused the error were:\n      CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n      -- -- -- -- -- -- -- --  ----------------  --------------------\n      60 00 00 ff ff ff 4f 00   3d+22:18:01.299  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:18:01.299  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:18:01.281  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:18:01.280  READ FPDMA QUEUED\n      60 00 08 ff ff ff 4f 00   3d+22:18:01.280  READ FPDMA QUEUED\n    \n    Error 11 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n      When the command that caused the error occurred, the device was active or idle.\n    \n      After command completion occurred, registers were:\n      ER ST SC SN CL CH DH\n      -- -- -- -- -- -- --\n      40 53 00 ff ff ff 0f  Error: UNC at LBA = 0x0fffffff = 268435455\n    \n      Commands leading to the command that caused the error were:\n      CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n      -- -- -- -- -- -- -- --  ----------------  --------------------\n      60 00 00 ff ff ff 4f 00   3d+22:17:49.626  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:17:49.625  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:17:49.614  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:17:49.614  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+22:17:49.614  READ FPDMA QUEUED\n    \n    Error 10 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n      When the command that caused the error occurred, the device was active or idle.\n    \n      After command completion occurred, registers were:\n      ER ST SC SN CL CH DH\n      -- -- -- -- -- -- --\n      40 53 00 ff ff ff 0f  Error: WP at LBA = 0x0fffffff = 268435455\n    \n      Commands leading to the command that caused the error were:\n      CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n      -- -- -- -- -- -- -- --  ----------------  --------------------\n      61 00 08 ff ff ff 4f 00   3d+21:55:15.094  WRITE FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+21:55:12.497  READ FPDMA QUEUED\n      60 00 38 ff ff ff 4f 00   3d+21:55:12.422  READ FPDMA QUEUED\n      60 00 08 ff ff ff 4f 00   3d+21:55:12.409  READ FPDMA QUEUED\n      60 00 08 ff ff ff 4f 00   3d+21:55:12.408  READ FPDMA QUEUED\n    \n    Error 9 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n      When the command that caused the error occurred, the device was active or idle.\n    \n      After command completion occurred, registers were:\n      ER ST SC SN CL CH DH\n      -- -- -- -- -- -- --\n      40 53 00 ff ff ff 0f  Error: UNC at LBA = 0x0fffffff = 268435455\n    \n      Commands leading to the command that caused the error were:\n      CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n      -- -- -- -- -- -- -- --  ----------------  --------------------\n      60 00 08 ff ff ff 4f 00   3d+21:55:09.476  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+21:55:09.474  READ FPDMA QUEUED\n      60 00 00 ff ff ff 4f 00   3d+21:55:09.473  READ FPDMA QUEUED\n      60 00 08 ff ff ff 4f 00   3d+21:55:09.450  READ FPDMA QUEUED\n      60 00 80 ff ff ff 4f 00   3d+21:55:09.450  READ FPDMA QUEUED\n    \n    SMART Self-test log structure revision number 1\n    Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    # 1  Short offline       Completed without error       00%         0         -\n    \n    SMART Selective self-test log data structure revision number 1\n     SPAN  MIN_LBA  MAX_LBA  CURRENT_TEST_STATUS\n        1        0        0  Not_testing\n        2        0        0  Not_testing\n        3        0        0  Not_testing\n        4        0        0  Not_testing\n        5        0        0  Not_testing\n    Selective self-test flags (0x0):\n      After scanning selected spans, do NOT read-scan remainder of disk.\n    If Selective self-test is pending on power-up, resume after 0 minute delay.\n\n&amp;#x200B;", "author_fullname": "t2_40crn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help interpreting SMART results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ando3p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707561958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I recently picked up some refurb exos from SPD for my array. To be fair, I&amp;#39;ve never been a huge fan of seagate after a critical fail 20 years ago, but I thought I&amp;#39;d give them another try. I&amp;#39;m running snapraid with a bash script nightly. One of the drives started reporting errors a couple of days ago. Started with 2 yesterday, and now at 13 today. I&amp;#39;ve never really had to worry about interpreting the reports because I&amp;#39;ve never had errors before, but now that I have them, I realize that I don&amp;#39;t know how to read them.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which errors are they, and how do I read them in the report for future reference so I don&amp;#39;t have to ask this question again?&lt;/li&gt;\n&lt;li&gt;Should I start an RMA or let it spin?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you for your time. Report as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;=== START OF INFORMATION SECTION ===\nModel Family:     Seagate Exos X16\nDevice Model:     ST16000NM001G-2KK103\nSerial Number:    ZL22QNRM\nLU WWN Device Id: 5 000c50 0c41bb535\nFirmware Version: SN04\nUser Capacity:    16,000,900,661,248 bytes [16.0 TB]\nSector Sizes:     512 bytes logical, 4096 bytes physical\nRotation Rate:    7200 rpm\nForm Factor:      3.5 inches\nDevice is:        In smartctl database [for details use: -P show]\nATA Version is:   ACS-4 (minor revision not indicated)\nSATA Version is:  SATA 3.3, 6.0 Gb/s (current: 6.0 Gb/s)\nLocal Time is:    Sat Feb 10 04:34:02 2024 CST\nSMART support is: Available - device has SMART capability.\nSMART support is: Enabled\n\n=== START OF READ SMART DATA SECTION ===\nSMART overall-health self-assessment test result: PASSED\n\nGeneral SMART Values:\nOffline data collection status:  (0x82) Offline data collection activity\n                                        was completed without error.\n                                        Auto Offline Data Collection: Enabled.\nSelf-test execution status:      (   0) The previous self-test routine completed\n                                        without error or no self-test has ever\n                                        been run.\nTotal time to complete Offline\ndata collection:                (  567) seconds.\nOffline data collection\ncapabilities:                    (0x7b) SMART execute Offline immediate.\n                                        Auto Offline data collection on/off support.\n                                        Suspend Offline collection upon new\n                                        command.\n                                        Offline surface scan supported.\n                                        Self-test supported.\n                                        Conveyance Self-test supported.\n                                        Selective Self-test supported.\nSMART capabilities:            (0x0003) Saves SMART data before entering\n                                        power-saving mode.\n                                        Supports SMART auto save timer.\nError logging capability:        (0x01) Error logging supported.\n                                        General Purpose Logging supported.\nShort self-test routine\nrecommended polling time:        (   1) minutes.\nExtended self-test routine\nrecommended polling time:        (1415) minutes.\nConveyance self-test routine\nrecommended polling time:        (   2) minutes.\nSCT capabilities:              (0x70bd) SCT Status supported.\n                                        SCT Error Recovery Control supported.\n                                        SCT Feature Control supported.\n                                        SCT Data Table supported.\n\nSMART Attributes Data Structure revision number: 10\nVendor Specific SMART Attributes with Thresholds:\nID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n  1 Raw_Read_Error_Rate     0x000f   074   064   044    Pre-fail  Always       -       27047936\n  3 Spin_Up_Time            0x0003   089   089   000    Pre-fail  Always       -       0\n  4 Start_Stop_Count        0x0032   100   100   020    Old_age   Always       -       35\n  5 Reallocated_Sector_Ct   0x0033   100   100   010    Pre-fail  Always       -       40\n  7 Seek_Error_Rate         0x000f   077   061   045    Pre-fail  Always       -       49487364\n  9 Power_On_Hours          0x0032   100   100   000    Old_age   Always       -       406\n 10 Spin_Retry_Count        0x0013   100   100   097    Pre-fail  Always       -       0\n 12 Power_Cycle_Count       0x0032   100   100   020    Old_age   Always       -       7\n 18 Head_Health             0x000b   100   100   050    Pre-fail  Always       -       0\n187 Reported_Uncorrect      0x0032   087   087   000    Old_age   Always       -       13\n188 Command_Timeout         0x0032   100   100   000    Old_age   Always       -       0\n190 Airflow_Temperature_Cel 0x0022   068   047   040    Old_age   Always       -       32 (Min/Max 20/32)\n192 Power-Off_Retract_Count 0x0032   100   100   000    Old_age   Always       -       1\n193 Load_Cycle_Count        0x0032   100   100   000    Old_age   Always       -       553\n194 Temperature_Celsius     0x0022   032   053   000    Old_age   Always       -       32 (0 20 0 0 0)\n197 Current_Pending_Sector  0x0012   100   100   000    Old_age   Always       -       0\n198 Offline_Uncorrectable   0x0010   100   100   000    Old_age   Offline      -       0\n199 UDMA_CRC_Error_Count    0x003e   200   200   000    Old_age   Always       -       0\n200 Pressure_Limit          0x0023   100   100   001    Pre-fail  Always       -       0\n240 Head_Flying_Hours       0x0000   100   253   000    Old_age   Offline      -       215h+57m+05.227s\n241 Total_LBAs_Written      0x0000   100   253   000    Old_age   Offline      -       30579256740\n242 Total_LBAs_Read         0x0000   100   253   000    Old_age   Offline      -       79888687517\n\nSMART Error Log Version: 1\nATA Error Count: 13 (device log contains only the most recent five errors)\n        CR = Command Register [HEX]\n        FR = Features Register [HEX]\n        SC = Sector Count Register [HEX]\n        SN = Sector Number Register [HEX]\n        CL = Cylinder Low Register [HEX]\n        CH = Cylinder High Register [HEX]\n        DH = Device/Head Register [HEX]\n        DC = Device Command Register [HEX]\n        ER = Error register [HEX]\n        ST = Status register [HEX]\nPowered_Up_Time is measured from power on, and printed as\nDDd+hh:mm:SS.sss where DD=days, hh=hours, mm=minutes,\nSS=sec, and sss=millisec. It &amp;quot;wraps&amp;quot; after 49.710 days.\n\nError 13 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n  When the command that caused the error occurred, the device was active or idle.\n\n  After command completion occurred, registers were:\n  ER ST SC SN CL CH DH\n  -- -- -- -- -- -- --\n  40 53 00 ff ff ff 0f  Error: UNC at LBA = 0x0fffffff = 268435455\n\n  Commands leading to the command that caused the error were:\n  CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n  -- -- -- -- -- -- -- --  ----------------  --------------------\n  60 00 00 ff ff ff 4f 00   3d+22:18:04.309  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:18:04.309  READ FPDMA QUEUED\n  60 00 08 ff ff ff 4f 00   3d+22:18:04.295  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:18:04.295  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:18:04.295  READ FPDMA QUEUED\n\nError 12 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n  When the command that caused the error occurred, the device was active or idle.\n\n  After command completion occurred, registers were:\n  ER ST SC SN CL CH DH\n  -- -- -- -- -- -- --\n  40 53 00 ff ff ff 0f  Error: UNC at LBA = 0x0fffffff = 268435455\n\n  Commands leading to the command that caused the error were:\n  CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n  -- -- -- -- -- -- -- --  ----------------  --------------------\n  60 00 00 ff ff ff 4f 00   3d+22:18:01.299  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:18:01.299  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:18:01.281  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:18:01.280  READ FPDMA QUEUED\n  60 00 08 ff ff ff 4f 00   3d+22:18:01.280  READ FPDMA QUEUED\n\nError 11 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n  When the command that caused the error occurred, the device was active or idle.\n\n  After command completion occurred, registers were:\n  ER ST SC SN CL CH DH\n  -- -- -- -- -- -- --\n  40 53 00 ff ff ff 0f  Error: UNC at LBA = 0x0fffffff = 268435455\n\n  Commands leading to the command that caused the error were:\n  CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n  -- -- -- -- -- -- -- --  ----------------  --------------------\n  60 00 00 ff ff ff 4f 00   3d+22:17:49.626  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:17:49.625  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:17:49.614  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:17:49.614  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+22:17:49.614  READ FPDMA QUEUED\n\nError 10 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n  When the command that caused the error occurred, the device was active or idle.\n\n  After command completion occurred, registers were:\n  ER ST SC SN CL CH DH\n  -- -- -- -- -- -- --\n  40 53 00 ff ff ff 0f  Error: WP at LBA = 0x0fffffff = 268435455\n\n  Commands leading to the command that caused the error were:\n  CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n  -- -- -- -- -- -- -- --  ----------------  --------------------\n  61 00 08 ff ff ff 4f 00   3d+21:55:15.094  WRITE FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+21:55:12.497  READ FPDMA QUEUED\n  60 00 38 ff ff ff 4f 00   3d+21:55:12.422  READ FPDMA QUEUED\n  60 00 08 ff ff ff 4f 00   3d+21:55:12.409  READ FPDMA QUEUED\n  60 00 08 ff ff ff 4f 00   3d+21:55:12.408  READ FPDMA QUEUED\n\nError 9 occurred at disk power-on lifetime: 405 hours (16 days + 21 hours)\n  When the command that caused the error occurred, the device was active or idle.\n\n  After command completion occurred, registers were:\n  ER ST SC SN CL CH DH\n  -- -- -- -- -- -- --\n  40 53 00 ff ff ff 0f  Error: UNC at LBA = 0x0fffffff = 268435455\n\n  Commands leading to the command that caused the error were:\n  CR FR SC SN CL CH DH DC   Powered_Up_Time  Command/Feature_Name\n  -- -- -- -- -- -- -- --  ----------------  --------------------\n  60 00 08 ff ff ff 4f 00   3d+21:55:09.476  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+21:55:09.474  READ FPDMA QUEUED\n  60 00 00 ff ff ff 4f 00   3d+21:55:09.473  READ FPDMA QUEUED\n  60 00 08 ff ff ff 4f 00   3d+21:55:09.450  READ FPDMA QUEUED\n  60 00 80 ff ff ff 4f 00   3d+21:55:09.450  READ FPDMA QUEUED\n\nSMART Self-test log structure revision number 1\nNum  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n# 1  Short offline       Completed without error       00%         0         -\n\nSMART Selective self-test log data structure revision number 1\n SPAN  MIN_LBA  MAX_LBA  CURRENT_TEST_STATUS\n    1        0        0  Not_testing\n    2        0        0  Not_testing\n    3        0        0  Not_testing\n    4        0        0  Not_testing\n    5        0        0  Not_testing\nSelective self-test flags (0x0):\n  After scanning selected spans, do NOT read-scan remainder of disk.\nIf Selective self-test is pending on power-up, resume after 0 minute delay.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ando3p", "is_robot_indexable": true, "report_reasons": null, "author": "stenzor", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ando3p/help_interpreting_smart_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ando3p/help_interpreting_smart_results/", "subreddit_subscribers": 732058, "created_utc": 1707561958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am looking for hardware recommendations for a Plex server. It should be able to transcode and maybe host a downloader. \nI think in the long term I need about 10+ TB storage and also for downloading a 512GB-1TB SSD.\nI think RAID is optional, as the data can be downloaded again.\nAlso transcoding is something I need to address.\n\nWhat do you think? I am thinking about a NAS or a diy solution, what suggestions and ideas do you have? \nOr is this rather a question for r/homelab ?!", "author_fullname": "t2_143ph6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking into scaling storage for Plex Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1andkd6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707561518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am looking for hardware recommendations for a Plex server. It should be able to transcode and maybe host a downloader. \nI think in the long term I need about 10+ TB storage and also for downloading a 512GB-1TB SSD.\nI think RAID is optional, as the data can be downloaded again.\nAlso transcoding is something I need to address.&lt;/p&gt;\n\n&lt;p&gt;What do you think? I am thinking about a NAS or a diy solution, what suggestions and ideas do you have? \nOr is this rather a question for &lt;a href=\"/r/homelab\"&gt;r/homelab&lt;/a&gt; ?!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1andkd6", "is_robot_indexable": true, "report_reasons": null, "author": "netcent_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1andkd6/looking_into_scaling_storage_for_plex_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1andkd6/looking_into_scaling_storage_for_plex_server/", "subreddit_subscribers": 732058, "created_utc": 1707561518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey i have an old cd which has some video clips from a family function on it in .dat extension. The video files can be played but cannot be copied. the transfer window just gets stuck at 0% and the cd also stops rotating (implying from the sound).\n\nAny solutions?", "author_fullname": "t2_dr4out0yz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to extract data from an old cd", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1andfq0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707560978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey i have an old cd which has some video clips from a family function on it in .dat extension. The video files can be played but cannot be copied. the transfer window just gets stuck at 0% and the cd also stops rotating (implying from the sound).&lt;/p&gt;\n\n&lt;p&gt;Any solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1andfq0", "is_robot_indexable": true, "report_reasons": null, "author": "rogue_assassin-", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1andfq0/how_to_extract_data_from_an_old_cd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1andfq0/how_to_extract_data_from_an_old_cd/", "subreddit_subscribers": 732058, "created_utc": 1707560978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As per title. I don't like Onedrive because it's super intrusive with its services and the client gets very laggy when dealing with it over time (not sure why).\n\nI'm moving away from dropbox because the mobile client is getting increasingly bad (regular crashes, sync issues where the file title will be there but the content is missing) and also because it screw up my 3rd party programs and drivers.  \n\n\nCan someone suggest an alternative to Dropbox? I've been using this program for over 7 years and am extremely out of the loop when it comes to LIGHTWEIGHT file syncing options with reasonable amounts of free space (at least 2GB)\n\nThe lightweight is super important here, I don't want to deal with extremely long upload/update times like with OneDrive.", "author_fullname": "t2_1361mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Dropbox alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ancp4m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707557838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As per title. I don&amp;#39;t like Onedrive because it&amp;#39;s super intrusive with its services and the client gets very laggy when dealing with it over time (not sure why).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m moving away from dropbox because the mobile client is getting increasingly bad (regular crashes, sync issues where the file title will be there but the content is missing) and also because it screw up my 3rd party programs and drivers.  &lt;/p&gt;\n\n&lt;p&gt;Can someone suggest an alternative to Dropbox? I&amp;#39;ve been using this program for over 7 years and am extremely out of the loop when it comes to LIGHTWEIGHT file syncing options with reasonable amounts of free space (at least 2GB)&lt;/p&gt;\n\n&lt;p&gt;The lightweight is super important here, I don&amp;#39;t want to deal with extremely long upload/update times like with OneDrive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ancp4m", "is_robot_indexable": true, "report_reasons": null, "author": "MildlyVandalized", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ancp4m/seeking_dropbox_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ancp4m/seeking_dropbox_alternative/", "subreddit_subscribers": 732058, "created_utc": 1707557838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Good deal on 5 used 16Tb Seagate Entreprise Exos. Still 3 years warranty. What do you think? Thanks!", "author_fullname": "t2_5ffslv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Second hand Seagate entreprise Exos 16Tb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1an1wv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-vuZiFH5xBXw0TStnNLT01L2Ee0ga3Icdq-iEa36Jco.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707521303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good deal on 5 used 16Tb Seagate Entreprise Exos. Still 3 years warranty. What do you think? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3v5o7x3i9nhc1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3v5o7x3i9nhc1.png?auto=webp&amp;s=2f835168ee593af8f8ee80b0b15d1b3b83eec6a8", "width": 1080, "height": 2400}, "resolutions": [{"url": "https://preview.redd.it/3v5o7x3i9nhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9ae12cd6c1cb6e4c9be01e2f606936dddb29f0f", "width": 108, "height": 216}, {"url": "https://preview.redd.it/3v5o7x3i9nhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=39b95360a800b1bca834b2d47c7529282f05fbba", "width": 216, "height": 432}, {"url": "https://preview.redd.it/3v5o7x3i9nhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ebc17c323b02d764c3591a36d9398549c70e19bf", "width": 320, "height": 640}, {"url": "https://preview.redd.it/3v5o7x3i9nhc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=809fa76fcb92eaf379b6ce9dab84f06bcc96a944", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/3v5o7x3i9nhc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c5b790b17272c98ba8480a7bb6b05fcf8f6dbf0d", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/3v5o7x3i9nhc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5f585866a14cd2a63940e96167aeb2eec1b5489e", "width": 1080, "height": 2160}], "variants": {}, "id": "pvj0cPm0P3qNCRTYxDSgLgUTt_Btna01KU1tLLpAQ40"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1an1wv5", "is_robot_indexable": true, "report_reasons": null, "author": "ElMarco19", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an1wv5/second_hand_seagate_entreprise_exos_16tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3v5o7x3i9nhc1.png", "subreddit_subscribers": 732058, "created_utc": 1707521303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am moving towards moving my data to an Asustor NAS with nvme SSDs over a 10g network as my primary storage for photo/video work. It's currently 26 TB and will probably expand a couple more drivs to 34tb soon.\n\nBackup up the NAS directly with b2 would be insanely expensive at $200 a month\n\nNow I want a local backup of this in order to backup to backblaze personal. I have a 22tb and 12tb hdd sitting around. Thinking to put these in a windows desktop and I need to sync the NAS to the local drives. It seems like stablebit drivepool would be the solution I am looking for to merge the two HDDs and simplify mirroring the NAS. Am I correct that the data on each drive would be accessible if they were read on another device or I had to restore the pc? Which drivepool settings would improve write performance with those two drives?\n\nThen I need a sync solution. I just want something that will run on the windows machine and importantly will verify  the data after copying so it isn't corrupted. I had an issue with lots of image data getting corrupted over a network transfer before I looked into stuff like teracopy so it is a concern.\n\nis freefilesync my best option for mirroring the NAS to the HDDs?  I am just uncertain about it's capabilities to verify files. It says it doesn't use checksums and verify is an expert feature\n\n\"**VerifyCopiedFiles:**If active, FreeFileSync will binary-compare source and target files after copying and report verification errors. Note that this may double file copy times and is no guarantee that data has not already been corrupted prior to copying.  \"\n\n[https://freefilesync.org/manual.php?topic=expert-settings](https://freefilesync.org/manual.php?topic=expert-settings)\n\nDoubling transfer times is concerning, is it really that slow?\n\nAny other better sync app for this that will verify file integrity?", "author_fullname": "t2_f74j8c33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for system for syncing a NAS to local HDDs in order to backup with Backblaze personal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1an0l48", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707517815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am moving towards moving my data to an Asustor NAS with nvme SSDs over a 10g network as my primary storage for photo/video work. It&amp;#39;s currently 26 TB and will probably expand a couple more drivs to 34tb soon.&lt;/p&gt;\n\n&lt;p&gt;Backup up the NAS directly with b2 would be insanely expensive at $200 a month&lt;/p&gt;\n\n&lt;p&gt;Now I want a local backup of this in order to backup to backblaze personal. I have a 22tb and 12tb hdd sitting around. Thinking to put these in a windows desktop and I need to sync the NAS to the local drives. It seems like stablebit drivepool would be the solution I am looking for to merge the two HDDs and simplify mirroring the NAS. Am I correct that the data on each drive would be accessible if they were read on another device or I had to restore the pc? Which drivepool settings would improve write performance with those two drives?&lt;/p&gt;\n\n&lt;p&gt;Then I need a sync solution. I just want something that will run on the windows machine and importantly will verify  the data after copying so it isn&amp;#39;t corrupted. I had an issue with lots of image data getting corrupted over a network transfer before I looked into stuff like teracopy so it is a concern.&lt;/p&gt;\n\n&lt;p&gt;is freefilesync my best option for mirroring the NAS to the HDDs?  I am just uncertain about it&amp;#39;s capabilities to verify files. It says it doesn&amp;#39;t use checksums and verify is an expert feature&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;&lt;strong&gt;VerifyCopiedFiles:&lt;/strong&gt;If active, FreeFileSync will binary-compare source and target files after copying and report verification errors. Note that this may double file copy times and is no guarantee that data has not already been corrupted prior to copying.  &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://freefilesync.org/manual.php?topic=expert-settings\"&gt;https://freefilesync.org/manual.php?topic=expert-settings&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Doubling transfer times is concerning, is it really that slow?&lt;/p&gt;\n\n&lt;p&gt;Any other better sync app for this that will verify file integrity?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JMHd1rWYktZD9wzH6JoTNk2mnIWmlNU-5Fkc3dgro_U.jpg?auto=webp&amp;s=cf28af2ecaeb1abf73af3afe21ddf8ba5b659b6f", "width": 256, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/JMHd1rWYktZD9wzH6JoTNk2mnIWmlNU-5Fkc3dgro_U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d377981e7ea719429ff57bfc335c6bc27459de7b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/JMHd1rWYktZD9wzH6JoTNk2mnIWmlNU-5Fkc3dgro_U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=359113c109fb45f6450e0394cf7baec07fac1b2b", "width": 216, "height": 216}], "variants": {}, "id": "jNzCAZNiy_wlz7c9Yl68-AO_E3gSxI4XCRMnDKeiLCw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1an0l48", "is_robot_indexable": true, "report_reasons": null, "author": "frozen_spectrum", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1an0l48/advice_for_system_for_syncing_a_nas_to_local_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1an0l48/advice_for_system_for_syncing_a_nas_to_local_hdds/", "subreddit_subscribers": 732058, "created_utc": 1707517815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm about to build a new server as I move away from Unraid to Proxmox w/ a TrueNAS VM. I'm currently in the design phase and am wondering if using a HBA/SaS drive setup has any benefits over just using the on-board SATA w/ SATA Drives.\n\nMy setup will be this:\n\n* TrueNAS Core running as a VM in Proxmox\n* 4x8TB vdev\n* No backplane/hotswap\n\nUse Case:\n\n* Storage of personal files (occasional uploads, infrequent reads)\n* Regular, automatic system backups from various servers\n* Media that will be accessed by Plex\n\n&amp;#x200B;", "author_fullname": "t2_bum3jdhe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HBA/SAS vs On-board/SATA: Does either have significant benefits for my use case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1amu78k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707501355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m about to build a new server as I move away from Unraid to Proxmox w/ a TrueNAS VM. I&amp;#39;m currently in the design phase and am wondering if using a HBA/SaS drive setup has any benefits over just using the on-board SATA w/ SATA Drives.&lt;/p&gt;\n\n&lt;p&gt;My setup will be this:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;TrueNAS Core running as a VM in Proxmox&lt;/li&gt;\n&lt;li&gt;4x8TB vdev&lt;/li&gt;\n&lt;li&gt;No backplane/hotswap&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Use Case:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Storage of personal files (occasional uploads, infrequent reads)&lt;/li&gt;\n&lt;li&gt;Regular, automatic system backups from various servers&lt;/li&gt;\n&lt;li&gt;Media that will be accessed by Plex&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1amu78k", "is_robot_indexable": true, "report_reasons": null, "author": "FrequentBag8846", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1amu78k/hbasas_vs_onboardsata_does_either_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1amu78k/hbasas_vs_onboardsata_does_either_have/", "subreddit_subscribers": 732058, "created_utc": 1707501355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For a long time, I've wanted to keep my blu ray collection on a NAS (or DAS/HDD/...), since I prefer the convenience of something like Plex over working with optical discs. The main thing that held me back was the storage cost; not just the initial upfront cost the NAS and the HDDs, but also the electricity cost to keep them running (I can justify one-off purchases for this \"hobby\" but find this harder for recurring costs :-)). So far, for my small collection I had just been using a Raspberry Pi (model 4B) with an external 6TB HDD. I've been very satisfied with that setup, but obviously need a lot more storage if I want to keep a collection of blu rays in there.\n\nFirst question: is there really any downside to keep using the Raspberry Pi as a low-power (budget) NAS? It seems that other devices (Intel NUCs, ...) are frequently recommended instead, but as far as I can tell, these seem to be both more expensive and more power hungry compared to the Pi (which only consumes like \\~2-3W when idle). **Low power consumption when not in use is pretty important to me!** Mostly because, for like 95% of the time, I won't be using the NAS (pretty much only when watching movies on weekends etc.), so I don't want it to literally waste a significant amount of power when I don't need it. The Pi also seems plenty powerful (even overkill) for this purpose, as without any transcoding it just has to serve files over the network (which even my older Pi can do without any significant CPU/RAM usage). Anything I'm missing here?\n\nSecond question: would it be a good idea to invest in something like [this](https://www.amazon.com/TerraMaster-External-Enclosure-Support-Diskless/dp/B005IOLBT2?th=1) to connect a large storage pool to the Pi? Again, I don't really mind the upfront cost, but just don't want to install a silent power hogger in my home. If I understand correctly, the drives will spin down and \"go to sleep\" when not in use, but how much power will the whole thing still be pulling when they are sleeping (assuming all bays are filled with HDDs)? And would the Pi + DAS setup still be lower in overall power consumption compared to a \"real\" NAS (like a pre-built Synology NAS)?\n\nDo share if you have any other ideas or advice!", "author_fullname": "t2_tuc32v418", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raspberry Pi + DAS as a low-power NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1amq695", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707491121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a long time, I&amp;#39;ve wanted to keep my blu ray collection on a NAS (or DAS/HDD/...), since I prefer the convenience of something like Plex over working with optical discs. The main thing that held me back was the storage cost; not just the initial upfront cost the NAS and the HDDs, but also the electricity cost to keep them running (I can justify one-off purchases for this &amp;quot;hobby&amp;quot; but find this harder for recurring costs :-)). So far, for my small collection I had just been using a Raspberry Pi (model 4B) with an external 6TB HDD. I&amp;#39;ve been very satisfied with that setup, but obviously need a lot more storage if I want to keep a collection of blu rays in there.&lt;/p&gt;\n\n&lt;p&gt;First question: is there really any downside to keep using the Raspberry Pi as a low-power (budget) NAS? It seems that other devices (Intel NUCs, ...) are frequently recommended instead, but as far as I can tell, these seem to be both more expensive and more power hungry compared to the Pi (which only consumes like ~2-3W when idle). &lt;strong&gt;Low power consumption when not in use is pretty important to me!&lt;/strong&gt; Mostly because, for like 95% of the time, I won&amp;#39;t be using the NAS (pretty much only when watching movies on weekends etc.), so I don&amp;#39;t want it to literally waste a significant amount of power when I don&amp;#39;t need it. The Pi also seems plenty powerful (even overkill) for this purpose, as without any transcoding it just has to serve files over the network (which even my older Pi can do without any significant CPU/RAM usage). Anything I&amp;#39;m missing here?&lt;/p&gt;\n\n&lt;p&gt;Second question: would it be a good idea to invest in something like &lt;a href=\"https://www.amazon.com/TerraMaster-External-Enclosure-Support-Diskless/dp/B005IOLBT2?th=1\"&gt;this&lt;/a&gt; to connect a large storage pool to the Pi? Again, I don&amp;#39;t really mind the upfront cost, but just don&amp;#39;t want to install a silent power hogger in my home. If I understand correctly, the drives will spin down and &amp;quot;go to sleep&amp;quot; when not in use, but how much power will the whole thing still be pulling when they are sleeping (assuming all bays are filled with HDDs)? And would the Pi + DAS setup still be lower in overall power consumption compared to a &amp;quot;real&amp;quot; NAS (like a pre-built Synology NAS)?&lt;/p&gt;\n\n&lt;p&gt;Do share if you have any other ideas or advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1amq695", "is_robot_indexable": true, "report_reasons": null, "author": "__hdnuts__", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1amq695/raspberry_pi_das_as_a_lowpower_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1amq695/raspberry_pi_das_as_a_lowpower_nas/", "subreddit_subscribers": 732058, "created_utc": 1707491121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As a follow-up to this: [https://www.reddit.com/r/DataHoarder/comments/13fasuz/google\\_workspace\\_unlimited\\_storage\\_its\\_over/](https://www.reddit.com/r/DataHoarder/comments/13fasuz/google_workspace_unlimited_storage_its_over/) \n\nIf you\u2019ve been impacted by the storage limitations of Google Workspace plans, don\u2019t underestimate the consequences. Google takes this seriously and will **terminate your account** if no action is taken. Whether you\u2019re storing a few dozen terabytes or hundreds, it\u2019s crucial to act promptly.\n\nGoogle gives you a mere **15 days** from the receipt of their email to take action. So, if you\u2019re like me and have already moved your data, kudos! But if not, consider this your friendly reminder to safeguard your precious files. \n\nhttps://preview.redd.it/d01rwvbaikhc1.jpg?width=790&amp;format=pjpg&amp;auto=webp&amp;s=8cc06cb0748f3b979de95d59c474c2077934e258", "author_fullname": "t2_7mwshopil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beware of ignoring storage limits on Google Workspaces", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"d01rwvbaikhc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 112, "x": 108, "u": "https://preview.redd.it/d01rwvbaikhc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf005f600fd10b725cd10e170acdfdc5b5590694"}, {"y": 224, "x": 216, "u": "https://preview.redd.it/d01rwvbaikhc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7b4227aeced23bfa17d136e3a1894fac67c552a7"}, {"y": 332, "x": 320, "u": "https://preview.redd.it/d01rwvbaikhc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=39a26689615987f9c5a2c573c0cd639d41d78e53"}, {"y": 664, "x": 640, "u": "https://preview.redd.it/d01rwvbaikhc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=96b816e0358bfb8dc3168c3fc1462b64d9559e4f"}], "s": {"y": 820, "x": 790, "u": "https://preview.redd.it/d01rwvbaikhc1.jpg?width=790&amp;format=pjpg&amp;auto=webp&amp;s=8cc06cb0748f3b979de95d59c474c2077934e258"}, "id": "d01rwvbaikhc1"}}, "name": "t3_1amp2b2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5vSuv0uU6jrarfbKemiP2euL_hzGaAF2OggnypHeEno.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707488037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a follow-up to this: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13fasuz/google_workspace_unlimited_storage_its_over/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13fasuz/google_workspace_unlimited_storage_its_over/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;If you\u2019ve been impacted by the storage limitations of Google Workspace plans, don\u2019t underestimate the consequences. Google takes this seriously and will &lt;strong&gt;terminate your account&lt;/strong&gt; if no action is taken. Whether you\u2019re storing a few dozen terabytes or hundreds, it\u2019s crucial to act promptly.&lt;/p&gt;\n\n&lt;p&gt;Google gives you a mere &lt;strong&gt;15 days&lt;/strong&gt; from the receipt of their email to take action. So, if you\u2019re like me and have already moved your data, kudos! But if not, consider this your friendly reminder to safeguard your precious files. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/d01rwvbaikhc1.jpg?width=790&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=8cc06cb0748f3b979de95d59c474c2077934e258\"&gt;https://preview.redd.it/d01rwvbaikhc1.jpg?width=790&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=8cc06cb0748f3b979de95d59c474c2077934e258&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1amp2b2", "is_robot_indexable": true, "report_reasons": null, "author": "CleanCodeFFS", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1amp2b2/beware_of_ignoring_storage_limits_on_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1amp2b2/beware_of_ignoring_storage_limits_on_google/", "subreddit_subscribers": 732058, "created_utc": 1707488037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, I need your advice on something if you may. \n\nI have a 12TB external HDD that I want to sync to a cloud so that I can access it from different locations.   \nLately, I have been working from various places, and I always struggle to copy and paste some of the files onto a portable SSD and bring it with me. \n\nI was wondering if there is a more intuitive solution, like syncing all my 12TB on a cloud without paying a fortune per month. Any recommendations?\n\nThank you in advance for your help", "author_fullname": "t2_12pg2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to Sync 12TB of Data to Cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anbvfi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707554377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I need your advice on something if you may. &lt;/p&gt;\n\n&lt;p&gt;I have a 12TB external HDD that I want to sync to a cloud so that I can access it from different locations.&lt;br/&gt;\nLately, I have been working from various places, and I always struggle to copy and paste some of the files onto a portable SSD and bring it with me. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if there is a more intuitive solution, like syncing all my 12TB on a cloud without paying a fortune per month. Any recommendations?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anbvfi", "is_robot_indexable": true, "report_reasons": null, "author": "zizo999", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anbvfi/best_way_to_sync_12tb_of_data_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anbvfi/best_way_to_sync_12tb_of_data_to_cloud/", "subreddit_subscribers": 732058, "created_utc": 1707554377.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}