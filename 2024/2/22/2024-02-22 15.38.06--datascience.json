{"kind": "Listing", "data": {"after": null, "dist": 10, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a new grad, is getting a masters an inevitability that I need to plan for\n\nAs a new grad, can someone clarify just how necessary a masters is and should I start planning to get one now?\n\nGraduating this May with a Bachelors in Applied Math from a top 10 university. Degree has been pretty much the intro math stuff (Calc2&amp;3, Linear Algebra) the 2 first years and Stats/CS/mathematical modeling last 2 years. I have a job lined up already as an L2 analyst at a company I\u2019ve been interning at for the past 2 years. \n\nI\u2019ve been researching around for more info on just how necessary a masters is in the field and if it\u2019s something I\u2019m going to eventually need to bite the bullet on. Currently, as I understand it, people tend to get caught up in chasing data scientist as a title (which is inherently a senior position) when analyst positions are the more entry level roles. So is it reasonable to assume that analyst for a few years -&gt; DS is a valid path or would I still eventually run into that wall of needing an advanced degree no matter what?\n\nI don\u2019t really want to go through the process of getting a masters. I\u2019m lucky enough to be graduating with no debt and am not really eager to voluntarily get it. The idea of taking 2 years off from making money is not very attractive as well. Also, part of me is just talking as a senior who\u2019s tired of school so there\u2019s that. \n\nBasically just looking for clarification on the topic from ppl already in industry and have navigated the market.", "author_fullname": "t2_sbwwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a new grad, is getting a masters an inevitability that I need to plan around", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awqhei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708556927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a new grad, is getting a masters an inevitability that I need to plan for&lt;/p&gt;\n\n&lt;p&gt;As a new grad, can someone clarify just how necessary a masters is and should I start planning to get one now?&lt;/p&gt;\n\n&lt;p&gt;Graduating this May with a Bachelors in Applied Math from a top 10 university. Degree has been pretty much the intro math stuff (Calc2&amp;amp;3, Linear Algebra) the 2 first years and Stats/CS/mathematical modeling last 2 years. I have a job lined up already as an L2 analyst at a company I\u2019ve been interning at for the past 2 years. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been researching around for more info on just how necessary a masters is in the field and if it\u2019s something I\u2019m going to eventually need to bite the bullet on. Currently, as I understand it, people tend to get caught up in chasing data scientist as a title (which is inherently a senior position) when analyst positions are the more entry level roles. So is it reasonable to assume that analyst for a few years -&amp;gt; DS is a valid path or would I still eventually run into that wall of needing an advanced degree no matter what?&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t really want to go through the process of getting a masters. I\u2019m lucky enough to be graduating with no debt and am not really eager to voluntarily get it. The idea of taking 2 years off from making money is not very attractive as well. Also, part of me is just talking as a senior who\u2019s tired of school so there\u2019s that. &lt;/p&gt;\n\n&lt;p&gt;Basically just looking for clarification on the topic from ppl already in industry and have navigated the market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1awqhei", "is_robot_indexable": true, "report_reasons": null, "author": "Loki433", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1awqhei/as_a_new_grad_is_getting_a_masters_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1awqhei/as_a_new_grad_is_getting_a_masters_an/", "subreddit_subscribers": 1358418, "created_utc": 1708556927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I came accross this video by **Andrej Karpathy on** *Let's build the GPT Tokenizer* last night while browsing. Now I can clearly admit that this is way way above my current level of understanding but if someone undersatnds the projects that he descibes on youtube and can implement it to solve other problems (not just copy paste it), how \"hireable\" they are?\n\nMy apology if this is not the proper place to ask such question.", "author_fullname": "t2_7lqv45ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Was suggested to post it here for more indepth asnwer] If someone can understand and implement the entire projects or something of similar complexity that Andrej Karpathy does on his YouTube channel, how industry ready are they? And how hireable are they in current job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awgwj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708534285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came accross this video by &lt;strong&gt;Andrej Karpathy on&lt;/strong&gt; &lt;em&gt;Let&amp;#39;s build the GPT Tokenizer&lt;/em&gt; last night while browsing. Now I can clearly admit that this is way way above my current level of understanding but if someone undersatnds the projects that he descibes on youtube and can implement it to solve other problems (not just copy paste it), how &amp;quot;hireable&amp;quot; they are?&lt;/p&gt;\n\n&lt;p&gt;My apology if this is not the proper place to ask such question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1awgwj8", "is_robot_indexable": true, "report_reasons": null, "author": "SmartPuppyy", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1awgwj8/was_suggested_to_post_it_here_for_more_indepth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1awgwj8/was_suggested_to_post_it_here_for_more_indepth/", "subreddit_subscribers": 1358418, "created_utc": 1708534285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: My binary churn prediction model performs way better in development than production. I've listed a few reasons why I think that is, and I'm seeking community help to verify &amp; learn through my mistakes in the process.\n\nHi! I've been working on a churn model at work. It is to be used to predict once per month, which users will churn in the next 30 days. The model performed much better in development (train/test) compared to initial production run.  \nRecall and precision from test: 85%, 85%  \nRecall and precision from production month 1: 60%, 18%\n\nI believe the reasons this happened (which I should've realised sooner) is because of the following:\n\n1. The model was trained on historical churn over 2 years (which resulted in a balanced dataset as over a longer period of time many users eventually churn, especially in the industry I'm in) but the inference in production happens on all \"current active users\" *each month* (This is a pretty imbalanced set as roughly 4-5% users churn each month).\n2. As the inference happens each month on almost the same user-set (current active users), we might end up making the same prediction as previous month especially if there isn't a huge change in user data since last month. i.e we end up carrying forward false-positives from previous month.\n3. Model was only trained on the final states of user-journey. This means I could not include seasonality features as it would leak target data. Why? Because all the non-events (did not churn) \"happen\" on the last month of the training dataset.\n\nJust to add onto point 3, would it have made sense to train model on different points of the user journey instead of just the final state?   \nExample:  \ndata-point 1 :: User 1 features at the end of Jan :: Did not churn  \ndata-point 2 :: User 1 features at the end of Feb :: Did not churn  \ndata-point 3 :: User 1 features at the end of March :: **Churned**\n\n**Is my reasoning correct? What could I do different if I had to do this over?**", "author_fullname": "t2_40233m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Churn prediction: A data imbalance issue, or something else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax45p8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708601239.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708601039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: My binary churn prediction model performs way better in development than production. I&amp;#39;ve listed a few reasons why I think that is, and I&amp;#39;m seeking community help to verify &amp;amp; learn through my mistakes in the process.&lt;/p&gt;\n\n&lt;p&gt;Hi! I&amp;#39;ve been working on a churn model at work. It is to be used to predict once per month, which users will churn in the next 30 days. The model performed much better in development (train/test) compared to initial production run.&lt;br/&gt;\nRecall and precision from test: 85%, 85%&lt;br/&gt;\nRecall and precision from production month 1: 60%, 18%&lt;/p&gt;\n\n&lt;p&gt;I believe the reasons this happened (which I should&amp;#39;ve realised sooner) is because of the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The model was trained on historical churn over 2 years (which resulted in a balanced dataset as over a longer period of time many users eventually churn, especially in the industry I&amp;#39;m in) but the inference in production happens on all &amp;quot;current active users&amp;quot; &lt;em&gt;each month&lt;/em&gt; (This is a pretty imbalanced set as roughly 4-5% users churn each month).&lt;/li&gt;\n&lt;li&gt;As the inference happens each month on almost the same user-set (current active users), we might end up making the same prediction as previous month especially if there isn&amp;#39;t a huge change in user data since last month. i.e we end up carrying forward false-positives from previous month.&lt;/li&gt;\n&lt;li&gt;Model was only trained on the final states of user-journey. This means I could not include seasonality features as it would leak target data. Why? Because all the non-events (did not churn) &amp;quot;happen&amp;quot; on the last month of the training dataset.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Just to add onto point 3, would it have made sense to train model on different points of the user journey instead of just the final state?&lt;br/&gt;\nExample:&lt;br/&gt;\ndata-point 1 :: User 1 features at the end of Jan :: Did not churn&lt;br/&gt;\ndata-point 2 :: User 1 features at the end of Feb :: Did not churn&lt;br/&gt;\ndata-point 3 :: User 1 features at the end of March :: &lt;strong&gt;Churned&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is my reasoning correct? What could I do different if I had to do this over?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ax45p8", "is_robot_indexable": true, "report_reasons": null, "author": "CrypticTac", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax45p8/churn_prediction_a_data_imbalance_issue_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax45p8/churn_prediction_a_data_imbalance_issue_or/", "subreddit_subscribers": 1358418, "created_utc": 1708601039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "With a BS + MS in Statistics I don\u2019t really have any plans to do a PhD. I am more interested in solving problems in the industry than in academia. However, part of me feels \u201cweird\u201d that my education is gonna stop at 24 and I will be working and not getting another degree. But that\u2019s besides the point. My real concern is whether I need to plan on getting some kind of \u201cprofessional\u201d degree after my MS in Stats. When I interviewed for a role the hiring manager (who had no background in anything stem) told me I should consider an MBA to round myself out. Frankly I have no interest in doing an MBA. I\u2019ve gone debt free for my education my whole life (thank you parents for bachelors, and thank you to myself for getting funding for my masters), but in no way do I want to pay for an MBA. \n\nFrom my limited experience it feels like MBAs are just degrees people get to prove to a higher up that they have the credential to get a c suite position. Cause ultimately people hire people and if the directors or c suites have MBAs they know if they have an MBA from xyz university then they are gonna get hired cause of it. \n\nWhat do you guys think, is education after my MS in stats necessary? I mean for me \u201ceducation\u201d post Masters degree is just reading advanced stats textbooks on my own for fun, whether I need to learn something for work or I\u2019m just studying it for my enjoyment. But is a formal \u201cdegree\u201d required? Like I don\u2019t really see the point in me doing a PhD in stats, because I just don\u2019t want to work in an academic setting and frankly I just want money more. \n\nIs there a natural cap with a MS in something technical (stats) for example?", "author_fullname": "t2_uy28jztl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Education beyond a Masters, is it necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax6dgp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708608434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With a BS + MS in Statistics I don\u2019t really have any plans to do a PhD. I am more interested in solving problems in the industry than in academia. However, part of me feels \u201cweird\u201d that my education is gonna stop at 24 and I will be working and not getting another degree. But that\u2019s besides the point. My real concern is whether I need to plan on getting some kind of \u201cprofessional\u201d degree after my MS in Stats. When I interviewed for a role the hiring manager (who had no background in anything stem) told me I should consider an MBA to round myself out. Frankly I have no interest in doing an MBA. I\u2019ve gone debt free for my education my whole life (thank you parents for bachelors, and thank you to myself for getting funding for my masters), but in no way do I want to pay for an MBA. &lt;/p&gt;\n\n&lt;p&gt;From my limited experience it feels like MBAs are just degrees people get to prove to a higher up that they have the credential to get a c suite position. Cause ultimately people hire people and if the directors or c suites have MBAs they know if they have an MBA from xyz university then they are gonna get hired cause of it. &lt;/p&gt;\n\n&lt;p&gt;What do you guys think, is education after my MS in stats necessary? I mean for me \u201ceducation\u201d post Masters degree is just reading advanced stats textbooks on my own for fun, whether I need to learn something for work or I\u2019m just studying it for my enjoyment. But is a formal \u201cdegree\u201d required? Like I don\u2019t really see the point in me doing a PhD in stats, because I just don\u2019t want to work in an academic setting and frankly I just want money more. &lt;/p&gt;\n\n&lt;p&gt;Is there a natural cap with a MS in something technical (stats) for example?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1ax6dgp", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Touch469", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax6dgp/education_beyond_a_masters_is_it_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax6dgp/education_beyond_a_masters_is_it_necessary/", "subreddit_subscribers": 1358418, "created_utc": 1708608434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We (2 developers) made marimo\\[1\\] compatible with WebAssembly (WASM), so you can run it entirely in the browser thanks to [Pyodide](https://pyodide.org/).\n\nYou can try out the playground: [https://marimo.app/](https://marimo.app/). This has been a great tool for learning Python or educating others, as you can share snippets of code via the URL. For example, here is a notebook on [Bayes' Theorem](https://marimo.app/?code=JYWwDg9gTgLgBCAhlUEBQaD6mDmBTAOzykRjwBNMB3YGACzgF44AiABgDoAmDgVhbSIwYJgmSoOAQWEAKAJQY0AASFgOAYzwAbLTLrByeTOoiHGAFSgBXPAsMAzONhkgIcgFxo43hBA4hyGS8fEKgWcOCQ7wBiOAAhRABPPABnAHI4czo8aDwQDCifTCzgFLhgAjISdRhgADc8OAIIMgAjCAgAazgqRDKkQx7aBgBtJBRXAF09GBgwFPcAekWcYatWjQgQRfHUAFoyRG3d1zkAGjhEAnJyspHWvoo4CAJL17wADzAtK9JgF%2BejgSyXSmWyuRAcFaiTgAHESJU4ABlK6GKApF7TOizeZLRZUAkcRIQKwwdZ4TbbXowdR0AD8dUYAAkAFqwgDCEAAagAxADMAE06gBZABkWlKMEYAAUADIALwAjgB2UwgGD2ADSAEUqFxNQBJVraxVsKDygDqUEVq3sTM1nWlsIAjKKKoYPoxXVK%2BSk5JgOAVCvEkqkMvQclA8nAwFAIHUDKlLnATAQGgRgIR4L0YTAICnEFp1FYfmQ4BGY3GHq1gBKYIlIlEII5EHA6IlIBGUqU4Hh0-AACRMgdwVbp3sJwwETRwAcAUQHnkbIQAOiNlz5pTImXAVyADHA53JRCv7NUAN5bpnHrdz3f7m7XgC%2Bl5kR6fgeDu8mii-ACo-yyRoCCsEBiFIaAOAAsFgNA8C8ygW5y2ySsIGrWtaBhZsJyzMp5xHVFZ2HNtVEICocA3bw83wCMoAAbmQ0hbjOINCjXSiQivG833vA9r1EW9d3UIQ4GvT9gxXH8OIAoC4CnLYKggqAoL-DiDVeVwUngYSixLP4XhSC5aCQ7ItDAewS3LfMoyoFAywreT9wIJTZ1vOQCLKVionYr83IE7c5EEvc%2BOPABqOAtxXIgcFEm84B44KbiivAYuvFiv0kryQiofRaXKV4ySgV5hNeQsMShRpbNoMhSpSX8JPXXy32PZgguEkR%2BPCtqROS1K5HEtify-cIBBCfqtDwewYHkRso0KghFBUYQNG0LQ0AcJxMBcNxPBCMBMAYZhXA4KxgA4FIJTRGRODYC5nQuH5Wm0RgWAHLiBxYC46kLGxGE4e64C0vAwD%2BjhnQUPbMCMMdCAO0RjtO87LuIa6OFuuAAce57XqCh9Yo%2Br6frwUG%2BQuIGQf%2BiGfH26H6lh5oYDho6-ERi7EygIIvxuu6HsQJ6tEYMI3oSvHevxz64G%2BrRfs4UnAbICmwcbKnvDmqwipjKHcDpggDouGntfTTAGb1zW6EW1QVp0dbJs2mQDZh3W6H1rXHeNlpTf2ugPEbGnRC9jgpZsP8HZ1g7A6JuBwpkZ04D2M2I%2Bl2wQ9dsOTboRObEbB4QUwKMUhLeBmADoPGj-TXaaNjPS7gRYK9mvB5qhUMUjz1JC5dvALeWzQdD0RNjFMYnLBsOxbecVxO8N2HnYr6fdfTl3vd2nxjoCTngygewRo4kJoliaUqz5jDalSLLgwFEkC2Kl57GAHB1caCtYzQ4%2B60zMpsIrPtcKIgcLnnLxR8-83g3EAYlXc0VRIDnPoUc8x0%2BgHRgCAXQIwvZTzdrPUORt06TDkE%2BWBURZLfBaBVLQEAqCS1KFYQswB5RJmfkfGs78kxf2yCkRoP9KgpA4HADiO8xpeTVkVbuahe5rQ2s4VMWlrA1EwC-dCdZEjyPITAH2IRpEwFkYzBRb9MIqJaDNUIjd1YLQwEtMRq1%2B6GEHmYEetgbaOGcDnVIbcC5aBgBcSeFcMFhywanHBHt-HL0bGvQIHEt4CK-D4Z0vDZLJB0BQuAUYahXBwBNZJwN86-2-v2P%2BFxCK0DKMgPArYezC34swc8JcibuE4FwewT4BwDWiTwGC5ZSlaEyakgg6TGjxmID8YQ5Ehj0GQo0BJ5DKEvEaFGWMqQckoS4YOO8K52rQIKdcXehQimXCjGUvCXEhLkFIbjEKohqnhxruXbBM9M54DqdwRpzTtneD5HElChwukpJgGkjJ9AmInNSAQNI8ABlQCGeMuAkykk-L%2BbMrJCzuFQuWbOVZ6yxbDk2eQV5IRdklIOa5GQmLjxrJOfAM5SUoGVLgOeGOccE6l2PDcgJ9Mgn3MeQ0ppgZcUADkWjABnAC%2BAFYC6QjYY0AlZQKizi4ARa4s4%2BQjh7Iw1%2BzDMJEqPBcmmnLnm8MISEAA8kQHoSQrLIQqN0PmJJ4DAjDDBCESEKz2AgIkmgvT3BQt0eq%2BsRKdwQKPMqsoqrFGYVxdhfCoC-4kWEGRXpVkaLZEQjICsBLARQrhb0jJA45XnDkvURMNxoReqYSfLCjhI10FIhmXpuKmKFi6SmlCYr02pv2Z-Ctcqo0DiVf1XF6kLVlGEhwi4drQRAUdSkJIdVcU%2BWid4K8QDDwtV3GeRA6hzyvn4pS2KT4XyvnfE%2BE8a6N2bpqUnI9ZLSGXMrnc0ue7903t1Q%2Bi5LjW750Ls%2B2dQ152sAiII4x81RFWwkePLatyna%2BMCYzYJ6ifAbU0do%2BRpalEGOmnBnZ4BoDwCQHMVREoNhgA7Koy4ZRvgwEIeRjgiAPipBmhxWIAAlRA5BgBWAWBjC49h114D2CYchUBPVRnIBcCg%2BA%2BOuugJ61oScOJUbvg-KMMgFPdnoYwGQAA2M4Gm5AqyiA8Dh-sPEcEY3gHpfSZDXQuGwPNAMAb2HUC9GT67OgSzMy9HKtA8AS0LGAKtoMuC8D0yEQ6MZjOmfMxNSz6MbNL3uTzOADmXowqoG5xzLBPNkAlljAWLAmQsGCz4W9TsjMwBM2Z35Wa8Ab3nVZuAsXcXnpsOlX9EGrlExa-OpLLAvmfVxe5jL%2Bgsudeib5-znBeAja-Dll6c4%2BtfkK94Yr7sYOlfK5F6ruL7btaTtZ2zDKmt4Cg2ymD8XEvpd66J9LmXvMFLMuNvgHFFthbKzgYS8hqPkEoGAUgtIZAGYcV%2BKjb3EAfZY9937dA9DPeB%2B9-q4P5GQ5kMt9OMPjMg7B19xHNIofLe9nJ4zE18DXCMZvExGtYeg708Im%2BBAZFWDkd6staGWLmMtuIxxdsMPlCw7AMQEx8x9F8A3Juk9FDACccbI4RhMBMGYCwbASAKjYBYCvbwltrAEHkEAA).\n\n\\[1\\] marimo is open-source on GitHub: [https://github.com/marimo-team/marimo](https://github.com/marimo-team/marimo)", "author_fullname": "t2_jul3ckjm3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "marimo-wasm: a reactive Python notebook in the browser", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awlq2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708545618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We (2 developers) made marimo[1] compatible with WebAssembly (WASM), so you can run it entirely in the browser thanks to &lt;a href=\"https://pyodide.org/\"&gt;Pyodide&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;You can try out the playground: &lt;a href=\"https://marimo.app/\"&gt;https://marimo.app/&lt;/a&gt;. This has been a great tool for learning Python or educating others, as you can share snippets of code via the URL. For example, here is a notebook on &lt;a href=\"https://marimo.app/?code=JYWwDg9gTgLgBCAhlUEBQaD6mDmBTAOzykRjwBNMB3YGACzgF44AiABgDoAmDgVhbSIwYJgmSoOAQWEAKAJQY0AASFgOAYzwAbLTLrByeTOoiHGAFSgBXPAsMAzONhkgIcgFxo43hBA4hyGS8fEKgWcOCQ7wBiOAAhRABPPABnAHI4czo8aDwQDCifTCzgFLhgAjISdRhgADc8OAIIMgAjCAgAazgqRDKkQx7aBgBtJBRXAF09GBgwFPcAekWcYatWjQgQRfHUAFoyRG3d1zkAGjhEAnJyspHWvoo4CAJL17wADzAtK9JgF%2BejgSyXSmWyuRAcFaiTgAHESJU4ABlK6GKApF7TOizeZLRZUAkcRIQKwwdZ4TbbXowdR0AD8dUYAAkAFqwgDCEAAagAxADMAE06gBZABkWlKMEYAAUADIALwAjgB2UwgGD2ADSAEUqFxNQBJVraxVsKDygDqUEVq3sTM1nWlsIAjKKKoYPoxXVK%2BSk5JgOAVCvEkqkMvQclA8nAwFAIHUDKlLnATAQGgRgIR4L0YTAICnEFp1FYfmQ4BGY3GHq1gBKYIlIlEII5EHA6IlIBGUqU4Hh0-AACRMgdwVbp3sJwwETRwAcAUQHnkbIQAOiNlz5pTImXAVyADHA53JRCv7NUAN5bpnHrdz3f7m7XgC%2Bl5kR6fgeDu8mii-ACo-yyRoCCsEBiFIaAOAAsFgNA8C8ygW5y2ySsIGrWtaBhZsJyzMp5xHVFZ2HNtVEICocA3bw83wCMoAAbmQ0hbjOINCjXSiQivG833vA9r1EW9d3UIQ4GvT9gxXH8OIAoC4CnLYKggqAoL-DiDVeVwUngYSixLP4XhSC5aCQ7ItDAewS3LfMoyoFAywreT9wIJTZ1vOQCLKVionYr83IE7c5EEvc%2BOPABqOAtxXIgcFEm84B44KbiivAYuvFiv0kryQiofRaXKV4ySgV5hNeQsMShRpbNoMhSpSX8JPXXy32PZgguEkR%2BPCtqROS1K5HEtify-cIBBCfqtDwewYHkRso0KghFBUYQNG0LQ0AcJxMBcNxPBCMBMAYZhXA4KxgA4FIJTRGRODYC5nQuH5Wm0RgWAHLiBxYC46kLGxGE4e64C0vAwD%2BjhnQUPbMCMMdCAO0RjtO87LuIa6OFuuAAce57XqCh9Yo%2Br6frwUG%2BQuIGQf%2BiGfH26H6lh5oYDho6-ERi7EygIIvxuu6HsQJ6tEYMI3oSvHevxz64G%2BrRfs4UnAbICmwcbKnvDmqwipjKHcDpggDouGntfTTAGb1zW6EW1QVp0dbJs2mQDZh3W6H1rXHeNlpTf2ugPEbGnRC9jgpZsP8HZ1g7A6JuBwpkZ04D2M2I%2Bl2wQ9dsOTboRObEbB4QUwKMUhLeBmADoPGj-TXaaNjPS7gRYK9mvB5qhUMUjz1JC5dvALeWzQdD0RNjFMYnLBsOxbecVxO8N2HnYr6fdfTl3vd2nxjoCTngygewRo4kJoliaUqz5jDalSLLgwFEkC2Kl57GAHB1caCtYzQ4%2B60zMpsIrPtcKIgcLnnLxR8-83g3EAYlXc0VRIDnPoUc8x0%2BgHRgCAXQIwvZTzdrPUORt06TDkE%2BWBURZLfBaBVLQEAqCS1KFYQswB5RJmfkfGs78kxf2yCkRoP9KgpA4HADiO8xpeTVkVbuahe5rQ2s4VMWlrA1EwC-dCdZEjyPITAH2IRpEwFkYzBRb9MIqJaDNUIjd1YLQwEtMRq1%2B6GEHmYEetgbaOGcDnVIbcC5aBgBcSeFcMFhywanHBHt-HL0bGvQIHEt4CK-D4Z0vDZLJB0BQuAUYahXBwBNZJwN86-2-v2P%2BFxCK0DKMgPArYezC34swc8JcibuE4FwewT4BwDWiTwGC5ZSlaEyakgg6TGjxmID8YQ5Ehj0GQo0BJ5DKEvEaFGWMqQckoS4YOO8K52rQIKdcXehQimXCjGUvCXEhLkFIbjEKohqnhxruXbBM9M54DqdwRpzTtneD5HElChwukpJgGkjJ9AmInNSAQNI8ABlQCGeMuAkykk-L%2BbMrJCzuFQuWbOVZ6yxbDk2eQV5IRdklIOa5GQmLjxrJOfAM5SUoGVLgOeGOccE6l2PDcgJ9Mgn3MeQ0ppgZcUADkWjABnAC%2BAFYC6QjYY0AlZQKizi4ARa4s4%2BQjh7Iw1%2BzDMJEqPBcmmnLnm8MISEAA8kQHoSQrLIQqN0PmJJ4DAjDDBCESEKz2AgIkmgvT3BQt0eq%2BsRKdwQKPMqsoqrFGYVxdhfCoC-4kWEGRXpVkaLZEQjICsBLARQrhb0jJA45XnDkvURMNxoReqYSfLCjhI10FIhmXpuKmKFi6SmlCYr02pv2Z-Ctcqo0DiVf1XF6kLVlGEhwi4drQRAUdSkJIdVcU%2BWid4K8QDDwtV3GeRA6hzyvn4pS2KT4XyvnfE%2BE8a6N2bpqUnI9ZLSGXMrnc0ue7903t1Q%2Bi5LjW750Ls%2B2dQ152sAiII4x81RFWwkePLatyna%2BMCYzYJ6ifAbU0do%2BRpalEGOmnBnZ4BoDwCQHMVREoNhgA7Koy4ZRvgwEIeRjgiAPipBmhxWIAAlRA5BgBWAWBjC49h114D2CYchUBPVRnIBcCg%2BA%2BOuugJ61oScOJUbvg-KMMgFPdnoYwGQAA2M4Gm5AqyiA8Dh-sPEcEY3gHpfSZDXQuGwPNAMAb2HUC9GT67OgSzMy9HKtA8AS0LGAKtoMuC8D0yEQ6MZjOmfMxNSz6MbNL3uTzOADmXowqoG5xzLBPNkAlljAWLAmQsGCz4W9TsjMwBM2Z35Wa8Ab3nVZuAsXcXnpsOlX9EGrlExa-OpLLAvmfVxe5jL%2Bgsudeib5-znBeAja-Dll6c4%2BtfkK94Yr7sYOlfK5F6ruL7btaTtZ2zDKmt4Cg2ymD8XEvpd66J9LmXvMFLMuNvgHFFthbKzgYS8hqPkEoGAUgtIZAGYcV%2BKjb3EAfZY9937dA9DPeB%2B9-q4P5GQ5kMt9OMPjMg7B19xHNIofLe9nJ4zE18DXCMZvExGtYeg708Im%2BBAZFWDkd6staGWLmMtuIxxdsMPlCw7AMQEx8x9F8A3Juk9FDACccbI4RhMBMGYCwbASAKjYBYCvbwltrAEHkEAA\"&gt;Bayes&amp;#39; Theorem&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;[1] marimo is open-source on GitHub: &lt;a href=\"https://github.com/marimo-team/marimo\"&gt;https://github.com/marimo-team/marimo&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1awlq2x", "is_robot_indexable": true, "report_reasons": null, "author": "mmmmmmyles", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1awlq2x/marimowasm_a_reactive_python_notebook_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1awlq2x/marimowasm_a_reactive_python_notebook_in_the/", "subreddit_subscribers": 1358418, "created_utc": 1708545618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, long time lurker, first time poster. I've been working on an AI assisted data pseudonymization app recently. Basically the idea is that you can build pseudonymization pipelines in the cloud with the help of an AI assistant that generates a template pipeline for you based on the uploaded contents (shameless plug, check out the app [seudo](https://seudo.alpn-software.com) here if you're interested).\n\nIn a nutshell, I need to be able to classify a data column in a CSV as either personal data or not. I'm interested in getting peoples thoughts on how to generate a feature space. What I've done so far is generate a feature vector using the column name and a sample value by running it through a bunch of regex expressions that check for common PI patterns in the data values and in the column name. I've also added some other basic string metrics (how long, how many vowels etc), and trained a random forrest classifier on a dataset that I generated.\n\nIt was loosely based on [this](https://medium.com/cape-ai-stories/case-study-using-machine-learning-to-classify-personally-identifiable-data-fields-6b9c5b0743e7) article (very loosely), and the results are mixed. The article in question was specific to a given region in SA, and doesnt generalise well to other parts of the world. Anyone done anything similar before? How would you go about generating a feature space to train a model?\n\nIf you're interested and have a minute, feel free to check out the app as well (link above). Any feedback is always appreciated.", "author_fullname": "t2_bep31tvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Classification Model for Personal Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax1ii5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708590570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, long time lurker, first time poster. I&amp;#39;ve been working on an AI assisted data pseudonymization app recently. Basically the idea is that you can build pseudonymization pipelines in the cloud with the help of an AI assistant that generates a template pipeline for you based on the uploaded contents (shameless plug, check out the app &lt;a href=\"https://seudo.alpn-software.com\"&gt;seudo&lt;/a&gt; here if you&amp;#39;re interested).&lt;/p&gt;\n\n&lt;p&gt;In a nutshell, I need to be able to classify a data column in a CSV as either personal data or not. I&amp;#39;m interested in getting peoples thoughts on how to generate a feature space. What I&amp;#39;ve done so far is generate a feature vector using the column name and a sample value by running it through a bunch of regex expressions that check for common PI patterns in the data values and in the column name. I&amp;#39;ve also added some other basic string metrics (how long, how many vowels etc), and trained a random forrest classifier on a dataset that I generated.&lt;/p&gt;\n\n&lt;p&gt;It was loosely based on &lt;a href=\"https://medium.com/cape-ai-stories/case-study-using-machine-learning-to-classify-personally-identifiable-data-fields-6b9c5b0743e7\"&gt;this&lt;/a&gt; article (very loosely), and the results are mixed. The article in question was specific to a given region in SA, and doesnt generalise well to other parts of the world. Anyone done anything similar before? How would you go about generating a feature space to train a model?&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested and have a minute, feel free to check out the app as well (link above). Any feedback is always appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1ax1ii5", "is_robot_indexable": true, "report_reasons": null, "author": "OkInteraction493", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax1ii5/classification_model_for_personal_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax1ii5/classification_model_for_personal_data/", "subreddit_subscribers": 1358418, "created_utc": 1708590570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Interesting paper I came across regarding statistical methodological innovations to address challenges in large scale online experimentation.\n\nhttps://arxiv.org/abs/2212.11366\n\n", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Challenges with online controlled experiments ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awfm6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708531251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interesting paper I came across regarding statistical methodological innovations to address challenges in large scale online experimentation.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2212.11366\"&gt;https://arxiv.org/abs/2212.11366&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1awfm6s", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1awfm6s/challenges_with_online_controlled_experiments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1awfm6s/challenges_with_online_controlled_experiments/", "subreddit_subscribers": 1358418, "created_utc": 1708531251.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to implement the R\u2019s random forest classifier equivalent in python:\n\n    # train random forest\n       \n    set.seed(5136)  \n    ty.rf = randomForest(y=ty.y, x= ty.x, ntree=1000, importance=T, strata=ty.y, sampsize=c(100,100), do.trace=10, proximity=T)  \n\nThe above classifier was implemented for an imbalanced data.\n\nI had tried to implement the above as following in python.\n\nHere\u2019s my implementation in python:\n\n    # random forest      \n    \n    rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),  ('model',RandomForestClassifier(n_estimators=1000,class_weight='balanced', random_state=5136, oob_score=True, bootstrap = True))])    rf_pipeline.fit(ty_x, ty_y)   \n\nIs this the equivalent syntax here? Also, after implementation in R code OOB estimate of error rate: 19.41% and in python OOB estimate of error rate: 7.14%, is this expected? I was expecting the oob\\_error to be similar. Can someone please clarify?", "author_fullname": "t2_p657jjww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Random Forest classifier in R vs scikit-learn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ax6pw1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708609457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to implement the R\u2019s random forest classifier equivalent in python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# train random forest\n\nset.seed(5136)  \nty.rf = randomForest(y=ty.y, x= ty.x, ntree=1000, importance=T, strata=ty.y, sampsize=c(100,100), do.trace=10, proximity=T)  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The above classifier was implemented for an imbalanced data.&lt;/p&gt;\n\n&lt;p&gt;I had tried to implement the above as following in python.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s my implementation in python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# random forest      \n\nrf_pipeline = Pipeline(steps=[(&amp;#39;preprocessor&amp;#39;, preprocessor),  (&amp;#39;model&amp;#39;,RandomForestClassifier(n_estimators=1000,class_weight=&amp;#39;balanced&amp;#39;, random_state=5136, oob_score=True, bootstrap = True))])    rf_pipeline.fit(ty_x, ty_y)   \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this the equivalent syntax here? Also, after implementation in R code OOB estimate of error rate: 19.41% and in python OOB estimate of error rate: 7.14%, is this expected? I was expecting the oob_error to be similar. Can someone please clarify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1ax6pw1", "is_robot_indexable": true, "report_reasons": null, "author": "tinkerpal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax6pw1/d_random_forest_classifier_in_r_vs_scikitlearn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax6pw1/d_random_forest_classifier_in_r_vs_scikitlearn/", "subreddit_subscribers": 1358418, "created_utc": 1708609457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For open-source practitioners of Data-Centric AI (using AI to systematically improve your existing data):  I just released major updates to cleanlab, the\u00a0most popular software library for Data-Centric AI (with 8000 GitHub stars thanks to an amazing community).  \n\n\nFlawed data produces flawed AI, and real-world datasets have many flaws that are hard to catch manually.  With one line of Python code, you can run cleanlab on any dataset to automatically catch these flaws, and thus improve almost any ML model fit to this data.  Try it quickly to see why thousands of data scientists have adopted cleanlab\u2019s AI-based data quality algorithms to deploy more reliable ML.  \n\n\nToday\u2019s v2.6.0 release includes new capabilities like Data Valuation (via Data Shapely), detection of Underperforming Data Slices/Groups, and lots more.  I published a blogpost outlining new automated techniques this library provides to systematically increase the value your existing data.   \n\n\nBlogpost:  [https://cleanlab.ai/blog/cleanlab-2.6](https://cleanlab.ai/blog/cleanlab-2.6) \n\nGitHub repo:  [https://github.com/cleanlab/cleanlab](https://github.com/cleanlab/cleanlab)\n\n5min notebook tutorials:  [https://docs.cleanlab.ai/](https://docs.cleanlab.ai/)  \n\n\nI'd love to hear how you all doing data prep / exploratory data analysis in 2024?  \nMy view is you shouldn't do 100% of your data checking manually \u2013 also use automated algorithms like cleanlab offers to ensure you don\u2019t miss any problems (significantly improved coverage in terms of data flaws discovered and addressed).  The vision of Data-Centric AI is to use your trained ML models to help you find and fix dataset issues, which can allow to you subsequently train better versions of these models.", "author_fullname": "t2_5v7p3x0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using AI automation to help with data prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awjf6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708540198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For open-source practitioners of Data-Centric AI (using AI to systematically improve your existing data):  I just released major updates to cleanlab, the\u00a0most popular software library for Data-Centric AI (with 8000 GitHub stars thanks to an amazing community).  &lt;/p&gt;\n\n&lt;p&gt;Flawed data produces flawed AI, and real-world datasets have many flaws that are hard to catch manually.  With one line of Python code, you can run cleanlab on any dataset to automatically catch these flaws, and thus improve almost any ML model fit to this data.  Try it quickly to see why thousands of data scientists have adopted cleanlab\u2019s AI-based data quality algorithms to deploy more reliable ML.  &lt;/p&gt;\n\n&lt;p&gt;Today\u2019s v2.6.0 release includes new capabilities like Data Valuation (via Data Shapely), detection of Underperforming Data Slices/Groups, and lots more.  I published a blogpost outlining new automated techniques this library provides to systematically increase the value your existing data.   &lt;/p&gt;\n\n&lt;p&gt;Blogpost:  &lt;a href=\"https://cleanlab.ai/blog/cleanlab-2.6\"&gt;https://cleanlab.ai/blog/cleanlab-2.6&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;GitHub repo:  &lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;https://github.com/cleanlab/cleanlab&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;5min notebook tutorials:  &lt;a href=\"https://docs.cleanlab.ai/\"&gt;https://docs.cleanlab.ai/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear how you all doing data prep / exploratory data analysis in 2024?&lt;br/&gt;\nMy view is you shouldn&amp;#39;t do 100% of your data checking manually \u2013 also use automated algorithms like cleanlab offers to ensure you don\u2019t miss any problems (significantly improved coverage in terms of data flaws discovered and addressed).  The vision of Data-Centric AI is to use your trained ML models to help you find and fix dataset issues, which can allow to you subsequently train better versions of these models.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jPz6eCa4tEkZMXOb8sleXHPqJpxG2RnvtaRB3sszX9Y.jpg?auto=webp&amp;s=76b269f80aed83cdba12887154819dec4688c156", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/jPz6eCa4tEkZMXOb8sleXHPqJpxG2RnvtaRB3sszX9Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d769d3004d3f186cfd8f0070d6c18cd102cb89a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/jPz6eCa4tEkZMXOb8sleXHPqJpxG2RnvtaRB3sszX9Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9a1f71d565f959f36171326b0eb6796cdd648d0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/jPz6eCa4tEkZMXOb8sleXHPqJpxG2RnvtaRB3sszX9Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b95b4145117fa58951aad2c5bdc6356287c0162b", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/jPz6eCa4tEkZMXOb8sleXHPqJpxG2RnvtaRB3sszX9Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1d817bb6d6835513053747a222fd97b50c6fe71d", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/jPz6eCa4tEkZMXOb8sleXHPqJpxG2RnvtaRB3sszX9Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ea17682e75005c2760d72a611fe32754eceeda36", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/jPz6eCa4tEkZMXOb8sleXHPqJpxG2RnvtaRB3sszX9Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3a3d5e8f1c31739430ffb6adeb84fc7cef56e5eb", "width": 1080, "height": 607}], "variants": {}, "id": "LFx82LBCBUMu3pBjyrqStW_8vMsq7aQRaM7_TF1CFEk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1awjf6e", "is_robot_indexable": true, "report_reasons": null, "author": "jonas__m", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1awjf6e/using_ai_automation_to_help_with_data_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1awjf6e/using_ai_automation_to_help_with_data_prep/", "subreddit_subscribers": 1358418, "created_utc": 1708540198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys! I wonder if it is possible to train an LLM model, like BERT, to be able to associate a word with another word. For example, \"Blue\" -&gt; \"Sky\" (the model associates the word \"Blue\" with \"Sky\"). Cheers!", "author_fullname": "t2_3j4e33js", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Word Association with LLM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax4lu1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708602720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! I wonder if it is possible to train an LLM model, like BERT, to be able to associate a word with another word. For example, &amp;quot;Blue&amp;quot; -&amp;gt; &amp;quot;Sky&amp;quot; (the model associates the word &amp;quot;Blue&amp;quot; with &amp;quot;Sky&amp;quot;). Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1ax4lu1", "is_robot_indexable": true, "report_reasons": null, "author": "OxheadGreg123", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax4lu1/word_association_with_llm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax4lu1/word_association_with_llm/", "subreddit_subscribers": 1358418, "created_utc": 1708602720.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}