{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a new grad, is getting a masters an inevitability that I need to plan for\n\nAs a new grad, can someone clarify just how necessary a masters is and should I start planning to get one now?\n\nGraduating this May with a Bachelors in Applied Math from a top 10 university. Degree has been pretty much the intro math stuff (Calc2&amp;3, Linear Algebra) the 2 first years and Stats/CS/mathematical modeling last 2 years. I have a job lined up already as an L2 analyst at a company I\u2019ve been interning at for the past 2 years. \n\nI\u2019ve been researching around for more info on just how necessary a masters is in the field and if it\u2019s something I\u2019m going to eventually need to bite the bullet on. Currently, as I understand it, people tend to get caught up in chasing data scientist as a title (which is inherently a senior position) when analyst positions are the more entry level roles. So is it reasonable to assume that analyst for a few years -&gt; DS is a valid path or would I still eventually run into that wall of needing an advanced degree no matter what?\n\nI don\u2019t really want to go through the process of getting a masters. I\u2019m lucky enough to be graduating with no debt and am not really eager to voluntarily get it. The idea of taking 2 years off from making money is not very attractive as well. Also, part of me is just talking as a senior who\u2019s tired of school so there\u2019s that. \n\nBasically just looking for clarification on the topic from ppl already in industry and have navigated the market.", "author_fullname": "t2_sbwwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a new grad, is getting a masters an inevitability that I need to plan around", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awqhei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708556927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a new grad, is getting a masters an inevitability that I need to plan for&lt;/p&gt;\n\n&lt;p&gt;As a new grad, can someone clarify just how necessary a masters is and should I start planning to get one now?&lt;/p&gt;\n\n&lt;p&gt;Graduating this May with a Bachelors in Applied Math from a top 10 university. Degree has been pretty much the intro math stuff (Calc2&amp;amp;3, Linear Algebra) the 2 first years and Stats/CS/mathematical modeling last 2 years. I have a job lined up already as an L2 analyst at a company I\u2019ve been interning at for the past 2 years. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been researching around for more info on just how necessary a masters is in the field and if it\u2019s something I\u2019m going to eventually need to bite the bullet on. Currently, as I understand it, people tend to get caught up in chasing data scientist as a title (which is inherently a senior position) when analyst positions are the more entry level roles. So is it reasonable to assume that analyst for a few years -&amp;gt; DS is a valid path or would I still eventually run into that wall of needing an advanced degree no matter what?&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t really want to go through the process of getting a masters. I\u2019m lucky enough to be graduating with no debt and am not really eager to voluntarily get it. The idea of taking 2 years off from making money is not very attractive as well. Also, part of me is just talking as a senior who\u2019s tired of school so there\u2019s that. &lt;/p&gt;\n\n&lt;p&gt;Basically just looking for clarification on the topic from ppl already in industry and have navigated the market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1awqhei", "is_robot_indexable": true, "report_reasons": null, "author": "Loki433", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1awqhei/as_a_new_grad_is_getting_a_masters_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1awqhei/as_a_new_grad_is_getting_a_masters_an/", "subreddit_subscribers": 1359323, "created_utc": 1708556927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: My binary churn prediction model performs way better in development than production. I've listed a few reasons why I think that is, and I'm seeking community help to verify &amp; learn through my mistakes in the process.\n\nHi! I've been working on a churn model at work. It is to be used to predict once per month, which users will churn in the next 30 days. The model performed much better in development (train/test) compared to initial production run.  \nRecall and precision from test: 85%, 85%  \nRecall and precision from production month 1: 60%, 18%\n\nI believe the reasons this happened (which I should've realised sooner) is because of the following:\n\n1. The model was trained on historical churn over 2 years (which resulted in a balanced dataset as over a longer period of time many users eventually churn, especially in the industry I'm in) but the inference in production happens on all \"current active users\" *each month* (This is a pretty imbalanced set as roughly 4-5% users churn each month).\n2. As the inference happens each month on almost the same user-set (current active users), we might end up making the same prediction as previous month especially if there isn't a huge change in user data since last month. i.e we end up carrying forward false-positives from previous month.\n3. Model was only trained on the final states of user-journey. This means I could not include seasonality features as it would leak target data. Why? Because all the non-events (did not churn) \"happen\" on the last month of the training dataset.\n\nJust to add onto point 3, would it have made sense to train model on different points of the user journey instead of just the final state?   \nExample:  \ndata-point 1 :: User 1 features at the end of Jan :: Did not churn  \ndata-point 2 :: User 1 features at the end of Feb :: Did not churn  \ndata-point 3 :: User 1 features at the end of March :: **Churned**\n\n**Is my reasoning correct? What could I do different if I had to do this over?**", "author_fullname": "t2_40233m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Churn prediction: A data imbalance issue, or something else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax45p8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708601239.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708601039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: My binary churn prediction model performs way better in development than production. I&amp;#39;ve listed a few reasons why I think that is, and I&amp;#39;m seeking community help to verify &amp;amp; learn through my mistakes in the process.&lt;/p&gt;\n\n&lt;p&gt;Hi! I&amp;#39;ve been working on a churn model at work. It is to be used to predict once per month, which users will churn in the next 30 days. The model performed much better in development (train/test) compared to initial production run.&lt;br/&gt;\nRecall and precision from test: 85%, 85%&lt;br/&gt;\nRecall and precision from production month 1: 60%, 18%&lt;/p&gt;\n\n&lt;p&gt;I believe the reasons this happened (which I should&amp;#39;ve realised sooner) is because of the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The model was trained on historical churn over 2 years (which resulted in a balanced dataset as over a longer period of time many users eventually churn, especially in the industry I&amp;#39;m in) but the inference in production happens on all &amp;quot;current active users&amp;quot; &lt;em&gt;each month&lt;/em&gt; (This is a pretty imbalanced set as roughly 4-5% users churn each month).&lt;/li&gt;\n&lt;li&gt;As the inference happens each month on almost the same user-set (current active users), we might end up making the same prediction as previous month especially if there isn&amp;#39;t a huge change in user data since last month. i.e we end up carrying forward false-positives from previous month.&lt;/li&gt;\n&lt;li&gt;Model was only trained on the final states of user-journey. This means I could not include seasonality features as it would leak target data. Why? Because all the non-events (did not churn) &amp;quot;happen&amp;quot; on the last month of the training dataset.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Just to add onto point 3, would it have made sense to train model on different points of the user journey instead of just the final state?&lt;br/&gt;\nExample:&lt;br/&gt;\ndata-point 1 :: User 1 features at the end of Jan :: Did not churn&lt;br/&gt;\ndata-point 2 :: User 1 features at the end of Feb :: Did not churn&lt;br/&gt;\ndata-point 3 :: User 1 features at the end of March :: &lt;strong&gt;Churned&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is my reasoning correct? What could I do different if I had to do this over?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ax45p8", "is_robot_indexable": true, "report_reasons": null, "author": "CrypticTac", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax45p8/churn_prediction_a_data_imbalance_issue_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax45p8/churn_prediction_a_data_imbalance_issue_or/", "subreddit_subscribers": 1359323, "created_utc": 1708601039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "With a BS + MS in Statistics I don\u2019t really have any plans to do a PhD. I am more interested in solving problems in the industry than in academia. However, part of me feels \u201cweird\u201d that my education is gonna stop at 24 and I will be working and not getting another degree. But that\u2019s besides the point. My real concern is whether I need to plan on getting some kind of \u201cprofessional\u201d degree after my MS in Stats. When I interviewed for a role the hiring manager (who had no background in anything stem) told me I should consider an MBA to round myself out. Frankly I have no interest in doing an MBA. I\u2019ve gone debt free for my education my whole life (thank you parents for bachelors, and thank you to myself for getting funding for my masters), but in no way do I want to pay for an MBA. \n\nFrom my limited experience it feels like MBAs are just degrees people get to prove to a higher up that they have the credential to get a c suite position. Cause ultimately people hire people and if the directors or c suites have MBAs they know if they have an MBA from xyz university then they are gonna get hired cause of it. \n\nWhat do you guys think, is education after my MS in stats necessary? I mean for me \u201ceducation\u201d post Masters degree is just reading advanced stats textbooks on my own for fun, whether I need to learn something for work or I\u2019m just studying it for my enjoyment. But is a formal \u201cdegree\u201d required? Like I don\u2019t really see the point in me doing a PhD in stats, because I just don\u2019t want to work in an academic setting and frankly I just want money more. \n\nIs there a natural cap with a MS in something technical (stats) for example?\n\n\nEdit: I have the offer and I am gonna be working for them. It\u2019s just the guy said consider one after working for a few years. ", "author_fullname": "t2_uy28jztl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Education beyond a Masters, is it necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax6dgp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708632166.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708608434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With a BS + MS in Statistics I don\u2019t really have any plans to do a PhD. I am more interested in solving problems in the industry than in academia. However, part of me feels \u201cweird\u201d that my education is gonna stop at 24 and I will be working and not getting another degree. But that\u2019s besides the point. My real concern is whether I need to plan on getting some kind of \u201cprofessional\u201d degree after my MS in Stats. When I interviewed for a role the hiring manager (who had no background in anything stem) told me I should consider an MBA to round myself out. Frankly I have no interest in doing an MBA. I\u2019ve gone debt free for my education my whole life (thank you parents for bachelors, and thank you to myself for getting funding for my masters), but in no way do I want to pay for an MBA. &lt;/p&gt;\n\n&lt;p&gt;From my limited experience it feels like MBAs are just degrees people get to prove to a higher up that they have the credential to get a c suite position. Cause ultimately people hire people and if the directors or c suites have MBAs they know if they have an MBA from xyz university then they are gonna get hired cause of it. &lt;/p&gt;\n\n&lt;p&gt;What do you guys think, is education after my MS in stats necessary? I mean for me \u201ceducation\u201d post Masters degree is just reading advanced stats textbooks on my own for fun, whether I need to learn something for work or I\u2019m just studying it for my enjoyment. But is a formal \u201cdegree\u201d required? Like I don\u2019t really see the point in me doing a PhD in stats, because I just don\u2019t want to work in an academic setting and frankly I just want money more. &lt;/p&gt;\n\n&lt;p&gt;Is there a natural cap with a MS in something technical (stats) for example?&lt;/p&gt;\n\n&lt;p&gt;Edit: I have the offer and I am gonna be working for them. It\u2019s just the guy said consider one after working for a few years. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1ax6dgp", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Touch469", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax6dgp/education_beyond_a_masters_is_it_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax6dgp/education_beyond_a_masters_is_it_necessary/", "subreddit_subscribers": 1359323, "created_utc": 1708608434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi data science Reddit. To those who employ causal inference and work in Python, you may find the new Forward Difference-in-Differences estimator of interest. [The code](https://github.com/jgreathouse9/FDIDTutorial/blob/main/Vignette.md) (still being refined, tightened, and expanded) is avaliable on my Github, along with two applied empirical examples from the econometrics literature. Use it and give feedback, should you wish. ", "author_fullname": "t2_amhd0mtb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction for Forward DID: A New Causal Inference Estimator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1axap5v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708619549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data science Reddit. To those who employ causal inference and work in Python, you may find the new Forward Difference-in-Differences estimator of interest. &lt;a href=\"https://github.com/jgreathouse9/FDIDTutorial/blob/main/Vignette.md\"&gt;The code&lt;/a&gt; (still being refined, tightened, and expanded) is avaliable on my Github, along with two applied empirical examples from the econometrics literature. Use it and give feedback, should you wish. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?auto=webp&amp;s=c6432c6b15633c240caedb345355f503ed188ff1", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d9e9c23a71de1db492bae1505665defeccf6da3a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=89f71f3298eb1fd9b1be06ffc86d9abd446f1d77", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2de251b256e8e16a0a06d4a851e19496f7b0123", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0361fec45fa9ced606fb4cd587d39c0692fccfb4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49e0d64d812c320d66df3f9a8d50bc87962a1ee4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b0af1efae9adf07acbb7b67cf479004090ae7296", "width": 1080, "height": 540}], "variants": {}, "id": "QVPhBjSi6MZSruvwLP31Y9CGVajgVwn9KoQeAxRsBJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1axap5v", "is_robot_indexable": true, "report_reasons": null, "author": "turingincarnate", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1axap5v/introduction_for_forward_did_a_new_causal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1axap5v/introduction_for_forward_did_a_new_causal/", "subreddit_subscribers": 1359323, "created_utc": 1708619549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, long time lurker, first time poster. I've been working on an AI assisted data pseudonymization app recently. Basically the idea is that you can build pseudonymization pipelines in the cloud with the help of an AI assistant that generates a template pipeline for you based on the uploaded contents (shameless plug, check out the app [seudo](https://seudo.alpn-software.com) here if you're interested).\n\nIn a nutshell, I need to be able to classify a data column in a CSV as either personal data or not. I'm interested in getting peoples thoughts on how to generate a feature space. What I've done so far is generate a feature vector using the column name and a sample value by running it through a bunch of regex expressions that check for common PI patterns in the data values and in the column name. I've also added some other basic string metrics (how long, how many vowels etc), and trained a random forrest classifier on a dataset that I generated.\n\nIt was loosely based on [this](https://medium.com/cape-ai-stories/case-study-using-machine-learning-to-classify-personally-identifiable-data-fields-6b9c5b0743e7) article (very loosely), and the results are mixed. The article in question was specific to a given region in SA, and doesnt generalise well to other parts of the world. Anyone done anything similar before? How would you go about generating a feature space to train a model?\n\nIf you're interested and have a minute, feel free to check out the app as well (link above). Any feedback is always appreciated.", "author_fullname": "t2_bep31tvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Classification Model for Personal Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax1ii5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708590570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, long time lurker, first time poster. I&amp;#39;ve been working on an AI assisted data pseudonymization app recently. Basically the idea is that you can build pseudonymization pipelines in the cloud with the help of an AI assistant that generates a template pipeline for you based on the uploaded contents (shameless plug, check out the app &lt;a href=\"https://seudo.alpn-software.com\"&gt;seudo&lt;/a&gt; here if you&amp;#39;re interested).&lt;/p&gt;\n\n&lt;p&gt;In a nutshell, I need to be able to classify a data column in a CSV as either personal data or not. I&amp;#39;m interested in getting peoples thoughts on how to generate a feature space. What I&amp;#39;ve done so far is generate a feature vector using the column name and a sample value by running it through a bunch of regex expressions that check for common PI patterns in the data values and in the column name. I&amp;#39;ve also added some other basic string metrics (how long, how many vowels etc), and trained a random forrest classifier on a dataset that I generated.&lt;/p&gt;\n\n&lt;p&gt;It was loosely based on &lt;a href=\"https://medium.com/cape-ai-stories/case-study-using-machine-learning-to-classify-personally-identifiable-data-fields-6b9c5b0743e7\"&gt;this&lt;/a&gt; article (very loosely), and the results are mixed. The article in question was specific to a given region in SA, and doesnt generalise well to other parts of the world. Anyone done anything similar before? How would you go about generating a feature space to train a model?&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested and have a minute, feel free to check out the app as well (link above). Any feedback is always appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1ax1ii5", "is_robot_indexable": true, "report_reasons": null, "author": "OkInteraction493", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax1ii5/classification_model_for_personal_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax1ii5/classification_model_for_personal_data/", "subreddit_subscribers": 1359323, "created_utc": 1708590570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to implement the R\u2019s random forest classifier equivalent in python:\n\n    # train random forest\n       \n    set.seed(5136)  \n    ty.rf = randomForest(y=ty.y, x= ty.x, ntree=1000, importance=T, strata=ty.y, sampsize=c(100,100), do.trace=10, proximity=T)  \n\nThe above classifier was implemented for an imbalanced data.\n\nI had tried to implement the above as following in python.\n\nHere\u2019s my implementation in python:\n\n    # random forest      \n    \n    rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),  \n    \n    ('model',RandomForestClassifier(n_estimators=1000,class_weight='balanced', random_state=5136, oob_score=True, bootstrap = True))])    rf_pipeline.fit(ty_x, ty_y)   \n\nIs this the equivalent syntax here? Also, after implementation in R code OOB estimate of error rate: 19.41% and in python OOB estimate of error rate: 7.14%, is this expected? I was expecting the oob\\_error to be similar. Can someone please clarify?", "author_fullname": "t2_p657jjww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Random Forest classifier in R vs scikit-learn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax6pw1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708636263.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708609457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to implement the R\u2019s random forest classifier equivalent in python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# train random forest\n\nset.seed(5136)  \nty.rf = randomForest(y=ty.y, x= ty.x, ntree=1000, importance=T, strata=ty.y, sampsize=c(100,100), do.trace=10, proximity=T)  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The above classifier was implemented for an imbalanced data.&lt;/p&gt;\n\n&lt;p&gt;I had tried to implement the above as following in python.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s my implementation in python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# random forest      \n\nrf_pipeline = Pipeline(steps=[(&amp;#39;preprocessor&amp;#39;, preprocessor),  \n\n(&amp;#39;model&amp;#39;,RandomForestClassifier(n_estimators=1000,class_weight=&amp;#39;balanced&amp;#39;, random_state=5136, oob_score=True, bootstrap = True))])    rf_pipeline.fit(ty_x, ty_y)   \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this the equivalent syntax here? Also, after implementation in R code OOB estimate of error rate: 19.41% and in python OOB estimate of error rate: 7.14%, is this expected? I was expecting the oob_error to be similar. Can someone please clarify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1ax6pw1", "is_robot_indexable": true, "report_reasons": null, "author": "tinkerpal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax6pw1/d_random_forest_classifier_in_r_vs_scikitlearn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax6pw1/d_random_forest_classifier_in_r_vs_scikitlearn/", "subreddit_subscribers": 1359323, "created_utc": 1708609457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a weekly time series model, with 8 weeks as the forecasting horizon. There are 4 exogenous variables, which I forecast also 8 weeks ahead and use as the input for the target variable forecast.\n\nNow I run this model every Monday. My teammate, without much time series knowledge, suggests that the model does not need to be retrained every week, and just train every 4 weeks or so.\n\nI understand the models like classification does not need to be retrained very often. With the sensitive of the time series, I think it would be necessary to include the new data especially the data is less granular like weekly.\n\nWhat is the best practice?", "author_fullname": "t2_12x43b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often to retrain the time series forecasting model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1axdyu8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708627109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a weekly time series model, with 8 weeks as the forecasting horizon. There are 4 exogenous variables, which I forecast also 8 weeks ahead and use as the input for the target variable forecast.&lt;/p&gt;\n\n&lt;p&gt;Now I run this model every Monday. My teammate, without much time series knowledge, suggests that the model does not need to be retrained every week, and just train every 4 weeks or so.&lt;/p&gt;\n\n&lt;p&gt;I understand the models like classification does not need to be retrained very often. With the sensitive of the time series, I think it would be necessary to include the new data especially the data is less granular like weekly.&lt;/p&gt;\n\n&lt;p&gt;What is the best practice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1axdyu8", "is_robot_indexable": true, "report_reasons": null, "author": "janicewa", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1axdyu8/how_often_to_retrain_the_time_series_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1axdyu8/how_often_to_retrain_the_time_series_forecasting/", "subreddit_subscribers": 1359323, "created_utc": 1708627109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys! I wonder if it is possible to train an LLM model, like BERT, to be able to associate a word with another word. For example, \"Blue\" -&gt; \"Sky\" (the model associates the word \"Blue\" with \"Sky\"). Cheers!", "author_fullname": "t2_3j4e33js", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Word Association with LLM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax4lu1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.47, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708602720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! I wonder if it is possible to train an LLM model, like BERT, to be able to associate a word with another word. For example, &amp;quot;Blue&amp;quot; -&amp;gt; &amp;quot;Sky&amp;quot; (the model associates the word &amp;quot;Blue&amp;quot; with &amp;quot;Sky&amp;quot;). Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1ax4lu1", "is_robot_indexable": true, "report_reasons": null, "author": "OxheadGreg123", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax4lu1/word_association_with_llm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax4lu1/word_association_with_llm/", "subreddit_subscribers": 1359323, "created_utc": 1708602720.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}