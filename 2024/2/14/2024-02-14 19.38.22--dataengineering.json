{"kind": "Listing", "data": {"after": "t3_1aqbjlu", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m writing this post after, admittedly, never having used a \u201cdata lake\u201d (I think) but have thought I knew what it was\u2026 on a few different occasions.\n\nI know it\u2019s a place to store data, but what data structure does it use? Presumably, it is a directory structure and storage is nonmutable\u2026 block storage, like S3. is that it?\n\nThen there\u2019s MongoDB Atlas which says it\u2019s a Data Lake and I\u2019m like wtf\u2026 I\u2019ve used Mongo before to record some JSON documents without a schema, but that\u2019s not what I know a Data Lake to be. Unless \u201cAtlas\u201d is something else\u2026\n\nSo now I\u2019m wondering, is a Data Lake less about the underlying structure and properties, and more about what goes in (raw data) and what derived data comes out (effectively ELT). Is this general idea, being used at large scale, what constitutes a \u201cData Lake?\u201d\n\nHelp me out here guy please.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What the Hell is a Data Lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqq9vc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707926350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m writing this post after, admittedly, never having used a \u201cdata lake\u201d (I think) but have thought I knew what it was\u2026 on a few different occasions.&lt;/p&gt;\n\n&lt;p&gt;I know it\u2019s a place to store data, but what data structure does it use? Presumably, it is a directory structure and storage is nonmutable\u2026 block storage, like S3. is that it?&lt;/p&gt;\n\n&lt;p&gt;Then there\u2019s MongoDB Atlas which says it\u2019s a Data Lake and I\u2019m like wtf\u2026 I\u2019ve used Mongo before to record some JSON documents without a schema, but that\u2019s not what I know a Data Lake to be. Unless \u201cAtlas\u201d is something else\u2026&lt;/p&gt;\n\n&lt;p&gt;So now I\u2019m wondering, is a Data Lake less about the underlying structure and properties, and more about what goes in (raw data) and what derived data comes out (effectively ELT). Is this general idea, being used at large scale, what constitutes a \u201cData Lake?\u201d&lt;/p&gt;\n\n&lt;p&gt;Help me out here guy please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqq9vc", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqq9vc/what_the_hell_is_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqq9vc/what_the_hell_is_a_data_lake/", "subreddit_subscribers": 160711, "created_utc": 1707926350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DBT announced a preview of a much requested feature - Column Level Lineage. \n\nThe only catch is you have to be a Cloud customer. \nDoes anyone know anymore about this and if it is coming to core?", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Column Level Lineage only for DBT Cloud customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqcvov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/z0lsxARMTCcEEhwTC0HsMFN-HuXPgaFLzzHTjhKPrd4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707880629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DBT announced a preview of a much requested feature - Column Level Lineage. &lt;/p&gt;\n\n&lt;p&gt;The only catch is you have to be a Cloud customer. \nDoes anyone know anymore about this and if it is coming to core?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?auto=webp&amp;s=cafd219029f0a3fbdad0ea8a2bcb66b3d78fde14", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b5c9815894c457c0876c8aa0738f085af8f7af8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1dd3758c396fe36d709ad00886acb150a1d9067d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94fcab0f230d58e3de92c5d7c2a2785144251838", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5a80590e63ba05ee3f1af94bd9e60ae2df5308a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=815507f574255f6785c16ea52b6bab5afc4d00bc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de48a264c01939fe48a8bdfeb28423431ccc3644", "width": 1080, "height": 567}], "variants": {}, "id": "DrZJUagpOb_HgXmGsRTaz04SkfN1EZhQLY4JvbX2Wb0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqcvov", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqcvov/dbt_column_level_lineage_only_for_dbt_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/", "subreddit_subscribers": 160711, "created_utc": 1707880629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you tried the following\n\nDremio\nTrino\nPresto\n\nIf you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? \n\nReally interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you tried these tools? If not, why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6dbj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707862868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried the following&lt;/p&gt;\n\n&lt;p&gt;Dremio\nTrino\nPresto&lt;/p&gt;\n\n&lt;p&gt;If you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? &lt;/p&gt;\n\n&lt;p&gt;Really interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq6dbj", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "subreddit_subscribers": 160711, "created_utc": 1707862868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " To process the 100 Gb of a file what is the bare minimum resources requirement for the spark job?\nHow many partitions will it create?\nWhat will be number of executors, cores, executor size?", "author_fullname": "t2_ojn8xr0i2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqhsg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707897837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To process the 100 Gb of a file what is the bare minimum resources requirement for the spark job?\nHow many partitions will it create?\nWhat will be number of executors, cores, executor size?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1aqhsg8", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic-Bell5386", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqhsg8/interview_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqhsg8/interview_question/", "subreddit_subscribers": 160711, "created_utc": 1707897837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6smf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My company just let me open source our orchestration tool 'Houston', an API based alternative to Airflow/Google Cloud Composer that we've been using internally for the last 4 years! It's great for low-cost, high-speed data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqmnx0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TvbgM6XU5pRyFVegumxyMoPZh1883NVwept3GPI1g3k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707916658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/datasparq-ai/houston", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?auto=webp&amp;s=17c406bb32ad5a30266b69dcafb176b148c7fceb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7cc92a3c283476dfb4ca5ec88b8c435c585f714", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7dbbe0719b6f282a0b4461814d45feece159c29", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=17d6dba66cf3894f446dbc9a27436cce9044e537", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5dbd07c99f928596baeb8c555a795120709030c9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7bcef0cc1f4098d67802083b47f3c830ae462678", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d61dfa599bfd7d04c0ca769ffa605657ad949911", "width": 1080, "height": 540}], "variants": {}, "id": "P67HJGdlWqP7-f47wdx-g-YFOqw7poBol8WKVocacEQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1aqmnx0", "is_robot_indexable": true, "report_reasons": null, "author": "flo0d", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqmnx0/my_company_just_let_me_open_source_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/datasparq-ai/houston", "subreddit_subscribers": 160711, "created_utc": 1707916658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**I am checking into multiple catalogs and I am  curious.**   \n*Have any of you set one up? Which one did you choose and why?* \n\n*What was the actual need for the data catalog in the first place?*   \n\n\n**For those who are working with catalogs:**  \n*How is it going? Was there any big change in how you work with your data or with your team?*  \n*Did anyone had any big wins by implementing a catalog?*  \n\n\n  \nSorry for asking too much questions. Any insights on the topic is appreciated !  \n\n\nThanks. ", "author_fullname": "t2_o78u2p44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who's Using Data Catalogs? Need your insights !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq7xh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707866755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;I am checking into multiple catalogs and I am  curious.&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;Have any of you set one up? Which one did you choose and why?&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;What was the actual need for the data catalog in the first place?&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;For those who are working with catalogs:&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;How is it going? Was there any big change in how you work with your data or with your team?&lt;/em&gt;&lt;br/&gt;\n&lt;em&gt;Did anyone had any big wins by implementing a catalog?&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;Sorry for asking too much questions. Any insights on the topic is appreciated !  &lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq7xh9", "is_robot_indexable": true, "report_reasons": null, "author": "SignificanceNo136", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "subreddit_subscribers": 160711, "created_utc": 1707866755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am at my 3rd company in my career that had executives release a mandate that \"we must move all of our infrastructure to the cloud\"... Because \"it has faster integration\"... And \"it will lower costs over *insert time horizon here*\"... \n\nThen followed by those executives bosses saying... \"You promised me value with the cloud ... Show me... Because these bills are outrageous\"...\n\nWhich is then followed by those executives (the ones who made the mandate and over promised to their superiors) laying people off because they realize they can't quickly unravel their cloud dreams (projects in flight and halfway or more to cloud already) but they can save money by laying people off... \n\nJust a sad state of affairs. Cloud is not for every situation and to sell top level executives on costs savings alone is basically setting all the IC's up for failure because those savings are never truly realized and should have never been used as a selling point. It's really just a shame ... When does it stop?", "author_fullname": "t2_90434l9q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When will \"we need to be on cloud\" statements stop with executive's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqsmoc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707932106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am at my 3rd company in my career that had executives release a mandate that &amp;quot;we must move all of our infrastructure to the cloud&amp;quot;... Because &amp;quot;it has faster integration&amp;quot;... And &amp;quot;it will lower costs over &lt;em&gt;insert time horizon here&lt;/em&gt;&amp;quot;... &lt;/p&gt;\n\n&lt;p&gt;Then followed by those executives bosses saying... &amp;quot;You promised me value with the cloud ... Show me... Because these bills are outrageous&amp;quot;...&lt;/p&gt;\n\n&lt;p&gt;Which is then followed by those executives (the ones who made the mandate and over promised to their superiors) laying people off because they realize they can&amp;#39;t quickly unravel their cloud dreams (projects in flight and halfway or more to cloud already) but they can save money by laying people off... &lt;/p&gt;\n\n&lt;p&gt;Just a sad state of affairs. Cloud is not for every situation and to sell top level executives on costs savings alone is basically setting all the IC&amp;#39;s up for failure because those savings are never truly realized and should have never been used as a selling point. It&amp;#39;s really just a shame ... When does it stop?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqsmoc", "is_robot_indexable": true, "report_reasons": null, "author": "Imaginary-Ad2828", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqsmoc/when_will_we_need_to_be_on_cloud_statements_stop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqsmoc/when_will_we_need_to_be_on_cloud_statements_stop/", "subreddit_subscribers": 160711, "created_utc": 1707932106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cb1if", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New DuckDB Array Type used for Vector databasing on top of Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 95, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqk7rs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/42h9thB8-GeclxIVqfxJQDkNwDSikQGRInIKhEWrsK0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707908193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luukvandervelden.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luukvandervelden.medium.com/vector-databasing-with-duckdb-on-top-of-pgvector-ec182f815a16?source=friends_link&amp;sk=041d8e614e2b4ada23af79205661e0d3", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?auto=webp&amp;s=878da16648a19e0a41a91ea1d43a9d22588c9b6e", "width": 1200, "height": 818}, "resolutions": [{"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25a16cb9c2b3fb03fa149eae5c0633f7ca0f4438", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=03c3c9a18844192231c7415e5c28ffc94cee8add", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14c7010de6e028feb9e101ed3321807ca7d15804", "width": 320, "height": 218}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02164756c7fb2a3f15838d538f406601d4582b71", "width": 640, "height": 436}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6227708b6bf2c031d7ea9342304b02984aa59a35", "width": 960, "height": 654}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=393ef36f0a2613fff4c04d265e20df598d53768b", "width": 1080, "height": 736}], "variants": {}, "id": "GafSvdTOfJuSt6EJ5qOfvDVJZbZAQVpDEk6MBKtOShk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqk7rs", "is_robot_indexable": true, "report_reasons": null, "author": "squareape", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqk7rs/new_duckdb_array_type_used_for_vector_databasing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luukvandervelden.medium.com/vector-databasing-with-duckdb-on-top-of-pgvector-ec182f815a16?source=friends_link&amp;sk=041d8e614e2b4ada23af79205661e0d3", "subreddit_subscribers": 160711, "created_utc": 1707908193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI'm currently an apprentice data engineer and in my second year of a master's program in data and AI.\n\nI've been asked to choose a certification to pursue, but I have little to no practical experience in data engineering. I'm familiar with SQL, Python, and have a basic understanding of MongoDB, as well as concepts like ETL and data warehousing. I've been advised to pursue Azure certifications since it's the most widely used cloud provider.\n\nWhich certification would you recommend for someone in my position to gain solid knowledge in data engineering?\n\nThanks again \ud83d\ude04", "author_fullname": "t2_8aldnk2t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which certification should I get ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqjqpf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707906287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently an apprentice data engineer and in my second year of a master&amp;#39;s program in data and AI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked to choose a certification to pursue, but I have little to no practical experience in data engineering. I&amp;#39;m familiar with SQL, Python, and have a basic understanding of MongoDB, as well as concepts like ETL and data warehousing. I&amp;#39;ve been advised to pursue Azure certifications since it&amp;#39;s the most widely used cloud provider.&lt;/p&gt;\n\n&lt;p&gt;Which certification would you recommend for someone in my position to gain solid knowledge in data engineering?&lt;/p&gt;\n\n&lt;p&gt;Thanks again \ud83d\ude04&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aqjqpf", "is_robot_indexable": true, "report_reasons": null, "author": "tn_receptionist_1520", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqjqpf/which_certification_should_i_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqjqpf/which_certification_should_i_get/", "subreddit_subscribers": 160711, "created_utc": 1707906287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in an organization that has built custom tooling, but there are many issues, and I'm looking into alternatives. I'm particularly concerned with orchestration, ELT tooling, and schema management. I've got my eyes on dagster + dbt right now, but I'm not sure they'll work for my purposes just yet.\n\nSome architecture that cannot change:\n\n* There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same\n* Due to the above, there must be a DAG instance per customer, for each DAG specification\n* Something is needed to manage schema updates and create new databases with up-to-date schemas\n\nI imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven't been able to easily discern this from documentation.\n\nI don't fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I'd only work with abstractions, or if I'd be working with underlying tables. I'm not really looking for an ORM. I'm looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.\n\nAny recommendations are appreciated! I'm just looking very high level right now.", "author_fullname": "t2_89dmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking recommendation for tools that will work for a specific architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq8qdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707868806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in an organization that has built custom tooling, but there are many issues, and I&amp;#39;m looking into alternatives. I&amp;#39;m particularly concerned with orchestration, ELT tooling, and schema management. I&amp;#39;ve got my eyes on dagster + dbt right now, but I&amp;#39;m not sure they&amp;#39;ll work for my purposes just yet.&lt;/p&gt;\n\n&lt;p&gt;Some architecture that cannot change:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same&lt;/li&gt;\n&lt;li&gt;Due to the above, there must be a DAG instance per customer, for each DAG specification&lt;/li&gt;\n&lt;li&gt;Something is needed to manage schema updates and create new databases with up-to-date schemas&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven&amp;#39;t been able to easily discern this from documentation.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I&amp;#39;d only work with abstractions, or if I&amp;#39;d be working with underlying tables. I&amp;#39;m not really looking for an ORM. I&amp;#39;m looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations are appreciated! I&amp;#39;m just looking very high level right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq8qdc", "is_robot_indexable": true, "report_reasons": null, "author": "endotronic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "subreddit_subscribers": 160711, "created_utc": 1707868806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently working as a Data Analyst but want to become a Data Engineer in the future. As apart of my discussed promotion, I\u2019m working with our pipelining team more and doing more ETL work. \n\nIt\u2019s possible that I could negotiate a change in title from DA to DE with the promotion. \n\nWould this really benefit me long term?", "author_fullname": "t2_4gm2xwt2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does title matter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqogdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707921699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working as a Data Analyst but want to become a Data Engineer in the future. As apart of my discussed promotion, I\u2019m working with our pipelining team more and doing more ETL work. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s possible that I could negotiate a change in title from DA to DE with the promotion. &lt;/p&gt;\n\n&lt;p&gt;Would this really benefit me long term?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aqogdc", "is_robot_indexable": true, "report_reasons": null, "author": "bcw28511", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqogdc/how_much_does_title_matter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqogdc/how_much_does_title_matter/", "subreddit_subscribers": 160711, "created_utc": 1707921699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are seeing very weird issue with our environment \n\nSo we run multiple notebooks in parallel on same compute\n\nLets say there are 2 notebooks running\nDimCustomer &amp; DimOrder\n\nBoth have variable names var_x and in first notebook we assign value DimCustomer to var_x and in second notebook we assign DimOrder to var_x\n\nBoth has data stored in dataframe variable called df\n\nWe are writing this df as table in databricks catalogue\n\nIntermittently we see that DimCustomer has data of DimOrder\n\nRe-running process alone will fix the issue, but should this even happen in first place?", "author_fullname": "t2_50u0h0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataframe overwritten using data from another notebook - Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqee7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707885360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are seeing very weird issue with our environment &lt;/p&gt;\n\n&lt;p&gt;So we run multiple notebooks in parallel on same compute&lt;/p&gt;\n\n&lt;p&gt;Lets say there are 2 notebooks running\nDimCustomer &amp;amp; DimOrder&lt;/p&gt;\n\n&lt;p&gt;Both have variable names var_x and in first notebook we assign value DimCustomer to var_x and in second notebook we assign DimOrder to var_x&lt;/p&gt;\n\n&lt;p&gt;Both has data stored in dataframe variable called df&lt;/p&gt;\n\n&lt;p&gt;We are writing this df as table in databricks catalogue&lt;/p&gt;\n\n&lt;p&gt;Intermittently we see that DimCustomer has data of DimOrder&lt;/p&gt;\n\n&lt;p&gt;Re-running process alone will fix the issue, but should this even happen in first place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqee7l", "is_robot_indexable": true, "report_reasons": null, "author": "dilkushpatel", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/", "subreddit_subscribers": 160711, "created_utc": 1707885360.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all.  Question about DBT testing.  \n\n1. is there a DBT sub that I cant find?\n\nWe have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR's proposed changes to that model.\n\n    SELECT \n        CASE \n            WHEN (SELECT COUNT(*) AS ROW_CNT\n                    FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n                = (SELECT COUNT(*) AS ROW_CNT\n                    FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            THEN 'Success!'\n            ELSE 'PR changed row count'\n        END AS STATUS\n\nI was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn't want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:\n\n    MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n    DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n\nSure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn't have a row count change.  \n\nIt also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR's are supposed to change the model's row count, so we wouldn't run this test on every model, and we would just skip it for those.\n\nBut also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_b12wxz418", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT generic schema tests questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6kpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707863377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.  Question about DBT testing.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;is there a DBT sub that I cant find?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR&amp;#39;s proposed changes to that model.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT \n    CASE \n        WHEN (SELECT COUNT(*) AS ROW_CNT\n                FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            = (SELECT COUNT(*) AS ROW_CNT\n                FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n        THEN &amp;#39;Success!&amp;#39;\n        ELSE &amp;#39;PR changed row count&amp;#39;\n    END AS STATUS\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn&amp;#39;t want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\nDBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Sure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn&amp;#39;t have a row count change.  &lt;/p&gt;\n\n&lt;p&gt;It also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR&amp;#39;s are supposed to change the model&amp;#39;s row count, so we wouldn&amp;#39;t run this test on every model, and we would just skip it for those.&lt;/p&gt;\n\n&lt;p&gt;But also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq6kpm", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Goose82", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "subreddit_subscribers": 160711, "created_utc": 1707863377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi all,\nhere's the scenario.  \n\nI've data in another company's MySQL DB. \nI don't have access to it, hence they've exported it into .SQL files.  These files have all the data as insert queries and create table statements.  \n\nNow the issue is, what I've is an SQL server  2016. Since these syntaxes won't support in SQL server. How can I load these data into SQL server tables? I don't have the option for an intermediate MySql db.\n\nOr in simple words, is there a way to convert this .SQL file data without access to a MySQL instance?", "author_fullname": "t2_5ks2jegk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting MySQL DB to SQL Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqkvme", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707918740.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707910686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi all,\nhere&amp;#39;s the scenario.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve data in another company&amp;#39;s MySQL DB. \nI don&amp;#39;t have access to it, hence they&amp;#39;ve exported it into .SQL files.  These files have all the data as insert queries and create table statements.  &lt;/p&gt;\n\n&lt;p&gt;Now the issue is, what I&amp;#39;ve is an SQL server  2016. Since these syntaxes won&amp;#39;t support in SQL server. How can I load these data into SQL server tables? I don&amp;#39;t have the option for an intermediate MySql db.&lt;/p&gt;\n\n&lt;p&gt;Or in simple words, is there a way to convert this .SQL file data without access to a MySQL instance?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqkvme", "is_robot_indexable": true, "report_reasons": null, "author": "das3012", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqkvme/converting_mysql_db_to_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqkvme/converting_mysql_db_to_sql_server/", "subreddit_subscribers": 160711, "created_utc": 1707910686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have not come across any resources which describe how to integrate Soda core with Delta lake. Does anyone have experience with this implementation? thanks!", "author_fullname": "t2_4wgaqe7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soda core for Delta lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqfd8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707888601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have not come across any resources which describe how to integrate Soda core with Delta lake. Does anyone have experience with this implementation? thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqfd8q", "is_robot_indexable": true, "report_reasons": null, "author": "Islamic_justice", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/", "subreddit_subscribers": 160711, "created_utc": 1707888601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The company I am working for looking to roll out dashboards for their app. The idea would be to embed the dashboard in an existing web app. \n\nAs a proof of concept, I created a quick prototype using Power BI, but never tried using Tableau. I was wondering if someone had experience with doing the same with Tableau.   \n\n\nDoes this work with Tableau? How was the experience? Any problems I should be aware? ", "author_fullname": "t2_h58nyr96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embedding Tableau dashboards in a web app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqhrti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707897765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The company I am working for looking to roll out dashboards for their app. The idea would be to embed the dashboard in an existing web app. &lt;/p&gt;\n\n&lt;p&gt;As a proof of concept, I created a quick prototype using Power BI, but never tried using Tableau. I was wondering if someone had experience with doing the same with Tableau.   &lt;/p&gt;\n\n&lt;p&gt;Does this work with Tableau? How was the experience? Any problems I should be aware? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqhrti", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyFish7104", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqhrti/embedding_tableau_dashboards_in_a_web_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqhrti/embedding_tableau_dashboards_in_a_web_app/", "subreddit_subscribers": 160711, "created_utc": 1707897765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI recently completed the IBM Data Engineering Professional Certificate and don\u2019t know what to do now. I\u2019m currently reading \u201cFundamentals of Data Engineering\u201d to connect the dots of what I learned in the data engineering certificate. Any recommendations on what I should I do next?\n\nBackground about me: I\u2019m in tech sales and want to get more into the solution engineering or technical account manager route. \n\nThanks!", "author_fullname": "t2_59z2hc1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Completed IBM Data Engineering Professional Certificate. Now what?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqbftj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707876359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I recently completed the IBM Data Engineering Professional Certificate and don\u2019t know what to do now. I\u2019m currently reading \u201cFundamentals of Data Engineering\u201d to connect the dots of what I learned in the data engineering certificate. Any recommendations on what I should I do next?&lt;/p&gt;\n\n&lt;p&gt;Background about me: I\u2019m in tech sales and want to get more into the solution engineering or technical account manager route. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aqbftj", "is_robot_indexable": true, "report_reasons": null, "author": "Cheetohcrank", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqbftj/completed_ibm_data_engineering_professional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqbftj/completed_ibm_data_engineering_professional/", "subreddit_subscribers": 160711, "created_utc": 1707876359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning AWS and have some parquet files I would like to import into Redshift.  They are in an S3 bucket in the same region as my Redshift and Glue instances.\n\nThe structure is: YYYY/MM/DD/ELEMENT/x.parquet (examples: 2024/01/30/carOEM/875817ui23b.parquet and 2024/02/5/carModel/7647u21.parquet\n\nWhat would be the best method to importing all of these parquet files into their respective Redshift tables?\n\nI have tried something like multiple rules with '2024/\\*\\*/\\*\\*/carOEM/ and carModel/' but both resulted in constant failures when running, success was seen only when I was explicit, eg: 2024/02/5/carModel/\n\nThanks!", "author_fullname": "t2_4c8ud9yw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to import parquet files into multiple Redshift tables based on source directory name using AWS Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqavuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707876381.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707874766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning AWS and have some parquet files I would like to import into Redshift.  They are in an S3 bucket in the same region as my Redshift and Glue instances.&lt;/p&gt;\n\n&lt;p&gt;The structure is: YYYY/MM/DD/ELEMENT/x.parquet (examples: 2024/01/30/carOEM/875817ui23b.parquet and 2024/02/5/carModel/7647u21.parquet&lt;/p&gt;\n\n&lt;p&gt;What would be the best method to importing all of these parquet files into their respective Redshift tables?&lt;/p&gt;\n\n&lt;p&gt;I have tried something like multiple rules with &amp;#39;2024/**/**/carOEM/ and carModel/&amp;#39; but both resulted in constant failures when running, success was seen only when I was explicit, eg: 2024/02/5/carModel/&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqavuu", "is_robot_indexable": true, "report_reasons": null, "author": "crampedTurtle", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqavuu/best_way_to_import_parquet_files_into_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqavuu/best_way_to_import_parquet_files_into_multiple/", "subreddit_subscribers": 160711, "created_utc": 1707874766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your favorite BI tool, where do you usually serve the data from (data warehouse, database, data lake).\n\nWhat do you like best about it and what techniques do you use for accelerating BI (cubes, extracts, reflections).", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite BI Tool, and why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqq4x1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707925986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your favorite BI tool, where do you usually serve the data from (data warehouse, database, data lake).&lt;/p&gt;\n\n&lt;p&gt;What do you like best about it and what techniques do you use for accelerating BI (cubes, extracts, reflections).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqq4x1", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqq4x1/favorite_bi_tool_and_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqq4x1/favorite_bi_tool_and_why/", "subreddit_subscribers": 160711, "created_utc": 1707925986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our Team, which it is composed of 1 data engineer, 1 data analyst, 1 data scientist, and a manager is the responsible of about 20-25 data products, most of them dashboard, and a couple of small webapps. Most of our stakeholders are withing the company, which requiere data visualization and simple analysis for creating reports for their clients.\n\nAll of us are capable of writing code, not as robust as the data engineer that is also a programmer. We create the whole data pipeline including the ETL (or ELT) for the data products. A really hard effort is being made to maintain these data products updated, most are dependable of scraping, unofficial APIs, and reading published excels on online pages for data acquisition, this creates a problem into maintaining the data products updated. Most of us are focused on the development of the data pipeline, ETL processes and correcting any changes that are made to the sources for data acquisition. We also create, by requests, small dashboard that do not need to be updated after delivery.\n\n* Where does de responsibility of maintaining the data product updated lies?\n* Who is going to periodically check the dashboard to see if it has the last readily available data? \n* Is normal for a small team to have in scope to many third-party data sources, some of them unreliable as an excel or scraped data? \n* Do the team need to highlight the weaknesses of these type of connections or does the team have to put its food down when unreliable sources are chosen for a data product? \n\nCurrently we are hold responsible for any outdated data on the dashboards, even from weak sources which are determined by the stakeholders. Also, because the data sources are third-party, we have little observability into changes on it which can disrupt the data pipeline and mess-up our workload. \n\nI'm opening the discussion of how a team can navigate these situations and what's is a reasonable scope for a small team to be sustainable in their delivery and quality. ", "author_fullname": "t2_qsq7zvwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this workload sustainable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqpa3y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707923845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our Team, which it is composed of 1 data engineer, 1 data analyst, 1 data scientist, and a manager is the responsible of about 20-25 data products, most of them dashboard, and a couple of small webapps. Most of our stakeholders are withing the company, which requiere data visualization and simple analysis for creating reports for their clients.&lt;/p&gt;\n\n&lt;p&gt;All of us are capable of writing code, not as robust as the data engineer that is also a programmer. We create the whole data pipeline including the ETL (or ELT) for the data products. A really hard effort is being made to maintain these data products updated, most are dependable of scraping, unofficial APIs, and reading published excels on online pages for data acquisition, this creates a problem into maintaining the data products updated. Most of us are focused on the development of the data pipeline, ETL processes and correcting any changes that are made to the sources for data acquisition. We also create, by requests, small dashboard that do not need to be updated after delivery.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Where does de responsibility of maintaining the data product updated lies?&lt;/li&gt;\n&lt;li&gt;Who is going to periodically check the dashboard to see if it has the last readily available data? &lt;/li&gt;\n&lt;li&gt;Is normal for a small team to have in scope to many third-party data sources, some of them unreliable as an excel or scraped data? &lt;/li&gt;\n&lt;li&gt;Do the team need to highlight the weaknesses of these type of connections or does the team have to put its food down when unreliable sources are chosen for a data product? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Currently we are hold responsible for any outdated data on the dashboards, even from weak sources which are determined by the stakeholders. Also, because the data sources are third-party, we have little observability into changes on it which can disrupt the data pipeline and mess-up our workload. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m opening the discussion of how a team can navigate these situations and what&amp;#39;s is a reasonable scope for a small team to be sustainable in their delivery and quality. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqpa3y", "is_robot_indexable": true, "report_reasons": null, "author": "sodatacram", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqpa3y/is_this_workload_sustainable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqpa3y/is_this_workload_sustainable/", "subreddit_subscribers": 160711, "created_utc": 1707923845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody.  \n\n\nI have the same repo, same rights as my colleagues. in my case dataform compiles then runs and create the tables.  \n\n\nIn my colleagues case it compiles then run but doesnt do anything.  \n\n\nAnyone had the same issue?", "author_fullname": "t2_m0fkuha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataform works in Mac but not Windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqmlce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707916426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody.  &lt;/p&gt;\n\n&lt;p&gt;I have the same repo, same rights as my colleagues. in my case dataform compiles then runs and create the tables.  &lt;/p&gt;\n\n&lt;p&gt;In my colleagues case it compiles then run but doesnt do anything.  &lt;/p&gt;\n\n&lt;p&gt;Anyone had the same issue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqmlce", "is_robot_indexable": true, "report_reasons": null, "author": "anfawave", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqmlce/dataform_works_in_mac_but_not_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqmlce/dataform_works_in_mac_but_not_windows/", "subreddit_subscribers": 160711, "created_utc": 1707916426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Challenges of Multiple Data Products, Duplication Management, and Governance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqm2qq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/LtpHDxjmtOdI8XbYcY0qUTgoIF9EGel20EUkA0-tWl8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707914812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/managing-the-evolving-landscape-of-data-products", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?auto=webp&amp;s=74a60904fc4082970c40c8c774cfa316349eca28", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3eb4d1dc891690ba394f22db8d3e6276d223027", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=96121439278beb996df236f74ee4fb4c919d34c4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c2ac79c7aaded2d10c94d2772df2fc9e79a1804", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0fdc085e2beb54b853374f6005a840eb3f296212", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=741eaf0f4569f1dbcf6e0257fe209c2093fbb946", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f2130d60ab93455414b1ec6b56fa4565c51bb0cf", "width": 1080, "height": 540}], "variants": {}, "id": "hTL2mgKSCo7xESDA1qHg-RhdxO_thI7hRM7L_VGYCaY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqm2qq", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqm2qq/challenges_of_multiple_data_products_duplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/managing-the-evolving-landscape-of-data-products", "subreddit_subscribers": 160711, "created_utc": 1707914812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any idea why GA4, Firebase and every other BigQuery export creates a single event table for all events instead of creating an individual table for each event? What workload is intended to run optimised/faster with this schema?", "author_fullname": "t2_h4q7gewg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why BigQuery exports are to a single table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqlxsa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707914373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any idea why GA4, Firebase and every other BigQuery export creates a single event table for all events instead of creating an individual table for each event? What workload is intended to run optimised/faster with this schema?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqlxsa", "is_robot_indexable": true, "report_reasons": null, "author": "aruntdharan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqlxsa/why_bigquery_exports_are_to_a_single_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqlxsa/why_bigquery_exports_are_to_a_single_table/", "subreddit_subscribers": 160711, "created_utc": 1707914373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So basically we want to show the client the data profile for each column, then give them the option to accept / discard the rules for each column. Accepted rules are actually applied on the data.\n\nI am clueless as to how to implement this flow, any ideas please?! thanks", "author_fullname": "t2_4wgaqe7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement results from Spark profiling to actual data quality checks (on Sodacore preferably)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqi1f4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707898880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically we want to show the client the data profile for each column, then give them the option to accept / discard the rules for each column. Accepted rules are actually applied on the data.&lt;/p&gt;\n\n&lt;p&gt;I am clueless as to how to implement this flow, any ideas please?! thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqi1f4", "is_robot_indexable": true, "report_reasons": null, "author": "Islamic_justice", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqi1f4/how_to_implement_results_from_spark_profiling_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqi1f4/how_to_implement_results_from_spark_profiling_to/", "subreddit_subscribers": 160711, "created_utc": 1707898880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHey everyone,\n\nI'm embarking on a data project centered around patent analysis, and I could really use some guidance on how to structure the architecture, especially when it comes to sourcing data. \n\nHere's a bit of background: I'm a data engineer student aiming to delve into patent data to analyze trends, identify patterns, extract valuable insights and visual the data. However, I'm facing a bit of a roadblock when it comes to sourcing the right data. There are various sources out there, each with its own pros and cons, and I'm struggling to determine the most suitable approach. \n\nSo, I'm turning to the experienced minds here for advice. How have you tackled data sourcing for similar projects in the past? Are there specific platforms, APIs, or databases that you've found particularly useful for patent analysis? Any tips or best practices for ensuring data quality and relevance? What did you use to analyse the data? \nAnd what the best tool to visualise it?\n\nAdditionally, I'd love to hear about any insights you've gained from working on patent analysis projects or any architectural considerations that proved crucial in your experience.\n\nYour input would be immensely valuable in helping.\nThanks in advance for your help and insights!", "author_fullname": "t2_7eqe0vfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Architecting a Data Project for Patent Analysis for an academic project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqbjlu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707876674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m embarking on a data project centered around patent analysis, and I could really use some guidance on how to structure the architecture, especially when it comes to sourcing data. &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a bit of background: I&amp;#39;m a data engineer student aiming to delve into patent data to analyze trends, identify patterns, extract valuable insights and visual the data. However, I&amp;#39;m facing a bit of a roadblock when it comes to sourcing the right data. There are various sources out there, each with its own pros and cons, and I&amp;#39;m struggling to determine the most suitable approach. &lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m turning to the experienced minds here for advice. How have you tackled data sourcing for similar projects in the past? Are there specific platforms, APIs, or databases that you&amp;#39;ve found particularly useful for patent analysis? Any tips or best practices for ensuring data quality and relevance? What did you use to analyse the data? \nAnd what the best tool to visualise it?&lt;/p&gt;\n\n&lt;p&gt;Additionally, I&amp;#39;d love to hear about any insights you&amp;#39;ve gained from working on patent analysis projects or any architectural considerations that proved crucial in your experience.&lt;/p&gt;\n\n&lt;p&gt;Your input would be immensely valuable in helping.\nThanks in advance for your help and insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqbjlu", "is_robot_indexable": true, "report_reasons": null, "author": "Positive_Temporary77", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqbjlu/seeking_advice_on_architecting_a_data_project_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqbjlu/seeking_advice_on_architecting_a_data_project_for/", "subreddit_subscribers": 160711, "created_utc": 1707876674.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}