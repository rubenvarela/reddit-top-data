{"kind": "Listing", "data": {"after": "t3_1aqhrti", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got message, from credly, that my badge is available!\n\nA bit surprised, exam was heavy &amp; messy. Lots of questions from adjacent specializations like DevOps, Data Analysts, Solution Architect, and actually not much about Data Engineering in general.\n\nNow I feel like true Data Engineer @ AWS ;)\n\nCheck your emails!\n\n&amp;#x200B;\n\nPS. Took exam 1/12, in last day where beta was available, no preparations, just wanted to see what is the true \"assessment\" of my skill, to challenge myself. Hopefully, it worked out.", "author_fullname": "t2_f3zvxf9b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Passed AWS Data Engineer - Associate !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apz616", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707847512.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707845473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got message, from credly, that my badge is available!&lt;/p&gt;\n\n&lt;p&gt;A bit surprised, exam was heavy &amp;amp; messy. Lots of questions from adjacent specializations like DevOps, Data Analysts, Solution Architect, and actually not much about Data Engineering in general.&lt;/p&gt;\n\n&lt;p&gt;Now I feel like true Data Engineer @ AWS ;)&lt;/p&gt;\n\n&lt;p&gt;Check your emails!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;PS. Took exam 1/12, in last day where beta was available, no preparations, just wanted to see what is the true &amp;quot;assessment&amp;quot; of my skill, to challenge myself. Hopefully, it worked out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1apz616", "is_robot_indexable": true, "report_reasons": null, "author": "dev_lvl80", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/", "subreddit_subscribers": 160644, "created_utc": 1707845473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DBT announced a preview of a much requested feature - Column Level Lineage. \n\nThe only catch is you have to be a Cloud customer. \nDoes anyone know anymore about this and if it is coming to core?", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Column Level Lineage only for DBT Cloud customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqcvov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/z0lsxARMTCcEEhwTC0HsMFN-HuXPgaFLzzHTjhKPrd4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707880629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DBT announced a preview of a much requested feature - Column Level Lineage. &lt;/p&gt;\n\n&lt;p&gt;The only catch is you have to be a Cloud customer. \nDoes anyone know anymore about this and if it is coming to core?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?auto=webp&amp;s=cafd219029f0a3fbdad0ea8a2bcb66b3d78fde14", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b5c9815894c457c0876c8aa0738f085af8f7af8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1dd3758c396fe36d709ad00886acb150a1d9067d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94fcab0f230d58e3de92c5d7c2a2785144251838", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5a80590e63ba05ee3f1af94bd9e60ae2df5308a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=815507f574255f6785c16ea52b6bab5afc4d00bc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de48a264c01939fe48a8bdfeb28423431ccc3644", "width": 1080, "height": 567}], "variants": {}, "id": "DrZJUagpOb_HgXmGsRTaz04SkfN1EZhQLY4JvbX2Wb0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqcvov", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqcvov/dbt_column_level_lineage_only_for_dbt_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/", "subreddit_subscribers": 160644, "created_utc": 1707880629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Context:**\n\nI work at a rather large company that itself houses smaller \"businesses\" within it. My small team is in charge of managing this small business and its business needs. Because the org as a whole is so large and there are so many of these smaller businesses that operate independently, there's no centralized data warehouse and retrieving data is manual, meaning report automation is next to impossible.\n\n&amp;#x200B;\n\n**The Goal:**\n\nIt's not pretty, but I've found a way to automate the retrieval of data from Workday, Oracle Business Intelligence, along with some other in-house apps/tools. My ultimate goal is to bring in data from all of these different sources and create a a stupid-simple relational database. Because this is just for the business needs of our small business, I'm not too worried about the volume of data becoming overwhelming (certainly not in the near future).\n\nI've worked with SQL in prior roles, but not from the perspective of a data/warehouse architect. That being said, I have time... lots and lots of time, so I don't mind learning on the side to get this done. This would be somewhat of a fun side project for me.\n\nAt the moment, I've identified PostgreSQL as a good candidate for both production and data warehousing. It might be that I'm hallucinating and this not remotely the best approach for what I'm trying to do, and I'm totally open to hearing that. I'm honestly just looking for where to go next, how to get started, and hopefully learn some tips from other who were on a similar boat.\n\n&amp;#x200B;\n\n**Notes and Constraints:**\n\n* I'll likely be able to secure a separate machine from my own to act as a server, but for now I'll be doing this on my own machine as a proof of concept.\n* I won't be able to pay for any of the usual services, it just doesn't make sense at this scale. This needs to be free aside from overhead.\n* There won't be a centralized solution coming - it's just not happening. If I don't do it, it just won't get done.\n* This will never leave the hands of our small business team, so I'm not worried about security.", "author_fullname": "t2_u4i3bpjyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I go about creating a small-scale data warehouse for a small business team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apzymj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707847774.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I work at a rather large company that itself houses smaller &amp;quot;businesses&amp;quot; within it. My small team is in charge of managing this small business and its business needs. Because the org as a whole is so large and there are so many of these smaller businesses that operate independently, there&amp;#39;s no centralized data warehouse and retrieving data is manual, meaning report automation is next to impossible.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Goal:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not pretty, but I&amp;#39;ve found a way to automate the retrieval of data from Workday, Oracle Business Intelligence, along with some other in-house apps/tools. My ultimate goal is to bring in data from all of these different sources and create a a stupid-simple relational database. Because this is just for the business needs of our small business, I&amp;#39;m not too worried about the volume of data becoming overwhelming (certainly not in the near future).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve worked with SQL in prior roles, but not from the perspective of a data/warehouse architect. That being said, I have time... lots and lots of time, so I don&amp;#39;t mind learning on the side to get this done. This would be somewhat of a fun side project for me.&lt;/p&gt;\n\n&lt;p&gt;At the moment, I&amp;#39;ve identified PostgreSQL as a good candidate for both production and data warehousing. It might be that I&amp;#39;m hallucinating and this not remotely the best approach for what I&amp;#39;m trying to do, and I&amp;#39;m totally open to hearing that. I&amp;#39;m honestly just looking for where to go next, how to get started, and hopefully learn some tips from other who were on a similar boat.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes and Constraints:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I&amp;#39;ll likely be able to secure a separate machine from my own to act as a server, but for now I&amp;#39;ll be doing this on my own machine as a proof of concept.&lt;/li&gt;\n&lt;li&gt;I won&amp;#39;t be able to pay for any of the usual services, it just doesn&amp;#39;t make sense at this scale. This needs to be free aside from overhead.&lt;/li&gt;\n&lt;li&gt;There won&amp;#39;t be a centralized solution coming - it&amp;#39;s just not happening. If I don&amp;#39;t do it, it just won&amp;#39;t get done.&lt;/li&gt;\n&lt;li&gt;This will never leave the hands of our small business team, so I&amp;#39;m not worried about security.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apzymj", "is_robot_indexable": true, "report_reasons": null, "author": "AstralSerenity", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/", "subreddit_subscribers": 160644, "created_utc": 1707847340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you tried the following\n\nDremio\nTrino\nPresto\n\nIf you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? \n\nReally interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you tried these tools? If not, why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6dbj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707862868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried the following&lt;/p&gt;\n\n&lt;p&gt;Dremio\nTrino\nPresto&lt;/p&gt;\n\n&lt;p&gt;If you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? &lt;/p&gt;\n\n&lt;p&gt;Really interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq6dbj", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "subreddit_subscribers": 160644, "created_utc": 1707862868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**I am checking into multiple catalogs and I am  curious.**   \n*Have any of you set one up? Which one did you choose and why?* \n\n*What was the actual need for the data catalog in the first place?*   \n\n\n**For those who are working with catalogs:**  \n*How is it going? Was there any big change in how you work with your data or with your team?*  \n*Did anyone had any big wins by implementing a catalog?*  \n\n\n  \nSorry for asking too much questions. Any insights on the topic is appreciated !  \n\n\nThanks. ", "author_fullname": "t2_o78u2p44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who's Using Data Catalogs? Need your insights !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq7xh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707866755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;I am checking into multiple catalogs and I am  curious.&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;Have any of you set one up? Which one did you choose and why?&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;What was the actual need for the data catalog in the first place?&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;For those who are working with catalogs:&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;How is it going? Was there any big change in how you work with your data or with your team?&lt;/em&gt;&lt;br/&gt;\n&lt;em&gt;Did anyone had any big wins by implementing a catalog?&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;Sorry for asking too much questions. Any insights on the topic is appreciated !  &lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq7xh9", "is_robot_indexable": true, "report_reasons": null, "author": "SignificanceNo136", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "subreddit_subscribers": 160644, "created_utc": 1707866755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was working with Kestra but really struggling with their documentation. Have heard good things about Kestra but was hoping for some general feedback.\n\nOne thing I noticed is the python based approach. We use a lot of docker containers so I was curious what others approach was. Do you interweave your existing code base with dagster by adding it directly within the code. Or do you make python workflows calling these docker containers?", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Feedback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apwl21", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707839274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was working with Kestra but really struggling with their documentation. Have heard good things about Kestra but was hoping for some general feedback.&lt;/p&gt;\n\n&lt;p&gt;One thing I noticed is the python based approach. We use a lot of docker containers so I was curious what others approach was. Do you interweave your existing code base with dagster by adding it directly within the code. Or do you make python workflows calling these docker containers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apwl21", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apwl21/dagster_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apwl21/dagster_feedback/", "subreddit_subscribers": 160644, "created_utc": 1707839274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " To process the 100 Gb of a file what is the bare minimum resources requirement for the spark job?\nHow many partitions will it create?\nWhat will be number of executors, cores, executor size?", "author_fullname": "t2_ojn8xr0i2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqhsg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707897837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To process the 100 Gb of a file what is the bare minimum resources requirement for the spark job?\nHow many partitions will it create?\nWhat will be number of executors, cores, executor size?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1aqhsg8", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic-Bell5386", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqhsg8/interview_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqhsg8/interview_question/", "subreddit_subscribers": 160644, "created_utc": 1707897837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Our research group at Princeton University recently produced Codex, an online data explorer for the first synapse-resolution brain map, known as a connectome. This connectome was mapped over the past 5 years with hundreds of researchers from around the world. \n\nNow that the brain is mapped, we're looking to improve automated cell labeling. Today the Visual Column Mapping Challenge launches on Codex. This open data analysis challenge will improve the assignment of neurons to optic units known as columns. \n\nAnyone is invited to participate: [https://codex.flywire.ai/app/visual\\_columns\\_challenge](https://codex.flywire.ai/app/visual_columns_challenge) The winner will be invited to give a talk at Princeton University, if interested. We're also hiring developers! \n\nPlease ask questions in the comments.\n\nMore information about the project: [flywire.ai](http://flywire.ai/)  \nExample neuron assignments: [https://youtu.be/wSP0st3ypA8](https://youtu.be/wSP0st3ypA8)", "author_fullname": "t2_4gw96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connectomics Data Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apv4t0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707835553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our research group at Princeton University recently produced Codex, an online data explorer for the first synapse-resolution brain map, known as a connectome. This connectome was mapped over the past 5 years with hundreds of researchers from around the world. &lt;/p&gt;\n\n&lt;p&gt;Now that the brain is mapped, we&amp;#39;re looking to improve automated cell labeling. Today the Visual Column Mapping Challenge launches on Codex. This open data analysis challenge will improve the assignment of neurons to optic units known as columns. &lt;/p&gt;\n\n&lt;p&gt;Anyone is invited to participate: &lt;a href=\"https://codex.flywire.ai/app/visual_columns_challenge\"&gt;https://codex.flywire.ai/app/visual_columns_challenge&lt;/a&gt; The winner will be invited to give a talk at Princeton University, if interested. We&amp;#39;re also hiring developers! &lt;/p&gt;\n\n&lt;p&gt;Please ask questions in the comments.&lt;/p&gt;\n\n&lt;p&gt;More information about the project: &lt;a href=\"http://flywire.ai/\"&gt;flywire.ai&lt;/a&gt;&lt;br/&gt;\nExample neuron assignments: &lt;a href=\"https://youtu.be/wSP0st3ypA8\"&gt;https://youtu.be/wSP0st3ypA8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1apv4t0", "is_robot_indexable": true, "report_reasons": null, "author": "amyleerobinson", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apv4t0/connectomics_data_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apv4t0/connectomics_data_challenge/", "subreddit_subscribers": 160644, "created_utc": 1707835553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI'm a data scientist transitioning into data engineering. I was wondering how is the job market in 2024 for foreigners in your country.\n\nAre there jobs that I can work home office from my country? Would I need to realocate? I'm wondering about this mostly for the US, Canada or Europe. How hard would that be? \n\nI'm brazilian, if that helps.", "author_fullname": "t2_5f8z1ygw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Market for Foreigners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq0u4f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707849432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data scientist transitioning into data engineering. I was wondering how is the job market in 2024 for foreigners in your country.&lt;/p&gt;\n\n&lt;p&gt;Are there jobs that I can work home office from my country? Would I need to realocate? I&amp;#39;m wondering about this mostly for the US, Canada or Europe. How hard would that be? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m brazilian, if that helps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aq0u4f", "is_robot_indexable": true, "report_reasons": null, "author": "luishacm", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/", "subreddit_subscribers": 160644, "created_utc": 1707849432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6smf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My company just let me open source our orchestration tool 'Houston', an API based alternative to Airflow/Google Cloud Composer that we've been using internally for the last 4 years! It's great for low-cost, high-speed data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_1aqmnx0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TvbgM6XU5pRyFVegumxyMoPZh1883NVwept3GPI1g3k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707916658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/datasparq-ai/houston", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?auto=webp&amp;s=17c406bb32ad5a30266b69dcafb176b148c7fceb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7cc92a3c283476dfb4ca5ec88b8c435c585f714", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7dbbe0719b6f282a0b4461814d45feece159c29", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=17d6dba66cf3894f446dbc9a27436cce9044e537", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5dbd07c99f928596baeb8c555a795120709030c9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7bcef0cc1f4098d67802083b47f3c830ae462678", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d61dfa599bfd7d04c0ca769ffa605657ad949911", "width": 1080, "height": 540}], "variants": {}, "id": "P67HJGdlWqP7-f47wdx-g-YFOqw7poBol8WKVocacEQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1aqmnx0", "is_robot_indexable": true, "report_reasons": null, "author": "flo0d", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqmnx0/my_company_just_let_me_open_source_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/datasparq-ai/houston", "subreddit_subscribers": 160644, "created_utc": 1707916658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cb1if", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New DuckDB Array Type used for Vector databasing on top of Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 95, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqk7rs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/42h9thB8-GeclxIVqfxJQDkNwDSikQGRInIKhEWrsK0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707908193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luukvandervelden.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luukvandervelden.medium.com/vector-databasing-with-duckdb-on-top-of-pgvector-ec182f815a16?source=friends_link&amp;sk=041d8e614e2b4ada23af79205661e0d3", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?auto=webp&amp;s=878da16648a19e0a41a91ea1d43a9d22588c9b6e", "width": 1200, "height": 818}, "resolutions": [{"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25a16cb9c2b3fb03fa149eae5c0633f7ca0f4438", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=03c3c9a18844192231c7415e5c28ffc94cee8add", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14c7010de6e028feb9e101ed3321807ca7d15804", "width": 320, "height": 218}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02164756c7fb2a3f15838d538f406601d4582b71", "width": 640, "height": 436}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6227708b6bf2c031d7ea9342304b02984aa59a35", "width": 960, "height": 654}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=393ef36f0a2613fff4c04d265e20df598d53768b", "width": 1080, "height": 736}], "variants": {}, "id": "GafSvdTOfJuSt6EJ5qOfvDVJZbZAQVpDEk6MBKtOShk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqk7rs", "is_robot_indexable": true, "report_reasons": null, "author": "squareape", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqk7rs/new_duckdb_array_type_used_for_vector_databasing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luukvandervelden.medium.com/vector-databasing-with-duckdb-on-top-of-pgvector-ec182f815a16?source=friends_link&amp;sk=041d8e614e2b4ada23af79205661e0d3", "subreddit_subscribers": 160644, "created_utc": 1707908193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in an organization that has built custom tooling, but there are many issues, and I'm looking into alternatives. I'm particularly concerned with orchestration, ELT tooling, and schema management. I've got my eyes on dagster + dbt right now, but I'm not sure they'll work for my purposes just yet.\n\nSome architecture that cannot change:\n\n* There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same\n* Due to the above, there must be a DAG instance per customer, for each DAG specification\n* Something is needed to manage schema updates and create new databases with up-to-date schemas\n\nI imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven't been able to easily discern this from documentation.\n\nI don't fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I'd only work with abstractions, or if I'd be working with underlying tables. I'm not really looking for an ORM. I'm looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.\n\nAny recommendations are appreciated! I'm just looking very high level right now.", "author_fullname": "t2_89dmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking recommendation for tools that will work for a specific architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq8qdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707868806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in an organization that has built custom tooling, but there are many issues, and I&amp;#39;m looking into alternatives. I&amp;#39;m particularly concerned with orchestration, ELT tooling, and schema management. I&amp;#39;ve got my eyes on dagster + dbt right now, but I&amp;#39;m not sure they&amp;#39;ll work for my purposes just yet.&lt;/p&gt;\n\n&lt;p&gt;Some architecture that cannot change:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same&lt;/li&gt;\n&lt;li&gt;Due to the above, there must be a DAG instance per customer, for each DAG specification&lt;/li&gt;\n&lt;li&gt;Something is needed to manage schema updates and create new databases with up-to-date schemas&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven&amp;#39;t been able to easily discern this from documentation.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I&amp;#39;d only work with abstractions, or if I&amp;#39;d be working with underlying tables. I&amp;#39;m not really looking for an ORM. I&amp;#39;m looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations are appreciated! I&amp;#39;m just looking very high level right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq8qdc", "is_robot_indexable": true, "report_reasons": null, "author": "endotronic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "subreddit_subscribers": 160644, "created_utc": 1707868806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In deciding whether I want to use a star schema for a portfolio project- I see that one of my dim tables will have a one-to-one relationship with the fact table.\n\nAm I right in thinking there isn't any point to this? and it would be better as OBT?\n\nfor context, this is NLP data extracted from YouTube video comment sections. The \"entity\\_id\" PK in topic\\_entities would have a 1:1 with video\\_topic\\_facts. However, video\\_id PK would have a regular many-to-one relationship to video\\_entities. \n\nFacts:\n\n* video\\_topic\\_facts\n   *   entity\\_count\n   *   entity\\_id\n   *   video\\_id\n\nDimensions:\n\n* topic\\_entities\n   * entity\\_text\n   * entity\\_type\n   * entity\\_id\n* video\\_entities\n   * video\\_title\n   * video\\_id\n\n&amp;#x200B;\n\n ", "author_fullname": "t2_8chdw7c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "one-to-one relationships in star schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq01f4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In deciding whether I want to use a star schema for a portfolio project- I see that one of my dim tables will have a one-to-one relationship with the fact table.&lt;/p&gt;\n\n&lt;p&gt;Am I right in thinking there isn&amp;#39;t any point to this? and it would be better as OBT?&lt;/p&gt;\n\n&lt;p&gt;for context, this is NLP data extracted from YouTube video comment sections. The &amp;quot;entity_id&amp;quot; PK in topic_entities would have a 1:1 with video_topic_facts. However, video_id PK would have a regular many-to-one relationship to video_entities. &lt;/p&gt;\n\n&lt;p&gt;Facts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;video_topic_facts\n\n&lt;ul&gt;\n&lt;li&gt;  entity_count&lt;/li&gt;\n&lt;li&gt;  entity_id&lt;/li&gt;\n&lt;li&gt;  video_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Dimensions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;topic_entities\n\n&lt;ul&gt;\n&lt;li&gt;entity_text&lt;/li&gt;\n&lt;li&gt;entity_type&lt;/li&gt;\n&lt;li&gt;entity_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;video_entities\n\n&lt;ul&gt;\n&lt;li&gt;video_title&lt;/li&gt;\n&lt;li&gt;video_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq01f4", "is_robot_indexable": true, "report_reasons": null, "author": "pdxtechnologist", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/", "subreddit_subscribers": 160644, "created_utc": 1707847529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nSo I have been working with tools like SSAS to create tabular models destined for analytics. But never got the chance to use datamarts and looking it up on the internet I still do not understand the difference between the two.\n\nAre datamarts an aggregated view/table that contains all necessary data for a specific requirement like Business Unit?", "author_fullname": "t2_c5ezp8a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the difference between a data mart and a regular data model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq00v5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;So I have been working with tools like SSAS to create tabular models destined for analytics. But never got the chance to use datamarts and looking it up on the internet I still do not understand the difference between the two.&lt;/p&gt;\n\n&lt;p&gt;Are datamarts an aggregated view/table that contains all necessary data for a specific requirement like Business Unit?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq00v5", "is_robot_indexable": true, "report_reasons": null, "author": "TaleLegal9085", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/", "subreddit_subscribers": 160644, "created_utc": 1707847492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nDo you know other teams building in public like the Gitlab team [https://gitlab.com/gitlab-data](https://gitlab.com/gitlab-data) ?\n\nI would like to get inspiration from their setup , I believe you can learn alot like that.\n\nThanks!", "author_fullname": "t2_ce0xxymx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data teams building in public repositories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apxt0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707842230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Do you know other teams building in public like the Gitlab team &lt;a href=\"https://gitlab.com/gitlab-data\"&gt;https://gitlab.com/gitlab-data&lt;/a&gt; ?&lt;/p&gt;\n\n&lt;p&gt;I would like to get inspiration from their setup , I believe you can learn alot like that.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?auto=webp&amp;s=2e94811ad974ef30758f1bfa1f573d0b8650b047", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38575afd6c6a3e5a0dcad7df2a63932f81adef3e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d40ddb743ced8470d911c7619186583ebb7cdc9a", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ed80f7c027a149b59802da37fcb5c5d42fc12bb", "width": 320, "height": 320}], "variants": {}, "id": "Vk4X7KEHj7HIY3r031F0NmctkfFvGIw2zTvw0AtlGsg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apxt0o", "is_robot_indexable": true, "report_reasons": null, "author": "Wingsofpeace7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/", "subreddit_subscribers": 160644, "created_utc": 1707842230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are seeing very weird issue with our environment \n\nSo we run multiple notebooks in parallel on same compute\n\nLets say there are 2 notebooks running\nDimCustomer &amp; DimOrder\n\nBoth have variable names var_x and in first notebook we assign value DimCustomer to var_x and in second notebook we assign DimOrder to var_x\n\nBoth has data stored in dataframe variable called df\n\nWe are writing this df as table in databricks catalogue\n\nIntermittently we see that DimCustomer has data of DimOrder\n\nRe-running process alone will fix the issue, but should this even happen in first place?", "author_fullname": "t2_50u0h0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataframe overwritten using data from another notebook - Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqee7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707885360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are seeing very weird issue with our environment &lt;/p&gt;\n\n&lt;p&gt;So we run multiple notebooks in parallel on same compute&lt;/p&gt;\n\n&lt;p&gt;Lets say there are 2 notebooks running\nDimCustomer &amp;amp; DimOrder&lt;/p&gt;\n\n&lt;p&gt;Both have variable names var_x and in first notebook we assign value DimCustomer to var_x and in second notebook we assign DimOrder to var_x&lt;/p&gt;\n\n&lt;p&gt;Both has data stored in dataframe variable called df&lt;/p&gt;\n\n&lt;p&gt;We are writing this df as table in databricks catalogue&lt;/p&gt;\n\n&lt;p&gt;Intermittently we see that DimCustomer has data of DimOrder&lt;/p&gt;\n\n&lt;p&gt;Re-running process alone will fix the issue, but should this even happen in first place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqee7l", "is_robot_indexable": true, "report_reasons": null, "author": "dilkushpatel", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/", "subreddit_subscribers": 160644, "created_utc": 1707885360.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all.  Question about DBT testing.  \n\n1. is there a DBT sub that I cant find?\n\nWe have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR's proposed changes to that model.\n\n    SELECT \n        CASE \n            WHEN (SELECT COUNT(*) AS ROW_CNT\n                    FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n                = (SELECT COUNT(*) AS ROW_CNT\n                    FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            THEN 'Success!'\n            ELSE 'PR changed row count'\n        END AS STATUS\n\nI was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn't want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:\n\n    MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n    DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n\nSure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn't have a row count change.  \n\nIt also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR's are supposed to change the model's row count, so we wouldn't run this test on every model, and we would just skip it for those.\n\nBut also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_b12wxz418", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT generic schema tests questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6kpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707863377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.  Question about DBT testing.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;is there a DBT sub that I cant find?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR&amp;#39;s proposed changes to that model.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT \n    CASE \n        WHEN (SELECT COUNT(*) AS ROW_CNT\n                FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            = (SELECT COUNT(*) AS ROW_CNT\n                FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n        THEN &amp;#39;Success!&amp;#39;\n        ELSE &amp;#39;PR changed row count&amp;#39;\n    END AS STATUS\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn&amp;#39;t want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\nDBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Sure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn&amp;#39;t have a row count change.  &lt;/p&gt;\n\n&lt;p&gt;It also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR&amp;#39;s are supposed to change the model&amp;#39;s row count, so we wouldn&amp;#39;t run this test on every model, and we would just skip it for those.&lt;/p&gt;\n\n&lt;p&gt;But also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq6kpm", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Goose82", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "subreddit_subscribers": 160644, "created_utc": 1707863377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have not come across any resources which describe how to integrate Soda core with Delta lake. Does anyone have experience with this implementation? thanks!", "author_fullname": "t2_4wgaqe7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soda core for Delta lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqfd8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707888601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have not come across any resources which describe how to integrate Soda core with Delta lake. Does anyone have experience with this implementation? thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqfd8q", "is_robot_indexable": true, "report_reasons": null, "author": "Islamic_justice", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/", "subreddit_subscribers": 160644, "created_utc": 1707888601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI'm exploring options for extracting data from GA4 and Google Ads efficiently for our data engineering projects. I'm particularly interested in tools or services that are reliable, scalable, and offer smooth integration with BigQuery. So far I've used Google Data Transfer (GAds) and Big Query Extract (GA4), but I'm not enough satisfied. \n\n* **What tools or methods are you currently using for this purpose?**\n* **Have you faced any challenges with your current approach?**\n* **Are there any specific features or capabilities you find essential in these tools?**\n* **Is there someone managing these pipeline with Airflow?**\n\nWould love to hear about your experiences, recommendations, and any insights you've gained from working with GA4 and Google Ads data extraction.\n\nThanks in advance for sharing your thoughts!", "author_fullname": "t2_s2zvff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are you using to extract Google Analytics (GA4) and Google Ads data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apywog", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707844850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m exploring options for extracting data from GA4 and Google Ads efficiently for our data engineering projects. I&amp;#39;m particularly interested in tools or services that are reliable, scalable, and offer smooth integration with BigQuery. So far I&amp;#39;ve used Google Data Transfer (GAds) and Big Query Extract (GA4), but I&amp;#39;m not enough satisfied. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;What tools or methods are you currently using for this purpose?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Have you faced any challenges with your current approach?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Are there any specific features or capabilities you find essential in these tools?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Is there someone managing these pipeline with Airflow?&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would love to hear about your experiences, recommendations, and any insights you&amp;#39;ve gained from working with GA4 and Google Ads data extraction.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for sharing your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apywog", "is_robot_indexable": true, "report_reasons": null, "author": "giuliosmall", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apywog/what_are_you_using_to_extract_google_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apywog/what_are_you_using_to_extract_google_analytics/", "subreddit_subscribers": 160644, "created_utc": 1707844850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, to preface, dbt is somewhat of a new tool for me and I'm still learning the ins and outs of how it works. We have a client who has two different snowflake environments/accounts. One for DEV and the other for PROD. Is it possible to have dbt run the development pipelines in the DEV account and then when we go to deploy we deploy the pipelines to the PRD account? Essentially all dev activities and builds would happen in the DEV Snowflake account but then deployment would occur in the PROD Snowflake account?", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using dbt with two different snowflake accounts? Looking for input.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apv42h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707835500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, to preface, dbt is somewhat of a new tool for me and I&amp;#39;m still learning the ins and outs of how it works. We have a client who has two different snowflake environments/accounts. One for DEV and the other for PROD. Is it possible to have dbt run the development pipelines in the DEV account and then when we go to deploy we deploy the pipelines to the PRD account? Essentially all dev activities and builds would happen in the DEV Snowflake account but then deployment would occur in the PROD Snowflake account?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apv42h", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apv42h/using_dbt_with_two_different_snowflake_accounts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apv42h/using_dbt_with_two_different_snowflake_accounts/", "subreddit_subscribers": 160644, "created_utc": 1707835500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All,\n\nI am trying to make a data flow task in SSIS where I insert data from an OLE DB Source to an OLE DB Destination (i.e. two different SQL Server instances on different VMs). I was able to get the OLE DB Source connection to work. The OLE DB Source is a SQL Server instance on a personal VM that I use for staging and data conversion.\n\nHowever, when I try to establish the OLE DB Destination I keep getting an error because the destination SQL Server is on a different VM/data server. No matter which provider, server name, or credentials I use I cannot get it to work. \n\nCan anyone please point me the in the right direction?\n\n[here are the providers that I see available.](https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;format=pjpg&amp;auto=webp&amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5)\n\nI usually use \"Microsoft OLE DB Provider for SQL Server\" for the source so I thought I could do the same with the destination, but I'm not sure which authentication I should be using?\n\n&amp;#x200B;\n\n[I've tried every combination of options here and I still get an error.](https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;format=pjpg&amp;auto=webp&amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72)\n\n&amp;#x200B;\n\nHere is the error I get when I try, for example, the sa account:\n\nhttps://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;format=pjpg&amp;auto=webp&amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6", "author_fullname": "t2_pz85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to establish an OLE DB Destination in SSIS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jgxp480s6dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ea4845ec5a30e8e4260764982dba818b95f3c67"}, {"y": 187, "x": 216, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=14989d0ec79924357426b04d3f42ca2e011f86f5"}, {"y": 277, "x": 320, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c4f027cc52e6156b0ec4a61478f0ab5e893b20d"}, {"y": 555, "x": 640, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b0ef8ce4f5d3950f6bf820a4f36a7b45725f67"}], "s": {"y": 615, "x": 709, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;format=pjpg&amp;auto=webp&amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72"}, "id": "jgxp480s6dic1"}, "0kh68hhi6dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 94, "x": 108, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f931891bef72e68dc315f12ae871955ae79acfe"}, {"y": 188, "x": 216, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4ed82d0e98bbf6b44bfa03cfeb446d4e69bd12f"}, {"y": 278, "x": 320, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e965273c6cab16e03206ddaa015db652288e272"}, {"y": 557, "x": 640, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a6e79e60be8183e9e1077b1feb6cdaf6a69fd39a"}], "s": {"y": 617, "x": 708, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;format=pjpg&amp;auto=webp&amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5"}, "id": "0kh68hhi6dic1"}, "fvhn6k947dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=727ed637847b1b59ead0d259c73fe74fc06d8d84"}, {"y": 186, "x": 216, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=71eaa0a28177d5f3f46145f49f8c34cb8b642546"}, {"y": 275, "x": 320, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f093e3f9905a98f74c0784b0b7c4b78e058f8e4"}, {"y": 551, "x": 640, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a48e2f4f5c636d6a0416f35e43ba7049bd10a192"}], "s": {"y": 615, "x": 714, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;format=pjpg&amp;auto=webp&amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6"}, "id": "fvhn6k947dic1"}}, "name": "t3_1apv2d7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707835372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All,&lt;/p&gt;\n\n&lt;p&gt;I am trying to make a data flow task in SSIS where I insert data from an OLE DB Source to an OLE DB Destination (i.e. two different SQL Server instances on different VMs). I was able to get the OLE DB Source connection to work. The OLE DB Source is a SQL Server instance on a personal VM that I use for staging and data conversion.&lt;/p&gt;\n\n&lt;p&gt;However, when I try to establish the OLE DB Destination I keep getting an error because the destination SQL Server is on a different VM/data server. No matter which provider, server name, or credentials I use I cannot get it to work. &lt;/p&gt;\n\n&lt;p&gt;Can anyone please point me the in the right direction?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5\"&gt;here are the providers that I see available.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I usually use &amp;quot;Microsoft OLE DB Provider for SQL Server&amp;quot; for the source so I thought I could do the same with the destination, but I&amp;#39;m not sure which authentication I should be using?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72\"&gt;I&amp;#39;ve tried every combination of options here and I still get an error.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is the error I get when I try, for example, the sa account:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6\"&gt;https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apv2d7", "is_robot_indexable": true, "report_reasons": null, "author": "imperialka", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apv2d7/how_to_establish_an_ole_db_destination_in_ssis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apv2d7/how_to_establish_an_ole_db_destination_in_ssis/", "subreddit_subscribers": 160644, "created_utc": 1707835372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Challenges of Multiple Data Products, Duplication Management, and Governance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_1aqm2qq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/LtpHDxjmtOdI8XbYcY0qUTgoIF9EGel20EUkA0-tWl8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707914812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/managing-the-evolving-landscape-of-data-products", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?auto=webp&amp;s=74a60904fc4082970c40c8c774cfa316349eca28", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3eb4d1dc891690ba394f22db8d3e6276d223027", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=96121439278beb996df236f74ee4fb4c919d34c4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c2ac79c7aaded2d10c94d2772df2fc9e79a1804", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0fdc085e2beb54b853374f6005a840eb3f296212", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=741eaf0f4569f1dbcf6e0257fe209c2093fbb946", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f2130d60ab93455414b1ec6b56fa4565c51bb0cf", "width": 1080, "height": 540}], "variants": {}, "id": "hTL2mgKSCo7xESDA1qHg-RhdxO_thI7hRM7L_VGYCaY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqm2qq", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqm2qq/challenges_of_multiple_data_products_duplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/managing-the-evolving-landscape-of-data-products", "subreddit_subscribers": 160644, "created_utc": 1707914812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi all,\nhere's the scenario.  \n\nI've data in another company's MySQL DB. \nI don't have access to it, hence they've exported it into .SQL files.  These files have all the data as insert queries and create table statements.  \n\nNow the issue is, what I've is an SQL server  2016. Since these syntaxes won't support in SQL server. How can I load these data into SQL server tables? I don't have the option for an intermediate MySql db.\n\nOr in simple words, is there a way to convert this .SQL file data without access to a MySQL instance?", "author_fullname": "t2_5ks2jegk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting MySQL DB to SQL Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqkvme", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707918740.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707910686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi all,\nhere&amp;#39;s the scenario.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve data in another company&amp;#39;s MySQL DB. \nI don&amp;#39;t have access to it, hence they&amp;#39;ve exported it into .SQL files.  These files have all the data as insert queries and create table statements.  &lt;/p&gt;\n\n&lt;p&gt;Now the issue is, what I&amp;#39;ve is an SQL server  2016. Since these syntaxes won&amp;#39;t support in SQL server. How can I load these data into SQL server tables? I don&amp;#39;t have the option for an intermediate MySql db.&lt;/p&gt;\n\n&lt;p&gt;Or in simple words, is there a way to convert this .SQL file data without access to a MySQL instance?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqkvme", "is_robot_indexable": true, "report_reasons": null, "author": "das3012", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqkvme/converting_mysql_db_to_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqkvme/converting_mysql_db_to_sql_server/", "subreddit_subscribers": 160644, "created_utc": 1707910686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI'm currently an apprentice data engineer and in my second year of a master's program in data and AI.\n\nI've been asked to choose a certification to pursue, but I have little to no practical experience in data engineering. I'm familiar with SQL, Python, and have a basic understanding of MongoDB, as well as concepts like ETL and data warehousing. I've been advised to pursue Azure certifications since it's the most widely used cloud provider.\n\nWhich certification would you recommend for someone in my position to gain solid knowledge in data engineering?\n\nThanks again \ud83d\ude04", "author_fullname": "t2_8aldnk2t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which certification should I get ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqjqpf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707906287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently an apprentice data engineer and in my second year of a master&amp;#39;s program in data and AI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked to choose a certification to pursue, but I have little to no practical experience in data engineering. I&amp;#39;m familiar with SQL, Python, and have a basic understanding of MongoDB, as well as concepts like ETL and data warehousing. I&amp;#39;ve been advised to pursue Azure certifications since it&amp;#39;s the most widely used cloud provider.&lt;/p&gt;\n\n&lt;p&gt;Which certification would you recommend for someone in my position to gain solid knowledge in data engineering?&lt;/p&gt;\n\n&lt;p&gt;Thanks again \ud83d\ude04&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aqjqpf", "is_robot_indexable": true, "report_reasons": null, "author": "tn_receptionist_1520", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqjqpf/which_certification_should_i_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqjqpf/which_certification_should_i_get/", "subreddit_subscribers": 160644, "created_utc": 1707906287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The company I am working for looking to roll out dashboards for their app. The idea would be to embed the dashboard in an existing web app. \n\nAs a proof of concept, I created a quick prototype using Power BI, but never tried using Tableau. I was wondering if someone had experience with doing the same with Tableau.   \n\n\nDoes this work with Tableau? How was the experience? Any problems I should be aware? ", "author_fullname": "t2_h58nyr96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embedding Tableau dashboards in a web app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqhrti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707897765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The company I am working for looking to roll out dashboards for their app. The idea would be to embed the dashboard in an existing web app. &lt;/p&gt;\n\n&lt;p&gt;As a proof of concept, I created a quick prototype using Power BI, but never tried using Tableau. I was wondering if someone had experience with doing the same with Tableau.   &lt;/p&gt;\n\n&lt;p&gt;Does this work with Tableau? How was the experience? Any problems I should be aware? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqhrti", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyFish7104", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqhrti/embedding_tableau_dashboards_in_a_web_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqhrti/embedding_tableau_dashboards_in_a_web_app/", "subreddit_subscribers": 160644, "created_utc": 1707897765.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}