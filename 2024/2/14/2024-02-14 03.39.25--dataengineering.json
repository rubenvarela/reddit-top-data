{"kind": "Listing", "data": {"after": "t3_1aps4cd", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am not usually reading about my craft, but recently came across two books that captured my imagination in CI/CD and data.\n\nReading these two helped me to understand the different perspectives coming from the technology side and from the business side.\n\nAs a result, I can better understand how the business sees problems which is not always easy for me as a dev. I think I can also have better conversations with the business side as an engineer.\n\n* The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win\n* The Unicorn Project: A Novel about Developers, Digital Disruption, and Thriving in the Age of Data\n\nReading these two helped me to understand the different perspectives coming from the technology side and the business side. ave better conversations with the business side as an engineer. ineer.\n\nThe title is obviously a bit of an overstatement, I'd love to hear your recommendations for the books you think are best.", "author_fullname": "t2_h58nyr96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The only two books you need to read about CI/CD and Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apolbz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707812720.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707812439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not usually reading about my craft, but recently came across two books that captured my imagination in CI/CD and data.&lt;/p&gt;\n\n&lt;p&gt;Reading these two helped me to understand the different perspectives coming from the technology side and from the business side.&lt;/p&gt;\n\n&lt;p&gt;As a result, I can better understand how the business sees problems which is not always easy for me as a dev. I think I can also have better conversations with the business side as an engineer.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win&lt;/li&gt;\n&lt;li&gt;The Unicorn Project: A Novel about Developers, Digital Disruption, and Thriving in the Age of Data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Reading these two helped me to understand the different perspectives coming from the technology side and the business side. ave better conversations with the business side as an engineer. ineer.&lt;/p&gt;\n\n&lt;p&gt;The title is obviously a bit of an overstatement, I&amp;#39;d love to hear your recommendations for the books you think are best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apolbz", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyFish7104", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apolbz/the_only_two_books_you_need_to_read_about_cicd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apolbz/the_only_two_books_you_need_to_read_about_cicd/", "subreddit_subscribers": 160534, "created_utc": 1707812439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got message, from credly, that my badge is available!\n\nA bit surprised, exam was heavy &amp; messy. Lots of questions from adjacent specializations like DevOps, Data Analysts, Solution Architect, and actually not much about Data Engineering in general.\n\nNow I feel like true Data Engineer @ AWS ;)\n\nCheck your emails!\n\n&amp;#x200B;\n\nPS. Took exam 1/12, in last day where beta was available, no preparations, just wanted to see what is the true \"assessment\" of my skill, to challenge myself. Hopefully, it worked out.", "author_fullname": "t2_f3zvxf9b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Passed AWS Data Engineer - Associate !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apz616", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707847512.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707845473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got message, from credly, that my badge is available!&lt;/p&gt;\n\n&lt;p&gt;A bit surprised, exam was heavy &amp;amp; messy. Lots of questions from adjacent specializations like DevOps, Data Analysts, Solution Architect, and actually not much about Data Engineering in general.&lt;/p&gt;\n\n&lt;p&gt;Now I feel like true Data Engineer @ AWS ;)&lt;/p&gt;\n\n&lt;p&gt;Check your emails!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;PS. Took exam 1/12, in last day where beta was available, no preparations, just wanted to see what is the true &amp;quot;assessment&amp;quot; of my skill, to challenge myself. Hopefully, it worked out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1apz616", "is_robot_indexable": true, "report_reasons": null, "author": "dev_lvl80", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/", "subreddit_subscribers": 160534, "created_utc": 1707845473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My friend is struggling to make a choice - remote, but 30% less pay and for big corporation or working in small firm of about 200 employees as a solo data analyst\n\nBig corporation - 50k employees +/-, 13 data analysts on her team, most are experienced, not much room to grow or manoeuvre (big bank in Poland). Remote as well.\n\nSmall firm - 30% paybump compared to big corporation, solo data analyst, about 20mins travel (which is OK for Poland) works underneath firm's director as solo analyst. Last one left because they wanted to move abroad. Company tripled in revenue in the last 2 years. Not a startup, been on the market 15 years. \n\nSo obviously remote is big plus, but not much room for growth -  she's still young, only 25, and it'll be hard to gain promotions and grow given there's 13 people in her team, and the second youngest person is over 30 with lots of experience. \n\nOther company - room to grow and expand, possible manager within two-ish years. Works underneath the firm's director and CEO. Obviously if something goes wrong it's on her. And in office, no hybrid. \n\nWhat would you pick, I said I'll ask some people but we're all kinda like \"that's a tough one\".", "author_fullname": "t2_ki4xz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pick 30% paybump for a small company or work in a big bank?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apqjnd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707820828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend is struggling to make a choice - remote, but 30% less pay and for big corporation or working in small firm of about 200 employees as a solo data analyst&lt;/p&gt;\n\n&lt;p&gt;Big corporation - 50k employees +/-, 13 data analysts on her team, most are experienced, not much room to grow or manoeuvre (big bank in Poland). Remote as well.&lt;/p&gt;\n\n&lt;p&gt;Small firm - 30% paybump compared to big corporation, solo data analyst, about 20mins travel (which is OK for Poland) works underneath firm&amp;#39;s director as solo analyst. Last one left because they wanted to move abroad. Company tripled in revenue in the last 2 years. Not a startup, been on the market 15 years. &lt;/p&gt;\n\n&lt;p&gt;So obviously remote is big plus, but not much room for growth -  she&amp;#39;s still young, only 25, and it&amp;#39;ll be hard to gain promotions and grow given there&amp;#39;s 13 people in her team, and the second youngest person is over 30 with lots of experience. &lt;/p&gt;\n\n&lt;p&gt;Other company - room to grow and expand, possible manager within two-ish years. Works underneath the firm&amp;#39;s director and CEO. Obviously if something goes wrong it&amp;#39;s on her. And in office, no hybrid. &lt;/p&gt;\n\n&lt;p&gt;What would you pick, I said I&amp;#39;ll ask some people but we&amp;#39;re all kinda like &amp;quot;that&amp;#39;s a tough one&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1apqjnd", "is_robot_indexable": true, "report_reasons": null, "author": "Leopatto", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apqjnd/pick_30_paybump_for_a_small_company_or_work_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apqjnd/pick_30_paybump_for_a_small_company_or_work_in_a/", "subreddit_subscribers": 160534, "created_utc": 1707820828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "These days it seems like every solution is cloud-based for data engineering. What are some instances in which moving to the cloud does not make sense.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are instances where data storage, ETL, analytics, etc don't make sense on the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apkimj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707797667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;These days it seems like every solution is cloud-based for data engineering. What are some instances in which moving to the cloud does not make sense.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apkimj", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apkimj/what_are_instances_where_data_storage_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apkimj/what_are_instances_where_data_storage_etl/", "subreddit_subscribers": 160534, "created_utc": 1707797667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI work in the data team for a very large organization. Despite the size and influence of the organization, we are actually quite behind other companies in terms of data architecture, the tools we use and so on. I guess a typical issue for a large old organization.\n\nTo put it in context, I work for a team that does analytics for the website and mobile app. The website is split per \u201cscope\u201d and there are one or multiple analysts assigned to each \u201cscope\u201d and usually that is their sole focus and they are not really aware of what other analysts are doing, what queries they use, how exactly they measure their KPIs and so on. I think you get the idea. We work in a very decentralized way and would like to move to a more centralized setup with one \u201csource of truth\u201d.\n\nWe are already working on documenting KPIs and aligning how each team calculates them so we do it the same way across the department. Baby steps at the moment.\n\nBut that\u2019s not why I am here. I have been assigned to lead a team that owns the data and transforms it for final use by the analysts. Basically transforming all the raw data into final tables (some people call it the \u201cgold layer\u201d).\n\nCurrently, each analyst would basically dig into the raw data and find whatever they need and schedule a query that would feed new data everyday to a table and that table would be connected to their dashboard. \n\nNot only is it ridiculously expensive, but also very inefficient. We work with millions of sessions per day so you can imagine how much data we have.\n\nI have spent quite some time looking for resources online but there is so little focusing on modeling event data. I have very little data engineering/analytics engineering experience so any resources or tips would be highly appreciated. \n\nWe only use BigQuery and dbt at the moment.\nLooking into adding fivetran to the stack to simplify data streams from all the third party apps (currently we have many scripts for each 3rd party app and eqch script is owned by a different person so not centralized at all)\n\nThank you!", "author_fullname": "t2_59sa4mgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for data modeling and building a data architecture for event data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apkw7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707822875.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707798861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I work in the data team for a very large organization. Despite the size and influence of the organization, we are actually quite behind other companies in terms of data architecture, the tools we use and so on. I guess a typical issue for a large old organization.&lt;/p&gt;\n\n&lt;p&gt;To put it in context, I work for a team that does analytics for the website and mobile app. The website is split per \u201cscope\u201d and there are one or multiple analysts assigned to each \u201cscope\u201d and usually that is their sole focus and they are not really aware of what other analysts are doing, what queries they use, how exactly they measure their KPIs and so on. I think you get the idea. We work in a very decentralized way and would like to move to a more centralized setup with one \u201csource of truth\u201d.&lt;/p&gt;\n\n&lt;p&gt;We are already working on documenting KPIs and aligning how each team calculates them so we do it the same way across the department. Baby steps at the moment.&lt;/p&gt;\n\n&lt;p&gt;But that\u2019s not why I am here. I have been assigned to lead a team that owns the data and transforms it for final use by the analysts. Basically transforming all the raw data into final tables (some people call it the \u201cgold layer\u201d).&lt;/p&gt;\n\n&lt;p&gt;Currently, each analyst would basically dig into the raw data and find whatever they need and schedule a query that would feed new data everyday to a table and that table would be connected to their dashboard. &lt;/p&gt;\n\n&lt;p&gt;Not only is it ridiculously expensive, but also very inefficient. We work with millions of sessions per day so you can imagine how much data we have.&lt;/p&gt;\n\n&lt;p&gt;I have spent quite some time looking for resources online but there is so little focusing on modeling event data. I have very little data engineering/analytics engineering experience so any resources or tips would be highly appreciated. &lt;/p&gt;\n\n&lt;p&gt;We only use BigQuery and dbt at the moment.\nLooking into adding fivetran to the stack to simplify data streams from all the third party apps (currently we have many scripts for each 3rd party app and eqch script is owned by a different person so not centralized at all)&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apkw7y", "is_robot_indexable": true, "report_reasons": null, "author": "Several_Percentage_5", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apkw7y/resources_for_data_modeling_and_building_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apkw7y/resources_for_data_modeling_and_building_a_data/", "subreddit_subscribers": 160534, "created_utc": 1707798861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Context:**\n\nI work at a rather large company that itself houses smaller \"businesses\" within it. My small team is in charge of managing this small business and its business needs. Because the org as a whole is so large and there are so many of these smaller businesses that operate independently, there's no centralized data warehouse and retrieving data is manual, meaning report automation is next to impossible.\n\n&amp;#x200B;\n\n**The Goal:**\n\nIt's not pretty, but I've found a way to automate the retrieval of data from Workday, Oracle Business Intelligence, along with some other in-house apps/tools. My ultimate goal is to bring in data from all of these different sources and create a a stupid-simple relational database. Because this is just for the business needs of our small business, I'm not too worried about the volume of data becoming overwhelming (certainly not in the near future).\n\nI've worked with SQL in prior roles, but not from the perspective of a data/warehouse architect. That being said, I have time... lots and lots of time, so I don't mind learning on the side to get this done. This would be somewhat of a fun side project for me.\n\nAt the moment, I've identified PostgreSQL as a good candidate for both production and data warehousing. It might be that I'm hallucinating and this not remotely the best approach for what I'm trying to do, and I'm totally open to hearing that. I'm honestly just looking for where to go next, how to get started, and hopefully learn some tips from other who were on a similar boat.\n\n&amp;#x200B;\n\n**Notes and Constraints:**\n\n* I'll likely be able to secure a separate machine from my own to act as a server, but for now I'll be doing this on my own machine as a proof of concept.\n* I won't be able to pay for any of the usual services, it just doesn't make sense at this scale. This needs to be free aside from overhead.\n* There won't be a centralized solution coming - it's just not happening. If I don't do it, it just won't get done.\n* This will never leave the hands of our small business team, so I'm not worried about security.", "author_fullname": "t2_u4i3bpjyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I go about creating a small-scale data warehouse for a small business team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apzymj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707847774.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I work at a rather large company that itself houses smaller &amp;quot;businesses&amp;quot; within it. My small team is in charge of managing this small business and its business needs. Because the org as a whole is so large and there are so many of these smaller businesses that operate independently, there&amp;#39;s no centralized data warehouse and retrieving data is manual, meaning report automation is next to impossible.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Goal:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not pretty, but I&amp;#39;ve found a way to automate the retrieval of data from Workday, Oracle Business Intelligence, along with some other in-house apps/tools. My ultimate goal is to bring in data from all of these different sources and create a a stupid-simple relational database. Because this is just for the business needs of our small business, I&amp;#39;m not too worried about the volume of data becoming overwhelming (certainly not in the near future).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve worked with SQL in prior roles, but not from the perspective of a data/warehouse architect. That being said, I have time... lots and lots of time, so I don&amp;#39;t mind learning on the side to get this done. This would be somewhat of a fun side project for me.&lt;/p&gt;\n\n&lt;p&gt;At the moment, I&amp;#39;ve identified PostgreSQL as a good candidate for both production and data warehousing. It might be that I&amp;#39;m hallucinating and this not remotely the best approach for what I&amp;#39;m trying to do, and I&amp;#39;m totally open to hearing that. I&amp;#39;m honestly just looking for where to go next, how to get started, and hopefully learn some tips from other who were on a similar boat.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes and Constraints:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I&amp;#39;ll likely be able to secure a separate machine from my own to act as a server, but for now I&amp;#39;ll be doing this on my own machine as a proof of concept.&lt;/li&gt;\n&lt;li&gt;I won&amp;#39;t be able to pay for any of the usual services, it just doesn&amp;#39;t make sense at this scale. This needs to be free aside from overhead.&lt;/li&gt;\n&lt;li&gt;There won&amp;#39;t be a centralized solution coming - it&amp;#39;s just not happening. If I don&amp;#39;t do it, it just won&amp;#39;t get done.&lt;/li&gt;\n&lt;li&gt;This will never leave the hands of our small business team, so I&amp;#39;m not worried about security.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apzymj", "is_robot_indexable": true, "report_reasons": null, "author": "AstralSerenity", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/", "subreddit_subscribers": 160534, "created_utc": 1707847340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you tried the following\n\nDremio\nTrino\nPresto\n\nIf you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? \n\nReally interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you tried these tools? If not, why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6dbj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707862868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried the following&lt;/p&gt;\n\n&lt;p&gt;Dremio\nTrino\nPresto&lt;/p&gt;\n\n&lt;p&gt;If you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? &lt;/p&gt;\n\n&lt;p&gt;Really interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq6dbj", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "subreddit_subscribers": 160534, "created_utc": 1707862868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was working with Kestra but really struggling with their documentation. Have heard good things about Kestra but was hoping for some general feedback.\n\nOne thing I noticed is the python based approach. We use a lot of docker containers so I was curious what others approach was. Do you interweave your existing code base with dagster by adding it directly within the code. Or do you make python workflows calling these docker containers?", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Feedback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apwl21", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707839274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was working with Kestra but really struggling with their documentation. Have heard good things about Kestra but was hoping for some general feedback.&lt;/p&gt;\n\n&lt;p&gt;One thing I noticed is the python based approach. We use a lot of docker containers so I was curious what others approach was. Do you interweave your existing code base with dagster by adding it directly within the code. Or do you make python workflows calling these docker containers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apwl21", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apwl21/dagster_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apwl21/dagster_feedback/", "subreddit_subscribers": 160534, "created_utc": 1707839274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Our research group at Princeton University recently produced Codex, an online data explorer for the first synapse-resolution brain map, known as a connectome. This connectome was mapped over the past 5 years with hundreds of researchers from around the world. \n\nNow that the brain is mapped, we're looking to improve automated cell labeling. Today the Visual Column Mapping Challenge launches on Codex. This open data analysis challenge will improve the assignment of neurons to optic units known as columns. \n\nAnyone is invited to participate: [https://codex.flywire.ai/app/visual\\_columns\\_challenge](https://codex.flywire.ai/app/visual_columns_challenge) The winner will be invited to give a talk at Princeton University, if interested. We're also hiring developers! \n\nPlease ask questions in the comments.\n\nMore information about the project: [flywire.ai](http://flywire.ai/)  \nExample neuron assignments: [https://youtu.be/wSP0st3ypA8](https://youtu.be/wSP0st3ypA8)", "author_fullname": "t2_4gw96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connectomics Data Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apv4t0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707835553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our research group at Princeton University recently produced Codex, an online data explorer for the first synapse-resolution brain map, known as a connectome. This connectome was mapped over the past 5 years with hundreds of researchers from around the world. &lt;/p&gt;\n\n&lt;p&gt;Now that the brain is mapped, we&amp;#39;re looking to improve automated cell labeling. Today the Visual Column Mapping Challenge launches on Codex. This open data analysis challenge will improve the assignment of neurons to optic units known as columns. &lt;/p&gt;\n\n&lt;p&gt;Anyone is invited to participate: &lt;a href=\"https://codex.flywire.ai/app/visual_columns_challenge\"&gt;https://codex.flywire.ai/app/visual_columns_challenge&lt;/a&gt; The winner will be invited to give a talk at Princeton University, if interested. We&amp;#39;re also hiring developers! &lt;/p&gt;\n\n&lt;p&gt;Please ask questions in the comments.&lt;/p&gt;\n\n&lt;p&gt;More information about the project: &lt;a href=\"http://flywire.ai/\"&gt;flywire.ai&lt;/a&gt;&lt;br/&gt;\nExample neuron assignments: &lt;a href=\"https://youtu.be/wSP0st3ypA8\"&gt;https://youtu.be/wSP0st3ypA8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1apv4t0", "is_robot_indexable": true, "report_reasons": null, "author": "amyleerobinson", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apv4t0/connectomics_data_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apv4t0/connectomics_data_challenge/", "subreddit_subscribers": 160534, "created_utc": 1707835553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**I am checking into multiple catalogs and I am  curious.**   \n*Have any of you set one up? Which one did you choose and why?* \n\n*What was the actual need for the data catalog in the first place?*   \n\n\n**For those who are working with catalogs:**  \n*How is it going? Was there any big change in how you work with your data or with your team?*  \n*Did anyone had any big wins by implementing a catalog?*  \n\n\n  \nSorry for asking too much questions. Any insights on the topic is appreciated !  \n\n\nThanks. ", "author_fullname": "t2_o78u2p44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who's Using Data Catalogs? Need your insights !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq7xh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707866755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;I am checking into multiple catalogs and I am  curious.&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;Have any of you set one up? Which one did you choose and why?&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;What was the actual need for the data catalog in the first place?&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;For those who are working with catalogs:&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;How is it going? Was there any big change in how you work with your data or with your team?&lt;/em&gt;&lt;br/&gt;\n&lt;em&gt;Did anyone had any big wins by implementing a catalog?&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;Sorry for asking too much questions. Any insights on the topic is appreciated !  &lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq7xh9", "is_robot_indexable": true, "report_reasons": null, "author": "SignificanceNo136", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "subreddit_subscribers": 160534, "created_utc": 1707866755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a potential for legal issues regarding intellectual property rights and the disclosure of information to the public or competitors when utilizing GenAI or PandasAI?\n\n I've come across articles indicating that one in four companies is restricting their use due to these concerns.\n\nhttps://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms\n\nIs it safe to use GenAi or PandasAi (powered by open ai) for clients data which is confidential and not suppose to leak in public??", "author_fullname": "t2_m8ka6cao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are GenAI&amp; PandasAi safe to use for confidential data ??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1appuju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707817934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a potential for legal issues regarding intellectual property rights and the disclosure of information to the public or competitors when utilizing GenAI or PandasAI?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve come across articles indicating that one in four companies is restricting their use due to these concerns.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms\"&gt;https://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is it safe to use GenAi or PandasAi (powered by open ai) for clients data which is confidential and not suppose to leak in public??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1appuju", "is_robot_indexable": true, "report_reasons": null, "author": "TylerTheBat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1appuju/are_genai_pandasai_safe_to_use_for_confidential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1appuju/are_genai_pandasai_safe_to_use_for_confidential/", "subreddit_subscribers": 160534, "created_utc": 1707817934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI'm a data scientist transitioning into data engineering. I was wondering how is the job market in 2024 for foreigners in your country.\n\nAre there jobs that I can work home office from my country? Would I need to realocate? I'm wondering about this mostly for the US, Canada or Europe. How hard would that be? \n\nI'm brazilian, if that helps.", "author_fullname": "t2_5f8z1ygw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Market for Foreigners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq0u4f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707849432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data scientist transitioning into data engineering. I was wondering how is the job market in 2024 for foreigners in your country.&lt;/p&gt;\n\n&lt;p&gt;Are there jobs that I can work home office from my country? Would I need to realocate? I&amp;#39;m wondering about this mostly for the US, Canada or Europe. How hard would that be? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m brazilian, if that helps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aq0u4f", "is_robot_indexable": true, "report_reasons": null, "author": "luishacm", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/", "subreddit_subscribers": 160534, "created_utc": 1707849432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In deciding whether I want to use a star schema for a portfolio project- I see that one of my dim tables will have a one-to-one relationship with the fact table.\n\nAm I right in thinking there isn't any point to this? and it would be better as OBT?\n\nfor context, this is NLP data extracted from YouTube video comment sections. The \"entity\\_id\" PK in topic\\_entities would have a 1:1 with video\\_topic\\_facts. However, video\\_id PK would have a regular many-to-one relationship to video\\_entities. \n\nFacts:\n\n* video\\_topic\\_facts\n   *   entity\\_count\n   *   entity\\_id\n   *   video\\_id\n\nDimensions:\n\n* topic\\_entities\n   * entity\\_text\n   * entity\\_type\n   * entity\\_id\n* video\\_entities\n   * video\\_title\n   * video\\_id\n\n&amp;#x200B;\n\n ", "author_fullname": "t2_8chdw7c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "one-to-one relationships in star schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq01f4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In deciding whether I want to use a star schema for a portfolio project- I see that one of my dim tables will have a one-to-one relationship with the fact table.&lt;/p&gt;\n\n&lt;p&gt;Am I right in thinking there isn&amp;#39;t any point to this? and it would be better as OBT?&lt;/p&gt;\n\n&lt;p&gt;for context, this is NLP data extracted from YouTube video comment sections. The &amp;quot;entity_id&amp;quot; PK in topic_entities would have a 1:1 with video_topic_facts. However, video_id PK would have a regular many-to-one relationship to video_entities. &lt;/p&gt;\n\n&lt;p&gt;Facts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;video_topic_facts\n\n&lt;ul&gt;\n&lt;li&gt;  entity_count&lt;/li&gt;\n&lt;li&gt;  entity_id&lt;/li&gt;\n&lt;li&gt;  video_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Dimensions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;topic_entities\n\n&lt;ul&gt;\n&lt;li&gt;entity_text&lt;/li&gt;\n&lt;li&gt;entity_type&lt;/li&gt;\n&lt;li&gt;entity_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;video_entities\n\n&lt;ul&gt;\n&lt;li&gt;video_title&lt;/li&gt;\n&lt;li&gt;video_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq01f4", "is_robot_indexable": true, "report_reasons": null, "author": "pdxtechnologist", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/", "subreddit_subscribers": 160534, "created_utc": 1707847529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nSo I have been working with tools like SSAS to create tabular models destined for analytics. But never got the chance to use datamarts and looking it up on the internet I still do not understand the difference between the two.\n\nAre datamarts an aggregated view/table that contains all necessary data for a specific requirement like Business Unit?", "author_fullname": "t2_c5ezp8a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the difference between a data mart and a regular data model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq00v5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;So I have been working with tools like SSAS to create tabular models destined for analytics. But never got the chance to use datamarts and looking it up on the internet I still do not understand the difference between the two.&lt;/p&gt;\n\n&lt;p&gt;Are datamarts an aggregated view/table that contains all necessary data for a specific requirement like Business Unit?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq00v5", "is_robot_indexable": true, "report_reasons": null, "author": "TaleLegal9085", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/", "subreddit_subscribers": 160534, "created_utc": 1707847492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teradata Vantage\u2122 destination now available on Airbyte Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1aptdwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Tiaut8WJbOq0L9bIRsUvKLmUIgUwE5YMJ2pEAaTH67w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707830668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/teradata/teradata-vantage-destination-now-available-on-airbyte-cloud-1eed7479e40e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?auto=webp&amp;s=e37a3e71b3f616b02118c07965c9b695c050e93b", "width": 720, "height": 378}, "resolutions": [{"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=524c6a562eaad5416a45bf286d89a1e0671c3199", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0871e1fcf68766d31dd58ea35a5a389781235418", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d9afa6e8c273da550a3984c885aa0e40100a65a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ddeaf70e6d816093cd513cb169dd1a6402ba919a", "width": 640, "height": 336}], "variants": {}, "id": "lVlFbUvlw0Jq-P3OEBBT3MD3fBTZ0fn8x73rPOj2HnU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aptdwv", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aptdwv/teradata_vantage_destination_now_available_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/teradata/teradata-vantage-destination-now-available-on-airbyte-cloud-1eed7479e40e", "subreddit_subscribers": 160534, "created_utc": 1707830668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have a task to load data from Salesforce to Snowflake using ADF. But so far I can see many people are using Blob storage for staging. So can we use ADF to copy data from Salesforce to Snowflake directly without staging data in Blob storage? because using Blog storage requires to use SaS token which my IT department is trying to avoid. #ADF #Snowflake #Salesforce #Azure #Blob", "author_fullname": "t2_hi267s7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we use ADF to copy data from Salesforce to Snowflake directly without staging data in Blob storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apktdn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707798612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a task to load data from Salesforce to Snowflake using ADF. But so far I can see many people are using Blob storage for staging. So can we use ADF to copy data from Salesforce to Snowflake directly without staging data in Blob storage? because using Blog storage requires to use SaS token which my IT department is trying to avoid. #ADF #Snowflake #Salesforce #Azure #Blob&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apktdn", "is_robot_indexable": true, "report_reasons": null, "author": "JK_1975", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apktdn/can_we_use_adf_to_copy_data_from_salesforce_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apktdn/can_we_use_adf_to_copy_data_from_salesforce_to/", "subreddit_subscribers": 160534, "created_utc": 1707798612.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nDo you know other teams building in public like the Gitlab team [https://gitlab.com/gitlab-data](https://gitlab.com/gitlab-data) ?\n\nI would like to get inspiration from their setup , I believe you can learn alot like that.\n\nThanks!", "author_fullname": "t2_ce0xxymx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data teams building in public repositories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apxt0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707842230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Do you know other teams building in public like the Gitlab team &lt;a href=\"https://gitlab.com/gitlab-data\"&gt;https://gitlab.com/gitlab-data&lt;/a&gt; ?&lt;/p&gt;\n\n&lt;p&gt;I would like to get inspiration from their setup , I believe you can learn alot like that.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?auto=webp&amp;s=2e94811ad974ef30758f1bfa1f573d0b8650b047", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38575afd6c6a3e5a0dcad7df2a63932f81adef3e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d40ddb743ced8470d911c7619186583ebb7cdc9a", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ed80f7c027a149b59802da37fcb5c5d42fc12bb", "width": 320, "height": 320}], "variants": {}, "id": "Vk4X7KEHj7HIY3r031F0NmctkfFvGIw2zTvw0AtlGsg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apxt0o", "is_robot_indexable": true, "report_reasons": null, "author": "Wingsofpeace7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/", "subreddit_subscribers": 160534, "created_utc": 1707842230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Current company is starting to reach a point of data-usage maturity where one-way reporting is not enough. Although a buzzword, the case for needing \u201cdata products\u201d is becoming relevant.\n\nOne such example is time-to-event analysis, where relevant stakeholders would like to be able to provide parameter inputs, which in turn will act as e.g., cohort definitions for analysis.\n\nIn contrast to current reporting, this usage pattern requires new tooling and processes. Current setup has Power BI and Databricks available - does anyone here have experience with using this mix as a frontend / backend setup through which Power BI parameters are passed to Databricks, and analysis results are returned dynamically? Is something like this possible?", "author_fullname": "t2_7569qa0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Power BI as frontend and Databricks as compute engine for data products", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aps1ts", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707826507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Current company is starting to reach a point of data-usage maturity where one-way reporting is not enough. Although a buzzword, the case for needing \u201cdata products\u201d is becoming relevant.&lt;/p&gt;\n\n&lt;p&gt;One such example is time-to-event analysis, where relevant stakeholders would like to be able to provide parameter inputs, which in turn will act as e.g., cohort definitions for analysis.&lt;/p&gt;\n\n&lt;p&gt;In contrast to current reporting, this usage pattern requires new tooling and processes. Current setup has Power BI and Databricks available - does anyone here have experience with using this mix as a frontend / backend setup through which Power BI parameters are passed to Databricks, and analysis results are returned dynamically? Is something like this possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aps1ts", "is_robot_indexable": true, "report_reasons": null, "author": "No_Lawfulness_6252", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aps1ts/using_power_bi_as_frontend_and_databricks_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aps1ts/using_power_bi_as_frontend_and_databricks_as/", "subreddit_subscribers": 160534, "created_utc": 1707826507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're considering transitioning to Kafka, specifically using the MSK managed service, from our current setup that involves ingesting data into an SQS FIFO queue. Our processing strategy relies on splitting the workload per message group ID, and we have around 20,000 different message group IDs in use.  \nI understand that mirroring this logic directly in Kafka by creating a partition for each message group ID might not align with best practices, especially since the volume of messages we're dealing with isn't extraordinarily high. However, adopting this approach could facilitate a smoother transition for our team.  \nCould anyone share insights on the practical upper limit for partitions in a Kafka (MSK managed) environment? Are there any significant downsides or performance implications we should be aware of when managing such a large number of partitions, particularly when the message volume doesn't necessarily justify it? Additionally, if anyone has navigated a similar transition or has alternative suggestions for handling this use case in Kafka, your advice would be greatly appreciated.", "author_fullname": "t2_4gvnzc5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Partitioning Limit in Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1appi2g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707816417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re considering transitioning to Kafka, specifically using the MSK managed service, from our current setup that involves ingesting data into an SQS FIFO queue. Our processing strategy relies on splitting the workload per message group ID, and we have around 20,000 different message group IDs in use.&lt;br/&gt;\nI understand that mirroring this logic directly in Kafka by creating a partition for each message group ID might not align with best practices, especially since the volume of messages we&amp;#39;re dealing with isn&amp;#39;t extraordinarily high. However, adopting this approach could facilitate a smoother transition for our team.&lt;br/&gt;\nCould anyone share insights on the practical upper limit for partitions in a Kafka (MSK managed) environment? Are there any significant downsides or performance implications we should be aware of when managing such a large number of partitions, particularly when the message volume doesn&amp;#39;t necessarily justify it? Additionally, if anyone has navigated a similar transition or has alternative suggestions for handling this use case in Kafka, your advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1appi2g", "is_robot_indexable": true, "report_reasons": null, "author": "Plus-Author9252", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1appi2g/partitioning_limit_in_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1appi2g/partitioning_limit_in_kafka/", "subreddit_subscribers": 160534, "created_utc": 1707816417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw today two people at my company who have respectively 10 months and 1 year of time as data engineers.\n\n the one who especialy caught my attention is the 10 months one , she got 1 terraform cert , 5 azure certifications (2 fundamental and 2 associate ) 1 aws associate sa and gcp data engineer professional ,the other 1 year guy got it too .\n\nthe crazy part is that she sometimes got 2 certs on the same month and gets also lots of badges from companies like ibm wich take around 3-5 hours each .\n\n this got me confused as to wether this pacing is normal , and wether it is actualy beneficial to spam learning certifications after comming from work?", "author_fullname": "t2_ugpyk8nc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is gcp professional data engineer certification easy or are the new grads i saw just good ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aqbfw4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707876365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw today two people at my company who have respectively 10 months and 1 year of time as data engineers.&lt;/p&gt;\n\n&lt;p&gt;the one who especialy caught my attention is the 10 months one , she got 1 terraform cert , 5 azure certifications (2 fundamental and 2 associate ) 1 aws associate sa and gcp data engineer professional ,the other 1 year guy got it too .&lt;/p&gt;\n\n&lt;p&gt;the crazy part is that she sometimes got 2 certs on the same month and gets also lots of badges from companies like ibm wich take around 3-5 hours each .&lt;/p&gt;\n\n&lt;p&gt;this got me confused as to wether this pacing is normal , and wether it is actualy beneficial to spam learning certifications after comming from work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqbfw4", "is_robot_indexable": true, "report_reasons": null, "author": "PapoPiPopA", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqbfw4/is_gcp_professional_data_engineer_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqbfw4/is_gcp_professional_data_engineer_certification/", "subreddit_subscribers": 160534, "created_utc": 1707876365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in an organization that has built custom tooling, but there are many issues, and I'm looking into alternatives. I'm particularly concerned with orchestration, ELT tooling, and schema management. I've got my eyes on dagster + dbt right now, but I'm not sure they'll work for my purposes just yet.\n\nSome architecture that cannot change:\n\n* There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same\n* Due to the above, there must be a DAG instance per customer, for each DAG specification\n* Something is needed to manage schema updates and create new databases with up-to-date schemas\n\nI imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven't been able to easily discern this from documentation.\n\nI don't fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I'd only work with abstractions, or if I'd be working with underlying tables. I'm not really looking for an ORM. I'm looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.\n\nAny recommendations are appreciated! I'm just looking very high level right now.", "author_fullname": "t2_89dmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking recommendation for tools that will work for a specific architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq8qdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707868806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in an organization that has built custom tooling, but there are many issues, and I&amp;#39;m looking into alternatives. I&amp;#39;m particularly concerned with orchestration, ELT tooling, and schema management. I&amp;#39;ve got my eyes on dagster + dbt right now, but I&amp;#39;m not sure they&amp;#39;ll work for my purposes just yet.&lt;/p&gt;\n\n&lt;p&gt;Some architecture that cannot change:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same&lt;/li&gt;\n&lt;li&gt;Due to the above, there must be a DAG instance per customer, for each DAG specification&lt;/li&gt;\n&lt;li&gt;Something is needed to manage schema updates and create new databases with up-to-date schemas&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven&amp;#39;t been able to easily discern this from documentation.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I&amp;#39;d only work with abstractions, or if I&amp;#39;d be working with underlying tables. I&amp;#39;m not really looking for an ORM. I&amp;#39;m looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations are appreciated! I&amp;#39;m just looking very high level right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq8qdc", "is_robot_indexable": true, "report_reasons": null, "author": "endotronic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "subreddit_subscribers": 160534, "created_utc": 1707868806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all.  Question about DBT testing.  \n\n1. is there a DBT sub that I cant find?\n\nWe have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR's proposed changes to that model.\n\n    SELECT \n        CASE \n            WHEN (SELECT COUNT(*) AS ROW_CNT\n                    FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n                = (SELECT COUNT(*) AS ROW_CNT\n                    FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            THEN 'Success!'\n            ELSE 'PR changed row count'\n        END AS STATUS\n\nI was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn't want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:\n\n    MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n    DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n\nSure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn't have a row count change.  \n\nIt also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR's are supposed to change the model's row count, so we wouldn't run this test on every model, and we would just skip it for those.\n\nBut also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_b12wxz418", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT generic schema tests questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6kpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707863377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.  Question about DBT testing.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;is there a DBT sub that I cant find?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR&amp;#39;s proposed changes to that model.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT \n    CASE \n        WHEN (SELECT COUNT(*) AS ROW_CNT\n                FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            = (SELECT COUNT(*) AS ROW_CNT\n                FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n        THEN &amp;#39;Success!&amp;#39;\n        ELSE &amp;#39;PR changed row count&amp;#39;\n    END AS STATUS\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn&amp;#39;t want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\nDBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Sure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn&amp;#39;t have a row count change.  &lt;/p&gt;\n\n&lt;p&gt;It also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR&amp;#39;s are supposed to change the model&amp;#39;s row count, so we wouldn&amp;#39;t run this test on every model, and we would just skip it for those.&lt;/p&gt;\n\n&lt;p&gt;But also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq6kpm", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Goose82", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "subreddit_subscribers": 160534, "created_utc": 1707863377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All,\n\nI am trying to make a data flow task in SSIS where I insert data from an OLE DB Source to an OLE DB Destination (i.e. two different SQL Server instances on different VMs). I was able to get the OLE DB Source connection to work. The OLE DB Source is a SQL Server instance on a personal VM that I use for staging and data conversion.\n\nHowever, when I try to establish the OLE DB Destination I keep getting an error because the destination SQL Server is on a different VM/data server. No matter which provider, server name, or credentials I use I cannot get it to work. \n\nCan anyone please point me the in the right direction?\n\n[here are the providers that I see available.](https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;format=pjpg&amp;auto=webp&amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5)\n\nI usually use \"Microsoft OLE DB Provider for SQL Server\" for the source so I thought I could do the same with the destination, but I'm not sure which authentication I should be using?\n\n&amp;#x200B;\n\n[I've tried every combination of options here and I still get an error.](https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;format=pjpg&amp;auto=webp&amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72)\n\n&amp;#x200B;\n\nHere is the error I get when I try, for example, the sa account:\n\nhttps://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;format=pjpg&amp;auto=webp&amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6", "author_fullname": "t2_pz85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to establish an OLE DB Destination in SSIS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jgxp480s6dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ea4845ec5a30e8e4260764982dba818b95f3c67"}, {"y": 187, "x": 216, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=14989d0ec79924357426b04d3f42ca2e011f86f5"}, {"y": 277, "x": 320, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c4f027cc52e6156b0ec4a61478f0ab5e893b20d"}, {"y": 555, "x": 640, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b0ef8ce4f5d3950f6bf820a4f36a7b45725f67"}], "s": {"y": 615, "x": 709, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;format=pjpg&amp;auto=webp&amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72"}, "id": "jgxp480s6dic1"}, "0kh68hhi6dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 94, "x": 108, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f931891bef72e68dc315f12ae871955ae79acfe"}, {"y": 188, "x": 216, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4ed82d0e98bbf6b44bfa03cfeb446d4e69bd12f"}, {"y": 278, "x": 320, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e965273c6cab16e03206ddaa015db652288e272"}, {"y": 557, "x": 640, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a6e79e60be8183e9e1077b1feb6cdaf6a69fd39a"}], "s": {"y": 617, "x": 708, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;format=pjpg&amp;auto=webp&amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5"}, "id": "0kh68hhi6dic1"}, "fvhn6k947dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=727ed637847b1b59ead0d259c73fe74fc06d8d84"}, {"y": 186, "x": 216, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=71eaa0a28177d5f3f46145f49f8c34cb8b642546"}, {"y": 275, "x": 320, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f093e3f9905a98f74c0784b0b7c4b78e058f8e4"}, {"y": 551, "x": 640, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a48e2f4f5c636d6a0416f35e43ba7049bd10a192"}], "s": {"y": 615, "x": 714, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;format=pjpg&amp;auto=webp&amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6"}, "id": "fvhn6k947dic1"}}, "name": "t3_1apv2d7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707835372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All,&lt;/p&gt;\n\n&lt;p&gt;I am trying to make a data flow task in SSIS where I insert data from an OLE DB Source to an OLE DB Destination (i.e. two different SQL Server instances on different VMs). I was able to get the OLE DB Source connection to work. The OLE DB Source is a SQL Server instance on a personal VM that I use for staging and data conversion.&lt;/p&gt;\n\n&lt;p&gt;However, when I try to establish the OLE DB Destination I keep getting an error because the destination SQL Server is on a different VM/data server. No matter which provider, server name, or credentials I use I cannot get it to work. &lt;/p&gt;\n\n&lt;p&gt;Can anyone please point me the in the right direction?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5\"&gt;here are the providers that I see available.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I usually use &amp;quot;Microsoft OLE DB Provider for SQL Server&amp;quot; for the source so I thought I could do the same with the destination, but I&amp;#39;m not sure which authentication I should be using?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72\"&gt;I&amp;#39;ve tried every combination of options here and I still get an error.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is the error I get when I try, for example, the sa account:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6\"&gt;https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apv2d7", "is_robot_indexable": true, "report_reasons": null, "author": "imperialka", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apv2d7/how_to_establish_an_ole_db_destination_in_ssis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apv2d7/how_to_establish_an_ole_db_destination_in_ssis/", "subreddit_subscribers": 160534, "created_utc": 1707835372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "9 Ways to Sell Data Services to Non-Data-Savvy Clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_1apslj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/A0JigRAjDKfQXGNY4Oro-5k6nQrFh6cFehUHXWEXp1M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707828296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arch.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arch.dev/blog/9-ways-to-sell-data-services-to-non-data-savvy-clients/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?auto=webp&amp;s=dd0619d54ab73c556df67e53bb6ac4094864d9bf", "width": 1792, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ced09eb8a9e4a3558ff5343beaa73a3c4cf95a71", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c040d916e2baeb92d720295d383e8fd8ad388645", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a115173d96ec81194ae458e7f3e746ee0c97ba0a", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2be395bfeae3bd57d82d217ac91e98f681910a3f", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0face84594b4d2c0185dcc068527fd7892187676", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a7d0a6feb383da3ef1f272a622d20f032a50316e", "width": 1080, "height": 617}], "variants": {}, "id": "z7CoTrlLtc-r4VMaXW_ohkdRv4NYyn8ke16DqOHW03k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1apslj8", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apslj8/9_ways_to_sell_data_services_to_nondatasavvy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arch.dev/blog/9-ways-to-sell-data-services-to-non-data-savvy-clients/", "subreddit_subscribers": 160534, "created_utc": 1707828296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\nHaving worked as a devops engineer for a while, I\u2019m a bit confused about how we use infrastructure as a code to deploy vertex ai pipelines. \n\nMy usually workflow is GitHub-PIpelines-Terraform-Infrastructure created. However this seems different with vertex ai pipelines ?", "author_fullname": "t2_93n793j1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vertex ai and code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aps4cd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707826748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Having worked as a devops engineer for a while, I\u2019m a bit confused about how we use infrastructure as a code to deploy vertex ai pipelines. &lt;/p&gt;\n\n&lt;p&gt;My usually workflow is GitHub-PIpelines-Terraform-Infrastructure created. However this seems different with vertex ai pipelines ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aps4cd", "is_robot_indexable": true, "report_reasons": null, "author": "Total_Definition_401", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aps4cd/vertex_ai_and_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aps4cd/vertex_ai_and_code/", "subreddit_subscribers": 160534, "created_utc": 1707826748.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}