{"kind": "Listing", "data": {"after": "t3_1aqee7l", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got message, from credly, that my badge is available!\n\nA bit surprised, exam was heavy &amp; messy. Lots of questions from adjacent specializations like DevOps, Data Analysts, Solution Architect, and actually not much about Data Engineering in general.\n\nNow I feel like true Data Engineer @ AWS ;)\n\nCheck your emails!\n\n&amp;#x200B;\n\nPS. Took exam 1/12, in last day where beta was available, no preparations, just wanted to see what is the true \"assessment\" of my skill, to challenge myself. Hopefully, it worked out.", "author_fullname": "t2_f3zvxf9b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Passed AWS Data Engineer - Associate !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apz616", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707847512.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707845473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got message, from credly, that my badge is available!&lt;/p&gt;\n\n&lt;p&gt;A bit surprised, exam was heavy &amp;amp; messy. Lots of questions from adjacent specializations like DevOps, Data Analysts, Solution Architect, and actually not much about Data Engineering in general.&lt;/p&gt;\n\n&lt;p&gt;Now I feel like true Data Engineer @ AWS ;)&lt;/p&gt;\n\n&lt;p&gt;Check your emails!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;PS. Took exam 1/12, in last day where beta was available, no preparations, just wanted to see what is the true &amp;quot;assessment&amp;quot; of my skill, to challenge myself. Hopefully, it worked out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1apz616", "is_robot_indexable": true, "report_reasons": null, "author": "dev_lvl80", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/", "subreddit_subscribers": 160579, "created_utc": 1707845473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am not usually reading about my craft, but recently came across two books that captured my imagination in CI/CD and data.\n\nReading these two helped me to understand the different perspectives coming from the technology side and from the business side.\n\nAs a result, I can better understand how the business sees problems which is not always easy for me as a dev. I think I can also have better conversations with the business side as an engineer.\n\n* The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win\n* The Unicorn Project: A Novel about Developers, Digital Disruption, and Thriving in the Age of Data\n\nReading these two helped me to understand the different perspectives coming from the technology side and the business side. ave better conversations with the business side as an engineer. ineer.\n\nThe title is obviously a bit of an overstatement, I'd love to hear your recommendations for the books you think are best.", "author_fullname": "t2_h58nyr96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The only two books you need to read about CI/CD and Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apolbz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707812720.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707812439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not usually reading about my craft, but recently came across two books that captured my imagination in CI/CD and data.&lt;/p&gt;\n\n&lt;p&gt;Reading these two helped me to understand the different perspectives coming from the technology side and from the business side.&lt;/p&gt;\n\n&lt;p&gt;As a result, I can better understand how the business sees problems which is not always easy for me as a dev. I think I can also have better conversations with the business side as an engineer.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win&lt;/li&gt;\n&lt;li&gt;The Unicorn Project: A Novel about Developers, Digital Disruption, and Thriving in the Age of Data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Reading these two helped me to understand the different perspectives coming from the technology side and the business side. ave better conversations with the business side as an engineer. ineer.&lt;/p&gt;\n\n&lt;p&gt;The title is obviously a bit of an overstatement, I&amp;#39;d love to hear your recommendations for the books you think are best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apolbz", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyFish7104", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apolbz/the_only_two_books_you_need_to_read_about_cicd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apolbz/the_only_two_books_you_need_to_read_about_cicd/", "subreddit_subscribers": 160579, "created_utc": 1707812439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My friend is struggling to make a choice - remote, but 30% less pay and for big corporation or working in small firm of about 200 employees as a solo data analyst\n\nBig corporation - 50k employees +/-, 13 data analysts on her team, most are experienced, not much room to grow or manoeuvre (big bank in Poland). Remote as well.\n\nSmall firm - 30% paybump compared to big corporation, solo data analyst, about 20mins travel (which is OK for Poland) works underneath firm's director as solo analyst. Last one left because they wanted to move abroad. Company tripled in revenue in the last 2 years. Not a startup, been on the market 15 years. \n\nSo obviously remote is big plus, but not much room for growth -  she's still young, only 25, and it'll be hard to gain promotions and grow given there's 13 people in her team, and the second youngest person is over 30 with lots of experience. \n\nOther company - room to grow and expand, possible manager within two-ish years. Works underneath the firm's director and CEO. Obviously if something goes wrong it's on her. And in office, no hybrid. \n\nWhat would you pick, I said I'll ask some people but we're all kinda like \"that's a tough one\".", "author_fullname": "t2_ki4xz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pick 30% paybump for a small company or work in a big bank?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apqjnd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707820828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend is struggling to make a choice - remote, but 30% less pay and for big corporation or working in small firm of about 200 employees as a solo data analyst&lt;/p&gt;\n\n&lt;p&gt;Big corporation - 50k employees +/-, 13 data analysts on her team, most are experienced, not much room to grow or manoeuvre (big bank in Poland). Remote as well.&lt;/p&gt;\n\n&lt;p&gt;Small firm - 30% paybump compared to big corporation, solo data analyst, about 20mins travel (which is OK for Poland) works underneath firm&amp;#39;s director as solo analyst. Last one left because they wanted to move abroad. Company tripled in revenue in the last 2 years. Not a startup, been on the market 15 years. &lt;/p&gt;\n\n&lt;p&gt;So obviously remote is big plus, but not much room for growth -  she&amp;#39;s still young, only 25, and it&amp;#39;ll be hard to gain promotions and grow given there&amp;#39;s 13 people in her team, and the second youngest person is over 30 with lots of experience. &lt;/p&gt;\n\n&lt;p&gt;Other company - room to grow and expand, possible manager within two-ish years. Works underneath the firm&amp;#39;s director and CEO. Obviously if something goes wrong it&amp;#39;s on her. And in office, no hybrid. &lt;/p&gt;\n\n&lt;p&gt;What would you pick, I said I&amp;#39;ll ask some people but we&amp;#39;re all kinda like &amp;quot;that&amp;#39;s a tough one&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1apqjnd", "is_robot_indexable": true, "report_reasons": null, "author": "Leopatto", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apqjnd/pick_30_paybump_for_a_small_company_or_work_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apqjnd/pick_30_paybump_for_a_small_company_or_work_in_a/", "subreddit_subscribers": 160579, "created_utc": 1707820828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw today two people at my company who have respectively 10 months and 1 year of time as data engineers.\n\n the one who especialy caught my attention is the 10 months one , she got 1 terraform cert , 5 azure certifications (2 fundamental and 2 associate ) 1 aws associate sa and gcp data engineer professional ,the other 1 year guy got it too .\n\nthe crazy part is that she sometimes got 2 certs on the same month and gets also lots of badges from companies like ibm wich take around 3-5 hours each .\n\n this got me confused as to wether this pacing is normal , and wether it is actualy beneficial to spam learning certifications after comming from work?", "author_fullname": "t2_ugpyk8nc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is gcp professional data engineer certification easy or are the new grads i saw just good ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqbfw4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707876365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw today two people at my company who have respectively 10 months and 1 year of time as data engineers.&lt;/p&gt;\n\n&lt;p&gt;the one who especialy caught my attention is the 10 months one , she got 1 terraform cert , 5 azure certifications (2 fundamental and 2 associate ) 1 aws associate sa and gcp data engineer professional ,the other 1 year guy got it too .&lt;/p&gt;\n\n&lt;p&gt;the crazy part is that she sometimes got 2 certs on the same month and gets also lots of badges from companies like ibm wich take around 3-5 hours each .&lt;/p&gt;\n\n&lt;p&gt;this got me confused as to wether this pacing is normal , and wether it is actualy beneficial to spam learning certifications after comming from work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqbfw4", "is_robot_indexable": true, "report_reasons": null, "author": "PapoPiPopA", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqbfw4/is_gcp_professional_data_engineer_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqbfw4/is_gcp_professional_data_engineer_certification/", "subreddit_subscribers": 160579, "created_utc": 1707876365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Context:**\n\nI work at a rather large company that itself houses smaller \"businesses\" within it. My small team is in charge of managing this small business and its business needs. Because the org as a whole is so large and there are so many of these smaller businesses that operate independently, there's no centralized data warehouse and retrieving data is manual, meaning report automation is next to impossible.\n\n&amp;#x200B;\n\n**The Goal:**\n\nIt's not pretty, but I've found a way to automate the retrieval of data from Workday, Oracle Business Intelligence, along with some other in-house apps/tools. My ultimate goal is to bring in data from all of these different sources and create a a stupid-simple relational database. Because this is just for the business needs of our small business, I'm not too worried about the volume of data becoming overwhelming (certainly not in the near future).\n\nI've worked with SQL in prior roles, but not from the perspective of a data/warehouse architect. That being said, I have time... lots and lots of time, so I don't mind learning on the side to get this done. This would be somewhat of a fun side project for me.\n\nAt the moment, I've identified PostgreSQL as a good candidate for both production and data warehousing. It might be that I'm hallucinating and this not remotely the best approach for what I'm trying to do, and I'm totally open to hearing that. I'm honestly just looking for where to go next, how to get started, and hopefully learn some tips from other who were on a similar boat.\n\n&amp;#x200B;\n\n**Notes and Constraints:**\n\n* I'll likely be able to secure a separate machine from my own to act as a server, but for now I'll be doing this on my own machine as a proof of concept.\n* I won't be able to pay for any of the usual services, it just doesn't make sense at this scale. This needs to be free aside from overhead.\n* There won't be a centralized solution coming - it's just not happening. If I don't do it, it just won't get done.\n* This will never leave the hands of our small business team, so I'm not worried about security.", "author_fullname": "t2_u4i3bpjyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I go about creating a small-scale data warehouse for a small business team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apzymj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707847774.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I work at a rather large company that itself houses smaller &amp;quot;businesses&amp;quot; within it. My small team is in charge of managing this small business and its business needs. Because the org as a whole is so large and there are so many of these smaller businesses that operate independently, there&amp;#39;s no centralized data warehouse and retrieving data is manual, meaning report automation is next to impossible.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Goal:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not pretty, but I&amp;#39;ve found a way to automate the retrieval of data from Workday, Oracle Business Intelligence, along with some other in-house apps/tools. My ultimate goal is to bring in data from all of these different sources and create a a stupid-simple relational database. Because this is just for the business needs of our small business, I&amp;#39;m not too worried about the volume of data becoming overwhelming (certainly not in the near future).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve worked with SQL in prior roles, but not from the perspective of a data/warehouse architect. That being said, I have time... lots and lots of time, so I don&amp;#39;t mind learning on the side to get this done. This would be somewhat of a fun side project for me.&lt;/p&gt;\n\n&lt;p&gt;At the moment, I&amp;#39;ve identified PostgreSQL as a good candidate for both production and data warehousing. It might be that I&amp;#39;m hallucinating and this not remotely the best approach for what I&amp;#39;m trying to do, and I&amp;#39;m totally open to hearing that. I&amp;#39;m honestly just looking for where to go next, how to get started, and hopefully learn some tips from other who were on a similar boat.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes and Constraints:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I&amp;#39;ll likely be able to secure a separate machine from my own to act as a server, but for now I&amp;#39;ll be doing this on my own machine as a proof of concept.&lt;/li&gt;\n&lt;li&gt;I won&amp;#39;t be able to pay for any of the usual services, it just doesn&amp;#39;t make sense at this scale. This needs to be free aside from overhead.&lt;/li&gt;\n&lt;li&gt;There won&amp;#39;t be a centralized solution coming - it&amp;#39;s just not happening. If I don&amp;#39;t do it, it just won&amp;#39;t get done.&lt;/li&gt;\n&lt;li&gt;This will never leave the hands of our small business team, so I&amp;#39;m not worried about security.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apzymj", "is_robot_indexable": true, "report_reasons": null, "author": "AstralSerenity", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/", "subreddit_subscribers": 160579, "created_utc": 1707847340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you tried the following\n\nDremio\nTrino\nPresto\n\nIf you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? \n\nReally interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you tried these tools? If not, why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6dbj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707862868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried the following&lt;/p&gt;\n\n&lt;p&gt;Dremio\nTrino\nPresto&lt;/p&gt;\n\n&lt;p&gt;If you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? &lt;/p&gt;\n\n&lt;p&gt;Really interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq6dbj", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "subreddit_subscribers": 160579, "created_utc": 1707862868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was working with Kestra but really struggling with their documentation. Have heard good things about Kestra but was hoping for some general feedback.\n\nOne thing I noticed is the python based approach. We use a lot of docker containers so I was curious what others approach was. Do you interweave your existing code base with dagster by adding it directly within the code. Or do you make python workflows calling these docker containers?", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Feedback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apwl21", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707839274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was working with Kestra but really struggling with their documentation. Have heard good things about Kestra but was hoping for some general feedback.&lt;/p&gt;\n\n&lt;p&gt;One thing I noticed is the python based approach. We use a lot of docker containers so I was curious what others approach was. Do you interweave your existing code base with dagster by adding it directly within the code. Or do you make python workflows calling these docker containers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apwl21", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apwl21/dagster_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apwl21/dagster_feedback/", "subreddit_subscribers": 160579, "created_utc": 1707839274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DBT announced a preview of a much requested feature - Column Level Lineage. \n\nThe only catch is you have to be a Cloud customer. \nDoes anyone know anymore about this and if it is coming to core?", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Column Level Lineage only for DBT Cloud customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqcvov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/z0lsxARMTCcEEhwTC0HsMFN-HuXPgaFLzzHTjhKPrd4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707880629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DBT announced a preview of a much requested feature - Column Level Lineage. &lt;/p&gt;\n\n&lt;p&gt;The only catch is you have to be a Cloud customer. \nDoes anyone know anymore about this and if it is coming to core?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?auto=webp&amp;s=cafd219029f0a3fbdad0ea8a2bcb66b3d78fde14", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b5c9815894c457c0876c8aa0738f085af8f7af8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1dd3758c396fe36d709ad00886acb150a1d9067d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94fcab0f230d58e3de92c5d7c2a2785144251838", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5a80590e63ba05ee3f1af94bd9e60ae2df5308a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=815507f574255f6785c16ea52b6bab5afc4d00bc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de48a264c01939fe48a8bdfeb28423431ccc3644", "width": 1080, "height": 567}], "variants": {}, "id": "DrZJUagpOb_HgXmGsRTaz04SkfN1EZhQLY4JvbX2Wb0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqcvov", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqcvov/dbt_column_level_lineage_only_for_dbt_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/", "subreddit_subscribers": 160579, "created_utc": 1707880629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**I am checking into multiple catalogs and I am  curious.**   \n*Have any of you set one up? Which one did you choose and why?* \n\n*What was the actual need for the data catalog in the first place?*   \n\n\n**For those who are working with catalogs:**  \n*How is it going? Was there any big change in how you work with your data or with your team?*  \n*Did anyone had any big wins by implementing a catalog?*  \n\n\n  \nSorry for asking too much questions. Any insights on the topic is appreciated !  \n\n\nThanks. ", "author_fullname": "t2_o78u2p44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who's Using Data Catalogs? Need your insights !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq7xh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707866755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;I am checking into multiple catalogs and I am  curious.&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;Have any of you set one up? Which one did you choose and why?&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;What was the actual need for the data catalog in the first place?&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;For those who are working with catalogs:&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;How is it going? Was there any big change in how you work with your data or with your team?&lt;/em&gt;&lt;br/&gt;\n&lt;em&gt;Did anyone had any big wins by implementing a catalog?&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;Sorry for asking too much questions. Any insights on the topic is appreciated !  &lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq7xh9", "is_robot_indexable": true, "report_reasons": null, "author": "SignificanceNo136", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "subreddit_subscribers": 160579, "created_utc": 1707866755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Our research group at Princeton University recently produced Codex, an online data explorer for the first synapse-resolution brain map, known as a connectome. This connectome was mapped over the past 5 years with hundreds of researchers from around the world. \n\nNow that the brain is mapped, we're looking to improve automated cell labeling. Today the Visual Column Mapping Challenge launches on Codex. This open data analysis challenge will improve the assignment of neurons to optic units known as columns. \n\nAnyone is invited to participate: [https://codex.flywire.ai/app/visual\\_columns\\_challenge](https://codex.flywire.ai/app/visual_columns_challenge) The winner will be invited to give a talk at Princeton University, if interested. We're also hiring developers! \n\nPlease ask questions in the comments.\n\nMore information about the project: [flywire.ai](http://flywire.ai/)  \nExample neuron assignments: [https://youtu.be/wSP0st3ypA8](https://youtu.be/wSP0st3ypA8)", "author_fullname": "t2_4gw96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connectomics Data Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apv4t0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707835553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our research group at Princeton University recently produced Codex, an online data explorer for the first synapse-resolution brain map, known as a connectome. This connectome was mapped over the past 5 years with hundreds of researchers from around the world. &lt;/p&gt;\n\n&lt;p&gt;Now that the brain is mapped, we&amp;#39;re looking to improve automated cell labeling. Today the Visual Column Mapping Challenge launches on Codex. This open data analysis challenge will improve the assignment of neurons to optic units known as columns. &lt;/p&gt;\n\n&lt;p&gt;Anyone is invited to participate: &lt;a href=\"https://codex.flywire.ai/app/visual_columns_challenge\"&gt;https://codex.flywire.ai/app/visual_columns_challenge&lt;/a&gt; The winner will be invited to give a talk at Princeton University, if interested. We&amp;#39;re also hiring developers! &lt;/p&gt;\n\n&lt;p&gt;Please ask questions in the comments.&lt;/p&gt;\n\n&lt;p&gt;More information about the project: &lt;a href=\"http://flywire.ai/\"&gt;flywire.ai&lt;/a&gt;&lt;br/&gt;\nExample neuron assignments: &lt;a href=\"https://youtu.be/wSP0st3ypA8\"&gt;https://youtu.be/wSP0st3ypA8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1apv4t0", "is_robot_indexable": true, "report_reasons": null, "author": "amyleerobinson", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apv4t0/connectomics_data_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apv4t0/connectomics_data_challenge/", "subreddit_subscribers": 160579, "created_utc": 1707835553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a potential for legal issues regarding intellectual property rights and the disclosure of information to the public or competitors when utilizing GenAI or PandasAI?\n\n I've come across articles indicating that one in four companies is restricting their use due to these concerns.\n\nhttps://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms\n\nIs it safe to use GenAi or PandasAi (powered by open ai) for clients data which is confidential and not suppose to leak in public??", "author_fullname": "t2_m8ka6cao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are GenAI&amp; PandasAi safe to use for confidential data ??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1appuju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707817934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a potential for legal issues regarding intellectual property rights and the disclosure of information to the public or competitors when utilizing GenAI or PandasAI?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve come across articles indicating that one in four companies is restricting their use due to these concerns.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms\"&gt;https://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is it safe to use GenAi or PandasAi (powered by open ai) for clients data which is confidential and not suppose to leak in public??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1appuju", "is_robot_indexable": true, "report_reasons": null, "author": "TylerTheBat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1appuju/are_genai_pandasai_safe_to_use_for_confidential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1appuju/are_genai_pandasai_safe_to_use_for_confidential/", "subreddit_subscribers": 160579, "created_utc": 1707817934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI'm a data scientist transitioning into data engineering. I was wondering how is the job market in 2024 for foreigners in your country.\n\nAre there jobs that I can work home office from my country? Would I need to realocate? I'm wondering about this mostly for the US, Canada or Europe. How hard would that be? \n\nI'm brazilian, if that helps.", "author_fullname": "t2_5f8z1ygw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Market for Foreigners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq0u4f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707849432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data scientist transitioning into data engineering. I was wondering how is the job market in 2024 for foreigners in your country.&lt;/p&gt;\n\n&lt;p&gt;Are there jobs that I can work home office from my country? Would I need to realocate? I&amp;#39;m wondering about this mostly for the US, Canada or Europe. How hard would that be? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m brazilian, if that helps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aq0u4f", "is_robot_indexable": true, "report_reasons": null, "author": "luishacm", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/", "subreddit_subscribers": 160579, "created_utc": 1707849432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In deciding whether I want to use a star schema for a portfolio project- I see that one of my dim tables will have a one-to-one relationship with the fact table.\n\nAm I right in thinking there isn't any point to this? and it would be better as OBT?\n\nfor context, this is NLP data extracted from YouTube video comment sections. The \"entity\\_id\" PK in topic\\_entities would have a 1:1 with video\\_topic\\_facts. However, video\\_id PK would have a regular many-to-one relationship to video\\_entities. \n\nFacts:\n\n* video\\_topic\\_facts\n   *   entity\\_count\n   *   entity\\_id\n   *   video\\_id\n\nDimensions:\n\n* topic\\_entities\n   * entity\\_text\n   * entity\\_type\n   * entity\\_id\n* video\\_entities\n   * video\\_title\n   * video\\_id\n\n&amp;#x200B;\n\n ", "author_fullname": "t2_8chdw7c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "one-to-one relationships in star schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq01f4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In deciding whether I want to use a star schema for a portfolio project- I see that one of my dim tables will have a one-to-one relationship with the fact table.&lt;/p&gt;\n\n&lt;p&gt;Am I right in thinking there isn&amp;#39;t any point to this? and it would be better as OBT?&lt;/p&gt;\n\n&lt;p&gt;for context, this is NLP data extracted from YouTube video comment sections. The &amp;quot;entity_id&amp;quot; PK in topic_entities would have a 1:1 with video_topic_facts. However, video_id PK would have a regular many-to-one relationship to video_entities. &lt;/p&gt;\n\n&lt;p&gt;Facts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;video_topic_facts\n\n&lt;ul&gt;\n&lt;li&gt;  entity_count&lt;/li&gt;\n&lt;li&gt;  entity_id&lt;/li&gt;\n&lt;li&gt;  video_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Dimensions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;topic_entities\n\n&lt;ul&gt;\n&lt;li&gt;entity_text&lt;/li&gt;\n&lt;li&gt;entity_type&lt;/li&gt;\n&lt;li&gt;entity_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;video_entities\n\n&lt;ul&gt;\n&lt;li&gt;video_title&lt;/li&gt;\n&lt;li&gt;video_id&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq01f4", "is_robot_indexable": true, "report_reasons": null, "author": "pdxtechnologist", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/", "subreddit_subscribers": 160579, "created_utc": 1707847529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nSo I have been working with tools like SSAS to create tabular models destined for analytics. But never got the chance to use datamarts and looking it up on the internet I still do not understand the difference between the two.\n\nAre datamarts an aggregated view/table that contains all necessary data for a specific requirement like Business Unit?", "author_fullname": "t2_c5ezp8a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the difference between a data mart and a regular data model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq00v5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707847492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;So I have been working with tools like SSAS to create tabular models destined for analytics. But never got the chance to use datamarts and looking it up on the internet I still do not understand the difference between the two.&lt;/p&gt;\n\n&lt;p&gt;Are datamarts an aggregated view/table that contains all necessary data for a specific requirement like Business Unit?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq00v5", "is_robot_indexable": true, "report_reasons": null, "author": "TaleLegal9085", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/", "subreddit_subscribers": 160579, "created_utc": 1707847492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in an organization that has built custom tooling, but there are many issues, and I'm looking into alternatives. I'm particularly concerned with orchestration, ELT tooling, and schema management. I've got my eyes on dagster + dbt right now, but I'm not sure they'll work for my purposes just yet.\n\nSome architecture that cannot change:\n\n* There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same\n* Due to the above, there must be a DAG instance per customer, for each DAG specification\n* Something is needed to manage schema updates and create new databases with up-to-date schemas\n\nI imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven't been able to easily discern this from documentation.\n\nI don't fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I'd only work with abstractions, or if I'd be working with underlying tables. I'm not really looking for an ORM. I'm looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.\n\nAny recommendations are appreciated! I'm just looking very high level right now.", "author_fullname": "t2_89dmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking recommendation for tools that will work for a specific architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq8qdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707868806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in an organization that has built custom tooling, but there are many issues, and I&amp;#39;m looking into alternatives. I&amp;#39;m particularly concerned with orchestration, ELT tooling, and schema management. I&amp;#39;ve got my eyes on dagster + dbt right now, but I&amp;#39;m not sure they&amp;#39;ll work for my purposes just yet.&lt;/p&gt;\n\n&lt;p&gt;Some architecture that cannot change:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same&lt;/li&gt;\n&lt;li&gt;Due to the above, there must be a DAG instance per customer, for each DAG specification&lt;/li&gt;\n&lt;li&gt;Something is needed to manage schema updates and create new databases with up-to-date schemas&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven&amp;#39;t been able to easily discern this from documentation.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I&amp;#39;d only work with abstractions, or if I&amp;#39;d be working with underlying tables. I&amp;#39;m not really looking for an ORM. I&amp;#39;m looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations are appreciated! I&amp;#39;m just looking very high level right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq8qdc", "is_robot_indexable": true, "report_reasons": null, "author": "endotronic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "subreddit_subscribers": 160579, "created_utc": 1707868806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all.  Question about DBT testing.  \n\n1. is there a DBT sub that I cant find?\n\nWe have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR's proposed changes to that model.\n\n    SELECT \n        CASE \n            WHEN (SELECT COUNT(*) AS ROW_CNT\n                    FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n                = (SELECT COUNT(*) AS ROW_CNT\n                    FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            THEN 'Success!'\n            ELSE 'PR changed row count'\n        END AS STATUS\n\nI was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn't want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:\n\n    MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n    DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n\nSure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn't have a row count change.  \n\nIt also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR's are supposed to change the model's row count, so we wouldn't run this test on every model, and we would just skip it for those.\n\nBut also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_b12wxz418", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT generic schema tests questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6kpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707863377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.  Question about DBT testing.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;is there a DBT sub that I cant find?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR&amp;#39;s proposed changes to that model.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT \n    CASE \n        WHEN (SELECT COUNT(*) AS ROW_CNT\n                FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            = (SELECT COUNT(*) AS ROW_CNT\n                FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n        THEN &amp;#39;Success!&amp;#39;\n        ELSE &amp;#39;PR changed row count&amp;#39;\n    END AS STATUS\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn&amp;#39;t want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\nDBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Sure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn&amp;#39;t have a row count change.  &lt;/p&gt;\n\n&lt;p&gt;It also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR&amp;#39;s are supposed to change the model&amp;#39;s row count, so we wouldn&amp;#39;t run this test on every model, and we would just skip it for those.&lt;/p&gt;\n\n&lt;p&gt;But also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq6kpm", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Goose82", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "subreddit_subscribers": 160579, "created_utc": 1707863377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nDo you know other teams building in public like the Gitlab team [https://gitlab.com/gitlab-data](https://gitlab.com/gitlab-data) ?\n\nI would like to get inspiration from their setup , I believe you can learn alot like that.\n\nThanks!", "author_fullname": "t2_ce0xxymx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data teams building in public repositories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apxt0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707842230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Do you know other teams building in public like the Gitlab team &lt;a href=\"https://gitlab.com/gitlab-data\"&gt;https://gitlab.com/gitlab-data&lt;/a&gt; ?&lt;/p&gt;\n\n&lt;p&gt;I would like to get inspiration from their setup , I believe you can learn alot like that.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?auto=webp&amp;s=2e94811ad974ef30758f1bfa1f573d0b8650b047", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38575afd6c6a3e5a0dcad7df2a63932f81adef3e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d40ddb743ced8470d911c7619186583ebb7cdc9a", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/nT3AFKKlLjNPN3j8UG9x0TYDZXOpknqvMr1xpF2uco4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ed80f7c027a149b59802da37fcb5c5d42fc12bb", "width": 320, "height": 320}], "variants": {}, "id": "Vk4X7KEHj7HIY3r031F0NmctkfFvGIw2zTvw0AtlGsg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apxt0o", "is_robot_indexable": true, "report_reasons": null, "author": "Wingsofpeace7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/", "subreddit_subscribers": 160579, "created_utc": 1707842230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teradata Vantage\u2122 destination now available on Airbyte Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1aptdwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Tiaut8WJbOq0L9bIRsUvKLmUIgUwE5YMJ2pEAaTH67w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707830668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/teradata/teradata-vantage-destination-now-available-on-airbyte-cloud-1eed7479e40e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?auto=webp&amp;s=e37a3e71b3f616b02118c07965c9b695c050e93b", "width": 720, "height": 378}, "resolutions": [{"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=524c6a562eaad5416a45bf286d89a1e0671c3199", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0871e1fcf68766d31dd58ea35a5a389781235418", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d9afa6e8c273da550a3984c885aa0e40100a65a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ddeaf70e6d816093cd513cb169dd1a6402ba919a", "width": 640, "height": 336}], "variants": {}, "id": "lVlFbUvlw0Jq-P3OEBBT3MD3fBTZ0fn8x73rPOj2HnU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aptdwv", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aptdwv/teradata_vantage_destination_now_available_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/teradata/teradata-vantage-destination-now-available-on-airbyte-cloud-1eed7479e40e", "subreddit_subscribers": 160579, "created_utc": 1707830668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Current company is starting to reach a point of data-usage maturity where one-way reporting is not enough. Although a buzzword, the case for needing \u201cdata products\u201d is becoming relevant.\n\nOne such example is time-to-event analysis, where relevant stakeholders would like to be able to provide parameter inputs, which in turn will act as e.g., cohort definitions for analysis.\n\nIn contrast to current reporting, this usage pattern requires new tooling and processes. Current setup has Power BI and Databricks available - does anyone here have experience with using this mix as a frontend / backend setup through which Power BI parameters are passed to Databricks, and analysis results are returned dynamically? Is something like this possible?", "author_fullname": "t2_7569qa0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Power BI as frontend and Databricks as compute engine for data products", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aps1ts", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707826507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Current company is starting to reach a point of data-usage maturity where one-way reporting is not enough. Although a buzzword, the case for needing \u201cdata products\u201d is becoming relevant.&lt;/p&gt;\n\n&lt;p&gt;One such example is time-to-event analysis, where relevant stakeholders would like to be able to provide parameter inputs, which in turn will act as e.g., cohort definitions for analysis.&lt;/p&gt;\n\n&lt;p&gt;In contrast to current reporting, this usage pattern requires new tooling and processes. Current setup has Power BI and Databricks available - does anyone here have experience with using this mix as a frontend / backend setup through which Power BI parameters are passed to Databricks, and analysis results are returned dynamically? Is something like this possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aps1ts", "is_robot_indexable": true, "report_reasons": null, "author": "No_Lawfulness_6252", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aps1ts/using_power_bi_as_frontend_and_databricks_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aps1ts/using_power_bi_as_frontend_and_databricks_as/", "subreddit_subscribers": 160579, "created_utc": 1707826507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're considering transitioning to Kafka, specifically using the MSK managed service, from our current setup that involves ingesting data into an SQS FIFO queue. Our processing strategy relies on splitting the workload per message group ID, and we have around 20,000 different message group IDs in use.  \nI understand that mirroring this logic directly in Kafka by creating a partition for each message group ID might not align with best practices, especially since the volume of messages we're dealing with isn't extraordinarily high. However, adopting this approach could facilitate a smoother transition for our team.  \nCould anyone share insights on the practical upper limit for partitions in a Kafka (MSK managed) environment? Are there any significant downsides or performance implications we should be aware of when managing such a large number of partitions, particularly when the message volume doesn't necessarily justify it? Additionally, if anyone has navigated a similar transition or has alternative suggestions for handling this use case in Kafka, your advice would be greatly appreciated.", "author_fullname": "t2_4gvnzc5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Partitioning Limit in Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1appi2g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707816417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re considering transitioning to Kafka, specifically using the MSK managed service, from our current setup that involves ingesting data into an SQS FIFO queue. Our processing strategy relies on splitting the workload per message group ID, and we have around 20,000 different message group IDs in use.&lt;br/&gt;\nI understand that mirroring this logic directly in Kafka by creating a partition for each message group ID might not align with best practices, especially since the volume of messages we&amp;#39;re dealing with isn&amp;#39;t extraordinarily high. However, adopting this approach could facilitate a smoother transition for our team.&lt;br/&gt;\nCould anyone share insights on the practical upper limit for partitions in a Kafka (MSK managed) environment? Are there any significant downsides or performance implications we should be aware of when managing such a large number of partitions, particularly when the message volume doesn&amp;#39;t necessarily justify it? Additionally, if anyone has navigated a similar transition or has alternative suggestions for handling this use case in Kafka, your advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1appi2g", "is_robot_indexable": true, "report_reasons": null, "author": "Plus-Author9252", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1appi2g/partitioning_limit_in_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1appi2g/partitioning_limit_in_kafka/", "subreddit_subscribers": 160579, "created_utc": 1707816417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have not come across any resources which describe how to integrate Soda core with Delta lake. Does anyone have experience with this implementation? thanks!", "author_fullname": "t2_4wgaqe7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soda core for Delta lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqfd8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707888601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have not come across any resources which describe how to integrate Soda core with Delta lake. Does anyone have experience with this implementation? thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqfd8q", "is_robot_indexable": true, "report_reasons": null, "author": "Islamic_justice", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/", "subreddit_subscribers": 160579, "created_utc": 1707888601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All,\n\nI am trying to make a data flow task in SSIS where I insert data from an OLE DB Source to an OLE DB Destination (i.e. two different SQL Server instances on different VMs). I was able to get the OLE DB Source connection to work. The OLE DB Source is a SQL Server instance on a personal VM that I use for staging and data conversion.\n\nHowever, when I try to establish the OLE DB Destination I keep getting an error because the destination SQL Server is on a different VM/data server. No matter which provider, server name, or credentials I use I cannot get it to work. \n\nCan anyone please point me the in the right direction?\n\n[here are the providers that I see available.](https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;format=pjpg&amp;auto=webp&amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5)\n\nI usually use \"Microsoft OLE DB Provider for SQL Server\" for the source so I thought I could do the same with the destination, but I'm not sure which authentication I should be using?\n\n&amp;#x200B;\n\n[I've tried every combination of options here and I still get an error.](https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;format=pjpg&amp;auto=webp&amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72)\n\n&amp;#x200B;\n\nHere is the error I get when I try, for example, the sa account:\n\nhttps://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;format=pjpg&amp;auto=webp&amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6", "author_fullname": "t2_pz85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to establish an OLE DB Destination in SSIS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jgxp480s6dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ea4845ec5a30e8e4260764982dba818b95f3c67"}, {"y": 187, "x": 216, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=14989d0ec79924357426b04d3f42ca2e011f86f5"}, {"y": 277, "x": 320, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c4f027cc52e6156b0ec4a61478f0ab5e893b20d"}, {"y": 555, "x": 640, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b0ef8ce4f5d3950f6bf820a4f36a7b45725f67"}], "s": {"y": 615, "x": 709, "u": "https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;format=pjpg&amp;auto=webp&amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72"}, "id": "jgxp480s6dic1"}, "0kh68hhi6dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 94, "x": 108, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f931891bef72e68dc315f12ae871955ae79acfe"}, {"y": 188, "x": 216, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4ed82d0e98bbf6b44bfa03cfeb446d4e69bd12f"}, {"y": 278, "x": 320, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e965273c6cab16e03206ddaa015db652288e272"}, {"y": 557, "x": 640, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a6e79e60be8183e9e1077b1feb6cdaf6a69fd39a"}], "s": {"y": 617, "x": 708, "u": "https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;format=pjpg&amp;auto=webp&amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5"}, "id": "0kh68hhi6dic1"}, "fvhn6k947dic1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=727ed637847b1b59ead0d259c73fe74fc06d8d84"}, {"y": 186, "x": 216, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=71eaa0a28177d5f3f46145f49f8c34cb8b642546"}, {"y": 275, "x": 320, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f093e3f9905a98f74c0784b0b7c4b78e058f8e4"}, {"y": 551, "x": 640, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a48e2f4f5c636d6a0416f35e43ba7049bd10a192"}], "s": {"y": 615, "x": 714, "u": "https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;format=pjpg&amp;auto=webp&amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6"}, "id": "fvhn6k947dic1"}}, "name": "t3_1apv2d7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707835372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All,&lt;/p&gt;\n\n&lt;p&gt;I am trying to make a data flow task in SSIS where I insert data from an OLE DB Source to an OLE DB Destination (i.e. two different SQL Server instances on different VMs). I was able to get the OLE DB Source connection to work. The OLE DB Source is a SQL Server instance on a personal VM that I use for staging and data conversion.&lt;/p&gt;\n\n&lt;p&gt;However, when I try to establish the OLE DB Destination I keep getting an error because the destination SQL Server is on a different VM/data server. No matter which provider, server name, or credentials I use I cannot get it to work. &lt;/p&gt;\n\n&lt;p&gt;Can anyone please point me the in the right direction?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0kh68hhi6dic1.jpg?width=708&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d33aef48dd0a786878bb1b6b4ceedee281631ab5\"&gt;here are the providers that I see available.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I usually use &amp;quot;Microsoft OLE DB Provider for SQL Server&amp;quot; for the source so I thought I could do the same with the destination, but I&amp;#39;m not sure which authentication I should be using?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jgxp480s6dic1.jpg?width=709&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=99985f5dfc9b114ed72d8f82f50d5f46dc3ddd72\"&gt;I&amp;#39;ve tried every combination of options here and I still get an error.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is the error I get when I try, for example, the sa account:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6\"&gt;https://preview.redd.it/fvhn6k947dic1.jpg?width=714&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=fe0bb5035c02f6210cf735c2be9ad1a2ac7800f6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apv2d7", "is_robot_indexable": true, "report_reasons": null, "author": "imperialka", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apv2d7/how_to_establish_an_ole_db_destination_in_ssis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apv2d7/how_to_establish_an_ole_db_destination_in_ssis/", "subreddit_subscribers": 160579, "created_utc": 1707835372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm currently working on a time-series classification project, comparing the performance of 30 odd algorithms. The dataset I'm working with is relatively large (\\~5Gb, \\~10000 .csv files) and as such I'm running up against the limits of my local machine; the slowest algorithm took just over 6hrs to process the entire dataset. I want to setup a remote and distributed pipeline to speed this process up, but I have very little experience with cloud computing, and honestly have no idea where to start.\n\nI'm thinking either a ECS (all the algorithms are Docker images) + EFS cluster, or setting up a HPC with SLURM will be good solutions - but I want to consult Reddit before going down the rabbithole. Thanks!", "author_fullname": "t2_cjrqj2bzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed time-series processing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aposzs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707813349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on a time-series classification project, comparing the performance of 30 odd algorithms. The dataset I&amp;#39;m working with is relatively large (~5Gb, ~10000 .csv files) and as such I&amp;#39;m running up against the limits of my local machine; the slowest algorithm took just over 6hrs to process the entire dataset. I want to setup a remote and distributed pipeline to speed this process up, but I have very little experience with cloud computing, and honestly have no idea where to start.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking either a ECS (all the algorithms are Docker images) + EFS cluster, or setting up a HPC with SLURM will be good solutions - but I want to consult Reddit before going down the rabbithole. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aposzs", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Pipe9828", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aposzs/distributed_timeseries_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aposzs/distributed_timeseries_processing/", "subreddit_subscribers": 160579, "created_utc": 1707813349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my understanding, structuring unstructured data is a necessary activity in our life. For example, if you want to have a financial report of what you buy this month, you first need to write down your transaction, like `fish 50k`. This is raw, unstructured data. Then at the end of the month you need to label/annotate/classify the data like this:\n\n* Object: `fish`\n* Type of Object: `food`\n* Place of transaction: `market`\n* Type of place of transaction: `offline`\n* Consumer: `myself`\n* Type of consumer: `myself`\n* Price: `50000 VND`\n\nAnd that's just one piece of input data. Imagine how large the data that specialized companies or projects (medical, law, finance, etc.) need to handle. In my understanding, their options are:\n\n* Have the staffs to do that manually, or\n* Have a dedicated data entry clerk role, or\n* Outsource that to a data entry company, or\n* Outsource that to a data entry freelancer, or\n* Outsource the automation task to a freelance programmer, or\n* Buy similar solutions from big data or information system companies\n\nNow, I wrote an app to automate this process. Technically ChatGPT can also do this, but its approach is statistical-based, while this app's approach is rule-based. If the raw data is just keywords, then this app is much faster, cheaper and more accurate than ChatGPT.\n\nAnyhow, with this app I guess I can work on multiple data entry jobs at once. So my options are either as a data entry freelancer or an employee of an outsourcing data entry company.\n\nIt will be easy as long as the clients only care about the final result. However, I have no insight on outsourcing data entry companies. From what I got, it's likely that they have a dedicated system to manage all data entry tasks. I guess I can only get benefit if:\n\n* They haven't implemented automatic classification system, \n* Raw data from the system can be copy-pasted to outside \n* Resulted data from outside of the system can be copy-pasted into it\n* The task they give me is only about classify/annotate text raw data\n* I can work online. (Or if I must work offline, then at least there is no overseer observes me, which I guess it's not possible.) \n\nI've tried to apply to them to gain more insight but haven't got any success. I'm still in my way to look for such company.\n\nIn general, do you know how large the market of text data entry keyword detection and classification/annotation currently is? And how do data entry outsourcing companies work?", "author_fullname": "t2_gm9rt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How large is the market of text data entry classification/annotation? And how do data entry outsourcing companies work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqft3w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707890150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my understanding, structuring unstructured data is a necessary activity in our life. For example, if you want to have a financial report of what you buy this month, you first need to write down your transaction, like &lt;code&gt;fish 50k&lt;/code&gt;. This is raw, unstructured data. Then at the end of the month you need to label/annotate/classify the data like this:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Object: &lt;code&gt;fish&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Type of Object: &lt;code&gt;food&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Place of transaction: &lt;code&gt;market&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Type of place of transaction: &lt;code&gt;offline&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Consumer: &lt;code&gt;myself&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Type of consumer: &lt;code&gt;myself&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Price: &lt;code&gt;50000 VND&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And that&amp;#39;s just one piece of input data. Imagine how large the data that specialized companies or projects (medical, law, finance, etc.) need to handle. In my understanding, their options are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Have the staffs to do that manually, or&lt;/li&gt;\n&lt;li&gt;Have a dedicated data entry clerk role, or&lt;/li&gt;\n&lt;li&gt;Outsource that to a data entry company, or&lt;/li&gt;\n&lt;li&gt;Outsource that to a data entry freelancer, or&lt;/li&gt;\n&lt;li&gt;Outsource the automation task to a freelance programmer, or&lt;/li&gt;\n&lt;li&gt;Buy similar solutions from big data or information system companies&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now, I wrote an app to automate this process. Technically ChatGPT can also do this, but its approach is statistical-based, while this app&amp;#39;s approach is rule-based. If the raw data is just keywords, then this app is much faster, cheaper and more accurate than ChatGPT.&lt;/p&gt;\n\n&lt;p&gt;Anyhow, with this app I guess I can work on multiple data entry jobs at once. So my options are either as a data entry freelancer or an employee of an outsourcing data entry company.&lt;/p&gt;\n\n&lt;p&gt;It will be easy as long as the clients only care about the final result. However, I have no insight on outsourcing data entry companies. From what I got, it&amp;#39;s likely that they have a dedicated system to manage all data entry tasks. I guess I can only get benefit if:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;They haven&amp;#39;t implemented automatic classification system, &lt;/li&gt;\n&lt;li&gt;Raw data from the system can be copy-pasted to outside &lt;/li&gt;\n&lt;li&gt;Resulted data from outside of the system can be copy-pasted into it&lt;/li&gt;\n&lt;li&gt;The task they give me is only about classify/annotate text raw data&lt;/li&gt;\n&lt;li&gt;I can work online. (Or if I must work offline, then at least there is no overseer observes me, which I guess it&amp;#39;s not possible.) &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve tried to apply to them to gain more insight but haven&amp;#39;t got any success. I&amp;#39;m still in my way to look for such company.&lt;/p&gt;\n\n&lt;p&gt;In general, do you know how large the market of text data entry keyword detection and classification/annotation currently is? And how do data entry outsourcing companies work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqft3w", "is_robot_indexable": true, "report_reasons": null, "author": "Ooker777", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqft3w/how_large_is_the_market_of_text_data_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqft3w/how_large_is_the_market_of_text_data_entry/", "subreddit_subscribers": 160579, "created_utc": 1707890150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are seeing very weird issue with our environment \n\nSo we run multiple notebooks in parallel on same compute\n\nLets say there are 2 notebooks running\nDimCustomer &amp; DimOrder\n\nBoth have variable names var_x and in first notebook we assign value DimCustomer to var_x and in second notebook we assign DimOrder to var_x\n\nBoth has data stored in dataframe variable called df\n\nWe are writing this df as table in databricks catalogue\n\nIntermittently we see that DimCustomer has data of DimOrder\n\nRe-running process alone will fix the issue, but should this even happen in first place?", "author_fullname": "t2_50u0h0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataframe overwritten using data from another notebook - Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqee7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707885360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are seeing very weird issue with our environment &lt;/p&gt;\n\n&lt;p&gt;So we run multiple notebooks in parallel on same compute&lt;/p&gt;\n\n&lt;p&gt;Lets say there are 2 notebooks running\nDimCustomer &amp;amp; DimOrder&lt;/p&gt;\n\n&lt;p&gt;Both have variable names var_x and in first notebook we assign value DimCustomer to var_x and in second notebook we assign DimOrder to var_x&lt;/p&gt;\n\n&lt;p&gt;Both has data stored in dataframe variable called df&lt;/p&gt;\n\n&lt;p&gt;We are writing this df as table in databricks catalogue&lt;/p&gt;\n\n&lt;p&gt;Intermittently we see that DimCustomer has data of DimOrder&lt;/p&gt;\n\n&lt;p&gt;Re-running process alone will fix the issue, but should this even happen in first place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqee7l", "is_robot_indexable": true, "report_reasons": null, "author": "dilkushpatel", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/", "subreddit_subscribers": 160579, "created_utc": 1707885360.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}