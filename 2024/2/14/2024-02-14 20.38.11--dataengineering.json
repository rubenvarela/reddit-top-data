{"kind": "Listing", "data": {"after": "t3_1aqm2qq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m writing this post after, admittedly, never having used a \u201cdata lake\u201d (I think) but have thought I knew what it was\u2026 on a few different occasions.\n\nI know it\u2019s a place to store data, but what data structure does it use? Presumably, it is a directory structure and storage is nonmutable\u2026 block storage, like S3. is that it?\n\nThen there\u2019s MongoDB Atlas which says it\u2019s a Data Lake and I\u2019m like wtf\u2026 I\u2019ve used Mongo before to record some JSON documents without a schema, but that\u2019s not what I know a Data Lake to be. Unless \u201cAtlas\u201d is something else\u2026\n\nSo now I\u2019m wondering, is a Data Lake less about the underlying structure and properties, and more about what goes in (raw data) and what derived data comes out (effectively ELT). Is this general idea, being used at large scale, what constitutes a \u201cData Lake?\u201d\n\nHelp me out here guy please.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What the Hell is a Data Lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqq9vc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707926350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m writing this post after, admittedly, never having used a \u201cdata lake\u201d (I think) but have thought I knew what it was\u2026 on a few different occasions.&lt;/p&gt;\n\n&lt;p&gt;I know it\u2019s a place to store data, but what data structure does it use? Presumably, it is a directory structure and storage is nonmutable\u2026 block storage, like S3. is that it?&lt;/p&gt;\n\n&lt;p&gt;Then there\u2019s MongoDB Atlas which says it\u2019s a Data Lake and I\u2019m like wtf\u2026 I\u2019ve used Mongo before to record some JSON documents without a schema, but that\u2019s not what I know a Data Lake to be. Unless \u201cAtlas\u201d is something else\u2026&lt;/p&gt;\n\n&lt;p&gt;So now I\u2019m wondering, is a Data Lake less about the underlying structure and properties, and more about what goes in (raw data) and what derived data comes out (effectively ELT). Is this general idea, being used at large scale, what constitutes a \u201cData Lake?\u201d&lt;/p&gt;\n\n&lt;p&gt;Help me out here guy please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqq9vc", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqq9vc/what_the_hell_is_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqq9vc/what_the_hell_is_a_data_lake/", "subreddit_subscribers": 160719, "created_utc": 1707926350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DBT announced a preview of a much requested feature - Column Level Lineage. \n\nThe only catch is you have to be a Cloud customer. \nDoes anyone know anymore about this and if it is coming to core?", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Column Level Lineage only for DBT Cloud customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqcvov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/z0lsxARMTCcEEhwTC0HsMFN-HuXPgaFLzzHTjhKPrd4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707880629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DBT announced a preview of a much requested feature - Column Level Lineage. &lt;/p&gt;\n\n&lt;p&gt;The only catch is you have to be a Cloud customer. \nDoes anyone know anymore about this and if it is coming to core?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?auto=webp&amp;s=cafd219029f0a3fbdad0ea8a2bcb66b3d78fde14", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b5c9815894c457c0876c8aa0738f085af8f7af8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1dd3758c396fe36d709ad00886acb150a1d9067d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94fcab0f230d58e3de92c5d7c2a2785144251838", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5a80590e63ba05ee3f1af94bd9e60ae2df5308a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=815507f574255f6785c16ea52b6bab5afc4d00bc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ONcH6yHvqa1gW-fzPXL7xYaMf8PQgZRoh3dtpHV4YCY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de48a264c01939fe48a8bdfeb28423431ccc3644", "width": 1080, "height": 567}], "variants": {}, "id": "DrZJUagpOb_HgXmGsRTaz04SkfN1EZhQLY4JvbX2Wb0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqcvov", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqcvov/dbt_column_level_lineage_only_for_dbt_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/", "subreddit_subscribers": 160719, "created_utc": 1707880629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you tried the following\n\nDremio\nTrino\nPresto\n\nIf you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? \n\nReally interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you tried these tools? If not, why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6dbj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707862868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried the following&lt;/p&gt;\n\n&lt;p&gt;Dremio\nTrino\nPresto&lt;/p&gt;\n\n&lt;p&gt;If you haven\u2019t tried one or more of these, was there a particular reason you didn\u2019t? &lt;/p&gt;\n\n&lt;p&gt;Really interested in what makes \u201ctrying something out\u201d more accessible and desirable for people.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq6dbj", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/", "subreddit_subscribers": 160719, "created_utc": 1707862868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6smf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My company just let me open source our orchestration tool 'Houston', an API based alternative to Airflow/Google Cloud Composer that we've been using internally for the last 4 years! It's great for low-cost, high-speed data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqmnx0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TvbgM6XU5pRyFVegumxyMoPZh1883NVwept3GPI1g3k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707916658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/datasparq-ai/houston", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?auto=webp&amp;s=17c406bb32ad5a30266b69dcafb176b148c7fceb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7cc92a3c283476dfb4ca5ec88b8c435c585f714", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7dbbe0719b6f282a0b4461814d45feece159c29", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=17d6dba66cf3894f446dbc9a27436cce9044e537", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5dbd07c99f928596baeb8c555a795120709030c9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7bcef0cc1f4098d67802083b47f3c830ae462678", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_rkYxHr3LH5dX_LmuWHD_y8P-NLzcS0WePA83xvmAdc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d61dfa599bfd7d04c0ca769ffa605657ad949911", "width": 1080, "height": 540}], "variants": {}, "id": "P67HJGdlWqP7-f47wdx-g-YFOqw7poBol8WKVocacEQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1aqmnx0", "is_robot_indexable": true, "report_reasons": null, "author": "flo0d", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqmnx0/my_company_just_let_me_open_source_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/datasparq-ai/houston", "subreddit_subscribers": 160719, "created_utc": 1707916658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " To process the 100 Gb of a file what is the bare minimum resources requirement for the spark job?\nHow many partitions will it create?\nWhat will be number of executors, cores, executor size?", "author_fullname": "t2_ojn8xr0i2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqhsg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707897837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To process the 100 Gb of a file what is the bare minimum resources requirement for the spark job?\nHow many partitions will it create?\nWhat will be number of executors, cores, executor size?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1aqhsg8", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic-Bell5386", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqhsg8/interview_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqhsg8/interview_question/", "subreddit_subscribers": 160719, "created_utc": 1707897837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am at my 3rd company in my career that had executives release a mandate that \"we must move all of our infrastructure to the cloud\"... Because \"it has faster integration\"... And \"it will lower costs over *insert time horizon here*\"... \n\nThen followed by those executives bosses saying... \"You promised me value with the cloud ... Show me... Because these bills are outrageous\"...\n\nWhich is then followed by those executives (the ones who made the mandate and over promised to their superiors) laying people off because they realize they can't quickly unravel their cloud dreams (projects in flight and halfway or more to cloud already) but they can save money by laying people off... \n\nJust a sad state of affairs. Cloud is not for every situation and to sell top level executives on costs savings alone is basically setting all the IC's up for failure because those savings are never truly realized and should have never been used as a selling point. It's really just a shame ... When does it stop?", "author_fullname": "t2_90434l9q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When will \"we need to be on cloud\" statements stop with executive's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqsmoc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707932106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am at my 3rd company in my career that had executives release a mandate that &amp;quot;we must move all of our infrastructure to the cloud&amp;quot;... Because &amp;quot;it has faster integration&amp;quot;... And &amp;quot;it will lower costs over &lt;em&gt;insert time horizon here&lt;/em&gt;&amp;quot;... &lt;/p&gt;\n\n&lt;p&gt;Then followed by those executives bosses saying... &amp;quot;You promised me value with the cloud ... Show me... Because these bills are outrageous&amp;quot;...&lt;/p&gt;\n\n&lt;p&gt;Which is then followed by those executives (the ones who made the mandate and over promised to their superiors) laying people off because they realize they can&amp;#39;t quickly unravel their cloud dreams (projects in flight and halfway or more to cloud already) but they can save money by laying people off... &lt;/p&gt;\n\n&lt;p&gt;Just a sad state of affairs. Cloud is not for every situation and to sell top level executives on costs savings alone is basically setting all the IC&amp;#39;s up for failure because those savings are never truly realized and should have never been used as a selling point. It&amp;#39;s really just a shame ... When does it stop?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqsmoc", "is_robot_indexable": true, "report_reasons": null, "author": "Imaginary-Ad2828", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqsmoc/when_will_we_need_to_be_on_cloud_statements_stop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqsmoc/when_will_we_need_to_be_on_cloud_statements_stop/", "subreddit_subscribers": 160719, "created_utc": 1707932106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**I am checking into multiple catalogs and I am  curious.**   \n*Have any of you set one up? Which one did you choose and why?* \n\n*What was the actual need for the data catalog in the first place?*   \n\n\n**For those who are working with catalogs:**  \n*How is it going? Was there any big change in how you work with your data or with your team?*  \n*Did anyone had any big wins by implementing a catalog?*  \n\n\n  \nSorry for asking too much questions. Any insights on the topic is appreciated !  \n\n\nThanks. ", "author_fullname": "t2_o78u2p44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who's Using Data Catalogs? Need your insights !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq7xh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707866755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;I am checking into multiple catalogs and I am  curious.&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;Have any of you set one up? Which one did you choose and why?&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;What was the actual need for the data catalog in the first place?&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;For those who are working with catalogs:&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;How is it going? Was there any big change in how you work with your data or with your team?&lt;/em&gt;&lt;br/&gt;\n&lt;em&gt;Did anyone had any big wins by implementing a catalog?&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;Sorry for asking too much questions. Any insights on the topic is appreciated !  &lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aq7xh9", "is_robot_indexable": true, "report_reasons": null, "author": "SignificanceNo136", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/", "subreddit_subscribers": 160719, "created_utc": 1707866755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cb1if", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New DuckDB Array Type used for Vector databasing on top of Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 95, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqk7rs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/42h9thB8-GeclxIVqfxJQDkNwDSikQGRInIKhEWrsK0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707908193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luukvandervelden.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luukvandervelden.medium.com/vector-databasing-with-duckdb-on-top-of-pgvector-ec182f815a16?source=friends_link&amp;sk=041d8e614e2b4ada23af79205661e0d3", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?auto=webp&amp;s=878da16648a19e0a41a91ea1d43a9d22588c9b6e", "width": 1200, "height": 818}, "resolutions": [{"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25a16cb9c2b3fb03fa149eae5c0633f7ca0f4438", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=03c3c9a18844192231c7415e5c28ffc94cee8add", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14c7010de6e028feb9e101ed3321807ca7d15804", "width": 320, "height": 218}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02164756c7fb2a3f15838d538f406601d4582b71", "width": 640, "height": 436}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6227708b6bf2c031d7ea9342304b02984aa59a35", "width": 960, "height": 654}, {"url": "https://external-preview.redd.it/aXA8BcN2kz0yqWqVJohCKEMrh6TwJuzGQ4MpnJIpxYk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=393ef36f0a2613fff4c04d265e20df598d53768b", "width": 1080, "height": 736}], "variants": {}, "id": "GafSvdTOfJuSt6EJ5qOfvDVJZbZAQVpDEk6MBKtOShk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqk7rs", "is_robot_indexable": true, "report_reasons": null, "author": "squareape", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqk7rs/new_duckdb_array_type_used_for_vector_databasing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luukvandervelden.medium.com/vector-databasing-with-duckdb-on-top-of-pgvector-ec182f815a16?source=friends_link&amp;sk=041d8e614e2b4ada23af79205661e0d3", "subreddit_subscribers": 160719, "created_utc": 1707908193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI'm currently an apprentice data engineer and in my second year of a master's program in data and AI.\n\nI've been asked to choose a certification to pursue, but I have little to no practical experience in data engineering. I'm familiar with SQL, Python, and have a basic understanding of MongoDB, as well as concepts like ETL and data warehousing. I've been advised to pursue Azure certifications since it's the most widely used cloud provider.\n\nWhich certification would you recommend for someone in my position to gain solid knowledge in data engineering?\n\nThanks again \ud83d\ude04", "author_fullname": "t2_8aldnk2t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which certification should I get ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqjqpf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707906287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently an apprentice data engineer and in my second year of a master&amp;#39;s program in data and AI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked to choose a certification to pursue, but I have little to no practical experience in data engineering. I&amp;#39;m familiar with SQL, Python, and have a basic understanding of MongoDB, as well as concepts like ETL and data warehousing. I&amp;#39;ve been advised to pursue Azure certifications since it&amp;#39;s the most widely used cloud provider.&lt;/p&gt;\n\n&lt;p&gt;Which certification would you recommend for someone in my position to gain solid knowledge in data engineering?&lt;/p&gt;\n\n&lt;p&gt;Thanks again \ud83d\ude04&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aqjqpf", "is_robot_indexable": true, "report_reasons": null, "author": "tn_receptionist_1520", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqjqpf/which_certification_should_i_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqjqpf/which_certification_should_i_get/", "subreddit_subscribers": 160719, "created_utc": 1707906287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently working as a Data Analyst but want to become a Data Engineer in the future. As apart of my discussed promotion, I\u2019m working with our pipelining team more and doing more ETL work. \n\nIt\u2019s possible that I could negotiate a change in title from DA to DE with the promotion. \n\nWould this really benefit me long term?", "author_fullname": "t2_4gm2xwt2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does title matter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqogdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707921699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working as a Data Analyst but want to become a Data Engineer in the future. As apart of my discussed promotion, I\u2019m working with our pipelining team more and doing more ETL work. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s possible that I could negotiate a change in title from DA to DE with the promotion. &lt;/p&gt;\n\n&lt;p&gt;Would this really benefit me long term?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aqogdc", "is_robot_indexable": true, "report_reasons": null, "author": "bcw28511", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqogdc/how_much_does_title_matter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqogdc/how_much_does_title_matter/", "subreddit_subscribers": 160719, "created_utc": 1707921699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in an organization that has built custom tooling, but there are many issues, and I'm looking into alternatives. I'm particularly concerned with orchestration, ELT tooling, and schema management. I've got my eyes on dagster + dbt right now, but I'm not sure they'll work for my purposes just yet.\n\nSome architecture that cannot change:\n\n* There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same\n* Due to the above, there must be a DAG instance per customer, for each DAG specification\n* Something is needed to manage schema updates and create new databases with up-to-date schemas\n\nI imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven't been able to easily discern this from documentation.\n\nI don't fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I'd only work with abstractions, or if I'd be working with underlying tables. I'm not really looking for an ORM. I'm looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.\n\nAny recommendations are appreciated! I'm just looking very high level right now.", "author_fullname": "t2_89dmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking recommendation for tools that will work for a specific architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq8qdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707868806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in an organization that has built custom tooling, but there are many issues, and I&amp;#39;m looking into alternatives. I&amp;#39;m particularly concerned with orchestration, ELT tooling, and schema management. I&amp;#39;ve got my eyes on dagster + dbt right now, but I&amp;#39;m not sure they&amp;#39;ll work for my purposes just yet.&lt;/p&gt;\n\n&lt;p&gt;Some architecture that cannot change:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There is a database per customer, and in normal cases (not during upgrades/migrations), the schemas are all the same&lt;/li&gt;\n&lt;li&gt;Due to the above, there must be a DAG instance per customer, for each DAG specification&lt;/li&gt;\n&lt;li&gt;Something is needed to manage schema updates and create new databases with up-to-date schemas&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I imagine that dagster must have some way of managing multiple instances of a DAG from one DAG specification, but I haven&amp;#39;t been able to easily discern this from documentation.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t fully understand the intricacies of dbt yet, so it is not clear to me if it would manage schemas and I&amp;#39;d only work with abstractions, or if I&amp;#39;d be working with underlying tables. I&amp;#39;m not really looking for an ORM. I&amp;#39;m looking to dbt as a way to actually run the ELT jobs in production with some way of running tests in development and CI/CD.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations are appreciated! I&amp;#39;m just looking very high level right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq8qdc", "is_robot_indexable": true, "report_reasons": null, "author": "endotronic", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/", "subreddit_subscribers": 160719, "created_utc": 1707868806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are seeing very weird issue with our environment \n\nSo we run multiple notebooks in parallel on same compute\n\nLets say there are 2 notebooks running\nDimCustomer &amp; DimOrder\n\nBoth have variable names var_x and in first notebook we assign value DimCustomer to var_x and in second notebook we assign DimOrder to var_x\n\nBoth has data stored in dataframe variable called df\n\nWe are writing this df as table in databricks catalogue\n\nIntermittently we see that DimCustomer has data of DimOrder\n\nRe-running process alone will fix the issue, but should this even happen in first place?", "author_fullname": "t2_50u0h0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataframe overwritten using data from another notebook - Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqee7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707885360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are seeing very weird issue with our environment &lt;/p&gt;\n\n&lt;p&gt;So we run multiple notebooks in parallel on same compute&lt;/p&gt;\n\n&lt;p&gt;Lets say there are 2 notebooks running\nDimCustomer &amp;amp; DimOrder&lt;/p&gt;\n\n&lt;p&gt;Both have variable names var_x and in first notebook we assign value DimCustomer to var_x and in second notebook we assign DimOrder to var_x&lt;/p&gt;\n\n&lt;p&gt;Both has data stored in dataframe variable called df&lt;/p&gt;\n\n&lt;p&gt;We are writing this df as table in databricks catalogue&lt;/p&gt;\n\n&lt;p&gt;Intermittently we see that DimCustomer has data of DimOrder&lt;/p&gt;\n\n&lt;p&gt;Re-running process alone will fix the issue, but should this even happen in first place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqee7l", "is_robot_indexable": true, "report_reasons": null, "author": "dilkushpatel", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/", "subreddit_subscribers": 160719, "created_utc": 1707885360.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all.  Question about DBT testing.  \n\n1. is there a DBT sub that I cant find?\n\nWe have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR's proposed changes to that model.\n\n    SELECT \n        CASE \n            WHEN (SELECT COUNT(*) AS ROW_CNT\n                    FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n                = (SELECT COUNT(*) AS ROW_CNT\n                    FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            THEN 'Success!'\n            ELSE 'PR changed row count'\n        END AS STATUS\n\nI was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn't want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:\n\n    MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n    DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n\nSure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn't have a row count change.  \n\nIt also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR's are supposed to change the model's row count, so we wouldn't run this test on every model, and we would just skip it for those.\n\nBut also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_b12wxz418", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT generic schema tests questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aq6kpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707863377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.  Question about DBT testing.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;is there a DBT sub that I cant find?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We have decided that we are going to check every PR for a few basic tests before merging.  Great idea! One of the new tests that we plan on running is simply a row count from the existing model, to the PR&amp;#39;s proposed changes to that model.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT \n    CASE \n        WHEN (SELECT COUNT(*) AS ROW_CNT\n                FROM MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n            = (SELECT COUNT(*) AS ROW_CNT\n                FROM DBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD)\n        THEN &amp;#39;Success!&amp;#39;\n        ELSE &amp;#39;PR changed row count&amp;#39;\n    END AS STATUS\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I was hoping to basically automate this as a macro.  Then if the prod model has the same count as the dev model we are good, otherwise, review.  My thought is we wouldn&amp;#39;t want to run this test every time model is materialized, just right now, to see if the dev accidentally updated more than they intended to.  Instead of having this be sourced to {{ model }} my thought was what if I just hard coded my variables, in this case to be:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;MARTS_DB.REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\nDBT_DEV_DB.DBT_CLOUD_PR_29568_1766_REPORT_MANAGER_MIGRATION.NAV_AVALARAUPLOAD\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Sure as the approver you would still need to go in and switch out the model names, but that seems easier than setting this up in the source.yml file, and then removing it for every PR that shouldn&amp;#39;t have a row count change.  &lt;/p&gt;\n\n&lt;p&gt;It also seems easier than me manually typing this all out in Snowflake to compare the row counts.  And some PR&amp;#39;s are supposed to change the model&amp;#39;s row count, so we wouldn&amp;#39;t run this test on every model, and we would just skip it for those.&lt;/p&gt;\n\n&lt;p&gt;But also it seems like there must be a better way to do this?  I keep finding ways to compare table 1 row count to table 2, but not table 1 to the new dev version of itself.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aq6kpm", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Goose82", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/", "subreddit_subscribers": 160719, "created_utc": 1707863377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi all,\nhere's the scenario.  \n\nI've data in another company's MySQL DB. \nI don't have access to it, hence they've exported it into .SQL files.  These files have all the data as insert queries and create table statements.  \n\nNow the issue is, what I've is an SQL server  2016. Since these syntaxes won't support in SQL server. How can I load these data into SQL server tables? I don't have the option for an intermediate MySql db.\n\nOr in simple words, is there a way to convert this .SQL file data without access to a MySQL instance?", "author_fullname": "t2_5ks2jegk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting MySQL DB to SQL Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqkvme", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707918740.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707910686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi all,\nhere&amp;#39;s the scenario.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve data in another company&amp;#39;s MySQL DB. \nI don&amp;#39;t have access to it, hence they&amp;#39;ve exported it into .SQL files.  These files have all the data as insert queries and create table statements.  &lt;/p&gt;\n\n&lt;p&gt;Now the issue is, what I&amp;#39;ve is an SQL server  2016. Since these syntaxes won&amp;#39;t support in SQL server. How can I load these data into SQL server tables? I don&amp;#39;t have the option for an intermediate MySql db.&lt;/p&gt;\n\n&lt;p&gt;Or in simple words, is there a way to convert this .SQL file data without access to a MySQL instance?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqkvme", "is_robot_indexable": true, "report_reasons": null, "author": "das3012", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqkvme/converting_mysql_db_to_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqkvme/converting_mysql_db_to_sql_server/", "subreddit_subscribers": 160719, "created_utc": 1707910686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have not come across any resources which describe how to integrate Soda core with Delta lake. Does anyone have experience with this implementation? thanks!", "author_fullname": "t2_4wgaqe7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soda core for Delta lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqfd8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707888601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have not come across any resources which describe how to integrate Soda core with Delta lake. Does anyone have experience with this implementation? thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqfd8q", "is_robot_indexable": true, "report_reasons": null, "author": "Islamic_justice", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/", "subreddit_subscribers": 160719, "created_utc": 1707888601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those who use both dagster &amp; dbt:\n\n* How do you manage the scheduling of dbt models?\n   * e.g., jobs+schedules, freshness policies, or auto-materialization policies\n* Say you have a model that needs to be run monthly that depends on daily models for that month. How do you ensure all daily partitions have been run before monthly kicks off?\n\nAny other tips/tricks would be appreciated.", "author_fullname": "t2_7ch0sgxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster + dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aqvhcj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707938943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those who use both dagster &amp;amp; dbt:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do you manage the scheduling of dbt models?\n\n&lt;ul&gt;\n&lt;li&gt;e.g., jobs+schedules, freshness policies, or auto-materialization policies&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Say you have a model that needs to be run monthly that depends on daily models for that month. How do you ensure all daily partitions have been run before monthly kicks off?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any other tips/tricks would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqvhcj", "is_robot_indexable": true, "report_reasons": null, "author": "coreytrevorlahey69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqvhcj/dagster_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqvhcj/dagster_dbt/", "subreddit_subscribers": 160719, "created_utc": 1707938943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody.  \n\n\nI have the same repo, same rights as my colleagues. in my case dataform compiles then runs and create the tables.  \n\n\nIn my colleagues case it compiles then run but doesnt do anything.  \n\n\nAnyone had the same issue?", "author_fullname": "t2_m0fkuha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataform works in Mac but not Windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqmlce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707916426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody.  &lt;/p&gt;\n\n&lt;p&gt;I have the same repo, same rights as my colleagues. in my case dataform compiles then runs and create the tables.  &lt;/p&gt;\n\n&lt;p&gt;In my colleagues case it compiles then run but doesnt do anything.  &lt;/p&gt;\n\n&lt;p&gt;Anyone had the same issue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqmlce", "is_robot_indexable": true, "report_reasons": null, "author": "anfawave", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqmlce/dataform_works_in_mac_but_not_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqmlce/dataform_works_in_mac_but_not_windows/", "subreddit_subscribers": 160719, "created_utc": 1707916426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The company I am working for looking to roll out dashboards for their app. The idea would be to embed the dashboard in an existing web app. \n\nAs a proof of concept, I created a quick prototype using Power BI, but never tried using Tableau. I was wondering if someone had experience with doing the same with Tableau.   \n\n\nDoes this work with Tableau? How was the experience? Any problems I should be aware? ", "author_fullname": "t2_h58nyr96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embedding Tableau dashboards in a web app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqhrti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707897765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The company I am working for looking to roll out dashboards for their app. The idea would be to embed the dashboard in an existing web app. &lt;/p&gt;\n\n&lt;p&gt;As a proof of concept, I created a quick prototype using Power BI, but never tried using Tableau. I was wondering if someone had experience with doing the same with Tableau.   &lt;/p&gt;\n\n&lt;p&gt;Does this work with Tableau? How was the experience? Any problems I should be aware? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqhrti", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyFish7104", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqhrti/embedding_tableau_dashboards_in_a_web_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqhrti/embedding_tableau_dashboards_in_a_web_app/", "subreddit_subscribers": 160719, "created_utc": 1707897765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI recently completed the IBM Data Engineering Professional Certificate and don\u2019t know what to do now. I\u2019m currently reading \u201cFundamentals of Data Engineering\u201d to connect the dots of what I learned in the data engineering certificate. Any recommendations on what I should I do next?\n\nBackground about me: I\u2019m in tech sales and want to get more into the solution engineering or technical account manager route. \n\nThanks!", "author_fullname": "t2_59z2hc1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Completed IBM Data Engineering Professional Certificate. Now what?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqbftj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707876359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I recently completed the IBM Data Engineering Professional Certificate and don\u2019t know what to do now. I\u2019m currently reading \u201cFundamentals of Data Engineering\u201d to connect the dots of what I learned in the data engineering certificate. Any recommendations on what I should I do next?&lt;/p&gt;\n\n&lt;p&gt;Background about me: I\u2019m in tech sales and want to get more into the solution engineering or technical account manager route. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aqbftj", "is_robot_indexable": true, "report_reasons": null, "author": "Cheetohcrank", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqbftj/completed_ibm_data_engineering_professional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqbftj/completed_ibm_data_engineering_professional/", "subreddit_subscribers": 160719, "created_utc": 1707876359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning AWS and have some parquet files I would like to import into Redshift.  They are in an S3 bucket in the same region as my Redshift and Glue instances.\n\nThe structure is: YYYY/MM/DD/ELEMENT/x.parquet (examples: 2024/01/30/carOEM/875817ui23b.parquet and 2024/02/5/carModel/7647u21.parquet\n\nWhat would be the best method to importing all of these parquet files into their respective Redshift tables?\n\nI have tried something like multiple rules with '2024/\\*\\*/\\*\\*/carOEM/ and carModel/' but both resulted in constant failures when running, success was seen only when I was explicit, eg: 2024/02/5/carModel/\n\nThanks!", "author_fullname": "t2_4c8ud9yw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to import parquet files into multiple Redshift tables based on source directory name using AWS Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqavuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707876381.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707874766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning AWS and have some parquet files I would like to import into Redshift.  They are in an S3 bucket in the same region as my Redshift and Glue instances.&lt;/p&gt;\n\n&lt;p&gt;The structure is: YYYY/MM/DD/ELEMENT/x.parquet (examples: 2024/01/30/carOEM/875817ui23b.parquet and 2024/02/5/carModel/7647u21.parquet&lt;/p&gt;\n\n&lt;p&gt;What would be the best method to importing all of these parquet files into their respective Redshift tables?&lt;/p&gt;\n\n&lt;p&gt;I have tried something like multiple rules with &amp;#39;2024/**/**/carOEM/ and carModel/&amp;#39; but both resulted in constant failures when running, success was seen only when I was explicit, eg: 2024/02/5/carModel/&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aqavuu", "is_robot_indexable": true, "report_reasons": null, "author": "crampedTurtle", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqavuu/best_way_to_import_parquet_files_into_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqavuu/best_way_to_import_parquet_files_into_multiple/", "subreddit_subscribers": 160719, "created_utc": 1707874766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Today, we at PeerDB are releasing our ClickHouse target connector in Beta. This enables you to replicate data from Postgres to ClickHouse with low latency and high throughput! [https://blog.peerdb.io/postgres-to-clickhouse-real-time-replication-using-peerdb](https://blog.peerdb.io/postgres-to-clickhouse-real-time-replication-using-peerdb)\n\nClickHouse support was one of the first open [issues](https://github.com/PeerDB-io/peerdb/issues/254) in our Github repo. We are seeing a shift in companies using ClickHouse over Snowflake and BigQuery for their Data Warehousing needs, to reduce costs. Companies attempting to move data from their OLTP Postgres database to ClickHouse were increasingly running into issues, at scale. We architected our ClickHouse connector to use many native ClickHouse features to make it rock solid. ", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low Latency Replication from Postgres to ClickHouse Using PeerDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aqw9uc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707940892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today, we at PeerDB are releasing our ClickHouse target connector in Beta. This enables you to replicate data from Postgres to ClickHouse with low latency and high throughput! &lt;a href=\"https://blog.peerdb.io/postgres-to-clickhouse-real-time-replication-using-peerdb\"&gt;https://blog.peerdb.io/postgres-to-clickhouse-real-time-replication-using-peerdb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ClickHouse support was one of the first open &lt;a href=\"https://github.com/PeerDB-io/peerdb/issues/254\"&gt;issues&lt;/a&gt; in our Github repo. We are seeing a shift in companies using ClickHouse over Snowflake and BigQuery for their Data Warehousing needs, to reduce costs. Companies attempting to move data from their OLTP Postgres database to ClickHouse were increasingly running into issues, at scale. We architected our ClickHouse connector to use many native ClickHouse features to make it rock solid. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3JjwGp0R4yUB3od69RF6EvlbhoNfqhI9V8X_TlLB79o.jpg?auto=webp&amp;s=4f1d8488552e8ede236fddb57dd4fb446a614179", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/3JjwGp0R4yUB3od69RF6EvlbhoNfqhI9V8X_TlLB79o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1c83d67c916ab5767fcdb806c57301bbbd9eae66", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/3JjwGp0R4yUB3od69RF6EvlbhoNfqhI9V8X_TlLB79o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d1a5b03a7c096118afdb3d1551a31be1336a77c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/3JjwGp0R4yUB3od69RF6EvlbhoNfqhI9V8X_TlLB79o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eee46f47e32590bfb27a0e02c15dc9ec679e3ba9", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/3JjwGp0R4yUB3od69RF6EvlbhoNfqhI9V8X_TlLB79o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a0ec5d0c8ea8aadc68e116d20dce192fd49ff64c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/3JjwGp0R4yUB3od69RF6EvlbhoNfqhI9V8X_TlLB79o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9da57196fd41173cc41c73082c221ec70efb22de", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/3JjwGp0R4yUB3od69RF6EvlbhoNfqhI9V8X_TlLB79o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bc33a9479b063a572e2fc19db2676c4731f5877b", "width": 1080, "height": 567}], "variants": {}, "id": "zNch8E8_IGu3r0AMvslJJUaD3xxGGBBKxzurDUjJVCI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqw9uc", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqw9uc/low_latency_replication_from_postgres_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqw9uc/low_latency_replication_from_postgres_to/", "subreddit_subscribers": 160719, "created_utc": 1707940892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " A project I'm working on involves building a data platform that:\n\n1. Ingests data from an API + some csv files provided by users,\n2. Runs a lot of hardcore statistics on this data\n3. Creates outputs that need to be displayed in graphical format via a UI multiple users can go play with.\n\nActivated by a batch processing schedule or triggered based on an event the user initiates. We'll need strict controls on who sees what: dev vs business stakeholder vs senior leader. We'll also need a beta and prod environment so we can test algorithm updates end-to-end without disrupting the business users.\n\nAs far as tooling, I'm weighing these options:\n\nA) AWS for #1 and #2, then Tableau for #3\n\nB) Azure for #1 and #2 and PowerBI for #3\n\nC) Any other options you'd recommend\n\nIf you were me, which option would you be inclined to use and why? A discussion of pros &amp; cons would be appreciated.", "author_fullname": "t2_ve6u4qfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS + Tableau OR Azure + PowerBI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aqv023", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707937766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A project I&amp;#39;m working on involves building a data platform that:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ingests data from an API + some csv files provided by users,&lt;/li&gt;\n&lt;li&gt;Runs a lot of hardcore statistics on this data&lt;/li&gt;\n&lt;li&gt;Creates outputs that need to be displayed in graphical format via a UI multiple users can go play with.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Activated by a batch processing schedule or triggered based on an event the user initiates. We&amp;#39;ll need strict controls on who sees what: dev vs business stakeholder vs senior leader. We&amp;#39;ll also need a beta and prod environment so we can test algorithm updates end-to-end without disrupting the business users.&lt;/p&gt;\n\n&lt;p&gt;As far as tooling, I&amp;#39;m weighing these options:&lt;/p&gt;\n\n&lt;p&gt;A) AWS for #1 and #2, then Tableau for #3&lt;/p&gt;\n\n&lt;p&gt;B) Azure for #1 and #2 and PowerBI for #3&lt;/p&gt;\n\n&lt;p&gt;C) Any other options you&amp;#39;d recommend&lt;/p&gt;\n\n&lt;p&gt;If you were me, which option would you be inclined to use and why? A discussion of pros &amp;amp; cons would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqv023", "is_robot_indexable": true, "report_reasons": null, "author": "Aleebee2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqv023/aws_tableau_or_azure_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqv023/aws_tableau_or_azure_powerbi/", "subreddit_subscribers": 160719, "created_utc": 1707937766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your favorite BI tool, where do you usually serve the data from (data warehouse, database, data lake).\n\nWhat do you like best about it and what techniques do you use for accelerating BI (cubes, extracts, reflections).", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite BI Tool, and why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqq4x1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707925986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your favorite BI tool, where do you usually serve the data from (data warehouse, database, data lake).&lt;/p&gt;\n\n&lt;p&gt;What do you like best about it and what techniques do you use for accelerating BI (cubes, extracts, reflections).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqq4x1", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqq4x1/favorite_bi_tool_and_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqq4x1/favorite_bi_tool_and_why/", "subreddit_subscribers": 160719, "created_utc": 1707925986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our Team, which it is composed of 1 data engineer, 1 data analyst, 1 data scientist, and a manager is the responsible of about 20-25 data products, most of them dashboard, and a couple of small webapps. Most of our stakeholders are withing the company, which requiere data visualization and simple analysis for creating reports for their clients.\n\nAll of us are capable of writing code, not as robust as the data engineer that is also a programmer. We create the whole data pipeline including the ETL (or ELT) for the data products. A really hard effort is being made to maintain these data products updated, most are dependable of scraping, unofficial APIs, and reading published excels on online pages for data acquisition, this creates a problem into maintaining the data products updated. Most of us are focused on the development of the data pipeline, ETL processes and correcting any changes that are made to the sources for data acquisition. We also create, by requests, small dashboard that do not need to be updated after delivery.\n\n* Where does de responsibility of maintaining the data product updated lies?\n* Who is going to periodically check the dashboard to see if it has the last readily available data? \n* Is normal for a small team to have in scope to many third-party data sources, some of them unreliable as an excel or scraped data? \n* Do the team need to highlight the weaknesses of these type of connections or does the team have to put its food down when unreliable sources are chosen for a data product? \n\nCurrently we are hold responsible for any outdated data on the dashboards, even from weak sources which are determined by the stakeholders. Also, because the data sources are third-party, we have little observability into changes on it which can disrupt the data pipeline and mess-up our workload. \n\nI'm opening the discussion of how a team can navigate these situations and what's is a reasonable scope for a small team to be sustainable in their delivery and quality. ", "author_fullname": "t2_qsq7zvwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this workload sustainable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqpa3y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707923845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our Team, which it is composed of 1 data engineer, 1 data analyst, 1 data scientist, and a manager is the responsible of about 20-25 data products, most of them dashboard, and a couple of small webapps. Most of our stakeholders are withing the company, which requiere data visualization and simple analysis for creating reports for their clients.&lt;/p&gt;\n\n&lt;p&gt;All of us are capable of writing code, not as robust as the data engineer that is also a programmer. We create the whole data pipeline including the ETL (or ELT) for the data products. A really hard effort is being made to maintain these data products updated, most are dependable of scraping, unofficial APIs, and reading published excels on online pages for data acquisition, this creates a problem into maintaining the data products updated. Most of us are focused on the development of the data pipeline, ETL processes and correcting any changes that are made to the sources for data acquisition. We also create, by requests, small dashboard that do not need to be updated after delivery.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Where does de responsibility of maintaining the data product updated lies?&lt;/li&gt;\n&lt;li&gt;Who is going to periodically check the dashboard to see if it has the last readily available data? &lt;/li&gt;\n&lt;li&gt;Is normal for a small team to have in scope to many third-party data sources, some of them unreliable as an excel or scraped data? &lt;/li&gt;\n&lt;li&gt;Do the team need to highlight the weaknesses of these type of connections or does the team have to put its food down when unreliable sources are chosen for a data product? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Currently we are hold responsible for any outdated data on the dashboards, even from weak sources which are determined by the stakeholders. Also, because the data sources are third-party, we have little observability into changes on it which can disrupt the data pipeline and mess-up our workload. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m opening the discussion of how a team can navigate these situations and what&amp;#39;s is a reasonable scope for a small team to be sustainable in their delivery and quality. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aqpa3y", "is_robot_indexable": true, "report_reasons": null, "author": "sodatacram", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqpa3y/is_this_workload_sustainable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aqpa3y/is_this_workload_sustainable/", "subreddit_subscribers": 160719, "created_utc": 1707923845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Challenges of Multiple Data Products, Duplication Management, and Governance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1aqm2qq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/LtpHDxjmtOdI8XbYcY0qUTgoIF9EGel20EUkA0-tWl8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707914812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/managing-the-evolving-landscape-of-data-products", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?auto=webp&amp;s=74a60904fc4082970c40c8c774cfa316349eca28", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3eb4d1dc891690ba394f22db8d3e6276d223027", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=96121439278beb996df236f74ee4fb4c919d34c4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c2ac79c7aaded2d10c94d2772df2fc9e79a1804", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0fdc085e2beb54b853374f6005a840eb3f296212", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=741eaf0f4569f1dbcf6e0257fe209c2093fbb946", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/nDoLrH7rOmo2XXCg_mhj4gTOFBToaiQXLU3kiQ_o6AI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f2130d60ab93455414b1ec6b56fa4565c51bb0cf", "width": 1080, "height": 540}], "variants": {}, "id": "hTL2mgKSCo7xESDA1qHg-RhdxO_thI7hRM7L_VGYCaY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aqm2qq", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aqm2qq/challenges_of_multiple_data_products_duplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/managing-the-evolving-landscape-of-data-products", "subreddit_subscribers": 160719, "created_utc": 1707914812.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}