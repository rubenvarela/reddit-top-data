{"kind": "Listing", "data": {"after": null, "dist": 10, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "With a BS + MS in Statistics I don\u2019t really have any plans to do a PhD. I am more interested in solving problems in the industry than in academia. However, part of me feels \u201cweird\u201d that my education is gonna stop at 24 and I will be working and not getting another degree. But that\u2019s besides the point. My real concern is whether I need to plan on getting some kind of \u201cprofessional\u201d degree after my MS in Stats. When I interviewed for a role the hiring manager (who had no background in anything stem) told me I should consider an MBA to round myself out. Frankly I have no interest in doing an MBA. I\u2019ve gone debt free for my education my whole life (thank you parents for bachelors, and thank you to myself for getting funding for my masters), but in no way do I want to pay for an MBA. \n\nFrom my limited experience it feels like MBAs are just degrees people get to prove to a higher up that they have the credential to get a c suite position. Cause ultimately people hire people and if the directors or c suites have MBAs they know if they have an MBA from xyz university then they are gonna get hired cause of it. \n\nWhat do you guys think, is education after my MS in stats necessary? I mean for me \u201ceducation\u201d post Masters degree is just reading advanced stats textbooks on my own for fun, whether I need to learn something for work or I\u2019m just studying it for my enjoyment. But is a formal \u201cdegree\u201d required? Like I don\u2019t really see the point in me doing a PhD in stats, because I just don\u2019t want to work in an academic setting and frankly I just want money more. \n\nIs there a natural cap with a MS in something technical (stats) for example?\n\n\nEdit: I have the offer and I am gonna be working for them. It\u2019s just the guy said consider one after working for a few years. ", "author_fullname": "t2_uy28jztl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Education beyond a Masters, is it necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax6dgp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708632166.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708608434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With a BS + MS in Statistics I don\u2019t really have any plans to do a PhD. I am more interested in solving problems in the industry than in academia. However, part of me feels \u201cweird\u201d that my education is gonna stop at 24 and I will be working and not getting another degree. But that\u2019s besides the point. My real concern is whether I need to plan on getting some kind of \u201cprofessional\u201d degree after my MS in Stats. When I interviewed for a role the hiring manager (who had no background in anything stem) told me I should consider an MBA to round myself out. Frankly I have no interest in doing an MBA. I\u2019ve gone debt free for my education my whole life (thank you parents for bachelors, and thank you to myself for getting funding for my masters), but in no way do I want to pay for an MBA. &lt;/p&gt;\n\n&lt;p&gt;From my limited experience it feels like MBAs are just degrees people get to prove to a higher up that they have the credential to get a c suite position. Cause ultimately people hire people and if the directors or c suites have MBAs they know if they have an MBA from xyz university then they are gonna get hired cause of it. &lt;/p&gt;\n\n&lt;p&gt;What do you guys think, is education after my MS in stats necessary? I mean for me \u201ceducation\u201d post Masters degree is just reading advanced stats textbooks on my own for fun, whether I need to learn something for work or I\u2019m just studying it for my enjoyment. But is a formal \u201cdegree\u201d required? Like I don\u2019t really see the point in me doing a PhD in stats, because I just don\u2019t want to work in an academic setting and frankly I just want money more. &lt;/p&gt;\n\n&lt;p&gt;Is there a natural cap with a MS in something technical (stats) for example?&lt;/p&gt;\n\n&lt;p&gt;Edit: I have the offer and I am gonna be working for them. It\u2019s just the guy said consider one after working for a few years. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1ax6dgp", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Touch469", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax6dgp/education_beyond_a_masters_is_it_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax6dgp/education_beyond_a_masters_is_it_necessary/", "subreddit_subscribers": 1360266, "created_utc": 1708608434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Some of the groups I support are very understanding of the capabilities I can do with the data that we have\u2026\n\nOther groups look at me like I\u2019m sort of black box, where they can ask for anything and have some kind of accurate output. I understand that the areas that have the least amount of data are where the most improvements can be made but there are limitations to what I can feasibly do.", "author_fullname": "t2_jbfeybb1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you guys ever feel like your stakeholders view you as magicians?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1axm5pv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708646708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some of the groups I support are very understanding of the capabilities I can do with the data that we have\u2026&lt;/p&gt;\n\n&lt;p&gt;Other groups look at me like I\u2019m sort of black box, where they can ask for anything and have some kind of accurate output. I understand that the areas that have the least amount of data are where the most improvements can be made but there are limitations to what I can feasibly do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1axm5pv", "is_robot_indexable": true, "report_reasons": null, "author": "bernful", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1axm5pv/do_you_guys_ever_feel_like_your_stakeholders_view/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1axm5pv/do_you_guys_ever_feel_like_your_stakeholders_view/", "subreddit_subscribers": 1360266, "created_utc": 1708646708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi data science Reddit. To those who employ causal inference and work in Python, you may find the new Forward Difference-in-Differences estimator of interest. [The code](https://github.com/jgreathouse9/FDIDTutorial/blob/main/Vignette.md) (still being refined, tightened, and expanded) is avaliable on my Github, along with two applied empirical examples from the econometrics literature. Use it and give feedback, should you wish. ", "author_fullname": "t2_amhd0mtb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction for Forward DID: A New Causal Inference Estimator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1axap5v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708619549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data science Reddit. To those who employ causal inference and work in Python, you may find the new Forward Difference-in-Differences estimator of interest. &lt;a href=\"https://github.com/jgreathouse9/FDIDTutorial/blob/main/Vignette.md\"&gt;The code&lt;/a&gt; (still being refined, tightened, and expanded) is avaliable on my Github, along with two applied empirical examples from the econometrics literature. Use it and give feedback, should you wish. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?auto=webp&amp;s=c6432c6b15633c240caedb345355f503ed188ff1", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d9e9c23a71de1db492bae1505665defeccf6da3a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=89f71f3298eb1fd9b1be06ffc86d9abd446f1d77", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2de251b256e8e16a0a06d4a851e19496f7b0123", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0361fec45fa9ced606fb4cd587d39c0692fccfb4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49e0d64d812c320d66df3f9a8d50bc87962a1ee4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5K3P4vWBMd0TN87wrLGdz7IvwBnJSy6yukJqDP11noM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b0af1efae9adf07acbb7b67cf479004090ae7296", "width": 1080, "height": 540}], "variants": {}, "id": "QVPhBjSi6MZSruvwLP31Y9CGVajgVwn9KoQeAxRsBJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1axap5v", "is_robot_indexable": true, "report_reasons": null, "author": "turingincarnate", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1axap5v/introduction_for_forward_did_a_new_causal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1axap5v/introduction_for_forward_did_a_new_causal/", "subreddit_subscribers": 1360266, "created_utc": 1708619549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: My binary churn prediction model performs way better in development than production. I've listed a few reasons why I think that is, and I'm seeking community help to verify &amp; learn through my mistakes in the process.\n\nHi! I've been working on a churn model at work. It is to be used to predict once per month, which users will churn in the next 30 days. The model performed much better in development (train/test) compared to initial production run.  \nRecall and precision from test: 85%, 85%  \nRecall and precision from production month 1: 60%, 18%\n\nI believe the reasons this happened (which I should've realised sooner) is because of the following:\n\n1. The model was trained on historical churn over 2 years (which resulted in a balanced dataset as over a longer period of time many users eventually churn, especially in the industry I'm in) but the inference in production happens on all \"current active users\" *each month* (This is a pretty imbalanced set as roughly 4-5% users churn each month).\n2. As the inference happens each month on almost the same user-set (current active users), we might end up making the same prediction as previous month especially if there isn't a huge change in user data since last month. i.e we end up carrying forward false-positives from previous month.\n3. Model was only trained on the final states of user-journey. This means I could not include seasonality features as it would leak target data. Why? Because all the non-events (did not churn) \"happen\" on the last month of the training dataset.\n\nJust to add onto point 3, would it have made sense to train model on different points of the user journey instead of just the final state?   \nExample:  \ndata-point 1 :: User 1 features at the end of Jan :: Did not churn  \ndata-point 2 :: User 1 features at the end of Feb :: Did not churn  \ndata-point 3 :: User 1 features at the end of March :: **Churned**\n\n**Is my reasoning correct? What could I do different if I had to do this over?**", "author_fullname": "t2_40233m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Churn prediction: A data imbalance issue, or something else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax45p8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708601239.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708601039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: My binary churn prediction model performs way better in development than production. I&amp;#39;ve listed a few reasons why I think that is, and I&amp;#39;m seeking community help to verify &amp;amp; learn through my mistakes in the process.&lt;/p&gt;\n\n&lt;p&gt;Hi! I&amp;#39;ve been working on a churn model at work. It is to be used to predict once per month, which users will churn in the next 30 days. The model performed much better in development (train/test) compared to initial production run.&lt;br/&gt;\nRecall and precision from test: 85%, 85%&lt;br/&gt;\nRecall and precision from production month 1: 60%, 18%&lt;/p&gt;\n\n&lt;p&gt;I believe the reasons this happened (which I should&amp;#39;ve realised sooner) is because of the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The model was trained on historical churn over 2 years (which resulted in a balanced dataset as over a longer period of time many users eventually churn, especially in the industry I&amp;#39;m in) but the inference in production happens on all &amp;quot;current active users&amp;quot; &lt;em&gt;each month&lt;/em&gt; (This is a pretty imbalanced set as roughly 4-5% users churn each month).&lt;/li&gt;\n&lt;li&gt;As the inference happens each month on almost the same user-set (current active users), we might end up making the same prediction as previous month especially if there isn&amp;#39;t a huge change in user data since last month. i.e we end up carrying forward false-positives from previous month.&lt;/li&gt;\n&lt;li&gt;Model was only trained on the final states of user-journey. This means I could not include seasonality features as it would leak target data. Why? Because all the non-events (did not churn) &amp;quot;happen&amp;quot; on the last month of the training dataset.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Just to add onto point 3, would it have made sense to train model on different points of the user journey instead of just the final state?&lt;br/&gt;\nExample:&lt;br/&gt;\ndata-point 1 :: User 1 features at the end of Jan :: Did not churn&lt;br/&gt;\ndata-point 2 :: User 1 features at the end of Feb :: Did not churn&lt;br/&gt;\ndata-point 3 :: User 1 features at the end of March :: &lt;strong&gt;Churned&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is my reasoning correct? What could I do different if I had to do this over?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ax45p8", "is_robot_indexable": true, "report_reasons": null, "author": "CrypticTac", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax45p8/churn_prediction_a_data_imbalance_issue_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax45p8/churn_prediction_a_data_imbalance_issue_or/", "subreddit_subscribers": 1360266, "created_utc": 1708601039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My current position is Senior Data Scientist, it is my second role, before that I was a DS consultant and I have about 4-5 yoe, depends on you count it. \n\nI have been working at my current place for about 2 years, and I got to the point where my learning is bounded. I am very appreciated at my current workplace, and I had the luck of entering to the company at a good time, so I took part in the development of several central pipelines, and saw our product become profitable. For the past six months, however, I have been feeling stuck and frustrated. Due to bad management we are now micro-managed by our CEO. It doesn't look like I have a lot of place to grow, and my direct manager isn't at a point he can guild me on ML and has a very modest technical stack to be generous. \n\nFor the past year, I started to develop interest in NLP, and since then I did on my spare time a lot of learning and some side project in varying complexity. In my work as well, I was able to push for using some of the things that I learned (also by doing extra hours, but it was for me as well). So far I led a project were we trained a RoBERTa model from scratch, including tokenization as we deal with somewhat a different domain than the off-the-shelf pre-trained datasets are familiar with. I also trained more modest models including siamese network to learn similarity between strings of different sources, and a Word2Vec for word embeddings when the use case made more sense than using contextual embeddings. All of the above are projects that ended up being delivered to customers, which I led from a-z.\n\nI know that in four months or so, I would like to start looking for a new place, and I know that I am looking for a place where I could deepen my knowledge about working with textual data. In the meantime I am trying to read as many papers as my time allows (both inside and outside of work), and I try to look for problems I can solve with NLP in my current workplace. Our main product is based on classification and we are heavily focus on low latency, so with these two limitations, I am struggling to see how transformer decoders (LLMs) can help. \n\nI don't know if the above would suffice to land a first job as an NLP engineer/DS in a company that focuses on textual data. **I am wondering what can I do in order to set myself apart from other candidates, and what hiring managers in such companies look for in a prospective candidate**. \n\nThanks!", "author_fullname": "t2_4udseb4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to prepare myself for next role as NLP Engineer/DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1axqwyj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708660264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My current position is Senior Data Scientist, it is my second role, before that I was a DS consultant and I have about 4-5 yoe, depends on you count it. &lt;/p&gt;\n\n&lt;p&gt;I have been working at my current place for about 2 years, and I got to the point where my learning is bounded. I am very appreciated at my current workplace, and I had the luck of entering to the company at a good time, so I took part in the development of several central pipelines, and saw our product become profitable. For the past six months, however, I have been feeling stuck and frustrated. Due to bad management we are now micro-managed by our CEO. It doesn&amp;#39;t look like I have a lot of place to grow, and my direct manager isn&amp;#39;t at a point he can guild me on ML and has a very modest technical stack to be generous. &lt;/p&gt;\n\n&lt;p&gt;For the past year, I started to develop interest in NLP, and since then I did on my spare time a lot of learning and some side project in varying complexity. In my work as well, I was able to push for using some of the things that I learned (also by doing extra hours, but it was for me as well). So far I led a project were we trained a RoBERTa model from scratch, including tokenization as we deal with somewhat a different domain than the off-the-shelf pre-trained datasets are familiar with. I also trained more modest models including siamese network to learn similarity between strings of different sources, and a Word2Vec for word embeddings when the use case made more sense than using contextual embeddings. All of the above are projects that ended up being delivered to customers, which I led from a-z.&lt;/p&gt;\n\n&lt;p&gt;I know that in four months or so, I would like to start looking for a new place, and I know that I am looking for a place where I could deepen my knowledge about working with textual data. In the meantime I am trying to read as many papers as my time allows (both inside and outside of work), and I try to look for problems I can solve with NLP in my current workplace. Our main product is based on classification and we are heavily focus on low latency, so with these two limitations, I am struggling to see how transformer decoders (LLMs) can help. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if the above would suffice to land a first job as an NLP engineer/DS in a company that focuses on textual data. &lt;strong&gt;I am wondering what can I do in order to set myself apart from other candidates, and what hiring managers in such companies look for in a prospective candidate&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1axqwyj", "is_robot_indexable": true, "report_reasons": null, "author": "David202023", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1axqwyj/how_to_prepare_myself_for_next_role_as_nlp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1axqwyj/how_to_prepare_myself_for_next_role_as_nlp/", "subreddit_subscribers": 1360266, "created_utc": 1708660264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a weekly time series model, with 8 weeks as the forecasting horizon. There are 4 exogenous variables, which I forecast also 8 weeks ahead and use as the input for the target variable forecast.\n\nNow I run this model every Monday. My teammate, without much time series knowledge, suggests that the model does not need to be retrained every week, and just train every 4 weeks or so.\n\nI understand the models like classification does not need to be retrained very often. With the sensitive of the time series, I think it would be necessary to include the new data especially the data is less granular like weekly.\n\nWhat is the best practice?", "author_fullname": "t2_12x43b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often to retrain the time series forecasting model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1axdyu8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708627109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a weekly time series model, with 8 weeks as the forecasting horizon. There are 4 exogenous variables, which I forecast also 8 weeks ahead and use as the input for the target variable forecast.&lt;/p&gt;\n\n&lt;p&gt;Now I run this model every Monday. My teammate, without much time series knowledge, suggests that the model does not need to be retrained every week, and just train every 4 weeks or so.&lt;/p&gt;\n\n&lt;p&gt;I understand the models like classification does not need to be retrained very often. With the sensitive of the time series, I think it would be necessary to include the new data especially the data is less granular like weekly.&lt;/p&gt;\n\n&lt;p&gt;What is the best practice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1axdyu8", "is_robot_indexable": true, "report_reasons": null, "author": "janicewa", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1axdyu8/how_often_to_retrain_the_time_series_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1axdyu8/how_often_to_retrain_the_time_series_forecasting/", "subreddit_subscribers": 1360266, "created_utc": 1708627109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, long time lurker, first time poster. I've been working on an AI assisted data pseudonymization app recently. Basically the idea is that you can build pseudonymization pipelines in the cloud with the help of an AI assistant that generates a template pipeline for you based on the uploaded contents (shameless plug, check out the app [seudo](https://seudo.alpn-software.com) here if you're interested).\n\nIn a nutshell, I need to be able to classify a data column in a CSV as either personal data or not. I'm interested in getting peoples thoughts on how to generate a feature space. What I've done so far is generate a feature vector using the column name and a sample value by running it through a bunch of regex expressions that check for common PI patterns in the data values and in the column name. I've also added some other basic string metrics (how long, how many vowels etc), and trained a random forrest classifier on a dataset that I generated.\n\nIt was loosely based on [this](https://medium.com/cape-ai-stories/case-study-using-machine-learning-to-classify-personally-identifiable-data-fields-6b9c5b0743e7) article (very loosely), and the results are mixed. The article in question was specific to a given region in SA, and doesnt generalise well to other parts of the world. Anyone done anything similar before? How would you go about generating a feature space to train a model?\n\nIf you're interested and have a minute, feel free to check out the app as well (link above). Any feedback is always appreciated.", "author_fullname": "t2_bep31tvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Classification Model for Personal Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax1ii5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708590570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, long time lurker, first time poster. I&amp;#39;ve been working on an AI assisted data pseudonymization app recently. Basically the idea is that you can build pseudonymization pipelines in the cloud with the help of an AI assistant that generates a template pipeline for you based on the uploaded contents (shameless plug, check out the app &lt;a href=\"https://seudo.alpn-software.com\"&gt;seudo&lt;/a&gt; here if you&amp;#39;re interested).&lt;/p&gt;\n\n&lt;p&gt;In a nutshell, I need to be able to classify a data column in a CSV as either personal data or not. I&amp;#39;m interested in getting peoples thoughts on how to generate a feature space. What I&amp;#39;ve done so far is generate a feature vector using the column name and a sample value by running it through a bunch of regex expressions that check for common PI patterns in the data values and in the column name. I&amp;#39;ve also added some other basic string metrics (how long, how many vowels etc), and trained a random forrest classifier on a dataset that I generated.&lt;/p&gt;\n\n&lt;p&gt;It was loosely based on &lt;a href=\"https://medium.com/cape-ai-stories/case-study-using-machine-learning-to-classify-personally-identifiable-data-fields-6b9c5b0743e7\"&gt;this&lt;/a&gt; article (very loosely), and the results are mixed. The article in question was specific to a given region in SA, and doesnt generalise well to other parts of the world. Anyone done anything similar before? How would you go about generating a feature space to train a model?&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested and have a minute, feel free to check out the app as well (link above). Any feedback is always appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1ax1ii5", "is_robot_indexable": true, "report_reasons": null, "author": "OkInteraction493", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax1ii5/classification_model_for_personal_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax1ii5/classification_model_for_personal_data/", "subreddit_subscribers": 1360266, "created_utc": 1708590570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to implement the R\u2019s random forest classifier equivalent in python:\n\n    # train random forest\n       \n    set.seed(5136)  \n    ty.rf = randomForest(y=ty.y, x= ty.x, ntree=1000, importance=T, strata=ty.y, sampsize=c(100,100), do.trace=10, proximity=T)  \n\nThe above classifier was implemented for an imbalanced data.\n\nI had tried to implement the above as following in python.\n\nHere\u2019s my implementation in python:\n\n    # random forest      \n    \n    rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),  \n    \n    ('model',RandomForestClassifier(n_estimators=1000,class_weight='balanced', random_state=5136, oob_score=True, bootstrap = True))])    rf_pipeline.fit(ty_x, ty_y)   \n\nIs this the equivalent syntax here? Also, after implementation in R code OOB estimate of error rate: 19.41% and in python OOB estimate of error rate: 7.14%, is this expected? I was expecting the oob\\_error to be similar. Can someone please clarify?", "author_fullname": "t2_p657jjww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Random Forest classifier in R vs scikit-learn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax6pw1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708636263.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708609457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to implement the R\u2019s random forest classifier equivalent in python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# train random forest\n\nset.seed(5136)  \nty.rf = randomForest(y=ty.y, x= ty.x, ntree=1000, importance=T, strata=ty.y, sampsize=c(100,100), do.trace=10, proximity=T)  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The above classifier was implemented for an imbalanced data.&lt;/p&gt;\n\n&lt;p&gt;I had tried to implement the above as following in python.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s my implementation in python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# random forest      \n\nrf_pipeline = Pipeline(steps=[(&amp;#39;preprocessor&amp;#39;, preprocessor),  \n\n(&amp;#39;model&amp;#39;,RandomForestClassifier(n_estimators=1000,class_weight=&amp;#39;balanced&amp;#39;, random_state=5136, oob_score=True, bootstrap = True))])    rf_pipeline.fit(ty_x, ty_y)   \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this the equivalent syntax here? Also, after implementation in R code OOB estimate of error rate: 19.41% and in python OOB estimate of error rate: 7.14%, is this expected? I was expecting the oob_error to be similar. Can someone please clarify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1ax6pw1", "is_robot_indexable": true, "report_reasons": null, "author": "tinkerpal", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax6pw1/d_random_forest_classifier_in_r_vs_scikitlearn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax6pw1/d_random_forest_classifier_in_r_vs_scikitlearn/", "subreddit_subscribers": 1360266, "created_utc": 1708609457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI know this topic has been extensively covered, but I haven't found an answer that suits my needs.\n\nI'm currently interning and working on electronic boards.\n\nThese electronic boards go through test benches. The test lasts about 3 hours if the board is compliant; otherwise, as soon as an anomaly appears, the test stops. This is the source of my missing values.\n\nMy topic is as follows: a number of these rejected boards are false negatives (a board detected as defective when it is actually compliant).\n\nTherefore, I'm looking to create a machine learning model to predict the false negatives in order to analyze the most influential parameters and correct them.\n\nHowever, missing values are a real problem for me, plus my data is highly imbalanced (m &lt;&lt;&lt;&lt; n), which doesn't make my job any easier.", "author_fullname": "t2_uqpbzszz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with missing values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1axcgfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708623629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I know this topic has been extensively covered, but I haven&amp;#39;t found an answer that suits my needs.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently interning and working on electronic boards.&lt;/p&gt;\n\n&lt;p&gt;These electronic boards go through test benches. The test lasts about 3 hours if the board is compliant; otherwise, as soon as an anomaly appears, the test stops. This is the source of my missing values.&lt;/p&gt;\n\n&lt;p&gt;My topic is as follows: a number of these rejected boards are false negatives (a board detected as defective when it is actually compliant).&lt;/p&gt;\n\n&lt;p&gt;Therefore, I&amp;#39;m looking to create a machine learning model to predict the false negatives in order to analyze the most influential parameters and correct them.&lt;/p&gt;\n\n&lt;p&gt;However, missing values are a real problem for me, plus my data is highly imbalanced (m &amp;lt;&amp;lt;&amp;lt;&amp;lt; n), which doesn&amp;#39;t make my job any easier.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1axcgfo", "is_robot_indexable": true, "report_reasons": null, "author": "omitna", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1axcgfo/how_to_deal_with_missing_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1axcgfo/how_to_deal_with_missing_values/", "subreddit_subscribers": 1360266, "created_utc": 1708623629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys! I wonder if it is possible to train an LLM model, like BERT, to be able to associate a word with another word. For example, \"Blue\" -&gt; \"Sky\" (the model associates the word \"Blue\" with \"Sky\"). Cheers!", "author_fullname": "t2_3j4e33js", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Word Association with LLM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ax4lu1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708602720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! I wonder if it is possible to train an LLM model, like BERT, to be able to associate a word with another word. For example, &amp;quot;Blue&amp;quot; -&amp;gt; &amp;quot;Sky&amp;quot; (the model associates the word &amp;quot;Blue&amp;quot; with &amp;quot;Sky&amp;quot;). Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1ax4lu1", "is_robot_indexable": true, "report_reasons": null, "author": "OxheadGreg123", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ax4lu1/word_association_with_llm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ax4lu1/word_association_with_llm/", "subreddit_subscribers": 1360266, "created_utc": 1708602720.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}