{"kind": "Listing", "data": {"after": "t3_1anugly", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When i was Torrenting yesterday i Stumbled apon the files to the Daft Punk DVD **D.A.F.T. - A Story About Dogs, Androids, Firemen and Tomatoes** i was thinking of uploading it to archive.org but I'm not sure if that is legal and I don't want to get in trouble", "author_fullname": "t2_e27dm3jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is uploading a out of print DVD to archive.org Legal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anwdbh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 80, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707615733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When i was Torrenting yesterday i Stumbled apon the files to the Daft Punk DVD &lt;strong&gt;D.A.F.T. - A Story About Dogs, Androids, Firemen and Tomatoes&lt;/strong&gt; i was thinking of uploading it to archive.org but I&amp;#39;m not sure if that is legal and I don&amp;#39;t want to get in trouble&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anwdbh", "is_robot_indexable": true, "report_reasons": null, "author": "StevenIsCool2004", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anwdbh/is_uploading_a_out_of_print_dvd_to_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anwdbh/is_uploading_a_out_of_print_dvd_to_archiveorg/", "subreddit_subscribers": 732365, "created_utc": 1707615733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for anyone who has an archive for the Marching Arts for BOA/Grand Nationals/local circuits etc....  I already have a huge drafted archive for DCI that's over 2TB from judges tapes to HQ Blurays.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The reason I want to do this is because unfortunately due to the terrible system that is music copyright laws, neither Flomarching, the event holder, or the band performing get maximum quality videos. Flomarching does allow you to watch their streams after the fact, but they are legally required to not save any of the audio. This means that the performers (or anyone else) cannot enjoy their to the full potential if they don't want to rely on bad phone recorded videos with peoples heads blocking or if they actually want to hear the music they played.                                       ", "author_fullname": "t2_9woubj41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone hoarding marching band videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anv48v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707612054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for anyone who has an archive for the Marching Arts for BOA/Grand Nationals/local circuits etc....  I already have a huge drafted archive for DCI that&amp;#39;s over 2TB from judges tapes to HQ Blurays.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The reason I want to do this is because unfortunately due to the terrible system that is music copyright laws, neither Flomarching, the event holder, or the band performing get maximum quality videos. Flomarching does allow you to watch their streams after the fact, but they are legally required to not save any of the audio. This means that the performers (or anyone else) cannot enjoy their to the full potential if they don&amp;#39;t want to rely on bad phone recorded videos with peoples heads blocking or if they actually want to hear the music they played.                                       &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anv48v", "is_robot_indexable": true, "report_reasons": null, "author": "Roleplex0", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anv48v/anyone_hoarding_marching_band_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anv48v/anyone_hoarding_marching_band_videos/", "subreddit_subscribers": 732365, "created_utc": 1707612054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm aware of archivebox but I'm wondering if there are other new tools that also archive web pages you visit? The last time I tried doing this was in 2012.", "author_fullname": "t2_4ph16ic4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools to archive visited web pages locally in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anopqc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707594675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m aware of archivebox but I&amp;#39;m wondering if there are other new tools that also archive web pages you visit? The last time I tried doing this was in 2012.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anopqc", "is_robot_indexable": true, "report_reasons": null, "author": "A9to5robot", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anopqc/tools_to_archive_visited_web_pages_locally_in_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anopqc/tools_to_archive_visited_web_pages_locally_in_2024/", "subreddit_subscribers": 732365, "created_utc": 1707594675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a computer with 3 1TB disks. All the disks have photos randomly strewn about the directory structure on the drives. Most have random filenames (game screnshots, photos of projects I've made, electrical schematics, photos of vehicles, old TVs, ect.)\n\nWhat's the best program I can use to find duplicates, and hopefully consolidate all the photos to one location?\n\nEdit: I'm on windows, so any tools would have to work on windows.", "author_fullname": "t2_ky0ji79zj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a way to find duplicate photos on multiple drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anjpwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707581429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a computer with 3 1TB disks. All the disks have photos randomly strewn about the directory structure on the drives. Most have random filenames (game screnshots, photos of projects I&amp;#39;ve made, electrical schematics, photos of vehicles, old TVs, ect.)&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best program I can use to find duplicates, and hopefully consolidate all the photos to one location?&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m on windows, so any tools would have to work on windows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anjpwf", "is_robot_indexable": true, "report_reasons": null, "author": "aspie_electrician", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anjpwf/looking_for_a_way_to_find_duplicate_photos_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anjpwf/looking_for_a_way_to_find_duplicate_photos_on/", "subreddit_subscribers": 732365, "created_utc": 1707581429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My TrueNAS Mini XL+ died the other day. No network, no connection over VGA. Looking into it, it seems relatively common. Anyway, getting in there I've decided I don't really want to continue using it anyway...\n\nThe TrueNAS Mini XL+ is fully populated with 8 HDDs. Next to that system I have a system that is running ZFS (no FreeNAS, etc, just Linux+ZFS) with the following hardware specs:\n\n* Fractal Design 7 (not xl, mid-tower, 8 bay model)\n* Gigabyte Z390 AORUS ULTRA-CF Motherboard\n* Intel i9-9900K\n* NVIDIA Corporation GP106GL [Quadro P2200]\n* 16GB memory (2x8GB Corsair CMK16GX4M2B3200C16 DIMMs)\n\nI'm thinking of either moving everything (all drives in TrueNAS Mini XL + all components in the Fractal Design 7 case) into a Fractal Design Meshify 2 XL case (all 16 drives); or, alternatively, I get a 2nd system and move everything from the TrueNAS case into the 2nd system.\n\nQuestions\n\n* Will I be able to simply migrate the pool from the TrueNAS into the new system w.o data loss? All HDDs are perfectly fine. I would assume this process should be just add a 2nd pool and everything is good, but not sure. Is this process more difficult if moving the drives into a system with an already existing ZFS pool?\n\n* In my situation would you buy a 2nd system, or move everything into a larger case? I just don't want to spend a bunch of money unnecessarily on another mobo/power supply/cpu/etc, especially if I can just move it into a larger case and have both ZFS pools running alongside each other. What are the pros/cons of these 2 scenarios?\n\nI am using the Fractal Design system as a Plex server. So now it would be a Plex server with 8 extra drives, beyond the 8 it already has.", "author_fullname": "t2_k7b5nyn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My TrueNAS Mini died. I have some questions regarding different paths I can take here.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao3cvy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707640272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My TrueNAS Mini XL+ died the other day. No network, no connection over VGA. Looking into it, it seems relatively common. Anyway, getting in there I&amp;#39;ve decided I don&amp;#39;t really want to continue using it anyway...&lt;/p&gt;\n\n&lt;p&gt;The TrueNAS Mini XL+ is fully populated with 8 HDDs. Next to that system I have a system that is running ZFS (no FreeNAS, etc, just Linux+ZFS) with the following hardware specs:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fractal Design 7 (not xl, mid-tower, 8 bay model)&lt;/li&gt;\n&lt;li&gt;Gigabyte Z390 AORUS ULTRA-CF Motherboard&lt;/li&gt;\n&lt;li&gt;Intel i9-9900K&lt;/li&gt;\n&lt;li&gt;NVIDIA Corporation GP106GL [Quadro P2200]&lt;/li&gt;\n&lt;li&gt;16GB memory (2x8GB Corsair CMK16GX4M2B3200C16 DIMMs)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of either moving everything (all drives in TrueNAS Mini XL + all components in the Fractal Design 7 case) into a Fractal Design Meshify 2 XL case (all 16 drives); or, alternatively, I get a 2nd system and move everything from the TrueNAS case into the 2nd system.&lt;/p&gt;\n\n&lt;p&gt;Questions&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Will I be able to simply migrate the pool from the TrueNAS into the new system w.o data loss? All HDDs are perfectly fine. I would assume this process should be just add a 2nd pool and everything is good, but not sure. Is this process more difficult if moving the drives into a system with an already existing ZFS pool?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In my situation would you buy a 2nd system, or move everything into a larger case? I just don&amp;#39;t want to spend a bunch of money unnecessarily on another mobo/power supply/cpu/etc, especially if I can just move it into a larger case and have both ZFS pools running alongside each other. What are the pros/cons of these 2 scenarios?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am using the Fractal Design system as a Plex server. So now it would be a Plex server with 8 extra drives, beyond the 8 it already has.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao3cvy", "is_robot_indexable": true, "report_reasons": null, "author": "retsuko_h4x", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao3cvy/my_truenas_mini_died_i_have_some_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao3cvy/my_truenas_mini_died_i_have_some_questions/", "subreddit_subscribers": 732365, "created_utc": 1707640272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have about 40TB to move from one server (old hardware raid 6) to a new server (zfs raidz2). I started the  process on one chunk ~3 TB and realized over my 1Gbit network this is going to take some time. \n\nI've moved around big chunks before but it was always within server ie raid array to raid array and it went pretty quick. Based on some rough calculations this is going to take like a month, which is fine I guess worst case..\n\nIs are there any lower cost solutions to moving this data? I'm going to guess probably not.\n\nEdit: I miscalculated, this will take a week, I'm going to just be patient.", "author_fullname": "t2_5s2jw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data migration old server -&gt; new", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anuc6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707615370.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 40TB to move from one server (old hardware raid 6) to a new server (zfs raidz2). I started the  process on one chunk ~3 TB and realized over my 1Gbit network this is going to take some time. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve moved around big chunks before but it was always within server ie raid array to raid array and it went pretty quick. Based on some rough calculations this is going to take like a month, which is fine I guess worst case..&lt;/p&gt;\n\n&lt;p&gt;Is are there any lower cost solutions to moving this data? I&amp;#39;m going to guess probably not.&lt;/p&gt;\n\n&lt;p&gt;Edit: I miscalculated, this will take a week, I&amp;#39;m going to just be patient.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anuc6f", "is_robot_indexable": true, "report_reasons": null, "author": "UACEENGR", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anuc6f/data_migration_old_server_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anuc6f/data_migration_old_server_new/", "subreddit_subscribers": 732365, "created_utc": 1707609828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an iPhone 13 and a MacBook Air. My goal is to move my photos/videos off my phone to (???) so that I can use Capcut to edit Youtube videos. I need the quality to stay the same. \n\nMy iPhone storage is now full at 200 GB, as is my MacBook Air space, it's all photos and videos, no apps, no additional data stored anywhere. \n\nWhat's my next step? ", "author_fullname": "t2_4vjnlv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Way to Clear Storage on iPhone (move Photos for Video Editing)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anu77j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an iPhone 13 and a MacBook Air. My goal is to move my photos/videos off my phone to (???) so that I can use Capcut to edit Youtube videos. I need the quality to stay the same. &lt;/p&gt;\n\n&lt;p&gt;My iPhone storage is now full at 200 GB, as is my MacBook Air space, it&amp;#39;s all photos and videos, no apps, no additional data stored anywhere. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s my next step? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anu77j", "is_robot_indexable": true, "report_reasons": null, "author": "BetweenOceans", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anu77j/best_way_to_clear_storage_on_iphone_move_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anu77j/best_way_to_clear_storage_on_iphone_move_photos/", "subreddit_subscribers": 732365, "created_utc": 1707609453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im wondering is theres any practical different in longetivity of using sas instead of sata drives in a standard pc chassi that has rubber feets most of the time for the HDDs.\n\nCompare that to sas vs sata in a enterprise chassi with standard hotswap bays in metal that propatage vibrations.\n\nToo soft of rubber feet on the hdd in a PC can cause the drive to vibrate more though.\n\nso for max longevity how do you rank a setup ?\n\nie:\n\n1. sas in PC\n2. sas in server chassi (do dampening rubber)\n3. sata in PC\n4. sata in server chassi", "author_fullname": "t2_3ods4ki7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAS vs SATA in PC vs Enterprise server chassi ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anhcij", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707574773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im wondering is theres any practical different in longetivity of using sas instead of sata drives in a standard pc chassi that has rubber feets most of the time for the HDDs.&lt;/p&gt;\n\n&lt;p&gt;Compare that to sas vs sata in a enterprise chassi with standard hotswap bays in metal that propatage vibrations.&lt;/p&gt;\n\n&lt;p&gt;Too soft of rubber feet on the hdd in a PC can cause the drive to vibrate more though.&lt;/p&gt;\n\n&lt;p&gt;so for max longevity how do you rank a setup ?&lt;/p&gt;\n\n&lt;p&gt;ie:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;sas in PC&lt;/li&gt;\n&lt;li&gt;sas in server chassi (do dampening rubber)&lt;/li&gt;\n&lt;li&gt;sata in PC&lt;/li&gt;\n&lt;li&gt;sata in server chassi&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1anhcij", "is_robot_indexable": true, "report_reasons": null, "author": "DifficultThing5140", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anhcij/sas_vs_sata_in_pc_vs_enterprise_server_chassi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anhcij/sas_vs_sata_in_pc_vs_enterprise_server_chassi/", "subreddit_subscribers": 732365, "created_utc": 1707574773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First of all, this is my first post in this community, so apologies if I am missing something here.\n\nI would like to download the original files from  [archive.org](https://archive.org) video repositories using the official [python CLI interface](https://github.com/jjjake/internetarchive).\n\nThe issues is, I cannot find a switch in the [documentation](https://archive.org/developers/internetarchive/api.html#internetarchive.download) of the `download` function to do exactly that.\n\nFor example, running `download('maus-06-07-30', verbose=True, dry_run=True)` shows that I would be downloading both .mp4 and .avi files as well as .jpg thumbnails with it, which I do *not* want.\n\nYes, I could exclude .mp4 files and .jpg files using the `glob_pattern` or `formats` parameter, but that would mean, I would first need to find a way to determine programmatically which files are the originals and which aren't.\n\nCheers, Andr\u00e9", "author_fullname": "t2_1agysvjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download only original files from archive.org using official python script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao4b68", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707644256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, this is my first post in this community, so apologies if I am missing something here.&lt;/p&gt;\n\n&lt;p&gt;I would like to download the original files from  &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt; video repositories using the official &lt;a href=\"https://github.com/jjjake/internetarchive\"&gt;python CLI interface&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The issues is, I cannot find a switch in the &lt;a href=\"https://archive.org/developers/internetarchive/api.html#internetarchive.download\"&gt;documentation&lt;/a&gt; of the &lt;code&gt;download&lt;/code&gt; function to do exactly that.&lt;/p&gt;\n\n&lt;p&gt;For example, running &lt;code&gt;download(&amp;#39;maus-06-07-30&amp;#39;, verbose=True, dry_run=True)&lt;/code&gt; shows that I would be downloading both .mp4 and .avi files as well as .jpg thumbnails with it, which I do &lt;em&gt;not&lt;/em&gt; want.&lt;/p&gt;\n\n&lt;p&gt;Yes, I could exclude .mp4 files and .jpg files using the &lt;code&gt;glob_pattern&lt;/code&gt; or &lt;code&gt;formats&lt;/code&gt; parameter, but that would mean, I would first need to find a way to determine programmatically which files are the originals and which aren&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Cheers, Andr\u00e9&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao4b68", "is_robot_indexable": true, "report_reasons": null, "author": "TXAndre", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao4b68/download_only_original_files_from_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao4b68/download_only_original_files_from_archiveorg/", "subreddit_subscribers": 732365, "created_utc": 1707644256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am asking if there is a caddy like device out there that actually works that will do 3.5/2.5 sata - msata and nvme all in one. I had a pc die on me with and my storage media had all different interfaces. I just want to recover the data from all of them in one sweep if possible.\n\nIf not what caddy work stations would you recommend I buy to get the job done?\n\nThanks", "author_fullname": "t2_kc1gh3j1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage media workstation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao488s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707643900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am asking if there is a caddy like device out there that actually works that will do 3.5/2.5 sata - msata and nvme all in one. I had a pc die on me with and my storage media had all different interfaces. I just want to recover the data from all of them in one sweep if possible.&lt;/p&gt;\n\n&lt;p&gt;If not what caddy work stations would you recommend I buy to get the job done?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao488s", "is_robot_indexable": true, "report_reasons": null, "author": "bassnerdmusic", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao488s/storage_media_workstation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao488s/storage_media_workstation/", "subreddit_subscribers": 732365, "created_utc": 1707643900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I created a batch file to download multiple links from tumblr, and it downloaded almost all of the links, except for this one line:\n\n    gallery-dl \"https://www.tumblr.com/username/tagged/my%20art\" --mtime-from-date -o skip=true -D \"D:\\[Art]\\tumblr\\username\"\n\nWhen I ran this command manually by opening command prompt and pasting it in, it worked, but when I ran it by opening the .bat file this came up:\n\n    [tumblr][info] No results for https://www.tumblr.com/username/tagged/my0art\"\n\nI assume this was because that command contained the special character \"&amp;\" so the .bat file didn't work, but I'm not sure because I don't know anything about coding. If you have any explanation or advice on how to fix this, I'd really appreciate it!", "author_fullname": "t2_ielfpq9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I fix gallery-dl .bat file skipping link with special character", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anz2ma", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707624363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created a batch file to download multiple links from tumblr, and it downloaded almost all of the links, except for this one line:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gallery-dl &amp;quot;https://www.tumblr.com/username/tagged/my%20art&amp;quot; --mtime-from-date -o skip=true -D &amp;quot;D:\\[Art]\\tumblr\\username&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When I ran this command manually by opening command prompt and pasting it in, it worked, but when I ran it by opening the .bat file this came up:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[tumblr][info] No results for https://www.tumblr.com/username/tagged/my0art&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I assume this was because that command contained the special character &amp;quot;&amp;amp;&amp;quot; so the .bat file didn&amp;#39;t work, but I&amp;#39;m not sure because I don&amp;#39;t know anything about coding. If you have any explanation or advice on how to fix this, I&amp;#39;d really appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anz2ma", "is_robot_indexable": true, "report_reasons": null, "author": "freetousebyjtc", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anz2ma/how_do_i_fix_gallerydl_bat_file_skipping_link/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anz2ma/how_do_i_fix_gallerydl_bat_file_skipping_link/", "subreddit_subscribers": 732365, "created_utc": 1707624363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I changed over to Firefox in order to use Stacher to its best capacity, but when I finally thought that I would be able to download some embeded Patreon videos, I get an error message saying that there was no supported media found in that post...\n\n    Collecting video metadata...\n    Generated command line:\n    C:\\Users\\User\\.stacher/youtube-dl -f best --no-warnings --cookies-from-browser firefox --no-check-certificate -o ~/Downloads/%(upload_date)s_%(title)s.%(ext)s --username ***************** --password **********\n    https://www.patreon.com/posts/uncut-goblin-s1-63227887\n    Starting download...\n    Extracting cookies from firefox\n    Extracted 25 cookies from firefox\n    [Patreon] Extracting URL: https://www.patreon.com/posts/uncut-goblin-s1-63227887 [Patreon] 63227887: Downloading API JSON\n    ERROR: [Patreon] 63227887: No supported media found in this post\n\nHow the hell can I fix that error? Or is there no way to fix it?\n\nAlso, if so, are there any other frontends for yt-dlp that use the newest version of it that might work with an embeded patreon video?", "author_fullname": "t2_9ata9p94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stacher Patreon: no supported media ERROR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anxwfu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707620559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I changed over to Firefox in order to use Stacher to its best capacity, but when I finally thought that I would be able to download some embeded Patreon videos, I get an error message saying that there was no supported media found in that post...&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Collecting video metadata...\nGenerated command line:\nC:\\Users\\User\\.stacher/youtube-dl -f best --no-warnings --cookies-from-browser firefox --no-check-certificate -o ~/Downloads/%(upload_date)s_%(title)s.%(ext)s --username ***************** --password **********\nhttps://www.patreon.com/posts/uncut-goblin-s1-63227887\nStarting download...\nExtracting cookies from firefox\nExtracted 25 cookies from firefox\n[Patreon] Extracting URL: https://www.patreon.com/posts/uncut-goblin-s1-63227887 [Patreon] 63227887: Downloading API JSON\nERROR: [Patreon] 63227887: No supported media found in this post\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How the hell can I fix that error? Or is there no way to fix it?&lt;/p&gt;\n\n&lt;p&gt;Also, if so, are there any other frontends for yt-dlp that use the newest version of it that might work with an embeded patreon video?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anxwfu", "is_robot_indexable": true, "report_reasons": null, "author": "PadoruPadome", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anxwfu/stacher_patreon_no_supported_media_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anxwfu/stacher_patreon_no_supported_media_error/", "subreddit_subscribers": 732365, "created_utc": 1707620559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a file that has thousands of (mostly jpeg) images in it -- my computers swap backgrounds by pulling from this file randomly. Some of the images should be culled, but File Explorer doesn't show the thumbnails for a lot of the jpegs, so it is super hard to review. You have to click into each one, which is infuriating.\n\nHow can I force File Explorer to update the jpegs? Do I need to use a different program?", "author_fullname": "t2_cwfuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to see thumbnails of all pictures in a file of thousands of them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anvyd4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707614466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a file that has thousands of (mostly jpeg) images in it -- my computers swap backgrounds by pulling from this file randomly. Some of the images should be culled, but File Explorer doesn&amp;#39;t show the thumbnails for a lot of the jpegs, so it is super hard to review. You have to click into each one, which is infuriating.&lt;/p&gt;\n\n&lt;p&gt;How can I force File Explorer to update the jpegs? Do I need to use a different program?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anvyd4", "is_robot_indexable": true, "report_reasons": null, "author": "BBorNot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anvyd4/how_to_see_thumbnails_of_all_pictures_in_a_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anvyd4/how_to_see_thumbnails_of_all_pictures_in_a_file/", "subreddit_subscribers": 732365, "created_utc": 1707614466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's out of another machine because I thought there were network issues, things were copying extremely slowly.  But it persists in a ssd dock.  I don't need hd sentinel installed on the machine it's running in to show such errors, do I?  I have no idea what could be wrong.  The machine is a 2013 dell, so it would support trim...  \n\n\nEDIT: machine was in raid mode instead of ahci, possibly ever since I installed windows on this machine.  Could that have done it?", "author_fullname": "t2_ubnt8yve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial bx500 ssd down to 91% health after four days total uptime, but no hd sentinel errors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ano129", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707594837.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707592869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s out of another machine because I thought there were network issues, things were copying extremely slowly.  But it persists in a ssd dock.  I don&amp;#39;t need hd sentinel installed on the machine it&amp;#39;s running in to show such errors, do I?  I have no idea what could be wrong.  The machine is a 2013 dell, so it would support trim...  &lt;/p&gt;\n\n&lt;p&gt;EDIT: machine was in raid mode instead of ahci, possibly ever since I installed windows on this machine.  Could that have done it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ano129", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Introduction5124", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ano129/crucial_bx500_ssd_down_to_91_health_after_four/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ano129/crucial_bx500_ssd_down_to_91_health_after_four/", "subreddit_subscribers": 732365, "created_utc": 1707592869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,  \nI have setup with mergerfs and snapraid in proxmox  \nsda 16TB - data  \nsdb 16TB - parity  \nsdc 4TB - data  \nsdd 4TB - data  \nthey are pooled into 20TB drive in /srv/pool/ then mountpoint set into fileserver CT and shared over SMB for my win workstation  \n\n\nI am running proxmox host on 1TB NVME drive, manually doing root clonezilla mirrors into external hdd once a month (not that much of data changes tho)  \nI got 10Gig network, I wanted to make things faster, maybe even reduce number of spinups for HDDs while using recent data when it's \"hot\" and leave eg movies or music I hoard there as \"cold\".  \n\n\nWhat are the options available?  \nGiven my proxmox doesn't need all 1TB and I moved it off from 120GB NVME, can I split Proxmox to use like 300GB and the remaining \\~700GB to be used for some sort of tiered cache? I don't really care much about wear of the NVME.\n\n&amp;#x200B;", "author_fullname": "t2_hty63", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4x HDD + 1x SSD mergerfs snapraid, how to get tiered cache to work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anh8to", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707574460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nI have setup with mergerfs and snapraid in proxmox&lt;br/&gt;\nsda 16TB - data&lt;br/&gt;\nsdb 16TB - parity&lt;br/&gt;\nsdc 4TB - data&lt;br/&gt;\nsdd 4TB - data&lt;br/&gt;\nthey are pooled into 20TB drive in /srv/pool/ then mountpoint set into fileserver CT and shared over SMB for my win workstation  &lt;/p&gt;\n\n&lt;p&gt;I am running proxmox host on 1TB NVME drive, manually doing root clonezilla mirrors into external hdd once a month (not that much of data changes tho)&lt;br/&gt;\nI got 10Gig network, I wanted to make things faster, maybe even reduce number of spinups for HDDs while using recent data when it&amp;#39;s &amp;quot;hot&amp;quot; and leave eg movies or music I hoard there as &amp;quot;cold&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;What are the options available?&lt;br/&gt;\nGiven my proxmox doesn&amp;#39;t need all 1TB and I moved it off from 120GB NVME, can I split Proxmox to use like 300GB and the remaining ~700GB to be used for some sort of tiered cache? I don&amp;#39;t really care much about wear of the NVME.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anh8to", "is_robot_indexable": true, "report_reasons": null, "author": "xmesaj2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anh8to/4x_hdd_1x_ssd_mergerfs_snapraid_how_to_get_tiered/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anh8to/4x_hdd_1x_ssd_mergerfs_snapraid_how_to_get_tiered/", "subreddit_subscribers": 732365, "created_utc": 1707574460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a couple drives from SPD a month ago after reading rave reviews about them here. I chose FedEx shipping and emailed FedEx saying I would like to self-clear the package when it crosses the border to avoid paying double for their brokerage fee. The FedEx rep made up some BS excuse saying I can't do that because the package crosses at a point of entry in a different province, which I'm pretty sure is BS because I have a CBSA inland office at my local airport and I should be able to self-clear by law. Anyways, they offered a \"one-time\" credit to the brokerage fee so I would only have to pay tax. So all fine and dandy.\n\nA few days ago one of the drives started failing the snapraid sync. And smart tests were throwing errors. I posted about it asking help here yesterday, but mods deleted my post. One helpful commenter did help interpret my results and said my drive should be fine. Well today's smart test went from 40 reallocated sectors to 2000. So pretty sure drive is fucked.\n\nI went to SPD to grab a couple more drives so that I could hopefully transfer my data before it's completely fried and then do the RMA. But at the checkout, the only option now for shipping is \"Duties &amp; Taxes Included\". I get that this is a good option for those that don't want to get the unexpected bill later in the mail from FedEx and co., but this basically forces me to pay the shipper's brokerage fees which sucks. Computers are duty-exempt, so I should only expect to pay taxes.\n\nFor my total CAD $431.61 I should expect to pay CAD $47.48 taxes. SPD at checkout asks me to pay CAD $63.41 for \"duty and tax\". I get that it's not a crazy amount higher, but if I was using a different shipping option, the duty and tax goes all the way up to CAD $145.16!\n\nWhat gives, /u/ServerPartDeals? Could we at least have the option back to pay duty/tax ourselves? I am sure this will be more convenient for some people, but we shouldn't be forced to pay brokerage fees.", "author_fullname": "t2_40crn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverpartdeals USA &gt; CAN now forces included duty/tax with shipping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ao5q1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707650109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a couple drives from SPD a month ago after reading rave reviews about them here. I chose FedEx shipping and emailed FedEx saying I would like to self-clear the package when it crosses the border to avoid paying double for their brokerage fee. The FedEx rep made up some BS excuse saying I can&amp;#39;t do that because the package crosses at a point of entry in a different province, which I&amp;#39;m pretty sure is BS because I have a CBSA inland office at my local airport and I should be able to self-clear by law. Anyways, they offered a &amp;quot;one-time&amp;quot; credit to the brokerage fee so I would only have to pay tax. So all fine and dandy.&lt;/p&gt;\n\n&lt;p&gt;A few days ago one of the drives started failing the snapraid sync. And smart tests were throwing errors. I posted about it asking help here yesterday, but mods deleted my post. One helpful commenter did help interpret my results and said my drive should be fine. Well today&amp;#39;s smart test went from 40 reallocated sectors to 2000. So pretty sure drive is fucked.&lt;/p&gt;\n\n&lt;p&gt;I went to SPD to grab a couple more drives so that I could hopefully transfer my data before it&amp;#39;s completely fried and then do the RMA. But at the checkout, the only option now for shipping is &amp;quot;Duties &amp;amp; Taxes Included&amp;quot;. I get that this is a good option for those that don&amp;#39;t want to get the unexpected bill later in the mail from FedEx and co., but this basically forces me to pay the shipper&amp;#39;s brokerage fees which sucks. Computers are duty-exempt, so I should only expect to pay taxes.&lt;/p&gt;\n\n&lt;p&gt;For my total CAD $431.61 I should expect to pay CAD $47.48 taxes. SPD at checkout asks me to pay CAD $63.41 for &amp;quot;duty and tax&amp;quot;. I get that it&amp;#39;s not a crazy amount higher, but if I was using a different shipping option, the duty and tax goes all the way up to CAD $145.16!&lt;/p&gt;\n\n&lt;p&gt;What gives, &lt;a href=\"/u/ServerPartDeals\"&gt;/u/ServerPartDeals&lt;/a&gt;? Could we at least have the option back to pay duty/tax ourselves? I am sure this will be more convenient for some people, but we shouldn&amp;#39;t be forced to pay brokerage fees.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ao5q1d", "is_robot_indexable": true, "report_reasons": null, "author": "stenzor", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao5q1d/serverpartdeals_usa_can_now_forces_included/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao5q1d/serverpartdeals_usa_can_now_forces_included/", "subreddit_subscribers": 732365, "created_utc": 1707650109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": ".", "author_fullname": "t2_5t2soh4f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What apps do you use for saving Instagram Stories on android/iphone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao2vk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707638271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao2vk2", "is_robot_indexable": true, "report_reasons": null, "author": "ContPosts", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao2vk2/what_apps_do_you_use_for_saving_instagram_stories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao2vk2/what_apps_do_you_use_for_saving_instagram_stories/", "subreddit_subscribers": 732365, "created_utc": 1707638271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a really old NexStar HX4R 4 bay usb 3.0 raid enclosure.  It's finally decided to die on me,\n\nIt's hooked up to a pc with an AMD Ryzen 5 2600 cpu in asrock B450M Pro4 16GB in an matx case (no room for 4 drives).  Running OMV for the OS.\n\nI would like to replace it with something very similar.   Here's my list of requirements: since I have a very limited budget\n\n* must be usb a or c. (not interested in a NAS right now).  My MB has usb-c, so that would be the better option.\n* Can be software or hardware raid (but I'd prefer hardware raid)\n* Can be rackmount or standalone\n\nI realize my requirements limit my choices, but I'd just like to get my best device for those options.\n\nThanks!", "author_fullname": "t2_m65zl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "my vantec NexStar HX4R finally died", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anwoa4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707616692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a really old NexStar HX4R 4 bay usb 3.0 raid enclosure.  It&amp;#39;s finally decided to die on me,&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s hooked up to a pc with an AMD Ryzen 5 2600 cpu in asrock B450M Pro4 16GB in an matx case (no room for 4 drives).  Running OMV for the OS.&lt;/p&gt;\n\n&lt;p&gt;I would like to replace it with something very similar.   Here&amp;#39;s my list of requirements: since I have a very limited budget&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;must be usb a or c. (not interested in a NAS right now).  My MB has usb-c, so that would be the better option.&lt;/li&gt;\n&lt;li&gt;Can be software or hardware raid (but I&amp;#39;d prefer hardware raid)&lt;/li&gt;\n&lt;li&gt;Can be rackmount or standalone&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I realize my requirements limit my choices, but I&amp;#39;d just like to get my best device for those options.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anwoa4", "is_robot_indexable": true, "report_reasons": null, "author": "ogg1e", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anwoa4/my_vantec_nexstar_hx4r_finally_died/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anwoa4/my_vantec_nexstar_hx4r_finally_died/", "subreddit_subscribers": 732365, "created_utc": 1707616692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys. New here and I think I have a fairly unique question. \n\nI have lectures for my classes. It\u2019s an online class that uses canvas. The videos are not downloadable from what I can tell. So how can I get this downloaded?", "author_fullname": "t2_3d9kn0k6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download Lecture From Canvas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anu849", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. New here and I think I have a fairly unique question. &lt;/p&gt;\n\n&lt;p&gt;I have lectures for my classes. It\u2019s an online class that uses canvas. The videos are not downloadable from what I can tell. So how can I get this downloaded?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anu849", "is_robot_indexable": true, "report_reasons": null, "author": "bstillab", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anu849/download_lecture_from_canvas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anu849/download_lecture_from_canvas/", "subreddit_subscribers": 732365, "created_utc": 1707609525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a list of topics in the following format: \"TOPIC NAME - https://xxx.xxx\".\n\nTopic titles are in French (there are 1000 of them)\n\nI'd like to keep only those related to technology and computing.\n\nHowever, filtering by keyword is not at all efficient.\n\nIs there an AI script that would work better? \n\nHere's an example of title:\n\n\"\\[TUTO\\] Securing your home network with a Raspberry Pi Firewall: https://www.xxx.xxx\"", "author_fullname": "t2_40h537oa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to classify a list of topics by theme with AI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ankbry", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707583095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a list of topics in the following format: &amp;quot;TOPIC NAME - &lt;a href=\"https://xxx.xxx\"&gt;https://xxx.xxx&lt;/a&gt;&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Topic titles are in French (there are 1000 of them)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to keep only those related to technology and computing.&lt;/p&gt;\n\n&lt;p&gt;However, filtering by keyword is not at all efficient.&lt;/p&gt;\n\n&lt;p&gt;Is there an AI script that would work better? &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an example of title:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;[TUTO] Securing your home network with a Raspberry Pi Firewall: &lt;a href=\"https://www.xxx.xxx\"&gt;https://www.xxx.xxx&lt;/a&gt;&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?auto=webp&amp;s=409b44003b061edd963030142265b9158d818126", "width": 1148, "height": 467}, "resolutions": [{"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8648cd22c51e3066b51e0151a3215e100394c693", "width": 108, "height": 43}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e6b13fff6dfaaae3dafde5db5427826916730da", "width": 216, "height": 87}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43b30ae498222d331345a71fb7ece0730871cc3d", "width": 320, "height": 130}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e799986951824243e277cd0e7df710dc0885c59", "width": 640, "height": 260}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1a55b4c6381cd4cebaaf5f61030964f89ff76e6", "width": 960, "height": 390}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=df496e2be405fa613938916237b080a53765f338", "width": 1080, "height": 439}], "variants": {}, "id": "D5rzZ8mAeUGjSM-jHkVVMuBs1eusBLLGW_U-ElbBkV0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ankbry", "is_robot_indexable": true, "report_reasons": null, "author": "clara59000", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ankbry/is_it_possible_to_classify_a_list_of_topics_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ankbry/is_it_possible_to_classify_a_list_of_topics_by/", "subreddit_subscribers": 732365, "created_utc": 1707583095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey,\n\nI am having trouble loading a deleted, but archived youtube video and I also can't download it using yt-dlp([https://web.archive.org/web/20181006071539/https://www.youtube.com/watch?v=ENxxnKnq\\_1Q](https://web.archive.org/web/20181006071539/https://www.youtube.com/watch?v=ENxxnKnq_1Q)).\n\nI know that the video is really old, but sometimes when I refresh the page it displays 00:00 / 32:08 in the youtube UI.\n\nIs this salvageable or not? I might just be stupid and doing something wrong.", "author_fullname": "t2_af4i2bzd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "problem loading video from the wayback machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anisun", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707578958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I am having trouble loading a deleted, but archived youtube video and I also can&amp;#39;t download it using yt-dlp(&lt;a href=\"https://web.archive.org/web/20181006071539/https://www.youtube.com/watch?v=ENxxnKnq_1Q\"&gt;https://web.archive.org/web/20181006071539/https://www.youtube.com/watch?v=ENxxnKnq_1Q&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;I know that the video is really old, but sometimes when I refresh the page it displays 00:00 / 32:08 in the youtube UI.&lt;/p&gt;\n\n&lt;p&gt;Is this salvageable or not? I might just be stupid and doing something wrong.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anisun", "is_robot_indexable": true, "report_reasons": null, "author": "Neimod", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anisun/problem_loading_video_from_the_wayback_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anisun/problem_loading_video_from_the_wayback_machine/", "subreddit_subscribers": 732365, "created_utc": 1707578958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A live stream was made on 2/6/2024 (4 days ago). So it is very fresh. It was privated on the same day it was streamed because something very, very juicy happened during the stream. And I want to see. However it's not on Internet Archive, and as far as I can tell no one decided to clip or download the stream and post it anywhere before it was private. This is the URL ( [YouTube](https://www.youtube.com/watch?v=hvn4TcFuD-8)) Oddly enough, I search the title on the internet and the video pops up in the results, but still can't watch it. So I know it still exists, just untouchable.", "author_fullname": "t2_ty5ruvsip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do when a video was private before anyone could archive it on the Internet Archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anyuth", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707623652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A live stream was made on 2/6/2024 (4 days ago). So it is very fresh. It was privated on the same day it was streamed because something very, very juicy happened during the stream. And I want to see. However it&amp;#39;s not on Internet Archive, and as far as I can tell no one decided to clip or download the stream and post it anywhere before it was private. This is the URL ( &lt;a href=\"https://www.youtube.com/watch?v=hvn4TcFuD-8\"&gt;YouTube&lt;/a&gt;) Oddly enough, I search the title on the internet and the video pops up in the results, but still can&amp;#39;t watch it. So I know it still exists, just untouchable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anyuth", "is_robot_indexable": true, "report_reasons": null, "author": "0KonKon0", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anyuth/what_to_do_when_a_video_was_private_before_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anyuth/what_to_do_when_a_video_was_private_before_anyone/", "subreddit_subscribers": 732365, "created_utc": 1707623652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! Apologies in advance, I did a lot of searching and tried what I could get to work myself before coming here to ask. I truly did my best, but I think a lot of it just flew it over my head.\n\nI'm trying to archive [this show](https://www.raiplay.it/video/2024/01/Sanremo-2024-74-Festival-della-Canzone-Italiana-Quarta-Serata-del-09022024-4cf62ab0-8200-4fbc-aa63-208fe874b971.html) that was broadcast live.\n\nI'm using youtube-dl to download other content from the same website. I use the Stacher frontend as I'm not too good with command lines. However, it throws an \"http error 403: forbidden\" error on that one, because it's actually an HLS stream.\n\nJDownloader2 can't download it either, it finds the files to be \"offline\".\n\nVideo DownloadHelper worked like a charm when using the dodgy \"assistant\"... then left me with a qr code on the video and just informed me that next time I better buy the premium version. Great.\n\nWith the \"[Live Stream Downloader](https://addons.mozilla.org/en-US/firefox/addon/live-stream-downloader/)\" extension I was able to download an .mkv of the show, but it's only video, no audio.\n\nI was recommended \"PastyLink\" but it's a bit dodgy, wants me to use its own downloader, and still throws in an error.\n\nApologies again if this is a well known thing. It's the first time I've encountered this format and I don't know what else to try. I think if all else fails I could learn how to mix up the video from the LiveStreamDownloader and the audio from the VideoDownloadHelper, but it doesn't seem like the best solution in the long run. Any better suggestion helps, thank you!", "author_fullname": "t2_k1cbdayg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with archiving an HLS video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ann21a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707590286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Apologies in advance, I did a lot of searching and tried what I could get to work myself before coming here to ask. I truly did my best, but I think a lot of it just flew it over my head.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to archive &lt;a href=\"https://www.raiplay.it/video/2024/01/Sanremo-2024-74-Festival-della-Canzone-Italiana-Quarta-Serata-del-09022024-4cf62ab0-8200-4fbc-aa63-208fe874b971.html\"&gt;this show&lt;/a&gt; that was broadcast live.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using youtube-dl to download other content from the same website. I use the Stacher frontend as I&amp;#39;m not too good with command lines. However, it throws an &amp;quot;http error 403: forbidden&amp;quot; error on that one, because it&amp;#39;s actually an HLS stream.&lt;/p&gt;\n\n&lt;p&gt;JDownloader2 can&amp;#39;t download it either, it finds the files to be &amp;quot;offline&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Video DownloadHelper worked like a charm when using the dodgy &amp;quot;assistant&amp;quot;... then left me with a qr code on the video and just informed me that next time I better buy the premium version. Great.&lt;/p&gt;\n\n&lt;p&gt;With the &amp;quot;&lt;a href=\"https://addons.mozilla.org/en-US/firefox/addon/live-stream-downloader/\"&gt;Live Stream Downloader&lt;/a&gt;&amp;quot; extension I was able to download an .mkv of the show, but it&amp;#39;s only video, no audio.&lt;/p&gt;\n\n&lt;p&gt;I was recommended &amp;quot;PastyLink&amp;quot; but it&amp;#39;s a bit dodgy, wants me to use its own downloader, and still throws in an error.&lt;/p&gt;\n\n&lt;p&gt;Apologies again if this is a well known thing. It&amp;#39;s the first time I&amp;#39;ve encountered this format and I don&amp;#39;t know what else to try. I think if all else fails I could learn how to mix up the video from the LiveStreamDownloader and the audio from the VideoDownloadHelper, but it doesn&amp;#39;t seem like the best solution in the long run. Any better suggestion helps, thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?auto=webp&amp;s=06b09d2520549672271645e9a69d3f612da08459", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f740ed2ac4dd8ae2fa7d6fd3087f40fa99fb342", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77908398a6722c5e9e86ab97350b36bf59eed2ca", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d67f48cd56273b92ab368691710106aa7662f6da", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=28ca7cf8f66254e6d3e60782f8e36e7d250388c9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=46df66ac966757b817e231489a18a7180503aaf7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bb7f7acacb7349770b053685511ab3036d98c1fe", "width": 1080, "height": 540}], "variants": {}, "id": "tRBsavIMz99JPesZZlaCIRweMO5iuJS7AFJEIbAB_yo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ann21a", "is_robot_indexable": true, "report_reasons": null, "author": "annapigna", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ann21a/help_with_archiving_an_hls_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ann21a/help_with_archiving_an_hls_video/", "subreddit_subscribers": 732365, "created_utc": 1707590286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "or forums that contain:\n\nlots of nice stuff, discussion, etc.", "author_fullname": "t2_6ilbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any forums where people talk about datahoarding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anvuy5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707614190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;or forums that contain:&lt;/p&gt;\n\n&lt;p&gt;lots of nice stuff, discussion, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anvuy5", "is_robot_indexable": true, "report_reasons": null, "author": "zuperfly", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anvuy5/are_there_any_forums_where_people_talk_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anvuy5/are_there_any_forums_where_people_talk_about/", "subreddit_subscribers": 732365, "created_utc": 1707614190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A relative recently died and in cleaning out their estate I've come across about 20 different editions of \"Band in a Box\" which are all on 2.5\"hdd and range from about 150gb to 225gb from the few I've taken apart so far. I plan on shucking them all and formating them all &amp; dividing them into 2 close to equal amounts of storage space to make 2 separate storage units out of them (each one itself would be split into an original and an on-site backup). One would be for me and one would be for my wife, mainly pictures and some wannabe YouTube content creator stuff. \n\n\nNot sure if I want to go the NAS or DAS route, we dont really need access to it from anything other than our own computers which points to DAS but it would be nice to be able to access stuff across them from eachothers computer incase we want to help eachother edit or anything which leans more towards NAS. \n\n\nI did get a couple of windows media center PCs (I think 2 are XP and 1 is Me or Vista or some combination thereof) out of this that I might be able to scavage parts from to homebrew something but I'm kinda thinking I'd just like to build 2 identical new setups instead. \n\n\nI guess TLDR is I got a bunch of drives for free that I want to turn into easily usable storage, be it acting like a giant external drive or be it acting like a storage server, point me in the right direction to get going please.", "author_fullname": "t2_64hhaufy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DIY storage setup, planning stages.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anugly", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707610176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A relative recently died and in cleaning out their estate I&amp;#39;ve come across about 20 different editions of &amp;quot;Band in a Box&amp;quot; which are all on 2.5&amp;quot;hdd and range from about 150gb to 225gb from the few I&amp;#39;ve taken apart so far. I plan on shucking them all and formating them all &amp;amp; dividing them into 2 close to equal amounts of storage space to make 2 separate storage units out of them (each one itself would be split into an original and an on-site backup). One would be for me and one would be for my wife, mainly pictures and some wannabe YouTube content creator stuff. &lt;/p&gt;\n\n&lt;p&gt;Not sure if I want to go the NAS or DAS route, we dont really need access to it from anything other than our own computers which points to DAS but it would be nice to be able to access stuff across them from eachothers computer incase we want to help eachother edit or anything which leans more towards NAS. &lt;/p&gt;\n\n&lt;p&gt;I did get a couple of windows media center PCs (I think 2 are XP and 1 is Me or Vista or some combination thereof) out of this that I might be able to scavage parts from to homebrew something but I&amp;#39;m kinda thinking I&amp;#39;d just like to build 2 identical new setups instead. &lt;/p&gt;\n\n&lt;p&gt;I guess TLDR is I got a bunch of drives for free that I want to turn into easily usable storage, be it acting like a giant external drive or be it acting like a storage server, point me in the right direction to get going please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anugly", "is_robot_indexable": true, "report_reasons": null, "author": "VKN_x_Media", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anugly/diy_storage_setup_planning_stages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anugly/diy_storage_setup_planning_stages/", "subreddit_subscribers": 732365, "created_utc": 1707610176.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}