{"kind": "Listing", "data": {"after": "t3_1ao5q1d", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When i was Torrenting yesterday i Stumbled apon the files to the Daft Punk DVD **D.A.F.T. - A Story About Dogs, Androids, Firemen and Tomatoes** i was thinking of uploading it to archive.org but I'm not sure if that is legal and I don't want to get in trouble", "author_fullname": "t2_e27dm3jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is uploading a out of print DVD to archive.org Legal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anwdbh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 105, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 105, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707615733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When i was Torrenting yesterday i Stumbled apon the files to the Daft Punk DVD &lt;strong&gt;D.A.F.T. - A Story About Dogs, Androids, Firemen and Tomatoes&lt;/strong&gt; i was thinking of uploading it to archive.org but I&amp;#39;m not sure if that is legal and I don&amp;#39;t want to get in trouble&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anwdbh", "is_robot_indexable": true, "report_reasons": null, "author": "StevenIsCool2004", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anwdbh/is_uploading_a_out_of_print_dvd_to_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anwdbh/is_uploading_a_out_of_print_dvd_to_archiveorg/", "subreddit_subscribers": 732465, "created_utc": 1707615733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_19chrnag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good to know I am not alone.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao8tdk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 141, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 141, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xE0TMPiPaO8GbRMT0UAw24EOudVncsRy4v6FYk3hfAA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707660703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0dxp6yruryhc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0dxp6yruryhc1.png?auto=webp&amp;s=b66b19fe8db9f945f80a80efc5d515e166ffbe33", "width": 617, "height": 606}, "resolutions": [{"url": "https://preview.redd.it/0dxp6yruryhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a595c28bf067d62b62090d35433f408a1c534f43", "width": 108, "height": 106}, {"url": "https://preview.redd.it/0dxp6yruryhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb54cc4b5218e5d748dbdd599568c29bdcff23a4", "width": 216, "height": 212}, {"url": "https://preview.redd.it/0dxp6yruryhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=15e5c8353d78fba8c5687a56ea9a07ad18848c0a", "width": 320, "height": 314}], "variants": {}, "id": "6tw3Qmec8MxxuE5FD2rwWL4UhqzBatOO0OPGenmmlig"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao8tdk", "is_robot_indexable": true, "report_reasons": null, "author": "Bastion80", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao8tdk/good_to_know_i_am_not_alone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/0dxp6yruryhc1.png", "subreddit_subscribers": 732465, "created_utc": 1707660703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for anyone who has an archive for the Marching Arts for BOA/Grand Nationals/local circuits etc....  I already have a huge drafted archive for DCI that's over 2TB from judges tapes to HQ Blurays.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The reason I want to do this is because unfortunately due to the terrible system that is music copyright laws, neither Flomarching, the event holder, or the band performing get maximum quality videos. Flomarching does allow you to watch their streams after the fact, but they are legally required to not save any of the audio. This means that the performers (or anyone else) cannot enjoy their to the full potential if they don't want to rely on bad phone recorded videos with peoples heads blocking or if they actually want to hear the music they played.                                       ", "author_fullname": "t2_9woubj41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone hoarding marching band videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anv48v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707612054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for anyone who has an archive for the Marching Arts for BOA/Grand Nationals/local circuits etc....  I already have a huge drafted archive for DCI that&amp;#39;s over 2TB from judges tapes to HQ Blurays.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The reason I want to do this is because unfortunately due to the terrible system that is music copyright laws, neither Flomarching, the event holder, or the band performing get maximum quality videos. Flomarching does allow you to watch their streams after the fact, but they are legally required to not save any of the audio. This means that the performers (or anyone else) cannot enjoy their to the full potential if they don&amp;#39;t want to rely on bad phone recorded videos with peoples heads blocking or if they actually want to hear the music they played.                                       &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anv48v", "is_robot_indexable": true, "report_reasons": null, "author": "Roleplex0", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anv48v/anyone_hoarding_marching_band_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anv48v/anyone_hoarding_marching_band_videos/", "subreddit_subscribers": 732465, "created_utc": 1707612054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm aware of archivebox but I'm wondering if there are other new tools that also archive web pages you visit? The last time I tried doing this was in 2012.", "author_fullname": "t2_4ph16ic4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools to archive visited web pages locally in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anopqc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707594675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m aware of archivebox but I&amp;#39;m wondering if there are other new tools that also archive web pages you visit? The last time I tried doing this was in 2012.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anopqc", "is_robot_indexable": true, "report_reasons": null, "author": "A9to5robot", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anopqc/tools_to_archive_visited_web_pages_locally_in_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anopqc/tools_to_archive_visited_web_pages_locally_in_2024/", "subreddit_subscribers": 732465, "created_utc": 1707594675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My TrueNAS Mini XL+ died the other day. No network, no connection over VGA. Looking into it, it seems relatively common. Anyway, getting in there I've decided I don't really want to continue using it anyway...\n\nThe TrueNAS Mini XL+ is fully populated with 8 HDDs. Next to that system I have a system that is running ZFS (no FreeNAS, etc, just Linux+ZFS) with the following hardware specs:\n\n* Fractal Design 7 (not xl, mid-tower, 8 bay model)\n* Gigabyte Z390 AORUS ULTRA-CF Motherboard\n* Intel i9-9900K\n* NVIDIA Corporation GP106GL [Quadro P2200]\n* 16GB memory (2x8GB Corsair CMK16GX4M2B3200C16 DIMMs)\n\nI'm thinking of either moving everything (all drives in TrueNAS Mini XL + all components in the Fractal Design 7 case) into a Fractal Design Meshify 2 XL case (all 16 drives); or, alternatively, I get a 2nd system and move everything from the TrueNAS case into the 2nd system.\n\nQuestions\n\n* Will I be able to simply migrate the pool from the TrueNAS into the new system w.o data loss? All HDDs are perfectly fine. I would assume this process should be just add a 2nd pool and everything is good, but not sure. Is this process more difficult if moving the drives into a system with an already existing ZFS pool?\n\n* In my situation would you buy a 2nd system, or move everything into a larger case? I just don't want to spend a bunch of money unnecessarily on another mobo/power supply/cpu/etc, especially if I can just move it into a larger case and have both ZFS pools running alongside each other. What are the pros/cons of these 2 scenarios?\n\nI am using the Fractal Design system as a Plex server. So now it would be a Plex server with 8 extra drives, beyond the 8 it already has.", "author_fullname": "t2_k7b5nyn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My TrueNAS Mini died. I have some questions regarding different paths I can take here.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao3cvy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707640272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My TrueNAS Mini XL+ died the other day. No network, no connection over VGA. Looking into it, it seems relatively common. Anyway, getting in there I&amp;#39;ve decided I don&amp;#39;t really want to continue using it anyway...&lt;/p&gt;\n\n&lt;p&gt;The TrueNAS Mini XL+ is fully populated with 8 HDDs. Next to that system I have a system that is running ZFS (no FreeNAS, etc, just Linux+ZFS) with the following hardware specs:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fractal Design 7 (not xl, mid-tower, 8 bay model)&lt;/li&gt;\n&lt;li&gt;Gigabyte Z390 AORUS ULTRA-CF Motherboard&lt;/li&gt;\n&lt;li&gt;Intel i9-9900K&lt;/li&gt;\n&lt;li&gt;NVIDIA Corporation GP106GL [Quadro P2200]&lt;/li&gt;\n&lt;li&gt;16GB memory (2x8GB Corsair CMK16GX4M2B3200C16 DIMMs)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of either moving everything (all drives in TrueNAS Mini XL + all components in the Fractal Design 7 case) into a Fractal Design Meshify 2 XL case (all 16 drives); or, alternatively, I get a 2nd system and move everything from the TrueNAS case into the 2nd system.&lt;/p&gt;\n\n&lt;p&gt;Questions&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Will I be able to simply migrate the pool from the TrueNAS into the new system w.o data loss? All HDDs are perfectly fine. I would assume this process should be just add a 2nd pool and everything is good, but not sure. Is this process more difficult if moving the drives into a system with an already existing ZFS pool?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In my situation would you buy a 2nd system, or move everything into a larger case? I just don&amp;#39;t want to spend a bunch of money unnecessarily on another mobo/power supply/cpu/etc, especially if I can just move it into a larger case and have both ZFS pools running alongside each other. What are the pros/cons of these 2 scenarios?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am using the Fractal Design system as a Plex server. So now it would be a Plex server with 8 extra drives, beyond the 8 it already has.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao3cvy", "is_robot_indexable": true, "report_reasons": null, "author": "retsuko_h4x", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao3cvy/my_truenas_mini_died_i_have_some_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao3cvy/my_truenas_mini_died_i_have_some_questions/", "subreddit_subscribers": 732465, "created_utc": 1707640272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a computer with 3 1TB disks. All the disks have photos randomly strewn about the directory structure on the drives. Most have random filenames (game screnshots, photos of projects I've made, electrical schematics, photos of vehicles, old TVs, ect.)\n\nWhat's the best program I can use to find duplicates, and hopefully consolidate all the photos to one location?\n\nEdit: I'm on windows, so any tools would have to work on windows.", "author_fullname": "t2_ky0ji79zj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a way to find duplicate photos on multiple drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anjpwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707581429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a computer with 3 1TB disks. All the disks have photos randomly strewn about the directory structure on the drives. Most have random filenames (game screnshots, photos of projects I&amp;#39;ve made, electrical schematics, photos of vehicles, old TVs, ect.)&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best program I can use to find duplicates, and hopefully consolidate all the photos to one location?&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m on windows, so any tools would have to work on windows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anjpwf", "is_robot_indexable": true, "report_reasons": null, "author": "aspie_electrician", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anjpwf/looking_for_a_way_to_find_duplicate_photos_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anjpwf/looking_for_a_way_to_find_duplicate_photos_on/", "subreddit_subscribers": 732465, "created_utc": 1707581429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There was a thread about burned CD-DVD decay a few days ago. The topic of chemical decay was brought up and after seeing the price of an old cartridge game I wondered if they just bought what will be a hunk of plastic in a few years. Do you think video games collections will just disappear in the next ten years due to chemical decay ?", "author_fullname": "t2_qynmwhsd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "About video game collections", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao6wac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707654578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There was a thread about burned CD-DVD decay a few days ago. The topic of chemical decay was brought up and after seeing the price of an old cartridge game I wondered if they just bought what will be a hunk of plastic in a few years. Do you think video games collections will just disappear in the next ten years due to chemical decay ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao6wac", "is_robot_indexable": true, "report_reasons": null, "author": "Studious_Roll", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao6wac/about_video_game_collections/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao6wac/about_video_game_collections/", "subreddit_subscribers": 732465, "created_utc": 1707654578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have about 40TB to move from one server (old hardware raid 6) to a new server (zfs raidz2). I started the  process on one chunk ~3 TB and realized over my 1Gbit network this is going to take some time. \n\nI've moved around big chunks before but it was always within server ie raid array to raid array and it went pretty quick. Based on some rough calculations this is going to take like a month, which is fine I guess worst case..\n\nIs are there any lower cost solutions to moving this data? I'm going to guess probably not.\n\nEdit: I miscalculated, this will take a week, I'm going to just be patient.", "author_fullname": "t2_5s2jw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data migration old server -&gt; new", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anuc6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707615370.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 40TB to move from one server (old hardware raid 6) to a new server (zfs raidz2). I started the  process on one chunk ~3 TB and realized over my 1Gbit network this is going to take some time. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve moved around big chunks before but it was always within server ie raid array to raid array and it went pretty quick. Based on some rough calculations this is going to take like a month, which is fine I guess worst case..&lt;/p&gt;\n\n&lt;p&gt;Is are there any lower cost solutions to moving this data? I&amp;#39;m going to guess probably not.&lt;/p&gt;\n\n&lt;p&gt;Edit: I miscalculated, this will take a week, I&amp;#39;m going to just be patient.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anuc6f", "is_robot_indexable": true, "report_reasons": null, "author": "UACEENGR", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anuc6f/data_migration_old_server_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anuc6f/data_migration_old_server_new/", "subreddit_subscribers": 732465, "created_utc": 1707609828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an iPhone 13 and a MacBook Air. My goal is to move my photos/videos off my phone to (???) so that I can use Capcut to edit Youtube videos. I need the quality to stay the same. \n\nMy iPhone storage is now full at 200 GB, as is my MacBook Air space, it's all photos and videos, no apps, no additional data stored anywhere. \n\nWhat's my next step? ", "author_fullname": "t2_4vjnlv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Way to Clear Storage on iPhone (move Photos for Video Editing)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anu77j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an iPhone 13 and a MacBook Air. My goal is to move my photos/videos off my phone to (???) so that I can use Capcut to edit Youtube videos. I need the quality to stay the same. &lt;/p&gt;\n\n&lt;p&gt;My iPhone storage is now full at 200 GB, as is my MacBook Air space, it&amp;#39;s all photos and videos, no apps, no additional data stored anywhere. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s my next step? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anu77j", "is_robot_indexable": true, "report_reasons": null, "author": "BetweenOceans", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anu77j/best_way_to_clear_storage_on_iphone_move_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anu77j/best_way_to_clear_storage_on_iphone_move_photos/", "subreddit_subscribers": 732465, "created_utc": 1707609453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all! I'm in the process of copying the data from my 3 TB HDD (not my Windows drive) to my 8 TB HDD so that way I can have a bigger HDD to fit everything on at once. That of course is the original HDD used daily and not a backup. This data is years in the making and losing it would affect me in a way I'd never recover from.\n\nI've been trying to figure out my best choices for a 3-2-1 backup scheme. 3 copies (NOT including the original), 2 on-site and 1 off-site.\n\nI already have Backblaze Personal as one of my off-site backups for my Windows SSD and main storage HDD. I've been thinking of getting another cloud backup service just in case.\n\nAs for the physical backups, I'm thinking of implementing a Synology NAS with one or more drives and then an additional internal HDD or an external HDD. The issue with another internal HDD is if my PC suffers catastrophic damage, the original and the internal backup are probably toast. An external HDD would mitigate this as long as there isn't a physical disaster in my area.\n\nAre these good solutions? I'm also considering infrequent off-site physical backups like HDDs or tapes, but I've never worked with the latter.\n\nWhat is the best method (software, whatever) for actually PERFORMING the backups to each of my drives? Something that can backup incrementally for my day-to-day operations and then do full backups weekly and/or bi-weekly/monthly. Ideally, the same software can handle all of my backup drives.\n\nIdeally, I want full backups as frequently as I can get without the cost being too high. Obviously a lot of data constantly getting full backups would equal a crazy amount of storage. I'm getting close to 3 TB worth of data. \n\nI've never had extensive physical backups so I have no idea what the contents of each drive would look like, storing incremental and full backups at once; or the software that might be best suited for the task.\n\nI'm a noob at this so I apologize if some of the wording might come off as a little ignorant or simple. If anything sounds wrong and there's a better way to implement a backup solution based on the information I've provided, please correct me! Any and all help would be greatly appreciated. Thank you!", "author_fullname": "t2_10lg61vc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to create and manage backups in daily incremental and full weekly/bi-weekly/monthly intervals? Also looking into physical backup solutions.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aoafv9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707665181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! I&amp;#39;m in the process of copying the data from my 3 TB HDD (not my Windows drive) to my 8 TB HDD so that way I can have a bigger HDD to fit everything on at once. That of course is the original HDD used daily and not a backup. This data is years in the making and losing it would affect me in a way I&amp;#39;d never recover from.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to figure out my best choices for a 3-2-1 backup scheme. 3 copies (NOT including the original), 2 on-site and 1 off-site.&lt;/p&gt;\n\n&lt;p&gt;I already have Backblaze Personal as one of my off-site backups for my Windows SSD and main storage HDD. I&amp;#39;ve been thinking of getting another cloud backup service just in case.&lt;/p&gt;\n\n&lt;p&gt;As for the physical backups, I&amp;#39;m thinking of implementing a Synology NAS with one or more drives and then an additional internal HDD or an external HDD. The issue with another internal HDD is if my PC suffers catastrophic damage, the original and the internal backup are probably toast. An external HDD would mitigate this as long as there isn&amp;#39;t a physical disaster in my area.&lt;/p&gt;\n\n&lt;p&gt;Are these good solutions? I&amp;#39;m also considering infrequent off-site physical backups like HDDs or tapes, but I&amp;#39;ve never worked with the latter.&lt;/p&gt;\n\n&lt;p&gt;What is the best method (software, whatever) for actually PERFORMING the backups to each of my drives? Something that can backup incrementally for my day-to-day operations and then do full backups weekly and/or bi-weekly/monthly. Ideally, the same software can handle all of my backup drives.&lt;/p&gt;\n\n&lt;p&gt;Ideally, I want full backups as frequently as I can get without the cost being too high. Obviously a lot of data constantly getting full backups would equal a crazy amount of storage. I&amp;#39;m getting close to 3 TB worth of data. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve never had extensive physical backups so I have no idea what the contents of each drive would look like, storing incremental and full backups at once; or the software that might be best suited for the task.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a noob at this so I apologize if some of the wording might come off as a little ignorant or simple. If anything sounds wrong and there&amp;#39;s a better way to implement a backup solution based on the information I&amp;#39;ve provided, please correct me! Any and all help would be greatly appreciated. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aoafv9", "is_robot_indexable": true, "report_reasons": null, "author": "Fulyen", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1aoafv9/what_is_the_best_way_to_create_and_manage_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1aoafv9/what_is_the_best_way_to_create_and_manage_backups/", "subreddit_subscribers": 732465, "created_utc": 1707665181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I saw a post today from someone reading old discs in a scanning tool. I believe they said that 30 out of 300 old discs were bad (if those weren't the numbers let's use them anyway for the sake of simplicity).\n\nThat gives us a failure rate of 10%.\n\nNow let's assume that all those discs had been copied offsite and everything else is equal including the assumed failure rate of the media over this time period (10%).\n\nEach onsite disc has one corresponding offsite copy. Both sets of media are subject to a 10% failure rate. \n\nWhat's the probability that there will be one disc in that group which fails in both onsite and offsite (ie both the onsite and corresponding offsite duplicate end up unreadable)? \n\nAnd finally:\n\nAssuming the same assumptions and mathematics, how much would we derisk the approach if we were to store a THIRD copy of the data (ie, a second duplicate to the original. Let's imagine there's a second to offsite library). \n\nSame media. Same predicted failure rate. Everything else equal. \n\n? \n\nTIA!", "author_fullname": "t2_poc45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone help with a quick calculation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao7pw3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707657328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw a post today from someone reading old discs in a scanning tool. I believe they said that 30 out of 300 old discs were bad (if those weren&amp;#39;t the numbers let&amp;#39;s use them anyway for the sake of simplicity).&lt;/p&gt;\n\n&lt;p&gt;That gives us a failure rate of 10%.&lt;/p&gt;\n\n&lt;p&gt;Now let&amp;#39;s assume that all those discs had been copied offsite and everything else is equal including the assumed failure rate of the media over this time period (10%).&lt;/p&gt;\n\n&lt;p&gt;Each onsite disc has one corresponding offsite copy. Both sets of media are subject to a 10% failure rate. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the probability that there will be one disc in that group which fails in both onsite and offsite (ie both the onsite and corresponding offsite duplicate end up unreadable)? &lt;/p&gt;\n\n&lt;p&gt;And finally:&lt;/p&gt;\n\n&lt;p&gt;Assuming the same assumptions and mathematics, how much would we derisk the approach if we were to store a THIRD copy of the data (ie, a second duplicate to the original. Let&amp;#39;s imagine there&amp;#39;s a second to offsite library). &lt;/p&gt;\n\n&lt;p&gt;Same media. Same predicted failure rate. Everything else equal. &lt;/p&gt;\n\n&lt;p&gt;? &lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao7pw3", "is_robot_indexable": true, "report_reasons": null, "author": "danielrosehill", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao7pw3/can_anyone_help_with_a_quick_calculation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao7pw3/can_anyone_help_with_a_quick_calculation/", "subreddit_subscribers": 732465, "created_utc": 1707657328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First of all, this is my first post in this community, so apologies if I am missing something here.\n\nI would like to download the original files from  [archive.org](https://archive.org) video repositories using the official [python CLI interface](https://github.com/jjjake/internetarchive).\n\nThe issues is, I cannot find a switch in the [documentation](https://archive.org/developers/internetarchive/api.html#internetarchive.download) of the `download` function to do exactly that.\n\nFor example, running `download('maus-06-07-30', verbose=True, dry_run=True)` shows that I would be downloading both .mp4 and .avi files as well as .jpg thumbnails with it, which I do *not* want.\n\nYes, I could exclude .mp4 files and .jpg files using the `glob_pattern` or `formats` parameter, but that would mean, I would first need to find a way to determine programmatically which files are the originals and which aren't.\n\nCheers, Andr\u00e9", "author_fullname": "t2_1agysvjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download only original files from archive.org using official python script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao4b68", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707644256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, this is my first post in this community, so apologies if I am missing something here.&lt;/p&gt;\n\n&lt;p&gt;I would like to download the original files from  &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt; video repositories using the official &lt;a href=\"https://github.com/jjjake/internetarchive\"&gt;python CLI interface&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The issues is, I cannot find a switch in the &lt;a href=\"https://archive.org/developers/internetarchive/api.html#internetarchive.download\"&gt;documentation&lt;/a&gt; of the &lt;code&gt;download&lt;/code&gt; function to do exactly that.&lt;/p&gt;\n\n&lt;p&gt;For example, running &lt;code&gt;download(&amp;#39;maus-06-07-30&amp;#39;, verbose=True, dry_run=True)&lt;/code&gt; shows that I would be downloading both .mp4 and .avi files as well as .jpg thumbnails with it, which I do &lt;em&gt;not&lt;/em&gt; want.&lt;/p&gt;\n\n&lt;p&gt;Yes, I could exclude .mp4 files and .jpg files using the &lt;code&gt;glob_pattern&lt;/code&gt; or &lt;code&gt;formats&lt;/code&gt; parameter, but that would mean, I would first need to find a way to determine programmatically which files are the originals and which aren&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Cheers, Andr\u00e9&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao4b68", "is_robot_indexable": true, "report_reasons": null, "author": "TXAndre", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao4b68/download_only_original_files_from_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao4b68/download_only_original_files_from_archiveorg/", "subreddit_subscribers": 732465, "created_utc": 1707644256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I created a batch file to download multiple links from tumblr, and it downloaded almost all of the links, except for this one line:\n\n    gallery-dl \"https://www.tumblr.com/username/tagged/my%20art\" --mtime-from-date -o skip=true -D \"D:\\[Art]\\tumblr\\username\"\n\nWhen I ran this command manually by opening command prompt and pasting it in, it worked, but when I ran it by opening the .bat file this came up:\n\n    [tumblr][info] No results for https://www.tumblr.com/username/tagged/my0art\"\n\nI assume this was because that command contained the special character \"&amp;\" so the .bat file didn't work, but I'm not sure because I don't know anything about coding. If you have any explanation or advice on how to fix this, I'd really appreciate it!", "author_fullname": "t2_ielfpq9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I fix gallery-dl .bat file skipping link with special character", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anz2ma", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707624363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created a batch file to download multiple links from tumblr, and it downloaded almost all of the links, except for this one line:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gallery-dl &amp;quot;https://www.tumblr.com/username/tagged/my%20art&amp;quot; --mtime-from-date -o skip=true -D &amp;quot;D:\\[Art]\\tumblr\\username&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When I ran this command manually by opening command prompt and pasting it in, it worked, but when I ran it by opening the .bat file this came up:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[tumblr][info] No results for https://www.tumblr.com/username/tagged/my0art&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I assume this was because that command contained the special character &amp;quot;&amp;amp;&amp;quot; so the .bat file didn&amp;#39;t work, but I&amp;#39;m not sure because I don&amp;#39;t know anything about coding. If you have any explanation or advice on how to fix this, I&amp;#39;d really appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anz2ma", "is_robot_indexable": true, "report_reasons": null, "author": "freetousebyjtc", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anz2ma/how_do_i_fix_gallerydl_bat_file_skipping_link/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anz2ma/how_do_i_fix_gallerydl_bat_file_skipping_link/", "subreddit_subscribers": 732465, "created_utc": 1707624363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I changed over to Firefox in order to use Stacher to its best capacity, but when I finally thought that I would be able to download some embeded Patreon videos, I get an error message saying that there was no supported media found in that post...\n\n    Collecting video metadata...\n    Generated command line:\n    C:\\Users\\User\\.stacher/youtube-dl -f best --no-warnings --cookies-from-browser firefox --no-check-certificate -o ~/Downloads/%(upload_date)s_%(title)s.%(ext)s --username ***************** --password **********\n    https://www.patreon.com/posts/uncut-goblin-s1-63227887\n    Starting download...\n    Extracting cookies from firefox\n    Extracted 25 cookies from firefox\n    [Patreon] Extracting URL: https://www.patreon.com/posts/uncut-goblin-s1-63227887 [Patreon] 63227887: Downloading API JSON\n    ERROR: [Patreon] 63227887: No supported media found in this post\n\nHow the hell can I fix that error? Or is there no way to fix it?\n\nAlso, if so, are there any other frontends for yt-dlp that use the newest version of it that might work with an embeded patreon video?", "author_fullname": "t2_9ata9p94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stacher Patreon: no supported media ERROR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anxwfu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707620559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I changed over to Firefox in order to use Stacher to its best capacity, but when I finally thought that I would be able to download some embeded Patreon videos, I get an error message saying that there was no supported media found in that post...&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Collecting video metadata...\nGenerated command line:\nC:\\Users\\User\\.stacher/youtube-dl -f best --no-warnings --cookies-from-browser firefox --no-check-certificate -o ~/Downloads/%(upload_date)s_%(title)s.%(ext)s --username ***************** --password **********\nhttps://www.patreon.com/posts/uncut-goblin-s1-63227887\nStarting download...\nExtracting cookies from firefox\nExtracted 25 cookies from firefox\n[Patreon] Extracting URL: https://www.patreon.com/posts/uncut-goblin-s1-63227887 [Patreon] 63227887: Downloading API JSON\nERROR: [Patreon] 63227887: No supported media found in this post\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How the hell can I fix that error? Or is there no way to fix it?&lt;/p&gt;\n\n&lt;p&gt;Also, if so, are there any other frontends for yt-dlp that use the newest version of it that might work with an embeded patreon video?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anxwfu", "is_robot_indexable": true, "report_reasons": null, "author": "PadoruPadome", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anxwfu/stacher_patreon_no_supported_media_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anxwfu/stacher_patreon_no_supported_media_error/", "subreddit_subscribers": 732465, "created_utc": 1707620559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a file that has thousands of (mostly jpeg) images in it -- my computers swap backgrounds by pulling from this file randomly. Some of the images should be culled, but File Explorer doesn't show the thumbnails for a lot of the jpegs, so it is super hard to review. You have to click into each one, which is infuriating.\n\nHow can I force File Explorer to update the jpegs? Do I need to use a different program?", "author_fullname": "t2_cwfuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to see thumbnails of all pictures in a file of thousands of them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anvyd4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707614466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a file that has thousands of (mostly jpeg) images in it -- my computers swap backgrounds by pulling from this file randomly. Some of the images should be culled, but File Explorer doesn&amp;#39;t show the thumbnails for a lot of the jpegs, so it is super hard to review. You have to click into each one, which is infuriating.&lt;/p&gt;\n\n&lt;p&gt;How can I force File Explorer to update the jpegs? Do I need to use a different program?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anvyd4", "is_robot_indexable": true, "report_reasons": null, "author": "BBorNot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anvyd4/how_to_see_thumbnails_of_all_pictures_in_a_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anvyd4/how_to_see_thumbnails_of_all_pictures_in_a_file/", "subreddit_subscribers": 732465, "created_utc": 1707614466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, i used my 1 TB External HDD to update my samsung TV, after that it decided to split up in two partitions and not work at all (it can\u2019t transfer in or out, but it displays all the files inside). Now i\u2019m formatting it via the disk manager on windows 11.\nI\u2019ve already done that twice but it still doesn\u2019t work, any advice?", "author_fullname": "t2_bcb53zvd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Broke HDD after updating Samsung TV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_1aob0um", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nrccFhrheQD9vYqGBG-xyAd7Qjp49dtAbIFeG4l53QY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707666702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, i used my 1 TB External HDD to update my samsung TV, after that it decided to split up in two partitions and not work at all (it can\u2019t transfer in or out, but it displays all the files inside). Now i\u2019m formatting it via the disk manager on windows 11.\nI\u2019ve already done that twice but it still doesn\u2019t work, any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/a73qzy6r9zhc1.jpeg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/a73qzy6r9zhc1.jpeg?auto=webp&amp;s=14fc8abf10ca6fb0be3bbfc6d2fe2669723e125a", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/a73qzy6r9zhc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=afe19c2ae7feff3cd56f363723c0e0cadec72e33", "width": 108, "height": 144}, {"url": "https://preview.redd.it/a73qzy6r9zhc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=85451932af9583306219110cb8db7baf8cdb7451", "width": 216, "height": 288}, {"url": "https://preview.redd.it/a73qzy6r9zhc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25a8e8b3649693f40e2d2cb22a66a1eb637f0d3e", "width": 320, "height": 426}, {"url": "https://preview.redd.it/a73qzy6r9zhc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4162675f2118fca6cb10df14992d0c82709d825", "width": 640, "height": 853}, {"url": "https://preview.redd.it/a73qzy6r9zhc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f5f417b674fca5c8848183afd3df5ae05554fdb", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/a73qzy6r9zhc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a3ad3fe89492bde2ec12af255e14bb16a72f37d", "width": 1080, "height": 1440}], "variants": {}, "id": "m_1COVKKAHIMLVvGoRsE3Pbu1YMUA2D0XXF-J0Kmhag"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aob0um", "is_robot_indexable": true, "report_reasons": null, "author": "JuiceKooky2629", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1aob0um/broke_hdd_after_updating_samsung_tv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/a73qzy6r9zhc1.jpeg", "subreddit_subscribers": 732465, "created_utc": 1707666702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I build a site to compare harddrives based on price,  size, price per GB, speed, internal, external and so on and I'm looking for feedback. Is this a good place to post the link or is this considered spam?", "author_fullname": "t2_9y6xwav4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Disk price comparison for german speaking countries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao8w1v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707660924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I build a site to compare harddrives based on price,  size, price per GB, speed, internal, external and so on and I&amp;#39;m looking for feedback. Is this a good place to post the link or is this considered spam?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao8w1v", "is_robot_indexable": true, "report_reasons": null, "author": "bigahuna", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao8w1v/disk_price_comparison_for_german_speaking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao8w1v/disk_price_comparison_for_german_speaking/", "subreddit_subscribers": 732465, "created_utc": 1707660924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": ".", "author_fullname": "t2_5t2soh4f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What apps do you use for saving Instagram Stories on android/iphone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao2vk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707638271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao2vk2", "is_robot_indexable": true, "report_reasons": null, "author": "ContPosts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao2vk2/what_apps_do_you_use_for_saving_instagram_stories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao2vk2/what_apps_do_you_use_for_saving_instagram_stories/", "subreddit_subscribers": 732465, "created_utc": 1707638271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a really old NexStar HX4R 4 bay usb 3.0 raid enclosure.  It's finally decided to die on me,\n\nIt's hooked up to a pc with an AMD Ryzen 5 2600 cpu in asrock B450M Pro4 16GB in an matx case (no room for 4 drives).  Running OMV for the OS.\n\nI would like to replace it with something very similar.   Here's my list of requirements: since I have a very limited budget\n\n* must be usb a or c. (not interested in a NAS right now).  My MB has usb-c, so that would be the better option.\n* Can be software or hardware raid (but I'd prefer hardware raid)\n* Can be rackmount or standalone\n\nI realize my requirements limit my choices, but I'd just like to get my best device for those options.\n\nThanks!", "author_fullname": "t2_m65zl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "my vantec NexStar HX4R finally died", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anwoa4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707616692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a really old NexStar HX4R 4 bay usb 3.0 raid enclosure.  It&amp;#39;s finally decided to die on me,&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s hooked up to a pc with an AMD Ryzen 5 2600 cpu in asrock B450M Pro4 16GB in an matx case (no room for 4 drives).  Running OMV for the OS.&lt;/p&gt;\n\n&lt;p&gt;I would like to replace it with something very similar.   Here&amp;#39;s my list of requirements: since I have a very limited budget&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;must be usb a or c. (not interested in a NAS right now).  My MB has usb-c, so that would be the better option.&lt;/li&gt;\n&lt;li&gt;Can be software or hardware raid (but I&amp;#39;d prefer hardware raid)&lt;/li&gt;\n&lt;li&gt;Can be rackmount or standalone&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I realize my requirements limit my choices, but I&amp;#39;d just like to get my best device for those options.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anwoa4", "is_robot_indexable": true, "report_reasons": null, "author": "ogg1e", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anwoa4/my_vantec_nexstar_hx4r_finally_died/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anwoa4/my_vantec_nexstar_hx4r_finally_died/", "subreddit_subscribers": 732465, "created_utc": 1707616692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys. New here and I think I have a fairly unique question. \n\nI have lectures for my classes. It\u2019s an online class that uses canvas. The videos are not downloadable from what I can tell. So how can I get this downloaded?", "author_fullname": "t2_3d9kn0k6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download Lecture From Canvas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anu849", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. New here and I think I have a fairly unique question. &lt;/p&gt;\n\n&lt;p&gt;I have lectures for my classes. It\u2019s an online class that uses canvas. The videos are not downloadable from what I can tell. So how can I get this downloaded?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anu849", "is_robot_indexable": true, "report_reasons": null, "author": "bstillab", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anu849/download_lecture_from_canvas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anu849/download_lecture_from_canvas/", "subreddit_subscribers": 732465, "created_utc": 1707609525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's out of another machine because I thought there were network issues, things were copying extremely slowly.  But it persists in a ssd dock.  I don't need hd sentinel installed on the machine it's running in to show such errors, do I?  I have no idea what could be wrong.  The machine is a 2013 dell, so it would support trim...  \n\n\nEDIT: machine was in raid mode instead of ahci, possibly ever since I installed windows on this machine.  Could that have done it?", "author_fullname": "t2_ubnt8yve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial bx500 ssd down to 91% health after four days total uptime, but no hd sentinel errors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ano129", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707594837.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707592869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s out of another machine because I thought there were network issues, things were copying extremely slowly.  But it persists in a ssd dock.  I don&amp;#39;t need hd sentinel installed on the machine it&amp;#39;s running in to show such errors, do I?  I have no idea what could be wrong.  The machine is a 2013 dell, so it would support trim...  &lt;/p&gt;\n\n&lt;p&gt;EDIT: machine was in raid mode instead of ahci, possibly ever since I installed windows on this machine.  Could that have done it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ano129", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Introduction5124", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ano129/crucial_bx500_ssd_down_to_91_health_after_four/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ano129/crucial_bx500_ssd_down_to_91_health_after_four/", "subreddit_subscribers": 732465, "created_utc": 1707592869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a 2009 thread with id 2052748 in /x/, but its kinda difficult to find it right know, almost impossible. There's an easy way to find it 15 years later?", "author_fullname": "t2_a0onuu4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a 4chan /x/ thread", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aoaneb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707665737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a 2009 thread with id 2052748 in /x/, but its kinda difficult to find it right know, almost impossible. There&amp;#39;s an easy way to find it 15 years later?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aoaneb", "is_robot_indexable": true, "report_reasons": null, "author": "Shadow52176", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1aoaneb/looking_for_a_4chan_x_thread/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1aoaneb/looking_for_a_4chan_x_thread/", "subreddit_subscribers": 732465, "created_utc": 1707665737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I have 4 drives that are currently just either on the floor or inside the pc case (not in a bay, they're just on the floor of the case). So does anyone have any recommendations for cheap containers where I can fit 8 in? I'm not looking for anything fancy with built in cables and stuff just something to fit them in with a little gap so I can wire the sata cables in. Thanks!", "author_fullname": "t2_emxhqub4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard drive bay/container", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aoa142", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707664090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I have 4 drives that are currently just either on the floor or inside the pc case (not in a bay, they&amp;#39;re just on the floor of the case). So does anyone have any recommendations for cheap containers where I can fit 8 in? I&amp;#39;m not looking for anything fancy with built in cables and stuff just something to fit them in with a little gap so I can wire the sata cables in. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aoa142", "is_robot_indexable": true, "report_reasons": null, "author": "hypocpk1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1aoa142/hard_drive_baycontainer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1aoa142/hard_drive_baycontainer/", "subreddit_subscribers": 732465, "created_utc": 1707664090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'd like to make a 4K remux to view via Plex. I've demuxed the raw streams using the latest version of eac3to and realised I now have 2 video streams (I understand that one of the streams is the enhancement layer) should I add both streams to mkvmerge or just one layer as I'm not sure as I haven't remuxed 4K before?", "author_fullname": "t2_5dkgegkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating 4K remux (2 Video streams)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aoa134", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707664088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to make a 4K remux to view via Plex. I&amp;#39;ve demuxed the raw streams using the latest version of eac3to and realised I now have 2 video streams (I understand that one of the streams is the enhancement layer) should I add both streams to mkvmerge or just one layer as I&amp;#39;m not sure as I haven&amp;#39;t remuxed 4K before?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1aoa134", "is_robot_indexable": true, "report_reasons": null, "author": "craftywizard1983", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1aoa134/creating_4k_remux_2_video_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1aoa134/creating_4k_remux_2_video_streams/", "subreddit_subscribers": 732465, "created_utc": 1707664088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a couple drives from SPD a month ago after reading rave reviews about them here. I chose FedEx shipping and emailed FedEx saying I would like to self-clear the package when it crosses the border to avoid paying double for their brokerage fee. The FedEx rep made up some BS excuse saying I can't do that because the package crosses at a point of entry in a different province, which I'm pretty sure is BS because I have a CBSA inland office at my local airport and I should be able to self-clear by law. Anyways, they offered a \"one-time\" credit to the brokerage fee so I would only have to pay tax. So all fine and dandy.\n\nA few days ago one of the drives started failing the snapraid sync. And smart tests were throwing errors. I posted about it asking help here yesterday, but mods deleted my post. One helpful commenter did help interpret my results and said my drive should be fine. Well today's smart test went from 40 reallocated sectors to 2000. So pretty sure drive is fucked.\n\nI went to SPD to grab a couple more drives so that I could hopefully transfer my data before it's completely fried and then do the RMA. But at the checkout, the only option now for shipping is \"Duties &amp; Taxes Included\". I get that this is a good option for those that don't want to get the unexpected bill later in the mail from FedEx and co., but this basically forces me to pay the shipper's brokerage fees which sucks. Computers are duty-exempt, so I should only expect to pay taxes.\n\nFor my total CAD $431.61 I should expect to pay CAD $47.48 taxes. SPD at checkout asks me to pay CAD $63.41 for \"duty and tax\". I get that it's not a crazy amount higher, but if I was using a different shipping option, the duty and tax goes all the way up to CAD $145.16!\n\nWhat gives, /u/ServerPartDeals? Could we at least have the option back to pay duty/tax ourselves? I am sure this will be more convenient for some people, but we shouldn't be forced to pay brokerage fees.", "author_fullname": "t2_40crn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverpartdeals USA &gt; CAN now forces included duty/tax with shipping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao5q1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707650109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a couple drives from SPD a month ago after reading rave reviews about them here. I chose FedEx shipping and emailed FedEx saying I would like to self-clear the package when it crosses the border to avoid paying double for their brokerage fee. The FedEx rep made up some BS excuse saying I can&amp;#39;t do that because the package crosses at a point of entry in a different province, which I&amp;#39;m pretty sure is BS because I have a CBSA inland office at my local airport and I should be able to self-clear by law. Anyways, they offered a &amp;quot;one-time&amp;quot; credit to the brokerage fee so I would only have to pay tax. So all fine and dandy.&lt;/p&gt;\n\n&lt;p&gt;A few days ago one of the drives started failing the snapraid sync. And smart tests were throwing errors. I posted about it asking help here yesterday, but mods deleted my post. One helpful commenter did help interpret my results and said my drive should be fine. Well today&amp;#39;s smart test went from 40 reallocated sectors to 2000. So pretty sure drive is fucked.&lt;/p&gt;\n\n&lt;p&gt;I went to SPD to grab a couple more drives so that I could hopefully transfer my data before it&amp;#39;s completely fried and then do the RMA. But at the checkout, the only option now for shipping is &amp;quot;Duties &amp;amp; Taxes Included&amp;quot;. I get that this is a good option for those that don&amp;#39;t want to get the unexpected bill later in the mail from FedEx and co., but this basically forces me to pay the shipper&amp;#39;s brokerage fees which sucks. Computers are duty-exempt, so I should only expect to pay taxes.&lt;/p&gt;\n\n&lt;p&gt;For my total CAD $431.61 I should expect to pay CAD $47.48 taxes. SPD at checkout asks me to pay CAD $63.41 for &amp;quot;duty and tax&amp;quot;. I get that it&amp;#39;s not a crazy amount higher, but if I was using a different shipping option, the duty and tax goes all the way up to CAD $145.16!&lt;/p&gt;\n\n&lt;p&gt;What gives, &lt;a href=\"/u/ServerPartDeals\"&gt;/u/ServerPartDeals&lt;/a&gt;? Could we at least have the option back to pay duty/tax ourselves? I am sure this will be more convenient for some people, but we shouldn&amp;#39;t be forced to pay brokerage fees.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ao5q1d", "is_robot_indexable": true, "report_reasons": null, "author": "stenzor", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao5q1d/serverpartdeals_usa_can_now_forces_included/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao5q1d/serverpartdeals_usa_can_now_forces_included/", "subreddit_subscribers": 732465, "created_utc": 1707650109.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}