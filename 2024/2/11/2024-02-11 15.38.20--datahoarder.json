{"kind": "Listing", "data": {"after": "t3_1anvuy5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When i was Torrenting yesterday i Stumbled apon the files to the Daft Punk DVD **D.A.F.T. - A Story About Dogs, Androids, Firemen and Tomatoes** i was thinking of uploading it to archive.org but I'm not sure if that is legal and I don't want to get in trouble", "author_fullname": "t2_e27dm3jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is uploading a out of print DVD to archive.org Legal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anwdbh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 102, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 102, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707615733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When i was Torrenting yesterday i Stumbled apon the files to the Daft Punk DVD &lt;strong&gt;D.A.F.T. - A Story About Dogs, Androids, Firemen and Tomatoes&lt;/strong&gt; i was thinking of uploading it to archive.org but I&amp;#39;m not sure if that is legal and I don&amp;#39;t want to get in trouble&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anwdbh", "is_robot_indexable": true, "report_reasons": null, "author": "StevenIsCool2004", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anwdbh/is_uploading_a_out_of_print_dvd_to_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anwdbh/is_uploading_a_out_of_print_dvd_to_archiveorg/", "subreddit_subscribers": 732445, "created_utc": 1707615733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for anyone who has an archive for the Marching Arts for BOA/Grand Nationals/local circuits etc....  I already have a huge drafted archive for DCI that's over 2TB from judges tapes to HQ Blurays.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The reason I want to do this is because unfortunately due to the terrible system that is music copyright laws, neither Flomarching, the event holder, or the band performing get maximum quality videos. Flomarching does allow you to watch their streams after the fact, but they are legally required to not save any of the audio. This means that the performers (or anyone else) cannot enjoy their to the full potential if they don't want to rely on bad phone recorded videos with peoples heads blocking or if they actually want to hear the music they played.                                       ", "author_fullname": "t2_9woubj41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone hoarding marching band videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anv48v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707612054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for anyone who has an archive for the Marching Arts for BOA/Grand Nationals/local circuits etc....  I already have a huge drafted archive for DCI that&amp;#39;s over 2TB from judges tapes to HQ Blurays.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The reason I want to do this is because unfortunately due to the terrible system that is music copyright laws, neither Flomarching, the event holder, or the band performing get maximum quality videos. Flomarching does allow you to watch their streams after the fact, but they are legally required to not save any of the audio. This means that the performers (or anyone else) cannot enjoy their to the full potential if they don&amp;#39;t want to rely on bad phone recorded videos with peoples heads blocking or if they actually want to hear the music they played.                                       &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anv48v", "is_robot_indexable": true, "report_reasons": null, "author": "Roleplex0", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anv48v/anyone_hoarding_marching_band_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anv48v/anyone_hoarding_marching_band_videos/", "subreddit_subscribers": 732445, "created_utc": 1707612054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm aware of archivebox but I'm wondering if there are other new tools that also archive web pages you visit? The last time I tried doing this was in 2012.", "author_fullname": "t2_4ph16ic4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools to archive visited web pages locally in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anopqc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707594675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m aware of archivebox but I&amp;#39;m wondering if there are other new tools that also archive web pages you visit? The last time I tried doing this was in 2012.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anopqc", "is_robot_indexable": true, "report_reasons": null, "author": "A9to5robot", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anopqc/tools_to_archive_visited_web_pages_locally_in_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anopqc/tools_to_archive_visited_web_pages_locally_in_2024/", "subreddit_subscribers": 732445, "created_utc": 1707594675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_19chrnag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good to know I am not alone.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": true, "name": "t3_1ao8tdk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xE0TMPiPaO8GbRMT0UAw24EOudVncsRy4v6FYk3hfAA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707660703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0dxp6yruryhc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0dxp6yruryhc1.png?auto=webp&amp;s=b66b19fe8db9f945f80a80efc5d515e166ffbe33", "width": 617, "height": 606}, "resolutions": [{"url": "https://preview.redd.it/0dxp6yruryhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a595c28bf067d62b62090d35433f408a1c534f43", "width": 108, "height": 106}, {"url": "https://preview.redd.it/0dxp6yruryhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb54cc4b5218e5d748dbdd599568c29bdcff23a4", "width": 216, "height": 212}, {"url": "https://preview.redd.it/0dxp6yruryhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=15e5c8353d78fba8c5687a56ea9a07ad18848c0a", "width": 320, "height": 314}], "variants": {}, "id": "6tw3Qmec8MxxuE5FD2rwWL4UhqzBatOO0OPGenmmlig"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao8tdk", "is_robot_indexable": true, "report_reasons": null, "author": "Bastion80", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao8tdk/good_to_know_i_am_not_alone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/0dxp6yruryhc1.png", "subreddit_subscribers": 732445, "created_utc": 1707660703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My TrueNAS Mini XL+ died the other day. No network, no connection over VGA. Looking into it, it seems relatively common. Anyway, getting in there I've decided I don't really want to continue using it anyway...\n\nThe TrueNAS Mini XL+ is fully populated with 8 HDDs. Next to that system I have a system that is running ZFS (no FreeNAS, etc, just Linux+ZFS) with the following hardware specs:\n\n* Fractal Design 7 (not xl, mid-tower, 8 bay model)\n* Gigabyte Z390 AORUS ULTRA-CF Motherboard\n* Intel i9-9900K\n* NVIDIA Corporation GP106GL [Quadro P2200]\n* 16GB memory (2x8GB Corsair CMK16GX4M2B3200C16 DIMMs)\n\nI'm thinking of either moving everything (all drives in TrueNAS Mini XL + all components in the Fractal Design 7 case) into a Fractal Design Meshify 2 XL case (all 16 drives); or, alternatively, I get a 2nd system and move everything from the TrueNAS case into the 2nd system.\n\nQuestions\n\n* Will I be able to simply migrate the pool from the TrueNAS into the new system w.o data loss? All HDDs are perfectly fine. I would assume this process should be just add a 2nd pool and everything is good, but not sure. Is this process more difficult if moving the drives into a system with an already existing ZFS pool?\n\n* In my situation would you buy a 2nd system, or move everything into a larger case? I just don't want to spend a bunch of money unnecessarily on another mobo/power supply/cpu/etc, especially if I can just move it into a larger case and have both ZFS pools running alongside each other. What are the pros/cons of these 2 scenarios?\n\nI am using the Fractal Design system as a Plex server. So now it would be a Plex server with 8 extra drives, beyond the 8 it already has.", "author_fullname": "t2_k7b5nyn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My TrueNAS Mini died. I have some questions regarding different paths I can take here.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao3cvy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707640272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My TrueNAS Mini XL+ died the other day. No network, no connection over VGA. Looking into it, it seems relatively common. Anyway, getting in there I&amp;#39;ve decided I don&amp;#39;t really want to continue using it anyway...&lt;/p&gt;\n\n&lt;p&gt;The TrueNAS Mini XL+ is fully populated with 8 HDDs. Next to that system I have a system that is running ZFS (no FreeNAS, etc, just Linux+ZFS) with the following hardware specs:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fractal Design 7 (not xl, mid-tower, 8 bay model)&lt;/li&gt;\n&lt;li&gt;Gigabyte Z390 AORUS ULTRA-CF Motherboard&lt;/li&gt;\n&lt;li&gt;Intel i9-9900K&lt;/li&gt;\n&lt;li&gt;NVIDIA Corporation GP106GL [Quadro P2200]&lt;/li&gt;\n&lt;li&gt;16GB memory (2x8GB Corsair CMK16GX4M2B3200C16 DIMMs)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of either moving everything (all drives in TrueNAS Mini XL + all components in the Fractal Design 7 case) into a Fractal Design Meshify 2 XL case (all 16 drives); or, alternatively, I get a 2nd system and move everything from the TrueNAS case into the 2nd system.&lt;/p&gt;\n\n&lt;p&gt;Questions&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Will I be able to simply migrate the pool from the TrueNAS into the new system w.o data loss? All HDDs are perfectly fine. I would assume this process should be just add a 2nd pool and everything is good, but not sure. Is this process more difficult if moving the drives into a system with an already existing ZFS pool?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In my situation would you buy a 2nd system, or move everything into a larger case? I just don&amp;#39;t want to spend a bunch of money unnecessarily on another mobo/power supply/cpu/etc, especially if I can just move it into a larger case and have both ZFS pools running alongside each other. What are the pros/cons of these 2 scenarios?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am using the Fractal Design system as a Plex server. So now it would be a Plex server with 8 extra drives, beyond the 8 it already has.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao3cvy", "is_robot_indexable": true, "report_reasons": null, "author": "retsuko_h4x", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao3cvy/my_truenas_mini_died_i_have_some_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao3cvy/my_truenas_mini_died_i_have_some_questions/", "subreddit_subscribers": 732445, "created_utc": 1707640272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a computer with 3 1TB disks. All the disks have photos randomly strewn about the directory structure on the drives. Most have random filenames (game screnshots, photos of projects I've made, electrical schematics, photos of vehicles, old TVs, ect.)\n\nWhat's the best program I can use to find duplicates, and hopefully consolidate all the photos to one location?\n\nEdit: I'm on windows, so any tools would have to work on windows.", "author_fullname": "t2_ky0ji79zj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a way to find duplicate photos on multiple drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anjpwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707581429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a computer with 3 1TB disks. All the disks have photos randomly strewn about the directory structure on the drives. Most have random filenames (game screnshots, photos of projects I&amp;#39;ve made, electrical schematics, photos of vehicles, old TVs, ect.)&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best program I can use to find duplicates, and hopefully consolidate all the photos to one location?&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m on windows, so any tools would have to work on windows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anjpwf", "is_robot_indexable": true, "report_reasons": null, "author": "aspie_electrician", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anjpwf/looking_for_a_way_to_find_duplicate_photos_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anjpwf/looking_for_a_way_to_find_duplicate_photos_on/", "subreddit_subscribers": 732445, "created_utc": 1707581429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have about 40TB to move from one server (old hardware raid 6) to a new server (zfs raidz2). I started the  process on one chunk ~3 TB and realized over my 1Gbit network this is going to take some time. \n\nI've moved around big chunks before but it was always within server ie raid array to raid array and it went pretty quick. Based on some rough calculations this is going to take like a month, which is fine I guess worst case..\n\nIs are there any lower cost solutions to moving this data? I'm going to guess probably not.\n\nEdit: I miscalculated, this will take a week, I'm going to just be patient.", "author_fullname": "t2_5s2jw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data migration old server -&gt; new", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anuc6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707615370.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 40TB to move from one server (old hardware raid 6) to a new server (zfs raidz2). I started the  process on one chunk ~3 TB and realized over my 1Gbit network this is going to take some time. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve moved around big chunks before but it was always within server ie raid array to raid array and it went pretty quick. Based on some rough calculations this is going to take like a month, which is fine I guess worst case..&lt;/p&gt;\n\n&lt;p&gt;Is are there any lower cost solutions to moving this data? I&amp;#39;m going to guess probably not.&lt;/p&gt;\n\n&lt;p&gt;Edit: I miscalculated, this will take a week, I&amp;#39;m going to just be patient.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anuc6f", "is_robot_indexable": true, "report_reasons": null, "author": "UACEENGR", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anuc6f/data_migration_old_server_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anuc6f/data_migration_old_server_new/", "subreddit_subscribers": 732445, "created_utc": 1707609828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an iPhone 13 and a MacBook Air. My goal is to move my photos/videos off my phone to (???) so that I can use Capcut to edit Youtube videos. I need the quality to stay the same. \n\nMy iPhone storage is now full at 200 GB, as is my MacBook Air space, it's all photos and videos, no apps, no additional data stored anywhere. \n\nWhat's my next step? ", "author_fullname": "t2_4vjnlv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Way to Clear Storage on iPhone (move Photos for Video Editing)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anu77j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an iPhone 13 and a MacBook Air. My goal is to move my photos/videos off my phone to (???) so that I can use Capcut to edit Youtube videos. I need the quality to stay the same. &lt;/p&gt;\n\n&lt;p&gt;My iPhone storage is now full at 200 GB, as is my MacBook Air space, it&amp;#39;s all photos and videos, no apps, no additional data stored anywhere. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s my next step? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anu77j", "is_robot_indexable": true, "report_reasons": null, "author": "BetweenOceans", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anu77j/best_way_to_clear_storage_on_iphone_move_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anu77j/best_way_to_clear_storage_on_iphone_move_photos/", "subreddit_subscribers": 732445, "created_utc": 1707609453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There was a thread about burned CD-DVD decay a few days ago. The topic of chemical decay was brought up and after seeing the price of an old cartridge game I wondered if they just bought what will be a hunk of plastic in a few years. Do you think video games collections will just disappear in the next ten years due to chemical decay ?", "author_fullname": "t2_qynmwhsd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "About video game collections", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao6wac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707654578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There was a thread about burned CD-DVD decay a few days ago. The topic of chemical decay was brought up and after seeing the price of an old cartridge game I wondered if they just bought what will be a hunk of plastic in a few years. Do you think video games collections will just disappear in the next ten years due to chemical decay ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao6wac", "is_robot_indexable": true, "report_reasons": null, "author": "Studious_Roll", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao6wac/about_video_game_collections/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao6wac/about_video_game_collections/", "subreddit_subscribers": 732445, "created_utc": 1707654578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First of all, this is my first post in this community, so apologies if I am missing something here.\n\nI would like to download the original files from  [archive.org](https://archive.org) video repositories using the official [python CLI interface](https://github.com/jjjake/internetarchive).\n\nThe issues is, I cannot find a switch in the [documentation](https://archive.org/developers/internetarchive/api.html#internetarchive.download) of the `download` function to do exactly that.\n\nFor example, running `download('maus-06-07-30', verbose=True, dry_run=True)` shows that I would be downloading both .mp4 and .avi files as well as .jpg thumbnails with it, which I do *not* want.\n\nYes, I could exclude .mp4 files and .jpg files using the `glob_pattern` or `formats` parameter, but that would mean, I would first need to find a way to determine programmatically which files are the originals and which aren't.\n\nCheers, Andr\u00e9", "author_fullname": "t2_1agysvjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download only original files from archive.org using official python script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao4b68", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707644256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, this is my first post in this community, so apologies if I am missing something here.&lt;/p&gt;\n\n&lt;p&gt;I would like to download the original files from  &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt; video repositories using the official &lt;a href=\"https://github.com/jjjake/internetarchive\"&gt;python CLI interface&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The issues is, I cannot find a switch in the &lt;a href=\"https://archive.org/developers/internetarchive/api.html#internetarchive.download\"&gt;documentation&lt;/a&gt; of the &lt;code&gt;download&lt;/code&gt; function to do exactly that.&lt;/p&gt;\n\n&lt;p&gt;For example, running &lt;code&gt;download(&amp;#39;maus-06-07-30&amp;#39;, verbose=True, dry_run=True)&lt;/code&gt; shows that I would be downloading both .mp4 and .avi files as well as .jpg thumbnails with it, which I do &lt;em&gt;not&lt;/em&gt; want.&lt;/p&gt;\n\n&lt;p&gt;Yes, I could exclude .mp4 files and .jpg files using the &lt;code&gt;glob_pattern&lt;/code&gt; or &lt;code&gt;formats&lt;/code&gt; parameter, but that would mean, I would first need to find a way to determine programmatically which files are the originals and which aren&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Cheers, Andr\u00e9&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao4b68", "is_robot_indexable": true, "report_reasons": null, "author": "TXAndre", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao4b68/download_only_original_files_from_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao4b68/download_only_original_files_from_archiveorg/", "subreddit_subscribers": 732445, "created_utc": 1707644256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I build a site to compare harddrives based on price,  size, price per GB, speed, internal, external and so on and I'm looking for feedback. Is this a good place to post the link or is this considered spam?", "author_fullname": "t2_9y6xwav4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Disk price comparison for german speaking countries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ao8w1v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707660924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I build a site to compare harddrives based on price,  size, price per GB, speed, internal, external and so on and I&amp;#39;m looking for feedback. Is this a good place to post the link or is this considered spam?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao8w1v", "is_robot_indexable": true, "report_reasons": null, "author": "bigahuna", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao8w1v/disk_price_comparison_for_german_speaking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao8w1v/disk_price_comparison_for_german_speaking/", "subreddit_subscribers": 732445, "created_utc": 1707660924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I saw a post today from someone reading old discs in a scanning tool. I believe they said that 30 out of 300 old discs were bad (if those weren't the numbers let's use them anyway for the sake of simplicity).\n\nThat gives us a failure rate of 10%.\n\nNow let's assume that all those discs had been copied offsite and everything else is equal including the assumed failure rate of the media over this time period (10%).\n\nEach onsite disc has one corresponding offsite copy. Both sets of media are subject to a 10% failure rate. \n\nWhat's the probability that there will be one disc in that group which fails in both onsite and offsite (ie both the onsite and corresponding offsite duplicate end up unreadable)? \n\nAnd finally:\n\nAssuming the same assumptions and mathematics, how much would we derisk the approach if we were to store a THIRD copy of the data (ie, a second duplicate to the original. Let's imagine there's a second to offsite library). \n\nSame media. Same predicted failure rate. Everything else equal. \n\n? \n\nTIA!", "author_fullname": "t2_poc45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone help with a quick calculation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao7pw3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707657328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw a post today from someone reading old discs in a scanning tool. I believe they said that 30 out of 300 old discs were bad (if those weren&amp;#39;t the numbers let&amp;#39;s use them anyway for the sake of simplicity).&lt;/p&gt;\n\n&lt;p&gt;That gives us a failure rate of 10%.&lt;/p&gt;\n\n&lt;p&gt;Now let&amp;#39;s assume that all those discs had been copied offsite and everything else is equal including the assumed failure rate of the media over this time period (10%).&lt;/p&gt;\n\n&lt;p&gt;Each onsite disc has one corresponding offsite copy. Both sets of media are subject to a 10% failure rate. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the probability that there will be one disc in that group which fails in both onsite and offsite (ie both the onsite and corresponding offsite duplicate end up unreadable)? &lt;/p&gt;\n\n&lt;p&gt;And finally:&lt;/p&gt;\n\n&lt;p&gt;Assuming the same assumptions and mathematics, how much would we derisk the approach if we were to store a THIRD copy of the data (ie, a second duplicate to the original. Let&amp;#39;s imagine there&amp;#39;s a second to offsite library). &lt;/p&gt;\n\n&lt;p&gt;Same media. Same predicted failure rate. Everything else equal. &lt;/p&gt;\n\n&lt;p&gt;? &lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao7pw3", "is_robot_indexable": true, "report_reasons": null, "author": "danielrosehill", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao7pw3/can_anyone_help_with_a_quick_calculation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao7pw3/can_anyone_help_with_a_quick_calculation/", "subreddit_subscribers": 732445, "created_utc": 1707657328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I created a batch file to download multiple links from tumblr, and it downloaded almost all of the links, except for this one line:\n\n    gallery-dl \"https://www.tumblr.com/username/tagged/my%20art\" --mtime-from-date -o skip=true -D \"D:\\[Art]\\tumblr\\username\"\n\nWhen I ran this command manually by opening command prompt and pasting it in, it worked, but when I ran it by opening the .bat file this came up:\n\n    [tumblr][info] No results for https://www.tumblr.com/username/tagged/my0art\"\n\nI assume this was because that command contained the special character \"&amp;\" so the .bat file didn't work, but I'm not sure because I don't know anything about coding. If you have any explanation or advice on how to fix this, I'd really appreciate it!", "author_fullname": "t2_ielfpq9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I fix gallery-dl .bat file skipping link with special character", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anz2ma", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707624363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created a batch file to download multiple links from tumblr, and it downloaded almost all of the links, except for this one line:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gallery-dl &amp;quot;https://www.tumblr.com/username/tagged/my%20art&amp;quot; --mtime-from-date -o skip=true -D &amp;quot;D:\\[Art]\\tumblr\\username&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When I ran this command manually by opening command prompt and pasting it in, it worked, but when I ran it by opening the .bat file this came up:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[tumblr][info] No results for https://www.tumblr.com/username/tagged/my0art&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I assume this was because that command contained the special character &amp;quot;&amp;amp;&amp;quot; so the .bat file didn&amp;#39;t work, but I&amp;#39;m not sure because I don&amp;#39;t know anything about coding. If you have any explanation or advice on how to fix this, I&amp;#39;d really appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anz2ma", "is_robot_indexable": true, "report_reasons": null, "author": "freetousebyjtc", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anz2ma/how_do_i_fix_gallerydl_bat_file_skipping_link/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anz2ma/how_do_i_fix_gallerydl_bat_file_skipping_link/", "subreddit_subscribers": 732445, "created_utc": 1707624363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I changed over to Firefox in order to use Stacher to its best capacity, but when I finally thought that I would be able to download some embeded Patreon videos, I get an error message saying that there was no supported media found in that post...\n\n    Collecting video metadata...\n    Generated command line:\n    C:\\Users\\User\\.stacher/youtube-dl -f best --no-warnings --cookies-from-browser firefox --no-check-certificate -o ~/Downloads/%(upload_date)s_%(title)s.%(ext)s --username ***************** --password **********\n    https://www.patreon.com/posts/uncut-goblin-s1-63227887\n    Starting download...\n    Extracting cookies from firefox\n    Extracted 25 cookies from firefox\n    [Patreon] Extracting URL: https://www.patreon.com/posts/uncut-goblin-s1-63227887 [Patreon] 63227887: Downloading API JSON\n    ERROR: [Patreon] 63227887: No supported media found in this post\n\nHow the hell can I fix that error? Or is there no way to fix it?\n\nAlso, if so, are there any other frontends for yt-dlp that use the newest version of it that might work with an embeded patreon video?", "author_fullname": "t2_9ata9p94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stacher Patreon: no supported media ERROR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anxwfu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707620559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I changed over to Firefox in order to use Stacher to its best capacity, but when I finally thought that I would be able to download some embeded Patreon videos, I get an error message saying that there was no supported media found in that post...&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Collecting video metadata...\nGenerated command line:\nC:\\Users\\User\\.stacher/youtube-dl -f best --no-warnings --cookies-from-browser firefox --no-check-certificate -o ~/Downloads/%(upload_date)s_%(title)s.%(ext)s --username ***************** --password **********\nhttps://www.patreon.com/posts/uncut-goblin-s1-63227887\nStarting download...\nExtracting cookies from firefox\nExtracted 25 cookies from firefox\n[Patreon] Extracting URL: https://www.patreon.com/posts/uncut-goblin-s1-63227887 [Patreon] 63227887: Downloading API JSON\nERROR: [Patreon] 63227887: No supported media found in this post\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How the hell can I fix that error? Or is there no way to fix it?&lt;/p&gt;\n\n&lt;p&gt;Also, if so, are there any other frontends for yt-dlp that use the newest version of it that might work with an embeded patreon video?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anxwfu", "is_robot_indexable": true, "report_reasons": null, "author": "PadoruPadome", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anxwfu/stacher_patreon_no_supported_media_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anxwfu/stacher_patreon_no_supported_media_error/", "subreddit_subscribers": 732445, "created_utc": 1707620559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a file that has thousands of (mostly jpeg) images in it -- my computers swap backgrounds by pulling from this file randomly. Some of the images should be culled, but File Explorer doesn't show the thumbnails for a lot of the jpegs, so it is super hard to review. You have to click into each one, which is infuriating.\n\nHow can I force File Explorer to update the jpegs? Do I need to use a different program?", "author_fullname": "t2_cwfuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to see thumbnails of all pictures in a file of thousands of them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anvyd4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707614466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a file that has thousands of (mostly jpeg) images in it -- my computers swap backgrounds by pulling from this file randomly. Some of the images should be culled, but File Explorer doesn&amp;#39;t show the thumbnails for a lot of the jpegs, so it is super hard to review. You have to click into each one, which is infuriating.&lt;/p&gt;\n\n&lt;p&gt;How can I force File Explorer to update the jpegs? Do I need to use a different program?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anvyd4", "is_robot_indexable": true, "report_reasons": null, "author": "BBorNot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anvyd4/how_to_see_thumbnails_of_all_pictures_in_a_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anvyd4/how_to_see_thumbnails_of_all_pictures_in_a_file/", "subreddit_subscribers": 732445, "created_utc": 1707614466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a really old NexStar HX4R 4 bay usb 3.0 raid enclosure.  It's finally decided to die on me,\n\nIt's hooked up to a pc with an AMD Ryzen 5 2600 cpu in asrock B450M Pro4 16GB in an matx case (no room for 4 drives).  Running OMV for the OS.\n\nI would like to replace it with something very similar.   Here's my list of requirements: since I have a very limited budget\n\n* must be usb a or c. (not interested in a NAS right now).  My MB has usb-c, so that would be the better option.\n* Can be software or hardware raid (but I'd prefer hardware raid)\n* Can be rackmount or standalone\n\nI realize my requirements limit my choices, but I'd just like to get my best device for those options.\n\nThanks!", "author_fullname": "t2_m65zl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "my vantec NexStar HX4R finally died", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anwoa4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707616692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a really old NexStar HX4R 4 bay usb 3.0 raid enclosure.  It&amp;#39;s finally decided to die on me,&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s hooked up to a pc with an AMD Ryzen 5 2600 cpu in asrock B450M Pro4 16GB in an matx case (no room for 4 drives).  Running OMV for the OS.&lt;/p&gt;\n\n&lt;p&gt;I would like to replace it with something very similar.   Here&amp;#39;s my list of requirements: since I have a very limited budget&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;must be usb a or c. (not interested in a NAS right now).  My MB has usb-c, so that would be the better option.&lt;/li&gt;\n&lt;li&gt;Can be software or hardware raid (but I&amp;#39;d prefer hardware raid)&lt;/li&gt;\n&lt;li&gt;Can be rackmount or standalone&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I realize my requirements limit my choices, but I&amp;#39;d just like to get my best device for those options.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anwoa4", "is_robot_indexable": true, "report_reasons": null, "author": "ogg1e", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anwoa4/my_vantec_nexstar_hx4r_finally_died/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anwoa4/my_vantec_nexstar_hx4r_finally_died/", "subreddit_subscribers": 732445, "created_utc": 1707616692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys. New here and I think I have a fairly unique question. \n\nI have lectures for my classes. It\u2019s an online class that uses canvas. The videos are not downloadable from what I can tell. So how can I get this downloaded?", "author_fullname": "t2_3d9kn0k6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download Lecture From Canvas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anu849", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707609525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. New here and I think I have a fairly unique question. &lt;/p&gt;\n\n&lt;p&gt;I have lectures for my classes. It\u2019s an online class that uses canvas. The videos are not downloadable from what I can tell. So how can I get this downloaded?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anu849", "is_robot_indexable": true, "report_reasons": null, "author": "bstillab", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anu849/download_lecture_from_canvas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anu849/download_lecture_from_canvas/", "subreddit_subscribers": 732445, "created_utc": 1707609525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's out of another machine because I thought there were network issues, things were copying extremely slowly.  But it persists in a ssd dock.  I don't need hd sentinel installed on the machine it's running in to show such errors, do I?  I have no idea what could be wrong.  The machine is a 2013 dell, so it would support trim...  \n\n\nEDIT: machine was in raid mode instead of ahci, possibly ever since I installed windows on this machine.  Could that have done it?", "author_fullname": "t2_ubnt8yve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial bx500 ssd down to 91% health after four days total uptime, but no hd sentinel errors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ano129", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707594837.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707592869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s out of another machine because I thought there were network issues, things were copying extremely slowly.  But it persists in a ssd dock.  I don&amp;#39;t need hd sentinel installed on the machine it&amp;#39;s running in to show such errors, do I?  I have no idea what could be wrong.  The machine is a 2013 dell, so it would support trim...  &lt;/p&gt;\n\n&lt;p&gt;EDIT: machine was in raid mode instead of ahci, possibly ever since I installed windows on this machine.  Could that have done it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ano129", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Introduction5124", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ano129/crucial_bx500_ssd_down_to_91_health_after_four/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ano129/crucial_bx500_ssd_down_to_91_health_after_four/", "subreddit_subscribers": 732445, "created_utc": 1707592869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a list of topics in the following format: \"TOPIC NAME - https://xxx.xxx\".\n\nTopic titles are in French (there are 1000 of them)\n\nI'd like to keep only those related to technology and computing.\n\nHowever, filtering by keyword is not at all efficient.\n\nIs there an AI script that would work better? \n\nHere's an example of title:\n\n\"\\[TUTO\\] Securing your home network with a Raspberry Pi Firewall: https://www.xxx.xxx\"", "author_fullname": "t2_40h537oa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to classify a list of topics by theme with AI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ankbry", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707583095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a list of topics in the following format: &amp;quot;TOPIC NAME - &lt;a href=\"https://xxx.xxx\"&gt;https://xxx.xxx&lt;/a&gt;&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Topic titles are in French (there are 1000 of them)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to keep only those related to technology and computing.&lt;/p&gt;\n\n&lt;p&gt;However, filtering by keyword is not at all efficient.&lt;/p&gt;\n\n&lt;p&gt;Is there an AI script that would work better? &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an example of title:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;[TUTO] Securing your home network with a Raspberry Pi Firewall: &lt;a href=\"https://www.xxx.xxx\"&gt;https://www.xxx.xxx&lt;/a&gt;&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?auto=webp&amp;s=409b44003b061edd963030142265b9158d818126", "width": 1148, "height": 467}, "resolutions": [{"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8648cd22c51e3066b51e0151a3215e100394c693", "width": 108, "height": 43}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e6b13fff6dfaaae3dafde5db5427826916730da", "width": 216, "height": 87}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43b30ae498222d331345a71fb7ece0730871cc3d", "width": 320, "height": 130}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e799986951824243e277cd0e7df710dc0885c59", "width": 640, "height": 260}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1a55b4c6381cd4cebaaf5f61030964f89ff76e6", "width": 960, "height": 390}, {"url": "https://external-preview.redd.it/Va4G-gSPa-KZygq6kehJvTevBnT3Fnaq9lOVkUQACpw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=df496e2be405fa613938916237b080a53765f338", "width": 1080, "height": 439}], "variants": {}, "id": "D5rzZ8mAeUGjSM-jHkVVMuBs1eusBLLGW_U-ElbBkV0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ankbry", "is_robot_indexable": true, "report_reasons": null, "author": "clara59000", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ankbry/is_it_possible_to_classify_a_list_of_topics_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ankbry/is_it_possible_to_classify_a_list_of_topics_by/", "subreddit_subscribers": 732445, "created_utc": 1707583095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey,\n\nI am having trouble loading a deleted, but archived youtube video and I also can't download it using yt-dlp([https://web.archive.org/web/20181006071539/https://www.youtube.com/watch?v=ENxxnKnq\\_1Q](https://web.archive.org/web/20181006071539/https://www.youtube.com/watch?v=ENxxnKnq_1Q)).\n\nI know that the video is really old, but sometimes when I refresh the page it displays 00:00 / 32:08 in the youtube UI.\n\nIs this salvageable or not? I might just be stupid and doing something wrong.", "author_fullname": "t2_af4i2bzd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "problem loading video from the wayback machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anisun", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707578958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I am having trouble loading a deleted, but archived youtube video and I also can&amp;#39;t download it using yt-dlp(&lt;a href=\"https://web.archive.org/web/20181006071539/https://www.youtube.com/watch?v=ENxxnKnq_1Q\"&gt;https://web.archive.org/web/20181006071539/https://www.youtube.com/watch?v=ENxxnKnq_1Q&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;I know that the video is really old, but sometimes when I refresh the page it displays 00:00 / 32:08 in the youtube UI.&lt;/p&gt;\n\n&lt;p&gt;Is this salvageable or not? I might just be stupid and doing something wrong.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anisun", "is_robot_indexable": true, "report_reasons": null, "author": "Neimod", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anisun/problem_loading_video_from_the_wayback_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anisun/problem_loading_video_from_the_wayback_machine/", "subreddit_subscribers": 732445, "created_utc": 1707578958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am asking if there is a caddy like device out there that actually works that will do 3.5/2.5 sata - msata and nvme all in one. I had a pc die on me with and my storage media had all different interfaces. I just want to recover the data from all of them in one sweep if possible.\n\nIf not what caddy work stations would you recommend I buy to get the job done?\n\nThanks", "author_fullname": "t2_kc1gh3j1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage media workstation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao488s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707643900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am asking if there is a caddy like device out there that actually works that will do 3.5/2.5 sata - msata and nvme all in one. I had a pc die on me with and my storage media had all different interfaces. I just want to recover the data from all of them in one sweep if possible.&lt;/p&gt;\n\n&lt;p&gt;If not what caddy work stations would you recommend I buy to get the job done?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao488s", "is_robot_indexable": true, "report_reasons": null, "author": "bassnerdmusic", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao488s/storage_media_workstation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao488s/storage_media_workstation/", "subreddit_subscribers": 732445, "created_utc": 1707643900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": ".", "author_fullname": "t2_5t2soh4f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What apps do you use for saving Instagram Stories on android/iphone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao2vk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707638271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ao2vk2", "is_robot_indexable": true, "report_reasons": null, "author": "ContPosts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao2vk2/what_apps_do_you_use_for_saving_instagram_stories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao2vk2/what_apps_do_you_use_for_saving_instagram_stories/", "subreddit_subscribers": 732445, "created_utc": 1707638271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! Apologies in advance, I did a lot of searching and tried what I could get to work myself before coming here to ask. I truly did my best, but I think a lot of it just flew it over my head.\n\nI'm trying to archive [this show](https://www.raiplay.it/video/2024/01/Sanremo-2024-74-Festival-della-Canzone-Italiana-Quarta-Serata-del-09022024-4cf62ab0-8200-4fbc-aa63-208fe874b971.html) that was broadcast live.\n\nI'm using youtube-dl to download other content from the same website. I use the Stacher frontend as I'm not too good with command lines. However, it throws an \"http error 403: forbidden\" error on that one, because it's actually an HLS stream.\n\nJDownloader2 can't download it either, it finds the files to be \"offline\".\n\nVideo DownloadHelper worked like a charm when using the dodgy \"assistant\"... then left me with a qr code on the video and just informed me that next time I better buy the premium version. Great.\n\nWith the \"[Live Stream Downloader](https://addons.mozilla.org/en-US/firefox/addon/live-stream-downloader/)\" extension I was able to download an .mkv of the show, but it's only video, no audio.\n\nI was recommended \"PastyLink\" but it's a bit dodgy, wants me to use its own downloader, and still throws in an error.\n\nApologies again if this is a well known thing. It's the first time I've encountered this format and I don't know what else to try. I think if all else fails I could learn how to mix up the video from the LiveStreamDownloader and the audio from the VideoDownloadHelper, but it doesn't seem like the best solution in the long run. Any better suggestion helps, thank you!", "author_fullname": "t2_k1cbdayg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with archiving an HLS video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ann21a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707590286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Apologies in advance, I did a lot of searching and tried what I could get to work myself before coming here to ask. I truly did my best, but I think a lot of it just flew it over my head.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to archive &lt;a href=\"https://www.raiplay.it/video/2024/01/Sanremo-2024-74-Festival-della-Canzone-Italiana-Quarta-Serata-del-09022024-4cf62ab0-8200-4fbc-aa63-208fe874b971.html\"&gt;this show&lt;/a&gt; that was broadcast live.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using youtube-dl to download other content from the same website. I use the Stacher frontend as I&amp;#39;m not too good with command lines. However, it throws an &amp;quot;http error 403: forbidden&amp;quot; error on that one, because it&amp;#39;s actually an HLS stream.&lt;/p&gt;\n\n&lt;p&gt;JDownloader2 can&amp;#39;t download it either, it finds the files to be &amp;quot;offline&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Video DownloadHelper worked like a charm when using the dodgy &amp;quot;assistant&amp;quot;... then left me with a qr code on the video and just informed me that next time I better buy the premium version. Great.&lt;/p&gt;\n\n&lt;p&gt;With the &amp;quot;&lt;a href=\"https://addons.mozilla.org/en-US/firefox/addon/live-stream-downloader/\"&gt;Live Stream Downloader&lt;/a&gt;&amp;quot; extension I was able to download an .mkv of the show, but it&amp;#39;s only video, no audio.&lt;/p&gt;\n\n&lt;p&gt;I was recommended &amp;quot;PastyLink&amp;quot; but it&amp;#39;s a bit dodgy, wants me to use its own downloader, and still throws in an error.&lt;/p&gt;\n\n&lt;p&gt;Apologies again if this is a well known thing. It&amp;#39;s the first time I&amp;#39;ve encountered this format and I don&amp;#39;t know what else to try. I think if all else fails I could learn how to mix up the video from the LiveStreamDownloader and the audio from the VideoDownloadHelper, but it doesn&amp;#39;t seem like the best solution in the long run. Any better suggestion helps, thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?auto=webp&amp;s=06b09d2520549672271645e9a69d3f612da08459", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f740ed2ac4dd8ae2fa7d6fd3087f40fa99fb342", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77908398a6722c5e9e86ab97350b36bf59eed2ca", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d67f48cd56273b92ab368691710106aa7662f6da", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=28ca7cf8f66254e6d3e60782f8e36e7d250388c9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=46df66ac966757b817e231489a18a7180503aaf7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/PqWdtebbT-qsgyQ5o4DsVXt8qTvE82gdqmhGiyssIs4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bb7f7acacb7349770b053685511ab3036d98c1fe", "width": 1080, "height": 540}], "variants": {}, "id": "tRBsavIMz99JPesZZlaCIRweMO5iuJS7AFJEIbAB_yo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ann21a", "is_robot_indexable": true, "report_reasons": null, "author": "annapigna", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ann21a/help_with_archiving_an_hls_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ann21a/help_with_archiving_an_hls_video/", "subreddit_subscribers": 732445, "created_utc": 1707590286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a couple drives from SPD a month ago after reading rave reviews about them here. I chose FedEx shipping and emailed FedEx saying I would like to self-clear the package when it crosses the border to avoid paying double for their brokerage fee. The FedEx rep made up some BS excuse saying I can't do that because the package crosses at a point of entry in a different province, which I'm pretty sure is BS because I have a CBSA inland office at my local airport and I should be able to self-clear by law. Anyways, they offered a \"one-time\" credit to the brokerage fee so I would only have to pay tax. So all fine and dandy.\n\nA few days ago one of the drives started failing the snapraid sync. And smart tests were throwing errors. I posted about it asking help here yesterday, but mods deleted my post. One helpful commenter did help interpret my results and said my drive should be fine. Well today's smart test went from 40 reallocated sectors to 2000. So pretty sure drive is fucked.\n\nI went to SPD to grab a couple more drives so that I could hopefully transfer my data before it's completely fried and then do the RMA. But at the checkout, the only option now for shipping is \"Duties &amp; Taxes Included\". I get that this is a good option for those that don't want to get the unexpected bill later in the mail from FedEx and co., but this basically forces me to pay the shipper's brokerage fees which sucks. Computers are duty-exempt, so I should only expect to pay taxes.\n\nFor my total CAD $431.61 I should expect to pay CAD $47.48 taxes. SPD at checkout asks me to pay CAD $63.41 for \"duty and tax\". I get that it's not a crazy amount higher, but if I was using a different shipping option, the duty and tax goes all the way up to CAD $145.16!\n\nWhat gives, /u/ServerPartDeals? Could we at least have the option back to pay duty/tax ourselves? I am sure this will be more convenient for some people, but we shouldn't be forced to pay brokerage fees.", "author_fullname": "t2_40crn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverpartdeals USA &gt; CAN now forces included duty/tax with shipping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao5q1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707650109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a couple drives from SPD a month ago after reading rave reviews about them here. I chose FedEx shipping and emailed FedEx saying I would like to self-clear the package when it crosses the border to avoid paying double for their brokerage fee. The FedEx rep made up some BS excuse saying I can&amp;#39;t do that because the package crosses at a point of entry in a different province, which I&amp;#39;m pretty sure is BS because I have a CBSA inland office at my local airport and I should be able to self-clear by law. Anyways, they offered a &amp;quot;one-time&amp;quot; credit to the brokerage fee so I would only have to pay tax. So all fine and dandy.&lt;/p&gt;\n\n&lt;p&gt;A few days ago one of the drives started failing the snapraid sync. And smart tests were throwing errors. I posted about it asking help here yesterday, but mods deleted my post. One helpful commenter did help interpret my results and said my drive should be fine. Well today&amp;#39;s smart test went from 40 reallocated sectors to 2000. So pretty sure drive is fucked.&lt;/p&gt;\n\n&lt;p&gt;I went to SPD to grab a couple more drives so that I could hopefully transfer my data before it&amp;#39;s completely fried and then do the RMA. But at the checkout, the only option now for shipping is &amp;quot;Duties &amp;amp; Taxes Included&amp;quot;. I get that this is a good option for those that don&amp;#39;t want to get the unexpected bill later in the mail from FedEx and co., but this basically forces me to pay the shipper&amp;#39;s brokerage fees which sucks. Computers are duty-exempt, so I should only expect to pay taxes.&lt;/p&gt;\n\n&lt;p&gt;For my total CAD $431.61 I should expect to pay CAD $47.48 taxes. SPD at checkout asks me to pay CAD $63.41 for &amp;quot;duty and tax&amp;quot;. I get that it&amp;#39;s not a crazy amount higher, but if I was using a different shipping option, the duty and tax goes all the way up to CAD $145.16!&lt;/p&gt;\n\n&lt;p&gt;What gives, &lt;a href=\"/u/ServerPartDeals\"&gt;/u/ServerPartDeals&lt;/a&gt;? Could we at least have the option back to pay duty/tax ourselves? I am sure this will be more convenient for some people, but we shouldn&amp;#39;t be forced to pay brokerage fees.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ao5q1d", "is_robot_indexable": true, "report_reasons": null, "author": "stenzor", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ao5q1d/serverpartdeals_usa_can_now_forces_included/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ao5q1d/serverpartdeals_usa_can_now_forces_included/", "subreddit_subscribers": 732445, "created_utc": 1707650109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "or forums that contain:\n\nlots of nice stuff, discussion, etc.", "author_fullname": "t2_6ilbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any forums where people talk about datahoarding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1anvuy5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707614190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;or forums that contain:&lt;/p&gt;\n\n&lt;p&gt;lots of nice stuff, discussion, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1anvuy5", "is_robot_indexable": true, "report_reasons": null, "author": "zuperfly", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1anvuy5/are_there_any_forums_where_people_talk_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1anvuy5/are_there_any_forums_where_people_talk_about/", "subreddit_subscribers": 732445, "created_utc": 1707614190.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}