{"kind": "Listing", "data": {"after": "t3_1aoj4m3", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c0f70ajh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What we learned after running Airflow on Kubernetes for 2 years", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1aofpbr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 137, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 137, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/NRo17tiAO9hX-xEB-0yUrdp8w5CHKVLe_oFL_qX5B50.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707678469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "api.daily.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://api.daily.dev/r/HAWJyvDVy", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JM8TAVP2x3Lg1S8Fx0XXjWfC9Jn16ZSotxFMrpvf8FY.jpg?auto=webp&amp;s=437d341e11e658f5b720f1602f9bb1a61c0789af", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/JM8TAVP2x3Lg1S8Fx0XXjWfC9Jn16ZSotxFMrpvf8FY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc32c2c535eddb86279543c58fff194a4d4e68b7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/JM8TAVP2x3Lg1S8Fx0XXjWfC9Jn16ZSotxFMrpvf8FY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f7fbc05f0c633fe410fa9b1116bcb5b28dff2d5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/JM8TAVP2x3Lg1S8Fx0XXjWfC9Jn16ZSotxFMrpvf8FY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6193685e5d95ed6ab4bf61fc5f7cf444848c973e", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/JM8TAVP2x3Lg1S8Fx0XXjWfC9Jn16ZSotxFMrpvf8FY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2dabe2feab2d4684d98c93652704ef5db8c53938", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/JM8TAVP2x3Lg1S8Fx0XXjWfC9Jn16ZSotxFMrpvf8FY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7690b6333d0278538cdd7c37a4f02adf556a47d9", "width": 960, "height": 960}], "variants": {}, "id": "222hXEHjEQgP5OrY9yu26A_RbxQRGXyluMOeD7ebrNA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aofpbr", "is_robot_indexable": true, "report_reasons": null, "author": "UpvoteBeast", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aofpbr/what_we_learned_after_running_airflow_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://api.daily.dev/r/HAWJyvDVy", "subreddit_subscribers": 160164, "created_utc": 1707678469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The other day I came across a post essentially wondering why data engineering positions often had less than 30 applications after a week while data science positions have hundreds within hours.\n\n&amp;#x200B;\n\nYet any time I look on linked in, 90% of all data engineering positions have over 100 applicants (or clicks at least) within the first day...\n\n&amp;#x200B;\n\nI'm wondering if I'm inefficient in my search? Essentially I look for jobs needing 4-7 years of experience, minimum 140,000 salary in the US. I look at remote (which obviously get lots of applications) but even when I look at hybrid or in-person roles in various areas (LA, San Diego, San Francisco and Denver metro), it's pretty much the same story. I sort by most recent and only look at jobs posted within the last 24 hours...\n\n&amp;#x200B;\n\nSo I guess what I'm wondering is, is the post I read totally out of touch with reality, or am I doing something wrong in my search, and if so, what should I do differently?", "author_fullname": "t2_gcq3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't understand the other post that said data engineering jobs have fewer than 20 applicants while data science openings have hundreds...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao6xbx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707654674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The other day I came across a post essentially wondering why data engineering positions often had less than 30 applications after a week while data science positions have hundreds within hours.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Yet any time I look on linked in, 90% of all data engineering positions have over 100 applicants (or clicks at least) within the first day...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if I&amp;#39;m inefficient in my search? Essentially I look for jobs needing 4-7 years of experience, minimum 140,000 salary in the US. I look at remote (which obviously get lots of applications) but even when I look at hybrid or in-person roles in various areas (LA, San Diego, San Francisco and Denver metro), it&amp;#39;s pretty much the same story. I sort by most recent and only look at jobs posted within the last 24 hours...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I guess what I&amp;#39;m wondering is, is the post I read totally out of touch with reality, or am I doing something wrong in my search, and if so, what should I do differently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ao6xbx", "is_robot_indexable": true, "report_reasons": null, "author": "johnsonfrusciante", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ao6xbx/i_dont_understand_the_other_post_that_said_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ao6xbx/i_dont_understand_the_other_post_that_said_data/", "subreddit_subscribers": 160164, "created_utc": 1707654674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Github repo:[https://github.com/Zzdragon66/university-reddit-data-dashboard](https://github.com/Zzdragon66/university-reddit-data-dashboard).\n\nHey everyone, here's an update on the previous project. I would really appreciate any suggestions for improvement. Thank you!\n\n## Features\n\n1. The project is entirely hosted on the Google Cloud Platform\n2. This project is ***horizontal scalable***. The scraping workload is evenly distributed across the computer engines(VM). Data manipulation is done through the Spark cluster(Google dataproc), where by increasing the worker node, the workload will be distributed across and finished more quickly.\n3. The data transformation phase incorporates ***deep learning*** techniques to enhance analysis and insights.\n4. For data visualization, the project utilizes D3.js to create graphical representations.\n\n## Project Structure\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ew1cjp8870ic1.png?width=9426&amp;format=png&amp;auto=webp&amp;s=502a9d668f0f7453f770cd9513ac33c041309e7a\n\n## Data Dashboard Examples\n\n## Example Local Dashboard(D3.js)\n\nhttps://preview.redd.it/fdhivgm970ic1.png?width=4038&amp;format=png&amp;auto=webp&amp;s=1bbac51ef3929b0b0ec1c7c21ea7b450bf0e6ed7\n\n## Example Google Looker Studio Data Dashboard\n\n[Looker Studio Data Dashboard](https://lookerstudio.google.com/s/hEfY-Q6G4Fo)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/m5imqa5b70ic1.png?width=2886&amp;format=png&amp;auto=webp&amp;s=32ea902c25e4f16b55da2085912d7585c743c6c5\n\n## Tools\n\n1. Python\n   1. PyTorch\n   2. Google Cloud Client Library\n   3. Huggingface\n2. Spark(*Data manipulation*)\n3. Apache Airflow(*Data orchestration*)\n   1. Dynamic DAG generation\n   2. Xcom\n   3. Variables\n   4. TaskGroup\n4. Google Cloud Platform\n   1. Computer Engine(*VM &amp; Deep learning*)\n   2. Dataproc (*Spark*)\n   3. Bigquery (*SQL*)\n   4. Cloud Storage (*Data Storage*)\n   5. Looker Studio (*Data visualization*)\n   6. VPC Network and Firewall Rules\n5. Terraform(*Cloud Infrastructure Management*)\n6. Docker(*containerization*) and Dockerhub(*Distribute container images*)\n7. SQL(*Data Manipulation*)\n8. Javascript\n   1. D3.js for data visualization\n9. Makefile", "author_fullname": "t2_5igde9z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Updated] Personal End-End ETL data pipeline(GCP, SPARK, AIRFLOW, TERRAFORM, DOCKER, DL, D3.JS)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ew1cjp8870ic1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/ew1cjp8870ic1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c8ed61f4421021c1f25fb50acff0758856180878"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/ew1cjp8870ic1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=adce36a6133b6aa9557b327bda71926d921274e9"}, {"y": 116, "x": 320, "u": "https://preview.redd.it/ew1cjp8870ic1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7244b9b08d87f76fa088e34766fc34b6c4c76c25"}, {"y": 232, "x": 640, "u": "https://preview.redd.it/ew1cjp8870ic1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=09fd658166fa41a4820a279c0fff772c40175992"}, {"y": 348, "x": 960, "u": "https://preview.redd.it/ew1cjp8870ic1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9f02e11ed2b9f98fa7ef1fbcb554d2549b16e164"}, {"y": 391, "x": 1080, "u": "https://preview.redd.it/ew1cjp8870ic1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f8a79215dfe71cfdded2084a53802170f7d05911"}], "s": {"y": 3420, "x": 9426, "u": "https://preview.redd.it/ew1cjp8870ic1.png?width=9426&amp;format=png&amp;auto=webp&amp;s=502a9d668f0f7453f770cd9513ac33c041309e7a"}, "id": "ew1cjp8870ic1"}, "fdhivgm970ic1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/fdhivgm970ic1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=35279c5206c5b6f019c7feb73f91b6c09af4f676"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/fdhivgm970ic1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=87c0295eae64831dd434292ac93888a5e89bebd8"}, {"y": 150, "x": 320, "u": "https://preview.redd.it/fdhivgm970ic1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb800ba4578a4854d6d78d186cf307eba2a0fa0b"}, {"y": 300, "x": 640, "u": "https://preview.redd.it/fdhivgm970ic1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b3b2ef54596bbd3ac6aaa259bf3be4b78d72aa66"}, {"y": 450, "x": 960, "u": "https://preview.redd.it/fdhivgm970ic1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b724b4637b5a57e8a88e65fc2b64cd261c0d0678"}, {"y": 507, "x": 1080, "u": "https://preview.redd.it/fdhivgm970ic1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5d73ea5df080d681f51125678d8bceac869be5e9"}], "s": {"y": 1896, "x": 4038, "u": "https://preview.redd.it/fdhivgm970ic1.png?width=4038&amp;format=png&amp;auto=webp&amp;s=1bbac51ef3929b0b0ec1c7c21ea7b450bf0e6ed7"}, "id": "fdhivgm970ic1"}, "m5imqa5b70ic1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/m5imqa5b70ic1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=616a7a46aa150b08e4ad8e053d0b73204e4a727c"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/m5imqa5b70ic1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4918166e170095d7259383d29303f109235068e0"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/m5imqa5b70ic1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=503e9376b64a3cc6f2de6eeb2677aae5509d5a76"}, {"y": 474, "x": 640, "u": "https://preview.redd.it/m5imqa5b70ic1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=30d7bab717117438c5b6b06644d300b3413bcd9d"}, {"y": 711, "x": 960, "u": "https://preview.redd.it/m5imqa5b70ic1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5bae71ea60fea5abcff78eed106be339a6711aea"}, {"y": 800, "x": 1080, "u": "https://preview.redd.it/m5imqa5b70ic1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=17a5423322213e3f8d34cedb40049a4b09556c53"}], "s": {"y": 2138, "x": 2886, "u": "https://preview.redd.it/m5imqa5b70ic1.png?width=2886&amp;format=png&amp;auto=webp&amp;s=32ea902c25e4f16b55da2085912d7585c743c6c5"}, "id": "m5imqa5b70ic1"}}, "name": "t3_1aofkv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7LTToHvYuUPEFBx2GEoigXqk54N8JrRlNtK8E4IJUSA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1707678149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Github repo:&lt;a href=\"https://github.com/Zzdragon66/university-reddit-data-dashboard\"&gt;https://github.com/Zzdragon66/university-reddit-data-dashboard&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Hey everyone, here&amp;#39;s an update on the previous project. I would really appreciate any suggestions for improvement. Thank you!&lt;/p&gt;\n\n&lt;h2&gt;Features&lt;/h2&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The project is entirely hosted on the Google Cloud Platform&lt;/li&gt;\n&lt;li&gt;This project is &lt;strong&gt;&lt;em&gt;horizontal scalable&lt;/em&gt;&lt;/strong&gt;. The scraping workload is evenly distributed across the computer engines(VM). Data manipulation is done through the Spark cluster(Google dataproc), where by increasing the worker node, the workload will be distributed across and finished more quickly.&lt;/li&gt;\n&lt;li&gt;The data transformation phase incorporates &lt;strong&gt;&lt;em&gt;deep learning&lt;/em&gt;&lt;/strong&gt; techniques to enhance analysis and insights.&lt;/li&gt;\n&lt;li&gt;For data visualization, the project utilizes D3.js to create graphical representations.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2&gt;Project Structure&lt;/h2&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ew1cjp8870ic1.png?width=9426&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=502a9d668f0f7453f770cd9513ac33c041309e7a\"&gt;https://preview.redd.it/ew1cjp8870ic1.png?width=9426&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=502a9d668f0f7453f770cd9513ac33c041309e7a&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Data Dashboard Examples&lt;/h2&gt;\n\n&lt;h2&gt;Example Local Dashboard(D3.js)&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fdhivgm970ic1.png?width=4038&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1bbac51ef3929b0b0ec1c7c21ea7b450bf0e6ed7\"&gt;https://preview.redd.it/fdhivgm970ic1.png?width=4038&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1bbac51ef3929b0b0ec1c7c21ea7b450bf0e6ed7&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Example Google Looker Studio Data Dashboard&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://lookerstudio.google.com/s/hEfY-Q6G4Fo\"&gt;Looker Studio Data Dashboard&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m5imqa5b70ic1.png?width=2886&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=32ea902c25e4f16b55da2085912d7585c743c6c5\"&gt;https://preview.redd.it/m5imqa5b70ic1.png?width=2886&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=32ea902c25e4f16b55da2085912d7585c743c6c5&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Tools&lt;/h2&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python\n\n&lt;ol&gt;\n&lt;li&gt;PyTorch&lt;/li&gt;\n&lt;li&gt;Google Cloud Client Library&lt;/li&gt;\n&lt;li&gt;Huggingface&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Spark(&lt;em&gt;Data manipulation&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Apache Airflow(&lt;em&gt;Data orchestration&lt;/em&gt;)\n\n&lt;ol&gt;\n&lt;li&gt;Dynamic DAG generation&lt;/li&gt;\n&lt;li&gt;Xcom&lt;/li&gt;\n&lt;li&gt;Variables&lt;/li&gt;\n&lt;li&gt;TaskGroup&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Google Cloud Platform\n\n&lt;ol&gt;\n&lt;li&gt;Computer Engine(&lt;em&gt;VM &amp;amp; Deep learning&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Dataproc (&lt;em&gt;Spark&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Bigquery (&lt;em&gt;SQL&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Cloud Storage (&lt;em&gt;Data Storage&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Looker Studio (&lt;em&gt;Data visualization&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;VPC Network and Firewall Rules&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Terraform(&lt;em&gt;Cloud Infrastructure Management&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Docker(&lt;em&gt;containerization&lt;/em&gt;) and Dockerhub(&lt;em&gt;Distribute container images&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;SQL(&lt;em&gt;Data Manipulation&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Javascript\n\n&lt;ol&gt;\n&lt;li&gt;D3.js for data visualization&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Makefile&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zldZHCckAmmqploRGhSZ9iZrsrFW7iQ9HTaF9W2Xw5Q.jpg?auto=webp&amp;s=3f8dcaa15caacf8384bd61463b8c28a99856354f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/zldZHCckAmmqploRGhSZ9iZrsrFW7iQ9HTaF9W2Xw5Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb4758bf0ed8f28e44bb1f7a697cfc60982b52a7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/zldZHCckAmmqploRGhSZ9iZrsrFW7iQ9HTaF9W2Xw5Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7411b6cf2b7622b35d0a27bf9983a30c52bb8f4e", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/zldZHCckAmmqploRGhSZ9iZrsrFW7iQ9HTaF9W2Xw5Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e84f77a5a72f7f9dcc12a1d540aa23dfecf99bf", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/zldZHCckAmmqploRGhSZ9iZrsrFW7iQ9HTaF9W2Xw5Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=06bb89980164a3ed06701c49c2aeb4649388e0ba", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/zldZHCckAmmqploRGhSZ9iZrsrFW7iQ9HTaF9W2Xw5Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=692d0fc68330ed18aaecc868646b87bcfd63174a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/zldZHCckAmmqploRGhSZ9iZrsrFW7iQ9HTaF9W2Xw5Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0bd366ff7d607b1ec05396474d7cae6ff0e8a296", "width": 1080, "height": 540}], "variants": {}, "id": "tCKgBogZ9tNepZfFFQ21QUDX0HCTKjVu8NJgPg_h-x8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1aofkv9", "is_robot_indexable": true, "report_reasons": null, "author": "AffectionateEmu8146", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aofkv9/updated_personal_endend_etl_data_pipelinegcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aofkv9/updated_personal_endend_etl_data_pipelinegcp/", "subreddit_subscribers": 160164, "created_utc": 1707678149.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I mean BigQuery can be called with the API, so I can just drop the config on a for and call the jobs when I need it orchestrated in Composer.\n\nI know there is the lineage management but I\u2019m not a fan of monolithic trees accumulated somewhere. BQ tables creation often occurs after transforming pipelines in Java or Python.\n\nFinally, I had to write specific functions to \u00ab\u00a0trick\u00a0\u00bb DBT doing the optimization I need (which I could have done directly in SQL by BQ API calls).\n\nDoes someone has an experience with it ?\nI\u2019m not sure what I should think about it.\n\nMy main fear is that people tend to accumulate queries on a single point and make unecessary and dangerous dependencies between tables while not cleaning the mess. Yes a tool is as good as you use it but I feel like the tool itself encourages you to fell on the trap\u2026", "author_fullname": "t2_ly1f1zyul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Isn\u2019t DBT an unecessary layer if you use BigQuery ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aonpuf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707699762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mean BigQuery can be called with the API, so I can just drop the config on a for and call the jobs when I need it orchestrated in Composer.&lt;/p&gt;\n\n&lt;p&gt;I know there is the lineage management but I\u2019m not a fan of monolithic trees accumulated somewhere. BQ tables creation often occurs after transforming pipelines in Java or Python.&lt;/p&gt;\n\n&lt;p&gt;Finally, I had to write specific functions to \u00ab\u00a0trick\u00a0\u00bb DBT doing the optimization I need (which I could have done directly in SQL by BQ API calls).&lt;/p&gt;\n\n&lt;p&gt;Does someone has an experience with it ?\nI\u2019m not sure what I should think about it.&lt;/p&gt;\n\n&lt;p&gt;My main fear is that people tend to accumulate queries on a single point and make unecessary and dangerous dependencies between tables while not cleaning the mess. Yes a tool is as good as you use it but I feel like the tool itself encourages you to fell on the trap\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aonpuf", "is_robot_indexable": true, "report_reasons": null, "author": "VegetableFan6622", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aonpuf/isnt_dbt_an_unecessary_layer_if_you_use_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aonpuf/isnt_dbt_an_unecessary_layer_if_you_use_bigquery/", "subreddit_subscribers": 160164, "created_utc": 1707699762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. Everyone. I'm a data scientist who also does Data Engineering at work depending on the business needs. Pandas is the tool I use the most for data pipelines (if my task doesn't involve big data), and I always face the same problem in the functions I write for the different steps in the pipeline:\n\nHuge functions with only 1 responsibility and too many steps which end up looking like huge blocks of pandas for accomplishing that one task. The thing is that if I start splitting that huge function into smaller parts, then those functions would only exist for that larger function to use.\n\nSo, I ultimately keep those larger functions because I'm not sure whether it is ok to have functions that are only used once for just one \"consumer\"\n\nHow could I deal with this problem in a way that's easier to read, doesn't involve huge walls of pandas and having functions that are highly coupled to one another, and pretty much exist for a \"greater good\" (i dont know what else to call it lol)\n\nNote: I'd like to know if there are common design patterns for this (maybe using OOP)", "author_fullname": "t2_kvl7dwa6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas, high coupling and single responsibility principle in data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aopq7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707706242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. Everyone. I&amp;#39;m a data scientist who also does Data Engineering at work depending on the business needs. Pandas is the tool I use the most for data pipelines (if my task doesn&amp;#39;t involve big data), and I always face the same problem in the functions I write for the different steps in the pipeline:&lt;/p&gt;\n\n&lt;p&gt;Huge functions with only 1 responsibility and too many steps which end up looking like huge blocks of pandas for accomplishing that one task. The thing is that if I start splitting that huge function into smaller parts, then those functions would only exist for that larger function to use.&lt;/p&gt;\n\n&lt;p&gt;So, I ultimately keep those larger functions because I&amp;#39;m not sure whether it is ok to have functions that are only used once for just one &amp;quot;consumer&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;How could I deal with this problem in a way that&amp;#39;s easier to read, doesn&amp;#39;t involve huge walls of pandas and having functions that are highly coupled to one another, and pretty much exist for a &amp;quot;greater good&amp;quot; (i dont know what else to call it lol)&lt;/p&gt;\n\n&lt;p&gt;Note: I&amp;#39;d like to know if there are common design patterns for this (maybe using OOP)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aopq7t", "is_robot_indexable": true, "report_reasons": null, "author": "Confident_Watch8207", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aopq7t/pandas_high_coupling_and_single_responsibility/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aopq7t/pandas_high_coupling_and_single_responsibility/", "subreddit_subscribers": 160164, "created_utc": 1707706242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thinking of using SQL server, and maybe a web app to access/filter content? Hoping someone has any off the shelf solutions. Thank you.", "author_fullname": "t2_60f7heoc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What technology would you use if you had a txt extract of a customer data with 16 million rows, and 30 columns and had to make a \"user friendly\" filtering system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aopf7d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707705251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thinking of using SQL server, and maybe a web app to access/filter content? Hoping someone has any off the shelf solutions. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aopf7d", "is_robot_indexable": true, "report_reasons": null, "author": "Candid94", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aopf7d/what_technology_would_you_use_if_you_had_a_txt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aopf7d/what_technology_would_you_use_if_you_had_a_txt/", "subreddit_subscribers": 160164, "created_utc": 1707705251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a project, the current phase involves parsing PDFs (tables, headers) and extracting the and transforming the data into JSON objects that I am currently dumping into a text files. For reference, the PDFs are 1000+ pages, and produce two lists of JSON objects, one has a size of around 7000+, and other only &lt;1000. The parsing takes about 5-7 minutes for each PDF. There are about 20-30 PDFs that are this large.\n\nMy goal is to create a data pipeline... Or an ETL (I think that's called a data pipeline atleast), that reads the JSON objects (in parallel maybe?) and make some very tiny changes (stripping, splitting strings) on the JSON and dump into a DB. I can use SQLAlchemy as an ORM, but I'll later be writing an [ASP.NET](https://ASP.NET) WebAPI, so can I use Entity Framework for the end of the pipeline?\n\nI also have a daemonized/cron update service (script) that looks for new PDFs, downloads them, I need to feed these to the parser and then the pipeline. How do I achieve this workflow?\n\nThis is my first data engineering project, so I have no idea what tools could help me here (Airflow, Kafka, ...?). How do I get started?", "author_fullname": "t2_45b66kd8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I write a data pipeline (ETL) ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aos0o3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707713997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project, the current phase involves parsing PDFs (tables, headers) and extracting the and transforming the data into JSON objects that I am currently dumping into a text files. For reference, the PDFs are 1000+ pages, and produce two lists of JSON objects, one has a size of around 7000+, and other only &amp;lt;1000. The parsing takes about 5-7 minutes for each PDF. There are about 20-30 PDFs that are this large.&lt;/p&gt;\n\n&lt;p&gt;My goal is to create a data pipeline... Or an ETL (I think that&amp;#39;s called a data pipeline atleast), that reads the JSON objects (in parallel maybe?) and make some very tiny changes (stripping, splitting strings) on the JSON and dump into a DB. I can use SQLAlchemy as an ORM, but I&amp;#39;ll later be writing an &lt;a href=\"https://ASP.NET\"&gt;ASP.NET&lt;/a&gt; WebAPI, so can I use Entity Framework for the end of the pipeline?&lt;/p&gt;\n\n&lt;p&gt;I also have a daemonized/cron update service (script) that looks for new PDFs, downloads them, I need to feed these to the parser and then the pipeline. How do I achieve this workflow?&lt;/p&gt;\n\n&lt;p&gt;This is my first data engineering project, so I have no idea what tools could help me here (Airflow, Kafka, ...?). How do I get started?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RvqZTha_jpsuzZWXfSdwZNHZ_Qvk62R3yl7YvkufrqI.jpg?auto=webp&amp;s=dac8ba253829e5b1a0d52a07b3d96fc9ec6f1a5a", "width": 238, "height": 238}, "resolutions": [{"url": "https://external-preview.redd.it/RvqZTha_jpsuzZWXfSdwZNHZ_Qvk62R3yl7YvkufrqI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=45348c732a19d9a609ae09564dd3c1bcd96ee24e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/RvqZTha_jpsuzZWXfSdwZNHZ_Qvk62R3yl7YvkufrqI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=062f6b4f074cf5d7329ced227851ad27f4336d8d", "width": 216, "height": 216}], "variants": {}, "id": "TtFVmEs53hWc_tUPscFPQzT0bv04t5CPuG5-SNnw3mo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aos0o3", "is_robot_indexable": true, "report_reasons": null, "author": "c0m94d3", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aos0o3/how_do_i_write_a_data_pipeline_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aos0o3/how_do_i_write_a_data_pipeline_etl/", "subreddit_subscribers": 160164, "created_utc": 1707713997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm student haven't worked professionally as DE but wanted to. All I hear about is python. Do we require java in DE ?", "author_fullname": "t2_k8v1awvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is java in the filed of DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao72iv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707655185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m student haven&amp;#39;t worked professionally as DE but wanted to. All I hear about is python. Do we require java in DE ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ao72iv", "is_robot_indexable": true, "report_reasons": null, "author": "hrishinstagram", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ao72iv/how_important_is_java_in_the_filed_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ao72iv/how_important_is_java_in_the_filed_of_de/", "subreddit_subscribers": 160164, "created_utc": 1707655185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI've been doing this for circa 4 years now, only building code based solutions.\n\nI'm chewing on an offer to switch companies (it's a good offer and my current employer sucks), and I've been told in the interview that they are considering Dataverse as their data warehouse. \n\nI'm not well acquainted with the solution, and I couldn't find a lot of resources online that would indicate that it's used for data warehousing initiatives.\n\nSome factors to consider:\n- I will be the only data engineer, everyone else is business\n- 150 employee company\n- Microsoft shop\n- Very traditional requirements\n- Data volume is very low\n-Very few tables, very few sources\n- For what I've gathered in the interview, the data requirements will not grow that much\n- They considered dataverse because no-one in the company has dev experience, so the \"Head of IT\" want an easy clickity-click solution\n\nFrom a personal point of view, I don't like the fact that I won't be able to interact with the database directly. And I won't be able to use stored procedures for data transformation (I tend to do ELT), but I will have to rely in dataflow/ADF/logicapps. And also, I guess CICD is out of the question.\n\nAdditionally, I don't mind spinning and maintaining the resources I need in Azure (DB instance, VMs for runtime, network, vault, etc), so I can't see a single benefit of dataverse from an infra point of view.\n\nI appreciate some out of the box features, but I don't need them and I don't see them cutting deployment times significantly.\n\nDespite all of the above, I'm sure I can make it work with Dataverse. So the question is: Why Dataverse would not be a good solution? Does anyone have experience with it? I don't want to accept the position, say yes to Dataverse and find out that is not viable.", "author_fullname": "t2_83poggkq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataverse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aoenig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707699634.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707675829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been doing this for circa 4 years now, only building code based solutions.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m chewing on an offer to switch companies (it&amp;#39;s a good offer and my current employer sucks), and I&amp;#39;ve been told in the interview that they are considering Dataverse as their data warehouse. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not well acquainted with the solution, and I couldn&amp;#39;t find a lot of resources online that would indicate that it&amp;#39;s used for data warehousing initiatives.&lt;/p&gt;\n\n&lt;p&gt;Some factors to consider:\n- I will be the only data engineer, everyone else is business\n- 150 employee company\n- Microsoft shop\n- Very traditional requirements\n- Data volume is very low\n-Very few tables, very few sources\n- For what I&amp;#39;ve gathered in the interview, the data requirements will not grow that much\n- They considered dataverse because no-one in the company has dev experience, so the &amp;quot;Head of IT&amp;quot; want an easy clickity-click solution&lt;/p&gt;\n\n&lt;p&gt;From a personal point of view, I don&amp;#39;t like the fact that I won&amp;#39;t be able to interact with the database directly. And I won&amp;#39;t be able to use stored procedures for data transformation (I tend to do ELT), but I will have to rely in dataflow/ADF/logicapps. And also, I guess CICD is out of the question.&lt;/p&gt;\n\n&lt;p&gt;Additionally, I don&amp;#39;t mind spinning and maintaining the resources I need in Azure (DB instance, VMs for runtime, network, vault, etc), so I can&amp;#39;t see a single benefit of dataverse from an infra point of view.&lt;/p&gt;\n\n&lt;p&gt;I appreciate some out of the box features, but I don&amp;#39;t need them and I don&amp;#39;t see them cutting deployment times significantly.&lt;/p&gt;\n\n&lt;p&gt;Despite all of the above, I&amp;#39;m sure I can make it work with Dataverse. So the question is: Why Dataverse would not be a good solution? Does anyone have experience with it? I don&amp;#39;t want to accept the position, say yes to Dataverse and find out that is not viable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aoenig", "is_robot_indexable": true, "report_reasons": null, "author": "Ancient-Entry-6436", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aoenig/dataverse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aoenig/dataverse/", "subreddit_subscribers": 160164, "created_utc": 1707675829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI'm currently in my first year working as a Data Engineer for a consulting company, with a focus on platforms dedicated to Data Management, Data Quality, and Data Governance. In my role as a Data Engineer and Product Specialist, my primary responsibilities include implementing (rather than designing) data quality controls and overseeing the ETL process. My main clients are in the banking and financial sectors.\n\nI plan to continue in this role for three years before seeking a transition to a Product Manager or Data Governance Manager position.\n\nTo enhance my expertise in this field and achieve my medium-term goals, I'm considering pursuing the CDMP (Certified Data Management Professional) certification, specifically aiming for the Professional level with specializations in Data Governance and Data Quality.\n\nMy question is about the costs associated with these specialization exams: Are they included in the CDMP exam fee, or do I need to budget for additional fees for these specializations?\n\nI'd appreciate any advice on my career and certification goals, especially considering I have only seven months of experience in this field. However, I am confident that this is the path I want to pursue, with the long-term ambition of becoming a Chief Data Officer in the next 10-15 years.\n\nTLDR: First-year Data Engineer aiming for CDMP certification with specializations in Data Governance and Data Quality. Wondering if specialization exam fees are separate from the CDMP exam fee and seeking career advice with a long-term goal of becoming a Chief Data Officer.", "author_fullname": "t2_bzkl24up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CDMP - DAMA Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao7gya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707656526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently in my first year working as a Data Engineer for a consulting company, with a focus on platforms dedicated to Data Management, Data Quality, and Data Governance. In my role as a Data Engineer and Product Specialist, my primary responsibilities include implementing (rather than designing) data quality controls and overseeing the ETL process. My main clients are in the banking and financial sectors.&lt;/p&gt;\n\n&lt;p&gt;I plan to continue in this role for three years before seeking a transition to a Product Manager or Data Governance Manager position.&lt;/p&gt;\n\n&lt;p&gt;To enhance my expertise in this field and achieve my medium-term goals, I&amp;#39;m considering pursuing the CDMP (Certified Data Management Professional) certification, specifically aiming for the Professional level with specializations in Data Governance and Data Quality.&lt;/p&gt;\n\n&lt;p&gt;My question is about the costs associated with these specialization exams: Are they included in the CDMP exam fee, or do I need to budget for additional fees for these specializations?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any advice on my career and certification goals, especially considering I have only seven months of experience in this field. However, I am confident that this is the path I want to pursue, with the long-term ambition of becoming a Chief Data Officer in the next 10-15 years.&lt;/p&gt;\n\n&lt;p&gt;TLDR: First-year Data Engineer aiming for CDMP certification with specializations in Data Governance and Data Quality. Wondering if specialization exam fees are separate from the CDMP exam fee and seeking career advice with a long-term goal of becoming a Chief Data Officer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ao7gya", "is_robot_indexable": true, "report_reasons": null, "author": "_CT-5555_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ao7gya/cdmp_dama_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ao7gya/cdmp_dama_certification/", "subreddit_subscribers": 160164, "created_utc": 1707656526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious on thoughts. With the Snowflake release of Dynamic Tables, and the ability to have them update on a schedule, triggered from the last table in the DAG, is there still a place for dbt on Snowflake?\n\nI get that it comes with docs, and a nice viz for lineage, but these things aren\u2019t hard to pull together in other ways.\n\nKeen to hear others thoughts.", "author_fullname": "t2_ojr03vx2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is dbt still relevant on Snowflake with Dynamic Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aovhqs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707727196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious on thoughts. With the Snowflake release of Dynamic Tables, and the ability to have them update on a schedule, triggered from the last table in the DAG, is there still a place for dbt on Snowflake?&lt;/p&gt;\n\n&lt;p&gt;I get that it comes with docs, and a nice viz for lineage, but these things aren\u2019t hard to pull together in other ways.&lt;/p&gt;\n\n&lt;p&gt;Keen to hear others thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aovhqs", "is_robot_indexable": true, "report_reasons": null, "author": "nydasco", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aovhqs/is_dbt_still_relevant_on_snowflake_with_dynamic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aovhqs/is_dbt_still_relevant_on_snowflake_with_dynamic/", "subreddit_subscribers": 160164, "created_utc": 1707727196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m managing a table for streaming data in databricks\nand I want to split it into two: \n1. hot table for the last 7 days\n2. \u2060cold table for historical data. \n\nCurrently, I'm moving data from the hot table to the cold table daily and then deleting it from the hot table. \nThis process is scheduled daily. \n\nIs there a more efficient approach than this?\n\nI can't use the merge option due to the large volume of data", "author_fullname": "t2_ptil4bof4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to manage Hot and Cold Tables for Streaming Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aoue6j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707722542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m managing a table for streaming data in databricks\nand I want to split it into two: \n1. hot table for the last 7 days\n2. \u2060cold table for historical data. &lt;/p&gt;\n\n&lt;p&gt;Currently, I&amp;#39;m moving data from the hot table to the cold table daily and then deleting it from the hot table. \nThis process is scheduled daily. &lt;/p&gt;\n\n&lt;p&gt;Is there a more efficient approach than this?&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t use the merge option due to the large volume of data&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aoue6j", "is_robot_indexable": true, "report_reasons": null, "author": "HousingStriking3770", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aoue6j/how_to_manage_hot_and_cold_tables_for_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aoue6j/how_to_manage_hot_and_cold_tables_for_streaming/", "subreddit_subscribers": 160164, "created_utc": 1707722542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am graduating with a CS degree soon and having a hard time finding a SWE engineering internship. It seems like DE internships are just as competitive. What are some ideas for roles suitable for a CS graduate that enable you to transition to DE? I have been applying to data analyst, business analyst/intelligence, IT internship ect. Not sure what the best path forward to start would be , since I\u2019m striking out with software/data engineering internships as of now. I am trying to find roles that are doable for me to get in this rough market but aren\u2019t dead end roles that won\u2019t be progressing my technical skills to reach one of my end goals (Data engineering, software engineering, cloud engineering). Don\u2019t really have the luxury of applying for a year after graduation, bills have to be paid. If anyone has role suggestions I haven\u2019t listed that would great. Thanks ", "author_fullname": "t2_126xnl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Viable starting paths to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aouc2b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707722769.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707722313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am graduating with a CS degree soon and having a hard time finding a SWE engineering internship. It seems like DE internships are just as competitive. What are some ideas for roles suitable for a CS graduate that enable you to transition to DE? I have been applying to data analyst, business analyst/intelligence, IT internship ect. Not sure what the best path forward to start would be , since I\u2019m striking out with software/data engineering internships as of now. I am trying to find roles that are doable for me to get in this rough market but aren\u2019t dead end roles that won\u2019t be progressing my technical skills to reach one of my end goals (Data engineering, software engineering, cloud engineering). Don\u2019t really have the luxury of applying for a year after graduation, bills have to be paid. If anyone has role suggestions I haven\u2019t listed that would great. Thanks &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aouc2b", "is_robot_indexable": true, "report_reasons": null, "author": "Kylerhanley", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aouc2b/viable_starting_paths_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aouc2b/viable_starting_paths_to_de/", "subreddit_subscribers": 160164, "created_utc": 1707722313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi everyone :)\n\nI've been working on a cool project in the past 1.5 months and I was wondering if you'd like to try it. It's called Merlinn, and it's for fellow engineers and anyone who use observability tools. It's an LLM agent designed to speed up incident resolution and minimize the Mean Time to Resolution (MTTR).\n\nWhat it does is it basically connects to your observability tools and data sources and tries to investigate production alerts &amp; incidents on its own, and provide key findings in seconds directly to Slack. You can learn more about it in this website: [https://merlinn.co](https://merlinn.co/)\n\nI'd really love to get some feedback on that and talk about how you investigate and resolve incidents &amp; alerts in your organization. I plan on building more integrations (OpenTelemetry, Prometheus, Google Cloud Logging, etc) and I'd love to talk with the community about observability.", "author_fullname": "t2_n9em3bcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I developed a cool new LLM agent that helps with investigating and resolving alerts faster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aoy4oo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707738198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone :)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on a cool project in the past 1.5 months and I was wondering if you&amp;#39;d like to try it. It&amp;#39;s called Merlinn, and it&amp;#39;s for fellow engineers and anyone who use observability tools. It&amp;#39;s an LLM agent designed to speed up incident resolution and minimize the Mean Time to Resolution (MTTR).&lt;/p&gt;\n\n&lt;p&gt;What it does is it basically connects to your observability tools and data sources and tries to investigate production alerts &amp;amp; incidents on its own, and provide key findings in seconds directly to Slack. You can learn more about it in this website: &lt;a href=\"https://merlinn.co/\"&gt;https://merlinn.co&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d really love to get some feedback on that and talk about how you investigate and resolve incidents &amp;amp; alerts in your organization. I plan on building more integrations (OpenTelemetry, Prometheus, Google Cloud Logging, etc) and I&amp;#39;d love to talk with the community about observability.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1aoy4oo", "is_robot_indexable": true, "report_reasons": null, "author": "Old_Cauliflower6316", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aoy4oo/i_developed_a_cool_new_llm_agent_that_helps_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aoy4oo/i_developed_a_cool_new_llm_agent_that_helps_with/", "subreddit_subscribers": 160164, "created_utc": 1707738198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been using dbt for over a year by now and i was one of those who requested to have such a Materialization as a feature to be added to dbt\n\nAnd it went out now in the stable release and got documented and that's all great right ! \ud83d\udc4d\n\nBut there is this one config that I can't wrap my head around\n\nOn configuration_change= \nApply\nContinue\nFail\n\nWhat are these values mean ? Especially when running things ... I can't debug their behavior, so any ideas what are they inteded to be doing ?", "author_fullname": "t2_2xhlwgrk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The dbt Materialzed_views Materialization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aowiur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707731795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been using dbt for over a year by now and i was one of those who requested to have such a Materialization as a feature to be added to dbt&lt;/p&gt;\n\n&lt;p&gt;And it went out now in the stable release and got documented and that&amp;#39;s all great right ! \ud83d\udc4d&lt;/p&gt;\n\n&lt;p&gt;But there is this one config that I can&amp;#39;t wrap my head around&lt;/p&gt;\n\n&lt;p&gt;On configuration_change= \nApply\nContinue\nFail&lt;/p&gt;\n\n&lt;p&gt;What are these values mean ? Especially when running things ... I can&amp;#39;t debug their behavior, so any ideas what are they inteded to be doing ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aowiur", "is_robot_indexable": true, "report_reasons": null, "author": "etsh_96", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aowiur/the_dbt_materialzed_views_materialization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aowiur/the_dbt_materialzed_views_materialization/", "subreddit_subscribers": 160164, "created_utc": 1707731795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any advice on using Nsx VMware for distributed firewall?", "author_fullname": "t2_8rpwh5mr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nsx VMware", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aohyqj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707684144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any advice on using Nsx VMware for distributed firewall?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aohyqj", "is_robot_indexable": true, "report_reasons": null, "author": "OldParticular2326", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aohyqj/nsx_vmware/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aohyqj/nsx_vmware/", "subreddit_subscribers": 160164, "created_utc": 1707684144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_zrj6c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Kafka Connect Single Message Transform (SMT) that enables you to append the record key to the value as a named field", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1aogoyd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/uX8hbHz46H5hrJgC-dAY9N_fDq5DRCwATkCyQM29h48.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707680980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/EladLeev/KeyToField-smt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aJ-4JNsLhN7t0oyMpXRmjT5fMkwsRx8kpYf8CAw4Ies.jpg?auto=webp&amp;s=3de20284b26273a6606b364fff05c750011d095e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aJ-4JNsLhN7t0oyMpXRmjT5fMkwsRx8kpYf8CAw4Ies.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5b40d4a2c8cfa1782bf347cb2feeeadf06443bbc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aJ-4JNsLhN7t0oyMpXRmjT5fMkwsRx8kpYf8CAw4Ies.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b7f3d119bf1e030b052196dd89ca5a5ee126744c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aJ-4JNsLhN7t0oyMpXRmjT5fMkwsRx8kpYf8CAw4Ies.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=190dee468e9065a9a140fdff48015c09f3cca672", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aJ-4JNsLhN7t0oyMpXRmjT5fMkwsRx8kpYf8CAw4Ies.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d9e755bb1bfb955fa0c383a7b2fb0baaf207d5b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aJ-4JNsLhN7t0oyMpXRmjT5fMkwsRx8kpYf8CAw4Ies.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7896542d66d52da9834e58bc4e38378e39fab587", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aJ-4JNsLhN7t0oyMpXRmjT5fMkwsRx8kpYf8CAw4Ies.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49d521727ba8409e43c16bb8980f134082dd471c", "width": 1080, "height": 540}], "variants": {}, "id": "PKDvWqp1Rpki1irwpQ9gcknTnQXYIowvDTsW7KKujSs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1aogoyd", "is_robot_indexable": true, "report_reasons": null, "author": "eladleev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aogoyd/a_kafka_connect_single_message_transform_smt_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/EladLeev/KeyToField-smt", "subreddit_subscribers": 160164, "created_utc": 1707680980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am doing a demo and I want to pull data from an API that has recent data. I want to call this API twice and show new data came in. The demo is 5 minutes so I need some API that is refreshing at least once per minute.\n\nAny suggestions for a data source? I am thinking something like weather data etc. The type of data is not super important, just want to show new data points coming in.", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aogc7m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707680103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am doing a demo and I want to pull data from an API that has recent data. I want to call this API twice and show new data came in. The demo is 5 minutes so I need some API that is refreshing at least once per minute.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for a data source? I am thinking something like weather data etc. The type of data is not super important, just want to show new data points coming in.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aogc7m", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aogc7m/data_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aogc7m/data_api/", "subreddit_subscribers": 160164, "created_utc": 1707680103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have got couple of questions with respect to Data Masking. a)What's the industry wide practice used to mask the data within AWS?. \nb)Data exist in on one Account and the data is supposed to be masked before brought into another account in AWS. What all services can be utilsied to perform the activity?", "author_fullname": "t2_5g6fe54r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Masking Within AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao6xqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707654712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have got couple of questions with respect to Data Masking. a)What&amp;#39;s the industry wide practice used to mask the data within AWS?. \nb)Data exist in on one Account and the data is supposed to be masked before brought into another account in AWS. What all services can be utilsied to perform the activity?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ao6xqq", "is_robot_indexable": true, "report_reasons": null, "author": "codeinsync", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ao6xqq/data_masking_within_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ao6xqq/data_masking_within_aws/", "subreddit_subscribers": 160164, "created_utc": 1707654712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, i am using aws glue to load big query data into dynamic dataframe but it is taking time. Is there a way to directly load big query data into spark dataframe using glue?", "author_fullname": "t2_3p3vfvzt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Loading big query data to spark dataframe.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aoy0ku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707737768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, i am using aws glue to load big query data into dynamic dataframe but it is taking time. Is there a way to directly load big query data into spark dataframe using glue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aoy0ku", "is_robot_indexable": true, "report_reasons": null, "author": "Dr_Fida", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aoy0ku/loading_big_query_data_to_spark_dataframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aoy0ku/loading_big_query_data_to_spark_dataframe/", "subreddit_subscribers": 160164, "created_utc": 1707737768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all\n\nI currently work a lot with SAP HANA, have done it for 3 years now.\n\nNow that I'm thinking for a switch , I have 2 options...find a SAP HANA DB based job (which won't require a lot of upskilling )\n\nOr else upskill in next 5 months and find a proper data engineer related job\n\nWhat is better financially and growth wise?", "author_fullname": "t2_6ociw9qb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAP HANA jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aoxq13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707736655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all&lt;/p&gt;\n\n&lt;p&gt;I currently work a lot with SAP HANA, have done it for 3 years now.&lt;/p&gt;\n\n&lt;p&gt;Now that I&amp;#39;m thinking for a switch , I have 2 options...find a SAP HANA DB based job (which won&amp;#39;t require a lot of upskilling )&lt;/p&gt;\n\n&lt;p&gt;Or else upskill in next 5 months and find a proper data engineer related job&lt;/p&gt;\n\n&lt;p&gt;What is better financially and growth wise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aoxq13", "is_robot_indexable": true, "report_reasons": null, "author": "Adorable_Finance3027", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aoxq13/sap_hana_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aoxq13/sap_hana_jobs/", "subreddit_subscribers": 160164, "created_utc": 1707736655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why using query builder when you have ORM ? Why Knex when you can have prisma ?\n\nCan you handle big application with query builder only and not ORM ? Is is tedious to not have intellisense when using query builder ? \n\nThanks, you production guys \ud83d\ude0e", "author_fullname": "t2_5lg752r5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ORM vs query builder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aolwjt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707694360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why using query builder when you have ORM ? Why Knex when you can have prisma ?&lt;/p&gt;\n\n&lt;p&gt;Can you handle big application with query builder only and not ORM ? Is is tedious to not have intellisense when using query builder ? &lt;/p&gt;\n\n&lt;p&gt;Thanks, you production guys \ud83d\ude0e&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aolwjt", "is_robot_indexable": true, "report_reasons": null, "author": "colet_te", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aolwjt/orm_vs_query_builder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aolwjt/orm_vs_query_builder/", "subreddit_subscribers": 160164, "created_utc": 1707694360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. Anyone has any experience working in abbott as senior DE. Want to know the work culture or pros/cons working at abbott IL location. \nI have gone through the glass door and indeed but i don\u2019t trust them as negative reviews can be deleted from them.", "author_fullname": "t2_t0zkmfpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with Abbott?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aolkgc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707693429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. Anyone has any experience working in abbott as senior DE. Want to know the work culture or pros/cons working at abbott IL location. \nI have gone through the glass door and indeed but i don\u2019t trust them as negative reviews can be deleted from them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aolkgc", "is_robot_indexable": true, "report_reasons": null, "author": "Terrible_Mud5318", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aolkgc/experience_with_abbott/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aolkgc/experience_with_abbott/", "subreddit_subscribers": 160164, "created_utc": 1707693429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since every company is now riding the GenAI bandwagon. How has your work as a DE changed with relation to GenAi? What are some of new changes that have come to your work/ skills expected/ new architecture designs ?", "author_fullname": "t2_9ckbn9tf2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GenAI and DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aol2vr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707692116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since every company is now riding the GenAI bandwagon. How has your work as a DE changed with relation to GenAi? What are some of new changes that have come to your work/ skills expected/ new architecture designs ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aol2vr", "is_robot_indexable": true, "report_reasons": null, "author": "Wise_Shop6419", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aol2vr/genai_and_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aol2vr/genai_and_de/", "subreddit_subscribers": 160164, "created_utc": 1707692116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nSo maybe I am mistaken but I recently got more into the azure data stack and to me it seems, there are no easy ways to do complex data transformations in azure. Sure you can do data flow actions or notebooks but there are no way to do complex, multi table transformations like for example in dbt. Am I missing something?\n\nCheers", "author_fullname": "t2_yobj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complex data transformations in azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aoj4m3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707687098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;So maybe I am mistaken but I recently got more into the azure data stack and to me it seems, there are no easy ways to do complex data transformations in azure. Sure you can do data flow actions or notebooks but there are no way to do complex, multi table transformations like for example in dbt. Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aoj4m3", "is_robot_indexable": true, "report_reasons": null, "author": "lschozar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aoj4m3/complex_data_transformations_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aoj4m3/complex_data_transformations_in_azure/", "subreddit_subscribers": 160164, "created_utc": 1707687098.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}