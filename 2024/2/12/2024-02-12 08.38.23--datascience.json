{"kind": "Listing", "data": {"after": null, "dist": 5, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data science already requires a ton of domain knowledge to go beyond a junior level in the current job market(and descriptions!), but when do you think it will no longer be commonplace to see a job for \u201cdata scientist\u201d or \u201cdata engineer\u201d with common requirements +preferred experience and see more jobs like \u201ccontent delivery algorithm scientist\u201d , \u201cmedical support optimization analyst\u201d or a \u201cSalesforce data pipelining engineer\u201d?  I know that we do already see roles like this, just wondering what y\u2019all think on how many years it\u2019ll be before data science goes the way of the business analyst and IT specialists.", "author_fullname": "t2_14wbpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many years do you think until data science, analysis, and engineering(MLE, etc.) roles split into domain specific roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aoko0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707691038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data science already requires a ton of domain knowledge to go beyond a junior level in the current job market(and descriptions!), but when do you think it will no longer be commonplace to see a job for \u201cdata scientist\u201d or \u201cdata engineer\u201d with common requirements +preferred experience and see more jobs like \u201ccontent delivery algorithm scientist\u201d , \u201cmedical support optimization analyst\u201d or a \u201cSalesforce data pipelining engineer\u201d?  I know that we do already see roles like this, just wondering what y\u2019all think on how many years it\u2019ll be before data science goes the way of the business analyst and IT specialists.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1aoko0o", "is_robot_indexable": true, "report_reasons": null, "author": "kater543", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aoko0o/how_many_years_do_you_think_until_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aoko0o/how_many_years_do_you_think_until_data_science/", "subreddit_subscribers": 1328435, "created_utc": 1707691038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Cross Entropy Loss for multi class classification, when the last layer is Softmax**\n\nThe misconception is that the network *only* learns from its prediction on the correct class\n\nIt is common online to see comments [like this one](https://datascience.stackexchange.com/a/20301/159699), that, while technically true, obfuscate the understanding of how a neural network updates its parameters after training on a single sample in multi-class classification. Other comments, [such as this one](https://datascience.stackexchange.com/a/31966/159699), [and this one](https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation/24696#comment91209_24696), are flat out wrong. This makes studying this topic especially confusing, so I wanted to clear some things up.\n\n# The Common Misconception\n\n&gt;The Cross Entropy Loss function for a single sample can be written as \ud835\udc3f = \u2212 **\ud835\udc32 \u22c5** log( **\ud835\udc32\u0302**\u00a0) . Therefore the Loss is only dependent on the active class in the y-vector, because that will be the only nonzero term after the dot product.^((This part is true))  \n&gt;  \n&gt;Therefore the neural network only learns from its prediction on the correct class\n\n**That is not true!**\n\nMinimizing the loss function is the objective, but the learning is performed with the gradient of the loss function. More specifically, the parameter updates are given by the learning rate times the negative gradient of the loss function with respect to the model parameters. Even though the Loss function will not change based on the predicted probabilities for the incorrect classes, its gradient does depend on those values.\n\nI can't really write equations here, but from *Neural Networks and Deep Learning, Charu C. Aggarwal*, the gradient for a **single layer network** (multinomial logistic regression)\u200b is given by\n\n\u2202L/\u2202W = {\n\nfor the correct class: -Xi ( 1 - \u0177 )\n\nfor the incorrect class: Xi \u0177\n\n}\n\nor in matrix form:  \u2202L/\u2202W = - Xi (y - \u0177)^(T)\n\nSo the gradient will be a matrix the same shape as the weight matrix.\n\nSo we can see that the model is penalized for:\n\n1. Predicting a small probability for the correct class\n2. Predicting a large probability for the incorrect class\n\n&amp;#x200B;\n\n**Generalizing to a multilayer network**\n\nThe gradient from a single training sample back propagates through each of the prediction neurons, to the specific weight vector pertaining to that neuron in the last weight matrix, as that is its only dependence. The overall weight matrix has k such vectors, for each of the classes. As the gradient back propagates further back into the network, the gradient on a singular weight element will be a sum of the k gradients originating at the prediction neurons.", "author_fullname": "t2_artaa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Common Misconception About Cross Entropy Loss", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aodk18", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707680580.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707673083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Cross Entropy Loss for multi class classification, when the last layer is Softmax&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The misconception is that the network &lt;em&gt;only&lt;/em&gt; learns from its prediction on the correct class&lt;/p&gt;\n\n&lt;p&gt;It is common online to see comments &lt;a href=\"https://datascience.stackexchange.com/a/20301/159699\"&gt;like this one&lt;/a&gt;, that, while technically true, obfuscate the understanding of how a neural network updates its parameters after training on a single sample in multi-class classification. Other comments, &lt;a href=\"https://datascience.stackexchange.com/a/31966/159699\"&gt;such as this one&lt;/a&gt;, &lt;a href=\"https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation/24696#comment91209_24696\"&gt;and this one&lt;/a&gt;, are flat out wrong. This makes studying this topic especially confusing, so I wanted to clear some things up.&lt;/p&gt;\n\n&lt;h1&gt;The Common Misconception&lt;/h1&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The Cross Entropy Loss function for a single sample can be written as \ud835\udc3f = \u2212 &lt;strong&gt;\ud835\udc32 \u22c5&lt;/strong&gt; log( &lt;strong&gt;\ud835\udc32\u0302&lt;/strong&gt;\u00a0) . Therefore the Loss is only dependent on the active class in the y-vector, because that will be the only nonzero term after the dot product.&lt;sup&gt;(This part is true&lt;/sup&gt;)  &lt;/p&gt;\n\n&lt;p&gt;Therefore the neural network only learns from its prediction on the correct class&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;That is not true!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Minimizing the loss function is the objective, but the learning is performed with the gradient of the loss function. More specifically, the parameter updates are given by the learning rate times the negative gradient of the loss function with respect to the model parameters. Even though the Loss function will not change based on the predicted probabilities for the incorrect classes, its gradient does depend on those values.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t really write equations here, but from &lt;em&gt;Neural Networks and Deep Learning, Charu C. Aggarwal&lt;/em&gt;, the gradient for a &lt;strong&gt;single layer network&lt;/strong&gt; (multinomial logistic regression)\u200b is given by&lt;/p&gt;\n\n&lt;p&gt;\u2202L/\u2202W = {&lt;/p&gt;\n\n&lt;p&gt;for the correct class: -Xi ( 1 - \u0177 )&lt;/p&gt;\n\n&lt;p&gt;for the incorrect class: Xi \u0177&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;or in matrix form:  \u2202L/\u2202W = - Xi (y - \u0177)&lt;sup&gt;T&lt;/sup&gt;&lt;/p&gt;\n\n&lt;p&gt;So the gradient will be a matrix the same shape as the weight matrix.&lt;/p&gt;\n\n&lt;p&gt;So we can see that the model is penalized for:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Predicting a small probability for the correct class&lt;/li&gt;\n&lt;li&gt;Predicting a large probability for the incorrect class&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Generalizing to a multilayer network&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The gradient from a single training sample back propagates through each of the prediction neurons, to the specific weight vector pertaining to that neuron in the last weight matrix, as that is its only dependence. The overall weight matrix has k such vectors, for each of the classes. As the gradient back propagates further back into the network, the gradient on a singular weight element will be a sum of the k gradients originating at the prediction neurons.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/me1LUltQmpb-Yjke82xaP2ImBnSFobPDxmMt2i8loOw.jpg?auto=webp&amp;s=07a8933208c10c1bb3e45948fc63f77e19e418be", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/me1LUltQmpb-Yjke82xaP2ImBnSFobPDxmMt2i8loOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=60f89fa9efeb92f4542ecded956ebdda00963d55", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/me1LUltQmpb-Yjke82xaP2ImBnSFobPDxmMt2i8loOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1a44929ca530bf0bfd5e4dae2d33fdf6d59bc1e", "width": 216, "height": 216}], "variants": {}, "id": "5np4J6mUzXYNu4qMlPrcnxOiqRs73wn9wB2s0b8TWkY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1aodk18", "is_robot_indexable": true, "report_reasons": null, "author": "Toasty_toaster", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aodk18/a_common_misconception_about_cross_entropy_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aodk18/a_common_misconception_about_cross_entropy_loss/", "subreddit_subscribers": 1328435, "created_utc": 1707673083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have relatively uniformly colored images and I extracted colors using k-means. k means 1 showed the best results for my modeling purposes, k means 2 not so much, and with k-means 3 there ceased to be differences between some channels of samples.\n\nIs this a reasonable approach and is it technically different from calculating the mean of all pixels in the image.\n\nCan it be said that I took the mean of all pixels if the result is the same?\n\n&amp;#x200B;\n\nedit: I need one color to represent each image for my purposes ideally\n\nedit 2: I am evaluating clustering based on the final model performance (as k means used only for image quantization to use as a target variable)", "author_fullname": "t2_7dv06hd2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "K means clustering of image with k=1 vs mean of all pixels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aoto4y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707726120.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707719712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have relatively uniformly colored images and I extracted colors using k-means. k means 1 showed the best results for my modeling purposes, k means 2 not so much, and with k-means 3 there ceased to be differences between some channels of samples.&lt;/p&gt;\n\n&lt;p&gt;Is this a reasonable approach and is it technically different from calculating the mean of all pixels in the image.&lt;/p&gt;\n\n&lt;p&gt;Can it be said that I took the mean of all pixels if the result is the same?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;edit: I need one color to represent each image for my purposes ideally&lt;/p&gt;\n\n&lt;p&gt;edit 2: I am evaluating clustering based on the final model performance (as k means used only for image quantization to use as a target variable)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1aoto4y", "is_robot_indexable": true, "report_reasons": null, "author": "Smart-Firefighter509", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aoto4y/k_means_clustering_of_image_with_k1_vs_mean_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aoto4y/k_means_clustering_of_image_with_k1_vs_mean_of/", "subreddit_subscribers": 1328435, "created_utc": 1707719712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, guys!! I need some help. I\u2019m a Data Scientist working on big consultancy and I have a Eletrical Engineering degree and current on Masters about Smart Systems. I\u2019ve been thinking of improve my portfolio, but I want to make a end-to-end solution about energy/Eletrical Engineering, with ETL and use the freemium of AWS/Some Cloud to deploy everything. Can you all give me some advices and resources to attemp this?", "author_fullname": "t2_ce6umqnmy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project of Energy/Eletrical Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ao6dz8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707652736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, guys!! I need some help. I\u2019m a Data Scientist working on big consultancy and I have a Eletrical Engineering degree and current on Masters about Smart Systems. I\u2019ve been thinking of improve my portfolio, but I want to make a end-to-end solution about energy/Eletrical Engineering, with ETL and use the freemium of AWS/Some Cloud to deploy everything. Can you all give me some advices and resources to attemp this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1ao6dz8", "is_robot_indexable": true, "report_reasons": null, "author": "TioMir", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ao6dz8/project_of_energyeletrical_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ao6dz8/project_of_energyeletrical_engineering/", "subreddit_subscribers": 1328435, "created_utc": 1707652736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 12 Feb, 2024 - 19 Feb, 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aos1w7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707714085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1aos1w7", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aos1w7/weekly_entering_transitioning_thread_12_feb_2024/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/1aos1w7/weekly_entering_transitioning_thread_12_feb_2024/", "subreddit_subscribers": 1328435, "created_utc": 1707714085.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}