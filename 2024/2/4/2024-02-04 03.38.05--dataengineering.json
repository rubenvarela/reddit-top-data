{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is really one of the things that make me scratch my head.\n\nI have nothing against Python, but I feel that for most data engineering problems, you could heavily benefit from type safety and reliable multi threading/parallel processing. Not to mention from scalability in terms of codebase (in my opinion, python projects don't tend to scale well, I don't mean at a performance level, but at structure level)\n\nBut I'm surprised because a lot of people here who say they have a DE role also say they work primarily in Python.\n\nSure, you got PySpark, but even then, that's just an API interacting with a JVM running an actual Scala Spark process.\n\nThe only reason I can think of is that Python has very relaxed syntax, with very few reserved keywords or extremely complex constructs, but of course that simplicity comes at the cost of performance and safety measures.", "author_fullname": "t2_s75gwyxxt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm just gonna go ahead and ask: why is Python so popular for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ahud3x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706960755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is really one of the things that make me scratch my head.&lt;/p&gt;\n\n&lt;p&gt;I have nothing against Python, but I feel that for most data engineering problems, you could heavily benefit from type safety and reliable multi threading/parallel processing. Not to mention from scalability in terms of codebase (in my opinion, python projects don&amp;#39;t tend to scale well, I don&amp;#39;t mean at a performance level, but at structure level)&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m surprised because a lot of people here who say they have a DE role also say they work primarily in Python.&lt;/p&gt;\n\n&lt;p&gt;Sure, you got PySpark, but even then, that&amp;#39;s just an API interacting with a JVM running an actual Scala Spark process.&lt;/p&gt;\n\n&lt;p&gt;The only reason I can think of is that Python has very relaxed syntax, with very few reserved keywords or extremely complex constructs, but of course that simplicity comes at the cost of performance and safety measures.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ahud3x", "is_robot_indexable": true, "report_reasons": null, "author": "yourAvgSE", "discussion_type": null, "num_comments": 89, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ahud3x/im_just_gonna_go_ahead_and_ask_why_is_python_so/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ahud3x/im_just_gonna_go_ahead_and_ask_why_is_python_so/", "subreddit_subscribers": 158095, "created_utc": 1706960755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7waxarsz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The less they know, the more they pay. Keep them hooked on stupid.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1aht9m3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p7h1O2SS3jdWO9LWY4LyR-onm2ueVraiQypiA9gfW_o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706956384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/y5ctytm4lcgc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/y5ctytm4lcgc1.png?auto=webp&amp;s=9fa5c35f3c61bd8d721cfdd3e0065eb28de36985", "width": 954, "height": 1256}, "resolutions": [{"url": "https://preview.redd.it/y5ctytm4lcgc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4834b62bde36a2f238dd99fd56a8c3130e455ca", "width": 108, "height": 142}, {"url": "https://preview.redd.it/y5ctytm4lcgc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc8042cb7e338d23e099a9981153665508b4cb45", "width": 216, "height": 284}, {"url": "https://preview.redd.it/y5ctytm4lcgc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=493f4133ccba57904b6997f990d359c5be4fcf58", "width": 320, "height": 421}, {"url": "https://preview.redd.it/y5ctytm4lcgc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ebe2bd0a2d3549bee28583c4e416fff9a90f17c", "width": 640, "height": 842}], "variants": {}, "id": "IvF2dOYaO_0FtRfoTDqouyGTSixVP4hTvng9NbwJByg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1aht9m3", "is_robot_indexable": true, "report_reasons": null, "author": "almost-mushroom", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aht9m3/the_less_they_know_the_more_they_pay_keep_them/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/y5ctytm4lcgc1.png", "subreddit_subscribers": 158095, "created_utc": 1706956384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it too much to ask for a thin open source code-first BI Tool with modern UI that has a semantic layer and can read from parquet directories?\n\nIf there\u2019s one out there, please point me in the right direction.\n\nAfter a career working with Crystal Reports, Jaspersoft, Cognos, PowerBI\u2026 they all suck in bloated ways that don\u2019t seem necessary anymore in these days of DBT, Parquet, Polars/Pandas, etc. for most common data loads. \n\nGive me something that doesn\u2019t manage security, that should be done farther left anyway. Give me something that is a good code-first development experience where I don\u2019t need a server to store reports, just Git. Make it YAML, SQL, Python, Git local hosting/static assets \u2014 these competencies should be replacing Excel as expected competencies for data practitioners if we\u2019re ever going to truly elevate data quality and literacy.\n\nThis is what \u201clow-code\u201d should mean.", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BI Tool Rant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai2d2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706984114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it too much to ask for a thin open source code-first BI Tool with modern UI that has a semantic layer and can read from parquet directories?&lt;/p&gt;\n\n&lt;p&gt;If there\u2019s one out there, please point me in the right direction.&lt;/p&gt;\n\n&lt;p&gt;After a career working with Crystal Reports, Jaspersoft, Cognos, PowerBI\u2026 they all suck in bloated ways that don\u2019t seem necessary anymore in these days of DBT, Parquet, Polars/Pandas, etc. for most common data loads. &lt;/p&gt;\n\n&lt;p&gt;Give me something that doesn\u2019t manage security, that should be done farther left anyway. Give me something that is a good code-first development experience where I don\u2019t need a server to store reports, just Git. Make it YAML, SQL, Python, Git local hosting/static assets \u2014 these competencies should be replacing Excel as expected competencies for data practitioners if we\u2019re ever going to truly elevate data quality and literacy.&lt;/p&gt;\n\n&lt;p&gt;This is what \u201clow-code\u201d should mean.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ai2d2z", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai2d2z/bi_tool_rant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai2d2z/bi_tool_rant/", "subreddit_subscribers": 158095, "created_utc": 1706984114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "W's\n\nIts cool that you can create folders and share it with others\n\nThere's a code version control (but this is also a L that's later explained)\n\nThere's a python worksheet, which is cool, not needed because you can always wrap it in a stored proc (and that's what it does under the hood anyway), but the package manager is cool nonetheless\n\nThe charts is a nice feature, wouldn't say its at the point where you can use it to report, but very nice to get a quick summary\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nL's (Some are not snowsight specific)\n\nThere's just 1 folder level, its not a major problem but I would like to create a 'recycle bin folder' and move everything in it without having to sort through it every now and then\n\nWith the Snowsight UI, a lot of times the log just disappears especially when you use a python worksheet\n\nRunning a bunch of queries often makes the code stuck in UI initializing\n\nIf you run a lot of SQL commands and the page refreshes, it just executes the last command and stops - this is incredibly frustrating\n\nVersion control is nightmare, especially if you have 2+ people working on it, and the saves aren't as intuitive as they are in databricks for some reason\n\nQuery history is far less that the classic UI, so many a times you actually have to go to the classic UI to see your query history\n\nThere's no way to see in which worksheet I have run my last query - this would be an amazing feature since if you run 100+ queries a day for adhoc business requests you often lose track of what's where\n\nUnlike databricks every python worksheet is like 1 cell in databricks, but what if i want to run 1 cell, then another cell, then another etc. That feels more intuitive when you are running data science experiments.\n\nsaving anything like a model object, pca object etc, means you have to keep it in a stage but that means you have to store it in a internal '/tmp/' folder first then upload to a stage, it just seems hacky imho. Not sure if other use the same proccess\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_reopsquch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Snowsight (Snowflake's new UI) a big L or big W?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ahnp1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706934835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;W&amp;#39;s&lt;/p&gt;\n\n&lt;p&gt;Its cool that you can create folders and share it with others&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a code version control (but this is also a L that&amp;#39;s later explained)&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a python worksheet, which is cool, not needed because you can always wrap it in a stored proc (and that&amp;#39;s what it does under the hood anyway), but the package manager is cool nonetheless&lt;/p&gt;\n\n&lt;p&gt;The charts is a nice feature, wouldn&amp;#39;t say its at the point where you can use it to report, but very nice to get a quick summary&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;L&amp;#39;s (Some are not snowsight specific)&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s just 1 folder level, its not a major problem but I would like to create a &amp;#39;recycle bin folder&amp;#39; and move everything in it without having to sort through it every now and then&lt;/p&gt;\n\n&lt;p&gt;With the Snowsight UI, a lot of times the log just disappears especially when you use a python worksheet&lt;/p&gt;\n\n&lt;p&gt;Running a bunch of queries often makes the code stuck in UI initializing&lt;/p&gt;\n\n&lt;p&gt;If you run a lot of SQL commands and the page refreshes, it just executes the last command and stops - this is incredibly frustrating&lt;/p&gt;\n\n&lt;p&gt;Version control is nightmare, especially if you have 2+ people working on it, and the saves aren&amp;#39;t as intuitive as they are in databricks for some reason&lt;/p&gt;\n\n&lt;p&gt;Query history is far less that the classic UI, so many a times you actually have to go to the classic UI to see your query history&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s no way to see in which worksheet I have run my last query - this would be an amazing feature since if you run 100+ queries a day for adhoc business requests you often lose track of what&amp;#39;s where&lt;/p&gt;\n\n&lt;p&gt;Unlike databricks every python worksheet is like 1 cell in databricks, but what if i want to run 1 cell, then another cell, then another etc. That feels more intuitive when you are running data science experiments.&lt;/p&gt;\n\n&lt;p&gt;saving anything like a model object, pca object etc, means you have to keep it in a stage but that means you have to store it in a internal &amp;#39;/tmp/&amp;#39; folder first then upload to a stage, it just seems hacky imho. Not sure if other use the same proccess&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ahnp1q", "is_robot_indexable": true, "report_reasons": null, "author": "Moist-Comedian5033", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ahnp1q/is_snowsight_snowflakes_new_ui_a_big_l_or_big_w/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ahnp1q/is_snowsight_snowflakes_new_ui_a_big_l_or_big_w/", "subreddit_subscribers": 158095, "created_utc": 1706934835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Calling all data engineers! \ud83d\ude97 I've got a big data dilemma. I'm about to dive into a job where we track vehicles using a software that stores real-time data from various GPS trackers in a MySQL database (around 4 million rows daily). Currently, the app is a bit sluggish \u2013 taking about a minute to display a month's worth of car positions. Do you reckon a switch from MySQL to big data tech like MongoDB is the way to go? \ud83e\udd14", "author_fullname": "t2_e1i3duqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iot and bigdata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ahziwb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706976640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Calling all data engineers! \ud83d\ude97 I&amp;#39;ve got a big data dilemma. I&amp;#39;m about to dive into a job where we track vehicles using a software that stores real-time data from various GPS trackers in a MySQL database (around 4 million rows daily). Currently, the app is a bit sluggish \u2013 taking about a minute to display a month&amp;#39;s worth of car positions. Do you reckon a switch from MySQL to big data tech like MongoDB is the way to go? \ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ahziwb", "is_robot_indexable": true, "report_reasons": null, "author": "ryan7ait", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ahziwb/iot_and_bigdata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ahziwb/iot_and_bigdata/", "subreddit_subscribers": 158095, "created_utc": 1706976640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7svy5qp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ship Data Mapping Features - News on Geoglify's GitHub OpenSource", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai2drq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/yhn701x3wegc1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/yhn701x3wegc1/DASH_96.mp4", "dash_url": "https://v.redd.it/yhn701x3wegc1/DASHPlaylist.mpd?a=1709609885%2CZjk3YmFiZTVmNmU4Njc2NWM0MzNkMzJlMjg0ZmUzYTEyN2VkM2VmNTdkZTUzZmQ5N2FiNzc1MjhlNjhhMDA5MQ%3D%3D&amp;v=1&amp;f=sd", "duration": 29, "hls_url": "https://v.redd.it/yhn701x3wegc1/HLSPlaylist.m3u8?a=1709609885%2CNjg1ZTYyYTUzYzliZTVkMzM4OWNjOGI2MDEyYWM3NDNiNzQ1MjE2ZTNkNjE4OTNmNzcxZWRjZWJlNTMxYjRlMQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=ba9166ad68a4b2f32b93bfcb8176de2fc55aca7b", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706984163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/yhn701x3wegc1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z.png?format=pjpg&amp;auto=webp&amp;s=0e833eef7a6ea618118e10491a3af2304c45e7c0", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=ca6746164350b46dc3ca206814e5c8ed795434da", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9318860a24e813ac4764c624e07e59fd93e66d91", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=73e4d35fe71e381b2d414dabf5a650c1a5831df3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=26482053ec1c95e1432e83f87f912a001d5790c3", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=1b31c37aac96e64bcdc9a0fadb36cf7a34d834b3", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e83d9c2b9d2d09e574ec8c45fb432bdadd3ae718", "width": 1080, "height": 607}], "variants": {}, "id": "bDQ2bHFjNmJ3ZWdjMbozT3C56Runm1lOUi1-MeF1Khvf3WjdQduLRTJQoe0Z"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1ai2drq", "is_robot_indexable": true, "report_reasons": null, "author": "leoneljdias", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai2drq/ship_data_mapping_features_news_on_geoglifys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/yhn701x3wegc1", "subreddit_subscribers": 158095, "created_utc": 1706984163.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/yhn701x3wegc1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/yhn701x3wegc1/DASH_96.mp4", "dash_url": "https://v.redd.it/yhn701x3wegc1/DASHPlaylist.mpd?a=1709609885%2CZjk3YmFiZTVmNmU4Njc2NWM0MzNkMzJlMjg0ZmUzYTEyN2VkM2VmNTdkZTUzZmQ5N2FiNzc1MjhlNjhhMDA5MQ%3D%3D&amp;v=1&amp;f=sd", "duration": 29, "hls_url": "https://v.redd.it/yhn701x3wegc1/HLSPlaylist.m3u8?a=1709609885%2CNjg1ZTYyYTUzYzliZTVkMzM4OWNjOGI2MDEyYWM3NDNiNzQ1MjE2ZTNkNjE4OTNmNzcxZWRjZWJlNTMxYjRlMQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have no idea whether this is going to be useful for anyone, but I've created a bare bones repo that provides an example of using Terraform to manage a Snowflake instance.\n\nIt creates users, warehouses, databases (and schemas), and assigns team roles to users, permission roles to schemas, and grants team roles access to the permission roles.\n\nThere are lots of ways to structure a Terraform repo. This is just one. Let me know if it's helpful.\n\n[https://github.com/nydasco/snowflake-terraform-demo](https://github.com/nydasco/snowflake-terraform-demo)", "author_fullname": "t2_ojr03vx2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bare bones IaC Terraform for Snowflake example", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ahnkyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706934471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have no idea whether this is going to be useful for anyone, but I&amp;#39;ve created a bare bones repo that provides an example of using Terraform to manage a Snowflake instance.&lt;/p&gt;\n\n&lt;p&gt;It creates users, warehouses, databases (and schemas), and assigns team roles to users, permission roles to schemas, and grants team roles access to the permission roles.&lt;/p&gt;\n\n&lt;p&gt;There are lots of ways to structure a Terraform repo. This is just one. Let me know if it&amp;#39;s helpful.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/nydasco/snowflake-terraform-demo\"&gt;https://github.com/nydasco/snowflake-terraform-demo&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p6a8_hc6XJhRGVq-uJjqXWOgXsOMHjjVNdNW3LhoH58.jpg?auto=webp&amp;s=cde19c8cdd4a0fe76397cdbccb74834370732aa7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/p6a8_hc6XJhRGVq-uJjqXWOgXsOMHjjVNdNW3LhoH58.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cea28de7fd9f001374ce0aee2af700273e987c84", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/p6a8_hc6XJhRGVq-uJjqXWOgXsOMHjjVNdNW3LhoH58.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1c6840ac69d687c413fc2358151e545849dcdb33", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/p6a8_hc6XJhRGVq-uJjqXWOgXsOMHjjVNdNW3LhoH58.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=56e26a08f6a75e81c9edf0411b7b66468aacefc7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/p6a8_hc6XJhRGVq-uJjqXWOgXsOMHjjVNdNW3LhoH58.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac229206935f64c5e4321a861a99e9301e59e76a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/p6a8_hc6XJhRGVq-uJjqXWOgXsOMHjjVNdNW3LhoH58.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ddf11bf9feb79b8b959437328aa8c7444c08b32", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/p6a8_hc6XJhRGVq-uJjqXWOgXsOMHjjVNdNW3LhoH58.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=41b907645337d8852632c3ab35294c8cb4093470", "width": 1080, "height": 540}], "variants": {}, "id": "32cljpCcBBDNWgyzwnL_0TMKpyADq2EXLfaS-xORIAQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1ahnkyi", "is_robot_indexable": true, "report_reasons": null, "author": "nydasco", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ahnkyi/bare_bones_iac_terraform_for_snowflake_example/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ahnkyi/bare_bones_iac_terraform_for_snowflake_example/", "subreddit_subscribers": 158095, "created_utc": 1706934471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All\n\nI\u2019m curious to know, what data engineering side projects are you working on? I\u2019m thinking to start one using Kafka and spark because I want to learn these technologies . Trying to find good real time data set or API?", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Side projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai5iha", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706992532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious to know, what data engineering side projects are you working on? I\u2019m thinking to start one using Kafka and spark because I want to learn these technologies . Trying to find good real time data set or API?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ai5iha", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1ai5iha/de_side_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai5iha/de_side_projects/", "subreddit_subscribers": 158095, "created_utc": 1706992532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I just shared a Python Data Science Bootcamp on YouTube. Bootcamp is over 7 hours and there are 6 courses and 3 projects. Courses are Python, Pandas, Numpy, Matplotlib, Seaborn, Plotly and Scikit-learn. I am leaving the link below, have a great day!\n\n[https://www.youtube.com/watch?v=6gDLcTcePhM](https://www.youtube.com/watch?v=6gDLcTcePhM)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I shared a Python Data Science Bootcamp (7+ Hours, 6 Courses and 3 Projects) on YouTube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai1vcj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706982828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I just shared a Python Data Science Bootcamp on YouTube. Bootcamp is over 7 hours and there are 6 courses and 3 projects. Courses are Python, Pandas, Numpy, Matplotlib, Seaborn, Plotly and Scikit-learn. I am leaving the link below, have a great day!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=6gDLcTcePhM\"&gt;https://www.youtube.com/watch?v=6gDLcTcePhM&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZB59F6fm5GAmswkqzNFNm6ikgKWmmNxoSJKJZMHD-gk.jpg?auto=webp&amp;s=cb983384e7b8827539dcccfe1fd1abd0612fee85", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ZB59F6fm5GAmswkqzNFNm6ikgKWmmNxoSJKJZMHD-gk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=33e9bd1241629a5b1b50d9df56262f29fce06478", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ZB59F6fm5GAmswkqzNFNm6ikgKWmmNxoSJKJZMHD-gk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d5eda15a19fd1fb31a2877b412e397f3ddd8e710", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ZB59F6fm5GAmswkqzNFNm6ikgKWmmNxoSJKJZMHD-gk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=91ec77e1a24309f8bae69d0594bd6c48d8be3262", "width": 320, "height": 240}], "variants": {}, "id": "7nXuf0hRU_C6xtaxx6XAs3TjDHojpgRbOJItO46oSrU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1ai1vcj", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai1vcj/i_shared_a_python_data_science_bootcamp_7_hours_6/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai1vcj/i_shared_a_python_data_science_bootcamp_7_hours_6/", "subreddit_subscribers": 158095, "created_utc": 1706982828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to get my team to adapt Parquet format for the data stored on AWS S3 instead of CSV. Our data engineering pipeline consists of Lambda triggers on S3 file drop.\n\nUnfortunately, I could not package pyarrow due to the 250 MB Lambda layer size limitation, so I ended up packaging fastparquet to read and writes parquet files.\n\nI created two identical lambda functions\n1. Read csv from s3 into a pandas dataframe -&gt; aggregation -&gt; write df to csv back to s3\n2. Read parque from s3 into a pandas dataframe -&gt;  aggregation -&gt; write df to parquet back to s3\n\nBoth the functions were processing the exact same dataset, just different file formats.\n\nThe read-parquet-write-parquet lambda consumes way more memory than the read-csv-write-csv lambda, for the same dataset, in some cases almost double. \n\nI tried the above tests with different sized datasets and different memory allocated to both lambda functions, got the same results. The benefit gained read and write speed of parquet data and the s3 storage size compared to csv, is negligible compared to the AWS lambda memory usage cost as parquet df consumes way more RAM than csv df ?\n\n\nWhat am I doing wrong? Could this be specific to fastparquet engine? Is there a way I can try the same test using Pyarrow (since I am not about to package pyarrow to AWS lambda)?", "author_fullname": "t2_v8qhw4wd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Lambda Parquet consumes more memory than csv", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ahw2qp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706967486.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706966798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to get my team to adapt Parquet format for the data stored on AWS S3 instead of CSV. Our data engineering pipeline consists of Lambda triggers on S3 file drop.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, I could not package pyarrow due to the 250 MB Lambda layer size limitation, so I ended up packaging fastparquet to read and writes parquet files.&lt;/p&gt;\n\n&lt;p&gt;I created two identical lambda functions\n1. Read csv from s3 into a pandas dataframe -&amp;gt; aggregation -&amp;gt; write df to csv back to s3\n2. Read parque from s3 into a pandas dataframe -&amp;gt;  aggregation -&amp;gt; write df to parquet back to s3&lt;/p&gt;\n\n&lt;p&gt;Both the functions were processing the exact same dataset, just different file formats.&lt;/p&gt;\n\n&lt;p&gt;The read-parquet-write-parquet lambda consumes way more memory than the read-csv-write-csv lambda, for the same dataset, in some cases almost double. &lt;/p&gt;\n\n&lt;p&gt;I tried the above tests with different sized datasets and different memory allocated to both lambda functions, got the same results. The benefit gained read and write speed of parquet data and the s3 storage size compared to csv, is negligible compared to the AWS lambda memory usage cost as parquet df consumes way more RAM than csv df ?&lt;/p&gt;\n\n&lt;p&gt;What am I doing wrong? Could this be specific to fastparquet engine? Is there a way I can try the same test using Pyarrow (since I am not about to package pyarrow to AWS lambda)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ahw2qp", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Love_648", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ahw2qp/aws_lambda_parquet_consumes_more_memory_than_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ahw2qp/aws_lambda_parquet_consumes_more_memory_than_csv/", "subreddit_subscribers": 158095, "created_utc": 1706966798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working with an Oracle database, and have configured VSCode to connect to it and run SQL queries using SQLTools. It's sometimes a bit clunky, but generally is a really good plug in. \n\nI wondered whether anyone here had some recommendations on how to be running SQL from VSCode, whether there are any other good plugins to consider! \n\nEspecially whether there are good presets or options to set when using SQLTools.", "author_fullname": "t2_40ho7lud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting a good SQL experience in VSCode", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai66ch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706994246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working with an Oracle database, and have configured VSCode to connect to it and run SQL queries using SQLTools. It&amp;#39;s sometimes a bit clunky, but generally is a really good plug in. &lt;/p&gt;\n\n&lt;p&gt;I wondered whether anyone here had some recommendations on how to be running SQL from VSCode, whether there are any other good plugins to consider! &lt;/p&gt;\n\n&lt;p&gt;Especially whether there are good presets or options to set when using SQLTools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ai66ch", "is_robot_indexable": true, "report_reasons": null, "author": "powerbihelpme", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai66ch/getting_a_good_sql_experience_in_vscode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai66ch/getting_a_good_sql_experience_in_vscode/", "subreddit_subscribers": 158095, "created_utc": 1706994246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company's data, something that is quite important for our analytics is what 'roles' have been assigned to our users. There are currently about 50 different roles, and each user can have many roles. These roles can represent different settings that have been selected by the user, or things like whether we are giving them early access to a new feature in our app.\n\nIn our application database, this is modelled roughly how you'd expect. We have a users table (one row per user), a roles tables (one row per role), and a user\\_roles table, which maps the users to each of the roles they have.\n\nI'm wondering if there is some best practice on how this should be modelled in a data warehouse. My predecessor wanted to de-normalize a lot of the data to make it easier to use for analytics (which in *general* I support), but in this case it meant that they created new columns in the our dim\\_user table in the datawarehouse for whether the user had each of the given roles. i.e.: columns for has\\_role1, has\\_role2 etc. I wonder if this is something people would generally support as a good idea, or if it might actually be better keeping this as a separate table. Would one approach be easier for keeping track of changes in the roles each user has?", "author_fullname": "t2_173s1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to model user roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ahx0t2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706969648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company&amp;#39;s data, something that is quite important for our analytics is what &amp;#39;roles&amp;#39; have been assigned to our users. There are currently about 50 different roles, and each user can have many roles. These roles can represent different settings that have been selected by the user, or things like whether we are giving them early access to a new feature in our app.&lt;/p&gt;\n\n&lt;p&gt;In our application database, this is modelled roughly how you&amp;#39;d expect. We have a users table (one row per user), a roles tables (one row per role), and a user_roles table, which maps the users to each of the roles they have.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there is some best practice on how this should be modelled in a data warehouse. My predecessor wanted to de-normalize a lot of the data to make it easier to use for analytics (which in &lt;em&gt;general&lt;/em&gt; I support), but in this case it meant that they created new columns in the our dim_user table in the datawarehouse for whether the user had each of the given roles. i.e.: columns for has_role1, has_role2 etc. I wonder if this is something people would generally support as a good idea, or if it might actually be better keeping this as a separate table. Would one approach be easier for keeping track of changes in the roles each user has?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ahx0t2", "is_robot_indexable": true, "report_reasons": null, "author": "Pancakeman123000", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ahx0t2/how_to_model_user_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ahx0t2/how_to_model_user_roles/", "subreddit_subscribers": 158095, "created_utc": 1706969648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I have an interview coming up for a Data Engineering Internship at Meta. It's the last round and I've heard it's an SQL interview. I was wondering if anyone here has gone through this round already, and if so, what kind of questions did they ask, or how difficult the problems were.  \nThank you!", "author_fullname": "t2_c2on738e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meta - Data Engineering (DE) Summer Internship 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai4562", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706988886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I have an interview coming up for a Data Engineering Internship at Meta. It&amp;#39;s the last round and I&amp;#39;ve heard it&amp;#39;s an SQL interview. I was wondering if anyone here has gone through this round already, and if so, what kind of questions did they ask, or how difficult the problems were.&lt;br/&gt;\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1ai4562", "is_robot_indexable": true, "report_reasons": null, "author": "Relative-Run-1620", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai4562/meta_data_engineering_de_summer_internship_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai4562/meta_data_engineering_de_summer_internship_2024/", "subreddit_subscribers": 158095, "created_utc": 1706988886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am getting my hands dirty with several database technologies like Redis or Elasticsearch. Many courses say that backend engineers in companies like IBM would need to understand newer database technologies and be \u201eAI affine\u201c. \n\nI am about to start delving into IBM products and I wanted to understand, as a backend engineer at IBM or such other companies what is one supposed to do? How can one improve the technology? If I think fancy then I imagine it is about bringing new AI technologies like Generative AI into specialized queries\u2026 what else can be expected there specifically in the context of products like DB2?", "author_fullname": "t2_3m71ghb3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to expect as a backend engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai0v7e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706980185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am getting my hands dirty with several database technologies like Redis or Elasticsearch. Many courses say that backend engineers in companies like IBM would need to understand newer database technologies and be \u201eAI affine\u201c. &lt;/p&gt;\n\n&lt;p&gt;I am about to start delving into IBM products and I wanted to understand, as a backend engineer at IBM or such other companies what is one supposed to do? How can one improve the technology? If I think fancy then I imagine it is about bringing new AI technologies like Generative AI into specialized queries\u2026 what else can be expected there specifically in the context of products like DB2?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ai0v7e", "is_robot_indexable": true, "report_reasons": null, "author": "tricostume", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai0v7e/what_to_expect_as_a_backend_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai0v7e/what_to_expect_as_a_backend_engineer/", "subreddit_subscribers": 158095, "created_utc": 1706980185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI've been working with dbt for a long time. While it greatly improves delivery speed and provides many QOL improvements, I have noticed some patterns that have significantly enhanced dbt development workflows.\n\nWith this in mind, I wrote an article (with fully working code) that goes over some tools &amp; techniques that I have seen improve dbt development speed by enabling.\n\n1. Reproducible environment\n2. Reducing feedback loop time\n3. Using existing dbt-packages\n4. Streamlining commonly run tasks\n\nI've also tried to specify any caveats/tradeoffs with the tools/approaches. I hope this helps someone looking to speed up their dbt development process with some good ideas.\n\nBlog: [Uplevel dbt](https://www.startdataengineering.com/post/uplevel-dbt-workflow/)\n\nCode: [dbt project](https://github.com/josephmachado/simple_dbt_project)\n\nI appreciate any questions, feedback, or comments. I hope this helps someone.", "author_fullname": "t2_5srxspj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Steps to enhance dbt(data build tool) dev workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ahwltd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706968459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working with dbt for a long time. While it greatly improves delivery speed and provides many QOL improvements, I have noticed some patterns that have significantly enhanced dbt development workflows.&lt;/p&gt;\n\n&lt;p&gt;With this in mind, I wrote an article (with fully working code) that goes over some tools &amp;amp; techniques that I have seen improve dbt development speed by enabling.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Reproducible environment&lt;/li&gt;\n&lt;li&gt;Reducing feedback loop time&lt;/li&gt;\n&lt;li&gt;Using existing dbt-packages&lt;/li&gt;\n&lt;li&gt;Streamlining commonly run tasks&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve also tried to specify any caveats/tradeoffs with the tools/approaches. I hope this helps someone looking to speed up their dbt development process with some good ideas.&lt;/p&gt;\n\n&lt;p&gt;Blog: &lt;a href=\"https://www.startdataengineering.com/post/uplevel-dbt-workflow/\"&gt;Uplevel dbt&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Code: &lt;a href=\"https://github.com/josephmachado/simple_dbt_project\"&gt;dbt project&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I appreciate any questions, feedback, or comments. I hope this helps someone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/09N95gjFm6Xzi6PIlSRJrKNMJO7GHw1stEbE_vD3RBk.jpg?auto=webp&amp;s=d3f46b7a5e182a2295460628dc1f041a7de1f3e1", "width": 1262, "height": 707}, "resolutions": [{"url": "https://external-preview.redd.it/09N95gjFm6Xzi6PIlSRJrKNMJO7GHw1stEbE_vD3RBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f2e7ced329f037447de0b6362a694be68e73aea", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/09N95gjFm6Xzi6PIlSRJrKNMJO7GHw1stEbE_vD3RBk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b1356076b1f7bb65859d5e658e01dfb6ada9332", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/09N95gjFm6Xzi6PIlSRJrKNMJO7GHw1stEbE_vD3RBk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2c2db5be5707398ffac36961f3bdd57d03489ace", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/09N95gjFm6Xzi6PIlSRJrKNMJO7GHw1stEbE_vD3RBk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7c9e184380a63b5eb0b3b80174abec522da14663", "width": 640, "height": 358}, {"url": "https://external-preview.redd.it/09N95gjFm6Xzi6PIlSRJrKNMJO7GHw1stEbE_vD3RBk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1007b5769638af0aaf4dc1c5b8fcbd9c0899b3f8", "width": 960, "height": 537}, {"url": "https://external-preview.redd.it/09N95gjFm6Xzi6PIlSRJrKNMJO7GHw1stEbE_vD3RBk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=90d8445fbdfbb3b97082c19cfb56b6b0bd43d94c", "width": 1080, "height": 605}], "variants": {}, "id": "t2uBlsTIaigUxxCU2fngqLcShkJLkDZmzsVkj3LAbvU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1ahwltd", "is_robot_indexable": true, "report_reasons": null, "author": "joseph_machado", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ahwltd/steps_to_enhance_dbtdata_build_tool_dev_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ahwltd/steps_to_enhance_dbtdata_build_tool_dev_workflow/", "subreddit_subscribers": 158095, "created_utc": 1706968459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/dzmiydoxiegc1.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;s=45924ab8c84ea49f532df900f1a6f4505e2b3479", "author_fullname": "t2_a8ditcldc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how can i create an event log like this one? (question in the comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dzmiydoxiegc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 110, "x": 108, "u": "https://preview.redd.it/dzmiydoxiegc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7673139d4fe8f167add19fad5c4ce5ff5f2dc36b"}, {"y": 220, "x": 216, "u": "https://preview.redd.it/dzmiydoxiegc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2caf37ba20def2de38a4b308d6a71411851bdd6e"}, {"y": 327, "x": 320, "u": "https://preview.redd.it/dzmiydoxiegc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63eef87f341cf0d640f95b1661fe6d49cf8709eb"}], "s": {"y": 626, "x": 612, "u": "https://preview.redd.it/dzmiydoxiegc1.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;s=45924ab8c84ea49f532df900f1a6f4505e2b3479"}, "id": "dzmiydoxiegc1"}}, "name": "t3_1ai0odm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ib8YpDgyJda1OMa26upk3DFR2SH2ajx8rTUu4MlpiHo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706979685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dzmiydoxiegc1.jpg?width=612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=45924ab8c84ea49f532df900f1a6f4505e2b3479\"&gt;https://preview.redd.it/dzmiydoxiegc1.jpg?width=612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=45924ab8c84ea49f532df900f1a6f4505e2b3479&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ai0odm", "is_robot_indexable": true, "report_reasons": null, "author": "qhelspil", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai0odm/how_can_i_create_an_event_log_like_this_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai0odm/how_can_i_create_an_event_log_like_this_one/", "subreddit_subscribers": 158095, "created_utc": 1706979685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I'm a CS student interested in DE jobs so I want to learn relevant skills to put on my resume. I have an idea for a project, and I want to know what are the things I'd need to learn to build it out and what would be the steps to build it.\n\nI'm an organizer of a major event at my university, and I'd like to build a live data dashboard tracking various metrics related to guest registration and activity. We already have a backend to collect and store registrations and user profiles (Postgres DB hosted on AWS). I want to build a data pipeline from that production DB to the dashboard. I have experience with the analytics part, but I want to learn how to get the data from the live DB to the dataset used for the dashboard. How should I go about building this? Any other tips/resources would also be appreciated!\n\nEdit: Just to clarify, this is just for learning purposes. It's not a real project with actual accountability or anything, I just want to learn DE by building something. If y'all want to suggest any other project ideas, I'm open to them as well!!", "author_fullname": "t2_bss8br1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help out a noob. How do I achieve this pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai4edk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707012017.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706989563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m a CS student interested in DE jobs so I want to learn relevant skills to put on my resume. I have an idea for a project, and I want to know what are the things I&amp;#39;d need to learn to build it out and what would be the steps to build it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an organizer of a major event at my university, and I&amp;#39;d like to build a live data dashboard tracking various metrics related to guest registration and activity. We already have a backend to collect and store registrations and user profiles (Postgres DB hosted on AWS). I want to build a data pipeline from that production DB to the dashboard. I have experience with the analytics part, but I want to learn how to get the data from the live DB to the dataset used for the dashboard. How should I go about building this? Any other tips/resources would also be appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: Just to clarify, this is just for learning purposes. It&amp;#39;s not a real project with actual accountability or anything, I just want to learn DE by building something. If y&amp;#39;all want to suggest any other project ideas, I&amp;#39;m open to them as well!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ai4edk", "is_robot_indexable": true, "report_reasons": null, "author": "throwlol134", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai4edk/help_out_a_noob_how_do_i_achieve_this_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai4edk/help_out_a_noob_how_do_i_achieve_this_pipeline/", "subreddit_subscribers": 158095, "created_utc": 1706989563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The business suite has a pretty extensive number of seemingly good tools. SharePoint Sites, Teams Chat, Lists, Planner\u2026 my company also has Power BI, Project, and Metabase (not Microsoft).\n\nIt\u2019s logical to me that this environment can be set up in such a way to empower our business users. For example, Teams can have Groups for every project. There can be a SharePoint site for every project. You can embed the SharePoint Site into the Teams Group as a tab. You can also use iframes in the SharePoint Site to embed dashboards. \n\nYou can deploy Microsoft Lists to a project and tell the stake holders to load it with data, then use the List as a data source for things like schedules. Push the schedules into Project and export to Planner. All of this accessible from the Teams group.\n\nThe freaking file system is accessible from Teams.\n\nThe only issue I have is that it\u2019s seemingly impossible to version control any of this. I\u2019ll keep investigating though\u2026 \n\nHas anyone had any luck reforming the companies use of MS 365?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Toyed Around With The Microsoft 365 Business Suite?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai3bmq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706986674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The business suite has a pretty extensive number of seemingly good tools. SharePoint Sites, Teams Chat, Lists, Planner\u2026 my company also has Power BI, Project, and Metabase (not Microsoft).&lt;/p&gt;\n\n&lt;p&gt;It\u2019s logical to me that this environment can be set up in such a way to empower our business users. For example, Teams can have Groups for every project. There can be a SharePoint site for every project. You can embed the SharePoint Site into the Teams Group as a tab. You can also use iframes in the SharePoint Site to embed dashboards. &lt;/p&gt;\n\n&lt;p&gt;You can deploy Microsoft Lists to a project and tell the stake holders to load it with data, then use the List as a data source for things like schedules. Push the schedules into Project and export to Planner. All of this accessible from the Teams group.&lt;/p&gt;\n\n&lt;p&gt;The freaking file system is accessible from Teams.&lt;/p&gt;\n\n&lt;p&gt;The only issue I have is that it\u2019s seemingly impossible to version control any of this. I\u2019ll keep investigating though\u2026 &lt;/p&gt;\n\n&lt;p&gt;Has anyone had any luck reforming the companies use of MS 365?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ai3bmq", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai3bmq/anyone_toyed_around_with_the_microsoft_365/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai3bmq/anyone_toyed_around_with_the_microsoft_365/", "subreddit_subscribers": 158095, "created_utc": 1706986674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are in the process to build a data team and ready to interview new candidates. We also already prepared a scorecard to evaluate future performances.\n\nI\u2019m curious here \u2014 which KPI/metrics do you take into account when it comes to evaluate data engineers\u2019 performances? \n\nI know it\u2019s tightly connected to company\u2019s goal, but would be great to have your opinion as well", "author_fullname": "t2_s2zvff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you measure DE performances?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai9qy6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707003808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are in the process to build a data team and ready to interview new candidates. We also already prepared a scorecard to evaluate future performances.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious here \u2014 which KPI/metrics do you take into account when it comes to evaluate data engineers\u2019 performances? &lt;/p&gt;\n\n&lt;p&gt;I know it\u2019s tightly connected to company\u2019s goal, but would be great to have your opinion as well&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ai9qy6", "is_robot_indexable": true, "report_reasons": null, "author": "giuliosmall", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai9qy6/how_do_you_measure_de_performances/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai9qy6/how_do_you_measure_de_performances/", "subreddit_subscribers": 158095, "created_utc": 1707003808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I recently completed my master's in Computer Science with 4 years of work experience at a Fortune 100 company(Financial Domain). I worked as a Backend Developer and Data Engineer(Data Warehousing).\n\nI am currently looking for jobs but am confused about the roles I should target.\n\nOn one hand, I have backend experience and I feel I could leverage that better than the Data Engineering experience(because I haven't worked on fancy technologies like Informatica, Kafka, etc).\n\nI have also done a few projects in AI/ML and my long-term plan is to work in the ML/AI domain so Data Engineering makes more sense.\n\nAny advice on what would be the right choice in the current job market? (I am looking for jobs in the US).", "author_fullname": "t2_k3d5pkx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice: SWE or Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ai7q0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706998364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently completed my master&amp;#39;s in Computer Science with 4 years of work experience at a Fortune 100 company(Financial Domain). I worked as a Backend Developer and Data Engineer(Data Warehousing).&lt;/p&gt;\n\n&lt;p&gt;I am currently looking for jobs but am confused about the roles I should target.&lt;/p&gt;\n\n&lt;p&gt;On one hand, I have backend experience and I feel I could leverage that better than the Data Engineering experience(because I haven&amp;#39;t worked on fancy technologies like Informatica, Kafka, etc).&lt;/p&gt;\n\n&lt;p&gt;I have also done a few projects in AI/ML and my long-term plan is to work in the ML/AI domain so Data Engineering makes more sense.&lt;/p&gt;\n\n&lt;p&gt;Any advice on what would be the right choice in the current job market? (I am looking for jobs in the US).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ai7q0c", "is_robot_indexable": true, "report_reasons": null, "author": "jasonn_786", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ai7q0c/career_advice_swe_or_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ai7q0c/career_advice_swe_or_data_engineer/", "subreddit_subscribers": 158095, "created_utc": 1706998364.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}