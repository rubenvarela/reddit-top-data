{"kind": "Listing", "data": {"after": "t3_1ajyxn2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "10+ years of data hoarding gone, just like that.\n\nI stupidly enabled SMB 1.0 on my home media server yesterday (Windows Server 2016, Hyper-V, home file share, etc) after coming across a Microsoft article titled \"Can't access shared folders from File Explorer in Windows 10\" as I was having trouble connecting to my SMB share from a new laptop. Hours later, kiddo says \"Plex isn't working\" So I open File Explorer and see thousands of files being modified with the extension .OP3v8o4K2 and a text file on my desktop with the same name. I open the file, and my worst fears are confirmed. \"Your files have been encrypted and will be leaked to the dark web if you don't pay ransom at the BTC address blah blah blah\". Another stupid move on my part was not screenshotting the ransom letter before shutting down the server so I could at least report it. It's because I panicked and powered it off ASAP to protect the rest of my home network. I unplugged from the network and attempted to boot back up and saw the classic \"No boot device found.\" I am suspicious that my server has been infected for a while, bypassing Windows Security, and enabling SMB 1.0 finally gave it permission to execute. My plan is to try a Windows PE and restore point, or boot to portable Linux and see how much data is salvageable and copy to a new drive. After the fact, boot and nuke the old drive. My file share exceeded 24TB (56TB capacity), and that was my backup destination for my other PCs, so I had no offline backups of my media.\n\nRIP to my much-loved home media server and a reminder to all you home server admins to 1. Measure twice cut once and 2. Practice a good backup routine and create one now if you don't have any backups\n\nTLDR; I fell victim to ransomware after enabling SMB 1.0 on Windows and lost 10+ years of managing my home media server and about 24TB of data.\n\nEdit: Answering some of the questions, I had Plex Media Server forwarded to port 32400 so it was exposed to the internet. The built-in Windows Server '16 firewall was enabled and my crappy router has its own firewall but no additional layers of antivirus. I suspected other devices on my network would quickly become infected but so far, thankfully that hasn't happened.", "author_fullname": "t2_2bzp5g6y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Don\u2019t be like me. Ransomware victim PSA.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajq8st", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 404, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 404, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707173303.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707163943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;10+ years of data hoarding gone, just like that.&lt;/p&gt;\n\n&lt;p&gt;I stupidly enabled SMB 1.0 on my home media server yesterday (Windows Server 2016, Hyper-V, home file share, etc) after coming across a Microsoft article titled &amp;quot;Can&amp;#39;t access shared folders from File Explorer in Windows 10&amp;quot; as I was having trouble connecting to my SMB share from a new laptop. Hours later, kiddo says &amp;quot;Plex isn&amp;#39;t working&amp;quot; So I open File Explorer and see thousands of files being modified with the extension .OP3v8o4K2 and a text file on my desktop with the same name. I open the file, and my worst fears are confirmed. &amp;quot;Your files have been encrypted and will be leaked to the dark web if you don&amp;#39;t pay ransom at the BTC address blah blah blah&amp;quot;. Another stupid move on my part was not screenshotting the ransom letter before shutting down the server so I could at least report it. It&amp;#39;s because I panicked and powered it off ASAP to protect the rest of my home network. I unplugged from the network and attempted to boot back up and saw the classic &amp;quot;No boot device found.&amp;quot; I am suspicious that my server has been infected for a while, bypassing Windows Security, and enabling SMB 1.0 finally gave it permission to execute. My plan is to try a Windows PE and restore point, or boot to portable Linux and see how much data is salvageable and copy to a new drive. After the fact, boot and nuke the old drive. My file share exceeded 24TB (56TB capacity), and that was my backup destination for my other PCs, so I had no offline backups of my media.&lt;/p&gt;\n\n&lt;p&gt;RIP to my much-loved home media server and a reminder to all you home server admins to 1. Measure twice cut once and 2. Practice a good backup routine and create one now if you don&amp;#39;t have any backups&lt;/p&gt;\n\n&lt;p&gt;TLDR; I fell victim to ransomware after enabling SMB 1.0 on Windows and lost 10+ years of managing my home media server and about 24TB of data.&lt;/p&gt;\n\n&lt;p&gt;Edit: Answering some of the questions, I had Plex Media Server forwarded to port 32400 so it was exposed to the internet. The built-in Windows Server &amp;#39;16 firewall was enabled and my crappy router has its own firewall but no additional layers of antivirus. I suspected other devices on my network would quickly become infected but so far, thankfully that hasn&amp;#39;t happened.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajq8st", "is_robot_indexable": true, "report_reasons": null, "author": "brandonclone1", "discussion_type": null, "num_comments": 202, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajq8st/dont_be_like_me_ransomware_victim_psa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajq8st/dont_be_like_me_ransomware_victim_psa/", "subreddit_subscribers": 730688, "created_utc": 1707163943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Original news article](https://worldoftanks.eu/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/) | [NA](https://worldoftanks.com/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/) | [ASIA](https://worldoftanks.asia/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/)\n\n&gt;Starting February 20 at 12:00 (MSK), we will be transitioning our forums to Discord. On this date, the forums will switch to read-only mode, and on May 20 at 12:00 (MSK), they will permanently close. \n\nGiven that, Wargaming scraps 13 years of World of Tanks community history, transitioning another platform to non-indexeable, unreliable platform, where they also continued butchering community's posts (e.g. media channel being removed, where stuff back from Discord server launch resided).\n\nNot an 'archive this for me' (rule 8) post.", "author_fullname": "t2_452npj84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wargaming.net to kill off World of Tanks official forums", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajiy4t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 298, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 298, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707146374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://worldoftanks.eu/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/\"&gt;Original news article&lt;/a&gt; | &lt;a href=\"https://worldoftanks.com/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/\"&gt;NA&lt;/a&gt; | &lt;a href=\"https://worldoftanks.asia/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/\"&gt;ASIA&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Starting February 20 at 12:00 (MSK), we will be transitioning our forums to Discord. On this date, the forums will switch to read-only mode, and on May 20 at 12:00 (MSK), they will permanently close. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Given that, Wargaming scraps 13 years of World of Tanks community history, transitioning another platform to non-indexeable, unreliable platform, where they also continued butchering community&amp;#39;s posts (e.g. media channel being removed, where stuff back from Discord server launch resided).&lt;/p&gt;\n\n&lt;p&gt;Not an &amp;#39;archive this for me&amp;#39; (rule 8) post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uv_kWCfxGxVrDYyN_OQDoxwJq7PUvOI9URhUb5zXwi8.jpg?auto=webp&amp;s=41667ba4aaa7cc488e6ed923463635bd1f12da6f", "width": 615, "height": 346}, "resolutions": [{"url": "https://external-preview.redd.it/uv_kWCfxGxVrDYyN_OQDoxwJq7PUvOI9URhUb5zXwi8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2334832bab81b94f435ffaba922b6a4189e936b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/uv_kWCfxGxVrDYyN_OQDoxwJq7PUvOI9URhUb5zXwi8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c182bbb74262b2045803775e86c4ca58bd542aff", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/uv_kWCfxGxVrDYyN_OQDoxwJq7PUvOI9URhUb5zXwi8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3bf9b1558dd445732b8516b7e4526921f809176a", "width": 320, "height": 180}], "variants": {}, "id": "ucb3UUFdB5Gkw_N528jGRvQOzW7wMhEq-7KsoTy8mN0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajiy4t", "is_robot_indexable": true, "report_reasons": null, "author": "SigmaTel71", "discussion_type": null, "num_comments": 86, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajiy4t/wargamingnet_to_kill_off_world_of_tanks_official/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajiy4t/wargamingnet_to_kill_off_world_of_tanks_official/", "subreddit_subscribers": 730688, "created_utc": 1707146374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The WD and seagate ones still use the old 3.0 micro b connector. I leave the short cable always connected because I hate plugging it in and don't want to accidentally damage the port. \n\nEspecially since WD ones cannot be shucked if needed.\n\nSo does anyone know the reason? Is it just cheaper to keep the same design?", "author_fullname": "t2_75tzmt2kw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why don't portable HDDs use USB-C ports?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajj0y1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707146577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The WD and seagate ones still use the old 3.0 micro b connector. I leave the short cable always connected because I hate plugging it in and don&amp;#39;t want to accidentally damage the port. &lt;/p&gt;\n\n&lt;p&gt;Especially since WD ones cannot be shucked if needed.&lt;/p&gt;\n\n&lt;p&gt;So does anyone know the reason? Is it just cheaper to keep the same design?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ajj0y1", "is_robot_indexable": true, "report_reasons": null, "author": "Amon9001", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajj0y1/why_dont_portable_hdds_use_usbc_ports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajj0y1/why_dont_portable_hdds_use_usbc_ports/", "subreddit_subscribers": 730688, "created_utc": 1707146577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a 16TB drive, and I've narrowed it down to a $260 Seagate Exos X18 drive and a $360 WD Gold drive. The datasheets are almost identical, with the only real difference being the cache size (Seagate 256MB, WD 512MB). Is there any reason not go for the Exos drive?", "author_fullname": "t2_1fwm352n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are WD Gold drives worth the extra money over Seagate Exos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajz9qm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707187389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a 16TB drive, and I&amp;#39;ve narrowed it down to a $260 Seagate Exos X18 drive and a $360 WD Gold drive. The datasheets are almost identical, with the only real difference being the cache size (Seagate 256MB, WD 512MB). Is there any reason not go for the Exos drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajz9qm", "is_robot_indexable": true, "report_reasons": null, "author": "YoBoiGeo", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajz9qm/are_wd_gold_drives_worth_the_extra_money_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajz9qm/are_wd_gold_drives_worth_the_extra_money_over/", "subreddit_subscribers": 730688, "created_utc": 1707187389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few 15.36TB **Intel D5-P4326s coming as I was able to get them for a reasonable price.  While they will eventually make their way into one of my NASs, they will be in my MSI Z790 system for a bit.  I had ordered a ton of PCI cheat adapters from Alliexpress in the hope that I'll get one method to work.  Today I was thinking about PCI bifurcation and this motherboard doesn't support it, but I don't know if I need to do that.  These two adapters are some of the things I have on order - will it just work or must you be able to change 16x to 4x4x4x4 and 8x to 4x4?  If it won't, I can just use them for an upcoming Xeon server build and go with the M.2 to U.2 adapters I bought - I'm hoping this top adaptor will work, though.**\n\n&amp;#x200B;\n\nhttps://preview.redd.it/pc8skwglougc1.jpg?width=490&amp;format=pjpg&amp;auto=webp&amp;s=91a99794931a2947bd14d0f111b6d25cd42697e7\n\nhttps://preview.redd.it/nmrcwk5lougc1.jpg?width=418&amp;format=pjpg&amp;auto=webp&amp;s=33c8ed73bf08ed00a864a29884d9300df1a0ad03\n\n&amp;#x200B;", "author_fullname": "t2_ldhe3aze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "U.2 NVMe drives vs PCIe question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pc8skwglougc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/pc8skwglougc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=82a7946b092a839f3a7f551fb4dfa93ba72fe7ec"}, {"y": 145, "x": 216, "u": "https://preview.redd.it/pc8skwglougc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b2233529114b929756e1300f98085a4b9ecdde8d"}, {"y": 214, "x": 320, "u": "https://preview.redd.it/pc8skwglougc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df52fcfd5d75059316e45c5f7f8bced6315841e7"}], "s": {"y": 329, "x": 490, "u": "https://preview.redd.it/pc8skwglougc1.jpg?width=490&amp;format=pjpg&amp;auto=webp&amp;s=91a99794931a2947bd14d0f111b6d25cd42697e7"}, "id": "pc8skwglougc1"}, "nmrcwk5lougc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 126, "x": 108, "u": "https://preview.redd.it/nmrcwk5lougc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de1be7202f6ec58cb471eddecfa096357f4c4988"}, {"y": 253, "x": 216, "u": "https://preview.redd.it/nmrcwk5lougc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=51543d80587b236ea8ac3bcc8ab0fc4d2184a938"}, {"y": 375, "x": 320, "u": "https://preview.redd.it/nmrcwk5lougc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02692eb00de21325c629c4e05ce70f950be32952"}], "s": {"y": 491, "x": 418, "u": "https://preview.redd.it/nmrcwk5lougc1.jpg?width=418&amp;format=pjpg&amp;auto=webp&amp;s=33c8ed73bf08ed00a864a29884d9300df1a0ad03"}, "id": "nmrcwk5lougc1"}}, "name": "t3_1ajv08w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/P2nD0t_5QYWZ1dXTyYFm4_51Rh1wp9UrAUX13NQO6yg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707175602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few 15.36TB &lt;strong&gt;Intel D5-P4326s coming as I was able to get them for a reasonable price.  While they will eventually make their way into one of my NASs, they will be in my MSI Z790 system for a bit.  I had ordered a ton of PCI cheat adapters from Alliexpress in the hope that I&amp;#39;ll get one method to work.  Today I was thinking about PCI bifurcation and this motherboard doesn&amp;#39;t support it, but I don&amp;#39;t know if I need to do that.  These two adapters are some of the things I have on order - will it just work or must you be able to change 16x to 4x4x4x4 and 8x to 4x4?  If it won&amp;#39;t, I can just use them for an upcoming Xeon server build and go with the M.2 to U.2 adapters I bought - I&amp;#39;m hoping this top adaptor will work, though.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pc8skwglougc1.jpg?width=490&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=91a99794931a2947bd14d0f111b6d25cd42697e7\"&gt;https://preview.redd.it/pc8skwglougc1.jpg?width=490&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=91a99794931a2947bd14d0f111b6d25cd42697e7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nmrcwk5lougc1.jpg?width=418&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=33c8ed73bf08ed00a864a29884d9300df1a0ad03\"&gt;https://preview.redd.it/nmrcwk5lougc1.jpg?width=418&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=33c8ed73bf08ed00a864a29884d9300df1a0ad03&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajv08w", "is_robot_indexable": true, "report_reasons": null, "author": "Kennyw88", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajv08w/u2_nvme_drives_vs_pcie_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajv08w/u2_nvme_drives_vs_pcie_question/", "subreddit_subscribers": 730688, "created_utc": 1707175602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_vjqremzo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "File transfer rate fluctuates from 100-20mb/s on a new ssd in just a sigle file, tried with different files, is it normal to get 20mb/s speed on a matebook d15 2020 connected to the motherboard via sata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sukzn7105vgc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/sukzn7105vgc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=01fdc00cbc0ea6711d25c8cba107f8f56b38b544"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/sukzn7105vgc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ced098848e6660e3f8b667d278adcf5bbbcdc974"}, {"y": 205, "x": 320, "u": "https://preview.redd.it/sukzn7105vgc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2fa8b7af018aaed2ec10e0b1043f51896bca3700"}], "s": {"y": 359, "x": 558, "u": "https://preview.redd.it/sukzn7105vgc1.png?width=558&amp;format=png&amp;auto=webp&amp;s=70b3a9d58b398ba08e504edc7909e6ffb086f772"}, "id": "sukzn7105vgc1"}, "spao89325vgc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 78, "x": 108, "u": "https://preview.redd.it/spao89325vgc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=403f483307e97d5b04f3abc63691c31b2feca520"}, {"y": 157, "x": 216, "u": "https://preview.redd.it/spao89325vgc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=99c828a38c4897b3568a59a9c93801f3f96b6173"}, {"y": 233, "x": 320, "u": "https://preview.redd.it/spao89325vgc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a0539786af3d8a6bfa80e7f30ecceee1a2266757"}], "s": {"y": 439, "x": 602, "u": "https://preview.redd.it/spao89325vgc1.png?width=602&amp;format=png&amp;auto=webp&amp;s=6333415bb85d12288780f9203ed93b8519da3049"}, "id": "spao89325vgc1"}}, "name": "t3_1ajx0y2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "ups": 5, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "sukzn7105vgc1", "id": 400828996}, {"media_id": "spao89325vgc1", "id": 400828997}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oV16Eqb9eKlyFofWSvLLWrKNSq0pSqXoCplGwPaGIaM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707180978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1ajx0y2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajx0y2", "is_robot_indexable": true, "report_reasons": null, "author": "Eduardo_2019", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajx0y2/file_transfer_rate_fluctuates_from_10020mbs_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1ajx0y2", "subreddit_subscribers": 730688, "created_utc": 1707180978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,i have a Canon Scan Lide 400 wich is an optical 4800dpi scanner and would like to digitalize and archive grandpa old photos. I'm new here to hoarding pics but i would like to discuss something before i start the process!\n\nGiven that in cameras world (not the same device, i know ..), a full frame sensors is way better than APS-C sensors, also due to pixel size (FF is **bigger**);\n\nI was just wondering if setting lower scan res, the scanner uses more \"reading\" pixels to scan the same point, resulting in a **bigger** \"combined\\_sensor\\_pixel\" block instead of one single pixel, giving better results in terms of quality and grain.\n\nI mean: if i scan at max 4800dpi each pixel reads a point, but what if i set 1200dpi (1/4 of max optical)? Do 4 pixels read the same point? I would have less resolution but maybe a better image overall?\n\n(sorry if i didn't used right scan technical terms, but hope i give the idea)\n\nI've done some scan test in TIFF with 4000dpi vs 2000dpi and the 2kdpi looks more sharp and clean!I have to run more scan tests to be sure (and i'll do) but i've seen this at the moment.\n\nAnyone has already tested photo scanning in this way?\n\nPS: at the end i'll keep TIFF archive as master and JPG for everyday use!  \n\n\nEDIT: we're talking about analog developed photos", "author_fullname": "t2_2fa047cs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitalizing old photos, best (and not necessarily MAX) dpi?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ak9l7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707229622.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707225633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,i have a Canon Scan Lide 400 wich is an optical 4800dpi scanner and would like to digitalize and archive grandpa old photos. I&amp;#39;m new here to hoarding pics but i would like to discuss something before i start the process!&lt;/p&gt;\n\n&lt;p&gt;Given that in cameras world (not the same device, i know ..), a full frame sensors is way better than APS-C sensors, also due to pixel size (FF is &lt;strong&gt;bigger&lt;/strong&gt;);&lt;/p&gt;\n\n&lt;p&gt;I was just wondering if setting lower scan res, the scanner uses more &amp;quot;reading&amp;quot; pixels to scan the same point, resulting in a &lt;strong&gt;bigger&lt;/strong&gt; &amp;quot;combined_sensor_pixel&amp;quot; block instead of one single pixel, giving better results in terms of quality and grain.&lt;/p&gt;\n\n&lt;p&gt;I mean: if i scan at max 4800dpi each pixel reads a point, but what if i set 1200dpi (1/4 of max optical)? Do 4 pixels read the same point? I would have less resolution but maybe a better image overall?&lt;/p&gt;\n\n&lt;p&gt;(sorry if i didn&amp;#39;t used right scan technical terms, but hope i give the idea)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done some scan test in TIFF with 4000dpi vs 2000dpi and the 2kdpi looks more sharp and clean!I have to run more scan tests to be sure (and i&amp;#39;ll do) but i&amp;#39;ve seen this at the moment.&lt;/p&gt;\n\n&lt;p&gt;Anyone has already tested photo scanning in this way?&lt;/p&gt;\n\n&lt;p&gt;PS: at the end i&amp;#39;ll keep TIFF archive as master and JPG for everyday use!  &lt;/p&gt;\n\n&lt;p&gt;EDIT: we&amp;#39;re talking about analog developed photos&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "14TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ak9l7f", "is_robot_indexable": true, "report_reasons": null, "author": "recursivepointer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1ak9l7f/digitalizing_old_photos_best_and_not_necessarily/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak9l7f/digitalizing_old_photos_best_and_not_necessarily/", "subreddit_subscribers": 730688, "created_utc": 1707225633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for open-source automated backup tools and I don't really know where to start. I found a few suggestions, however, I don't really know what the difference is between them:\n\n* [Pika](https://github.com/pika-backup/pika-backup)\n* [Restic](https://github.com/restic/restic)\n* [Duplicati](https://www.duplicati.com/)\n* [Urbackup](https://www.urbackup.org/)\n* [BorgBackup](https://github.com/borgbackup)\n\nEssentially, the setup that I have now is that I have a single external hard drive which I connect to and to which I backup whenever I want or remember to. I do it by simply copying the folders I need to the HDD. I don't really need system backups but I assume most tools allow to do them anyway.\n\nI know that a better way would be to have a drive constantly connected with a wire or in a home network with a computer but that's not really possible. My main goals for now are to at least try to backup more periodically than I do now but also keep it all compressed because the HDD space is, of course, limited.\n\nAn added benefit would be a nice GUI so that I don't have to google the commands each time I need to do a backup but that's not a top priority if the tool is otherwise great.\n\nThe problem is I don't even know **what to look for** in automated backup tools and I don't know if there's a tool that will fit the needs I described above. Where do I start?\n\n*I know this has been asked before but I think I have a specific request.*", "author_fullname": "t2_hcxl0cq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-source automated backup tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajrykz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707168092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for open-source automated backup tools and I don&amp;#39;t really know where to start. I found a few suggestions, however, I don&amp;#39;t really know what the difference is between them:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/pika-backup/pika-backup\"&gt;Pika&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/restic/restic\"&gt;Restic&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.duplicati.com/\"&gt;Duplicati&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.urbackup.org/\"&gt;Urbackup&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/borgbackup\"&gt;BorgBackup&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Essentially, the setup that I have now is that I have a single external hard drive which I connect to and to which I backup whenever I want or remember to. I do it by simply copying the folders I need to the HDD. I don&amp;#39;t really need system backups but I assume most tools allow to do them anyway.&lt;/p&gt;\n\n&lt;p&gt;I know that a better way would be to have a drive constantly connected with a wire or in a home network with a computer but that&amp;#39;s not really possible. My main goals for now are to at least try to backup more periodically than I do now but also keep it all compressed because the HDD space is, of course, limited.&lt;/p&gt;\n\n&lt;p&gt;An added benefit would be a nice GUI so that I don&amp;#39;t have to google the commands each time I need to do a backup but that&amp;#39;s not a top priority if the tool is otherwise great.&lt;/p&gt;\n\n&lt;p&gt;The problem is I don&amp;#39;t even know &lt;strong&gt;what to look for&lt;/strong&gt; in automated backup tools and I don&amp;#39;t know if there&amp;#39;s a tool that will fit the needs I described above. Where do I start?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I know this has been asked before but I think I have a specific request.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?auto=webp&amp;s=e92a7d73b6cc4a5dbc4d23aca8d451823a40f167", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b6409a2c87bcd4e5320c74919a44c115376c9436", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9955380c628587a83da7426ca8733120f0d43e2b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9560c6af215985bdf3470dfaf97766845be9272f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8963fcf065074edadb7a8991bb8e65764e94f169", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ce4d64d26dd89aa351c18ca9a3e34ac8079a3a54", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7e8075e5db2c75401d742d89eefde625c07ccf22", "width": 1080, "height": 540}], "variants": {}, "id": "kgMdspa7BS7i2z1MUSOoKaElD4VV4a75W5TiQ5DqKEg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajrykz", "is_robot_indexable": true, "report_reasons": null, "author": "FypeWaqer", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajrykz/opensource_automated_backup_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajrykz/opensource_automated_backup_tools/", "subreddit_subscribers": 730688, "created_utc": 1707168092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Basically, like it sounds.. have a ton of old DVD backups that are going bad.. so, I would like to dump everything possible and generate a log.txt that lists whatever didn't make it. Doing this on Windows laptop. Suggestions?", "author_fullname": "t2_nosi5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dumping semi bad DVD discs - log failed files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak5mku", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707210522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically, like it sounds.. have a ton of old DVD backups that are going bad.. so, I would like to dump everything possible and generate a log.txt that lists whatever didn&amp;#39;t make it. Doing this on Windows laptop. Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak5mku", "is_robot_indexable": true, "report_reasons": null, "author": "s1mbin", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak5mku/dumping_semi_bad_dvd_discs_log_failed_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak5mku/dumping_semi_bad_dvd_discs_log_failed_files/", "subreddit_subscribers": 730688, "created_utc": 1707210522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 4x 18tb on my pc for media storage to play over plex (not including OS drive). I have them currently as separate disk, and just manually mirroring disks 1-2 to 3-4. Been looking into raid, and if I understand correctly, if I set them up in raid 5, I would have more storage space with one parity drive (versus 2 mirrored drives). What are the negatives to setting them up as a raid array?", "author_fullname": "t2_6ntr7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raid or separate disks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajns1g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707158034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 4x 18tb on my pc for media storage to play over plex (not including OS drive). I have them currently as separate disk, and just manually mirroring disks 1-2 to 3-4. Been looking into raid, and if I understand correctly, if I set them up in raid 5, I would have more storage space with one parity drive (versus 2 mirrored drives). What are the negatives to setting them up as a raid array?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajns1g", "is_robot_indexable": true, "report_reasons": null, "author": "taintedplay", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajns1g/raid_or_separate_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajns1g/raid_or_separate_disks/", "subreddit_subscribers": 730688, "created_utc": 1707158034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I accidentally bought a hard drive that uses SAS connectors instead of SATA. Should I buy a PCIE chip that can read SAS from eBay or send it back? The hard drive was cheap; I should have read the description more closely.", "author_fullname": "t2_bi4wsne4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What To Do With SAS HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajn6eb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707156594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I accidentally bought a hard drive that uses SAS connectors instead of SATA. Should I buy a PCIE chip that can read SAS from eBay or send it back? The hard drive was cheap; I should have read the description more closely.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajn6eb", "is_robot_indexable": true, "report_reasons": null, "author": "Fast_Lunch_8103", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajn6eb/what_to_do_with_sas_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajn6eb/what_to_do_with_sas_hdd/", "subreddit_subscribers": 730688, "created_utc": 1707156594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi datahoarders! I'm searching for the cheapest jbod sas enclosure who supports large disks (14Tb+). It's for personal usage so budget is low as possible and I will buy used ones. \n\nThe cheapest one I've fount - EMC2 KTN-STL3, but I'm not sure of it supports disks more then 2Tb. \n\nI will be grateful for any advice", "author_fullname": "t2_254trxp0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "JBOD SAS3 enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ak8wac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707223468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi datahoarders! I&amp;#39;m searching for the cheapest jbod sas enclosure who supports large disks (14Tb+). It&amp;#39;s for personal usage so budget is low as possible and I will buy used ones. &lt;/p&gt;\n\n&lt;p&gt;The cheapest one I&amp;#39;ve fount - EMC2 KTN-STL3, but I&amp;#39;m not sure of it supports disks more then 2Tb. &lt;/p&gt;\n\n&lt;p&gt;I will be grateful for any advice&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak8wac", "is_robot_indexable": true, "report_reasons": null, "author": "krakazyabra", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak8wac/jbod_sas3_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak8wac/jbod_sas3_enclosure/", "subreddit_subscribers": 730688, "created_utc": 1707223468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have around 100GB of data , that I will maybe use once every 5 years, but I really want it on my working PC for the peace of mind. \n\nI do not mind compressing it , even it means accesing the data will take some time. \n\nI guess winrar works, too, but is properly no as effective.", "author_fullname": "t2_3lyupz8a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does someone have experience using freearc ( compressing files)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak6wch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707216078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 100GB of data , that I will maybe use once every 5 years, but I really want it on my working PC for the peace of mind. &lt;/p&gt;\n\n&lt;p&gt;I do not mind compressing it , even it means accesing the data will take some time. &lt;/p&gt;\n\n&lt;p&gt;I guess winrar works, too, but is properly no as effective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak6wch", "is_robot_indexable": true, "report_reasons": null, "author": "seronlover", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak6wch/does_someone_have_experience_using_freearc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak6wch/does_someone_have_experience_using_freearc/", "subreddit_subscribers": 730688, "created_utc": 1707216078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any advice on compression big files with saving the quality? I tried IrfanView but quality is drascitly deacrsing compared to original.", "author_fullname": "t2_qb0cdrj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image compression w/o significant quality loss", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak3o1t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707202122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any advice on compression big files with saving the quality? I tried IrfanView but quality is drascitly deacrsing compared to original.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak3o1t", "is_robot_indexable": true, "report_reasons": null, "author": "SmugXOF", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak3o1t/image_compression_wo_significant_quality_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak3o1t/image_compression_wo_significant_quality_loss/", "subreddit_subscribers": 730688, "created_utc": 1707202122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nwhat are currently the best tools for creating and checking hash values to ensure the integrity of data, to detect a hardware defect, bitrot...?  \nI would like to calculate hash values for a bunch of files, so that I can later check them individually or completely.\n\nFor Windows, small, fast, reliable, easy to use, maybe even portable - just the usual. :-)\n\nI've kinda misused \"CDCheck\" for this, but it's quiet old and and has his quirks.  \nWhat tools are used for this job today?\n\nThanks for any suggestions!  \nGreetings, Martin", "author_fullname": "t2_n03vn6lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which tools to ensure data integrity? Looking for a good hasher/comparator tool.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak032z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707189835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;what are currently the best tools for creating and checking hash values to ensure the integrity of data, to detect a hardware defect, bitrot...?&lt;br/&gt;\nI would like to calculate hash values for a bunch of files, so that I can later check them individually or completely.&lt;/p&gt;\n\n&lt;p&gt;For Windows, small, fast, reliable, easy to use, maybe even portable - just the usual. :-)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve kinda misused &amp;quot;CDCheck&amp;quot; for this, but it&amp;#39;s quiet old and and has his quirks.&lt;br/&gt;\nWhat tools are used for this job today?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions!&lt;br/&gt;\nGreetings, Martin&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak032z", "is_robot_indexable": true, "report_reasons": null, "author": "mfessl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak032z/which_tools_to_ensure_data_integrity_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak032z/which_tools_to_ensure_data_integrity_looking_for/", "subreddit_subscribers": 730688, "created_utc": 1707189835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nI always have a somewhat uneasy feeling when using container formats, especially as backups.  \nThey simplify handling immensely, relieve the \"load\" on the file system, and offer features such as checksums and error correction data, which can be very helpful in the event of a hardware defect.  \nBut when restoring data, it may be easier if they were saved as \"normal files\" and not within a vhd/vhdx, rar, 7z...\n\nYes, stored once \"natively\" and a second time in a container is probably the best, but there is always not enough space.\n\nHow do you think about that?\n\nThanks in advance for any opinion!  \nGreetings, Martin", "author_fullname": "t2_n03vn6lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better to storage data \"natively\" (as normal files) or in a container format. Disadvantages in case of data recovery?!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajzolq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707188613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I always have a somewhat uneasy feeling when using container formats, especially as backups.&lt;br/&gt;\nThey simplify handling immensely, relieve the &amp;quot;load&amp;quot; on the file system, and offer features such as checksums and error correction data, which can be very helpful in the event of a hardware defect.&lt;br/&gt;\nBut when restoring data, it may be easier if they were saved as &amp;quot;normal files&amp;quot; and not within a vhd/vhdx, rar, 7z...&lt;/p&gt;\n\n&lt;p&gt;Yes, stored once &amp;quot;natively&amp;quot; and a second time in a container is probably the best, but there is always not enough space.&lt;/p&gt;\n\n&lt;p&gt;How do you think about that?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any opinion!&lt;br/&gt;\nGreetings, Martin&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ajzolq", "is_robot_indexable": true, "report_reasons": null, "author": "mfessl", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajzolq/is_it_better_to_storage_data_natively_as_normal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajzolq/is_it_better_to_storage_data_natively_as_normal/", "subreddit_subscribers": 730688, "created_utc": 1707188613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nwhat good tools are there to \"refresh\" data without copying it to another medium?  \nI only know of DiskFresh, which is over 10 years old. HDSentinel seems also has an option for that.  \nAre there other alternatives?\n\nTo what extent is Bitrot actually an issue?  \nTo be honest, I haven't had a case in over 30 years.   \nDamaged files due to defective drives have happened, but no file has ever changed \"just by itself\". Maybe I was just lucky or I just didn't notice it (yet).  \nOf course, you also have to keep in mind that today's density and not least amount of data is completely different than it was just a few years ago.\n\nHow do you see the issue?  \nAnd does anyone have any tips for appropriate tools?\n\nThanks for any suggestions!  \nGreetings, Martin", "author_fullname": "t2_n03vn6lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool to refresh data to counteract Bitrot. Is that even really a problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajz2hw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707186788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;what good tools are there to &amp;quot;refresh&amp;quot; data without copying it to another medium?&lt;br/&gt;\nI only know of DiskFresh, which is over 10 years old. HDSentinel seems also has an option for that.&lt;br/&gt;\nAre there other alternatives?&lt;/p&gt;\n\n&lt;p&gt;To what extent is Bitrot actually an issue?&lt;br/&gt;\nTo be honest, I haven&amp;#39;t had a case in over 30 years.&lt;br/&gt;\nDamaged files due to defective drives have happened, but no file has ever changed &amp;quot;just by itself&amp;quot;. Maybe I was just lucky or I just didn&amp;#39;t notice it (yet).&lt;br/&gt;\nOf course, you also have to keep in mind that today&amp;#39;s density and not least amount of data is completely different than it was just a few years ago.&lt;/p&gt;\n\n&lt;p&gt;How do you see the issue?&lt;br/&gt;\nAnd does anyone have any tips for appropriate tools?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions!&lt;br/&gt;\nGreetings, Martin&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajz2hw", "is_robot_indexable": true, "report_reasons": null, "author": "mfessl", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajz2hw/tool_to_refresh_data_to_counteract_bitrot_is_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajz2hw/tool_to_refresh_data_to_counteract_bitrot_is_that/", "subreddit_subscribers": 730688, "created_utc": 1707186788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don\u2019t know if this is a stupid question. I was just setting up xigmanas on my new file server and wanted to encrypt a 20tb hdd. My old file server was a old windows machine where I encrypted the hdd using VeraCrypt. It took for 10tb almost 3 days back then. I assumed it would take xigmanas also some time to encrypt my 20tb drive but it only took seconds. How is that possible? What am I missing?", "author_fullname": "t2_zuupz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VeraCypt and Encryption on Xigmnas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajnh01", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707157297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t know if this is a stupid question. I was just setting up xigmanas on my new file server and wanted to encrypt a 20tb hdd. My old file server was a old windows machine where I encrypted the hdd using VeraCrypt. It took for 10tb almost 3 days back then. I assumed it would take xigmanas also some time to encrypt my 20tb drive but it only took seconds. How is that possible? What am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajnh01", "is_robot_indexable": true, "report_reasons": null, "author": "unknown_73", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajnh01/veracypt_and_encryption_on_xigmnas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajnh01/veracypt_and_encryption_on_xigmnas/", "subreddit_subscribers": 730688, "created_utc": 1707157297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I am required to store client documents for 7 years. I (ideally) average about two clients per day, and each generates 80-120 pages. My clients initial every page and sign at the end. After my clients leave, I spend 30-45 minutes scanning the documents, one at a time, on my old cannon. Finally, my clients pick up their documents a week later or I ship them with a courier service (nerve wracking).\n\nI want a solution that I can put the stack of papers in, and quickly (&lt;5 min) scan the files while my client sits in my office and just send the files home with the client.\n\nI tried a scansnap ix1600, but had to return it because the feeder tray only fits ~50 pages.\n\nWhat would you recommend?\n\nHow about a used FI-6670? Thinking of one solely because that one guy did 80k pages in 5 days. ", "author_fullname": "t2_6ohcl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestion for a scanner that can easily and quickly handle 80-120 duplex pages at a time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajmdlb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707155022.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707154753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am required to store client documents for 7 years. I (ideally) average about two clients per day, and each generates 80-120 pages. My clients initial every page and sign at the end. After my clients leave, I spend 30-45 minutes scanning the documents, one at a time, on my old cannon. Finally, my clients pick up their documents a week later or I ship them with a courier service (nerve wracking).&lt;/p&gt;\n\n&lt;p&gt;I want a solution that I can put the stack of papers in, and quickly (&amp;lt;5 min) scan the files while my client sits in my office and just send the files home with the client.&lt;/p&gt;\n\n&lt;p&gt;I tried a scansnap ix1600, but had to return it because the feeder tray only fits ~50 pages.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend?&lt;/p&gt;\n\n&lt;p&gt;How about a used FI-6670? Thinking of one solely because that one guy did 80k pages in 5 days. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajmdlb", "is_robot_indexable": true, "report_reasons": null, "author": "Dannyz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajmdlb/suggestion_for_a_scanner_that_can_easily_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajmdlb/suggestion_for_a_scanner_that_can_easily_and/", "subreddit_subscribers": 730688, "created_utc": 1707154753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I tried YouTube-DLG but it is sadly not working - my videos are stuck on queued and I think that's because it hasn't been updated since 2017 lol", "author_fullname": "t2_l9nej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Safe, open-source, Youtube downloader that has a UI and doesn't work with cmd lines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ak9n9h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707225805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried YouTube-DLG but it is sadly not working - my videos are stuck on queued and I think that&amp;#39;s because it hasn&amp;#39;t been updated since 2017 lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak9n9h", "is_robot_indexable": true, "report_reasons": null, "author": "TheyTukMyJub", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak9n9h/safe_opensource_youtube_downloader_that_has_a_ui/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak9n9h/safe_opensource_youtube_downloader_that_has_a_ui/", "subreddit_subscribers": 730688, "created_utc": 1707225805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello. This is multiple first for me. First post here. First SAS controller dead on my watch, in my computer, probably burnt.\n\nI use this computer as secondary NAS and backup. I have 2 Avago 2308 based controllers there. The other one is still fine. I am lucky I have literally good 50 of various Avago SAS RAID controllers. I just replaced it with inferior one (I need pass-through, as this is soft RAID5).\n\nThe controller crashed on 30th January and haven't recovered. Yesterday (5th February) I noticed my backup isn't being transfered into backup mashine. I woke it up (it is sleeping all the time, being woke up for backup and after backup bring put back to sleep), checked and seen my secondary SAS controller isn't responding. I rebooted, no dice, not even detected. Power cycle, detected, but crashed after first activity (building MD array). Reboot, lost controller. Power off, controller is literally hot despite bring directly in airflow. Power on, nothing controller isn't there. This time controller is actually too cold. It have signs of over current on PCIe pins.\n\nThis is first time I have seen something like that.\n\nHave spares, as you may loose access to data.", "author_fullname": "t2_aybw94ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Avago SAS9217-4i4e crashed twice, then overheated and died", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak5l62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707210334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. This is multiple first for me. First post here. First SAS controller dead on my watch, in my computer, probably burnt.&lt;/p&gt;\n\n&lt;p&gt;I use this computer as secondary NAS and backup. I have 2 Avago 2308 based controllers there. The other one is still fine. I am lucky I have literally good 50 of various Avago SAS RAID controllers. I just replaced it with inferior one (I need pass-through, as this is soft RAID5).&lt;/p&gt;\n\n&lt;p&gt;The controller crashed on 30th January and haven&amp;#39;t recovered. Yesterday (5th February) I noticed my backup isn&amp;#39;t being transfered into backup mashine. I woke it up (it is sleeping all the time, being woke up for backup and after backup bring put back to sleep), checked and seen my secondary SAS controller isn&amp;#39;t responding. I rebooted, no dice, not even detected. Power cycle, detected, but crashed after first activity (building MD array). Reboot, lost controller. Power off, controller is literally hot despite bring directly in airflow. Power on, nothing controller isn&amp;#39;t there. This time controller is actually too cold. It have signs of over current on PCIe pins.&lt;/p&gt;\n\n&lt;p&gt;This is first time I have seen something like that.&lt;/p&gt;\n\n&lt;p&gt;Have spares, as you may loose access to data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak5l62", "is_robot_indexable": true, "report_reasons": null, "author": "WizardNumberNext", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak5l62/avago_sas92174i4e_crashed_twice_then_overheated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak5l62/avago_sas92174i4e_crashed_twice_then_overheated/", "subreddit_subscribers": 730688, "created_utc": 1707210334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Several posts have recommended Uranium Backup. Since trying to use it, it has been crashing/freezing. Trying to set up the backups and it would freeze with the blue spinning cursor that when clicked enough would have Windows ask if I want to wait or close the program. I am on 9.8.3 free and Windows 10. If no solutions are found, I will google/ search this sub for other options. There was a program I used to use, but the ended the free version, even for local backup. Only online for businesses. I was going to email Uranium support, but it says free technical support is only for business users or what ever that tier is. Thanks.", "author_fullname": "t2_15u275", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uranium Backup Crashing.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak4fef", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707205205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Several posts have recommended Uranium Backup. Since trying to use it, it has been crashing/freezing. Trying to set up the backups and it would freeze with the blue spinning cursor that when clicked enough would have Windows ask if I want to wait or close the program. I am on 9.8.3 free and Windows 10. If no solutions are found, I will google/ search this sub for other options. There was a program I used to use, but the ended the free version, even for local backup. Only online for businesses. I was going to email Uranium support, but it says free technical support is only for business users or what ever that tier is. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak4fef", "is_robot_indexable": true, "report_reasons": null, "author": "Coolshows101", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak4fef/uranium_backup_crashing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak4fef/uranium_backup_crashing/", "subreddit_subscribers": 730688, "created_utc": 1707205205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there,\n\nI hope this is the right place to ask - there is a r/wdmycloud subreddit, but that seems to be quite deserted.\n\nAnyway: yesterday I performed a soft reset on my WD MyCloud Mirror Gen2 (by pushing a pin into the hole at the back for a few seconds to push the reset button), and normally the top light at the front blinks for a few minutes before the device is back online.\n\nHowever, this time it's been about 12 hours, the light is still blinking, the dashboard is down, and the device is not accessible on the network. I actually did another soft reset this morning (not sure if that was a good idea, or if it made a the process take even longer), which didn't help either.\n\n&amp;#x200B;\n\nSo, the question is: any theories as to why it's taking so long? is this just a question of waiting it out, and for it to finish whatever it's doing?", "author_fullname": "t2_2241hakp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD MyCloud Mirror soft reset taking ages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak3xtr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707227754.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707203172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I hope this is the right place to ask - there is a &lt;a href=\"/r/wdmycloud\"&gt;r/wdmycloud&lt;/a&gt; subreddit, but that seems to be quite deserted.&lt;/p&gt;\n\n&lt;p&gt;Anyway: yesterday I performed a soft reset on my WD MyCloud Mirror Gen2 (by pushing a pin into the hole at the back for a few seconds to push the reset button), and normally the top light at the front blinks for a few minutes before the device is back online.&lt;/p&gt;\n\n&lt;p&gt;However, this time it&amp;#39;s been about 12 hours, the light is still blinking, the dashboard is down, and the device is not accessible on the network. I actually did another soft reset this morning (not sure if that was a good idea, or if it made a the process take even longer), which didn&amp;#39;t help either.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So, the question is: any theories as to why it&amp;#39;s taking so long? is this just a question of waiting it out, and for it to finish whatever it&amp;#39;s doing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak3xtr", "is_robot_indexable": true, "report_reasons": null, "author": "Ailar68", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak3xtr/wd_mycloud_mirror_soft_reset_taking_ages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak3xtr/wd_mycloud_mirror_soft_reset_taking_ages/", "subreddit_subscribers": 730688, "created_utc": 1707203172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What are some examples of alternative archives you guys like? Perhaps at the intersection of art and archival, or projects that center community archives? Things like [LACA](https://www.lacarchive.com/browse/bydate), or [Cyberfeminism Index](https://cyberfeminismindex.com/)? [Community Archives Collaborative](https://communityarchivescollab.org/) Or archivists doing interesting work? Like Stephanie Syjuco? Or [ANJALI ARONDEKAR](https://anjaliarondekar.sites.ucsc.edu/)? ", "author_fullname": "t2_prf08ntbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking more alternative archives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajznh6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707188521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some examples of alternative archives you guys like? Perhaps at the intersection of art and archival, or projects that center community archives? Things like &lt;a href=\"https://www.lacarchive.com/browse/bydate\"&gt;LACA&lt;/a&gt;, or &lt;a href=\"https://cyberfeminismindex.com/\"&gt;Cyberfeminism Index&lt;/a&gt;? &lt;a href=\"https://communityarchivescollab.org/\"&gt;Community Archives Collaborative&lt;/a&gt; Or archivists doing interesting work? Like Stephanie Syjuco? Or &lt;a href=\"https://anjaliarondekar.sites.ucsc.edu/\"&gt;ANJALI ARONDEKAR&lt;/a&gt;? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajznh6", "is_robot_indexable": true, "report_reasons": null, "author": "bigfoambrick", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajznh6/seeking_more_alternative_archives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajznh6/seeking_more_alternative_archives/", "subreddit_subscribers": 730688, "created_utc": 1707188521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Where do I find sas3flash for Linux(or efi, not picky by this point)? Broadcom is completely useless by this point and I can't find anywhere else to download it from.", "author_fullname": "t2_5v1j3d7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "sas3flash command not found", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajyxn2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707186395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where do I find sas3flash for Linux(or efi, not picky by this point)? Broadcom is completely useless by this point and I can&amp;#39;t find anywhere else to download it from.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajyxn2", "is_robot_indexable": true, "report_reasons": null, "author": "steampunk333", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajyxn2/sas3flash_command_not_found/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajyxn2/sas3flash_command_not_found/", "subreddit_subscribers": 730688, "created_utc": 1707186395.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}