{"kind": "Listing", "data": {"after": "t3_1ajyxn2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "10+ years of data hoarding gone, just like that.\n\nI stupidly enabled SMB 1.0 on my home media server yesterday (Windows Server 2016, Hyper-V, home file share, etc) after coming across a Microsoft article titled \"Can't access shared folders from File Explorer in Windows 10\" as I was having trouble connecting to my SMB share from a new laptop. Hours later, kiddo says \"Plex isn't working\" So I open File Explorer and see thousands of files being modified with the extension .OP3v8o4K2 and a text file on my desktop with the same name. I open the file, and my worst fears are confirmed. \"Your files have been encrypted and will be leaked to the dark web if you don't pay ransom at the BTC address blah blah blah\". Another stupid move on my part was not screenshotting the ransom letter before shutting down the server so I could at least report it. It's because I panicked and powered it off ASAP to protect the rest of my home network. I unplugged from the network and attempted to boot back up and saw the classic \"No boot device found.\" I am suspicious that my server has been infected for a while, bypassing Windows Security, and enabling SMB 1.0 finally gave it permission to execute. My plan is to try a Windows PE and restore point, or boot to portable Linux and see how much data is salvageable and copy to a new drive. After the fact, boot and nuke the old drive. My file share exceeded 24TB (56TB capacity), and that was my backup destination for my other PCs, so I had no offline backups of my media.\n\nRIP to my much-loved home media server and a reminder to all you home server admins to 1. Measure twice cut once and 2. Practice a good backup routine and create one now if you don't have any backups\n\nTLDR; I fell victim to ransomware after enabling SMB 1.0 on Windows and lost 10+ years of managing my home media server and about 24TB of data.\n\nEdit: Answering some of the questions, I had Plex Media Server forwarded to port 32400 so it was exposed to the internet. The built-in Windows Server '16 firewall was enabled and my crappy router has its own firewall but no additional layers of antivirus. I suspected other devices on my network would quickly become infected but so far, thankfully that hasn't happened.", "author_fullname": "t2_2bzp5g6y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Don\u2019t be like me. Ransomware victim PSA.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajq8st", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 287, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 287, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707173303.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707163943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;10+ years of data hoarding gone, just like that.&lt;/p&gt;\n\n&lt;p&gt;I stupidly enabled SMB 1.0 on my home media server yesterday (Windows Server 2016, Hyper-V, home file share, etc) after coming across a Microsoft article titled &amp;quot;Can&amp;#39;t access shared folders from File Explorer in Windows 10&amp;quot; as I was having trouble connecting to my SMB share from a new laptop. Hours later, kiddo says &amp;quot;Plex isn&amp;#39;t working&amp;quot; So I open File Explorer and see thousands of files being modified with the extension .OP3v8o4K2 and a text file on my desktop with the same name. I open the file, and my worst fears are confirmed. &amp;quot;Your files have been encrypted and will be leaked to the dark web if you don&amp;#39;t pay ransom at the BTC address blah blah blah&amp;quot;. Another stupid move on my part was not screenshotting the ransom letter before shutting down the server so I could at least report it. It&amp;#39;s because I panicked and powered it off ASAP to protect the rest of my home network. I unplugged from the network and attempted to boot back up and saw the classic &amp;quot;No boot device found.&amp;quot; I am suspicious that my server has been infected for a while, bypassing Windows Security, and enabling SMB 1.0 finally gave it permission to execute. My plan is to try a Windows PE and restore point, or boot to portable Linux and see how much data is salvageable and copy to a new drive. After the fact, boot and nuke the old drive. My file share exceeded 24TB (56TB capacity), and that was my backup destination for my other PCs, so I had no offline backups of my media.&lt;/p&gt;\n\n&lt;p&gt;RIP to my much-loved home media server and a reminder to all you home server admins to 1. Measure twice cut once and 2. Practice a good backup routine and create one now if you don&amp;#39;t have any backups&lt;/p&gt;\n\n&lt;p&gt;TLDR; I fell victim to ransomware after enabling SMB 1.0 on Windows and lost 10+ years of managing my home media server and about 24TB of data.&lt;/p&gt;\n\n&lt;p&gt;Edit: Answering some of the questions, I had Plex Media Server forwarded to port 32400 so it was exposed to the internet. The built-in Windows Server &amp;#39;16 firewall was enabled and my crappy router has its own firewall but no additional layers of antivirus. I suspected other devices on my network would quickly become infected but so far, thankfully that hasn&amp;#39;t happened.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajq8st", "is_robot_indexable": true, "report_reasons": null, "author": "brandonclone1", "discussion_type": null, "num_comments": 154, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajq8st/dont_be_like_me_ransomware_victim_psa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajq8st/dont_be_like_me_ransomware_victim_psa/", "subreddit_subscribers": 730653, "created_utc": 1707163943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Original news article](https://worldoftanks.eu/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/) | [NA](https://worldoftanks.com/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/) | [ASIA](https://worldoftanks.asia/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/)\n\n&gt;Starting February 20 at 12:00 (MSK), we will be transitioning our forums to Discord. On this date, the forums will switch to read-only mode, and on May 20 at 12:00 (MSK), they will permanently close. \n\nGiven that, Wargaming scraps 13 years of World of Tanks community history, transitioning another platform to non-indexeable, unreliable platform, where they also continued butchering community's posts (e.g. media channel being removed, where stuff back from Discord server launch resided).\n\nNot an 'archive this for me' (rule 8) post.", "author_fullname": "t2_452npj84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wargaming.net to kill off World of Tanks official forums", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajiy4t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 264, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 264, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707146374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://worldoftanks.eu/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/\"&gt;Original news article&lt;/a&gt; | &lt;a href=\"https://worldoftanks.com/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/\"&gt;NA&lt;/a&gt; | &lt;a href=\"https://worldoftanks.asia/en/news/general-news/community-update-wot-forum-yt-consolidation-feb24/\"&gt;ASIA&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Starting February 20 at 12:00 (MSK), we will be transitioning our forums to Discord. On this date, the forums will switch to read-only mode, and on May 20 at 12:00 (MSK), they will permanently close. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Given that, Wargaming scraps 13 years of World of Tanks community history, transitioning another platform to non-indexeable, unreliable platform, where they also continued butchering community&amp;#39;s posts (e.g. media channel being removed, where stuff back from Discord server launch resided).&lt;/p&gt;\n\n&lt;p&gt;Not an &amp;#39;archive this for me&amp;#39; (rule 8) post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uv_kWCfxGxVrDYyN_OQDoxwJq7PUvOI9URhUb5zXwi8.jpg?auto=webp&amp;s=41667ba4aaa7cc488e6ed923463635bd1f12da6f", "width": 615, "height": 346}, "resolutions": [{"url": "https://external-preview.redd.it/uv_kWCfxGxVrDYyN_OQDoxwJq7PUvOI9URhUb5zXwi8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2334832bab81b94f435ffaba922b6a4189e936b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/uv_kWCfxGxVrDYyN_OQDoxwJq7PUvOI9URhUb5zXwi8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c182bbb74262b2045803775e86c4ca58bd542aff", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/uv_kWCfxGxVrDYyN_OQDoxwJq7PUvOI9URhUb5zXwi8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3bf9b1558dd445732b8516b7e4526921f809176a", "width": 320, "height": 180}], "variants": {}, "id": "ucb3UUFdB5Gkw_N528jGRvQOzW7wMhEq-7KsoTy8mN0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajiy4t", "is_robot_indexable": true, "report_reasons": null, "author": "SigmaTel71", "discussion_type": null, "num_comments": 80, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajiy4t/wargamingnet_to_kill_off_world_of_tanks_official/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajiy4t/wargamingnet_to_kill_off_world_of_tanks_official/", "subreddit_subscribers": 730653, "created_utc": 1707146374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The WD and seagate ones still use the old 3.0 micro b connector. I leave the short cable always connected because I hate plugging it in and don't want to accidentally damage the port. \n\nEspecially since WD ones cannot be shucked if needed.\n\nSo does anyone know the reason? Is it just cheaper to keep the same design?", "author_fullname": "t2_75tzmt2kw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why don't portable HDDs use USB-C ports?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajj0y1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707146577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The WD and seagate ones still use the old 3.0 micro b connector. I leave the short cable always connected because I hate plugging it in and don&amp;#39;t want to accidentally damage the port. &lt;/p&gt;\n\n&lt;p&gt;Especially since WD ones cannot be shucked if needed.&lt;/p&gt;\n\n&lt;p&gt;So does anyone know the reason? Is it just cheaper to keep the same design?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ajj0y1", "is_robot_indexable": true, "report_reasons": null, "author": "Amon9001", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajj0y1/why_dont_portable_hdds_use_usbc_ports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajj0y1/why_dont_portable_hdds_use_usbc_ports/", "subreddit_subscribers": 730653, "created_utc": 1707146577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few 15.36TB **Intel D5-P4326s coming as I was able to get them for a reasonable price.  While they will eventually make their way into one of my NASs, they will be in my MSI Z790 system for a bit.  I had ordered a ton of PCI cheat adapters from Alliexpress in the hope that I'll get one method to work.  Today I was thinking about PCI bifurcation and this motherboard doesn't support it, but I don't know if I need to do that.  These two adapters are some of the things I have on order - will it just work or must you be able to change 16x to 4x4x4x4 and 8x to 4x4?  If it won't, I can just use them for an upcoming Xeon server build and go with the M.2 to U.2 adapters I bought - I'm hoping this top adaptor will work, though.**\n\n&amp;#x200B;\n\nhttps://preview.redd.it/pc8skwglougc1.jpg?width=490&amp;format=pjpg&amp;auto=webp&amp;s=91a99794931a2947bd14d0f111b6d25cd42697e7\n\nhttps://preview.redd.it/nmrcwk5lougc1.jpg?width=418&amp;format=pjpg&amp;auto=webp&amp;s=33c8ed73bf08ed00a864a29884d9300df1a0ad03\n\n&amp;#x200B;", "author_fullname": "t2_ldhe3aze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "U.2 NVMe drives vs PCIe question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pc8skwglougc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/pc8skwglougc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=82a7946b092a839f3a7f551fb4dfa93ba72fe7ec"}, {"y": 145, "x": 216, "u": "https://preview.redd.it/pc8skwglougc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b2233529114b929756e1300f98085a4b9ecdde8d"}, {"y": 214, "x": 320, "u": "https://preview.redd.it/pc8skwglougc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df52fcfd5d75059316e45c5f7f8bced6315841e7"}], "s": {"y": 329, "x": 490, "u": "https://preview.redd.it/pc8skwglougc1.jpg?width=490&amp;format=pjpg&amp;auto=webp&amp;s=91a99794931a2947bd14d0f111b6d25cd42697e7"}, "id": "pc8skwglougc1"}, "nmrcwk5lougc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 126, "x": 108, "u": "https://preview.redd.it/nmrcwk5lougc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de1be7202f6ec58cb471eddecfa096357f4c4988"}, {"y": 253, "x": 216, "u": "https://preview.redd.it/nmrcwk5lougc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=51543d80587b236ea8ac3bcc8ab0fc4d2184a938"}, {"y": 375, "x": 320, "u": "https://preview.redd.it/nmrcwk5lougc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02692eb00de21325c629c4e05ce70f950be32952"}], "s": {"y": 491, "x": 418, "u": "https://preview.redd.it/nmrcwk5lougc1.jpg?width=418&amp;format=pjpg&amp;auto=webp&amp;s=33c8ed73bf08ed00a864a29884d9300df1a0ad03"}, "id": "nmrcwk5lougc1"}}, "name": "t3_1ajv08w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/P2nD0t_5QYWZ1dXTyYFm4_51Rh1wp9UrAUX13NQO6yg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707175602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few 15.36TB &lt;strong&gt;Intel D5-P4326s coming as I was able to get them for a reasonable price.  While they will eventually make their way into one of my NASs, they will be in my MSI Z790 system for a bit.  I had ordered a ton of PCI cheat adapters from Alliexpress in the hope that I&amp;#39;ll get one method to work.  Today I was thinking about PCI bifurcation and this motherboard doesn&amp;#39;t support it, but I don&amp;#39;t know if I need to do that.  These two adapters are some of the things I have on order - will it just work or must you be able to change 16x to 4x4x4x4 and 8x to 4x4?  If it won&amp;#39;t, I can just use them for an upcoming Xeon server build and go with the M.2 to U.2 adapters I bought - I&amp;#39;m hoping this top adaptor will work, though.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pc8skwglougc1.jpg?width=490&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=91a99794931a2947bd14d0f111b6d25cd42697e7\"&gt;https://preview.redd.it/pc8skwglougc1.jpg?width=490&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=91a99794931a2947bd14d0f111b6d25cd42697e7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nmrcwk5lougc1.jpg?width=418&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=33c8ed73bf08ed00a864a29884d9300df1a0ad03\"&gt;https://preview.redd.it/nmrcwk5lougc1.jpg?width=418&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=33c8ed73bf08ed00a864a29884d9300df1a0ad03&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajv08w", "is_robot_indexable": true, "report_reasons": null, "author": "Kennyw88", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajv08w/u2_nvme_drives_vs_pcie_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajv08w/u2_nvme_drives_vs_pcie_question/", "subreddit_subscribers": 730653, "created_utc": 1707175602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_vjqremzo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "File transfer rate fluctuates from 100-20mb/s on a new ssd in just a sigle file, tried with different files, is it normal to get 20mb/s speed on a matebook d15 2020 connected to the motherboard via sata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sukzn7105vgc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/sukzn7105vgc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=01fdc00cbc0ea6711d25c8cba107f8f56b38b544"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/sukzn7105vgc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ced098848e6660e3f8b667d278adcf5bbbcdc974"}, {"y": 205, "x": 320, "u": "https://preview.redd.it/sukzn7105vgc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2fa8b7af018aaed2ec10e0b1043f51896bca3700"}], "s": {"y": 359, "x": 558, "u": "https://preview.redd.it/sukzn7105vgc1.png?width=558&amp;format=png&amp;auto=webp&amp;s=70b3a9d58b398ba08e504edc7909e6ffb086f772"}, "id": "sukzn7105vgc1"}, "spao89325vgc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 78, "x": 108, "u": "https://preview.redd.it/spao89325vgc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=403f483307e97d5b04f3abc63691c31b2feca520"}, {"y": 157, "x": 216, "u": "https://preview.redd.it/spao89325vgc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=99c828a38c4897b3568a59a9c93801f3f96b6173"}, {"y": 233, "x": 320, "u": "https://preview.redd.it/spao89325vgc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a0539786af3d8a6bfa80e7f30ecceee1a2266757"}], "s": {"y": 439, "x": 602, "u": "https://preview.redd.it/spao89325vgc1.png?width=602&amp;format=png&amp;auto=webp&amp;s=6333415bb85d12288780f9203ed93b8519da3049"}, "id": "spao89325vgc1"}}, "name": "t3_1ajx0y2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "ups": 3, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "sukzn7105vgc1", "id": 400828996}, {"media_id": "spao89325vgc1", "id": 400828997}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oV16Eqb9eKlyFofWSvLLWrKNSq0pSqXoCplGwPaGIaM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707180978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1ajx0y2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajx0y2", "is_robot_indexable": true, "report_reasons": null, "author": "Eduardo_2019", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajx0y2/file_transfer_rate_fluctuates_from_10020mbs_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1ajx0y2", "subreddit_subscribers": 730653, "created_utc": 1707180978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 4x 18tb on my pc for media storage to play over plex (not including OS drive). I have them currently as separate disk, and just manually mirroring disks 1-2 to 3-4. Been looking into raid, and if I understand correctly, if I set them up in raid 5, I would have more storage space with one parity drive (versus 2 mirrored drives). What are the negatives to setting them up as a raid array?", "author_fullname": "t2_6ntr7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raid or separate disks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajns1g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707158034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 4x 18tb on my pc for media storage to play over plex (not including OS drive). I have them currently as separate disk, and just manually mirroring disks 1-2 to 3-4. Been looking into raid, and if I understand correctly, if I set them up in raid 5, I would have more storage space with one parity drive (versus 2 mirrored drives). What are the negatives to setting them up as a raid array?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajns1g", "is_robot_indexable": true, "report_reasons": null, "author": "taintedplay", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajns1g/raid_or_separate_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajns1g/raid_or_separate_disks/", "subreddit_subscribers": 730653, "created_utc": 1707158034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I accidentally bought a hard drive that uses SAS connectors instead of SATA. Should I buy a PCIE chip that can read SAS from eBay or send it back? The hard drive was cheap; I should have read the description more closely.", "author_fullname": "t2_bi4wsne4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What To Do With SAS HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajn6eb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707156594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I accidentally bought a hard drive that uses SAS connectors instead of SATA. Should I buy a PCIE chip that can read SAS from eBay or send it back? The hard drive was cheap; I should have read the description more closely.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajn6eb", "is_robot_indexable": true, "report_reasons": null, "author": "Fast_Lunch_8103", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajn6eb/what_to_do_with_sas_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajn6eb/what_to_do_with_sas_hdd/", "subreddit_subscribers": 730653, "created_utc": 1707156594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, \n\nI know this is not a 100% data hoarding related question and it could be seen as violating rule number 2, but I thought it falls into the general principle of preserving digital content.\n\nThe Logitech Harmony devices have already been discontinued for some time. The servers (that you need in order to configure your remote for new devices) are still there, but the question is for how long? For those maybe not aware, when you want to configure your Harmony remote (e.g. to use a new device or change button associations) it will connect to the Harmony servers, as the profiles are stored in the cloud. So when the servers would go down tomorrow, you still could control your TV and other appliances, but not configure your remote to do different things.\n\nI was wondering over the weekend if there would be a way to scrape the device DB of the Harmony servers with the goal to build a self hostable replacement of the server backend when Logitech will shut off the servers at some point in the future.\n\nAny opinions?", "author_fullname": "t2_qzhj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logitech Harmony backend scrape/replacement?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajc4zl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707123328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I know this is not a 100% data hoarding related question and it could be seen as violating rule number 2, but I thought it falls into the general principle of preserving digital content.&lt;/p&gt;\n\n&lt;p&gt;The Logitech Harmony devices have already been discontinued for some time. The servers (that you need in order to configure your remote for new devices) are still there, but the question is for how long? For those maybe not aware, when you want to configure your Harmony remote (e.g. to use a new device or change button associations) it will connect to the Harmony servers, as the profiles are stored in the cloud. So when the servers would go down tomorrow, you still could control your TV and other appliances, but not configure your remote to do different things.&lt;/p&gt;\n\n&lt;p&gt;I was wondering over the weekend if there would be a way to scrape the device DB of the Harmony servers with the goal to build a self hostable replacement of the server backend when Logitech will shut off the servers at some point in the future.&lt;/p&gt;\n\n&lt;p&gt;Any opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ajc4zl", "is_robot_indexable": true, "report_reasons": null, "author": "Sono-Gomorrha", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajc4zl/logitech_harmony_backend_scrapereplacement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajc4zl/logitech_harmony_backend_scrapereplacement/", "subreddit_subscribers": 730653, "created_utc": 1707123328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any advice on compression big files with saving the quality? I tried IrfanView but quality is drascitly deacrsing compared to original.", "author_fullname": "t2_qb0cdrj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image compression w/o significant quality loss", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ak3o1t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707202122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any advice on compression big files with saving the quality? I tried IrfanView but quality is drascitly deacrsing compared to original.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak3o1t", "is_robot_indexable": true, "report_reasons": null, "author": "SmugXOF", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak3o1t/image_compression_wo_significant_quality_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak3o1t/image_compression_wo_significant_quality_loss/", "subreddit_subscribers": 730653, "created_utc": 1707202122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m doing research on my new-to-me server ([Dell PowerEdge T110-II](https://i.dell.com/sites/csdocuments/Shared-Content_data-Sheets_Documents/en/Dell-PowerEdge-T110II-SpecSheet.pdf)). I had impulsively bought 4x 10TB WD Gold drives to fill this guy up ( I don\u2019t know what 2x RAID 1 is called, but that\u2019s what I wanted to do), plus a 1TB boot drive. While waiting for shipping to come, I find out that the motherboard only supports 12TB total storage. \n\nNow, my question is, would using a PERC H310 or something similar be the move to enable the 21 TB, or should I buy  different drives?", "author_fullname": "t2_ebd9trlq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My first Server- Need Advice on Storage Config", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ak3j3j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707201613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m doing research on my new-to-me server (&lt;a href=\"https://i.dell.com/sites/csdocuments/Shared-Content_data-Sheets_Documents/en/Dell-PowerEdge-T110II-SpecSheet.pdf\"&gt;Dell PowerEdge T110-II&lt;/a&gt;). I had impulsively bought 4x 10TB WD Gold drives to fill this guy up ( I don\u2019t know what 2x RAID 1 is called, but that\u2019s what I wanted to do), plus a 1TB boot drive. While waiting for shipping to come, I find out that the motherboard only supports 12TB total storage. &lt;/p&gt;\n\n&lt;p&gt;Now, my question is, would using a PERC H310 or something similar be the move to enable the 21 TB, or should I buy  different drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak3j3j", "is_robot_indexable": true, "report_reasons": null, "author": "SkabKid", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak3j3j/my_first_server_need_advice_on_storage_config/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak3j3j/my_first_server_need_advice_on_storage_config/", "subreddit_subscribers": 730653, "created_utc": 1707201613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nwhat are currently the best tools for creating and checking hash values to ensure the integrity of data, to detect a hardware defect, bitrot...?  \nI would like to calculate hash values for a bunch of files, so that I can later check them individually or completely.\n\nFor Windows, small, fast, reliable, easy to use, maybe even portable - just the usual. :-)\n\nI've kinda misused \"CDCheck\" for this, but it's quiet old and and has his quirks.  \nWhat tools are used for this job today?\n\nThanks for any suggestions!  \nGreetings, Martin", "author_fullname": "t2_n03vn6lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which tools to ensure data integrity? Looking for a good hasher/comparator tool.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak032z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707189835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;what are currently the best tools for creating and checking hash values to ensure the integrity of data, to detect a hardware defect, bitrot...?&lt;br/&gt;\nI would like to calculate hash values for a bunch of files, so that I can later check them individually or completely.&lt;/p&gt;\n\n&lt;p&gt;For Windows, small, fast, reliable, easy to use, maybe even portable - just the usual. :-)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve kinda misused &amp;quot;CDCheck&amp;quot; for this, but it&amp;#39;s quiet old and and has his quirks.&lt;br/&gt;\nWhat tools are used for this job today?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions!&lt;br/&gt;\nGreetings, Martin&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak032z", "is_robot_indexable": true, "report_reasons": null, "author": "mfessl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak032z/which_tools_to_ensure_data_integrity_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak032z/which_tools_to_ensure_data_integrity_looking_for/", "subreddit_subscribers": 730653, "created_utc": 1707189835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nI always have a somewhat uneasy feeling when using container formats, especially as backups.  \nThey simplify handling immensely, relieve the \"load\" on the file system, and offer features such as checksums and error correction data, which can be very helpful in the event of a hardware defect.  \nBut when restoring data, it may be easier if they were saved as \"normal files\" and not within a vhd/vhdx, rar, 7z...\n\nYes, stored once \"natively\" and a second time in a container is probably the best, but there is always not enough space.\n\nHow do you think about that?\n\nThanks in advance for any opinion!  \nGreetings, Martin", "author_fullname": "t2_n03vn6lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better to storage data \"natively\" (as normal files) or in a container format. Disadvantages in case of data recovery?!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajzolq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707188613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I always have a somewhat uneasy feeling when using container formats, especially as backups.&lt;br/&gt;\nThey simplify handling immensely, relieve the &amp;quot;load&amp;quot; on the file system, and offer features such as checksums and error correction data, which can be very helpful in the event of a hardware defect.&lt;br/&gt;\nBut when restoring data, it may be easier if they were saved as &amp;quot;normal files&amp;quot; and not within a vhd/vhdx, rar, 7z...&lt;/p&gt;\n\n&lt;p&gt;Yes, stored once &amp;quot;natively&amp;quot; and a second time in a container is probably the best, but there is always not enough space.&lt;/p&gt;\n\n&lt;p&gt;How do you think about that?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any opinion!&lt;br/&gt;\nGreetings, Martin&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ajzolq", "is_robot_indexable": true, "report_reasons": null, "author": "mfessl", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajzolq/is_it_better_to_storage_data_natively_as_normal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajzolq/is_it_better_to_storage_data_natively_as_normal/", "subreddit_subscribers": 730653, "created_utc": 1707188613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What are some examples of alternative archives you guys like? Perhaps at the intersection of art and archival, or projects that center community archives? Things like [LACA](https://www.lacarchive.com/browse/bydate), or [Cyberfeminism Index](https://cyberfeminismindex.com/)? [Community Archives Collaborative](https://communityarchivescollab.org/) Or archivists doing interesting work? Like Stephanie Syjuco? Or [ANJALI ARONDEKAR](https://anjaliarondekar.sites.ucsc.edu/)? ", "author_fullname": "t2_prf08ntbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking more alternative archives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajznh6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707188521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some examples of alternative archives you guys like? Perhaps at the intersection of art and archival, or projects that center community archives? Things like &lt;a href=\"https://www.lacarchive.com/browse/bydate\"&gt;LACA&lt;/a&gt;, or &lt;a href=\"https://cyberfeminismindex.com/\"&gt;Cyberfeminism Index&lt;/a&gt;? &lt;a href=\"https://communityarchivescollab.org/\"&gt;Community Archives Collaborative&lt;/a&gt; Or archivists doing interesting work? Like Stephanie Syjuco? Or &lt;a href=\"https://anjaliarondekar.sites.ucsc.edu/\"&gt;ANJALI ARONDEKAR&lt;/a&gt;? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajznh6", "is_robot_indexable": true, "report_reasons": null, "author": "bigfoambrick", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajznh6/seeking_more_alternative_archives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajznh6/seeking_more_alternative_archives/", "subreddit_subscribers": 730653, "created_utc": 1707188521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nwhat good tools are there to \"refresh\" data without copying it to another medium?  \nI only know of DiskFresh, which is over 10 years old. HDSentinel seems also has an option for that.  \nAre there other alternatives?\n\nTo what extent is Bitrot actually an issue?  \nTo be honest, I haven't had a case in over 30 years.   \nDamaged files due to defective drives have happened, but no file has ever changed \"just by itself\". Maybe I was just lucky or I just didn't notice it (yet).  \nOf course, you also have to keep in mind that today's density and not least amount of data is completely different than it was just a few years ago.\n\nHow do you see the issue?  \nAnd does anyone have any tips for appropriate tools?\n\nThanks for any suggestions!  \nGreetings, Martin", "author_fullname": "t2_n03vn6lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool to refresh data to counteract Bitrot. Is that even really a problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajz2hw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707186788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;what good tools are there to &amp;quot;refresh&amp;quot; data without copying it to another medium?&lt;br/&gt;\nI only know of DiskFresh, which is over 10 years old. HDSentinel seems also has an option for that.&lt;br/&gt;\nAre there other alternatives?&lt;/p&gt;\n\n&lt;p&gt;To what extent is Bitrot actually an issue?&lt;br/&gt;\nTo be honest, I haven&amp;#39;t had a case in over 30 years.&lt;br/&gt;\nDamaged files due to defective drives have happened, but no file has ever changed &amp;quot;just by itself&amp;quot;. Maybe I was just lucky or I just didn&amp;#39;t notice it (yet).&lt;br/&gt;\nOf course, you also have to keep in mind that today&amp;#39;s density and not least amount of data is completely different than it was just a few years ago.&lt;/p&gt;\n\n&lt;p&gt;How do you see the issue?&lt;br/&gt;\nAnd does anyone have any tips for appropriate tools?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions!&lt;br/&gt;\nGreetings, Martin&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajz2hw", "is_robot_indexable": true, "report_reasons": null, "author": "mfessl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajz2hw/tool_to_refresh_data_to_counteract_bitrot_is_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajz2hw/tool_to_refresh_data_to_counteract_bitrot_is_that/", "subreddit_subscribers": 730653, "created_utc": 1707186788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for open-source automated backup tools and I don't really know where to start. I found a few suggestions, however, I don't really know what the difference is between them:\n\n* [Pika](https://github.com/pika-backup/pika-backup)\n* [Restic](https://github.com/restic/restic)\n* [Duplicati](https://www.duplicati.com/)\n* [Urbackup](https://www.urbackup.org/)\n* [BorgBackup](https://github.com/borgbackup)\n\nEssentially, the setup that I have now is that I have a single external hard drive which I connect to and to which I backup whenever I want or remember to. I do it by simply copying the folders I need to the HDD. I don't really need system backups but I assume most tools allow to do them anyway.\n\nI know that a better way would be to have a drive constantly connected with a wire or in a home network with a computer but that's not really possible. My main goals for now are to at least try to backup more periodically than I do now but also keep it all compressed because the HDD space is, of course, limited.\n\nAn added benefit would be a nice GUI so that I don't have to google the commands each time I need to do a backup but that's not a top priority if the tool is otherwise great.\n\nThe problem is I don't even know **what to look for** in automated backup tools and I don't know if there's a tool that will fit the needs I described above. Where do I start?\n\n*I know this has been asked before but I think I have a specific request.*", "author_fullname": "t2_hcxl0cq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-source automated backup tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajrykz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707168092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for open-source automated backup tools and I don&amp;#39;t really know where to start. I found a few suggestions, however, I don&amp;#39;t really know what the difference is between them:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/pika-backup/pika-backup\"&gt;Pika&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/restic/restic\"&gt;Restic&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.duplicati.com/\"&gt;Duplicati&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.urbackup.org/\"&gt;Urbackup&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/borgbackup\"&gt;BorgBackup&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Essentially, the setup that I have now is that I have a single external hard drive which I connect to and to which I backup whenever I want or remember to. I do it by simply copying the folders I need to the HDD. I don&amp;#39;t really need system backups but I assume most tools allow to do them anyway.&lt;/p&gt;\n\n&lt;p&gt;I know that a better way would be to have a drive constantly connected with a wire or in a home network with a computer but that&amp;#39;s not really possible. My main goals for now are to at least try to backup more periodically than I do now but also keep it all compressed because the HDD space is, of course, limited.&lt;/p&gt;\n\n&lt;p&gt;An added benefit would be a nice GUI so that I don&amp;#39;t have to google the commands each time I need to do a backup but that&amp;#39;s not a top priority if the tool is otherwise great.&lt;/p&gt;\n\n&lt;p&gt;The problem is I don&amp;#39;t even know &lt;strong&gt;what to look for&lt;/strong&gt; in automated backup tools and I don&amp;#39;t know if there&amp;#39;s a tool that will fit the needs I described above. Where do I start?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I know this has been asked before but I think I have a specific request.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?auto=webp&amp;s=e92a7d73b6cc4a5dbc4d23aca8d451823a40f167", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b6409a2c87bcd4e5320c74919a44c115376c9436", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9955380c628587a83da7426ca8733120f0d43e2b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9560c6af215985bdf3470dfaf97766845be9272f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8963fcf065074edadb7a8991bb8e65764e94f169", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ce4d64d26dd89aa351c18ca9a3e34ac8079a3a54", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1DgWyyr-TTSzP_yiEUT7Q1lDJ_H1J5rs-bJaX98XNqk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7e8075e5db2c75401d742d89eefde625c07ccf22", "width": 1080, "height": 540}], "variants": {}, "id": "kgMdspa7BS7i2z1MUSOoKaElD4VV4a75W5TiQ5DqKEg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajrykz", "is_robot_indexable": true, "report_reasons": null, "author": "FypeWaqer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajrykz/opensource_automated_backup_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajrykz/opensource_automated_backup_tools/", "subreddit_subscribers": 730653, "created_utc": 1707168092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don\u2019t know if this is a stupid question. I was just setting up xigmanas on my new file server and wanted to encrypt a 20tb hdd. My old file server was a old windows machine where I encrypted the hdd using VeraCrypt. It took for 10tb almost 3 days back then. I assumed it would take xigmanas also some time to encrypt my 20tb drive but it only took seconds. How is that possible? What am I missing?", "author_fullname": "t2_zuupz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VeraCypt and Encryption on Xigmnas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajnh01", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707157297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t know if this is a stupid question. I was just setting up xigmanas on my new file server and wanted to encrypt a 20tb hdd. My old file server was a old windows machine where I encrypted the hdd using VeraCrypt. It took for 10tb almost 3 days back then. I assumed it would take xigmanas also some time to encrypt my 20tb drive but it only took seconds. How is that possible? What am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajnh01", "is_robot_indexable": true, "report_reasons": null, "author": "unknown_73", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajnh01/veracypt_and_encryption_on_xigmnas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajnh01/veracypt_and_encryption_on_xigmnas/", "subreddit_subscribers": 730653, "created_utc": 1707157297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I am required to store client documents for 7 years. I (ideally) average about two clients per day, and each generates 80-120 pages. My clients initial every page and sign at the end. After my clients leave, I spend 30-45 minutes scanning the documents, one at a time, on my old cannon. Finally, my clients pick up their documents a week later or I ship them with a courier service (nerve wracking).\n\nI want a solution that I can put the stack of papers in, and quickly (&lt;5 min) scan the files while my client sits in my office and just send the files home with the client.\n\nI tried a scansnap ix1600, but had to return it because the feeder tray only fits ~50 pages.\n\nWhat would you recommend?\n\nHow about a used FI-6670? Thinking of one solely because that one guy did 80k pages in 5 days. ", "author_fullname": "t2_6ohcl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestion for a scanner that can easily and quickly handle 80-120 duplex pages at a time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajmdlb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707155022.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707154753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am required to store client documents for 7 years. I (ideally) average about two clients per day, and each generates 80-120 pages. My clients initial every page and sign at the end. After my clients leave, I spend 30-45 minutes scanning the documents, one at a time, on my old cannon. Finally, my clients pick up their documents a week later or I ship them with a courier service (nerve wracking).&lt;/p&gt;\n\n&lt;p&gt;I want a solution that I can put the stack of papers in, and quickly (&amp;lt;5 min) scan the files while my client sits in my office and just send the files home with the client.&lt;/p&gt;\n\n&lt;p&gt;I tried a scansnap ix1600, but had to return it because the feeder tray only fits ~50 pages.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend?&lt;/p&gt;\n\n&lt;p&gt;How about a used FI-6670? Thinking of one solely because that one guy did 80k pages in 5 days. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajmdlb", "is_robot_indexable": true, "report_reasons": null, "author": "Dannyz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajmdlb/suggestion_for_a_scanner_that_can_easily_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajmdlb/suggestion_for_a_scanner_that_can_easily_and/", "subreddit_subscribers": 730653, "created_utc": 1707154753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nI've just managed to have running for the first time a Restic instance to backup important personal data from my UnRaid NAS to a minIO s3 on a debian machine at my parents house (albeit with a single hdd) both within my Tailscale network.\n\nIt appears to be working but it'd be great to have suggestions on how to improve and secure the docker compose setup, so I have a few questions for anyone that can help:\n\n\\- Should I be concerned that all passwords (restic and minIO repository) are clear text in my docker compose (portainer)/ Is there any better way to secure this?  \n\\- Target server has a single HDD (and no space to add more), should I be worried about backup integrity/ how to make it better?  \n\\- Is there something more secure/ performant than the minIOs3 instance? (it was really easy to setup)  \n\\- Any more suggestions on config more than appreciated\n\n    version: \"3.8\"\n    services:\n    backup:\n    image: mazzolino/restic\n    container_name: restic\n    hostname: unraid\n    restart: unless-stopped\n    environment:\n    RUN_ON_STARTUP: \"true\" \n     \n    BACKUP_CRON: \"0 */12 * * *\" \n     \n    RESTIC_REPOSITORY: s3:http://[IP]:9030/unRAID \n     \n    AWS_ACCESS_KEY_ID: user\n    AWS_SECRET_ACCESS_KEY: password\n    RESTIC_PASSWORD: password\n    RESTIC_BACKUP_SOURCES: /mnt/backup \n     \n    RESTIC_COMPRESSION: auto \n     \n    RESTIC_BACKUP_ARGS: &gt;-\n    --tag automatic \n     \n    --verbose\n    RESTIC_FORGET_ARGS: &gt;- \n     \n    --keep-daily 7\n    --keep-weekly 5\n    --keep-monthly 12\n    TZ: [TZ]\n    volumes:\n    - /tmp/restic/restore:/tmp-for-restore\n    - /mnt/user/data/backup:/mnt/backup/documents:ro \n     \n    security_opt:\n    - no-new-privileges:true\n    prune:\n    image: mazzolino/restic\n    container_name: restic-prune\n    hostname: unraid\n    restart: unless-stopped\n    environment:\n    RUN_ON_STARTUP: \"false\"\n    RESTIC_REPOSITORY: s3:http://[IP]:9030/restic\n    AWS_ACCESS_KEY_ID: user\n    AWS_SECRET_ACCESS_KEY: password\n    RESTIC_PASSWORD: password\n    PRUNE_CRON: \"0 0 4 * * *\"\n    TZ: [TZ]\n    security_opt:\n    - no-new-privileges:true\n    check:\n    image: mazzolino/restic\n    container_name: restic-check\n    hostname: unraid\n    restart: unless-stopped\n    environment:\n    RUN_ON_STARTUP: \"false\" \n     \n    RESTIC_REPOSITORY: s3:http://[IP]:9030/restic\n    AWS_ACCESS_KEY_ID: user\n    AWS_SECRET_ACCESS_KEY: password\n    RESTIC_PASSWORD: password\n    CHECK_CRON: \"0 0 5 * * SUN\" \n     \n    RESTIC_CHECK_ARGS: &gt;-\n    --read-data-subset=10%\n    TZ: [TZ]\n    security_opt:\n    - no-new-privileges:true\n\n&amp;#x200B;", "author_fullname": "t2_9b7opui4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Secure and improve Restic backup instance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajeadm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707132290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just managed to have running for the first time a Restic instance to backup important personal data from my UnRaid NAS to a minIO s3 on a debian machine at my parents house (albeit with a single hdd) both within my Tailscale network.&lt;/p&gt;\n\n&lt;p&gt;It appears to be working but it&amp;#39;d be great to have suggestions on how to improve and secure the docker compose setup, so I have a few questions for anyone that can help:&lt;/p&gt;\n\n&lt;p&gt;- Should I be concerned that all passwords (restic and minIO repository) are clear text in my docker compose (portainer)/ Is there any better way to secure this?&lt;br/&gt;\n- Target server has a single HDD (and no space to add more), should I be worried about backup integrity/ how to make it better?&lt;br/&gt;\n- Is there something more secure/ performant than the minIOs3 instance? (it was really easy to setup)&lt;br/&gt;\n- Any more suggestions on config more than appreciated&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;version: &amp;quot;3.8&amp;quot;\nservices:\nbackup:\nimage: mazzolino/restic\ncontainer_name: restic\nhostname: unraid\nrestart: unless-stopped\nenvironment:\nRUN_ON_STARTUP: &amp;quot;true&amp;quot; \n\nBACKUP_CRON: &amp;quot;0 */12 * * *&amp;quot; \n\nRESTIC_REPOSITORY: s3:http://[IP]:9030/unRAID \n\nAWS_ACCESS_KEY_ID: user\nAWS_SECRET_ACCESS_KEY: password\nRESTIC_PASSWORD: password\nRESTIC_BACKUP_SOURCES: /mnt/backup \n\nRESTIC_COMPRESSION: auto \n\nRESTIC_BACKUP_ARGS: &amp;gt;-\n--tag automatic \n\n--verbose\nRESTIC_FORGET_ARGS: &amp;gt;- \n\n--keep-daily 7\n--keep-weekly 5\n--keep-monthly 12\nTZ: [TZ]\nvolumes:\n- /tmp/restic/restore:/tmp-for-restore\n- /mnt/user/data/backup:/mnt/backup/documents:ro \n\nsecurity_opt:\n- no-new-privileges:true\nprune:\nimage: mazzolino/restic\ncontainer_name: restic-prune\nhostname: unraid\nrestart: unless-stopped\nenvironment:\nRUN_ON_STARTUP: &amp;quot;false&amp;quot;\nRESTIC_REPOSITORY: s3:http://[IP]:9030/restic\nAWS_ACCESS_KEY_ID: user\nAWS_SECRET_ACCESS_KEY: password\nRESTIC_PASSWORD: password\nPRUNE_CRON: &amp;quot;0 0 4 * * *&amp;quot;\nTZ: [TZ]\nsecurity_opt:\n- no-new-privileges:true\ncheck:\nimage: mazzolino/restic\ncontainer_name: restic-check\nhostname: unraid\nrestart: unless-stopped\nenvironment:\nRUN_ON_STARTUP: &amp;quot;false&amp;quot; \n\nRESTIC_REPOSITORY: s3:http://[IP]:9030/restic\nAWS_ACCESS_KEY_ID: user\nAWS_SECRET_ACCESS_KEY: password\nRESTIC_PASSWORD: password\nCHECK_CRON: &amp;quot;0 0 5 * * SUN&amp;quot; \n\nRESTIC_CHECK_ARGS: &amp;gt;-\n--read-data-subset=10%\nTZ: [TZ]\nsecurity_opt:\n- no-new-privileges:true\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajeadm", "is_robot_indexable": true, "report_reasons": null, "author": "Maximus_Air", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajeadm/secure_and_improve_restic_backup_instance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajeadm/secure_and_improve_restic_backup_instance/", "subreddit_subscribers": 730653, "created_utc": 1707132290.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My work involves loading the same \\~50 large CSV files (each of them are GZIPPED) from disk, into RAM, over and over. I want to buy a SSD with fast read speeds.\n\nBut I'm not sure whether I need fast Sequential Read or fast Random Read, or both? If I only need Sequential Read, I should get the Sabrent Rocket 4 Plus, it's cheaper (where I live, about 20% cheaper) and has the same Sequential Read speed as a Samsung Pro 990. But if I need high Random Read speed too, I should get Samsung Pro 990.\n\nMy motherboard is X570 Aorus Master. I have 5800X3D cpu and 7900XTX gpu and 32gb DDR4 RAM.\n\nThoughts?", "author_fullname": "t2_e0cvzudd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Sequential Read or Random Read more important for parsing large CSV files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajcqkt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707126616.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707125960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My work involves loading the same ~50 large CSV files (each of them are GZIPPED) from disk, into RAM, over and over. I want to buy a SSD with fast read speeds.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m not sure whether I need fast Sequential Read or fast Random Read, or both? If I only need Sequential Read, I should get the Sabrent Rocket 4 Plus, it&amp;#39;s cheaper (where I live, about 20% cheaper) and has the same Sequential Read speed as a Samsung Pro 990. But if I need high Random Read speed too, I should get Samsung Pro 990.&lt;/p&gt;\n\n&lt;p&gt;My motherboard is X570 Aorus Master. I have 5800X3D cpu and 7900XTX gpu and 32gb DDR4 RAM.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ajcqkt", "is_robot_indexable": true, "report_reasons": null, "author": "FunHoliday7437", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajcqkt/is_sequential_read_or_random_read_more_important/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajcqkt/is_sequential_read_or_random_read_more_important/", "subreddit_subscribers": 730653, "created_utc": 1707125960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " Is this still the way to go for long-term cold storage?", "author_fullname": "t2_dpmxx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommendations for an M-Disc/M-Ready internal desktop blu-ray drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak24lb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707196518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is this still the way to go for long-term cold storage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak24lb", "is_robot_indexable": true, "report_reasons": null, "author": "Web-Dude", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak24lb/any_recommendations_for_an_mdiscmready_internal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak24lb/any_recommendations_for_an_mdiscmready_internal/", "subreddit_subscribers": 730653, "created_utc": 1707196518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My current backup is on an older nuc computer with a usb das device plugged in. It works well and is pretty small and low power. \n\nI'm looking to get a second backup device similar as my first but i figured I'd look at those mini itx cases that have 4+ 3.5\" drive bays in them which look much nicer and perhaps only slightly bigger but it'll mean less cables hanging around.\n\nI've seen a few cases in eBay, Amazon and AliExpress and the prices aren't too bad, same for the power supply but i can't seem to find a cheap mini itx board to go with it.\n\nIn the past I've had a few boards with onboard sata and sold them on eBay for whatever market rate is but now mostly what i see seems to be scalpers(?) Selling their \"gaming\" machines that are way over specced and probably a bit power hungry.\n\nIs there any chance of getting something in the sub-100 (ideally around 50) that's a handful of generations old but has 8+gb ram and will idle at under 15 watts?\n\nI'm also considering a cheap nas device as well but i wanted to eventually move it to my parents house so I'd want to be able to run wireguard on it (or maybe just handling it from the router would be easier though)", "author_fullname": "t2_ly1a1ad1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do y'all get cheap hardware", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak1wqz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707195758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My current backup is on an older nuc computer with a usb das device plugged in. It works well and is pretty small and low power. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to get a second backup device similar as my first but i figured I&amp;#39;d look at those mini itx cases that have 4+ 3.5&amp;quot; drive bays in them which look much nicer and perhaps only slightly bigger but it&amp;#39;ll mean less cables hanging around.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a few cases in eBay, Amazon and AliExpress and the prices aren&amp;#39;t too bad, same for the power supply but i can&amp;#39;t seem to find a cheap mini itx board to go with it.&lt;/p&gt;\n\n&lt;p&gt;In the past I&amp;#39;ve had a few boards with onboard sata and sold them on eBay for whatever market rate is but now mostly what i see seems to be scalpers(?) Selling their &amp;quot;gaming&amp;quot; machines that are way over specced and probably a bit power hungry.&lt;/p&gt;\n\n&lt;p&gt;Is there any chance of getting something in the sub-100 (ideally around 50) that&amp;#39;s a handful of generations old but has 8+gb ram and will idle at under 15 watts?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also considering a cheap nas device as well but i wanted to eventually move it to my parents house so I&amp;#39;d want to be able to run wireguard on it (or maybe just handling it from the router would be easier though)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak1wqz", "is_robot_indexable": true, "report_reasons": null, "author": "GloriousHousehold", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak1wqz/where_do_yall_get_cheap_hardware/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak1wqz/where_do_yall_get_cheap_hardware/", "subreddit_subscribers": 730653, "created_utc": 1707195758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone! I have a question regarding a backup of my computer system. The title pretty much sums it up. \n\nSo I have a 256 GB NVME for my windows 10 OS, a 2 TB NVME for games, and a 4 TB HDD for storage of pictures and videos. \n\nI\u2019m looking to back up my whole computer in case of data loss or emergency, but I am unsure about how to go about it. \n\nI would like to make the backups accessible as well as having a bootable clone of my c drive that I can use if I ever need to boot from it. I also want to backup my other drives in case I lose any data.\n\nTo do this, I bought an 8 TB Seagate External Drive to hold my backups. However, I want to make sure that I am backing my data up properly. \n\nAny advice on how to go about this would be greatly appreciated!", "author_fullname": "t2_oyybmbjy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to backup multiple drives onto one external drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak192w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707193576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I have a question regarding a backup of my computer system. The title pretty much sums it up. &lt;/p&gt;\n\n&lt;p&gt;So I have a 256 GB NVME for my windows 10 OS, a 2 TB NVME for games, and a 4 TB HDD for storage of pictures and videos. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking to back up my whole computer in case of data loss or emergency, but I am unsure about how to go about it. &lt;/p&gt;\n\n&lt;p&gt;I would like to make the backups accessible as well as having a bootable clone of my c drive that I can use if I ever need to boot from it. I also want to backup my other drives in case I lose any data.&lt;/p&gt;\n\n&lt;p&gt;To do this, I bought an 8 TB Seagate External Drive to hold my backups. However, I want to make sure that I am backing my data up properly. &lt;/p&gt;\n\n&lt;p&gt;Any advice on how to go about this would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak192w", "is_robot_indexable": true, "report_reasons": null, "author": "TheLunarNguyen", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak192w/how_to_backup_multiple_drives_onto_one_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak192w/how_to_backup_multiple_drives_onto_one_external/", "subreddit_subscribers": 730653, "created_utc": 1707193576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm installing Ubuntu on a 2TB M.2 SSD, to perform ML tasks that involve parsing multiple large gzipped csv files between 200MB-10GB into RAM primarily (perhaps VRAM, too). I have 32GB RAM and 24GB VRAM and AMD 5800X3D 8-core CPU. I'm trying to optimize my partitions around this use-case. I'm thinking:\n\n* /boot 1GB ext4\n* /swap 16GB\n* / (root) 100GB ext4\n* /home 1883GB **XFS**\n\nIs this sensible? Especially the XFS choice and the choice to put 100GB into root? I heard XFS is better for handling large-ish files, and I heard I may need overhead for ML frameworks installation (hence 100GB into root), but I do not have high confidence in these two conclusions.", "author_fullname": "t2_e0cvzudd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ext4 or XFS for machine learning tasks on Ubuntu?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak0vjb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707192347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m installing Ubuntu on a 2TB M.2 SSD, to perform ML tasks that involve parsing multiple large gzipped csv files between 200MB-10GB into RAM primarily (perhaps VRAM, too). I have 32GB RAM and 24GB VRAM and AMD 5800X3D 8-core CPU. I&amp;#39;m trying to optimize my partitions around this use-case. I&amp;#39;m thinking:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;/boot 1GB ext4&lt;/li&gt;\n&lt;li&gt;/swap 16GB&lt;/li&gt;\n&lt;li&gt;/ (root) 100GB ext4&lt;/li&gt;\n&lt;li&gt;/home 1883GB &lt;strong&gt;XFS&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is this sensible? Especially the XFS choice and the choice to put 100GB into root? I heard XFS is better for handling large-ish files, and I heard I may need overhead for ML frameworks installation (hence 100GB into root), but I do not have high confidence in these two conclusions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ak0vjb", "is_robot_indexable": true, "report_reasons": null, "author": "FunHoliday7437", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ak0vjb/ext4_or_xfs_for_machine_learning_tasks_on_ubuntu/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ak0vjb/ext4_or_xfs_for_machine_learning_tasks_on_ubuntu/", "subreddit_subscribers": 730653, "created_utc": 1707192347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a 16TB drive, and I've narrowed it down to a $260 Seagate Exos X18 drive and a $360 WD Gold drive. The datasheets are almost identical, with the only real difference being the cache size (Seagate 256MB, WD 512MB). Is there any reason not go for the Exos drive?", "author_fullname": "t2_1fwm352n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are WD Gold drives worth the extra money over Seagate Exos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajz9qm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707187389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a 16TB drive, and I&amp;#39;ve narrowed it down to a $260 Seagate Exos X18 drive and a $360 WD Gold drive. The datasheets are almost identical, with the only real difference being the cache size (Seagate 256MB, WD 512MB). Is there any reason not go for the Exos drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajz9qm", "is_robot_indexable": true, "report_reasons": null, "author": "YoBoiGeo", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajz9qm/are_wd_gold_drives_worth_the_extra_money_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajz9qm/are_wd_gold_drives_worth_the_extra_money_over/", "subreddit_subscribers": 730653, "created_utc": 1707187389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Where do I find sas3flash for Linux(or efi, not picky by this point)? Broadcom is completely useless by this point and I can't find anywhere else to download it from.", "author_fullname": "t2_5v1j3d7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "sas3flash command not found", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajyxn2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707186395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where do I find sas3flash for Linux(or efi, not picky by this point)? Broadcom is completely useless by this point and I can&amp;#39;t find anywhere else to download it from.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ajyxn2", "is_robot_indexable": true, "report_reasons": null, "author": "steampunk333", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ajyxn2/sas3flash_command_not_found/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ajyxn2/sas3flash_command_not_found/", "subreddit_subscribers": 730653, "created_utc": 1707186395.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}