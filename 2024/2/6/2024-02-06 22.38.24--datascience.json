{"kind": "Listing", "data": {"after": null, "dist": 7, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The company I work for (large company serving millions of end-users), appear to have completely lost their minds over GenAI. It started quite well. They were interested, I was in a good position as being able to advise them. The CEO got to know me. The executives were asking my advice and we were coming up with some cool genuine use cases that had legs. However, now they are just trying to shoehorn gen AI wherever they can for the sake of the investors. They are not making rational decisions anymore. They aren't even asking me about it anymore. Some exec wakes up one day and has a crazy misguided idea about sticking gen AI somewhere and then asking junior (non DS) devs to build it without DS input. All the while, traditional ML is actually making the company money, projects are going well, but getting ignored. Does this sound familiar? Do the execs get over it and go back to traditional ML eventually, or do they go crazy and start sacking traditional data scientists in favour of hiring prompt engineers?", "author_fullname": "t2_8ttg11n0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone elses company executives losing their shit over GenAI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak6kb5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 311, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 311, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707214652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The company I work for (large company serving millions of end-users), appear to have completely lost their minds over GenAI. It started quite well. They were interested, I was in a good position as being able to advise them. The CEO got to know me. The executives were asking my advice and we were coming up with some cool genuine use cases that had legs. However, now they are just trying to shoehorn gen AI wherever they can for the sake of the investors. They are not making rational decisions anymore. They aren&amp;#39;t even asking me about it anymore. Some exec wakes up one day and has a crazy misguided idea about sticking gen AI somewhere and then asking junior (non DS) devs to build it without DS input. All the while, traditional ML is actually making the company money, projects are going well, but getting ignored. Does this sound familiar? Do the execs get over it and go back to traditional ML eventually, or do they go crazy and start sacking traditional data scientists in favour of hiring prompt engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ak6kb5", "is_robot_indexable": true, "report_reasons": null, "author": "Glass_Jellyfish6528", "discussion_type": null, "num_comments": 95, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ak6kb5/anyone_elses_company_executives_losing_their_shit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ak6kb5/anyone_elses_company_executives_losing_their_shit/", "subreddit_subscribers": 1312511, "created_utc": 1707214652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Read a job posting with a biotech firm that's looking for candidates with experience manipulating data with **trillions** of records.\n\nI can't fathom working with datasets that big. Depending on the number of variables, would think it'd be more convenient to draw a random sample?", "author_fullname": "t2_6cjiszgb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing datasets with trillions of records?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ak0mke", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707191539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Read a job posting with a biotech firm that&amp;#39;s looking for candidates with experience manipulating data with &lt;strong&gt;trillions&lt;/strong&gt; of records.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t fathom working with datasets that big. Depending on the number of variables, would think it&amp;#39;d be more convenient to draw a random sample?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ak0mke", "is_robot_indexable": true, "report_reasons": null, "author": "RobertWF_47", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ak0mke/analyzing_datasets_with_trillions_of_records/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ak0mke/analyzing_datasets_with_trillions_of_records/", "subreddit_subscribers": 1312511, "created_utc": 1707191539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I don't mean just for production, I mean for the entire algo development process, relying on .py files and PyCharm for everything. Does anyone do this? PyCharm has really powerful debugging features to let you examine variable contents. The biggest disadvantage for me might be having to execute segments of code at a time by setting a bunch of breakpoints. I use .value\\_counts() constantly as well, and it seems inconvenient to have to rerun my entire code to examine output changes from minor input changes.\n\nOr maybe I just have to adjust my workflow. Thoughts on using .py files + PyCharm (or IDE of choice) for everything as a DS?", "author_fullname": "t2_15xuhx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Avoiding Jupyter Notebooks entirely and doing everything in .py files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajw9s8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707178897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t mean just for production, I mean for the entire algo development process, relying on .py files and PyCharm for everything. Does anyone do this? PyCharm has really powerful debugging features to let you examine variable contents. The biggest disadvantage for me might be having to execute segments of code at a time by setting a bunch of breakpoints. I use .value_counts() constantly as well, and it seems inconvenient to have to rerun my entire code to examine output changes from minor input changes.&lt;/p&gt;\n\n&lt;p&gt;Or maybe I just have to adjust my workflow. Thoughts on using .py files + PyCharm (or IDE of choice) for everything as a DS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1ajw9s8", "is_robot_indexable": true, "report_reasons": null, "author": "question_23", "discussion_type": null, "num_comments": 131, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ajw9s8/avoiding_jupyter_notebooks_entirely_and_doing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ajw9s8/avoiding_jupyter_notebooks_entirely_and_doing/", "subreddit_subscribers": 1312511, "created_utc": 1707178897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Perhaps some imposter syndrome, or perhaps not...**basically--how complex ARE your models, realistically, for industry purposes?** \n\n\"Industry Purposes\" in the sense of answering business questions, such as:\n\n* Build me a model that can predict whether a free user is going to convert to a paid user. (Prediction)\n* Here's data from our experiment on Button A vs. Button B, which Button should we use? (Inference)\n* Based on our data from clicks on our website, should we market towards Demographic A? (Inference)\n\nI guess inherently I'm approaching this scenario from a prediction or inference perspective, and not from like a \"building for GenAI or Computer Vision\" perspective.\n\n------------------\n\nI know (and have experienced) that a lot of the work in Data Science is prepping and cleaning the data, but I always feel a little imposter syndrome when I spend the bulk of my time doing that, and then throw the data into a package that creates like a \"black-box\" Random Forest model that spits out the model we ultimately use or deploy.\n\nSure, along the way I spend time tweaking the model parameters (for a Random Forest example--tuning # of trees or depth) and checking my train/test splits, communicating with stakeholders, gaining more domain knowledge, etc., but \"creating the model\" once the data is cleaned to a reasonable degree is just loading things into a package and letting it do the rest. Feels a little too simple and cheap in some respects...especially for the salaries commanded as you go up the chain.\n\nAnd since a lot of money is at stake based on the model performance, it's always a little nerve-wracking to hinge yourself on some black-box model that performed well on your train/test data and \"hope\" it generalizes to unseen data and makes the company some money.\n\nDefinitely much less stressful when it's just projects for academics or hypotheticals where there's no real-world repercussions...there's always that voice in the back of my head saying \"surely, something as simple as this needs to be improved for the company to deem it worth investing so much time/money/etc. into, right?\"\n\n------------------\n\nAnyone else feel this way? Normal feeling--get used to it over time? Or is it that the more experience you gain, the bulk of \"what you are paid for\" isn't necessarily developing complex or novel algorithms for a business question, but rather how you communicate with stakeholders and deal with data-related issues, or similar stuff like that...?\n\n------------------\n\n**EDIT: Some good discussion about what types of models people use on a daily basis for work, but beyond saying \"I use Random Forest/XGBoost/etc.\", do you incorporate more complexity besides the \"simple\" pipeline of: Clean Data -&gt; Import into Package and do basic Train/Test + Hyperparameter Tuning + etc., -&gt; Output Model for Use?**", "author_fullname": "t2_6a2b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How complex ARE your models in Industry, really? (Imposter Syndrome)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akjw7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707255673.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707251775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Perhaps some imposter syndrome, or perhaps not...&lt;strong&gt;basically--how complex ARE your models, realistically, for industry purposes?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Industry Purposes&amp;quot; in the sense of answering business questions, such as:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Build me a model that can predict whether a free user is going to convert to a paid user. (Prediction)&lt;/li&gt;\n&lt;li&gt;Here&amp;#39;s data from our experiment on Button A vs. Button B, which Button should we use? (Inference)&lt;/li&gt;\n&lt;li&gt;Based on our data from clicks on our website, should we market towards Demographic A? (Inference)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I guess inherently I&amp;#39;m approaching this scenario from a prediction or inference perspective, and not from like a &amp;quot;building for GenAI or Computer Vision&amp;quot; perspective.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;I know (and have experienced) that a lot of the work in Data Science is prepping and cleaning the data, but I always feel a little imposter syndrome when I spend the bulk of my time doing that, and then throw the data into a package that creates like a &amp;quot;black-box&amp;quot; Random Forest model that spits out the model we ultimately use or deploy.&lt;/p&gt;\n\n&lt;p&gt;Sure, along the way I spend time tweaking the model parameters (for a Random Forest example--tuning # of trees or depth) and checking my train/test splits, communicating with stakeholders, gaining more domain knowledge, etc., but &amp;quot;creating the model&amp;quot; once the data is cleaned to a reasonable degree is just loading things into a package and letting it do the rest. Feels a little too simple and cheap in some respects...especially for the salaries commanded as you go up the chain.&lt;/p&gt;\n\n&lt;p&gt;And since a lot of money is at stake based on the model performance, it&amp;#39;s always a little nerve-wracking to hinge yourself on some black-box model that performed well on your train/test data and &amp;quot;hope&amp;quot; it generalizes to unseen data and makes the company some money.&lt;/p&gt;\n\n&lt;p&gt;Definitely much less stressful when it&amp;#39;s just projects for academics or hypotheticals where there&amp;#39;s no real-world repercussions...there&amp;#39;s always that voice in the back of my head saying &amp;quot;surely, something as simple as this needs to be improved for the company to deem it worth investing so much time/money/etc. into, right?&amp;quot;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Anyone else feel this way? Normal feeling--get used to it over time? Or is it that the more experience you gain, the bulk of &amp;quot;what you are paid for&amp;quot; isn&amp;#39;t necessarily developing complex or novel algorithms for a business question, but rather how you communicate with stakeholders and deal with data-related issues, or similar stuff like that...?&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT: Some good discussion about what types of models people use on a daily basis for work, but beyond saying &amp;quot;I use Random Forest/XGBoost/etc.&amp;quot;, do you incorporate more complexity besides the &amp;quot;simple&amp;quot; pipeline of: Clean Data -&amp;gt; Import into Package and do basic Train/Test + Hyperparameter Tuning + etc., -&amp;gt; Output Model for Use?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1akjw7t", "is_robot_indexable": true, "report_reasons": null, "author": "Joe10112", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1akjw7t/how_complex_are_your_models_in_industry_really/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1akjw7t/how_complex_are_your_models_in_industry_really/", "subreddit_subscribers": 1312511, "created_utc": 1707251775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "He's one my direct reports. Gives off a vibe of disrespect that I have a real hard time to tolerate. The problem is it's a \"feeling\" and I can't exactly pinpoint on any specific event or activities so I'm giving him the benefit of doubt. But, in the meantime, any tips about how to demand respect from him? \n\nFor context, he comes from econ Ms, with questionable stats/model skills and no coding skills but with very a high self esteem about his skill levels. For example, he ran an MLR to predict binary outcomes and was doing all sorts of data gymnastics to convert the linear outcomes into probabilities \ud83e\udd26\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f Hopefully that gives you a good idea about his skill level. Needless to say, hiring wasn't my direct decision.", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some tips to gain respect from an arrogant reportee.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akjpw0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707251358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;He&amp;#39;s one my direct reports. Gives off a vibe of disrespect that I have a real hard time to tolerate. The problem is it&amp;#39;s a &amp;quot;feeling&amp;quot; and I can&amp;#39;t exactly pinpoint on any specific event or activities so I&amp;#39;m giving him the benefit of doubt. But, in the meantime, any tips about how to demand respect from him? &lt;/p&gt;\n\n&lt;p&gt;For context, he comes from econ Ms, with questionable stats/model skills and no coding skills but with very a high self esteem about his skill levels. For example, he ran an MLR to predict binary outcomes and was doing all sorts of data gymnastics to convert the linear outcomes into probabilities \ud83e\udd26\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f Hopefully that gives you a good idea about his skill level. Needless to say, hiring wasn&amp;#39;t my direct decision.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1akjpw0", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1akjpw0/need_some_tips_to_gain_respect_from_an_arrogant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1akjpw0/need_some_tips_to_gain_respect_from_an_arrogant/", "subreddit_subscribers": 1312511, "created_utc": 1707251358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there a place where I can find gene regulatory networks that have been validated ? I would like to benchmark my causal discovery methods but I can't find a curated causal graphs to use as ground truth.", "author_fullname": "t2_87xxasa2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gene causal networks repository", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ajw3tb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707178440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a place where I can find gene regulatory networks that have been validated ? I would like to benchmark my causal discovery methods but I can&amp;#39;t find a curated causal graphs to use as ground truth.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ajw3tb", "is_robot_indexable": true, "report_reasons": null, "author": "Amazing_Alarm6130", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ajw3tb/gene_causal_networks_repository/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ajw3tb/gene_causal_networks_repository/", "subreddit_subscribers": 1312511, "created_utc": 1707178440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_v8n3a1nm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TA lib with Python and Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1akffr5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/MQyyATi3_Vs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"TA lib with Python and Pandas\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "TA lib with Python and Pandas", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/MQyyATi3_Vs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"TA lib with Python and Pandas\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/MQyyATi3_Vs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/MQyyATi3_Vs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"TA lib with Python and Pandas\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1akffr5", "height": 200}, "link_flair_text": "Tools", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BBp7UYoiAVonBiffrIrsijuVGYLmAwKm2CLwguGrrIg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707241025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/MQyyATi3_Vs?si=9a7X5oH3EGXvBLMu", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TI0auhdxXNi-AG9Y0X2CdCT6inxdBceh2tP9EBM3oSk.jpg?auto=webp&amp;s=41cad9a8a193c66bd9b66cb7daffb719cbc1ac9b", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/TI0auhdxXNi-AG9Y0X2CdCT6inxdBceh2tP9EBM3oSk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=958f4d0846408eb62624b9b07be5badb264cb001", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/TI0auhdxXNi-AG9Y0X2CdCT6inxdBceh2tP9EBM3oSk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e552a9ff19bed140fa0f807f6bf1b2f5e65ac4b4", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/TI0auhdxXNi-AG9Y0X2CdCT6inxdBceh2tP9EBM3oSk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7fd37a99024545c4635f417dc03df3bdec9c7347", "width": 320, "height": 240}], "variants": {}, "id": "bCm61iW8q75xXVFaW76AyASXFu1_-bUJGef1WnGfavc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1akffr5", "is_robot_indexable": true, "report_reasons": null, "author": "fancypigollo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1akffr5/ta_lib_with_python_and_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/MQyyATi3_Vs?si=9a7X5oH3EGXvBLMu", "subreddit_subscribers": 1312511, "created_utc": 1707241025.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "TA lib with Python and Pandas", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/MQyyATi3_Vs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"TA lib with Python and Pandas\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/MQyyATi3_Vs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}], "before": null}}