{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\n**TLDR:** Louis here from Quary - we have spent the past few months re-engineering DBT core (python) into rust to create a fast data transformation (SQL inference &amp; modelling) package in Rust.\n\nWith DBT Core (Data Build Tool) you would need to spin up a server to run Python to make the package work. Thanks to Rust WASM we are able to make the transformation engine portable so that it runs entirely in the browser.\n\nWe wanted to give back to this community so we have decided to Open Source the entire project under an MIT license to give back to this community.\n\nLooking forward to hearing your thoughts in the comments! (A GitHub star is always appreciated \ud83d\ude03)\n\nhttps://preview.redd.it/3kisasoefwjc1.jpg?width=3612&amp;format=pjpg&amp;auto=webp&amp;s=38666d5d348282797edbc19aa69d0df040fc3ed5", "author_fullname": "t2_dr38sa99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open source DBT core alternative written in Rust (30x faster)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3kisasoefwjc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/3kisasoefwjc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b268eb8ba9f4e906d5aff5f16f58945a88b06e0b"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/3kisasoefwjc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af417f90677c04df9ae254e038c926930b7de974"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/3kisasoefwjc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a7f7b68171bfd3c6c10a566df5c1775268f6d0f"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/3kisasoefwjc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=adc7e1478f6ee2a0e55cfebc81e89dd6e2801f3c"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/3kisasoefwjc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dd118e81cb6c6ce854522191cb0693b7babc4a26"}, {"y": 662, "x": 1080, "u": "https://preview.redd.it/3kisasoefwjc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=38628b6d703ed6b02580f66bb9b5819575da209b"}], "s": {"y": 2216, "x": 3612, "u": "https://preview.redd.it/3kisasoefwjc1.jpg?width=3612&amp;format=pjpg&amp;auto=webp&amp;s=38666d5d348282797edbc19aa69d0df040fc3ed5"}, "id": "3kisasoefwjc1"}}, "name": "t3_1aw7368", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VZi9tcyvi9b-tgRfYixpPxqpV_kseg8ktYRf428RVvo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708503956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; Louis here from Quary - we have spent the past few months re-engineering DBT core (python) into rust to create a fast data transformation (SQL inference &amp;amp; modelling) package in Rust.&lt;/p&gt;\n\n&lt;p&gt;With DBT Core (Data Build Tool) you would need to spin up a server to run Python to make the package work. Thanks to Rust WASM we are able to make the transformation engine portable so that it runs entirely in the browser.&lt;/p&gt;\n\n&lt;p&gt;We wanted to give back to this community so we have decided to Open Source the entire project under an MIT license to give back to this community.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to hearing your thoughts in the comments! (A GitHub star is always appreciated \ud83d\ude03)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3kisasoefwjc1.jpg?width=3612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=38666d5d348282797edbc19aa69d0df040fc3ed5\"&gt;https://preview.redd.it/3kisasoefwjc1.jpg?width=3612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=38666d5d348282797edbc19aa69d0df040fc3ed5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1aw7368", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Call6280", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aw7368/open_source_dbt_core_alternative_written_in_rust/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aw7368/open_source_dbt_core_alternative_written_in_rust/", "subreddit_subscribers": 162549, "created_utc": 1708503956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw a post earlier about Data Engineering roles having way too much applicant and most of the people answered \"only a few of those applicant are good\". I am a Java/Scala developer at the moment and I want to transition to full time data engineer roles and I want to know how can i seperate myself from the group and be regarded as one of the good ones. What should be in my portfolio etc. ? ", "author_fullname": "t2_13mcsa6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What divides good from average?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aw4uaq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708495611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw a post earlier about Data Engineering roles having way too much applicant and most of the people answered &amp;quot;only a few of those applicant are good&amp;quot;. I am a Java/Scala developer at the moment and I want to transition to full time data engineer roles and I want to know how can i seperate myself from the group and be regarded as one of the good ones. What should be in my portfolio etc. ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aw4uaq", "is_robot_indexable": true, "report_reasons": null, "author": "Chediras", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aw4uaq/what_divides_good_from_average/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aw4uaq/what_divides_good_from_average/", "subreddit_subscribers": 162549, "created_utc": 1708495611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, i just started my master's project and currently working with .parquet files that are \\~20GB each but i do not have much of an idea on how to work with those. I need to merge multiple of these files (each carrying different types of information) with a key that is not unique (so in each file the key that i am using appears in multiple different rows). When i try to do that with python-pandas, things quickly get out of hand with the memory and the system crashes. What would be the best way to achieve  the equivalent of 'inner' or 'left' merge of these .parquet files? Any help will be greatly appreciated :)", "author_fullname": "t2_a2ypvree", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Merging large .parquet files without a unique key efficiently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avo2kw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708460079.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708451836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, i just started my master&amp;#39;s project and currently working with .parquet files that are ~20GB each but i do not have much of an idea on how to work with those. I need to merge multiple of these files (each carrying different types of information) with a key that is not unique (so in each file the key that i am using appears in multiple different rows). When i try to do that with python-pandas, things quickly get out of hand with the memory and the system crashes. What would be the best way to achieve  the equivalent of &amp;#39;inner&amp;#39; or &amp;#39;left&amp;#39; merge of these .parquet files? Any help will be greatly appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1avo2kw", "is_robot_indexable": true, "report_reasons": null, "author": "Martian_Onion", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avo2kw/merging_large_parquet_files_without_a_unique_key/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avo2kw/merging_large_parquet_files_without_a_unique_key/", "subreddit_subscribers": 162549, "created_utc": 1708451836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently working as a DE for a big insurance company in EU. My manager sees me (medior) fit for a more senior role within the company to coach and bring juniors/mediors to their next level (technical and soft skills). This is new for me, so I would appreciate some tips from DE leads and seniors.\n\n1. What are your tips and best practices to coach and bring juniors/mediors to their next level (technical/soft skills)?\n\n2. And, what should I be carefull with?\n\nThis would help me out a lot to get started with my next steps becoming a senior ;)\n", "author_fullname": "t2_344js9zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dear seniors, how do you coach juniors/mediors to their next level?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avu2vf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708466035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working as a DE for a big insurance company in EU. My manager sees me (medior) fit for a more senior role within the company to coach and bring juniors/mediors to their next level (technical and soft skills). This is new for me, so I would appreciate some tips from DE leads and seniors.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What are your tips and best practices to coach and bring juniors/mediors to their next level (technical/soft skills)?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;And, what should I be carefull with?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This would help me out a lot to get started with my next steps becoming a senior ;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1avu2vf", "is_robot_indexable": true, "report_reasons": null, "author": "-SCYLLA-", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avu2vf/dear_seniors_how_do_you_coach_juniorsmediors_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avu2vf/dear_seniors_how_do_you_coach_juniorsmediors_to/", "subreddit_subscribers": 162549, "created_utc": 1708466035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a small website to help people brand new to Spark get started. The goal is to teach all of the basics in an afternoon, along with some opinionated style suggestions on how to write Spark code. However, before someone can get started though, they need somewhere to run their Spark code. \n\nI'm wondering what people found most helpful as they were getting started. Personally, I tend to prefer working locally with Docker, but I can see that being a small hurdle if folks aren't already familiar with running Docker (even though docker-compose simplifies this a lot IMO).\n\nWhat helped you with writing and testing out Spark when you were starting out?", "author_fullname": "t2_uyd9mc1b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you find it easier to learn Spark using a cloud notebook environment or locally with Docker?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avoont", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708453239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a small website to help people brand new to Spark get started. The goal is to teach all of the basics in an afternoon, along with some opinionated style suggestions on how to write Spark code. However, before someone can get started though, they need somewhere to run their Spark code. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what people found most helpful as they were getting started. Personally, I tend to prefer working locally with Docker, but I can see that being a small hurdle if folks aren&amp;#39;t already familiar with running Docker (even though docker-compose simplifies this a lot IMO).&lt;/p&gt;\n\n&lt;p&gt;What helped you with writing and testing out Spark when you were starting out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1avoont", "is_robot_indexable": true, "report_reasons": null, "author": "zchtsk", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avoont/do_you_find_it_easier_to_learn_spark_using_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avoont/do_you_find_it_easier_to_learn_spark_using_a/", "subreddit_subscribers": 162549, "created_utc": 1708453239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm about to embark on the most boring project of my life: updating product documentation \ud83e\udd23  \n\n\nAnd I need some inspiration before I get started.  \n\n\nCurious - of all the data products that you've used, which one has the best documentation?\n\nAspects of great documentation might include:  \n\\- Navigable  \n\\- Clear, concise (you're question gets answered quickly. Learning something new on the platform is straightforward)   \n\\- Companion tutorials  \n\n\n... Your input could save my sanity!", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Boring topic - Documentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avrbd5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708459541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m about to embark on the most boring project of my life: updating product documentation \ud83e\udd23  &lt;/p&gt;\n\n&lt;p&gt;And I need some inspiration before I get started.  &lt;/p&gt;\n\n&lt;p&gt;Curious - of all the data products that you&amp;#39;ve used, which one has the best documentation?&lt;/p&gt;\n\n&lt;p&gt;Aspects of great documentation might include:&lt;br/&gt;\n- Navigable&lt;br/&gt;\n- Clear, concise (you&amp;#39;re question gets answered quickly. Learning something new on the platform is straightforward)&lt;br/&gt;\n- Companion tutorials  &lt;/p&gt;\n\n&lt;p&gt;... Your input could save my sanity!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1avrbd5", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avrbd5/boring_topic_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avrbd5/boring_topic_documentation/", "subreddit_subscribers": 162549, "created_utc": 1708459541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I had started a blog series to guide people on the path I felt they should follow, to transition into Azure Data Engineer role as a way back of doing good to the community and help people in making their careers and providing for their family. The blog where I mentioned this received tremendous response which really motivated me to go for it.\n\nHowever that is where things changed. The first blog titled, structured way to get into DE, though received very good response on upvotes and shares, was filled with negative comments. Some questioned why only Azure, some questioned why I had given timelines, some questioned why am I focusing on only X number of things, etc etc. Very very few people had something positive to say. Still I ignored it as helping community was more important but the next two blogs, SQL and ADF had a drastic decrease in engagement. Almost 80% engagement was gone.\n\nThis brings me to the question, are the blogs still needed by the community, are they helping you in any way or it's something unnecessary and should be stopped?\n\nNote: If this ends up on the positive side, I will be needing at least 50 upvotes or shares (as karma farming comments will come so I am fine with just shares too) for the already published blogs (SQL and ADF) and the ones to follow from now. This way it can be ensured that people are engaging with the content and I am not spending time creating something nobody is reading :)\n\n[View Poll](https://www.reddit.com/poll/1avnq5y)", "author_fullname": "t2_f86nbjeq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The End?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avnq5y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708455800.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708451004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had started a blog series to guide people on the path I felt they should follow, to transition into Azure Data Engineer role as a way back of doing good to the community and help people in making their careers and providing for their family. The blog where I mentioned this received tremendous response which really motivated me to go for it.&lt;/p&gt;\n\n&lt;p&gt;However that is where things changed. The first blog titled, structured way to get into DE, though received very good response on upvotes and shares, was filled with negative comments. Some questioned why only Azure, some questioned why I had given timelines, some questioned why am I focusing on only X number of things, etc etc. Very very few people had something positive to say. Still I ignored it as helping community was more important but the next two blogs, SQL and ADF had a drastic decrease in engagement. Almost 80% engagement was gone.&lt;/p&gt;\n\n&lt;p&gt;This brings me to the question, are the blogs still needed by the community, are they helping you in any way or it&amp;#39;s something unnecessary and should be stopped?&lt;/p&gt;\n\n&lt;p&gt;Note: If this ends up on the positive side, I will be needing at least 50 upvotes or shares (as karma farming comments will come so I am fine with just shares too) for the already published blogs (SQL and ADF) and the ones to follow from now. This way it can be ensured that people are engaging with the content and I am not spending time creating something nobody is reading :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1avnq5y\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1avnq5y", "is_robot_indexable": true, "report_reasons": null, "author": "Vikinghehe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1708537404984, "options": [{"text": "Continue with the blogs.", "id": "27157742"}, {"text": "Stop the blogs.", "id": "27157743"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 37, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avnq5y/the_end/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/1avnq5y/the_end/", "subreddit_subscribers": 162549, "created_utc": 1708451004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\nI am looking for practical walkthrough on how, step-by-step, one does normalization and implements a star schema data warehouse using Python or SQL. For such cases, people mostly throwing books and theory at you, Ive read those but looking for real implementation. In the past I was on fairly small project, where I would get everything in one table (which later stays as fact), create synthetic keys there, and then strip down distinct values along with keys to dim table with qualitative attributes as a view but I think thats not how every other, bigger project goes so I wonder. Is there any video/tutorial like that, or my approach seem correct for most of projects", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dimensional modelling implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aw9q6b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708515205.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708514508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello\nI am looking for practical walkthrough on how, step-by-step, one does normalization and implements a star schema data warehouse using Python or SQL. For such cases, people mostly throwing books and theory at you, Ive read those but looking for real implementation. In the past I was on fairly small project, where I would get everything in one table (which later stays as fact), create synthetic keys there, and then strip down distinct values along with keys to dim table with qualitative attributes as a view but I think thats not how every other, bigger project goes so I wonder. Is there any video/tutorial like that, or my approach seem correct for most of projects&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aw9q6b", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aw9q6b/dimensional_modelling_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aw9q6b/dimensional_modelling_implementation/", "subreddit_subscribers": 162549, "created_utc": 1708514508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a bit stuck and need some input from my fellow reddit engineers. :D\n\nWe are redesigning our (central) data platform and I'm trying to identify database candidates that we could use to serve req/rep-style workloads related to personalization and \"data apps\". I looked at the obvious candidates - Firebolt, Druid, MongoDB, Postgres - but neither convinced me as the \"obviously right choice\". Are there others or am I missing something?\n\nThe characteristics that I need are:\n\n* **Throughput-optimized ingest**: We currently produce around 12TB/day of clickstream data and a couple GB/day of transaction and marketing data. I can filter this down in our stream layer (Kafka+Flink) but I still expect &gt;10M updates/inserts a day if not more.\n* **low-latency point queries**: Queries will ask for data on a specific userID in order to personalize user experience, trigger custom offers, etc. This is user-facing so it should have low latency to not affect UX negatively. Currently there is no latency SLA, but lower is certainly better.\n* **rollup/aggregation**: We expect queries to ask for aggregates, e.g., number of orders for this userID over the last 30 days, number of product/page views in the current session, etc.\n\nFor context: *Our current setup is segment based. We have a batch pipeline that spins at regular intervals, computes statistics for each segment using a warehouse (redshift) and then sends the updates to an OLTP database (postgres) for serving. We would like to change the grain from segment-level to user-level and are now checking what implications this would have for our platform/infra.*\n\n&amp;#x200B;", "author_fullname": "t2_frdb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing a database for personalization and \"data apps\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aw762n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708504284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a bit stuck and need some input from my fellow reddit engineers. :D&lt;/p&gt;\n\n&lt;p&gt;We are redesigning our (central) data platform and I&amp;#39;m trying to identify database candidates that we could use to serve req/rep-style workloads related to personalization and &amp;quot;data apps&amp;quot;. I looked at the obvious candidates - Firebolt, Druid, MongoDB, Postgres - but neither convinced me as the &amp;quot;obviously right choice&amp;quot;. Are there others or am I missing something?&lt;/p&gt;\n\n&lt;p&gt;The characteristics that I need are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Throughput-optimized ingest&lt;/strong&gt;: We currently produce around 12TB/day of clickstream data and a couple GB/day of transaction and marketing data. I can filter this down in our stream layer (Kafka+Flink) but I still expect &amp;gt;10M updates/inserts a day if not more.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;low-latency point queries&lt;/strong&gt;: Queries will ask for data on a specific userID in order to personalize user experience, trigger custom offers, etc. This is user-facing so it should have low latency to not affect UX negatively. Currently there is no latency SLA, but lower is certainly better.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;rollup/aggregation&lt;/strong&gt;: We expect queries to ask for aggregates, e.g., number of orders for this userID over the last 30 days, number of product/page views in the current session, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For context: &lt;em&gt;Our current setup is segment based. We have a batch pipeline that spins at regular intervals, computes statistics for each segment using a warehouse (redshift) and then sends the updates to an OLTP database (postgres) for serving. We would like to change the grain from segment-level to user-level and are now checking what implications this would have for our platform/infra.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aw762n", "is_robot_indexable": true, "report_reasons": null, "author": "FirefoxMetzger", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aw762n/choosing_a_database_for_personalization_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aw762n/choosing_a_database_for_personalization_and_data/", "subreddit_subscribers": 162549, "created_utc": 1708504284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: \nI have a project coming up and I\u2019m being considered to play the  Data Architect for migration work and design. \n\nThe only issue is the tech stack is terrible for DE work \n- Powerapps (Dataverse, power automate etc) \n- Dynamics ( not sure this is still a thing) \n- Legacy Third party systems upstream sources  (Oracle , Java). No api confirmed.  No direct access. May have to write .net integrations \n\nA lot of this work seems to be glorified ETL. But not in a trivial sense. Tons of tables and likely a lot inconsistencies/clean up work. \n\nI maybe will get an Azure SQL Database, Data Factory and Logic Apps. Also expected to write integrations in .net to integrate the power apps ecosystem. Management is bought into low code and wants to avoid these tools, custom code etc. \n\nWhile I\u2019m excited by the title bump the effort seems doomed to fail just off the tech stack being a mess and the \u201clow code\u201d nonsense. The people who put this together are mostly concerned about the frontend and security. I didn\u2019t get to choose but I\u2019m thinking of pushing back and advocating for a proper azure architecture or at least fabric. Also suggesting Python. If I can\u2019t get the tooling I need to succeed this could be a real slog. \n\nMy question is \u2014 should I just take it in the chin and get the experience ? Has anyone done something similar (power through dumpster fire systems ) . There are zero online resources on this except from SharePoint devs and my prior work with power apps lets me know it\u2019s a clunky mess. \n\n", "author_fullname": "t2_ema0429e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take this Data Architect Role ? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aw6nu9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708502266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: \nI have a project coming up and I\u2019m being considered to play the  Data Architect for migration work and design. &lt;/p&gt;\n\n&lt;p&gt;The only issue is the tech stack is terrible for DE work \n- Powerapps (Dataverse, power automate etc) \n- Dynamics ( not sure this is still a thing) \n- Legacy Third party systems upstream sources  (Oracle , Java). No api confirmed.  No direct access. May have to write .net integrations &lt;/p&gt;\n\n&lt;p&gt;A lot of this work seems to be glorified ETL. But not in a trivial sense. Tons of tables and likely a lot inconsistencies/clean up work. &lt;/p&gt;\n\n&lt;p&gt;I maybe will get an Azure SQL Database, Data Factory and Logic Apps. Also expected to write integrations in .net to integrate the power apps ecosystem. Management is bought into low code and wants to avoid these tools, custom code etc. &lt;/p&gt;\n\n&lt;p&gt;While I\u2019m excited by the title bump the effort seems doomed to fail just off the tech stack being a mess and the \u201clow code\u201d nonsense. The people who put this together are mostly concerned about the frontend and security. I didn\u2019t get to choose but I\u2019m thinking of pushing back and advocating for a proper azure architecture or at least fabric. Also suggesting Python. If I can\u2019t get the tooling I need to succeed this could be a real slog. &lt;/p&gt;\n\n&lt;p&gt;My question is \u2014 should I just take it in the chin and get the experience ? Has anyone done something similar (power through dumpster fire systems ) . There are zero online resources on this except from SharePoint devs and my prior work with power apps lets me know it\u2019s a clunky mess. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aw6nu9", "is_robot_indexable": true, "report_reasons": null, "author": "IntentionThis441", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1aw6nu9/should_i_take_this_data_architect_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aw6nu9/should_i_take_this_data_architect_role/", "subreddit_subscribers": 162549, "created_utc": 1708502266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "in the last days I saw a sessionization tool for ad tech events that was a domain specific language (not SQL) without any weird joins.\n\n&amp;#x200B;\n\nsadly now when I need it I cannot find it anymore. Does anyone know what it is and cand share a link? It was a specific database with its own query engine to simplify sessionization event queries ", "author_fullname": "t2_8dvvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "simplified sessionization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avrl12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "#46d160", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708460186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;in the last days I saw a sessionization tool for ad tech events that was a domain specific language (not SQL) without any weird joins.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;sadly now when I need it I cannot find it anymore. Does anyone know what it is and cand share a link? It was a specific database with its own query engine to simplify sessionization event queries &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1avrl12", "is_robot_indexable": true, "report_reasons": null, "author": "geoheil", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/1avrl12/simplified_sessionization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avrl12/simplified_sessionization/", "subreddit_subscribers": 162549, "created_utc": 1708460186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to develop an in house data lineage application. I am able to get the data about relationships between tables but struggling with visualization of data. So far, I have tried using pyvis and d3 hierarchy trees. The problem I\u2019m facing in pyvis is flexibility to add on click node functions and problem with trees is that I cannot deal with multiple parent nodes(Since it is for hierarchical data). Has anybody worked on a similar project? If yes, then please help \n", "author_fullname": "t2_eb80kwgd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lineage Solution: Snowflake, Django, D3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awa1zz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708515711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to develop an in house data lineage application. I am able to get the data about relationships between tables but struggling with visualization of data. So far, I have tried using pyvis and d3 hierarchy trees. The problem I\u2019m facing in pyvis is flexibility to add on click node functions and problem with trees is that I cannot deal with multiple parent nodes(Since it is for hierarchical data). Has anybody worked on a similar project? If yes, then please help &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1awa1zz", "is_robot_indexable": true, "report_reasons": null, "author": "No-Caregiver-1204", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awa1zz/data_lineage_solution_snowflake_django_d3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awa1zz/data_lineage_solution_snowflake_django_d3/", "subreddit_subscribers": 162549, "created_utc": 1708515711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI'm a software developer diving in a new project in work for analytics in Azure and I need suggestions.  \nI have experience with airflow,sql, python and so on.  \nWe are going to create analytics solution for our customers.\n\nwe have raw data layer as parquet in azure blob storage. we use synapse to extract the data.  \n\n\nWe need to transform the data for other layers (silver,gold) and I find azure stack disappointing.  \n\n\n* Synapse and ADF are mostly no code solutions and I'm looking for something or combination that I can create scheduling and transform in code.  \n\n* for scheduling - synapse scheduling is lacking and airflow managed is very limited. ADF also seems no code.\n* databricks seems very pricey and more than we need.\n\n&amp;#x200B;\n\nfor the transformation - I know we need pyspark as we have a lot of data. this is also a code solution that satisfy me.\n\n&amp;#x200B;\n\nI see a PR with json file instead of code and I know it will slow development and won't be maintainable.  \n\n\nanyone has recommendation for stack that involve code ? coming from more software oriented I believe in more coding solutions as I worked with Apache NiFi and it was not maintainable.  \n\n\nThanks  \n", "author_fullname": "t2_atpck6ua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure stack for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aw80uf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708507794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a software developer diving in a new project in work for analytics in Azure and I need suggestions.&lt;br/&gt;\nI have experience with airflow,sql, python and so on.&lt;br/&gt;\nWe are going to create analytics solution for our customers.&lt;/p&gt;\n\n&lt;p&gt;we have raw data layer as parquet in azure blob storage. we use synapse to extract the data.  &lt;/p&gt;\n\n&lt;p&gt;We need to transform the data for other layers (silver,gold) and I find azure stack disappointing.  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Synapse and ADF are mostly no code solutions and I&amp;#39;m looking for something or combination that I can create scheduling and transform in code.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;for scheduling - synapse scheduling is lacking and airflow managed is very limited. ADF also seems no code.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;databricks seems very pricey and more than we need.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;for the transformation - I know we need pyspark as we have a lot of data. this is also a code solution that satisfy me.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I see a PR with json file instead of code and I know it will slow development and won&amp;#39;t be maintainable.  &lt;/p&gt;\n\n&lt;p&gt;anyone has recommendation for stack that involve code ? coming from more software oriented I believe in more coding solutions as I worked with Apache NiFi and it was not maintainable.  &lt;/p&gt;\n\n&lt;p&gt;Thanks  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aw80uf", "is_robot_indexable": true, "report_reasons": null, "author": "pythondeveloper77", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aw80uf/azure_stack_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aw80uf/azure_stack_for_de/", "subreddit_subscribers": 162549, "created_utc": 1708507794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ez8d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Review: Deciphering Data Architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avne6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1708450239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mullins.pro", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://mullins.pro/posts/deciphering_data_architectures/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1avne6e", "is_robot_indexable": true, "report_reasons": null, "author": "Bazencourt", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avne6e/review_deciphering_data_architectures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mullins.pro/posts/deciphering_data_architectures/", "subreddit_subscribers": 162549, "created_utc": 1708450239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So yeah, if you do use tests, model &amp; column descriptions, how do you handle duplicates? Like if my \"customer id\" is referenced in 3 models, do you write the same definition, or even a slightly different one in each of the referenced models? ", "author_fullname": "t2_1bx2p34m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Users -&gt; Do you write column descriptions for EVERYTHING? I started to do it, and realized how many duplicates there would be as we follow the source -&gt; staging -&gt; int -&gt; mart which duplicates columns in each layer.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1awfnk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708531335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So yeah, if you do use tests, model &amp;amp; column descriptions, how do you handle duplicates? Like if my &amp;quot;customer id&amp;quot; is referenced in 3 models, do you write the same definition, or even a slightly different one in each of the referenced models? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1awfnk5", "is_robot_indexable": true, "report_reasons": null, "author": "TheGrapez", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awfnk5/dbt_users_do_you_write_column_descriptions_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awfnk5/dbt_users_do_you_write_column_descriptions_for/", "subreddit_subscribers": 162549, "created_utc": 1708531335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I'm trying to weigh the benefits of various tools to figure out what the best one would be for our use case.\n\nOur team is regularly tasked with setting up jobs that move data from 50-60 separate PostgreSQL databases to a single destination PostgreSQL database. Problem is, no one on the team is a trained data engineer. The current way we move data from Source A to Destination B is by writing Airflow jobs but the process to create regularly recurring transfers tends to be prohibitively time intensive, and it seems like there's a better way than writing new airflow scripts every time we need to set up a new job.\n\nI'm looking to push for the adoption of a tool that is specifically meant for this purpose (data modeling and recurring transfers). So far I've seen people recommend DBT and Fivetran, but I don't want to overengineer it, considering our use case is fairly limited in scope. What would make the most sense for us to pursue?", "author_fullname": "t2_104vvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What ETL/ELT tool to use for this use-case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1awegrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708528490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I&amp;#39;m trying to weigh the benefits of various tools to figure out what the best one would be for our use case.&lt;/p&gt;\n\n&lt;p&gt;Our team is regularly tasked with setting up jobs that move data from 50-60 separate PostgreSQL databases to a single destination PostgreSQL database. Problem is, no one on the team is a trained data engineer. The current way we move data from Source A to Destination B is by writing Airflow jobs but the process to create regularly recurring transfers tends to be prohibitively time intensive, and it seems like there&amp;#39;s a better way than writing new airflow scripts every time we need to set up a new job.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to push for the adoption of a tool that is specifically meant for this purpose (data modeling and recurring transfers). So far I&amp;#39;ve seen people recommend DBT and Fivetran, but I don&amp;#39;t want to overengineer it, considering our use case is fairly limited in scope. What would make the most sense for us to pursue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1awegrq", "is_robot_indexable": true, "report_reasons": null, "author": "LonghornMorgs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awegrq/what_etlelt_tool_to_use_for_this_usecase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awegrq/what_etlelt_tool_to_use_for_this_usecase/", "subreddit_subscribers": 162549, "created_utc": 1708528490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use bitbucket for our CI/CD deployments.   \nHave tried airbyte via UI and would like to check if anyone has tried CI/CD deployment? Is it possible wit bitbucket CI/CD pipeline?", "author_fullname": "t2_eozceps7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte CI/CD deployments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1awebe6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708528131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use bitbucket for our CI/CD deployments.&lt;br/&gt;\nHave tried airbyte via UI and would like to check if anyone has tried CI/CD deployment? Is it possible wit bitbucket CI/CD pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1awebe6", "is_robot_indexable": true, "report_reasons": null, "author": "Liily_07", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awebe6/airbyte_cicd_deployments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awebe6/airbyte_cicd_deployments/", "subreddit_subscribers": 162549, "created_utc": 1708528131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\nI plan to take one of the above AWS certifications but I am confused about which one to take. I have worked as an ETL Developer for almost 3 years and now want to switch to DE.   \nPlease help me choose the right AWS certification from above, which will benefit me in the long term.", "author_fullname": "t2_skmlxs64", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is more appropriate for DE? AWS Data Engineer Associate or AWS Solutions Architect?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1awe5pd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708527747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I plan to take one of the above AWS certifications but I am confused about which one to take. I have worked as an ETL Developer for almost 3 years and now want to switch to DE.&lt;br/&gt;\nPlease help me choose the right AWS certification from above, which will benefit me in the long term.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1awe5pd", "is_robot_indexable": true, "report_reasons": null, "author": "Over_Student_2522", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awe5pd/which_is_more_appropriate_for_de_aws_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awe5pd/which_is_more_appropriate_for_de_aws_data/", "subreddit_subscribers": 162549, "created_utc": 1708527747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have loaded 5 million documents having 2 text fields to an open search index.\n\nI want to use open search sql to filter about 1 million distinct values of a field.\n\nIs open search a good tool for such bulk searches or should i consider a cache instead?", "author_fullname": "t2_kfvc08j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opensearch question ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awaq1v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708518041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have loaded 5 million documents having 2 text fields to an open search index.&lt;/p&gt;\n\n&lt;p&gt;I want to use open search sql to filter about 1 million distinct values of a field.&lt;/p&gt;\n\n&lt;p&gt;Is open search a good tool for such bulk searches or should i consider a cache instead?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1awaq1v", "is_robot_indexable": true, "report_reasons": null, "author": "RepulsiveCry8412", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awaq1v/opensearch_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awaq1v/opensearch_question/", "subreddit_subscribers": 162549, "created_utc": 1708518041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For data lake including rbacs for project folder, synapse, data factory, power bi. In past i've used yaml but this time they want in biceps. Does biceps will support or any limitation/complexity is there? What about synapse analytics iac deployment in bicep with roles, user creation etc and can we use sql script for schemas, objects creation? Advise synapse data artifacts deployment best approach/", "author_fullname": "t2_gw1qtave", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data analytics iac deployment through Azure bicep ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awa35p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708515841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For data lake including rbacs for project folder, synapse, data factory, power bi. In past i&amp;#39;ve used yaml but this time they want in biceps. Does biceps will support or any limitation/complexity is there? What about synapse analytics iac deployment in bicep with roles, user creation etc and can we use sql script for schemas, objects creation? Advise synapse data artifacts deployment best approach/&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1awa35p", "is_robot_indexable": true, "report_reasons": null, "author": "efor007", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awa35p/data_analytics_iac_deployment_through_azure_bicep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awa35p/data_analytics_iac_deployment_through_azure_bicep/", "subreddit_subscribers": 162549, "created_utc": 1708515841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm building up tables and shema in my data warehouse (let's say Redshift). And this build-up process is in very early stage right now.\n\nand no matter how long I give a careful thought on how to set the schema right, at some point I have to change schema (add or subtract columns) .\n\nIt's like this:\n\n\\--------------------------------------------------------------------------------------\n\n|date              | base\\_trade\\_volume | quote\\_trade\\_volume |\n\n| 2023-01-02 | 200,000                       | 400,000,000               |\n\n| 2023-01-03 | 300,000                       | 450,000,000               |\n\n|    ....               |            ....                     |        ...                           |\n\n\\--------------------------------------------------------------------------------------\n\nThis is a table called 'user\\_trade\\_statistics'. and is the very first version of it.\n\n&amp;#x200B;\n\nand all of sudden, there's a need for 'trade\\_count' column. so I have to reprocess whole data to add new column to existing table.\n\n\\-------------------------------------------------------------------------------------------------------------\n\n|date              | base\\_trade\\_volume | quote\\_trade\\_volume |. trade\\_count\n\n| 2023-01-02 | 200,000                       | 400,000,000               |.  120\n\n| 2023-01-03 | 300,000                       | 450,000,000               |.  130\n\n|    ....               |            ....                     |        ...                           |.  .......\n\n\\-------------------------------------------------------------------------------------------------------------\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThe problem here is I have to use lots of resources every time to reprocess for the changing schema. and this is going to happen quite frequently until the warehouse gets mature.\n\nI just want to know how you guys these kind of problems.\n\n&amp;#x200B;\n\np.s. This problem has nothing to do with 'slow changing dimension(SCD)'\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_h4q1lnfou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with frequently changing schema in early stage of building data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aw9rlc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708515750.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708514657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building up tables and shema in my data warehouse (let&amp;#39;s say Redshift). And this build-up process is in very early stage right now.&lt;/p&gt;\n\n&lt;p&gt;and no matter how long I give a careful thought on how to set the schema right, at some point I have to change schema (add or subtract columns) .&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like this:&lt;/p&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;|date              | base_trade_volume | quote_trade_volume |&lt;/p&gt;\n\n&lt;p&gt;| 2023-01-02 | 200,000                       | 400,000,000               |&lt;/p&gt;\n\n&lt;p&gt;| 2023-01-03 | 300,000                       | 450,000,000               |&lt;/p&gt;\n\n&lt;p&gt;|    ....               |            ....                     |        ...                           |&lt;/p&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;This is a table called &amp;#39;user_trade_statistics&amp;#39;. and is the very first version of it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;and all of sudden, there&amp;#39;s a need for &amp;#39;trade_count&amp;#39; column. so I have to reprocess whole data to add new column to existing table.&lt;/p&gt;\n\n&lt;p&gt;-------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;|date              | base_trade_volume | quote_trade_volume |. trade_count&lt;/p&gt;\n\n&lt;p&gt;| 2023-01-02 | 200,000                       | 400,000,000               |.  120&lt;/p&gt;\n\n&lt;p&gt;| 2023-01-03 | 300,000                       | 450,000,000               |.  130&lt;/p&gt;\n\n&lt;p&gt;|    ....               |            ....                     |        ...                           |.  .......&lt;/p&gt;\n\n&lt;p&gt;-------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The problem here is I have to use lots of resources every time to reprocess for the changing schema. and this is going to happen quite frequently until the warehouse gets mature.&lt;/p&gt;\n\n&lt;p&gt;I just want to know how you guys these kind of problems.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;p.s. This problem has nothing to do with &amp;#39;slow changing dimension(SCD)&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aw9rlc", "is_robot_indexable": true, "report_reasons": null, "author": "DonkeyThin8833", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aw9rlc/how_do_you_deal_with_frequently_changing_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aw9rlc/how_do_you_deal_with_frequently_changing_schema/", "subreddit_subscribers": 162549, "created_utc": 1708514657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The dynamic world of data wrangling, shedding light on its techniques, distinguishing it from ETL processes and uncovering the trends shaping its trajectory in 2024. \n\n[https://www.dasca.org/world-of-big-data/article/the-art-of-data-wrangling-in-2024-techniques-and-trends](https://www.dasca.org/world-of-big-data/article/the-art-of-data-wrangling-in-2024-techniques-and-trends)", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Art of Data Wrangling in 2024: Techniques and Trends", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1awbz56", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708521933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The dynamic world of data wrangling, shedding light on its techniques, distinguishing it from ETL processes and uncovering the trends shaping its trajectory in 2024. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.dasca.org/world-of-big-data/article/the-art-of-data-wrangling-in-2024-techniques-and-trends\"&gt;https://www.dasca.org/world-of-big-data/article/the-art-of-data-wrangling-in-2024-techniques-and-trends&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZnyYGYrWCEtbmSXB8oDNvWRZW-djUwe98lI1WtlW4Fk.jpg?auto=webp&amp;s=c3804eeb91601ba8602083cbc04c036e2eda2f1d", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/ZnyYGYrWCEtbmSXB8oDNvWRZW-djUwe98lI1WtlW4Fk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=716d82775e810cc312111695e076e3c1cdfb05f8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZnyYGYrWCEtbmSXB8oDNvWRZW-djUwe98lI1WtlW4Fk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a19beec9cb6ccee91dd0a483b0e6e5941215c84d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZnyYGYrWCEtbmSXB8oDNvWRZW-djUwe98lI1WtlW4Fk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9acc0e8c19c5ef812142cde49ff5ceae94a4fcb1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZnyYGYrWCEtbmSXB8oDNvWRZW-djUwe98lI1WtlW4Fk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c6c70ae7817412367fc6993e9bdb15ec6175b505", "width": 640, "height": 336}], "variants": {}, "id": "GnNSv05l5aF3AMGceHxYmU5bdiOnSDtx6JDC87xpbFg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1awbz56", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awbz56/the_art_of_data_wrangling_in_2024_techniques_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awbz56/the_art_of_data_wrangling_in_2024_techniques_and/", "subreddit_subscribers": 162549, "created_utc": 1708521933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Asking as a junior DE. But answers from all levels of experience are very welcome!", "author_fullname": "t2_ecnqt6o1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those who have worked in both, which do you prefer: start ups or big corporations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1awe533", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708527707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Asking as a junior DE. But answers from all levels of experience are very welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1awe533", "is_robot_indexable": true, "report_reasons": null, "author": "silentwardrbe", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1awe533/for_those_who_have_worked_in_both_which_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1awe533/for_those_who_have_worked_in_both_which_do_you/", "subreddit_subscribers": 162549, "created_utc": 1708527707.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}