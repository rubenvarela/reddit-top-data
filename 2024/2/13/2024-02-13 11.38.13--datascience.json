{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Before the pandemic, I would meet people at conferences and/or weekly coding sessions, but since the pandemic, most of them had moved online, which doesn't seem as effective for meeting people. How are you guys meeting people in the field?", "author_fullname": "t2_15atwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you guys network?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap16o1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707747933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before the pandemic, I would meet people at conferences and/or weekly coding sessions, but since the pandemic, most of them had moved online, which doesn&amp;#39;t seem as effective for meeting people. How are you guys meeting people in the field?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1ap16o1", "is_robot_indexable": true, "report_reasons": null, "author": "GiliGiliAi", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ap16o1/how_do_you_guys_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ap16o1/how_do_you_guys_network/", "subreddit_subscribers": 1331791, "created_utc": 1707747933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got my MS in stats in 2020 and had about 3.5 years experience as a data analyst at that time. I wanted to break into data science, and so it being lock down and nothing else for me to do, I started teaching myself the cutting edge of the field at the time, things like neural nets and a bunch of advanced ML techniques. I did several projects on my own (no, not just titanic and mnist datasets) and created an online public portfolio. I applied to tons of data science jobs but had no luck. I've been able to increase my salary through a progression of analyst jobs, but none of them really use anything advanced. The one I was at before had a little tiny bit of clustering and FA, and maybe a basic regression model, the one I'm at now is literally all just SQL dashboarding. \n\nAfter my first move in Feb '21, I kind of just stopped trying to stay on top of the field, since I got a higher salary and I just kind of burnt out of doing so much stuff on my own to try and make myself more marketable. I just did other things with my life for a few years, but I'm feeling ready for another move now. I notice now data science positions are asking for AI, GPT4, LlaMa, and those things weren't around when I was really working on my skills. I'm willing to learn those things if there's a good chance I'll use them, but I haven't used tensorflow, keras, or sklearn at all despite sinking massive amounts of my personal time into them.\n\nI think part of it is there seem to be no junior level data scientist roles. It seems at most places, analyst is a different career path that tops out at management instead of more advanced methodologies, and so it doesn't really get me any closer to data scientist. Most open DS positions I see are senior or even manager and so I'm nowhere near qualified for them. I'm questioning if it's even worth it for me to spend so much time trying to learn these things when the DS positions are forever out of reach, and perhaps I'm better off getting an MBA or something and trying to target leadership analyst type roles.", "author_fullname": "t2_abhp8o9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it even worth it for me to try to learn new data science methodologies and techniques at this point?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apf2gc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707782108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got my MS in stats in 2020 and had about 3.5 years experience as a data analyst at that time. I wanted to break into data science, and so it being lock down and nothing else for me to do, I started teaching myself the cutting edge of the field at the time, things like neural nets and a bunch of advanced ML techniques. I did several projects on my own (no, not just titanic and mnist datasets) and created an online public portfolio. I applied to tons of data science jobs but had no luck. I&amp;#39;ve been able to increase my salary through a progression of analyst jobs, but none of them really use anything advanced. The one I was at before had a little tiny bit of clustering and FA, and maybe a basic regression model, the one I&amp;#39;m at now is literally all just SQL dashboarding. &lt;/p&gt;\n\n&lt;p&gt;After my first move in Feb &amp;#39;21, I kind of just stopped trying to stay on top of the field, since I got a higher salary and I just kind of burnt out of doing so much stuff on my own to try and make myself more marketable. I just did other things with my life for a few years, but I&amp;#39;m feeling ready for another move now. I notice now data science positions are asking for AI, GPT4, LlaMa, and those things weren&amp;#39;t around when I was really working on my skills. I&amp;#39;m willing to learn those things if there&amp;#39;s a good chance I&amp;#39;ll use them, but I haven&amp;#39;t used tensorflow, keras, or sklearn at all despite sinking massive amounts of my personal time into them.&lt;/p&gt;\n\n&lt;p&gt;I think part of it is there seem to be no junior level data scientist roles. It seems at most places, analyst is a different career path that tops out at management instead of more advanced methodologies, and so it doesn&amp;#39;t really get me any closer to data scientist. Most open DS positions I see are senior or even manager and so I&amp;#39;m nowhere near qualified for them. I&amp;#39;m questioning if it&amp;#39;s even worth it for me to spend so much time trying to learn these things when the DS positions are forever out of reach, and perhaps I&amp;#39;m better off getting an MBA or something and trying to target leadership analyst type roles.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1apf2gc", "is_robot_indexable": true, "report_reasons": null, "author": "son_of_tv_c", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1apf2gc/is_it_even_worth_it_for_me_to_try_to_learn_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1apf2gc/is_it_even_worth_it_for_me_to_try_to_learn_new/", "subreddit_subscribers": 1331791, "created_utc": 1707782108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nI'm back with an update! My original post on this sub ([https://www.reddit.com/r/datascience/comments/18bgpy2/explaining\\_how\\_generative\\_ai\\_works\\_in\\_code\\_from/](https://www.reddit.com/r/datascience/comments/18bgpy2/explaining_how_generative_ai_works_in_code_from/)) got some positive feedback so I thought I would give another update.\n\n\\---\n\nu/NeetCode and I are excited to announce free coding problems for AI/ML that you can solve in your browser and run against test cases. They assume no prior background knowledge in AI/ML or absurdly in depth math. They work up from linear regression to coding and training a GPT chat model from scratch!\n\nFor each problem, I created a 5-10 minute background video covering the concepts needed to solve the problem (or quiz, for the topics that have multiple choice quizzes to go along with them) as well as a solution video.\n\nAll the videos for the problems, and 2x a week concept overviews on different ML topics (suggestions welcome!) can be found on my channel: [https://www.youtube.com/@GPTandChill](https://www.youtube.com/@GPTandChill)\n\nThe problem list can be found here [https://neetcode.io/practice?subpage=practice&amp;tab=coreSkills&amp;topic=Machine%20Learning](https://neetcode.io/practice?subpage=practice&amp;tab=coreSkills&amp;topic=Machine%20Learning) OR here [https://www.gptandchill.ai/leetcode-for-ml](https://www.gptandchill.ai/leetcode-for-ml)\n\nAnd here are Navi's posts for some additional context:\n\n[https://x.com/neetcode1/status/1756997643556041191?s=20](https://x.com/neetcode1/status/1756997643556041191?s=20)\n\n[https://www.linkedin.com/posts/activity-7162822685037674496-i0Yo?utm\\_source=share&amp;utm\\_medium=member\\_desktop](https://www.linkedin.com/posts/activity-7162822685037674496-i0Yo?utm_source=share&amp;utm_medium=member_desktop)\n\nLet us know if you like this kind of educational content or have any feedback!", "author_fullname": "t2_o8bqxbsy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Announcing Bite-Sized Coding Problems for AI/ML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aphcpy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707789582.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707788436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m back with an update! My original post on this sub (&lt;a href=\"https://www.reddit.com/r/datascience/comments/18bgpy2/explaining_how_generative_ai_works_in_code_from/\"&gt;https://www.reddit.com/r/datascience/comments/18bgpy2/explaining_how_generative_ai_works_in_code_from/&lt;/a&gt;) got some positive feedback so I thought I would give another update.&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/u/NeetCode\"&gt;u/NeetCode&lt;/a&gt; and I are excited to announce free coding problems for AI/ML that you can solve in your browser and run against test cases. They assume no prior background knowledge in AI/ML or absurdly in depth math. They work up from linear regression to coding and training a GPT chat model from scratch!&lt;/p&gt;\n\n&lt;p&gt;For each problem, I created a 5-10 minute background video covering the concepts needed to solve the problem (or quiz, for the topics that have multiple choice quizzes to go along with them) as well as a solution video.&lt;/p&gt;\n\n&lt;p&gt;All the videos for the problems, and 2x a week concept overviews on different ML topics (suggestions welcome!) can be found on my channel: &lt;a href=\"https://www.youtube.com/@GPTandChill\"&gt;https://www.youtube.com/@GPTandChill&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The problem list can be found here &lt;a href=\"https://neetcode.io/practice?subpage=practice&amp;amp;tab=coreSkills&amp;amp;topic=Machine%20Learning\"&gt;https://neetcode.io/practice?subpage=practice&amp;amp;tab=coreSkills&amp;amp;topic=Machine%20Learning&lt;/a&gt; OR here &lt;a href=\"https://www.gptandchill.ai/leetcode-for-ml\"&gt;https://www.gptandchill.ai/leetcode-for-ml&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And here are Navi&amp;#39;s posts for some additional context:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://x.com/neetcode1/status/1756997643556041191?s=20\"&gt;https://x.com/neetcode1/status/1756997643556041191?s=20&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.linkedin.com/posts/activity-7162822685037674496-i0Yo?utm_source=share&amp;amp;utm_medium=member_desktop\"&gt;https://www.linkedin.com/posts/activity-7162822685037674496-i0Yo?utm_source=share&amp;amp;utm_medium=member_desktop&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let us know if you like this kind of educational content or have any feedback!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iHd1w4T0Mbm_gpfUBLM8kXrsy3-vCZKQ_Lk0UTMRxyU.jpg?auto=webp&amp;s=90d6f559319f3e7f0c2421491c8a2d56eeebef78", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/iHd1w4T0Mbm_gpfUBLM8kXrsy3-vCZKQ_Lk0UTMRxyU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8307c7113ef9def195dc7ec58dd5745a009a679d", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/iHd1w4T0Mbm_gpfUBLM8kXrsy3-vCZKQ_Lk0UTMRxyU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a524217d25076f0904ee73210946ae9b22f0662", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/iHd1w4T0Mbm_gpfUBLM8kXrsy3-vCZKQ_Lk0UTMRxyU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f50bec08fd8c8f3c3d7bb03fa83da26911c9b58d", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/iHd1w4T0Mbm_gpfUBLM8kXrsy3-vCZKQ_Lk0UTMRxyU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6514c735a74f7caded69afd3b9ffede4b6673ef3", "width": 640, "height": 640}], "variants": {}, "id": "JX4w5wfPYB87b1BTpn1l3m6t2e8uqC-2QUWb8nK_rAg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1aphcpy", "is_robot_indexable": true, "report_reasons": null, "author": "GPTandChill", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aphcpy/announcing_bitesized_coding_problems_for_aiml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aphcpy/announcing_bitesized_coding_problems_for_aiml/", "subreddit_subscribers": 1331791, "created_utc": 1707788436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "# Question\n\nWhat tools exist today for automated alerting? Do you use them in your core job? Wondering if there have been advances in the space in the last few years? If you do use them then what business function are you running them for.\n\n# My past experience \n\nMy team and I built an internal tool for alerting (called Cassandra) in 2016. A business user specified the metric they would like to track and we automatically identified anomalous changes across dimensions then emailed them when it fell outside the range. They could then dig in further in our interactive dashboard. It failed as we were not precise enough with our alerting and consumers ultimately lost interest in our alerts and began to treat them as spam. \n\n&amp;#x200B;", "author_fullname": "t2_tszztjadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use automated alerting in your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aph771", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707788009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Question&lt;/h1&gt;\n\n&lt;p&gt;What tools exist today for automated alerting? Do you use them in your core job? Wondering if there have been advances in the space in the last few years? If you do use them then what business function are you running them for.&lt;/p&gt;\n\n&lt;h1&gt;My past experience&lt;/h1&gt;\n\n&lt;p&gt;My team and I built an internal tool for alerting (called Cassandra) in 2016. A business user specified the metric they would like to track and we automatically identified anomalous changes across dimensions then emailed them when it fell outside the range. They could then dig in further in our interactive dashboard. It failed as we were not precise enough with our alerting and consumers ultimately lost interest in our alerts and began to treat them as spam. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1aph771", "is_robot_indexable": true, "report_reasons": null, "author": "jmack_startups", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aph771/do_you_use_automated_alerting_in_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aph771/do_you_use_automated_alerting_in_your_job/", "subreddit_subscribers": 1331791, "created_utc": 1707788009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, I wrote a [tutorial](http://squack.io/post/vendors) on how to string together some new LLM techniques to automate a categorization task from start to finish.\n\nUnlike a lot of AI out there, I'm operating under the philosophy that it's better to automate 90% with 100% confidence, than 100% with 90% confidence.\n\nThe example I go through is for bookkeeping, but you could probably apply the same principles to any workflow where matching is involved.\n\nCheck it out, and let me know what y'all think!\n\n[Fine-tuned control over final accuracy](https://preview.redd.it/8u50wr1mo7ic1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=924559aa616ee638b88a964bb1bd4ac88c9b2274)", "author_fullname": "t2_898csv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automated categorization with LLMs tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8u50wr1mo7ic1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/8u50wr1mo7ic1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e375ce507f8ddd70fface04465b57dd5880f2e97"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/8u50wr1mo7ic1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=83cc2c13c2c5222cf4f177ff5b16a43cd7424bb5"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/8u50wr1mo7ic1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=42d2a519c5292382ad5087ea1f68702cb2066481"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/8u50wr1mo7ic1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ba63803dc891886a019b02780c9e81d65a11f19"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/8u50wr1mo7ic1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=70035a8558beffec0ee40d53397a0fad81cb2da8"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/8u50wr1mo7ic1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b55fca9c1691ee7dc3af30c1194a195d188022a5"}], "s": {"y": 1440, "x": 1920, "u": "https://preview.redd.it/8u50wr1mo7ic1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=924559aa616ee638b88a964bb1bd4ac88c9b2274"}, "id": "8u50wr1mo7ic1"}}, "name": "t3_1ap9kpg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/ni69SRk97WSP29K5QaOThyI3zXHAyW7mm7qRh4GeZCI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707768589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I wrote a &lt;a href=\"http://squack.io/post/vendors\"&gt;tutorial&lt;/a&gt; on how to string together some new LLM techniques to automate a categorization task from start to finish.&lt;/p&gt;\n\n&lt;p&gt;Unlike a lot of AI out there, I&amp;#39;m operating under the philosophy that it&amp;#39;s better to automate 90% with 100% confidence, than 100% with 90% confidence.&lt;/p&gt;\n\n&lt;p&gt;The example I go through is for bookkeeping, but you could probably apply the same principles to any workflow where matching is involved.&lt;/p&gt;\n\n&lt;p&gt;Check it out, and let me know what y&amp;#39;all think!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8u50wr1mo7ic1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=924559aa616ee638b88a964bb1bd4ac88c9b2274\"&gt;Fine-tuned control over final accuracy&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1ap9kpg", "is_robot_indexable": true, "report_reasons": null, "author": "evilredpanda", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ap9kpg/automated_categorization_with_llms_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ap9kpg/automated_categorization_with_llms_tutorial/", "subreddit_subscribers": 1331791, "created_utc": 1707768589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**My ad-hoc data exploration workflow is broken.** It's too heavy and time-consuming, and I end up doing less of it as a result.  **How do you do it? What am I missing?  What can be improved?** \n\n**My workflow now:** \n\n* Decide I need some metric or insight (say 7D user retention for a specific product feature)\n* Find out the out of the box dashboards don't have exactly what I need. \n* Fire up SQL with our internal query engine. Research the table and start running queries. Table often massive so they take time to run. \n* Get roughly the data I need and either port my output data into Colab or keep hacking away in SQL with spreadsheets. \n* Hopefully get my insight as a once off but then it falls out of relevance as it's not refreshed continuously with time. I don't want to own pipelines so rarely worth keeping it updating live time.", "author_fullname": "t2_tszztjadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you do Ad-Hoc data exploration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apc5y8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707774757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;My ad-hoc data exploration workflow is broken.&lt;/strong&gt; It&amp;#39;s too heavy and time-consuming, and I end up doing less of it as a result.  &lt;strong&gt;How do you do it? What am I missing?  What can be improved?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My workflow now:&lt;/strong&gt; &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Decide I need some metric or insight (say 7D user retention for a specific product feature)&lt;/li&gt;\n&lt;li&gt;Find out the out of the box dashboards don&amp;#39;t have exactly what I need. &lt;/li&gt;\n&lt;li&gt;Fire up SQL with our internal query engine. Research the table and start running queries. Table often massive so they take time to run. &lt;/li&gt;\n&lt;li&gt;Get roughly the data I need and either port my output data into Colab or keep hacking away in SQL with spreadsheets. &lt;/li&gt;\n&lt;li&gt;Hopefully get my insight as a once off but then it falls out of relevance as it&amp;#39;s not refreshed continuously with time. I don&amp;#39;t want to own pipelines so rarely worth keeping it updating live time.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1apc5y8", "is_robot_indexable": true, "report_reasons": null, "author": "jmack_startups", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1apc5y8/how_do_you_do_adhoc_data_exploration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1apc5y8/how_do_you_do_adhoc_data_exploration/", "subreddit_subscribers": 1331791, "created_utc": 1707774757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Since you guys seemed to enjoy my [last post](https://www.reddit.com/r/datascience/comments/197dkkz/the_hard_truth_about_artificial_intelligence_in/), I thought I'd share my latest blog post. [Check it out here.](https://www.reddit.com/r/datascience/comments/197dkkz/the_hard_truth_about_artificial_intelligence_in/) Below is a quick brief about the article:\n\nIn drug development, where the median clinical trial costs about $48 million, biotech companies face the major challenge of balancing expenses with the need for robust, well-designed, and sufficiently large clinical trials. This reality has motivated software companies like Unlearn.AI to pioneer machine learning (ML) applications to boost clinical trial efficiency. Yet, implementing such cutting-edge methodology is not without significant practical challenges.\n\nToday's post delves into the merits and limitations of Unlearn's ML-based Prognostic Covariate Adjustment (PROCOVA). I argue that the theoretical cost-savings of PROCOVA are unlikely to be realized in practice. Given the often high stakes of clinical trials, the risk of adopting innovative ML-based methodologies may not be worth the purported benefits.\n\nWhere do you see ML and clinical trials going? Let me know in the comments below!", "author_fullname": "t2_8ce5e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can Machine Learning Give Us Faster and Cheaper Clinical Trials? (On Trial Design, Historical Controls, and Clinical Prediction Models)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap3tes", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707754876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since you guys seemed to enjoy my &lt;a href=\"https://www.reddit.com/r/datascience/comments/197dkkz/the_hard_truth_about_artificial_intelligence_in/\"&gt;last post&lt;/a&gt;, I thought I&amp;#39;d share my latest blog post. &lt;a href=\"https://www.reddit.com/r/datascience/comments/197dkkz/the_hard_truth_about_artificial_intelligence_in/\"&gt;Check it out here.&lt;/a&gt; Below is a quick brief about the article:&lt;/p&gt;\n\n&lt;p&gt;In drug development, where the median clinical trial costs about $48 million, biotech companies face the major challenge of balancing expenses with the need for robust, well-designed, and sufficiently large clinical trials. This reality has motivated software companies like Unlearn.AI to pioneer machine learning (ML) applications to boost clinical trial efficiency. Yet, implementing such cutting-edge methodology is not without significant practical challenges.&lt;/p&gt;\n\n&lt;p&gt;Today&amp;#39;s post delves into the merits and limitations of Unlearn&amp;#39;s ML-based Prognostic Covariate Adjustment (PROCOVA). I argue that the theoretical cost-savings of PROCOVA are unlikely to be realized in practice. Given the often high stakes of clinical trials, the risk of adopting innovative ML-based methodologies may not be worth the purported benefits.&lt;/p&gt;\n\n&lt;p&gt;Where do you see ML and clinical trials going? Let me know in the comments below!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1ap3tes", "is_robot_indexable": true, "report_reasons": null, "author": "Zawadscki", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ap3tes/can_machine_learning_give_us_faster_and_cheaper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ap3tes/can_machine_learning_give_us_faster_and_cheaper/", "subreddit_subscribers": 1331791, "created_utc": 1707754876.0, "num_crossposts": 3, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What interesting things did you discover? Any interesting variables? May be working on a project around it soon.", "author_fullname": "t2_495cn7pm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone ever do anything with NPS (Net Promoter Scores) in the insurance industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apeal9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707780074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What interesting things did you discover? Any interesting variables? May be working on a project around it soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1apeal9", "is_robot_indexable": true, "report_reasons": null, "author": "Throwawayforgainz99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1apeal9/anyone_ever_do_anything_with_nps_net_promoter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1apeal9/anyone_ever_do_anything_with_nps_net_promoter/", "subreddit_subscribers": 1331791, "created_utc": 1707780074.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}