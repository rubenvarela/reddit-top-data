{"kind": "Listing", "data": {"after": "t3_1ap6e48", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked as a data professional with different job titles for about 10 years now and I'm noticing a pattern that I haven't seen explored before, and I'm interested in some structure.  I see two types of data engineering roles/teams and I'll try to describe them as best I can in a couple bullets.  \n\n\nType 1: the converted software engineer\n\n* Comfortable in Scala/Rust/Spark/kubernetes\n* Handles not just deployment but serving production systems\n* Highly interested in optimizations as these save the company real money or just to make the problems tractable. \n* More likely to use streaming architectures.\n* Further removed from the business problems.\n\n&amp;#x200B;\n\nType 2: the senior data scientist\n\n* I've built a fancy model, now what?\n* Has to set up their own OLAP architecture as the only dbs the software engineering team uses are OLTP, possibly even setting up their own data lakes as well\n* Likely don't have replicated environments.\n* Passes off data artifacts/exposes data products to the SE team for integration into core platform\n* Focused on solving problems for the business, which necessitates data engineering.\n\n&amp;#x200B;\n\nI could go on but I hope the distinction is clear.  Core skills SQL/Python/Data modeling/cloud are the same and of course many roles will be a hybrid.  Anyone have useful nomenclature for each of these archetypes?", "author_fullname": "t2_xi7dy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering vs Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap40zg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707755384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked as a data professional with different job titles for about 10 years now and I&amp;#39;m noticing a pattern that I haven&amp;#39;t seen explored before, and I&amp;#39;m interested in some structure.  I see two types of data engineering roles/teams and I&amp;#39;ll try to describe them as best I can in a couple bullets.  &lt;/p&gt;\n\n&lt;p&gt;Type 1: the converted software engineer&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Comfortable in Scala/Rust/Spark/kubernetes&lt;/li&gt;\n&lt;li&gt;Handles not just deployment but serving production systems&lt;/li&gt;\n&lt;li&gt;Highly interested in optimizations as these save the company real money or just to make the problems tractable. &lt;/li&gt;\n&lt;li&gt;More likely to use streaming architectures.&lt;/li&gt;\n&lt;li&gt;Further removed from the business problems.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Type 2: the senior data scientist&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I&amp;#39;ve built a fancy model, now what?&lt;/li&gt;\n&lt;li&gt;Has to set up their own OLAP architecture as the only dbs the software engineering team uses are OLTP, possibly even setting up their own data lakes as well&lt;/li&gt;\n&lt;li&gt;Likely don&amp;#39;t have replicated environments.&lt;/li&gt;\n&lt;li&gt;Passes off data artifacts/exposes data products to the SE team for integration into core platform&lt;/li&gt;\n&lt;li&gt;Focused on solving problems for the business, which necessitates data engineering.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I could go on but I hope the distinction is clear.  Core skills SQL/Python/Data modeling/cloud are the same and of course many roles will be a hybrid.  Anyone have useful nomenclature for each of these archetypes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ap40zg", "is_robot_indexable": true, "report_reasons": null, "author": "apple_pie_52", "discussion_type": null, "num_comments": 19, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap40zg/data_engineering_vs_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap40zg/data_engineering_vs_data_engineering/", "subreddit_subscribers": 160411, "created_utc": 1707755384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One part of my app acts as a pseudo data-pipeline, where I ETL a single player's data at a time (I have to due to the nature of the API I'm pulling data from).\n\nI am currently using pandas for all of this, where I pull the data from the API, throw it in a dataframe, transform it, and run \\`pandas.to\\_sql()\\` to store it.\n\nThe problem is that this is memory intensive, and I'm running into RAM issues when running this in a docker container.\n\nWhat would be a good memory efficient tool to work with moving datasets through an application?\n\nTo clarify: I am using pandas as a tool to efficiently pass around this dataset that I add data to, transform it, and store it in the database. I would need this replacement tool to do the same thing in python. I also have only 1 server, so a distributed system like Spark isn't an option for me", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using pandas in a data-intensive application - what the best, RAM-efficient, alternative?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aphlml", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707789616.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707789155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One part of my app acts as a pseudo data-pipeline, where I ETL a single player&amp;#39;s data at a time (I have to due to the nature of the API I&amp;#39;m pulling data from).&lt;/p&gt;\n\n&lt;p&gt;I am currently using pandas for all of this, where I pull the data from the API, throw it in a dataframe, transform it, and run `pandas.to_sql()` to store it.&lt;/p&gt;\n\n&lt;p&gt;The problem is that this is memory intensive, and I&amp;#39;m running into RAM issues when running this in a docker container.&lt;/p&gt;\n\n&lt;p&gt;What would be a good memory efficient tool to work with moving datasets through an application?&lt;/p&gt;\n\n&lt;p&gt;To clarify: I am using pandas as a tool to efficiently pass around this dataset that I add data to, transform it, and store it in the database. I would need this replacement tool to do the same thing in python. I also have only 1 server, so a distributed system like Spark isn&amp;#39;t an option for me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aphlml", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aphlml/using_pandas_in_a_dataintensive_application_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aphlml/using_pandas_in_a_dataintensive_application_what/", "subreddit_subscribers": 160411, "created_utc": 1707789155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the dbt features you use and love most?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite DBT features?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap8onr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707766517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the dbt features you use and love most?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ap8onr", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap8onr/favorite_dbt_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap8onr/favorite_dbt_features/", "subreddit_subscribers": 160411, "created_utc": 1707766517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am not usually reading about my craft, but recently came across two books that captured my imagination in CI/CD and data.\n\nReading these two helped me to understand the different perspectives coming from the technology side and from the business side.\n\nAs a result, I can better understand how the business sees problems which is not always easy for me as a dev. I think I can also have better conversations with the business side as an engineer.\n\n* The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win\n* The Unicorn Project: A Novel about Developers, Digital Disruption, and Thriving in the Age of Data\n\nReading these two helped me to understand the different perspectives coming from the technology side and the business side. ave better conversations with the business side as an engineer. ineer.\n\nThe title is obviously a bit of an overstatement, I'd love to hear your recommendations for the books you think are best.", "author_fullname": "t2_h58nyr96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The only two books you need to read about CI/CD and Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apolbz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707812720.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707812439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not usually reading about my craft, but recently came across two books that captured my imagination in CI/CD and data.&lt;/p&gt;\n\n&lt;p&gt;Reading these two helped me to understand the different perspectives coming from the technology side and from the business side.&lt;/p&gt;\n\n&lt;p&gt;As a result, I can better understand how the business sees problems which is not always easy for me as a dev. I think I can also have better conversations with the business side as an engineer.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win&lt;/li&gt;\n&lt;li&gt;The Unicorn Project: A Novel about Developers, Digital Disruption, and Thriving in the Age of Data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Reading these two helped me to understand the different perspectives coming from the technology side and the business side. ave better conversations with the business side as an engineer. ineer.&lt;/p&gt;\n\n&lt;p&gt;The title is obviously a bit of an overstatement, I&amp;#39;d love to hear your recommendations for the books you think are best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apolbz", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyFish7104", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apolbz/the_only_two_books_you_need_to_read_about_cicd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apolbz/the_only_two_books_you_need_to_read_about_cicd/", "subreddit_subscribers": 160411, "created_utc": 1707812439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "These days it seems like every solution is cloud-based for data engineering. What are some instances in which moving to the cloud does not make sense.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are instances where data storage, ETL, analytics, etc don't make sense on the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apkimj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707797667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;These days it seems like every solution is cloud-based for data engineering. What are some instances in which moving to the cloud does not make sense.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apkimj", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apkimj/what_are_instances_where_data_storage_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apkimj/what_are_instances_where_data_storage_etl/", "subreddit_subscribers": 160411, "created_utc": 1707797667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI work in the data team for a very large organization. Despite the size and influence of the organization, we are actually quite behind other companies in terms of data architecture, the tools we use and so on. I guess a typical issue for a large old organization.\n\nTo put it in context, I work for a team that does analytics for the website and mobile app. The website is split per \u201cscope\u201d and there are one or multiple analysts assigned to each \u201cscope\u201d and usually that is their sole focus and they are not really aware of what other analysts are doing, what queries they use, how exactly they measure their KPIs and so on. I think you get the idea. We work in a very decentralized way and would like to move to a more centralized setup with one \u201csource of truth\u201d.\n\nWe are already working on documenting KPIs and aligning how each team calculates them so we do it the same way across the department. Baby steps at the moment.\n\nBut that\u2019s not why I am here. I have been assigned to lead a team that owns the data and transforms it for final use by the analysts. Basically transforming all the raw data into final tables (some people call it the \u201cgold layer\u201d).\n\nCurrently, each analyst would basically dig into the raw data and find whatever they need and schedule a query that would feed new data everyday to a table and that table would be connected to their dashboard. \n\nNot only is it ridiculously expensive, but also very inefficient. We work with millions of sessions per day so you can imagine how much data we have.\n\nI have spent quite some time looking for resources online but there is so little focusing on modeling event data. I have very little data engineering/analytics engineering experience so any resources or tips would be highly appreciated. \n\nWe only use BigQuery and dbt at the moment.\nLooking into adding fivetran to the stack to simplify data streams from all the third party apps (currently we have many scripts for each 3rd party app and eqch script is owned by a different person so not centralized at all)\n\nThank you!", "author_fullname": "t2_59sa4mgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for data modeling and building a data architecture for event data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apkw7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707822875.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707798861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I work in the data team for a very large organization. Despite the size and influence of the organization, we are actually quite behind other companies in terms of data architecture, the tools we use and so on. I guess a typical issue for a large old organization.&lt;/p&gt;\n\n&lt;p&gt;To put it in context, I work for a team that does analytics for the website and mobile app. The website is split per \u201cscope\u201d and there are one or multiple analysts assigned to each \u201cscope\u201d and usually that is their sole focus and they are not really aware of what other analysts are doing, what queries they use, how exactly they measure their KPIs and so on. I think you get the idea. We work in a very decentralized way and would like to move to a more centralized setup with one \u201csource of truth\u201d.&lt;/p&gt;\n\n&lt;p&gt;We are already working on documenting KPIs and aligning how each team calculates them so we do it the same way across the department. Baby steps at the moment.&lt;/p&gt;\n\n&lt;p&gt;But that\u2019s not why I am here. I have been assigned to lead a team that owns the data and transforms it for final use by the analysts. Basically transforming all the raw data into final tables (some people call it the \u201cgold layer\u201d).&lt;/p&gt;\n\n&lt;p&gt;Currently, each analyst would basically dig into the raw data and find whatever they need and schedule a query that would feed new data everyday to a table and that table would be connected to their dashboard. &lt;/p&gt;\n\n&lt;p&gt;Not only is it ridiculously expensive, but also very inefficient. We work with millions of sessions per day so you can imagine how much data we have.&lt;/p&gt;\n\n&lt;p&gt;I have spent quite some time looking for resources online but there is so little focusing on modeling event data. I have very little data engineering/analytics engineering experience so any resources or tips would be highly appreciated. &lt;/p&gt;\n\n&lt;p&gt;We only use BigQuery and dbt at the moment.\nLooking into adding fivetran to the stack to simplify data streams from all the third party apps (currently we have many scripts for each 3rd party app and eqch script is owned by a different person so not centralized at all)&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apkw7y", "is_robot_indexable": true, "report_reasons": null, "author": "Several_Percentage_5", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apkw7y/resources_for_data_modeling_and_building_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apkw7y/resources_for_data_modeling_and_building_a_data/", "subreddit_subscribers": 160411, "created_utc": 1707798861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m exhausted of the Iceberg vs Delta Lake arguments. They\u2019ve devolved to nitpicking minor features, none of which bring long-term value to Data Engineering.\n\nGoogle and Microsoft appear to be backing OneTable (renamed to XTable). What are your thoughts?\n\nhttps://cwiki.apache.org/confluence/plugins/servlet/mobile?contentId=276106065#content/view/276106065", "author_fullname": "t2_z15jq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on OneTable/XTable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap2xop", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707752677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m exhausted of the Iceberg vs Delta Lake arguments. They\u2019ve devolved to nitpicking minor features, none of which bring long-term value to Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;Google and Microsoft appear to be backing OneTable (renamed to XTable). What are your thoughts?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cwiki.apache.org/confluence/plugins/servlet/mobile?contentId=276106065#content/view/276106065\"&gt;https://cwiki.apache.org/confluence/plugins/servlet/mobile?contentId=276106065#content/view/276106065&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ap2xop", "is_robot_indexable": true, "report_reasons": null, "author": "Data_cruncher", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap2xop/thoughts_on_onetablextable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap2xop/thoughts_on_onetablextable/", "subreddit_subscribers": 160411, "created_utc": 1707752677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My friend is struggling to make a choice - remote, but 30% less pay and for big corporation or working in small firm of about 200 employees as a solo data analyst\n\nBig corporation - 50k employees +/-, 13 data analysts on her team, most are experienced, not much room to grow or manoeuvre (big bank in Poland). Remote as well.\n\nSmall firm - 30% paybump compared to big corporation, solo data analyst, about 20mins travel (which is OK for Poland) works underneath firm's director as solo analyst. Last one left because they wanted to move abroad. Company tripled in revenue in the last 2 years. Not a startup, been on the market 15 years. \n\nSo obviously remote is big plus, but not much room for growth -  she's still young, only 25, and it'll be hard to gain promotions and grow given there's 13 people in her team, and the second youngest person is over 30 with lots of experience. \n\nOther company - room to grow and expand, possible manager within two-ish years. Works underneath the firm's director and CEO. Obviously if something goes wrong it's on her. And in office, no hybrid. \n\nWhat would you pick, I said I'll ask some people but we're all kinda like \"that's a tough one\".", "author_fullname": "t2_ki4xz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pick 30% paybump for a small company or work in a big bank?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apqjnd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707820828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend is struggling to make a choice - remote, but 30% less pay and for big corporation or working in small firm of about 200 employees as a solo data analyst&lt;/p&gt;\n\n&lt;p&gt;Big corporation - 50k employees +/-, 13 data analysts on her team, most are experienced, not much room to grow or manoeuvre (big bank in Poland). Remote as well.&lt;/p&gt;\n\n&lt;p&gt;Small firm - 30% paybump compared to big corporation, solo data analyst, about 20mins travel (which is OK for Poland) works underneath firm&amp;#39;s director as solo analyst. Last one left because they wanted to move abroad. Company tripled in revenue in the last 2 years. Not a startup, been on the market 15 years. &lt;/p&gt;\n\n&lt;p&gt;So obviously remote is big plus, but not much room for growth -  she&amp;#39;s still young, only 25, and it&amp;#39;ll be hard to gain promotions and grow given there&amp;#39;s 13 people in her team, and the second youngest person is over 30 with lots of experience. &lt;/p&gt;\n\n&lt;p&gt;Other company - room to grow and expand, possible manager within two-ish years. Works underneath the firm&amp;#39;s director and CEO. Obviously if something goes wrong it&amp;#39;s on her. And in office, no hybrid. &lt;/p&gt;\n\n&lt;p&gt;What would you pick, I said I&amp;#39;ll ask some people but we&amp;#39;re all kinda like &amp;quot;that&amp;#39;s a tough one&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1apqjnd", "is_robot_indexable": true, "report_reasons": null, "author": "Leopatto", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apqjnd/pick_30_paybump_for_a_small_company_or_work_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apqjnd/pick_30_paybump_for_a_small_company_or_work_in_a/", "subreddit_subscribers": 160411, "created_utc": 1707820828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " My team has some Python scripts which extract data from several API sources and save as csv files. The data from each source produces several staging tables. So for example we extract several data objects from the Salesforce API and same for Stripe etc and I'm not sure how I'd structure this in a bucket. I was thinking something like this:\n\ns3://{bucketname}/{API\\_source}/{dataobject or tablename}/{yyyy-mm-dd}\n\nor\n\ns3://{bucketname}/{API\\_source}/{yyyy-mm-dd}/{dataobject or tablename}\n\nNot sure which of these two is better or if there is a better way altogether. We have no need for an additional 'layer' in the form of a separate bucket because we have minimal pre-processing.", "author_fullname": "t2_hxekotykt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to properly structure and partition an S3 bucket for raw data storage from several sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apdkil", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707778238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team has some Python scripts which extract data from several API sources and save as csv files. The data from each source produces several staging tables. So for example we extract several data objects from the Salesforce API and same for Stripe etc and I&amp;#39;m not sure how I&amp;#39;d structure this in a bucket. I was thinking something like this:&lt;/p&gt;\n\n&lt;p&gt;s3://{bucketname}/{API_source}/{dataobject or tablename}/{yyyy-mm-dd}&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;s3://{bucketname}/{API_source}/{yyyy-mm-dd}/{dataobject or tablename}&lt;/p&gt;\n\n&lt;p&gt;Not sure which of these two is better or if there is a better way altogether. We have no need for an additional &amp;#39;layer&amp;#39; in the form of a separate bucket because we have minimal pre-processing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1apdkil", "is_robot_indexable": true, "report_reasons": null, "author": "NotGuiltySparkk", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apdkil/how_to_properly_structure_and_partition_an_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apdkil/how_to_properly_structure_and_partition_an_s3/", "subreddit_subscribers": 160411, "created_utc": 1707778238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Aspirants,\n\nLast week, I cleared DP-203 with 920 score after 2 weeks of studying. I have made a post about it and the resources used here: [https://www.reddit.com/r/dataengineering/comments/1andkrm/passed\\_dp203\\_last\\_week\\_details\\_for\\_aspirants\\_in/?utm\\_source=share&amp;utm\\_medium=web2x&amp;context=3](https://www.reddit.com/r/dataengineering/comments/1andkrm/passed_dp203_last_week_details_for_aspirants_in/?utm_source=share&amp;utm_medium=web2x&amp;context=3)\n\nThis will be my second and last post related to DP-203. In this post I focus on how you should go about studying as in my preparation I came across so many resources to study but no concrete plan or strategy which only led to confusion.\n\n**Section A: Build Your Knowledge Base**\n\n1. Start with synapse documentation.  \nUnderstand spark pools, difference between serverless and dedicated sql pools. Managed and external tables. Dynamic Data Masking. TDE. Row Level Security and Column Level Security.\n2. Azure Stream Analytics documentation will be up next.  \nBe sure to understand 5 types of windows as atleast 1 question will be on that.\n3. Azure Data Factory Documentation\n4. MS Learn Path  \nSCD Types. 1 questions atleast will come on it.\n\nNote: There is no way you are going to go through all the pages in documentations and next to impossible to remember them. My advise would be to skim through it and try to build a high level knowledge base. You do not need to be expert who knows everything.\n\n**Section B: Real Preparation Starts Here, Build Knowledge required for actual exam.**  \nNote: Below two points are going to be very vital for you to pass the exam as 70-80% questions will be from Dump.\n\n1. Exam Topics free questions.  \nGo through the discussions and the links provided, this is where your best learning is going to happen. There will be some questions with divided answers and you are going to just have to trust your gut. \n2. [https://youtu.be/0QUSK48YX04?list=PL0AYtrUw-NRQu89sbJNXPEo0dkBVTujY5](https://youtu.be/0QUSK48YX04?list=PL0AYtrUw-NRQu89sbJNXPEo0dkBVTujY5)  \nGo through this video. Many questions will overlap with Exam Topics but still highly recommened watching this video as questions will come from this as well, especially the case study.\n\n**Section C: Important must-do topics**\n\n1. SCD Types: [https://learn.microsoft.com/en-us/training/modules/populate-slowly-changing-dimensions-azure-synapse-analytics-pipelines/3-choose-between-dimension-types](https://learn.microsoft.com/en-us/training/modules/populate-slowly-changing-dimensions-azure-synapse-analytics-pipelines/3-choose-between-dimension-types)\n2. Replication Zones: [https://youtu.be/K9epl86BGOk](https://youtu.be/K9epl86BGOk)  \nAbove channel is a gold mine for this certification as well as for aspiring Azure Data Engineers. Highly recommend going through his videos, especially security, access tier and ADF ones.\n3. Window Types in Stream Analytics: [https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions](https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions)\n4. Data Masking: [https://learn.microsoft.com/en-us/azure/azure-sql/database/dynamic-data-masking-overview?view=azuresql](https://learn.microsoft.com/en-us/azure/azure-sql/database/dynamic-data-masking-overview?view=azuresql)\n\n**Section D: Final Tips for Exam**\n\n1. Do give Microsoft practice assessment. \n2. Try to navigate MS learn when studying, giving above assessment, etc. It will be useful when giving exam, you can get couple of answers by going through it.\n3. Know the answers to previously asked questions and the logic for them thoroughly.\n4. Plan how you are going to give exam. I had 41 questions and 100 minutes. I thought I'll be attempting 15 questions every 30 minutes but as it turned out most questions were from dumps so ended up marking 30 questions inside first 20 minutes :)   \nPoint is you will have lot of time if you have done the dumps thoroughly, so mark questions you are not sure about for review, and at the end go through MS learn.  \n\n\nIf anyone has any questions, feel free to reach out to me or comment here. I'll be glad to help.", "author_fullname": "t2_f86nbjeq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Study advise for DP-203 Aspirants.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap22x7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707750407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Aspirants,&lt;/p&gt;\n\n&lt;p&gt;Last week, I cleared DP-203 with 920 score after 2 weeks of studying. I have made a post about it and the resources used here: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/1andkrm/passed_dp203_last_week_details_for_aspirants_in/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;https://www.reddit.com/r/dataengineering/comments/1andkrm/passed_dp203_last_week_details_for_aspirants_in/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This will be my second and last post related to DP-203. In this post I focus on how you should go about studying as in my preparation I came across so many resources to study but no concrete plan or strategy which only led to confusion.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Section A: Build Your Knowledge Base&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Start with synapse documentation.&lt;br/&gt;\nUnderstand spark pools, difference between serverless and dedicated sql pools. Managed and external tables. Dynamic Data Masking. TDE. Row Level Security and Column Level Security.&lt;/li&gt;\n&lt;li&gt;Azure Stream Analytics documentation will be up next.&lt;br/&gt;\nBe sure to understand 5 types of windows as atleast 1 question will be on that.&lt;/li&gt;\n&lt;li&gt;Azure Data Factory Documentation&lt;/li&gt;\n&lt;li&gt;MS Learn Path&lt;br/&gt;\nSCD Types. 1 questions atleast will come on it.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Note: There is no way you are going to go through all the pages in documentations and next to impossible to remember them. My advise would be to skim through it and try to build a high level knowledge base. You do not need to be expert who knows everything.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Section B: Real Preparation Starts Here, Build Knowledge required for actual exam.&lt;/strong&gt;&lt;br/&gt;\nNote: Below two points are going to be very vital for you to pass the exam as 70-80% questions will be from Dump.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Exam Topics free questions.&lt;br/&gt;\nGo through the discussions and the links provided, this is where your best learning is going to happen. There will be some questions with divided answers and you are going to just have to trust your gut. &lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://youtu.be/0QUSK48YX04?list=PL0AYtrUw-NRQu89sbJNXPEo0dkBVTujY5\"&gt;https://youtu.be/0QUSK48YX04?list=PL0AYtrUw-NRQu89sbJNXPEo0dkBVTujY5&lt;/a&gt;&lt;br/&gt;\nGo through this video. Many questions will overlap with Exam Topics but still highly recommened watching this video as questions will come from this as well, especially the case study.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Section C: Important must-do topics&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;SCD Types: &lt;a href=\"https://learn.microsoft.com/en-us/training/modules/populate-slowly-changing-dimensions-azure-synapse-analytics-pipelines/3-choose-between-dimension-types\"&gt;https://learn.microsoft.com/en-us/training/modules/populate-slowly-changing-dimensions-azure-synapse-analytics-pipelines/3-choose-between-dimension-types&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Replication Zones: &lt;a href=\"https://youtu.be/K9epl86BGOk\"&gt;https://youtu.be/K9epl86BGOk&lt;/a&gt;&lt;br/&gt;\nAbove channel is a gold mine for this certification as well as for aspiring Azure Data Engineers. Highly recommend going through his videos, especially security, access tier and ADF ones.&lt;/li&gt;\n&lt;li&gt;Window Types in Stream Analytics: &lt;a href=\"https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions\"&gt;https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Data Masking: &lt;a href=\"https://learn.microsoft.com/en-us/azure/azure-sql/database/dynamic-data-masking-overview?view=azuresql\"&gt;https://learn.microsoft.com/en-us/azure/azure-sql/database/dynamic-data-masking-overview?view=azuresql&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Section D: Final Tips for Exam&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do give Microsoft practice assessment. &lt;/li&gt;\n&lt;li&gt;Try to navigate MS learn when studying, giving above assessment, etc. It will be useful when giving exam, you can get couple of answers by going through it.&lt;/li&gt;\n&lt;li&gt;Know the answers to previously asked questions and the logic for them thoroughly.&lt;/li&gt;\n&lt;li&gt;Plan how you are going to give exam. I had 41 questions and 100 minutes. I thought I&amp;#39;ll be attempting 15 questions every 30 minutes but as it turned out most questions were from dumps so ended up marking 30 questions inside first 20 minutes :)&lt;br/&gt;\nPoint is you will have lot of time if you have done the dumps thoroughly, so mark questions you are not sure about for review, and at the end go through MS learn.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If anyone has any questions, feel free to reach out to me or comment here. I&amp;#39;ll be glad to help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9KjfBI4bExBMA-SppEoXnyUO9JCGHQsyiH1zLRFUuxM.jpg?auto=webp&amp;s=9bbf148fcd0f0b8b6fd5549050b351928e70b845", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/9KjfBI4bExBMA-SppEoXnyUO9JCGHQsyiH1zLRFUuxM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cba2396bca6523f443570ee351863f6ce61485eb", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/9KjfBI4bExBMA-SppEoXnyUO9JCGHQsyiH1zLRFUuxM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92392c8a86e0431966f0e26cb979c564da2e37fd", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/9KjfBI4bExBMA-SppEoXnyUO9JCGHQsyiH1zLRFUuxM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=13b784ad47410ac26c659b9de5295ad6e6f32249", "width": 320, "height": 240}], "variants": {}, "id": "t-X48R81FbV2hHKHXQHfnFoap_VzKiNwCda90e43_Hs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1ap22x7", "is_robot_indexable": true, "report_reasons": null, "author": "Vikinghehe", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap22x7/study_advise_for_dp203_aspirants/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap22x7/study_advise_for_dp203_aspirants/", "subreddit_subscribers": 160411, "created_utc": 1707750407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to transition into data engineering and am looking for advice. \n\nIn a few months, I'll graduate with a PhD in physics. I've decided that staying in academia isn't for me, and thought some of my skills might translate well to data engineering. I've been applying to positions for about a month now, and haven't had any luck. I'm seeking feedback. \n\nMy research requires me to use Python to interact with datasets almost daily. I'm confident writing code for data acquisition, complex calculations, as well as data-visualization.\n\nI lack any experience with common cloud-based systems (AWS, Azure, etc). I also don't have SQL experience (although I've been learning on my own time). \n\nAre there any obvious steps I could take to get a foot in the door? Is it worth completing AWS certifications, or am I just throwing money away? \n\nAny advice would be appreciated.", "author_fullname": "t2_4ebp7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for someone trying to transition into data engineering from academia?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap269w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707750659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to transition into data engineering and am looking for advice. &lt;/p&gt;\n\n&lt;p&gt;In a few months, I&amp;#39;ll graduate with a PhD in physics. I&amp;#39;ve decided that staying in academia isn&amp;#39;t for me, and thought some of my skills might translate well to data engineering. I&amp;#39;ve been applying to positions for about a month now, and haven&amp;#39;t had any luck. I&amp;#39;m seeking feedback. &lt;/p&gt;\n\n&lt;p&gt;My research requires me to use Python to interact with datasets almost daily. I&amp;#39;m confident writing code for data acquisition, complex calculations, as well as data-visualization.&lt;/p&gt;\n\n&lt;p&gt;I lack any experience with common cloud-based systems (AWS, Azure, etc). I also don&amp;#39;t have SQL experience (although I&amp;#39;ve been learning on my own time). &lt;/p&gt;\n\n&lt;p&gt;Are there any obvious steps I could take to get a foot in the door? Is it worth completing AWS certifications, or am I just throwing money away? &lt;/p&gt;\n\n&lt;p&gt;Any advice would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ap269w", "is_robot_indexable": true, "report_reasons": null, "author": "ianmgull", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap269w/advice_for_someone_trying_to_transition_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap269w/advice_for_someone_trying_to_transition_into_data/", "subreddit_subscribers": 160411, "created_utc": 1707750659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a position open in my company I am very interested in. The salary range is significantly higher and I think i would be a good fit.\n\nAt my company, its required that I discuss it with my manager before applying and I would certainly do that if I were to apply.\n\nI would ideally like to get a feel for the position with the hiring manager and kindly ask if she/he thinks I have a chance. I am currently a Data Engineer and this would be a jump to Senior Data Engineer.\n\nHow have you approached applying for internal jobs? Do you think its a good idea to first reach out to hiring manager without telling your boss about it? Not sure if its frowned upon? I dont want to jump to conclusions, just trying to cover my back and prevent a misfire.", "author_fullname": "t2_5epqry7a5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats the proper way to apply for internal job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apip8g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707792313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a position open in my company I am very interested in. The salary range is significantly higher and I think i would be a good fit.&lt;/p&gt;\n\n&lt;p&gt;At my company, its required that I discuss it with my manager before applying and I would certainly do that if I were to apply.&lt;/p&gt;\n\n&lt;p&gt;I would ideally like to get a feel for the position with the hiring manager and kindly ask if she/he thinks I have a chance. I am currently a Data Engineer and this would be a jump to Senior Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;How have you approached applying for internal jobs? Do you think its a good idea to first reach out to hiring manager without telling your boss about it? Not sure if its frowned upon? I dont want to jump to conclusions, just trying to cover my back and prevent a misfire.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1apip8g", "is_robot_indexable": true, "report_reasons": null, "author": "liskeeksil", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apip8g/whats_the_proper_way_to_apply_for_internal_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apip8g/whats_the_proper_way_to_apply_for_internal_job/", "subreddit_subscribers": 160411, "created_utc": 1707792313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been prototyping a simple data tool for small teams. The problem I'm trying to validate is: setting up a data stack and doing basic analytics is hard for growing teams. \n\nThere are [too many moving parts](https://twitter.com/eladgil/status/1649861867576385537) (managing ingestion with Fivetran/Meltano/Airbyte, managing a warehouse, setting up Airflow, dbt, and then finally building out your model and metrics for dashboards) and this puts people off. \n\nI spoke with a few somewhat-large teams (Series A/B/C startups) and realized most data stacks are built in a rush, with poor UX for the folks building it. Essentially, teams tend to avoid building out a data stack for as long as possible. \n\nI'm trying to do a few things at the same time, so I thought I'd turn to this community for feedback. I think:\n\n1. Building a tool which spins up a warehouse (you pick between Bigquery, Redshift, Snowflake) lets you pick connectors directly (from fivetran/metlano/airbyte) and start ingesting data right away\n2. Comes with pre-built metrics layer for the most commonly used metrics (mostly marketing, sales, product metrics) \n3. You can extend by bringing in or building metrics with SQL that sync (bi-directionally) with dbt\n4. Has basic features like reporting, alerts, campaign drill-downs built into it. \n\nMy hypothesis is that this might allow small and growing teams to handle their own data needs by themselves, and once they have a data engineer onboard will still be built on top of tools they are familiar with. \n\nI'm hesitant to paste a link here, because this really isn't a promotion or shill, rather I just want to get feedback, and help think through common gotcha's. I know there are a billion tools out there that do some part of this, but I'm targeting: \n\n1. Super-modern UX (like Vercel for analytics) \n2. Go to exclusively teams that are just starting out with their data-stacks\n3. Eventually build a cheaper, better UX platform that helps you build, manage, and run anything data-related on your team\n\nOpen to your feedback here or via DMs. Would love to learn what I'm doing wrong (or right) ", "author_fullname": "t2_jds3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on building data platform as a service", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap90en", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707767288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been prototyping a simple data tool for small teams. The problem I&amp;#39;m trying to validate is: setting up a data stack and doing basic analytics is hard for growing teams. &lt;/p&gt;\n\n&lt;p&gt;There are &lt;a href=\"https://twitter.com/eladgil/status/1649861867576385537\"&gt;too many moving parts&lt;/a&gt; (managing ingestion with Fivetran/Meltano/Airbyte, managing a warehouse, setting up Airflow, dbt, and then finally building out your model and metrics for dashboards) and this puts people off. &lt;/p&gt;\n\n&lt;p&gt;I spoke with a few somewhat-large teams (Series A/B/C startups) and realized most data stacks are built in a rush, with poor UX for the folks building it. Essentially, teams tend to avoid building out a data stack for as long as possible. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to do a few things at the same time, so I thought I&amp;#39;d turn to this community for feedback. I think:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Building a tool which spins up a warehouse (you pick between Bigquery, Redshift, Snowflake) lets you pick connectors directly (from fivetran/metlano/airbyte) and start ingesting data right away&lt;/li&gt;\n&lt;li&gt;Comes with pre-built metrics layer for the most commonly used metrics (mostly marketing, sales, product metrics) &lt;/li&gt;\n&lt;li&gt;You can extend by bringing in or building metrics with SQL that sync (bi-directionally) with dbt&lt;/li&gt;\n&lt;li&gt;Has basic features like reporting, alerts, campaign drill-downs built into it. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;My hypothesis is that this might allow small and growing teams to handle their own data needs by themselves, and once they have a data engineer onboard will still be built on top of tools they are familiar with. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hesitant to paste a link here, because this really isn&amp;#39;t a promotion or shill, rather I just want to get feedback, and help think through common gotcha&amp;#39;s. I know there are a billion tools out there that do some part of this, but I&amp;#39;m targeting: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Super-modern UX (like Vercel for analytics) &lt;/li&gt;\n&lt;li&gt;Go to exclusively teams that are just starting out with their data-stacks&lt;/li&gt;\n&lt;li&gt;Eventually build a cheaper, better UX platform that helps you build, manage, and run anything data-related on your team&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Open to your feedback here or via DMs. Would love to learn what I&amp;#39;m doing wrong (or right) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gZtwRFTdTjVvN5MidYDGlbQpBxsFK2nnwxJOv5BL9D0.jpg?auto=webp&amp;s=a52b7664a0a6cdc0baabbd748e5d383577482cff", "width": 140, "height": 86}, "resolutions": [{"url": "https://external-preview.redd.it/gZtwRFTdTjVvN5MidYDGlbQpBxsFK2nnwxJOv5BL9D0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8cc7450e847783aae707948d4ddb8aee792c6808", "width": 108, "height": 66}], "variants": {}, "id": "CCMEE5mjEXNzmtN7_L3L1qiCpCkb4utxHPPcTV9mF90"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ap90en", "is_robot_indexable": true, "report_reasons": null, "author": "peekkk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap90en/feedback_on_building_data_platform_as_a_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap90en/feedback_on_building_data_platform_as_a_service/", "subreddit_subscribers": 160411, "created_utc": 1707767288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a potential for legal issues regarding intellectual property rights and the disclosure of information to the public or competitors when utilizing GenAI or PandasAI?\n\n I've come across articles indicating that one in four companies is restricting their use due to these concerns.\n\nhttps://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms\n\nIs it safe to use GenAi or PandasAi (powered by open ai) for clients data which is confidential and not suppose to leak in public??", "author_fullname": "t2_m8ka6cao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are GenAI&amp; PandasAi safe to use for confidential data ??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1appuju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707817934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a potential for legal issues regarding intellectual property rights and the disclosure of information to the public or competitors when utilizing GenAI or PandasAI?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve come across articles indicating that one in four companies is restricting their use due to these concerns.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms\"&gt;https://m.economictimes.com/tech/technology/over-1-in-4-firms-ban-genai-over-privacy-data-security-risks-report/amp_articleshow/107220444.cms&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is it safe to use GenAi or PandasAi (powered by open ai) for clients data which is confidential and not suppose to leak in public??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1appuju", "is_robot_indexable": true, "report_reasons": null, "author": "TylerTheBat", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1appuju/are_genai_pandasai_safe_to_use_for_confidential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1appuju/are_genai_pandasai_safe_to_use_for_confidential/", "subreddit_subscribers": 160411, "created_utc": 1707817934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have a task to load data from Salesforce to Snowflake using ADF. But so far I can see many people are using Blob storage for staging. So can we use ADF to copy data from Salesforce to Snowflake directly without staging data in Blob storage? because using Blog storage requires to use SaS token which my IT department is trying to avoid. #ADF #Snowflake #Salesforce #Azure #Blob", "author_fullname": "t2_hi267s7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we use ADF to copy data from Salesforce to Snowflake directly without staging data in Blob storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1apktdn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707798612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a task to load data from Salesforce to Snowflake using ADF. But so far I can see many people are using Blob storage for staging. So can we use ADF to copy data from Salesforce to Snowflake directly without staging data in Blob storage? because using Blog storage requires to use SaS token which my IT department is trying to avoid. #ADF #Snowflake #Salesforce #Azure #Blob&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1apktdn", "is_robot_indexable": true, "report_reasons": null, "author": "JK_1975", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apktdn/can_we_use_adf_to_copy_data_from_salesforce_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1apktdn/can_we_use_adf_to_copy_data_from_salesforce_to/", "subreddit_subscribers": 160411, "created_utc": 1707798612.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Previous Post](https://www.reddit.com/r/dataengineering/comments/1aj3fac/people_who_use_dbt_data_build_tool_what_are_you/)\n\n Hello DBT Enthusiasts!\n\nAfter some great discussions from my last post, I'm curious about another aspect of DBT: **DBT Packages**. I've recently gone through the package list again, after having gained significantly more experience in DBT and found the dbt\\_artifacts package that now allows me to report on our \"dbt exposures\". It provides the ability to report on things like test &amp; documentation coverage which is something I'm interested in lately.   \n\n\nI'd like to know:\n\n1. **Which DBT Packages are essential in your projects?**\n2. **Any challenges or limitations with these packages?**\n3. **Have you created custom DBT packages? If so, what prompted this?**  \n\n\nI'll go first:\n\n1. dbt\\_artifacts &amp; dbt\\_codegen most notably.\n   1. Artifacts I've explained above, and codegen is great for adding new resources like sources, models or yaml files.\n2. Sharing &amp; documenting which macros the company uses, and for what. I know this is solved by a Notion wiki or something, but that's work. \n3. No, but I did create a model that shows column-level descriptions from a dbt\\_artifacts asset. The gets extracted from dbt\\_artifacts' \"models\" table. I thought about trying to contribute it to the project myself, but it uses a db-specific function so wouldn't work for everyone.\n\nYour insights will help us all better understand the practical use of these packages and potentially inspire improvements or new creations!\n\nExcited to hear your thoughts!  \n\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_1bx2p34m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Another question for DBT Users -&gt; Who's Using DBT Packages and How?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap88lt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707765469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/1aj3fac/people_who_use_dbt_data_build_tool_what_are_you/\"&gt;Previous Post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hello DBT Enthusiasts!&lt;/p&gt;\n\n&lt;p&gt;After some great discussions from my last post, I&amp;#39;m curious about another aspect of DBT: &lt;strong&gt;DBT Packages&lt;/strong&gt;. I&amp;#39;ve recently gone through the package list again, after having gained significantly more experience in DBT and found the dbt_artifacts package that now allows me to report on our &amp;quot;dbt exposures&amp;quot;. It provides the ability to report on things like test &amp;amp; documentation coverage which is something I&amp;#39;m interested in lately.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to know:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Which DBT Packages are essential in your projects?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Any challenges or limitations with these packages?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Have you created custom DBT packages? If so, what prompted this?&lt;/strong&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ll go first:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;dbt_artifacts &amp;amp; dbt_codegen most notably.\n\n&lt;ol&gt;\n&lt;li&gt;Artifacts I&amp;#39;ve explained above, and codegen is great for adding new resources like sources, models or yaml files.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Sharing &amp;amp; documenting which macros the company uses, and for what. I know this is solved by a Notion wiki or something, but that&amp;#39;s work. &lt;/li&gt;\n&lt;li&gt;No, but I did create a model that shows column-level descriptions from a dbt_artifacts asset. The gets extracted from dbt_artifacts&amp;#39; &amp;quot;models&amp;quot; table. I thought about trying to contribute it to the project myself, but it uses a db-specific function so wouldn&amp;#39;t work for everyone.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your insights will help us all better understand the practical use of these packages and potentially inspire improvements or new creations!&lt;/p&gt;\n\n&lt;p&gt;Excited to hear your thoughts!  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ap88lt", "is_robot_indexable": true, "report_reasons": null, "author": "TheGrapez", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap88lt/another_question_for_dbt_users_whos_using_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap88lt/another_question_for_dbt_users_whos_using_dbt/", "subreddit_subscribers": 160411, "created_utc": 1707765469.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Column and table names occasionally change, sometimes on tables inside the organization we do not maintain. Our current solution is we have a piece of regex code that finds all of the GitHub repositories that use whatever field or table you are looking for and provides the code that field is in and we tell everyone to update their code based on who usually owns/works on that repo. \n\nMy supervisor doesn't like this because it is manual and wants the DE team to be responsible on fixing things when these changes occur. I don't like writing a regex replace on an entire code base because I find it tedious, prone to error, and prefer to leave coding changes up to the product owner. Am I being stubborn? Are there other ways to manage this?\n\nWe have an on-prem oracle DB, sloowwwlly moving over to snowflake, and code in python/SQL orchestrated by Airflow. \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_f1q7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing SQL Table Changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap3flw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707753939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Column and table names occasionally change, sometimes on tables inside the organization we do not maintain. Our current solution is we have a piece of regex code that finds all of the GitHub repositories that use whatever field or table you are looking for and provides the code that field is in and we tell everyone to update their code based on who usually owns/works on that repo. &lt;/p&gt;\n\n&lt;p&gt;My supervisor doesn&amp;#39;t like this because it is manual and wants the DE team to be responsible on fixing things when these changes occur. I don&amp;#39;t like writing a regex replace on an entire code base because I find it tedious, prone to error, and prefer to leave coding changes up to the product owner. Am I being stubborn? Are there other ways to manage this?&lt;/p&gt;\n\n&lt;p&gt;We have an on-prem oracle DB, sloowwwlly moving over to snowflake, and code in python/SQL orchestrated by Airflow. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ap3flw", "is_robot_indexable": true, "report_reasons": null, "author": "machinegunke11y", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap3flw/managing_sql_table_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap3flw/managing_sql_table_changes/", "subreddit_subscribers": 160411, "created_utc": 1707753939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teradata Vantage\u2122 destination now available on Airbyte Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1aptdwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Tiaut8WJbOq0L9bIRsUvKLmUIgUwE5YMJ2pEAaTH67w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707830668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/teradata/teradata-vantage-destination-now-available-on-airbyte-cloud-1eed7479e40e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?auto=webp&amp;s=e37a3e71b3f616b02118c07965c9b695c050e93b", "width": 720, "height": 378}, "resolutions": [{"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=524c6a562eaad5416a45bf286d89a1e0671c3199", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0871e1fcf68766d31dd58ea35a5a389781235418", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d9afa6e8c273da550a3984c885aa0e40100a65a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/7FHta6Xy2YCTzdDnNfh3iHNJmSXE1Bf-C8vk46s0soU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ddeaf70e6d816093cd513cb169dd1a6402ba919a", "width": 640, "height": 336}], "variants": {}, "id": "lVlFbUvlw0Jq-P3OEBBT3MD3fBTZ0fn8x73rPOj2HnU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aptdwv", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aptdwv/teradata_vantage_destination_now_available_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/teradata/teradata-vantage-destination-now-available-on-airbyte-cloud-1eed7479e40e", "subreddit_subscribers": 160411, "created_utc": 1707830668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "9 Ways to Sell Data Services to Non-Data-Savvy Clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_1apslj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/A0JigRAjDKfQXGNY4Oro-5k6nQrFh6cFehUHXWEXp1M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707828296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arch.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arch.dev/blog/9-ways-to-sell-data-services-to-non-data-savvy-clients/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?auto=webp&amp;s=dd0619d54ab73c556df67e53bb6ac4094864d9bf", "width": 1792, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ced09eb8a9e4a3558ff5343beaa73a3c4cf95a71", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c040d916e2baeb92d720295d383e8fd8ad388645", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a115173d96ec81194ae458e7f3e746ee0c97ba0a", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2be395bfeae3bd57d82d217ac91e98f681910a3f", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0face84594b4d2c0185dcc068527fd7892187676", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/sg1m91K4fH-dIPi2wAOdCdZtFofxSu61ITjrH_QgN-Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a7d0a6feb383da3ef1f272a622d20f032a50316e", "width": 1080, "height": 617}], "variants": {}, "id": "z7CoTrlLtc-r4VMaXW_ohkdRv4NYyn8ke16DqOHW03k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1apslj8", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1apslj8/9_ways_to_sell_data_services_to_nondatasavvy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arch.dev/blog/9-ways-to-sell-data-services-to-non-data-savvy-clients/", "subreddit_subscribers": 160411, "created_utc": 1707828296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\nHaving worked as a devops engineer for a while, I\u2019m a bit confused about how we use infrastructure as a code to deploy vertex ai pipelines. \n\nMy usually workflow is GitHub-PIpelines-Terraform-Infrastructure created. However this seems different with vertex ai pipelines ?", "author_fullname": "t2_93n793j1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vertex ai and code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aps4cd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707826748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Having worked as a devops engineer for a while, I\u2019m a bit confused about how we use infrastructure as a code to deploy vertex ai pipelines. &lt;/p&gt;\n\n&lt;p&gt;My usually workflow is GitHub-PIpelines-Terraform-Infrastructure created. However this seems different with vertex ai pipelines ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aps4cd", "is_robot_indexable": true, "report_reasons": null, "author": "Total_Definition_401", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aps4cd/vertex_ai_and_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aps4cd/vertex_ai_and_code/", "subreddit_subscribers": 160411, "created_utc": 1707826748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're considering transitioning to Kafka, specifically using the MSK managed service, from our current setup that involves ingesting data into an SQS FIFO queue. Our processing strategy relies on splitting the workload per message group ID, and we have around 20,000 different message group IDs in use.  \nI understand that mirroring this logic directly in Kafka by creating a partition for each message group ID might not align with best practices, especially since the volume of messages we're dealing with isn't extraordinarily high. However, adopting this approach could facilitate a smoother transition for our team.  \nCould anyone share insights on the practical upper limit for partitions in a Kafka (MSK managed) environment? Are there any significant downsides or performance implications we should be aware of when managing such a large number of partitions, particularly when the message volume doesn't necessarily justify it? Additionally, if anyone has navigated a similar transition or has alternative suggestions for handling this use case in Kafka, your advice would be greatly appreciated.", "author_fullname": "t2_4gvnzc5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Partitioning Limit in Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1appi2g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707816417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re considering transitioning to Kafka, specifically using the MSK managed service, from our current setup that involves ingesting data into an SQS FIFO queue. Our processing strategy relies on splitting the workload per message group ID, and we have around 20,000 different message group IDs in use.&lt;br/&gt;\nI understand that mirroring this logic directly in Kafka by creating a partition for each message group ID might not align with best practices, especially since the volume of messages we&amp;#39;re dealing with isn&amp;#39;t extraordinarily high. However, adopting this approach could facilitate a smoother transition for our team.&lt;br/&gt;\nCould anyone share insights on the practical upper limit for partitions in a Kafka (MSK managed) environment? Are there any significant downsides or performance implications we should be aware of when managing such a large number of partitions, particularly when the message volume doesn&amp;#39;t necessarily justify it? Additionally, if anyone has navigated a similar transition or has alternative suggestions for handling this use case in Kafka, your advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1appi2g", "is_robot_indexable": true, "report_reasons": null, "author": "Plus-Author9252", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1appi2g/partitioning_limit_in_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1appi2g/partitioning_limit_in_kafka/", "subreddit_subscribers": 160411, "created_utc": 1707816417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm currently working on a time-series classification project, comparing the performance of 30 odd algorithms. The dataset I'm working with is relatively large (\\~5Gb, \\~10000 .csv files) and as such I'm running up against the limits of my local machine; the slowest algorithm took just over 6hrs to process the entire dataset. I want to setup a remote and distributed pipeline to speed this process up, but I have very little experience with cloud computing, and honestly have no idea where to start.\n\nI'm thinking either a ECS (all the algorithms are Docker images) + EFS cluster, or setting up a HPC with SLURM will be good solutions - but I want to consult Reddit before going down the rabbithole. Thanks!", "author_fullname": "t2_cjrqj2bzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed time-series processing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aposzs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707813349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on a time-series classification project, comparing the performance of 30 odd algorithms. The dataset I&amp;#39;m working with is relatively large (~5Gb, ~10000 .csv files) and as such I&amp;#39;m running up against the limits of my local machine; the slowest algorithm took just over 6hrs to process the entire dataset. I want to setup a remote and distributed pipeline to speed this process up, but I have very little experience with cloud computing, and honestly have no idea where to start.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking either a ECS (all the algorithms are Docker images) + EFS cluster, or setting up a HPC with SLURM will be good solutions - but I want to consult Reddit before going down the rabbithole. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aposzs", "is_robot_indexable": true, "report_reasons": null, "author": "Sea_Pipe9828", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aposzs/distributed_timeseries_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aposzs/distributed_timeseries_processing/", "subreddit_subscribers": 160411, "created_utc": 1707813349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi smart people!!! \nHope this reaches someone who did something similar before\u2026 just thought I\u2019ll ask\u2026\n\nMy company sends a lot of data out and some are pipe delimited text files or .csv, excel files. \nI was approached to possibly find a in-house solution to have a file data validation tool\u2026 wanted to see what other companies or data engineers do and thought I\u2019ll ask if you don\u2019t mind\u2026 \n\nSo far some suggestions were to use JavaScript (like snowflake, but we don\u2019t use snowflake) \nIdeally we look at columns and find innapropriate dups or wrong data types,,. (Like string column having numeric/int etc\u2026) \n\nIf in house development is difficult, we are not oppose to paying for a product that worked for others that is not too expensive.\nAny advice is much appreciated!", "author_fullname": "t2_s4904u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data quality tool for extracts (txt/delimited, .csv etc\u2026)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aphgks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707788747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi smart people!!! \nHope this reaches someone who did something similar before\u2026 just thought I\u2019ll ask\u2026&lt;/p&gt;\n\n&lt;p&gt;My company sends a lot of data out and some are pipe delimited text files or .csv, excel files. \nI was approached to possibly find a in-house solution to have a file data validation tool\u2026 wanted to see what other companies or data engineers do and thought I\u2019ll ask if you don\u2019t mind\u2026 &lt;/p&gt;\n\n&lt;p&gt;So far some suggestions were to use JavaScript (like snowflake, but we don\u2019t use snowflake) \nIdeally we look at columns and find innapropriate dups or wrong data types,,. (Like string column having numeric/int etc\u2026) &lt;/p&gt;\n\n&lt;p&gt;If in house development is difficult, we are not oppose to paying for a product that worked for others that is not too expensive.\nAny advice is much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aphgks", "is_robot_indexable": true, "report_reasons": null, "author": "mg_1987", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aphgks/data_quality_tool_for_extracts_txtdelimited_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aphgks/data_quality_tool_for_extracts_txtdelimited_csv/", "subreddit_subscribers": 160411, "created_utc": 1707788747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "AWS Learning Path\n\nHello everyone,\n\nI have been preparing for the AWS Cloud Practitioner certification for about 2 weeks and I have also created an account in AWS and I am using free tier. I am the totally new in AWS but I have been almost 4 years experience in a software industry in data related positions. Mostly data scientist but lately data engineer. So, I'm familiar with the concepts. I want to improve myself on AWS.\n\nAny resources, advice or a road map would be really great. \n\nAlso, I like to get my hands dirty, so I'm open to project ideas that I can do while learning AWS.", "author_fullname": "t2_nfbsqoqx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Learning Path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap7eqf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707763465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;AWS Learning Path&lt;/p&gt;\n\n&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been preparing for the AWS Cloud Practitioner certification for about 2 weeks and I have also created an account in AWS and I am using free tier. I am the totally new in AWS but I have been almost 4 years experience in a software industry in data related positions. Mostly data scientist but lately data engineer. So, I&amp;#39;m familiar with the concepts. I want to improve myself on AWS.&lt;/p&gt;\n\n&lt;p&gt;Any resources, advice or a road map would be really great. &lt;/p&gt;\n\n&lt;p&gt;Also, I like to get my hands dirty, so I&amp;#39;m open to project ideas that I can do while learning AWS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ap7eqf", "is_robot_indexable": true, "report_reasons": null, "author": "satyriconw", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap7eqf/aws_learning_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap7eqf/aws_learning_path/", "subreddit_subscribers": 160411, "created_utc": 1707763465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have an upcoming senior data engineer interview with Atlassian. Anybody has any recent interview experience with Atlassian? If yes, please share more details about the process and questions asked. Thanks in advance!", "author_fullname": "t2_o1ex5zsz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Atlassian Senior Data Engineer interview process and questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ap6e48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707761050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have an upcoming senior data engineer interview with Atlassian. Anybody has any recent interview experience with Atlassian? If yes, please share more details about the process and questions asked. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1ap6e48", "is_robot_indexable": true, "report_reasons": null, "author": "tank3190", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ap6e48/atlassian_senior_data_engineer_interview_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ap6e48/atlassian_senior_data_engineer_interview_process/", "subreddit_subscribers": 160411, "created_utc": 1707761050.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}