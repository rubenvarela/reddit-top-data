{"kind": "Listing", "data": {"after": "t3_1b34su2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "2 YOE, 2022 CSE grad. Got placed into a data analyst job for 7.7lpa for which the tech stack is Informatica and Qliksense. My team never gave me a chance to work in Informatica projects, so I have been primarily working on just Qliksense which kills me with the shame everyday. Wanted to get SDE job, prepared for few months for it but felt like i need to achieve small goals first instead of aiming too high. Hence I changed the decision to Data engineering and preparing for it.\n\nBut currently my lead has been forcing me to get into functional domain (SAP) which is making me feel like resigning immediately. Also please note that in 2 hike cycles, I have been given only 6% and 4% hike respectively. I have considered myself a good student throughout my life and a pretty decent technical person. How do I deal with my situation now? I want to put papers and study and give interviews peacefully. But that seems not feasible since if I put papers, I still have to do functional work in my 3 months of Notice Period. How do I escape from this situation? Please help me. Please help me to get a direction. I have been thinking of putting papers everyday since last 1 year but I couldn't. This work, these people, this company just disgust me. Please advise. My current job is a waste of time and it's ruining my life.", "author_fullname": "t2_3v896k2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please help me with the urge of resigning every day. My current job is a waste of time.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2zhni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709210755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;2 YOE, 2022 CSE grad. Got placed into a data analyst job for 7.7lpa for which the tech stack is Informatica and Qliksense. My team never gave me a chance to work in Informatica projects, so I have been primarily working on just Qliksense which kills me with the shame everyday. Wanted to get SDE job, prepared for few months for it but felt like i need to achieve small goals first instead of aiming too high. Hence I changed the decision to Data engineering and preparing for it.&lt;/p&gt;\n\n&lt;p&gt;But currently my lead has been forcing me to get into functional domain (SAP) which is making me feel like resigning immediately. Also please note that in 2 hike cycles, I have been given only 6% and 4% hike respectively. I have considered myself a good student throughout my life and a pretty decent technical person. How do I deal with my situation now? I want to put papers and study and give interviews peacefully. But that seems not feasible since if I put papers, I still have to do functional work in my 3 months of Notice Period. How do I escape from this situation? Please help me. Please help me to get a direction. I have been thinking of putting papers everyday since last 1 year but I couldn&amp;#39;t. This work, these people, this company just disgust me. Please advise. My current job is a waste of time and it&amp;#39;s ruining my life.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2zhni", "is_robot_indexable": true, "report_reasons": null, "author": "pavip51", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2zhni/please_help_me_with_the_urge_of_resigning_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2zhni/please_help_me_with_the_urge_of_resigning_every/", "subreddit_subscribers": 164712, "created_utc": 1709210755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I (M20) just had a second round of 1 on 1 session for data engineer trainee in a company. \n\nI was asked to reverse a string in python and I forgot the syntax of while loop. And this one mistake just put me in a downward spiral for the entire hour of the session. So much so that once he asked me if two null values will be equal and I said no, and he asked why but I could not bring myself to be confident enough to say anything about memory addresses even after knowing about it, he asked me about indexing in database and I could only answer it in very simple terms.\n\nI feel really low right now, what can I do to improve and get better at interviewing.", "author_fullname": "t2_9pezqc7t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I bombed the interviuw and feel like the dumbest person in the world", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b34q4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709224773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I (M20) just had a second round of 1 on 1 session for data engineer trainee in a company. &lt;/p&gt;\n\n&lt;p&gt;I was asked to reverse a string in python and I forgot the syntax of while loop. And this one mistake just put me in a downward spiral for the entire hour of the session. So much so that once he asked me if two null values will be equal and I said no, and he asked why but I could not bring myself to be confident enough to say anything about memory addresses even after knowing about it, he asked me about indexing in database and I could only answer it in very simple terms.&lt;/p&gt;\n\n&lt;p&gt;I feel really low right now, what can I do to improve and get better at interviewing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b34q4i", "is_robot_indexable": true, "report_reasons": null, "author": "pmme_ur_titsandclits", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b34q4i/i_bombed_the_interviuw_and_feel_like_the_dumbest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b34q4i/i_bombed_the_interviuw_and_feel_like_the_dumbest/", "subreddit_subscribers": 164712, "created_utc": 1709224773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've spent the last ten years at a struggling consulting firm. I specialized in Pentaho. However, my firm never won any big data warehouse projects, so most of my projects were using Pentaho to make Excel spreadsheets.\n\nI stayed because I liked my coworkers and boss. Now that they're gone, I want to leave too and realized I don't have many skills but a decent sounding background since I also shadowed some big sounding projects.\n\nWhat's the best way to revive my career? I don't think Pentaho is it. Or is it? Should I focus a different low code ETL tool? Learn Python?\n\nMaybe go a different path and focus on architecture? Data modeling? Power BI?\n\nHas anyone else struggled with their YOE outpacing their skills?", "author_fullname": "t2_11kz8d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Can I Revive My Career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2jptp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709161841.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709159696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve spent the last ten years at a struggling consulting firm. I specialized in Pentaho. However, my firm never won any big data warehouse projects, so most of my projects were using Pentaho to make Excel spreadsheets.&lt;/p&gt;\n\n&lt;p&gt;I stayed because I liked my coworkers and boss. Now that they&amp;#39;re gone, I want to leave too and realized I don&amp;#39;t have many skills but a decent sounding background since I also shadowed some big sounding projects.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to revive my career? I don&amp;#39;t think Pentaho is it. Or is it? Should I focus a different low code ETL tool? Learn Python?&lt;/p&gt;\n\n&lt;p&gt;Maybe go a different path and focus on architecture? Data modeling? Power BI?&lt;/p&gt;\n\n&lt;p&gt;Has anyone else struggled with their YOE outpacing their skills?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2jptp", "is_robot_indexable": true, "report_reasons": null, "author": "nigelwiggins", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2jptp/how_can_i_revive_my_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2jptp/how_can_i_revive_my_career/", "subreddit_subscribers": 164712, "created_utc": 1709159696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been scrolling through the job postings on LinkedIn, and a lot of them have been asking for knowledge of ML with some MLOps experience. \n\nIn my current company, data engineers only work on ETLs with Airflow and some services in python.\n\nSo I was wondering if I need to properly learn ML to be a good data engineer and maybe secure the future so to say.\n", "author_fullname": "t2_75codjxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common for data engineers to have proficiency in ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2qxvx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709179180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been scrolling through the job postings on LinkedIn, and a lot of them have been asking for knowledge of ML with some MLOps experience. &lt;/p&gt;\n\n&lt;p&gt;In my current company, data engineers only work on ETLs with Airflow and some services in python.&lt;/p&gt;\n\n&lt;p&gt;So I was wondering if I need to properly learn ML to be a good data engineer and maybe secure the future so to say.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2qxvx", "is_robot_indexable": true, "report_reasons": null, "author": "UltramanQuar", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2qxvx/is_it_common_for_data_engineers_to_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2qxvx/is_it_common_for_data_engineers_to_have/", "subreddit_subscribers": 164712, "created_utc": 1709179180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently, I did a task for a company. One of the questions was to write a SQL query to get number of recurring customers (those that had a purchase in the 12 months before the current month) vs new customers based on an orders table. What I did was use 2 CTEs with subqueries inside them, something like this:\n\n    -- count recurring customers\n    with recurring_customers as (select extract(year from order_date) as year,\n                                        extract(month from order_date) as month,\n                                        count(distinct (customer_id)) as recurring_customers\n                                 from orders o1\n                                 where (select count(*)\n                                        from orders o2\n                                        where o2.customer_id = o1.customer_id\n                                          and o2.order_date &lt; o1.order_date and o2.order_date &gt; (o1.order_date  - interval '12 months') ) &gt; 0\n                                 group by 1, 2),\n    -- count all customers\n        all_customers as (\n            select extract(year from order_date) as year,\n                                        extract(month from order_date) as month,\n                                        count(distinct (customer_id)) as all_customers\n                                 from orders\n                                 group by 1,2\n        )\n    \n    select a.year, a.month, recurring_customers, all_customers,\n           coalesce(recurring_customers, 0)/cast(all_customers as decimal) from all_customers a\n    left join recurring_customers r\n    on a.year = r.year and a.month = r.month\n\nI got the feedback that using subqueries in a CTEs wasn't incorrect per se, but they found it *strange*. I guess it's bad practice, but could someone explain why? And what would be a better way to do this? Using window functions?\n\nAlso, can you recommend a good resource to learn SQL best practices and to practice SQL? I never really worked in a position where I would get much feedback on my SQL - as long as it works and executes in a reasonable amount of time, it was alright, but I'm really looking for a way to improve my skills. \n\nThank you!!", "author_fullname": "t2_14oqfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL help - why shouldn't I use subqueries inside CTEs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2y3sd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709205975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently, I did a task for a company. One of the questions was to write a SQL query to get number of recurring customers (those that had a purchase in the 12 months before the current month) vs new customers based on an orders table. What I did was use 2 CTEs with subqueries inside them, something like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;-- count recurring customers\nwith recurring_customers as (select extract(year from order_date) as year,\n                                    extract(month from order_date) as month,\n                                    count(distinct (customer_id)) as recurring_customers\n                             from orders o1\n                             where (select count(*)\n                                    from orders o2\n                                    where o2.customer_id = o1.customer_id\n                                      and o2.order_date &amp;lt; o1.order_date and o2.order_date &amp;gt; (o1.order_date  - interval &amp;#39;12 months&amp;#39;) ) &amp;gt; 0\n                             group by 1, 2),\n-- count all customers\n    all_customers as (\n        select extract(year from order_date) as year,\n                                    extract(month from order_date) as month,\n                                    count(distinct (customer_id)) as all_customers\n                             from orders\n                             group by 1,2\n    )\n\nselect a.year, a.month, recurring_customers, all_customers,\n       coalesce(recurring_customers, 0)/cast(all_customers as decimal) from all_customers a\nleft join recurring_customers r\non a.year = r.year and a.month = r.month\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I got the feedback that using subqueries in a CTEs wasn&amp;#39;t incorrect per se, but they found it &lt;em&gt;strange&lt;/em&gt;. I guess it&amp;#39;s bad practice, but could someone explain why? And what would be a better way to do this? Using window functions?&lt;/p&gt;\n\n&lt;p&gt;Also, can you recommend a good resource to learn SQL best practices and to practice SQL? I never really worked in a position where I would get much feedback on my SQL - as long as it works and executes in a reasonable amount of time, it was alright, but I&amp;#39;m really looking for a way to improve my skills. &lt;/p&gt;\n\n&lt;p&gt;Thank you!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2y3sd", "is_robot_indexable": true, "report_reasons": null, "author": "n_ex", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2y3sd/sql_help_why_shouldnt_i_use_subqueries_inside_ctes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2y3sd/sql_help_why_shouldnt_i_use_subqueries_inside_ctes/", "subreddit_subscribers": 164712, "created_utc": 1709205975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks! I am almost 9 months into my first DE job which is also my first programming job. I decided to switch to DE around 7 years after I graduated from uni and found my current job last summer.\n\nOver the past 9 months, I have helped in building 2 end to end pipelines applying both streaming and batch processing. I have also worked on a data viz project for internal use with another junior DE who joined around the same time but is much younger and a recent college grad.\n\nI am fearful that I am not pulling my weight at all even though my manager has never raised a performance issue and my two reviews so far have been quite good. I think this has something to do with me being closer in age to the mid level folks but being a rank amateur in competence compared to them. \n\nI am definitely asking for less help now and at least when I do I am able to show exactly what I did/why I did but I am keen to know what a very junior DE should be expected to do/know after 9 months. Thanks!", "author_fullname": "t2_chptq8qwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I a handicap, deadweight to my team as a junior DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2xftn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709203446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks! I am almost 9 months into my first DE job which is also my first programming job. I decided to switch to DE around 7 years after I graduated from uni and found my current job last summer.&lt;/p&gt;\n\n&lt;p&gt;Over the past 9 months, I have helped in building 2 end to end pipelines applying both streaming and batch processing. I have also worked on a data viz project for internal use with another junior DE who joined around the same time but is much younger and a recent college grad.&lt;/p&gt;\n\n&lt;p&gt;I am fearful that I am not pulling my weight at all even though my manager has never raised a performance issue and my two reviews so far have been quite good. I think this has something to do with me being closer in age to the mid level folks but being a rank amateur in competence compared to them. &lt;/p&gt;\n\n&lt;p&gt;I am definitely asking for less help now and at least when I do I am able to show exactly what I did/why I did but I am keen to know what a very junior DE should be expected to do/know after 9 months. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2xftn", "is_robot_indexable": true, "report_reasons": null, "author": "jnrdataengineer2023", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2xftn/am_i_a_handicap_deadweight_to_my_team_as_a_junior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2xftn/am_i_a_handicap_deadweight_to_my_team_as_a_junior/", "subreddit_subscribers": 164712, "created_utc": 1709203446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can someone please help me understand a use case that fits the usage of Redis? I have never worked on it just trying to understand its use cases before diving deep into it.\n\nMy friend recently went through a system design round for a company, and faced a scenario to build a system for displaying real time user count (logged in on a website) on a dashboard.\nWe were thinking of a an event based setup like kafka writing onto a nosql which renders data for dashboard.\nAnd we came to a conclusion that eventually persisting the events from queue to nosql would take all the time and defeat the solution.\n\nIs this a right use case for Redis?\n\n", "author_fullname": "t2_epbwyu83", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redis use case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2wcm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709198909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone please help me understand a use case that fits the usage of Redis? I have never worked on it just trying to understand its use cases before diving deep into it.&lt;/p&gt;\n\n&lt;p&gt;My friend recently went through a system design round for a company, and faced a scenario to build a system for displaying real time user count (logged in on a website) on a dashboard.\nWe were thinking of a an event based setup like kafka writing onto a nosql which renders data for dashboard.\nAnd we came to a conclusion that eventually persisting the events from queue to nosql would take all the time and defeat the solution.&lt;/p&gt;\n\n&lt;p&gt;Is this a right use case for Redis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b2wcm4", "is_robot_indexable": true, "report_reasons": null, "author": "gurmanavfc14", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2wcm4/redis_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2wcm4/redis_use_case/", "subreddit_subscribers": 164712, "created_utc": 1709198909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am applying for an Advertising Technology company for data engineer role and company said they'll prefer candidates who has some AdTech related data engineering projects. Any suggestions/project ideas you guys have ( plus if you can in short write a high level design description about your project idea then it'll be helpful) ", "author_fullname": "t2_umxhnmq0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want suggestions for making an AdTech related data engineering project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2rrjj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709181779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am applying for an Advertising Technology company for data engineer role and company said they&amp;#39;ll prefer candidates who has some AdTech related data engineering projects. Any suggestions/project ideas you guys have ( plus if you can in short write a high level design description about your project idea then it&amp;#39;ll be helpful) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2rrjj", "is_robot_indexable": true, "report_reasons": null, "author": "perfektenschlagggg", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2rrjj/want_suggestions_for_making_an_adtech_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2rrjj/want_suggestions_for_making_an_adtech_related/", "subreddit_subscribers": 164712, "created_utc": 1709181779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_46tlcjz3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PostgreSQL: Prevent accidental database deletion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2h27l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jv2DTODEkKIrWzAlETVfeZyIapbdI3nYmgISPkk0eEw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709153477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "telablog.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://telablog.com/postgresql-prevent-accidental-database-deletion", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?auto=webp&amp;s=975a6bcde79f529ec129d699f8409a9b286861c3", "width": 630, "height": 453}, "resolutions": [{"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aa32bb93cad95f6e2cfd72151be0bfb909066cb", "width": 108, "height": 77}, {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35712222711f2186f600b7062158da4ec1fad92a", "width": 216, "height": 155}, {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=448c26ecdb1120d348a7c7857a528381ac0aabf5", "width": 320, "height": 230}], "variants": {}, "id": "1LFo4RaOds-V5iIDcqED1C0usKQRMLUDV_VKhGkZwcI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b2h27l", "is_robot_indexable": true, "report_reasons": null, "author": "stjohn_piano", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2h27l/postgresql_prevent_accidental_database_deletion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://telablog.com/postgresql-prevent-accidental-database-deletion", "subreddit_subscribers": 164712, "created_utc": 1709153477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading [this article](https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/) from Start Data Engineering today, and saw they suggest including Make in your projects. I generally really like the Start Data Engineering content, but I guess I don't really see the clear value of Make. In my personal projects I've developed, my IaC and things like pushing new Docker containers is governed by Github Actions. \n\nIs there a lot of complex CLI work in on-the-job workflows where Make would have more value? ", "author_fullname": "t2_u7dxdkls1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common in the use of Make/Makefiles in the field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2ekwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709147712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading &lt;a href=\"https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/\"&gt;this article&lt;/a&gt; from Start Data Engineering today, and saw they suggest including Make in your projects. I generally really like the Start Data Engineering content, but I guess I don&amp;#39;t really see the clear value of Make. In my personal projects I&amp;#39;ve developed, my IaC and things like pushing new Docker containers is governed by Github Actions. &lt;/p&gt;\n\n&lt;p&gt;Is there a lot of complex CLI work in on-the-job workflows where Make would have more value? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?auto=webp&amp;s=6868d1afd30fafa653a032eb2da58622ea884d10", "width": 1707, "height": 961}, "resolutions": [{"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e21312ac131abd754219be380dab9dd9e467ba6", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab6d062abc62b7caadc8a19b44d8c000993675d5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb4f46bf53ebfa79c43faac10ced6bda3c97a7d8", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8aad3115e4ceb2e5c04e65d64a60019d2f5aa217", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fb4f67358973f94066e046ed886b376d71897eb4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4a7872abe5498e855972451d3dd12aa86ad51e81", "width": 1080, "height": 608}], "variants": {}, "id": "35-OLZXPWHZTRGzuafvdWv9VwqHqY_S4pFJfcK7yGZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b2ekwa", "is_robot_indexable": true, "report_reasons": null, "author": "SchemaScorcher", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2ekwa/how_common_in_the_use_of_makemakefiles_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2ekwa/how_common_in_the_use_of_makemakefiles_in_the/", "subreddit_subscribers": 164712, "created_utc": 1709147712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since January 31, 2024, Talend (acquired by Qlik) has been removed from the Talend Open Studio site. It's also impossible to find a version on Source forge.\n\nWho still has a copy of Talend Open Studio?", "author_fullname": "t2_634ju3is", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am looking for Talend Open Studio since it's not open source anymore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b319x2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709216028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since January 31, 2024, Talend (acquired by Qlik) has been removed from the Talend Open Studio site. It&amp;#39;s also impossible to find a version on Source forge.&lt;/p&gt;\n\n&lt;p&gt;Who still has a copy of Talend Open Studio?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b319x2", "is_robot_indexable": true, "report_reasons": null, "author": "lilbuldogz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b319x2/i_am_looking_for_talend_open_studio_since_its_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b319x2/i_am_looking_for_talend_open_studio_since_its_not/", "subreddit_subscribers": 164712, "created_utc": 1709216028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey Azure enthusiasts and data wizards! \ud83d\ude80\n\nWe've put together an **in-depth video series** designed to take your Azure Data Engineering and Analytics skills to the next level. Whether you're just starting out or looking to deepen your expertise, our playlist covers everything from **real-time analytics** to **data wrangling**, and more, using Azure's powerful suite of services.\n\n**Here's a sneak peek of what you'll find:**\n\n1. **Twitter Sentiment Analysis with Azure Synapse Analytics** \\- Dive into real-time sentiment analysis and build end-to-end big data pipelines.\n2. **Real-time Vehicle Telemetry Processing** \\- Learn how to handle real-time vehicle data with Azure Stream Analytics and Event Hub.\n3. **Fraudulent Call Detection** \\- Discover how to detect fraudulent calls in real-time using Azure Stream Analytics.\n4. **Weather Forecasting with Azure IoT Hub** \\- Explore how to forecast weather using sensor data from Azure IoT Hub and Machine Learning Studio.\n5. **Web Scraping with Azure Synapse** \\- Get hands-on with web scraping using Azure Synapse, Python, and Spark Pool.\n6. ... and much more across 20+ videos covering Azure Databricks, Azure Data Factory, and other Azure services.\n\n**Why check out our playlist?**\n\n* **Varied Topics**: From analytics to processing, explore Azure's capabilities through practical examples.\n* **Skill Levels**: Content tailored for both beginners and experienced professionals.\n* **Community Support**: Join our growing community, share your progress, and get support from fellow Azure learners.\n\nDive in now and start transforming data into actionable insights with Azure! Check out our playlist\n\n[https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0](https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0)\n\n**What's your biggest challenge with Azure or data engineering/analytics?** Let's discuss in the comments below!", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlock the Full Potential of Azure for Data Engineering and Analytics with Our Comprehensive Video Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2tcev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709186992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Azure enthusiasts and data wizards! \ud83d\ude80&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve put together an &lt;strong&gt;in-depth video series&lt;/strong&gt; designed to take your Azure Data Engineering and Analytics skills to the next level. Whether you&amp;#39;re just starting out or looking to deepen your expertise, our playlist covers everything from &lt;strong&gt;real-time analytics&lt;/strong&gt; to &lt;strong&gt;data wrangling&lt;/strong&gt;, and more, using Azure&amp;#39;s powerful suite of services.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s a sneak peek of what you&amp;#39;ll find:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Twitter Sentiment Analysis with Azure Synapse Analytics&lt;/strong&gt; - Dive into real-time sentiment analysis and build end-to-end big data pipelines.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Real-time Vehicle Telemetry Processing&lt;/strong&gt; - Learn how to handle real-time vehicle data with Azure Stream Analytics and Event Hub.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fraudulent Call Detection&lt;/strong&gt; - Discover how to detect fraudulent calls in real-time using Azure Stream Analytics.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Weather Forecasting with Azure IoT Hub&lt;/strong&gt; - Explore how to forecast weather using sensor data from Azure IoT Hub and Machine Learning Studio.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Web Scraping with Azure Synapse&lt;/strong&gt; - Get hands-on with web scraping using Azure Synapse, Python, and Spark Pool.&lt;/li&gt;\n&lt;li&gt;... and much more across 20+ videos covering Azure Databricks, Azure Data Factory, and other Azure services.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Why check out our playlist?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Varied Topics&lt;/strong&gt;: From analytics to processing, explore Azure&amp;#39;s capabilities through practical examples.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Skill Levels&lt;/strong&gt;: Content tailored for both beginners and experienced professionals.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Community Support&lt;/strong&gt;: Join our growing community, share your progress, and get support from fellow Azure learners.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Dive in now and start transforming data into actionable insights with Azure! Check out our playlist&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0\"&gt;https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s your biggest challenge with Azure or data engineering/analytics?&lt;/strong&gt; Let&amp;#39;s discuss in the comments below!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/i77eGnJm5EfFhj2Iq4lTkoc5z9v72OpTXOO4rMMBP_4.jpg?auto=webp&amp;s=d77ea717953685723e11d432a03b8e1a193364f2", "width": 168, "height": 94}, "resolutions": [{"url": "https://external-preview.redd.it/i77eGnJm5EfFhj2Iq4lTkoc5z9v72OpTXOO4rMMBP_4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c44d70afc0a3160f83b7d53dfc53e12f46edea0e", "width": 108, "height": 60}], "variants": {}, "id": "ljaxuQA5RXlRP1KI4q0RlFon2Axy4tPxeCMyfteBtAg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b2tcev", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2tcev/unlock_the_full_potential_of_azure_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2tcev/unlock_the_full_potential_of_azure_for_data/", "subreddit_subscribers": 164712, "created_utc": 1709186992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All. I am an engineering fresh graduate and am trying to learn about different big data technologies. I want to create a project to put on my portfolio, but I am quite confused about different tools. This workflow is what I am thinking:\n\nStep 1: Calling financial data API / Google Trend from Python running on local laptop\n\nStep 2: Sending above data to Kafka topics hosted on EC2\n\nStep 3: Subscribing to the topics from pyspark and carry out stream transformation and aggregation\n\nStep 4: Streaming the results to Snowflake for more analysis and visualization\n\nSo firstly, I feel that I am just using Kafka as a pub-sub service, and pyspark as another version of pandas. Even if I get all these to work, I am not confident that I can work with \"big\" data. What else should I learn about these tools. Are they supposed to just work when deployed to an auto-scaling compute cluster?\n\nAnd secondly, is this what you would see in real-life application?\n\nWould love suggestions on what to learn and changes to make. Thanks in advance!", "author_fullname": "t2_jcn6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning about big data techs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2qijg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709187233.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709177865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. I am an engineering fresh graduate and am trying to learn about different big data technologies. I want to create a project to put on my portfolio, but I am quite confused about different tools. This workflow is what I am thinking:&lt;/p&gt;\n\n&lt;p&gt;Step 1: Calling financial data API / Google Trend from Python running on local laptop&lt;/p&gt;\n\n&lt;p&gt;Step 2: Sending above data to Kafka topics hosted on EC2&lt;/p&gt;\n\n&lt;p&gt;Step 3: Subscribing to the topics from pyspark and carry out stream transformation and aggregation&lt;/p&gt;\n\n&lt;p&gt;Step 4: Streaming the results to Snowflake for more analysis and visualization&lt;/p&gt;\n\n&lt;p&gt;So firstly, I feel that I am just using Kafka as a pub-sub service, and pyspark as another version of pandas. Even if I get all these to work, I am not confident that I can work with &amp;quot;big&amp;quot; data. What else should I learn about these tools. Are they supposed to just work when deployed to an auto-scaling compute cluster?&lt;/p&gt;\n\n&lt;p&gt;And secondly, is this what you would see in real-life application?&lt;/p&gt;\n\n&lt;p&gt;Would love suggestions on what to learn and changes to make. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2qijg", "is_robot_indexable": true, "report_reasons": null, "author": "hyyyyyyyyy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2qijg/learning_about_big_data_techs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2qijg/learning_about_big_data_techs/", "subreddit_subscribers": 164712, "created_utc": 1709177865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New library out of airbyte - [\u201cPyAirbyte\u201d](https://docs.airbyte.com/using-airbyte/pyairbyte/getting-started). Excited to use airbyte connectors without a UI or platform, I generally stick to writing scripts over no-code tools\n\n&amp;#x200B;\n\nDo you think you will try this in your ELT/ETL pipelines? ", "author_fullname": "t2_5h5nqi7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python library for ELT pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b36rlx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709229680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New library out of airbyte - &lt;a href=\"https://docs.airbyte.com/using-airbyte/pyairbyte/getting-started\"&gt;\u201cPyAirbyte\u201d&lt;/a&gt;. Excited to use airbyte connectors without a UI or platform, I generally stick to writing scripts over no-code tools&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you think you will try this in your ELT/ETL pipelines? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b36rlx", "is_robot_indexable": true, "report_reasons": null, "author": "Chemical-Treat6596", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b36rlx/python_library_for_elt_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b36rlx/python_library_for_elt_pipelines/", "subreddit_subscribers": 164712, "created_utc": 1709229680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If DuckDb and dbt snapshot had a baby", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1b34lag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rfI1t9OkvDrHhQj1mW6PkEO7O6ES-_zHhH85_PMj4mM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709224443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/okfy1mrnxjlc1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?format=png8&amp;s=f3d0d3774f848b3e4b122db9c8cd8008ac461bdf", "width": 800, "height": 600}, "resolutions": [{"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=6bc4f5d39365b9ddf2279d6ea8c92df6af0e92f6", "width": 108, "height": 81}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=eb2aa40846c0019b47d166889b9ec31d32fdcff5", "width": 216, "height": 162}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=4b7cd4a7b5ee25bbc1a561596df48a28a62ddcdf", "width": 320, "height": 240}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=52594cbe54fc43cae1a99189591fc41dc846f7c9", "width": 640, "height": 480}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?s=0987419796f35c807cdb61548584e7f30bb35ddd", "width": 800, "height": 600}, "resolutions": [{"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=108&amp;crop=smart&amp;s=59b599f6c8db7ea6685f94bf6c2c65cec9aa0f21", "width": 108, "height": 81}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=216&amp;crop=smart&amp;s=e331c2813a0adb69c01f1eb15e7e256971ed22a8", "width": 216, "height": 162}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=320&amp;crop=smart&amp;s=05e952f2124949eed70113c7a3be6e5b5a45a61f", "width": 320, "height": 240}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=640&amp;crop=smart&amp;s=d33c572e19921ecb002d0f18879666e7bac284bc", "width": 640, "height": 480}]}, "mp4": {"source": {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?format=mp4&amp;s=c96cfcf49b8c716100ce1ae504ec48c77b76ddbb", "width": 800, "height": 600}, "resolutions": [{"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=108&amp;format=mp4&amp;s=6e6734053a2d5f0a1e50bb2874aa88120d83c762", "width": 108, "height": 81}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=216&amp;format=mp4&amp;s=ba5786607830da36758615226237902bd0283279", "width": 216, "height": 162}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=320&amp;format=mp4&amp;s=ef67fc499fc4717eb3545379ab25c6560d7de420", "width": 320, "height": 240}, {"url": "https://preview.redd.it/okfy1mrnxjlc1.gif?width=640&amp;format=mp4&amp;s=8d5fcc65a1666f8bd84dfc24f903380ab01084fe", "width": 640, "height": 480}]}}, "id": "UklnMD9hFtQNuBI9rsBdDxN5wSNZjBccH9s7WJ4tHBk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1b34lag", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b34lag/if_duckdb_and_dbt_snapshot_had_a_baby/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/okfy1mrnxjlc1.gif", "subreddit_subscribers": 164712, "created_utc": 1709224443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to stream the changes made in my Postgresql DB using Debezium and Kafka. This is my connector configuration(pic 1)\n\nThe connector is created and I am able to consume the changes in Jupyter notebook using my Kafka consumer. But I am only getting the row data that was inserted or updated(pic 2). I am not able to get the operation that was performed(whether it was INSERT or UPDATE). Is there a way to get the operation performed data as well? also is it possible to get other operations data like TRUNCATE,DROP,ALTER because WAL logs store these information(pic 3- you can see the delete operation being logged but this doesnt get consumed by kafka).", "author_fullname": "t2_d37wcj6i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting additional data from Debezium connector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2xs94", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709204772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to stream the changes made in my Postgresql DB using Debezium and Kafka. This is my connector configuration(pic 1)&lt;/p&gt;\n\n&lt;p&gt;The connector is created and I am able to consume the changes in Jupyter notebook using my Kafka consumer. But I am only getting the row data that was inserted or updated(pic 2). I am not able to get the operation that was performed(whether it was INSERT or UPDATE). Is there a way to get the operation performed data as well? also is it possible to get other operations data like TRUNCATE,DROP,ALTER because WAL logs store these information(pic 3- you can see the delete operation being logged but this doesnt get consumed by kafka).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2xs94", "is_robot_indexable": true, "report_reasons": null, "author": "Minute-Internal5628", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2xs94/getting_additional_data_from_debezium_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2xs94/getting_additional_data_from_debezium_connector/", "subreddit_subscribers": 164712, "created_utc": 1709204772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, everyone. I have question like this. I am trying to build datalake house with some components such as, Minio as a object storage, dreamio as SQL engine.  Requirements are like below;  \n\n\n* Migrate some tables (not high volume tables) from MSSQL to Minio, so we can simply join these tables with Dreamio and query these tables. This part is not the problematic. I already migrated all tables to Minio bucket with the help of Apache Spark.   \n\n\nProblem: Now, I need to bring only incremental changes to Minio. I think the way it can be done is Airbyte using enabled CDC on MSSQL to S3 (Minio bucket) connector. Lets say, one row got updated on source Sink (mssql) and CDC captured this change, and my airbyte job also migrated this incremental change as file to bucket. But then how can I implement this change to files there, so dreamio tables can also reflect these changes on tables. Source operations are insert, update, delete. Maybe someone will recommend to overwrite everything each time. So all the time there will be updated data. But I dont want to put this kind of strain, instead I want to use incremental changes. Is there anybody has idea about this ?", "author_fullname": "t2_m2wfe4pj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datalakehouse pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2wlrw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709199990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, everyone. I have question like this. I am trying to build datalake house with some components such as, Minio as a object storage, dreamio as SQL engine.  Requirements are like below;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Migrate some tables (not high volume tables) from MSSQL to Minio, so we can simply join these tables with Dreamio and query these tables. This part is not the problematic. I already migrated all tables to Minio bucket with the help of Apache Spark.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Problem: Now, I need to bring only incremental changes to Minio. I think the way it can be done is Airbyte using enabled CDC on MSSQL to S3 (Minio bucket) connector. Lets say, one row got updated on source Sink (mssql) and CDC captured this change, and my airbyte job also migrated this incremental change as file to bucket. But then how can I implement this change to files there, so dreamio tables can also reflect these changes on tables. Source operations are insert, update, delete. Maybe someone will recommend to overwrite everything each time. So all the time there will be updated data. But I dont want to put this kind of strain, instead I want to use incremental changes. Is there anybody has idea about this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b2wlrw", "is_robot_indexable": true, "report_reasons": null, "author": "Over_Ad_6186", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2wlrw/datalakehouse_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2wlrw/datalakehouse_pipeline/", "subreddit_subscribers": 164712, "created_utc": 1709199990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wanna do Microsoft Azure associate data engineer certification DP-203. How is Alan Rodrigues's course on udemy for exam preparation for extreme newbie in data engineering. \n\nEdit - Also as a fresher applying for data engineering roles is this certification worth it?", "author_fullname": "t2_umxhnmq0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanna do Microsoft Azure associate data engineer certification DP-203. How is Alan Rodrigues's course on udemy for exam preparation for extreme newbie in data engineering. ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2us18", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709192627.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709192364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanna do Microsoft Azure associate data engineer certification DP-203. How is Alan Rodrigues&amp;#39;s course on udemy for exam preparation for extreme newbie in data engineering. &lt;/p&gt;\n\n&lt;p&gt;Edit - Also as a fresher applying for data engineering roles is this certification worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2us18", "is_robot_indexable": true, "report_reasons": null, "author": "perfektenschlagggg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2us18/wanna_do_microsoft_azure_associate_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2us18/wanna_do_microsoft_azure_associate_data_engineer/", "subreddit_subscribers": 164712, "created_utc": 1709192364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to compile a resource for the best open source databases. \n\n**Here is what I have so far:**\n\n* [https://www.starrocks.io/](https://www.starrocks.io/)\n* duckdb\n* postgresql\n* clickhouse\n\nWhat are others that you would consider the best and why? \n\nThanks!", "author_fullname": "t2_fosm1pwyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best open source databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2l5oe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709163080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to compile a resource for the best open source databases. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is what I have so far:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.starrocks.io/\"&gt;https://www.starrocks.io/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;duckdb&lt;/li&gt;\n&lt;li&gt;postgresql&lt;/li&gt;\n&lt;li&gt;clickhouse&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What are others that you would consider the best and why? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2l5oe", "is_robot_indexable": true, "report_reasons": null, "author": "Data-Queen-Mayra", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2l5oe/best_open_source_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2l5oe/best_open_source_databases/", "subreddit_subscribers": 164712, "created_utc": 1709163080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nToday I am working on a data pipeline where my ingestion-app processes realtime network traffic from multiple sources and writes into a Kafka bus in JSON format to be consumed by multiple endpoints. Apart from realtime processing I need to store a copy of it for future  processing/analysis.\n\nI was wondering which db would be the better option for offline consumption as the data is huge (atleast 10-20 TB per month) from more than 1000 nodes. I came across different demos where clickhouse or elastic search is used as final resting place or storage of network traffic and then grafana is used for visualization. \n\nI am not an elastic search expert but I feel it is a search engine capable of indexing string data. But can I retrieve the same data in future for further processing? Since Network traffic is timeseries data is elastic search good for this?\n\nAny suggestions based on your experience would be of great help\n\n&amp;#x200B;", "author_fullname": "t2_a0gdmw2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage of network traffic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2kluj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709161760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;Today I am working on a data pipeline where my ingestion-app processes realtime network traffic from multiple sources and writes into a Kafka bus in JSON format to be consumed by multiple endpoints. Apart from realtime processing I need to store a copy of it for future  processing/analysis.&lt;/p&gt;\n\n&lt;p&gt;I was wondering which db would be the better option for offline consumption as the data is huge (atleast 10-20 TB per month) from more than 1000 nodes. I came across different demos where clickhouse or elastic search is used as final resting place or storage of network traffic and then grafana is used for visualization. &lt;/p&gt;\n\n&lt;p&gt;I am not an elastic search expert but I feel it is a search engine capable of indexing string data. But can I retrieve the same data in future for further processing? Since Network traffic is timeseries data is elastic search good for this?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions based on your experience would be of great help&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2kluj", "is_robot_indexable": true, "report_reasons": null, "author": "LobsterMost5947", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2kluj/storage_of_network_traffic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2kluj/storage_of_network_traffic/", "subreddit_subscribers": 164712, "created_utc": 1709161760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to create a mapping table which would contain hased value of my primary key .\n\nOnce the data gets inside the snowflake , before it stored to table a proc shall be able to hash the values for all columns which are tagged as pii.\nThis hashed value shall be used in all transformation and when this data gets out of snowflake  want to change it back to original value using the mapping table.\nEg. Below data to be ingested in target_table \nId1| type|id2|type|\n1234@abc.com|email|987654321|phone.\n\n\nSo basically id1 and id2 shall be stored in mapping table along with their hased value and type(for cluster) ,and it's hashed value shall be stored in target _table.\n\nOne way of doing it is \nCreate a mapping table cluster by pii type .\nProc1 : to check into mapping table , if the I'd exists,if not then insert the I'd value along with type and it's hashed value .\nProc2 : to join the outlying data with mapping table and convert the id1 and id2 into it's hashed version.\n\n\nBut this solution is not scaleable. What I mean is if my mapping  table  size is huge like 100 billion records , the join operation takes too much time .\n", "author_fullname": "t2_a3fustvg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake virtualization table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2g1os", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709151138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to create a mapping table which would contain hased value of my primary key .&lt;/p&gt;\n\n&lt;p&gt;Once the data gets inside the snowflake , before it stored to table a proc shall be able to hash the values for all columns which are tagged as pii.\nThis hashed value shall be used in all transformation and when this data gets out of snowflake  want to change it back to original value using the mapping table.\nEg. Below data to be ingested in target_table \nId1| type|id2|type|\n&lt;a href=\"mailto:1234@abc.com\"&gt;1234@abc.com&lt;/a&gt;|email|987654321|phone.&lt;/p&gt;\n\n&lt;p&gt;So basically id1 and id2 shall be stored in mapping table along with their hased value and type(for cluster) ,and it&amp;#39;s hashed value shall be stored in target _table.&lt;/p&gt;\n\n&lt;p&gt;One way of doing it is \nCreate a mapping table cluster by pii type .\nProc1 : to check into mapping table , if the I&amp;#39;d exists,if not then insert the I&amp;#39;d value along with type and it&amp;#39;s hashed value .\nProc2 : to join the outlying data with mapping table and convert the id1 and id2 into it&amp;#39;s hashed version.&lt;/p&gt;\n\n&lt;p&gt;But this solution is not scaleable. What I mean is if my mapping  table  size is huge like 100 billion records , the join operation takes too much time .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2g1os", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Ad4657", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2g1os/snowflake_virtualization_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2g1os/snowflake_virtualization_table/", "subreddit_subscribers": 164712, "created_utc": 1709151138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, havent seen any info on this, so perhaps its very dumb idea... would it make sense to run Polars on Databricks, using single node clusters.?\n\nReasoning being,... trying to get the advantages/features of databricks while at the same time using a small single node cluster with Polars instead of Spark/Pyspark to process data.   any opinions?\n\n", "author_fullname": "t2_3laxwg3l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars on Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b37ca1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709231087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, havent seen any info on this, so perhaps its very dumb idea... would it make sense to run Polars on Databricks, using single node clusters.?&lt;/p&gt;\n\n&lt;p&gt;Reasoning being,... trying to get the advantages/features of databricks while at the same time using a small single node cluster with Polars instead of Spark/Pyspark to process data.   any opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b37ca1", "is_robot_indexable": true, "report_reasons": null, "author": "acelisalas", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b37ca1/polars_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b37ca1/polars_on_databricks/", "subreddit_subscribers": 164712, "created_utc": 1709231087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do companies in healthcare or climate tech hire data or distributed systems engineers?\n\nAre these jobs fulfilling careers? Are the people well renumerated.", "author_fullname": "t2_vqjalmbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer jobs in healthcare or climate tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b374j2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709230558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do companies in healthcare or climate tech hire data or distributed systems engineers?&lt;/p&gt;\n\n&lt;p&gt;Are these jobs fulfilling careers? Are the people well renumerated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b374j2", "is_robot_indexable": true, "report_reasons": null, "author": "diego-the-tortoise", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b374j2/data_engineer_jobs_in_healthcare_or_climate_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b374j2/data_engineer_jobs_in_healthcare_or_climate_tech/", "subreddit_subscribers": 164712, "created_utc": 1709230558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to transfer the 365 data through api from 365 to big query, what would be the effective way to do this process !? Any suggestions ", "author_fullname": "t2_9r5qrevk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft 365 business central to big query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b34y1i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709225319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to transfer the 365 data through api from 365 to big query, what would be the effective way to do this process !? Any suggestions &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b34y1i", "is_robot_indexable": true, "report_reasons": null, "author": "Fabro_vaz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b34y1i/microsoft_365_business_central_to_big_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b34y1i/microsoft_365_business_central_to_big_query/", "subreddit_subscribers": 164712, "created_utc": 1709225319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I think I already know the answer to this, but just checking here as a last ditch attempt. \n\nI am working on a pipeline that eventually ends up depositing production data into a parquet-based data lake (delta lake actually for all that matters) hosted on ADLS2. One of the columns contains long strings of sensitive client data. My default position is that this data should be encrypted, as it would potentially be a disaster if it was compromised and I don't trust \"walled behind Azure's security\" to be sufficient protection against leaks.\n\nI also have stakeholders who would like this data to be filterable via the content of these strings, i.e. `SELECT * FROM table WHERE encrypted_column like '%you know what an sql query looks like%';`. Is it possible to fulfil this request? It doesn't matter if the query ends up taking a very long time, just whether it's possible without coding a whole new query engine. Otherwise, am I being unreasonable in thinking that I need to be encrypting these columns when the lake itself will be managed by IAM?", "author_fullname": "t2_qid87sfh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filtering on Encrypted Parquet Columns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b34su2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709224959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I think I already know the answer to this, but just checking here as a last ditch attempt. &lt;/p&gt;\n\n&lt;p&gt;I am working on a pipeline that eventually ends up depositing production data into a parquet-based data lake (delta lake actually for all that matters) hosted on ADLS2. One of the columns contains long strings of sensitive client data. My default position is that this data should be encrypted, as it would potentially be a disaster if it was compromised and I don&amp;#39;t trust &amp;quot;walled behind Azure&amp;#39;s security&amp;quot; to be sufficient protection against leaks.&lt;/p&gt;\n\n&lt;p&gt;I also have stakeholders who would like this data to be filterable via the content of these strings, i.e. &lt;code&gt;SELECT * FROM table WHERE encrypted_column like &amp;#39;%you know what an sql query looks like%&amp;#39;;&lt;/code&gt;. Is it possible to fulfil this request? It doesn&amp;#39;t matter if the query ends up taking a very long time, just whether it&amp;#39;s possible without coding a whole new query engine. Otherwise, am I being unreasonable in thinking that I need to be encrypting these columns when the lake itself will be managed by IAM?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b34su2", "is_robot_indexable": true, "report_reasons": null, "author": "Alwaysragestillplay", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b34su2/filtering_on_encrypted_parquet_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b34su2/filtering_on_encrypted_parquet_columns/", "subreddit_subscribers": 164712, "created_utc": 1709224959.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}