{"kind": "Listing", "data": {"after": "t3_1b3d7m0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I (M20) just had a second round of 1 on 1 session for data engineer trainee in a company. \n\nI was asked to reverse a string in python and I forgot the syntax of while loop. And this one mistake just put me in a downward spiral for the entire hour of the session. So much so that once he asked me if two null values will be equal and I said no, and he asked why but I could not bring myself to be confident enough to say anything about memory addresses even after knowing about it, he asked me about indexing in database and I could only answer it in very simple terms.\n\nI feel really low right now, what can I do to improve and get better at interviewing.", "author_fullname": "t2_9pezqc7t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I bombed the interviuw and feel like the dumbest person in the world", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b34q4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709224773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I (M20) just had a second round of 1 on 1 session for data engineer trainee in a company. &lt;/p&gt;\n\n&lt;p&gt;I was asked to reverse a string in python and I forgot the syntax of while loop. And this one mistake just put me in a downward spiral for the entire hour of the session. So much so that once he asked me if two null values will be equal and I said no, and he asked why but I could not bring myself to be confident enough to say anything about memory addresses even after knowing about it, he asked me about indexing in database and I could only answer it in very simple terms.&lt;/p&gt;\n\n&lt;p&gt;I feel really low right now, what can I do to improve and get better at interviewing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b34q4i", "is_robot_indexable": true, "report_reasons": null, "author": "pmme_ur_titsandclits", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b34q4i/i_bombed_the_interviuw_and_feel_like_the_dumbest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b34q4i/i_bombed_the_interviuw_and_feel_like_the_dumbest/", "subreddit_subscribers": 164761, "created_utc": 1709224773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "2 YOE, 2022 CSE grad. Got placed into a data analyst job for 7.7lpa for which the tech stack is Informatica and Qliksense. My team never gave me a chance to work in Informatica projects, so I have been primarily working on just Qliksense which kills me with the shame everyday. Wanted to get SDE job, prepared for few months for it but felt like i need to achieve small goals first instead of aiming too high. Hence I changed the decision to Data engineering and preparing for it.\n\nBut currently my lead has been forcing me to get into functional domain (SAP) which is making me feel like resigning immediately. Also please note that in 2 hike cycles, I have been given only 6% and 4% hike respectively. I have considered myself a good student throughout my life and a pretty decent technical person. How do I deal with my situation now? I want to put papers and study and give interviews peacefully. But that seems not feasible since if I put papers, I still have to do functional work in my 3 months of Notice Period. How do I escape from this situation? Please help me. Please help me to get a direction. I have been thinking of putting papers everyday since last 1 year but I couldn't. This work, these people, this company just disgust me. Please advise. My current job is a waste of time and it's ruining my life.", "author_fullname": "t2_3v896k2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please help me with the urge of resigning every day. My current job is a waste of time.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2zhni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709210755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;2 YOE, 2022 CSE grad. Got placed into a data analyst job for 7.7lpa for which the tech stack is Informatica and Qliksense. My team never gave me a chance to work in Informatica projects, so I have been primarily working on just Qliksense which kills me with the shame everyday. Wanted to get SDE job, prepared for few months for it but felt like i need to achieve small goals first instead of aiming too high. Hence I changed the decision to Data engineering and preparing for it.&lt;/p&gt;\n\n&lt;p&gt;But currently my lead has been forcing me to get into functional domain (SAP) which is making me feel like resigning immediately. Also please note that in 2 hike cycles, I have been given only 6% and 4% hike respectively. I have considered myself a good student throughout my life and a pretty decent technical person. How do I deal with my situation now? I want to put papers and study and give interviews peacefully. But that seems not feasible since if I put papers, I still have to do functional work in my 3 months of Notice Period. How do I escape from this situation? Please help me. Please help me to get a direction. I have been thinking of putting papers everyday since last 1 year but I couldn&amp;#39;t. This work, these people, this company just disgust me. Please advise. My current job is a waste of time and it&amp;#39;s ruining my life.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2zhni", "is_robot_indexable": true, "report_reasons": null, "author": "pavip51", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2zhni/please_help_me_with_the_urge_of_resigning_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2zhni/please_help_me_with_the_urge_of_resigning_every/", "subreddit_subscribers": 164761, "created_utc": 1709210755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently, I did a task for a company. One of the questions was to write a SQL query to get number of recurring customers (those that had a purchase in the 12 months before the current month) vs new customers based on an orders table. What I did was use 2 CTEs with subqueries inside them, something like this:\n\n    -- count recurring customers\n    with recurring_customers as (select extract(year from order_date) as year,\n                                        extract(month from order_date) as month,\n                                        count(distinct (customer_id)) as recurring_customers\n                                 from orders o1\n                                 where (select count(*)\n                                        from orders o2\n                                        where o2.customer_id = o1.customer_id\n                                          and o2.order_date &lt; o1.order_date and o2.order_date &gt; (o1.order_date  - interval '12 months') ) &gt; 0\n                                 group by 1, 2),\n    -- count all customers\n        all_customers as (\n            select extract(year from order_date) as year,\n                                        extract(month from order_date) as month,\n                                        count(distinct (customer_id)) as all_customers\n                                 from orders\n                                 group by 1,2\n        )\n    \n    select a.year, a.month, recurring_customers, all_customers,\n           coalesce(recurring_customers, 0)/cast(all_customers as decimal) from all_customers a\n    left join recurring_customers r\n    on a.year = r.year and a.month = r.month\n\nI got the feedback that using subqueries in a CTEs wasn't incorrect per se, but they found it *strange*. I guess it's bad practice, but could someone explain why? And what would be a better way to do this? Using window functions?\n\nAlso, can you recommend a good resource to learn SQL best practices and to practice SQL? I never really worked in a position where I would get much feedback on my SQL - as long as it works and executes in a reasonable amount of time, it was alright, but I'm really looking for a way to improve my skills. \n\nThank you!!", "author_fullname": "t2_14oqfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL help - why shouldn't I use subqueries inside CTEs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2y3sd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709205975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently, I did a task for a company. One of the questions was to write a SQL query to get number of recurring customers (those that had a purchase in the 12 months before the current month) vs new customers based on an orders table. What I did was use 2 CTEs with subqueries inside them, something like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;-- count recurring customers\nwith recurring_customers as (select extract(year from order_date) as year,\n                                    extract(month from order_date) as month,\n                                    count(distinct (customer_id)) as recurring_customers\n                             from orders o1\n                             where (select count(*)\n                                    from orders o2\n                                    where o2.customer_id = o1.customer_id\n                                      and o2.order_date &amp;lt; o1.order_date and o2.order_date &amp;gt; (o1.order_date  - interval &amp;#39;12 months&amp;#39;) ) &amp;gt; 0\n                             group by 1, 2),\n-- count all customers\n    all_customers as (\n        select extract(year from order_date) as year,\n                                    extract(month from order_date) as month,\n                                    count(distinct (customer_id)) as all_customers\n                             from orders\n                             group by 1,2\n    )\n\nselect a.year, a.month, recurring_customers, all_customers,\n       coalesce(recurring_customers, 0)/cast(all_customers as decimal) from all_customers a\nleft join recurring_customers r\non a.year = r.year and a.month = r.month\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I got the feedback that using subqueries in a CTEs wasn&amp;#39;t incorrect per se, but they found it &lt;em&gt;strange&lt;/em&gt;. I guess it&amp;#39;s bad practice, but could someone explain why? And what would be a better way to do this? Using window functions?&lt;/p&gt;\n\n&lt;p&gt;Also, can you recommend a good resource to learn SQL best practices and to practice SQL? I never really worked in a position where I would get much feedback on my SQL - as long as it works and executes in a reasonable amount of time, it was alright, but I&amp;#39;m really looking for a way to improve my skills. &lt;/p&gt;\n\n&lt;p&gt;Thank you!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2y3sd", "is_robot_indexable": true, "report_reasons": null, "author": "n_ex", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2y3sd/sql_help_why_shouldnt_i_use_subqueries_inside_ctes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2y3sd/sql_help_why_shouldnt_i_use_subqueries_inside_ctes/", "subreddit_subscribers": 164761, "created_utc": 1709205975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been scrolling through the job postings on LinkedIn, and a lot of them have been asking for knowledge of ML with some MLOps experience. \n\nIn my current company, data engineers only work on ETLs with Airflow and some services in python.\n\nSo I was wondering if I need to properly learn ML to be a good data engineer and maybe secure the future so to say.\n", "author_fullname": "t2_75codjxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common for data engineers to have proficiency in ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2qxvx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709179180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been scrolling through the job postings on LinkedIn, and a lot of them have been asking for knowledge of ML with some MLOps experience. &lt;/p&gt;\n\n&lt;p&gt;In my current company, data engineers only work on ETLs with Airflow and some services in python.&lt;/p&gt;\n\n&lt;p&gt;So I was wondering if I need to properly learn ML to be a good data engineer and maybe secure the future so to say.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2qxvx", "is_robot_indexable": true, "report_reasons": null, "author": "UltramanQuar", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2qxvx/is_it_common_for_data_engineers_to_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2qxvx/is_it_common_for_data_engineers_to_have/", "subreddit_subscribers": 164761, "created_utc": 1709179180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks! I am almost 9 months into my first DE job which is also my first programming job. I decided to switch to DE around 7 years after I graduated from uni and found my current job last summer.\n\nOver the past 9 months, I have helped in building 2 end to end pipelines applying both streaming and batch processing. I have also worked on a data viz project for internal use with another junior DE who joined around the same time but is much younger and a recent college grad.\n\nI am fearful that I am not pulling my weight at all even though my manager has never raised a performance issue and my two reviews so far have been quite good. I think this has something to do with me being closer in age to the mid level folks but being a rank amateur in competence compared to them. \n\nI am definitely asking for less help now and at least when I do I am able to show exactly what I did/why I did but I am keen to know what a very junior DE should be expected to do/know after 9 months. Thanks!", "author_fullname": "t2_chptq8qwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I a handicap, deadweight to my team as a junior DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2xftn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709203446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks! I am almost 9 months into my first DE job which is also my first programming job. I decided to switch to DE around 7 years after I graduated from uni and found my current job last summer.&lt;/p&gt;\n\n&lt;p&gt;Over the past 9 months, I have helped in building 2 end to end pipelines applying both streaming and batch processing. I have also worked on a data viz project for internal use with another junior DE who joined around the same time but is much younger and a recent college grad.&lt;/p&gt;\n\n&lt;p&gt;I am fearful that I am not pulling my weight at all even though my manager has never raised a performance issue and my two reviews so far have been quite good. I think this has something to do with me being closer in age to the mid level folks but being a rank amateur in competence compared to them. &lt;/p&gt;\n\n&lt;p&gt;I am definitely asking for less help now and at least when I do I am able to show exactly what I did/why I did but I am keen to know what a very junior DE should be expected to do/know after 9 months. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2xftn", "is_robot_indexable": true, "report_reasons": null, "author": "jnrdataengineer2023", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2xftn/am_i_a_handicap_deadweight_to_my_team_as_a_junior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2xftn/am_i_a_handicap_deadweight_to_my_team_as_a_junior/", "subreddit_subscribers": 164761, "created_utc": 1709203446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can someone please help me understand a use case that fits the usage of Redis? I have never worked on it just trying to understand its use cases before diving deep into it.\n\nMy friend recently went through a system design round for a company, and faced a scenario to build a system for displaying real time user count (logged in on a website) on a dashboard.\nWe were thinking of a an event based setup like kafka writing onto a nosql which renders data for dashboard.\nAnd we came to a conclusion that eventually persisting the events from queue to nosql would take all the time and defeat the solution.\n\nIs this a right use case for Redis?\n\n", "author_fullname": "t2_epbwyu83", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redis use case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2wcm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709198909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone please help me understand a use case that fits the usage of Redis? I have never worked on it just trying to understand its use cases before diving deep into it.&lt;/p&gt;\n\n&lt;p&gt;My friend recently went through a system design round for a company, and faced a scenario to build a system for displaying real time user count (logged in on a website) on a dashboard.\nWe were thinking of a an event based setup like kafka writing onto a nosql which renders data for dashboard.\nAnd we came to a conclusion that eventually persisting the events from queue to nosql would take all the time and defeat the solution.&lt;/p&gt;\n\n&lt;p&gt;Is this a right use case for Redis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b2wcm4", "is_robot_indexable": true, "report_reasons": null, "author": "gurmanavfc14", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2wcm4/redis_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2wcm4/redis_use_case/", "subreddit_subscribers": 164761, "created_utc": 1709198909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do companies in healthcare or climate tech hire data or distributed systems engineers?\n\nAre these jobs fulfilling careers? Are the people well renumerated.", "author_fullname": "t2_vqjalmbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer jobs in healthcare or climate tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b374j2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709230558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do companies in healthcare or climate tech hire data or distributed systems engineers?&lt;/p&gt;\n\n&lt;p&gt;Are these jobs fulfilling careers? Are the people well renumerated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b374j2", "is_robot_indexable": true, "report_reasons": null, "author": "diego-the-tortoise", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b374j2/data_engineer_jobs_in_healthcare_or_climate_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b374j2/data_engineer_jobs_in_healthcare_or_climate_tech/", "subreddit_subscribers": 164761, "created_utc": 1709230558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am applying for an Advertising Technology company for data engineer role and company said they'll prefer candidates who has some AdTech related data engineering projects. Any suggestions/project ideas you guys have ( plus if you can in short write a high level design description about your project idea then it'll be helpful) ", "author_fullname": "t2_umxhnmq0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want suggestions for making an AdTech related data engineering project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2rrjj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709181779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am applying for an Advertising Technology company for data engineer role and company said they&amp;#39;ll prefer candidates who has some AdTech related data engineering projects. Any suggestions/project ideas you guys have ( plus if you can in short write a high level design description about your project idea then it&amp;#39;ll be helpful) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2rrjj", "is_robot_indexable": true, "report_reasons": null, "author": "perfektenschlagggg", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2rrjj/want_suggestions_for_making_an_adtech_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2rrjj/want_suggestions_for_making_an_adtech_related/", "subreddit_subscribers": 164761, "created_utc": 1709181779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The data is in a table in redshift. On loading this data we plan to run few ML functions on the data (random forest etc), so doing it in python/pandas is essential. Any ideas/suggestions on how this can be performed ?\nEdit: Tech stack currently does not have spark. We are a small team that operates on pandas and sql", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I load a 70 million row table in a dataframe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b3cb1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709243537.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709242979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The data is in a table in redshift. On loading this data we plan to run few ML functions on the data (random forest etc), so doing it in python/pandas is essential. Any ideas/suggestions on how this can be performed ?\nEdit: Tech stack currently does not have spark. We are a small team that operates on pandas and sql&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3cb1t", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3cb1t/how_do_i_load_a_70_million_row_table_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3cb1t/how_do_i_load_a_70_million_row_table_in_a/", "subreddit_subscribers": 164761, "created_utc": 1709242979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a DBA (My work is 100% database development) at my company for almost 5 years. I have very strong TSQL skills and spend a majority of my day working on stored procedures, performance tuning, and various adhoc request. I used Python at my previous job for about a year so I plan on refreshing myself on that as well. I'm trying to break into the field so would getting certified in dp-900 then dp-203 be a good strategy of transitioning into the field? Are there any other things I should learn before applying for jobs?", "author_fullname": "t2_84h9upq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on next steps for career advancement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b38evb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709233671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a DBA (My work is 100% database development) at my company for almost 5 years. I have very strong TSQL skills and spend a majority of my day working on stored procedures, performance tuning, and various adhoc request. I used Python at my previous job for about a year so I plan on refreshing myself on that as well. I&amp;#39;m trying to break into the field so would getting certified in dp-900 then dp-203 be a good strategy of transitioning into the field? Are there any other things I should learn before applying for jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b38evb", "is_robot_indexable": true, "report_reasons": null, "author": "Dirtygerd", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b38evb/advice_on_next_steps_for_career_advancement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b38evb/advice_on_next_steps_for_career_advancement/", "subreddit_subscribers": 164761, "created_utc": 1709233671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, havent seen any info on this, so perhaps its very dumb idea... would it make sense to run Polars on Databricks, using single node clusters.?\n\nReasoning being,... trying to get the advantages/features of databricks while at the same time using a small single node cluster with Polars instead of Spark/Pyspark to process data.   any opinions?\n\n", "author_fullname": "t2_3laxwg3l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars on Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b37ca1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709231087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, havent seen any info on this, so perhaps its very dumb idea... would it make sense to run Polars on Databricks, using single node clusters.?&lt;/p&gt;\n\n&lt;p&gt;Reasoning being,... trying to get the advantages/features of databricks while at the same time using a small single node cluster with Polars instead of Spark/Pyspark to process data.   any opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b37ca1", "is_robot_indexable": true, "report_reasons": null, "author": "acelisalas", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b37ca1/polars_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b37ca1/polars_on_databricks/", "subreddit_subscribers": 164761, "created_utc": 1709231087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey Azure enthusiasts and data wizards! \ud83d\ude80\n\nWe've put together an **in-depth video series** designed to take your Azure Data Engineering and Analytics skills to the next level. Whether you're just starting out or looking to deepen your expertise, our playlist covers everything from **real-time analytics** to **data wrangling**, and more, using Azure's powerful suite of services.\n\n**Here's a sneak peek of what you'll find:**\n\n1. **Twitter Sentiment Analysis with Azure Synapse Analytics** \\- Dive into real-time sentiment analysis and build end-to-end big data pipelines.\n2. **Real-time Vehicle Telemetry Processing** \\- Learn how to handle real-time vehicle data with Azure Stream Analytics and Event Hub.\n3. **Fraudulent Call Detection** \\- Discover how to detect fraudulent calls in real-time using Azure Stream Analytics.\n4. **Weather Forecasting with Azure IoT Hub** \\- Explore how to forecast weather using sensor data from Azure IoT Hub and Machine Learning Studio.\n5. **Web Scraping with Azure Synapse** \\- Get hands-on with web scraping using Azure Synapse, Python, and Spark Pool.\n6. ... and much more across 20+ videos covering Azure Databricks, Azure Data Factory, and other Azure services.\n\n**Why check out our playlist?**\n\n* **Varied Topics**: From analytics to processing, explore Azure's capabilities through practical examples.\n* **Skill Levels**: Content tailored for both beginners and experienced professionals.\n* **Community Support**: Join our growing community, share your progress, and get support from fellow Azure learners.\n\nDive in now and start transforming data into actionable insights with Azure! Check out our playlist\n\n[https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0](https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0)\n\n**What's your biggest challenge with Azure or data engineering/analytics?** Let's discuss in the comments below!", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlock the Full Potential of Azure for Data Engineering and Analytics with Our Comprehensive Video Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2tcev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709186992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Azure enthusiasts and data wizards! \ud83d\ude80&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve put together an &lt;strong&gt;in-depth video series&lt;/strong&gt; designed to take your Azure Data Engineering and Analytics skills to the next level. Whether you&amp;#39;re just starting out or looking to deepen your expertise, our playlist covers everything from &lt;strong&gt;real-time analytics&lt;/strong&gt; to &lt;strong&gt;data wrangling&lt;/strong&gt;, and more, using Azure&amp;#39;s powerful suite of services.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s a sneak peek of what you&amp;#39;ll find:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Twitter Sentiment Analysis with Azure Synapse Analytics&lt;/strong&gt; - Dive into real-time sentiment analysis and build end-to-end big data pipelines.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Real-time Vehicle Telemetry Processing&lt;/strong&gt; - Learn how to handle real-time vehicle data with Azure Stream Analytics and Event Hub.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fraudulent Call Detection&lt;/strong&gt; - Discover how to detect fraudulent calls in real-time using Azure Stream Analytics.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Weather Forecasting with Azure IoT Hub&lt;/strong&gt; - Explore how to forecast weather using sensor data from Azure IoT Hub and Machine Learning Studio.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Web Scraping with Azure Synapse&lt;/strong&gt; - Get hands-on with web scraping using Azure Synapse, Python, and Spark Pool.&lt;/li&gt;\n&lt;li&gt;... and much more across 20+ videos covering Azure Databricks, Azure Data Factory, and other Azure services.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Why check out our playlist?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Varied Topics&lt;/strong&gt;: From analytics to processing, explore Azure&amp;#39;s capabilities through practical examples.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Skill Levels&lt;/strong&gt;: Content tailored for both beginners and experienced professionals.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Community Support&lt;/strong&gt;: Join our growing community, share your progress, and get support from fellow Azure learners.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Dive in now and start transforming data into actionable insights with Azure! Check out our playlist&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0\"&gt;https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s your biggest challenge with Azure or data engineering/analytics?&lt;/strong&gt; Let&amp;#39;s discuss in the comments below!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/i77eGnJm5EfFhj2Iq4lTkoc5z9v72OpTXOO4rMMBP_4.jpg?auto=webp&amp;s=d77ea717953685723e11d432a03b8e1a193364f2", "width": 168, "height": 94}, "resolutions": [{"url": "https://external-preview.redd.it/i77eGnJm5EfFhj2Iq4lTkoc5z9v72OpTXOO4rMMBP_4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c44d70afc0a3160f83b7d53dfc53e12f46edea0e", "width": 108, "height": 60}], "variants": {}, "id": "ljaxuQA5RXlRP1KI4q0RlFon2Axy4tPxeCMyfteBtAg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b2tcev", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2tcev/unlock_the_full_potential_of_azure_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2tcev/unlock_the_full_potential_of_azure_for_data/", "subreddit_subscribers": 164761, "created_utc": 1709186992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All. I am an engineering fresh graduate and am trying to learn about different big data technologies. I want to create a project to put on my portfolio, but I am quite confused about different tools. This workflow is what I am thinking:\n\nStep 1: Calling financial data API / Google Trend from Python running on local laptop\n\nStep 2: Sending above data to Kafka topics hosted on EC2\n\nStep 3: Subscribing to the topics from pyspark and carry out stream transformation and aggregation\n\nStep 4: Streaming the results to Snowflake for more analysis and visualization\n\nSo firstly, I feel that I am just using Kafka as a pub-sub service, and pyspark as another version of pandas. Even if I get all these to work, I am not confident that I can work with \"big\" data. What else should I learn about these tools. Are they supposed to just work when deployed to an auto-scaling compute cluster?\n\nAnd secondly, is this what you would see in real-life application?\n\nWould love suggestions on what to learn and changes to make. Thanks in advance!", "author_fullname": "t2_jcn6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning about big data techs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2qijg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709187233.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709177865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. I am an engineering fresh graduate and am trying to learn about different big data technologies. I want to create a project to put on my portfolio, but I am quite confused about different tools. This workflow is what I am thinking:&lt;/p&gt;\n\n&lt;p&gt;Step 1: Calling financial data API / Google Trend from Python running on local laptop&lt;/p&gt;\n\n&lt;p&gt;Step 2: Sending above data to Kafka topics hosted on EC2&lt;/p&gt;\n\n&lt;p&gt;Step 3: Subscribing to the topics from pyspark and carry out stream transformation and aggregation&lt;/p&gt;\n\n&lt;p&gt;Step 4: Streaming the results to Snowflake for more analysis and visualization&lt;/p&gt;\n\n&lt;p&gt;So firstly, I feel that I am just using Kafka as a pub-sub service, and pyspark as another version of pandas. Even if I get all these to work, I am not confident that I can work with &amp;quot;big&amp;quot; data. What else should I learn about these tools. Are they supposed to just work when deployed to an auto-scaling compute cluster?&lt;/p&gt;\n\n&lt;p&gt;And secondly, is this what you would see in real-life application?&lt;/p&gt;\n\n&lt;p&gt;Would love suggestions on what to learn and changes to make. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2qijg", "is_robot_indexable": true, "report_reasons": null, "author": "hyyyyyyyyy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2qijg/learning_about_big_data_techs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2qijg/learning_about_big_data_techs/", "subreddit_subscribers": 164761, "created_utc": 1709177865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As title says, i am trying to find job and it has been more than a roller coaster ride. I applied multiple positions and got rejected for most of them and the other few interviews I got I messed up with lack of enough technical experience in answering questions and confidence. \n\nI am currently on H1-B and need your help on what I should do to increase my chances of getting a job. I am trying for data analyst and data engineer job roles. Here is my background: \nBachelors in Computer Science, Masters in Data Analytics, two internships with data analyst titles, one capstone project during masters, full-time role as SDE for two years, back to data analyst role (this is a contract role and its coming to end)\n\nSkills wise, I am confident in Sql and avg with python. I am learning azure cloud, databricks and airflow currently. I have knowledge on Aws cloud. I am comfortable with Tableau and Power BI. \n\nPlease let me know any inputs or leads that I could use and find a job. I have attached my CV any guidance on how to make it effective to get calls is much appreciated.", "author_fullname": "t2_qwixqkzsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I am trying to find job and desperately need guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"a4686fq4ollc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 138, "x": 108, "u": "https://preview.redd.it/a4686fq4ollc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f756b47aff0f4e18ec46c0df2ce41d511988a982"}, {"y": 276, "x": 216, "u": "https://preview.redd.it/a4686fq4ollc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=31a083889089f0b32611c5380154202a7df5d8e6"}, {"y": 409, "x": 320, "u": "https://preview.redd.it/a4686fq4ollc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=48780a628a7a90c59f85496cb54757e72eef6189"}, {"y": 818, "x": 640, "u": "https://preview.redd.it/a4686fq4ollc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=15ffad1d5ee50e5c7f418969620b487ff2c5f248"}, {"y": 1228, "x": 960, "u": "https://preview.redd.it/a4686fq4ollc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=38cd4c6d0976074e95a44d87b74a8d08dd89f006"}, {"y": 1382, "x": 1080, "u": "https://preview.redd.it/a4686fq4ollc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4167c5db972f1271157748e554fd2e2b81d58f6d"}], "s": {"y": 1606, "x": 1255, "u": "https://preview.redd.it/a4686fq4ollc1.jpg?width=1255&amp;format=pjpg&amp;auto=webp&amp;s=cdb97bdc867c0aec5d2a24c6830ec1e8ef9cd721"}, "id": "a4686fq4ollc1"}, "fl3jecq4ollc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 141, "x": 108, "u": "https://preview.redd.it/fl3jecq4ollc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6eabadeb30f40b9ff7b2d3bac0d79e86fa322758"}, {"y": 282, "x": 216, "u": "https://preview.redd.it/fl3jecq4ollc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=99dd9f0742d3008d470d2b878a8ba6d554ce2a27"}, {"y": 418, "x": 320, "u": "https://preview.redd.it/fl3jecq4ollc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b38a9c3ed8b1c81b72a2883c4652e4cc49d52ed"}, {"y": 836, "x": 640, "u": "https://preview.redd.it/fl3jecq4ollc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4e15f3cc4464089c556c4f61b5a01819a9aeaf9b"}, {"y": 1255, "x": 960, "u": "https://preview.redd.it/fl3jecq4ollc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e1ad347e2a3a77f9bab49b451c076464d37876ca"}, {"y": 1412, "x": 1080, "u": "https://preview.redd.it/fl3jecq4ollc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=31a45d4d49abed639510a415b820644582367c19"}], "s": {"y": 1620, "x": 1239, "u": "https://preview.redd.it/fl3jecq4ollc1.jpg?width=1239&amp;format=pjpg&amp;auto=webp&amp;s=ac7effba8a78734ff7e97faf67a25f8e31a1875d"}, "id": "fl3jecq4ollc1"}}, "name": "t3_1b3dc78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "a4686fq4ollc1", "id": 413181711}, {"media_id": "fl3jecq4ollc1", "id": 413181712}]}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1oXBuwj8UsWhdUfWU-LqbmPRH26f7qlUQtuYASCOnNk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709245400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title says, i am trying to find job and it has been more than a roller coaster ride. I applied multiple positions and got rejected for most of them and the other few interviews I got I messed up with lack of enough technical experience in answering questions and confidence. &lt;/p&gt;\n\n&lt;p&gt;I am currently on H1-B and need your help on what I should do to increase my chances of getting a job. I am trying for data analyst and data engineer job roles. Here is my background: \nBachelors in Computer Science, Masters in Data Analytics, two internships with data analyst titles, one capstone project during masters, full-time role as SDE for two years, back to data analyst role (this is a contract role and its coming to end)&lt;/p&gt;\n\n&lt;p&gt;Skills wise, I am confident in Sql and avg with python. I am learning azure cloud, databricks and airflow currently. I have knowledge on Aws cloud. I am comfortable with Tableau and Power BI. &lt;/p&gt;\n\n&lt;p&gt;Please let me know any inputs or leads that I could use and find a job. I have attached my CV any guidance on how to make it effective to get calls is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1b3dc78", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b3dc78", "is_robot_indexable": true, "report_reasons": null, "author": "Critical-Radish1062", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3dc78/i_am_trying_to_find_job_and_desperately_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1b3dc78", "subreddit_subscribers": 164761, "created_utc": 1709245400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to transfer the 365 data through api from 365 to big query, what would be the effective way to do this process !? Any suggestions ", "author_fullname": "t2_9r5qrevk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft 365 business central to big query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b34y1i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709225319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to transfer the 365 data through api from 365 to big query, what would be the effective way to do this process !? Any suggestions &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b34y1i", "is_robot_indexable": true, "report_reasons": null, "author": "Fabro_vaz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b34y1i/microsoft_365_business_central_to_big_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b34y1i/microsoft_365_business_central_to_big_query/", "subreddit_subscribers": 164761, "created_utc": 1709225319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a newbie about data warehouse. I want to design a Warehouse using Star Schema for company problems.\n Different business processes will be designed with different schemas such as sales_schema, financial_schema. However, some schemas will use common dim tables such as dim_product. So how should the dim table be designed and stored in schema to be most effective and appropriate?\n- Should a table dim_product be created in a common schema (eg public_schema) and other schemas (sales_schema, financial_schema) can use data from the common table dim_product (public_schema)\n- Each schema (sales_schema, financial_schema) will create a dim_product table (duplicate data)\n\nPlease help me. Thank you !", "author_fullname": "t2_7fja37x0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design schema use Star Schema in Data Warehouse Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b33ph1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709222262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a newbie about data warehouse. I want to design a Warehouse using Star Schema for company problems.\n Different business processes will be designed with different schemas such as sales_schema, financial_schema. However, some schemas will use common dim tables such as dim_product. So how should the dim table be designed and stored in schema to be most effective and appropriate?\n- Should a table dim_product be created in a common schema (eg public_schema) and other schemas (sales_schema, financial_schema) can use data from the common table dim_product (public_schema)\n- Each schema (sales_schema, financial_schema) will create a dim_product table (duplicate data)&lt;/p&gt;\n\n&lt;p&gt;Please help me. Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b33ph1", "is_robot_indexable": true, "report_reasons": null, "author": "Waste-Orchid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b33ph1/design_schema_use_star_schema_in_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b33ph1/design_schema_use_star_schema_in_data_warehouse/", "subreddit_subscribers": 164761, "created_utc": 1709222262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since January 31, 2024, Talend (acquired by Qlik) has been removed from the Talend Open Studio site. It's also impossible to find a version on Source forge.\n\nWho still has a copy of Talend Open Studio?", "author_fullname": "t2_634ju3is", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am looking for Talend Open Studio since it's not open source anymore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b319x2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709216028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since January 31, 2024, Talend (acquired by Qlik) has been removed from the Talend Open Studio site. It&amp;#39;s also impossible to find a version on Source forge.&lt;/p&gt;\n\n&lt;p&gt;Who still has a copy of Talend Open Studio?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b319x2", "is_robot_indexable": true, "report_reasons": null, "author": "lilbuldogz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b319x2/i_am_looking_for_talend_open_studio_since_its_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b319x2/i_am_looking_for_talend_open_studio_since_its_not/", "subreddit_subscribers": 164761, "created_utc": 1709216028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to stream the changes made in my Postgresql DB using Debezium and Kafka. This is my connector configuration(pic 1)\n\nThe connector is created and I am able to consume the changes in Jupyter notebook using my Kafka consumer. But I am only getting the row data that was inserted or updated(pic 2). I am not able to get the operation that was performed(whether it was INSERT or UPDATE). Is there a way to get the operation performed data as well? also is it possible to get other operations data like TRUNCATE,DROP,ALTER because WAL logs store these information(pic 3- you can see the delete operation being logged but this doesnt get consumed by kafka).", "author_fullname": "t2_d37wcj6i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting additional data from Debezium connector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2xs94", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709204772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to stream the changes made in my Postgresql DB using Debezium and Kafka. This is my connector configuration(pic 1)&lt;/p&gt;\n\n&lt;p&gt;The connector is created and I am able to consume the changes in Jupyter notebook using my Kafka consumer. But I am only getting the row data that was inserted or updated(pic 2). I am not able to get the operation that was performed(whether it was INSERT or UPDATE). Is there a way to get the operation performed data as well? also is it possible to get other operations data like TRUNCATE,DROP,ALTER because WAL logs store these information(pic 3- you can see the delete operation being logged but this doesnt get consumed by kafka).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2xs94", "is_robot_indexable": true, "report_reasons": null, "author": "Minute-Internal5628", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2xs94/getting_additional_data_from_debezium_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2xs94/getting_additional_data_from_debezium_connector/", "subreddit_subscribers": 164761, "created_utc": 1709204772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, everyone. I have question like this. I am trying to build datalake house with some components such as, Minio as a object storage, dreamio as SQL engine.  Requirements are like below;  \n\n\n* Migrate some tables (not high volume tables) from MSSQL to Minio, so we can simply join these tables with Dreamio and query these tables. This part is not the problematic. I already migrated all tables to Minio bucket with the help of Apache Spark.   \n\n\nProblem: Now, I need to bring only incremental changes to Minio. I think the way it can be done is Airbyte using enabled CDC on MSSQL to S3 (Minio bucket) connector. Lets say, one row got updated on source Sink (mssql) and CDC captured this change, and my airbyte job also migrated this incremental change as file to bucket. But then how can I implement this change to files there, so dreamio tables can also reflect these changes on tables. Source operations are insert, update, delete. Maybe someone will recommend to overwrite everything each time. So all the time there will be updated data. But I dont want to put this kind of strain, instead I want to use incremental changes. Is there anybody has idea about this ?", "author_fullname": "t2_m2wfe4pj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datalakehouse pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2wlrw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709199990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, everyone. I have question like this. I am trying to build datalake house with some components such as, Minio as a object storage, dreamio as SQL engine.  Requirements are like below;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Migrate some tables (not high volume tables) from MSSQL to Minio, so we can simply join these tables with Dreamio and query these tables. This part is not the problematic. I already migrated all tables to Minio bucket with the help of Apache Spark.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Problem: Now, I need to bring only incremental changes to Minio. I think the way it can be done is Airbyte using enabled CDC on MSSQL to S3 (Minio bucket) connector. Lets say, one row got updated on source Sink (mssql) and CDC captured this change, and my airbyte job also migrated this incremental change as file to bucket. But then how can I implement this change to files there, so dreamio tables can also reflect these changes on tables. Source operations are insert, update, delete. Maybe someone will recommend to overwrite everything each time. So all the time there will be updated data. But I dont want to put this kind of strain, instead I want to use incremental changes. Is there anybody has idea about this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b2wlrw", "is_robot_indexable": true, "report_reasons": null, "author": "Over_Ad_6186", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2wlrw/datalakehouse_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2wlrw/datalakehouse_pipeline/", "subreddit_subscribers": 164761, "created_utc": 1709199990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wanna do Microsoft Azure associate data engineer certification DP-203. How is Alan Rodrigues's course on udemy for exam preparation for extreme newbie in data engineering. \n\nEdit - Also as a fresher applying for data engineering roles is this certification worth it?", "author_fullname": "t2_umxhnmq0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanna do Microsoft Azure associate data engineer certification DP-203. How is Alan Rodrigues's course on udemy for exam preparation for extreme newbie in data engineering. ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2us18", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709192627.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709192364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanna do Microsoft Azure associate data engineer certification DP-203. How is Alan Rodrigues&amp;#39;s course on udemy for exam preparation for extreme newbie in data engineering. &lt;/p&gt;\n\n&lt;p&gt;Edit - Also as a fresher applying for data engineering roles is this certification worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2us18", "is_robot_indexable": true, "report_reasons": null, "author": "perfektenschlagggg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2us18/wanna_do_microsoft_azure_associate_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2us18/wanna_do_microsoft_azure_associate_data_engineer/", "subreddit_subscribers": 164761, "created_utc": 1709192364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to compile a resource for the best open source databases. \n\n**Here is what I have so far:**\n\n* [https://www.starrocks.io/](https://www.starrocks.io/)\n* duckdb\n* postgresql\n* clickhouse\n\nWhat are others that you would consider the best and why? \n\nThanks!", "author_fullname": "t2_fosm1pwyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best open source databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2l5oe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709163080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to compile a resource for the best open source databases. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is what I have so far:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.starrocks.io/\"&gt;https://www.starrocks.io/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;duckdb&lt;/li&gt;\n&lt;li&gt;postgresql&lt;/li&gt;\n&lt;li&gt;clickhouse&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What are others that you would consider the best and why? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2l5oe", "is_robot_indexable": true, "report_reasons": null, "author": "Data-Queen-Mayra", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2l5oe/best_open_source_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2l5oe/best_open_source_databases/", "subreddit_subscribers": 164761, "created_utc": 1709163080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nToday I am working on a data pipeline where my ingestion-app processes realtime network traffic from multiple sources and writes into a Kafka bus in JSON format to be consumed by multiple endpoints. Apart from realtime processing I need to store a copy of it for future  processing/analysis.\n\nI was wondering which db would be the better option for offline consumption as the data is huge (atleast 10-20 TB per month) from more than 1000 nodes. I came across different demos where clickhouse or elastic search is used as final resting place or storage of network traffic and then grafana is used for visualization. \n\nI am not an elastic search expert but I feel it is a search engine capable of indexing string data. But can I retrieve the same data in future for further processing? Since Network traffic is timeseries data is elastic search good for this?\n\nAny suggestions based on your experience would be of great help\n\n&amp;#x200B;", "author_fullname": "t2_a0gdmw2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage of network traffic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2kluj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709161760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;Today I am working on a data pipeline where my ingestion-app processes realtime network traffic from multiple sources and writes into a Kafka bus in JSON format to be consumed by multiple endpoints. Apart from realtime processing I need to store a copy of it for future  processing/analysis.&lt;/p&gt;\n\n&lt;p&gt;I was wondering which db would be the better option for offline consumption as the data is huge (atleast 10-20 TB per month) from more than 1000 nodes. I came across different demos where clickhouse or elastic search is used as final resting place or storage of network traffic and then grafana is used for visualization. &lt;/p&gt;\n\n&lt;p&gt;I am not an elastic search expert but I feel it is a search engine capable of indexing string data. But can I retrieve the same data in future for further processing? Since Network traffic is timeseries data is elastic search good for this?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions based on your experience would be of great help&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2kluj", "is_robot_indexable": true, "report_reasons": null, "author": "LobsterMost5947", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2kluj/storage_of_network_traffic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2kluj/storage_of_network_traffic/", "subreddit_subscribers": 164761, "created_utc": 1709161760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I've been hired as a junior dataeng consultant and it seems ill have to go through another round of interviews to get my first project at another company \n\nSo far, I've learned the position is pretty technical.  I'll have to ensure that pipelines are working from Big Query throught DBT to a CDP. Also ensuring the data quality of those processes.\n\nWhat kind of questions could I ask to better understand the project and what should I be wary of?", "author_fullname": "t2_7sxjsnci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of questions should I ask for a consulting gig?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b3e6nx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709247421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;ve been hired as a junior dataeng consultant and it seems ill have to go through another round of interviews to get my first project at another company &lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;ve learned the position is pretty technical.  I&amp;#39;ll have to ensure that pipelines are working from Big Query throught DBT to a CDP. Also ensuring the data quality of those processes.&lt;/p&gt;\n\n&lt;p&gt;What kind of questions could I ask to better understand the project and what should I be wary of?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3e6nx", "is_robot_indexable": true, "report_reasons": null, "author": "IncidentAppropriate5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3e6nx/what_kind_of_questions_should_i_ask_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3e6nx/what_kind_of_questions_should_i_ask_for_a/", "subreddit_subscribers": 164761, "created_utc": 1709247421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team,\n\nI've got to make a report from our DW on customers and their transactions (for example). I am divided between having a single Spark job handle all the customers+transactions and give it lots of breathing room (in terms of cluster size), or whether I should have the Spark job handle a single customer+(all transactions) and rely on Airflow to get everything done.\n\nAdvice? Please and thank you.\n\nUpdate: The report is like a statement. One report per customer, including all transactions for the given time period.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Many \"customers\" in single Spark job, or many Spark jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b3dkm3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709247485.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709245958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got to make a report from our DW on customers and their transactions (for example). I am divided between having a single Spark job handle all the customers+transactions and give it lots of breathing room (in terms of cluster size), or whether I should have the Spark job handle a single customer+(all transactions) and rely on Airflow to get everything done.&lt;/p&gt;\n\n&lt;p&gt;Advice? Please and thank you.&lt;/p&gt;\n\n&lt;p&gt;Update: The report is like a statement. One report per customer, including all transactions for the given time period.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b3dkm3", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3dkm3/many_customers_in_single_spark_job_or_many_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3dkm3/many_customers_in_single_spark_job_or_many_spark/", "subreddit_subscribers": 164761, "created_utc": 1709245958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I create a Dataflow using the mongodb to BQ template, it asks for the URI. But of course, I dont want to paste the string, I need more security than that. How can I do this? Couldn't find any docs on this", "author_fullname": "t2_4rpxclpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In Dataflow using the MongoDB to BigQuery connector. How can I pass the URI as a secret?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b3d7m0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709245102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I create a Dataflow using the mongodb to BQ template, it asks for the URI. But of course, I dont want to paste the string, I need more security than that. How can I do this? Couldn&amp;#39;t find any docs on this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b3d7m0", "is_robot_indexable": true, "report_reasons": null, "author": "RedBlueWhiteBlack", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b3d7m0/in_dataflow_using_the_mongodb_to_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b3d7m0/in_dataflow_using_the_mongodb_to_bigquery/", "subreddit_subscribers": 164761, "created_utc": 1709245102.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}