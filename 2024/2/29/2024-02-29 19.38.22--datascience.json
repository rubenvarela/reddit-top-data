{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a degree in the Arts field. Have been successful in this field and peaked at where I am (mid 30s). Looking to make use of self-taught programming, Tableau, analytics, etc. to get another job/career start. \n\nIf you were in a similar spot with an unrelated degree and unrelated previous career, what was it? Did you manage to find some work in data? \n\nWould love to hear your story for some inspiration.", "author_fullname": "t2_11oo1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analysts with Weird Degrees: What is it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2n9ib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709168601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a degree in the Arts field. Have been successful in this field and peaked at where I am (mid 30s). Looking to make use of self-taught programming, Tableau, analytics, etc. to get another job/career start. &lt;/p&gt;\n\n&lt;p&gt;If you were in a similar spot with an unrelated degree and unrelated previous career, what was it? Did you manage to find some work in data? &lt;/p&gt;\n\n&lt;p&gt;Would love to hear your story for some inspiration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b2n9ib", "is_robot_indexable": true, "report_reasons": null, "author": "Itsallkosher1", "discussion_type": null, "num_comments": 78, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b2n9ib/analysts_with_weird_degrees_what_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b2n9ib/analysts_with_weird_degrees_what_is_it/", "subreddit_subscribers": 1381042, "created_utc": 1709168601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Got a mouthful from my manager about me working extra and that i didnt communicate that i have to work extra. Despite actually communicating this and sending the work at like 7-8 PM. \n\nFor example: i get ask at 3-4 pm and they want numbers next day. So i started logging my hours as my teammates and I have to work extra just to meet the deadlines, maintain the existing jobs, and also do asks.\n\nWhat i got was that in my team we never had people log their hours despite the fact that everyone is overworked to the bone and my coworker literally said she wants to quit and hates it.\n\nso as a community how should i proceed as my manager wants to escalate and I dont understand what i did wrong. I literally logged the hours that i worked after communicating that i have to work extra. Am\nI being gaslighted?", "author_fullname": "t2_ieiq39sml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you get reprimanded for logging your hours for your job for working extra?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2lw0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709164938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got a mouthful from my manager about me working extra and that i didnt communicate that i have to work extra. Despite actually communicating this and sending the work at like 7-8 PM. &lt;/p&gt;\n\n&lt;p&gt;For example: i get ask at 3-4 pm and they want numbers next day. So i started logging my hours as my teammates and I have to work extra just to meet the deadlines, maintain the existing jobs, and also do asks.&lt;/p&gt;\n\n&lt;p&gt;What i got was that in my team we never had people log their hours despite the fact that everyone is overworked to the bone and my coworker literally said she wants to quit and hates it.&lt;/p&gt;\n\n&lt;p&gt;so as a community how should i proceed as my manager wants to escalate and I dont understand what i did wrong. I literally logged the hours that i worked after communicating that i have to work extra. Am\nI being gaslighted?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b2lw0z", "is_robot_indexable": true, "report_reasons": null, "author": "JobIsAss", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b2lw0z/can_you_get_reprimanded_for_logging_your_hours/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b2lw0z/can_you_get_reprimanded_for_logging_your_hours/", "subreddit_subscribers": 1381042, "created_utc": 1709164938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "All ML models are designed to do one thing: learning a probability distribution in the form of P(y|X). In other words, they try to learn how to model an outcome 'y' given the input variables 'X'. \n\nThis probability distribution, P(y|X), is also called Concept. Therefore, if the Concept changes, the model may become invalid.\n\nBut how do we know if there is a new Concept in our data?  \nOr, more importantly, how do we measure if the new Concept is affecting the model's performance?\n\nHere is a clever solution where the main ingredients are a reference dataset, one where the model's performance is known, and a dataset with the latest data we would like to monitor.\n\n**Step-by-Step solution:**\n\n1. We start by training an internal model on a chunk of the latest data. -&gt; This allows us to learn the new possible Concept presented in the data.\n2. Next, we use the internal model to make predictions on the reference dataset.\n3. We then estimate the model's performance on the reference dataset, assuming the model's predictions on the monitoring data as ground truth.\n4. If the estimated performance of the internal model and the actual monitored model are very different, we then say that there has been a Concept Drift.\n\nTo quantify how this Concept impacts performance, we subtract the actual model's performance on reference from the estimated performance and report a delta of the performance metric. -&gt; This is what the plot below shows. The change of the F1-score due to Concept drift!   \n\n\nThis process is repeated for every new chunk of data that we get. \n\nhttps://preview.redd.it/3hyu6a8jhhlc1.jpg?width=2738&amp;format=pjpg&amp;auto=webp&amp;s=6898ac6ccb3675d2816870047ffd2a95f1aa53b2", "author_fullname": "t2_5hgh94wf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Algorithm to detect Concept Drift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3hyu6a8jhhlc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=acd42b6ac1978ddc064700ce9748c2bda66dddc4"}, {"y": 154, "x": 216, "u": "https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e0afcbb6040d9f0b0599683134a8c09d64e54dcb"}, {"y": 229, "x": 320, "u": "https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b66225730020c108d0edb5f812cff81f2934a715"}, {"y": 458, "x": 640, "u": "https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b08d179054fc7934e28197f9ebd0b573c45ba8f"}, {"y": 687, "x": 960, "u": "https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4c2d5ef98c2a0dabe502238813f537f7791dd94d"}, {"y": 773, "x": 1080, "u": "https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8df2d7d19be4a6aaed679eacaf0f15fda1029487"}], "s": {"y": 1960, "x": 2738, "u": "https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=2738&amp;format=pjpg&amp;auto=webp&amp;s=6898ac6ccb3675d2816870047ffd2a95f1aa53b2"}, "id": "3hyu6a8jhhlc1"}}, "name": "t3_1b2vg0u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0gv43RrNesDueT4gFrodMa8MgkpUgfLS7Vps2yKWdug.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709195055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All ML models are designed to do one thing: learning a probability distribution in the form of P(y|X). In other words, they try to learn how to model an outcome &amp;#39;y&amp;#39; given the input variables &amp;#39;X&amp;#39;. &lt;/p&gt;\n\n&lt;p&gt;This probability distribution, P(y|X), is also called Concept. Therefore, if the Concept changes, the model may become invalid.&lt;/p&gt;\n\n&lt;p&gt;But how do we know if there is a new Concept in our data?&lt;br/&gt;\nOr, more importantly, how do we measure if the new Concept is affecting the model&amp;#39;s performance?&lt;/p&gt;\n\n&lt;p&gt;Here is a clever solution where the main ingredients are a reference dataset, one where the model&amp;#39;s performance is known, and a dataset with the latest data we would like to monitor.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step-by-Step solution:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We start by training an internal model on a chunk of the latest data. -&amp;gt; This allows us to learn the new possible Concept presented in the data.&lt;/li&gt;\n&lt;li&gt;Next, we use the internal model to make predictions on the reference dataset.&lt;/li&gt;\n&lt;li&gt;We then estimate the model&amp;#39;s performance on the reference dataset, assuming the model&amp;#39;s predictions on the monitoring data as ground truth.&lt;/li&gt;\n&lt;li&gt;If the estimated performance of the internal model and the actual monitored model are very different, we then say that there has been a Concept Drift.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To quantify how this Concept impacts performance, we subtract the actual model&amp;#39;s performance on reference from the estimated performance and report a delta of the performance metric. -&amp;gt; This is what the plot below shows. The change of the F1-score due to Concept drift!   &lt;/p&gt;\n\n&lt;p&gt;This process is repeated for every new chunk of data that we get. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=2738&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=6898ac6ccb3675d2816870047ffd2a95f1aa53b2\"&gt;https://preview.redd.it/3hyu6a8jhhlc1.jpg?width=2738&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=6898ac6ccb3675d2816870047ffd2a95f1aa53b2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b2vg0u", "is_robot_indexable": true, "report_reasons": null, "author": "santiviquez", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b2vg0u/algorithm_to_detect_concept_drift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b2vg0u/algorithm_to_detect_concept_drift/", "subreddit_subscribers": 1381042, "created_utc": 1709195055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "And if yes, where does one find the commonly accepted approaches?\n\nFor context, say you are asked to solve a churn problem. How do you get started on this? Do you read published literature? Medium articles? Ask your senior? Just know off the top of your head? \n\nAs someone early in their career I would like to know how to find the generally accepted approach of trying to solve a problem that has been solved before.", "author_fullname": "t2_wsaymmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there accepted approaches/starting points to solving common problems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b310nm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709215328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And if yes, where does one find the commonly accepted approaches?&lt;/p&gt;\n\n&lt;p&gt;For context, say you are asked to solve a churn problem. How do you get started on this? Do you read published literature? Medium articles? Ask your senior? Just know off the top of your head? &lt;/p&gt;\n\n&lt;p&gt;As someone early in their career I would like to know how to find the generally accepted approach of trying to solve a problem that has been solved before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b310nm", "is_robot_indexable": true, "report_reasons": null, "author": "jstr36", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b310nm/are_there_accepted_approachesstarting_points_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b310nm/are_there_accepted_approachesstarting_points_to/", "subreddit_subscribers": 1381042, "created_utc": 1709215328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am doing my master\u2019s thesis, and I would like any information on where I can get this type of dataset? I am primarily worried about lacking data variables in the dataset.\n\nCan someone offer me some guidance?", "author_fullname": "t2_17ir90", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survival analysis on cancer patients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2n3aq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709168122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am doing my master\u2019s thesis, and I would like any information on where I can get this type of dataset? I am primarily worried about lacking data variables in the dataset.&lt;/p&gt;\n\n&lt;p&gt;Can someone offer me some guidance?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1b2n3aq", "is_robot_indexable": true, "report_reasons": null, "author": "EmilyEmlz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b2n3aq/survival_analysis_on_cancer_patients/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b2n3aq/survival_analysis_on_cancer_patients/", "subreddit_subscribers": 1381042, "created_utc": 1709168122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "online masters in CS or analytics? \nOr should I even go find a proper economics/metrics or stats program?\n\nCurrent DS , 7 YOE in a variety of topics spanning the DA/DE/DS-lite Spectrum wanting to upgrade my degree to look more competitive on resumes. Working for very very large company. Company is willing to pay for school.  Which one should I do? Should I even think about MBAs if I\u2019m aiming for front-line management?", "author_fullname": "t2_14wbpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OMSCS or OMSA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2l79i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709163187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;online masters in CS or analytics? \nOr should I even go find a proper economics/metrics or stats program?&lt;/p&gt;\n\n&lt;p&gt;Current DS , 7 YOE in a variety of topics spanning the DA/DE/DS-lite Spectrum wanting to upgrade my degree to look more competitive on resumes. Working for very very large company. Company is willing to pay for school.  Which one should I do? Should I even think about MBAs if I\u2019m aiming for front-line management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1b2l79i", "is_robot_indexable": true, "report_reasons": null, "author": "kater543", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b2l79i/omscs_or_omsa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b2l79i/omscs_or_omsa/", "subreddit_subscribers": 1381042, "created_utc": 1709163187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am the only analyst working at my job which is the center of a consortium, with a lot of different audiences demanding information. In the last few months, my job was pushed to launch a new program without having everything fully ready to go yet. Now, we are in a situation where our main database is going through weekly changes while people are collecting data, with little documentation on what actually means what. It's being built as we're using it, to the frustration of everyone, but especially me because it turns a 10 minute pull into a 2 hour one while I have to go hunt down what things actually mean what.\n\nThere are last minute data requests from people who don't even fully know what data they're asking for, people who want involved analyses within two days, etc, all while our database is changing constantly. Someone from our board recently asked for numbers of \"top 10 states\" but gave no specification. Top 10 what? When asked, all he replied with was \"I'd be interested in absolute numbers and per capita numbers\" and still no specification. And he wanted it almost immediately so he'd have a talking point for a speech.\n\nA lot of them are either ignoring the dashboards that can give them the info they look for, or aren't allowed to have direct access in the first place because my org is strict with who can access what. I can't leave this job until June, but what methods can I use to get control of these requests, or what data policies can I advocate for with my higher-ups, because they don't know anything about tech or data. At this point, I'm going to either ignore silly requests, tell them to go look at the dashboards, or tell people they'll have to wait to receive it.", "author_fullname": "t2_3u65v6ol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get control of last minute data requests?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b32h79", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709219167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the only analyst working at my job which is the center of a consortium, with a lot of different audiences demanding information. In the last few months, my job was pushed to launch a new program without having everything fully ready to go yet. Now, we are in a situation where our main database is going through weekly changes while people are collecting data, with little documentation on what actually means what. It&amp;#39;s being built as we&amp;#39;re using it, to the frustration of everyone, but especially me because it turns a 10 minute pull into a 2 hour one while I have to go hunt down what things actually mean what.&lt;/p&gt;\n\n&lt;p&gt;There are last minute data requests from people who don&amp;#39;t even fully know what data they&amp;#39;re asking for, people who want involved analyses within two days, etc, all while our database is changing constantly. Someone from our board recently asked for numbers of &amp;quot;top 10 states&amp;quot; but gave no specification. Top 10 what? When asked, all he replied with was &amp;quot;I&amp;#39;d be interested in absolute numbers and per capita numbers&amp;quot; and still no specification. And he wanted it almost immediately so he&amp;#39;d have a talking point for a speech.&lt;/p&gt;\n\n&lt;p&gt;A lot of them are either ignoring the dashboards that can give them the info they look for, or aren&amp;#39;t allowed to have direct access in the first place because my org is strict with who can access what. I can&amp;#39;t leave this job until June, but what methods can I use to get control of these requests, or what data policies can I advocate for with my higher-ups, because they don&amp;#39;t know anything about tech or data. At this point, I&amp;#39;m going to either ignore silly requests, tell them to go look at the dashboards, or tell people they&amp;#39;ll have to wait to receive it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b32h79", "is_robot_indexable": true, "report_reasons": null, "author": "lemonbottles_89", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b32h79/how_to_get_control_of_last_minute_data_requests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b32h79/how_to_get_control_of_last_minute_data_requests/", "subreddit_subscribers": 1381042, "created_utc": 1709219167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a pretty new data scientist in big tech I churn out a lot of experiment launches but haven't had a stakeholder ask for this before. \n\nIf we have 3 experiments that each improved a metric by 10% during the experiment, we launch all 3 a month later, and the metric improves by 15%, how do we know the contribution from each launch?", "author_fullname": "t2_2ocktbno", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Measuring the actual impact of experiment launches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b36w4f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709229981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a pretty new data scientist in big tech I churn out a lot of experiment launches but haven&amp;#39;t had a stakeholder ask for this before. &lt;/p&gt;\n\n&lt;p&gt;If we have 3 experiments that each improved a metric by 10% during the experiment, we launch all 3 a month later, and the metric improves by 15%, how do we know the contribution from each launch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1b36w4f", "is_robot_indexable": true, "report_reasons": null, "author": "bukakke-n-chill", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1b36w4f/measuring_the_actual_impact_of_experiment_launches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1b36w4f/measuring_the_actual_impact_of_experiment_launches/", "subreddit_subscribers": 1381042, "created_utc": 1709229981.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}