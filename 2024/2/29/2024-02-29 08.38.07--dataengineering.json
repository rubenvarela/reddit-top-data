{"kind": "Listing", "data": {"after": "t3_1b22r8x", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the SQL patterns you use on a regular basis and why?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite SQL patterns?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b26kf9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709128402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the SQL patterns you use on a regular basis and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b26kf9", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 110, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b26kf9/favorite_sql_patterns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b26kf9/favorite_sql_patterns/", "subreddit_subscribers": 164578, "created_utc": 1709128402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I suck at live Python coding interviews. I've been practicing for months and building projects on my portfolio that hiring managers won't even let me show them as a means of proving competency. I spent 8 months just to find one Junior DE role that I was able to have a conversation over and blew it because I didn't remember how to append a list within a function, and blanked out on proper syntax. That's after a few dozens of hours of practice. \n\nBut if you ask me how to best optimize a query, do live exercises on SQL, explain and query use cases for CTEs, window functions, etc. I can do that just fine. 80% of DE tools use SQL, and you can use queries to do much of the transformation work outside of Python. Outside of SQL Developer, are there other job titles or methods of looking that I'm missing? I don't want to have to stop trying, but after a year and 7 months, I don't really have anything left.", "author_fullname": "t2_lp2ob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there still a place for people who specialize in SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2cr2g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709152730.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709143481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I suck at live Python coding interviews. I&amp;#39;ve been practicing for months and building projects on my portfolio that hiring managers won&amp;#39;t even let me show them as a means of proving competency. I spent 8 months just to find one Junior DE role that I was able to have a conversation over and blew it because I didn&amp;#39;t remember how to append a list within a function, and blanked out on proper syntax. That&amp;#39;s after a few dozens of hours of practice. &lt;/p&gt;\n\n&lt;p&gt;But if you ask me how to best optimize a query, do live exercises on SQL, explain and query use cases for CTEs, window functions, etc. I can do that just fine. 80% of DE tools use SQL, and you can use queries to do much of the transformation work outside of Python. Outside of SQL Developer, are there other job titles or methods of looking that I&amp;#39;m missing? I don&amp;#39;t want to have to stop trying, but after a year and 7 months, I don&amp;#39;t really have anything left.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2cr2g", "is_robot_indexable": true, "report_reasons": null, "author": "mrbrucel33", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2cr2g/is_there_still_a_place_for_people_who_specialize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2cr2g/is_there_still_a_place_for_people_who_specialize/", "subreddit_subscribers": 164578, "created_utc": 1709143481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all. I've been with a large non-tech company for about 6 months now in a Jr data engineering role, where I got hired with lots of other new grads.  Before this I did a DE internship mostly using Pyspark and snowflake. I enjoyed the work, so I figured I\u2019d go for it as my first job.\n\n\n\n\nOn one hand, I love my team and manager, they are all really kind and supportive. It's a great working environment, with good benefits and decent pay.\n\n\n\n\nBut my work is really dry compared to my internship and coursework- the relatively little work I get at least. I was placed with a maintenance team where most of the work is small SQL bug fixes, some legacy code updates, and running no/low code jobs. And as a Jr, they've been pretty slow to get me involved in any of the more in depth work despite my insistence. All of my learning is very company specific business process stuff, and I feel like I'm becoming a worse programmer every day. But pretty much everything *besides the work* is great here. I know some other new grads hired as part of the same cohort as me are working with Pyspark, designing new pipelines and features, and generally doing much more technical work , so I kinda feel like I just got unlucky with my placement in that way. I\u2019m very concerned that I\u2019m not learning any transferable skills if/when I\u2019m looking for DE roles in other companies down the line.\n\n\n\n\nHas anyone been in a similar position? Should I stick it out, or try to move to a different team internally? Then I run the risk of getting a much less pleasant to work with team is my worry. I'm trying to work on side projects more to regain some technical skills, it's just tough to balance with work, other hobbies etc. I wish my job stimulated those skills at least a little.", "author_fullname": "t2_1bjk3j6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling stagnant at first DE role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b29psy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709139037.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709136570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. I&amp;#39;ve been with a large non-tech company for about 6 months now in a Jr data engineering role, where I got hired with lots of other new grads.  Before this I did a DE internship mostly using Pyspark and snowflake. I enjoyed the work, so I figured I\u2019d go for it as my first job.&lt;/p&gt;\n\n&lt;p&gt;On one hand, I love my team and manager, they are all really kind and supportive. It&amp;#39;s a great working environment, with good benefits and decent pay.&lt;/p&gt;\n\n&lt;p&gt;But my work is really dry compared to my internship and coursework- the relatively little work I get at least. I was placed with a maintenance team where most of the work is small SQL bug fixes, some legacy code updates, and running no/low code jobs. And as a Jr, they&amp;#39;ve been pretty slow to get me involved in any of the more in depth work despite my insistence. All of my learning is very company specific business process stuff, and I feel like I&amp;#39;m becoming a worse programmer every day. But pretty much everything &lt;em&gt;besides the work&lt;/em&gt; is great here. I know some other new grads hired as part of the same cohort as me are working with Pyspark, designing new pipelines and features, and generally doing much more technical work , so I kinda feel like I just got unlucky with my placement in that way. I\u2019m very concerned that I\u2019m not learning any transferable skills if/when I\u2019m looking for DE roles in other companies down the line.&lt;/p&gt;\n\n&lt;p&gt;Has anyone been in a similar position? Should I stick it out, or try to move to a different team internally? Then I run the risk of getting a much less pleasant to work with team is my worry. I&amp;#39;m trying to work on side projects more to regain some technical skills, it&amp;#39;s just tough to balance with work, other hobbies etc. I wish my job stimulated those skills at least a little.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b29psy", "is_robot_indexable": true, "report_reasons": null, "author": "npapa17", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b29psy/feeling_stagnant_at_first_de_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b29psy/feeling_stagnant_at_first_de_role/", "subreddit_subscribers": 164578, "created_utc": 1709136570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1c6f704", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zero to Hero: Mastering Change Data Capture For Remarkable Database Integrations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1b27q0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ycJDX51KGt-CxBXVSFmRxnoz0uvD4GgdsxwjC2QQ2CU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709131557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datagibberish.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datagibberish.com/p/cdc-zero-to-hero?r=odlo3&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6Yprr-_9ZZ177Pzj549GKTWYY4_RTOWLuJ9LsDuo7AY.jpg?auto=webp&amp;s=0be439f660d0bfd5718272bbd3f5c44f51ad10d1", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/6Yprr-_9ZZ177Pzj549GKTWYY4_RTOWLuJ9LsDuo7AY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=60cbd1a1eeee95e619272d080f6972b2dc9c0356", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/6Yprr-_9ZZ177Pzj549GKTWYY4_RTOWLuJ9LsDuo7AY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=38ca2aefb06f6f2d40c2900172a9f6189dbb6783", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/6Yprr-_9ZZ177Pzj549GKTWYY4_RTOWLuJ9LsDuo7AY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b8ec0c152bfd228b7e6fe3d6902b09609ea7633", "width": 320, "height": 320}], "variants": {}, "id": "IVo0FWHiDAfejzfRVaj0bCPCxjaTH9Zcu4cj0zREdp0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b27q0s", "is_robot_indexable": true, "report_reasons": null, "author": "ivanovyordan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1b27q0s/zero_to_hero_mastering_change_data_capture_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datagibberish.com/p/cdc-zero-to-hero?r=odlo3&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 164578, "created_utc": 1709131557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is using Airbyte for ELT, and having the option to easily add a Dbt transformation with each connection was probably the main point of choosing Airbyte, but they're deprecating this feature by the end of March and focusing on the EL process. We're looking for a data orchestrator to help schedule our airbyte connections (these are created and triggered by using Airbyte's API's) followed by the Dbt transformations, and the recommended tools by Airbyte are Airflow, Dagster, Prefect and Kestra. Which of these would you recommend?\n\nP.S. I think it's obvious that I'm a junior DE that's still very new to the field, I'd appreciate any guidance.", "author_fullname": "t2_fkh83nm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte + Airflow, Dagster, Prefect or Kestra?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b24nxy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709122497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is using Airbyte for ELT, and having the option to easily add a Dbt transformation with each connection was probably the main point of choosing Airbyte, but they&amp;#39;re deprecating this feature by the end of March and focusing on the EL process. We&amp;#39;re looking for a data orchestrator to help schedule our airbyte connections (these are created and triggered by using Airbyte&amp;#39;s API&amp;#39;s) followed by the Dbt transformations, and the recommended tools by Airbyte are Airflow, Dagster, Prefect and Kestra. Which of these would you recommend?&lt;/p&gt;\n\n&lt;p&gt;P.S. I think it&amp;#39;s obvious that I&amp;#39;m a junior DE that&amp;#39;s still very new to the field, I&amp;#39;d appreciate any guidance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b24nxy", "is_robot_indexable": true, "report_reasons": null, "author": "Whatinthetabuleh", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b24nxy/airbyte_airflow_dagster_prefect_or_kestra/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b24nxy/airbyte_airflow_dagster_prefect_or_kestra/", "subreddit_subscribers": 164578, "created_utc": 1709122497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5puh1cdh2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is It Time To Move From dbt to SQLMesh?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2a3xe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1709137477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2024-02-28-dbt-or-sqlmesh", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b2a3xe", "is_robot_indexable": true, "report_reasons": null, "author": "Merlich_RSt", "discussion_type": null, "num_comments": 38, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2a3xe/is_it_time_to_move_from_dbt_to_sqlmesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2024-02-28-dbt-or-sqlmesh", "subreddit_subscribers": 164578, "created_utc": 1709137477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've spent the last ten years at a struggling consulting firm. I specialized in Pentaho. However, my firm never won any big data warehouse projects, so most of my projects were using Pentaho to make Excel spreadsheets.\n\nI stayed because I liked my coworkers and boss. Now that they're gone, I want to leave too and realized I don't have many skills but a decent sounding background since I also shadowed some big sounding projects.\n\nWhat's the best way to revive my career? I don't think Pentaho is it. Or is it? Should I focus a different low code ETL tool? Learn Python?\n\nMaybe go a different path and focus on architecture? Data modeling? Power BI?\n\nHas anyone else struggled with their YOE outpacing their skills?", "author_fullname": "t2_11kz8d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Can I Revive My Career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2jptp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709161841.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709159696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve spent the last ten years at a struggling consulting firm. I specialized in Pentaho. However, my firm never won any big data warehouse projects, so most of my projects were using Pentaho to make Excel spreadsheets.&lt;/p&gt;\n\n&lt;p&gt;I stayed because I liked my coworkers and boss. Now that they&amp;#39;re gone, I want to leave too and realized I don&amp;#39;t have many skills but a decent sounding background since I also shadowed some big sounding projects.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to revive my career? I don&amp;#39;t think Pentaho is it. Or is it? Should I focus a different low code ETL tool? Learn Python?&lt;/p&gt;\n\n&lt;p&gt;Maybe go a different path and focus on architecture? Data modeling? Power BI?&lt;/p&gt;\n\n&lt;p&gt;Has anyone else struggled with their YOE outpacing their skills?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2jptp", "is_robot_indexable": true, "report_reasons": null, "author": "nigelwiggins", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2jptp/how_can_i_revive_my_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2jptp/how_can_i_revive_my_career/", "subreddit_subscribers": 164578, "created_utc": 1709159696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python ETL pipeline with Airbyte and Pathway", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b27h4g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1709130889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pathway.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pathway.com/developers/showcases/etl-python-airbyte", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b27h4g", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b27h4g/python_etl_pipeline_with_airbyte_and_pathway/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pathway.com/developers/showcases/etl-python-airbyte", "subreddit_subscribers": 164578, "created_utc": 1709130889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been scrolling through the job postings on LinkedIn, and a lot of them have been asking for knowledge of ML with some MLOps experience. \n\nIn my current company, data engineers only work on ETLs with Airflow and some services in python.\n\nSo I was wondering if I need to properly learn ML to be a good data engineer and maybe secure the future so to say.\n", "author_fullname": "t2_75codjxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common for data engineers to have proficiency in ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2qxvx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709179180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been scrolling through the job postings on LinkedIn, and a lot of them have been asking for knowledge of ML with some MLOps experience. &lt;/p&gt;\n\n&lt;p&gt;In my current company, data engineers only work on ETLs with Airflow and some services in python.&lt;/p&gt;\n\n&lt;p&gt;So I was wondering if I need to properly learn ML to be a good data engineer and maybe secure the future so to say.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2qxvx", "is_robot_indexable": true, "report_reasons": null, "author": "UltramanQuar", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2qxvx/is_it_common_for_data_engineers_to_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2qxvx/is_it_common_for_data_engineers_to_have/", "subreddit_subscribers": 164578, "created_utc": 1709179180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nJust wrapped up a project where I built a system to predict rental prices using data from Rightmove. I really dived into Data Engineering, ML Engineering, and MLOps, all thanks to the free Data Talk Clubs courses I took. I am self taught in Data Engineering and ML in general (Finance graduate). I would really appreciate any constructive feedback on this project. \n\n**Quick features:**\n\n* Production Web Scraping with monitoring\n* RandomForest Rental Prediction model with feature engineering. Engineered the walk score algorithm (based on what I could find online) \n* MLOps with model, data quality and data drift monitoring. \n\n**Tech Stack:**\n\n* Infrastructure: Terraform, Docker Compose, AWS, and GCP.\n* Model serving with FastAPI and visual insights via Streamlit and Grafana.\n* Experiment tracking with MLFlow.\n\nI really tried to mesh everything I could from these courses together. I am not sure if I followed industry standards. Feel free to be as harsh and as honest as you like. All I care about is that the feedback is actionable. Thank you. \n\n&amp;#x200B;\n\n[System Diagram](https://preview.redd.it/hkikvujy9blc1.png?width=4913&amp;format=png&amp;auto=webp&amp;s=8df8f6e916fd98a48ca89b7467e4b4d917b7a7bd)\n\nGithub: [https://github.com/alexandergirardet/london\\_rightmove](https://github.com/alexandergirardet/london_rightmove)", "author_fullname": "t2_7kiysnlez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rental Price Prediction ML/Data system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hkikvujy9blc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/hkikvujy9blc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6b4ecf2fe0ef73b5dc27d2555c54346cf414dfaa"}, {"y": 142, "x": 216, "u": "https://preview.redd.it/hkikvujy9blc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f7b791dda412d51718c47c7fc75c4eedca8e99bf"}, {"y": 211, "x": 320, "u": "https://preview.redd.it/hkikvujy9blc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2bd0aee1e01699207466451210f864605d526d41"}, {"y": 423, "x": 640, "u": "https://preview.redd.it/hkikvujy9blc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b12ae52d47ce9bcaf8f6bdd732b5877662d12ff"}, {"y": 634, "x": 960, "u": "https://preview.redd.it/hkikvujy9blc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0f2c241e29f1baec345d13a994aff4fda15cde66"}, {"y": 713, "x": 1080, "u": "https://preview.redd.it/hkikvujy9blc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d42da4d411d269eb458b1a57ffa8bca7536c8b0d"}], "s": {"y": 3248, "x": 4913, "u": "https://preview.redd.it/hkikvujy9blc1.png?width=4913&amp;format=png&amp;auto=webp&amp;s=8df8f6e916fd98a48ca89b7467e4b4d917b7a7bd"}, "id": "hkikvujy9blc1"}}, "name": "t3_1b23thj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pF2HR7JNASG7SvVBIwqpZ18vFo5gCEZW6EK8QLX6ATU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1709119579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;Just wrapped up a project where I built a system to predict rental prices using data from Rightmove. I really dived into Data Engineering, ML Engineering, and MLOps, all thanks to the free Data Talk Clubs courses I took. I am self taught in Data Engineering and ML in general (Finance graduate). I would really appreciate any constructive feedback on this project. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick features:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Production Web Scraping with monitoring&lt;/li&gt;\n&lt;li&gt;RandomForest Rental Prediction model with feature engineering. Engineered the walk score algorithm (based on what I could find online) &lt;/li&gt;\n&lt;li&gt;MLOps with model, data quality and data drift monitoring. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Tech Stack:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Infrastructure: Terraform, Docker Compose, AWS, and GCP.&lt;/li&gt;\n&lt;li&gt;Model serving with FastAPI and visual insights via Streamlit and Grafana.&lt;/li&gt;\n&lt;li&gt;Experiment tracking with MLFlow.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I really tried to mesh everything I could from these courses together. I am not sure if I followed industry standards. Feel free to be as harsh and as honest as you like. All I care about is that the feedback is actionable. Thank you. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hkikvujy9blc1.png?width=4913&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8df8f6e916fd98a48ca89b7467e4b4d917b7a7bd\"&gt;System Diagram&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/alexandergirardet/london_rightmove\"&gt;https://github.com/alexandergirardet/london_rightmove&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_VYKNb9XM32VNo31NViqbvuQWQ_oQZyIQv97uSIZ36E.jpg?auto=webp&amp;s=1ae21a88a44fcec76fcc4fcd3fbc82f4c54cfa78", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_VYKNb9XM32VNo31NViqbvuQWQ_oQZyIQv97uSIZ36E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=601bdb1e3403eaa8c338c8cd4e4eacd6cc9a43ac", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_VYKNb9XM32VNo31NViqbvuQWQ_oQZyIQv97uSIZ36E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=690b982c78a6f130040da7605f55e82e5bfa2893", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_VYKNb9XM32VNo31NViqbvuQWQ_oQZyIQv97uSIZ36E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e2b21acf899b7251354347bfa50b80c024f5834", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_VYKNb9XM32VNo31NViqbvuQWQ_oQZyIQv97uSIZ36E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e5857ffe0f3f70e26bebecd6220980fe9ad7fab", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_VYKNb9XM32VNo31NViqbvuQWQ_oQZyIQv97uSIZ36E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=026227c8bdb54856ecf4a89daaaee393a7ff6bf8", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_VYKNb9XM32VNo31NViqbvuQWQ_oQZyIQv97uSIZ36E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1729cd0fd7b0c72b3c2d1761f87b556ed476fa1d", "width": 1080, "height": 540}], "variants": {}, "id": "H1SGab16E_VzBuxBMY1UzihuMtP-QTbjKRH4HFsHyyY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1b23thj", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Bobcat_7458", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b23thj/rental_price_prediction_mldata_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b23thj/rental_price_prediction_mldata_system/", "subreddit_subscribers": 164578, "created_utc": 1709119579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey Azure enthusiasts and data wizards! \ud83d\ude80\n\nWe've put together an **in-depth video series** designed to take your Azure Data Engineering and Analytics skills to the next level. Whether you're just starting out or looking to deepen your expertise, our playlist covers everything from **real-time analytics** to **data wrangling**, and more, using Azure's powerful suite of services.\n\n**Here's a sneak peek of what you'll find:**\n\n1. **Twitter Sentiment Analysis with Azure Synapse Analytics** \\- Dive into real-time sentiment analysis and build end-to-end big data pipelines.\n2. **Real-time Vehicle Telemetry Processing** \\- Learn how to handle real-time vehicle data with Azure Stream Analytics and Event Hub.\n3. **Fraudulent Call Detection** \\- Discover how to detect fraudulent calls in real-time using Azure Stream Analytics.\n4. **Weather Forecasting with Azure IoT Hub** \\- Explore how to forecast weather using sensor data from Azure IoT Hub and Machine Learning Studio.\n5. **Web Scraping with Azure Synapse** \\- Get hands-on with web scraping using Azure Synapse, Python, and Spark Pool.\n6. ... and much more across 20+ videos covering Azure Databricks, Azure Data Factory, and other Azure services.\n\n**Why check out our playlist?**\n\n* **Varied Topics**: From analytics to processing, explore Azure's capabilities through practical examples.\n* **Skill Levels**: Content tailored for both beginners and experienced professionals.\n* **Community Support**: Join our growing community, share your progress, and get support from fellow Azure learners.\n\nDive in now and start transforming data into actionable insights with Azure! Check out our playlist\n\n[https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0](https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0)\n\n**What's your biggest challenge with Azure or data engineering/analytics?** Let's discuss in the comments below!", "author_fullname": "t2_b7f9ay9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlock the Full Potential of Azure for Data Engineering and Analytics with Our Comprehensive Video Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2tcev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709186992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Azure enthusiasts and data wizards! \ud83d\ude80&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve put together an &lt;strong&gt;in-depth video series&lt;/strong&gt; designed to take your Azure Data Engineering and Analytics skills to the next level. Whether you&amp;#39;re just starting out or looking to deepen your expertise, our playlist covers everything from &lt;strong&gt;real-time analytics&lt;/strong&gt; to &lt;strong&gt;data wrangling&lt;/strong&gt;, and more, using Azure&amp;#39;s powerful suite of services.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s a sneak peek of what you&amp;#39;ll find:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Twitter Sentiment Analysis with Azure Synapse Analytics&lt;/strong&gt; - Dive into real-time sentiment analysis and build end-to-end big data pipelines.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Real-time Vehicle Telemetry Processing&lt;/strong&gt; - Learn how to handle real-time vehicle data with Azure Stream Analytics and Event Hub.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fraudulent Call Detection&lt;/strong&gt; - Discover how to detect fraudulent calls in real-time using Azure Stream Analytics.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Weather Forecasting with Azure IoT Hub&lt;/strong&gt; - Explore how to forecast weather using sensor data from Azure IoT Hub and Machine Learning Studio.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Web Scraping with Azure Synapse&lt;/strong&gt; - Get hands-on with web scraping using Azure Synapse, Python, and Spark Pool.&lt;/li&gt;\n&lt;li&gt;... and much more across 20+ videos covering Azure Databricks, Azure Data Factory, and other Azure services.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Why check out our playlist?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Varied Topics&lt;/strong&gt;: From analytics to processing, explore Azure&amp;#39;s capabilities through practical examples.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Skill Levels&lt;/strong&gt;: Content tailored for both beginners and experienced professionals.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Community Support&lt;/strong&gt;: Join our growing community, share your progress, and get support from fellow Azure learners.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Dive in now and start transforming data into actionable insights with Azure! Check out our playlist&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0\"&gt;https://www.youtube.com/playlist?list=PLDgHYwLUl4HjJMw1-z7MNDEnM7JNchIe0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s your biggest challenge with Azure or data engineering/analytics?&lt;/strong&gt; Let&amp;#39;s discuss in the comments below!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/i77eGnJm5EfFhj2Iq4lTkoc5z9v72OpTXOO4rMMBP_4.jpg?auto=webp&amp;s=d77ea717953685723e11d432a03b8e1a193364f2", "width": 168, "height": 94}, "resolutions": [{"url": "https://external-preview.redd.it/i77eGnJm5EfFhj2Iq4lTkoc5z9v72OpTXOO4rMMBP_4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c44d70afc0a3160f83b7d53dfc53e12f46edea0e", "width": 108, "height": 60}], "variants": {}, "id": "ljaxuQA5RXlRP1KI4q0RlFon2Axy4tPxeCMyfteBtAg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b2tcev", "is_robot_indexable": true, "report_reasons": null, "author": "balramprasad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2tcev/unlock_the_full_potential_of_azure_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2tcev/unlock_the_full_potential_of_azure_for_data/", "subreddit_subscribers": 164578, "created_utc": 1709186992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are in the process of building out a new data warehouse, and I've been reading Kimball on dimensional modeling. Does anyone know of any good sources or have any advice on optimizing our data model specifically with PowerBI's vertipaq engine in mind?", "author_fullname": "t2_49ipr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing data model for PowerBI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b27wbs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709132026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are in the process of building out a new data warehouse, and I&amp;#39;ve been reading Kimball on dimensional modeling. Does anyone know of any good sources or have any advice on optimizing our data model specifically with PowerBI&amp;#39;s vertipaq engine in mind?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b27wbs", "is_robot_indexable": true, "report_reasons": null, "author": "thomasutra", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b27wbs/optimizing_data_model_for_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b27wbs/optimizing_data_model_for_powerbi/", "subreddit_subscribers": 164578, "created_utc": 1709132026.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Role of Interoperability in End-to-End Data Governance: As Implemented by Data Developer Platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1b25xlc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/M4cxEA9NVhD8DRIWHM8Ajz_2HN3nPEhqfhlSZm6P2xc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709126512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/role-of-interoperability-in-end-to", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RRw0A9DFPXOPeSrK3f3BXSpbqYgmyA6qGabnFAxNhN8.jpg?auto=webp&amp;s=4d9c8cccb71946e01306c967d477a205f10d362b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/RRw0A9DFPXOPeSrK3f3BXSpbqYgmyA6qGabnFAxNhN8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=314e4e94f444969dad82dfb98e383bc69dc54fa4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/RRw0A9DFPXOPeSrK3f3BXSpbqYgmyA6qGabnFAxNhN8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=507d19878f183c99abec4797771193cc2ebb1877", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/RRw0A9DFPXOPeSrK3f3BXSpbqYgmyA6qGabnFAxNhN8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=addb80b38d493b4a5b902d5c4ae744678e03ed23", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/RRw0A9DFPXOPeSrK3f3BXSpbqYgmyA6qGabnFAxNhN8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d2f2868977ec9a9690a4c46182abf87e3221485c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/RRw0A9DFPXOPeSrK3f3BXSpbqYgmyA6qGabnFAxNhN8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=175f2aefcfdf5427d8de757de3db14e4290c829d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/RRw0A9DFPXOPeSrK3f3BXSpbqYgmyA6qGabnFAxNhN8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5dd448f1e944e3f2f54c55c18830c600312592eb", "width": 1080, "height": 540}], "variants": {}, "id": "6rcHi_tEisOpy7ufTkqiEjSOuRr6NREOrmx6JJA2zck"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b25xlc", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b25xlc/role_of_interoperability_in_endtoend_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/role-of-interoperability-in-end-to", "subreddit_subscribers": 164578, "created_utc": 1709126512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am applying for an Advertising Technology company for data engineer role and company said they'll prefer candidates who has some AdTech related data engineering projects. Any suggestions/project ideas you guys have ( plus if you can in short write a high level design description about your project idea then it'll be helpful) ", "author_fullname": "t2_umxhnmq0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want suggestions for making an AdTech related data engineering project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2rrjj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709181779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am applying for an Advertising Technology company for data engineer role and company said they&amp;#39;ll prefer candidates who has some AdTech related data engineering projects. Any suggestions/project ideas you guys have ( plus if you can in short write a high level design description about your project idea then it&amp;#39;ll be helpful) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b2rrjj", "is_robot_indexable": true, "report_reasons": null, "author": "perfektenschlagggg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2rrjj/want_suggestions_for_making_an_adtech_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2rrjj/want_suggestions_for_making_an_adtech_related/", "subreddit_subscribers": 164578, "created_utc": 1709181779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_46tlcjz3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PostgreSQL: Prevent accidental database deletion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2h27l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jv2DTODEkKIrWzAlETVfeZyIapbdI3nYmgISPkk0eEw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709153477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "telablog.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://telablog.com/postgresql-prevent-accidental-database-deletion", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?auto=webp&amp;s=975a6bcde79f529ec129d699f8409a9b286861c3", "width": 630, "height": 453}, "resolutions": [{"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aa32bb93cad95f6e2cfd72151be0bfb909066cb", "width": 108, "height": 77}, {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35712222711f2186f600b7062158da4ec1fad92a", "width": 216, "height": 155}, {"url": "https://external-preview.redd.it/4sGhT9umGZ-82kigEnFjlBA5aQlLy8OYTTVeTLOAeBc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=448c26ecdb1120d348a7c7857a528381ac0aabf5", "width": 320, "height": 230}], "variants": {}, "id": "1LFo4RaOds-V5iIDcqED1C0usKQRMLUDV_VKhGkZwcI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b2h27l", "is_robot_indexable": true, "report_reasons": null, "author": "stjohn_piano", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2h27l/postgresql_prevent_accidental_database_deletion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://telablog.com/postgresql-prevent-accidental-database-deletion", "subreddit_subscribers": 164578, "created_utc": 1709153477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was reading [this article](https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/) from Start Data Engineering today, and saw they suggest including Make in your projects. I generally really like the Start Data Engineering content, but I guess I don't really see the clear value of Make. In my personal projects I've developed, my IaC and things like pushing new Docker containers is governed by Github Actions. \n\nIs there a lot of complex CLI work in on-the-job workflows where Make would have more value? ", "author_fullname": "t2_u7dxdkls1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common in the use of Make/Makefiles in the field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2ekwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709147712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading &lt;a href=\"https://www.startdataengineering.com/post/data-engineering-projects-with-free-template/\"&gt;this article&lt;/a&gt; from Start Data Engineering today, and saw they suggest including Make in your projects. I generally really like the Start Data Engineering content, but I guess I don&amp;#39;t really see the clear value of Make. In my personal projects I&amp;#39;ve developed, my IaC and things like pushing new Docker containers is governed by Github Actions. &lt;/p&gt;\n\n&lt;p&gt;Is there a lot of complex CLI work in on-the-job workflows where Make would have more value? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?auto=webp&amp;s=6868d1afd30fafa653a032eb2da58622ea884d10", "width": 1707, "height": 961}, "resolutions": [{"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e21312ac131abd754219be380dab9dd9e467ba6", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab6d062abc62b7caadc8a19b44d8c000993675d5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb4f46bf53ebfa79c43faac10ced6bda3c97a7d8", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8aad3115e4ceb2e5c04e65d64a60019d2f5aa217", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fb4f67358973f94066e046ed886b376d71897eb4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/CcOzb493iHpy9vgZ9tvIp4SuiudGeb-5SBmuQKuQMRo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4a7872abe5498e855972451d3dd12aa86ad51e81", "width": 1080, "height": 608}], "variants": {}, "id": "35-OLZXPWHZTRGzuafvdWv9VwqHqY_S4pFJfcK7yGZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b2ekwa", "is_robot_indexable": true, "report_reasons": null, "author": "SchemaScorcher", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2ekwa/how_common_in_the_use_of_makemakefiles_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2ekwa/how_common_in_the_use_of_makemakefiles_in_the/", "subreddit_subscribers": 164578, "created_utc": 1709147712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a data engineer and my manager wants to keep a decision log of all decision made on the project. Is this something useful I should spent time on? Any suggestion on how to do this?", "author_fullname": "t2_8kjj8h0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Decision log - what is your opinion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2b54x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709139845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data engineer and my manager wants to keep a decision log of all decision made on the project. Is this something useful I should spent time on? Any suggestion on how to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b2b54x", "is_robot_indexable": true, "report_reasons": null, "author": "Lem0nR0cket", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2b54x/decision_log_what_is_your_opinion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2b54x/decision_log_what_is_your_opinion/", "subreddit_subscribers": 164578, "created_utc": 1709139845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there - I have an option to either go for a DBA internship in a big tech company which might lead to job/give me a kickstart in data career OR take an expensive Data Engineering bootcamp which would teach latest tech stack like Apache Nifi, Spark, Hive, Pig, Kafka, etc. and offer job/internship placement.\n\nWhich path should I take? I am a recent grad with Engineering Major. My ultimate goal is to become Data Engineer but due to no Data related experience, I am not really able to land a relevant role.\n\nWould appreciate any guidance/comments!", "author_fullname": "t2_lm8mxlfu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance needed: DBA internship or DE bootcamp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b28f8d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709133382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there - I have an option to either go for a DBA internship in a big tech company which might lead to job/give me a kickstart in data career OR take an expensive Data Engineering bootcamp which would teach latest tech stack like Apache Nifi, Spark, Hive, Pig, Kafka, etc. and offer job/internship placement.&lt;/p&gt;\n\n&lt;p&gt;Which path should I take? I am a recent grad with Engineering Major. My ultimate goal is to become Data Engineer but due to no Data related experience, I am not really able to land a relevant role.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate any guidance/comments!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b28f8d", "is_robot_indexable": true, "report_reasons": null, "author": "NetIllustrious6586", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b28f8d/guidance_needed_dba_internship_or_de_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b28f8d/guidance_needed_dba_internship_or_de_bootcamp/", "subreddit_subscribers": 164578, "created_utc": 1709133382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All. I am an engineering fresh graduate and am trying to learn about different big data technologies. I want to create a project to put on my portfolio, but I am quite confused about different tools. This workflow is what I am thinking:\n\nStep 1: Calling financial data API / Google Trend from Python running on local laptop\n\nStep 2: Sending above data to Kafka topics hosted on EC2\n\nStep 3: Subscribing to the topics from pyspark and carry out stream transformation and aggregation\n\nStep 4: Streaming the results to Snowflake for more analysis and visualization\n\nSo firstly, I feel that I am just using Kafka as a pub-sub service, and pyspark as another version of pandas. Even if I get all these to work, I am not confident that I can work with \"big\" data. What else should I learn about these tools. Are they supposed to just work when deployed to an auto-scaling compute cluster?\n\nAnd secondly, is this what you would see in real-life application?\n\nWould love suggestions on what to learn and changes to make. Thanks in advance!", "author_fullname": "t2_jcn6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning about big data techs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2qijg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709187233.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709177865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. I am an engineering fresh graduate and am trying to learn about different big data technologies. I want to create a project to put on my portfolio, but I am quite confused about different tools. This workflow is what I am thinking:&lt;/p&gt;\n\n&lt;p&gt;Step 1: Calling financial data API / Google Trend from Python running on local laptop&lt;/p&gt;\n\n&lt;p&gt;Step 2: Sending above data to Kafka topics hosted on EC2&lt;/p&gt;\n\n&lt;p&gt;Step 3: Subscribing to the topics from pyspark and carry out stream transformation and aggregation&lt;/p&gt;\n\n&lt;p&gt;Step 4: Streaming the results to Snowflake for more analysis and visualization&lt;/p&gt;\n\n&lt;p&gt;So firstly, I feel that I am just using Kafka as a pub-sub service, and pyspark as another version of pandas. Even if I get all these to work, I am not confident that I can work with &amp;quot;big&amp;quot; data. What else should I learn about these tools. Are they supposed to just work when deployed to an auto-scaling compute cluster?&lt;/p&gt;\n\n&lt;p&gt;And secondly, is this what you would see in real-life application?&lt;/p&gt;\n\n&lt;p&gt;Would love suggestions on what to learn and changes to make. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2qijg", "is_robot_indexable": true, "report_reasons": null, "author": "hyyyyyyyyy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2qijg/learning_about_big_data_techs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2qijg/learning_about_big_data_techs/", "subreddit_subscribers": 164578, "created_utc": 1709177865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nToday I am working on a data pipeline where my ingestion-app processes realtime network traffic from multiple sources and writes into a Kafka bus in JSON format to be consumed by multiple endpoints. Apart from realtime processing I need to store a copy of it for future  processing/analysis.\n\nI was wondering which db would be the better option for offline consumption as the data is huge (atleast 10-20 TB per month) from more than 1000 nodes. I came across different demos where clickhouse or elastic search is used as final resting place or storage of network traffic and then grafana is used for visualization. \n\nI am not an elastic search expert but I feel it is a search engine capable of indexing string data. But can I retrieve the same data in future for further processing? Since Network traffic is timeseries data is elastic search good for this?\n\nAny suggestions based on your experience would be of great help\n\n&amp;#x200B;", "author_fullname": "t2_a0gdmw2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage of network traffic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2kluj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709161760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;Today I am working on a data pipeline where my ingestion-app processes realtime network traffic from multiple sources and writes into a Kafka bus in JSON format to be consumed by multiple endpoints. Apart from realtime processing I need to store a copy of it for future  processing/analysis.&lt;/p&gt;\n\n&lt;p&gt;I was wondering which db would be the better option for offline consumption as the data is huge (atleast 10-20 TB per month) from more than 1000 nodes. I came across different demos where clickhouse or elastic search is used as final resting place or storage of network traffic and then grafana is used for visualization. &lt;/p&gt;\n\n&lt;p&gt;I am not an elastic search expert but I feel it is a search engine capable of indexing string data. But can I retrieve the same data in future for further processing? Since Network traffic is timeseries data is elastic search good for this?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions based on your experience would be of great help&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2kluj", "is_robot_indexable": true, "report_reasons": null, "author": "LobsterMost5947", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2kluj/storage_of_network_traffic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2kluj/storage_of_network_traffic/", "subreddit_subscribers": 164578, "created_utc": 1709161760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to create a mapping table which would contain hased value of my primary key .\n\nOnce the data gets inside the snowflake , before it stored to table a proc shall be able to hash the values for all columns which are tagged as pii.\nThis hashed value shall be used in all transformation and when this data gets out of snowflake  want to change it back to original value using the mapping table.\nEg. Below data to be ingested in target_table \nId1| type|id2|type|\n1234@abc.com|email|987654321|phone.\n\n\nSo basically id1 and id2 shall be stored in mapping table along with their hased value and type(for cluster) ,and it's hashed value shall be stored in target _table.\n\nOne way of doing it is \nCreate a mapping table cluster by pii type .\nProc1 : to check into mapping table , if the I'd exists,if not then insert the I'd value along with type and it's hashed value .\nProc2 : to join the outlying data with mapping table and convert the id1 and id2 into it's hashed version.\n\n\nBut this solution is not scaleable. What I mean is if my mapping  table  size is huge like 100 billion records , the join operation takes too much time .\n", "author_fullname": "t2_a3fustvg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake virtualization table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b2g1os", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709151138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to create a mapping table which would contain hased value of my primary key .&lt;/p&gt;\n\n&lt;p&gt;Once the data gets inside the snowflake , before it stored to table a proc shall be able to hash the values for all columns which are tagged as pii.\nThis hashed value shall be used in all transformation and when this data gets out of snowflake  want to change it back to original value using the mapping table.\nEg. Below data to be ingested in target_table \nId1| type|id2|type|\n&lt;a href=\"mailto:1234@abc.com\"&gt;1234@abc.com&lt;/a&gt;|email|987654321|phone.&lt;/p&gt;\n\n&lt;p&gt;So basically id1 and id2 shall be stored in mapping table along with their hased value and type(for cluster) ,and it&amp;#39;s hashed value shall be stored in target _table.&lt;/p&gt;\n\n&lt;p&gt;One way of doing it is \nCreate a mapping table cluster by pii type .\nProc1 : to check into mapping table , if the I&amp;#39;d exists,if not then insert the I&amp;#39;d value along with type and it&amp;#39;s hashed value .\nProc2 : to join the outlying data with mapping table and convert the id1 and id2 into it&amp;#39;s hashed version.&lt;/p&gt;\n\n&lt;p&gt;But this solution is not scaleable. What I mean is if my mapping  table  size is huge like 100 billion records , the join operation takes too much time .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b2g1os", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Ad4657", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b2g1os/snowflake_virtualization_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b2g1os/snowflake_virtualization_table/", "subreddit_subscribers": 164578, "created_utc": 1709151138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  Not quite a DE question, but DE adjacent.\n\nI come from a very traditional data warehouse background (read: I'm old) and I am trying to understand the databricks ecosystem from an architecture POV.  I've always thought of DBX as \"hosted spark\" but there is a lot of talk around the \"lakehouse\" using DeltaLake + Unity + Photon (which I assume is similar to Iceberg + Glue/ Hive + Presto/trino).  \n\nMy question is... to use DBX, are most companies using Unity or Hive catalog to organize their files?  Is the \"Lakehouse\" architecture ubiquitous or something that DBX marketing is pushing?  If your company is using DBX, what is the main value driver?\n\nSorry for the noob question here... just trying to understand how DBX is being used in the wild vs what I can read on the interwebs.  Is there any DBX user communities that I might get some real world information that you all recommend?", "author_fullname": "t2_oswdvnyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning DBX Ecosystem- architecture qs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b29dip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709135763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!  Not quite a DE question, but DE adjacent.&lt;/p&gt;\n\n&lt;p&gt;I come from a very traditional data warehouse background (read: I&amp;#39;m old) and I am trying to understand the databricks ecosystem from an architecture POV.  I&amp;#39;ve always thought of DBX as &amp;quot;hosted spark&amp;quot; but there is a lot of talk around the &amp;quot;lakehouse&amp;quot; using DeltaLake + Unity + Photon (which I assume is similar to Iceberg + Glue/ Hive + Presto/trino).  &lt;/p&gt;\n\n&lt;p&gt;My question is... to use DBX, are most companies using Unity or Hive catalog to organize their files?  Is the &amp;quot;Lakehouse&amp;quot; architecture ubiquitous or something that DBX marketing is pushing?  If your company is using DBX, what is the main value driver?&lt;/p&gt;\n\n&lt;p&gt;Sorry for the noob question here... just trying to understand how DBX is being used in the wild vs what I can read on the interwebs.  Is there any DBX user communities that I might get some real world information that you all recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b29dip", "is_robot_indexable": true, "report_reasons": null, "author": "Fine_Piglet_815", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b29dip/learning_dbx_ecosystem_architecture_qs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b29dip/learning_dbx_ecosystem_architecture_qs/", "subreddit_subscribers": 164578, "created_utc": 1709135763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow data plumbers,\n\nHow have you guys implemented Symantec layer in your organisation? We have a Data Mesh and hybrid cloud with multiple CDPs and On Prem data platform for different regions and specific BUs. Now want to implement a Symantec layer to sit on top of them. DBT Cloud Symantec layer looked interesting and we are already implementing DBT core in one of the regions (This is on Snowflake )\n\nCurious to know how is it being done in other large enterprises with multiple data platforms. Any insights are much appreciated ", "author_fullname": "t2_qshu8mn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Symantec Layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b27lwz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709131251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow data plumbers,&lt;/p&gt;\n\n&lt;p&gt;How have you guys implemented Symantec layer in your organisation? We have a Data Mesh and hybrid cloud with multiple CDPs and On Prem data platform for different regions and specific BUs. Now want to implement a Symantec layer to sit on top of them. DBT Cloud Symantec layer looked interesting and we are already implementing DBT core in one of the regions (This is on Snowflake )&lt;/p&gt;\n\n&lt;p&gt;Curious to know how is it being done in other large enterprises with multiple data platforms. Any insights are much appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b27lwz", "is_robot_indexable": true, "report_reasons": null, "author": "Global_Industry_6801", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b27lwz/symantec_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b27lwz/symantec_layer/", "subreddit_subscribers": 164578, "created_utc": 1709131251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Either I\u2019m losing my ability to google, or there really is just a complete lack of comprehensive Prefect testing documentation that covers more than assert my_flow() == 42. I feel like I need to join the Freemasons to learn the ancient secrets for this. \n\nBasic stuff I get, but mocking dependencies? Mocking out datetime without freezegun causing everything to error out?\n\nHas anyone successfully unit tested anything in prefect more advanced than a hello world flow?", "author_fullname": "t2_1eht5os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on unit testing Prefect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b26bx0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709127703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Either I\u2019m losing my ability to google, or there really is just a complete lack of comprehensive Prefect testing documentation that covers more than assert my_flow() == 42. I feel like I need to join the Freemasons to learn the ancient secrets for this. &lt;/p&gt;\n\n&lt;p&gt;Basic stuff I get, but mocking dependencies? Mocking out datetime without freezegun causing everything to error out?&lt;/p&gt;\n\n&lt;p&gt;Has anyone successfully unit tested anything in prefect more advanced than a hello world flow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b26bx0", "is_robot_indexable": true, "report_reasons": null, "author": "mbsquad24", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b26bx0/need_advice_on_unit_testing_prefect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b26bx0/need_advice_on_unit_testing_prefect/", "subreddit_subscribers": 164578, "created_utc": 1709127703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here is my situation:\n\nIt is required to implement an address management system for an existent web-based software solution at the company That uses an OLTP Postgres database to store relevant address data. The address data covers a single state, with a complete amount of 5 million addresses. The project context is building broadband infrastructure for each of the addresses that do not have a fast-speed internet connection yet. There are several steps in the address management process involved, with each step adding more attributes to the address data. For instance, there is the source address data with basic address information such as street name, house number, or zip code. Then there is another external data provider who provides information about the amount of households at the address and a third provider who gives information about the height of the building. All this data is now the starting point for the address data process, in which addresses can be verified, changed, excluded (or deleted) and even new addresses added. These operations can be performed by different stakeholder, e.g. the municipality in which the address is located at or the project manager. However, relevant data comes from different plattforms, depending on the process step. For example\n\n* data is delivered as Excel by mail,\n* a CRM system stores status of projects and important files that need to be linked to the adress,\n* A partner company handles the tracking of the construction process in their web-software\n* our own web-software to handle specific attributes of an address and even add or remove addresses\n\nHere is a (not complete) process of the data:\n\n1. Identify addresses that are eligible to get new broadband infrastructure and flag them accordingly and add information about their currently connected technology\n2. Provide the opportunity to change values of specific attributes of an address.\n3. When data was verified, send the data to the public institution that handles allowance of receiving public funding for building the infrastructure.\n4. Receive the data back from the instituion once the check is finished and add data check inquiries asked by that institution into the address data.\n5. Provide the opportunity to change that data accordingly by project managers.\n6. Provide final data to the companies that build that infrastructure grouped by incremental building areas and track the progress of the work in the address data.\n\nI struggle with the following problem:\n\nIs it rational to have a Data Warehouse that acts as a center piece to handle all that data? When I see the following definition of a data warehouse I found in the internet it is exactly the use case I have:\n\n&gt;Data warehouses are commonly used primarily for combining data from one or more sources, reducing load on operational systems, tracking historical changes in data and providing a single source of truth.\n\nHowever, on the other side its main purpose (by definition) is to provide analytical capabilities, which are also to some extent necessary, but the main focus for us would be to use the data warehouse as an intermediate step, where our web software is not only the source of the data but also the target of data that was cleaned, checked and processed in the data warehouse. Or should everything happen in the existing OLTP Postgres database and a data warehouse is not necessary?", "author_fullname": "t2_mwoc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OLAP vs. OLTP? Which system to use to handle business process for adress management?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b22r8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709115533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is my situation:&lt;/p&gt;\n\n&lt;p&gt;It is required to implement an address management system for an existent web-based software solution at the company That uses an OLTP Postgres database to store relevant address data. The address data covers a single state, with a complete amount of 5 million addresses. The project context is building broadband infrastructure for each of the addresses that do not have a fast-speed internet connection yet. There are several steps in the address management process involved, with each step adding more attributes to the address data. For instance, there is the source address data with basic address information such as street name, house number, or zip code. Then there is another external data provider who provides information about the amount of households at the address and a third provider who gives information about the height of the building. All this data is now the starting point for the address data process, in which addresses can be verified, changed, excluded (or deleted) and even new addresses added. These operations can be performed by different stakeholder, e.g. the municipality in which the address is located at or the project manager. However, relevant data comes from different plattforms, depending on the process step. For example&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;data is delivered as Excel by mail,&lt;/li&gt;\n&lt;li&gt;a CRM system stores status of projects and important files that need to be linked to the adress,&lt;/li&gt;\n&lt;li&gt;A partner company handles the tracking of the construction process in their web-software&lt;/li&gt;\n&lt;li&gt;our own web-software to handle specific attributes of an address and even add or remove addresses&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here is a (not complete) process of the data:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Identify addresses that are eligible to get new broadband infrastructure and flag them accordingly and add information about their currently connected technology&lt;/li&gt;\n&lt;li&gt;Provide the opportunity to change values of specific attributes of an address.&lt;/li&gt;\n&lt;li&gt;When data was verified, send the data to the public institution that handles allowance of receiving public funding for building the infrastructure.&lt;/li&gt;\n&lt;li&gt;Receive the data back from the instituion once the check is finished and add data check inquiries asked by that institution into the address data.&lt;/li&gt;\n&lt;li&gt;Provide the opportunity to change that data accordingly by project managers.&lt;/li&gt;\n&lt;li&gt;Provide final data to the companies that build that infrastructure grouped by incremental building areas and track the progress of the work in the address data.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I struggle with the following problem:&lt;/p&gt;\n\n&lt;p&gt;Is it rational to have a Data Warehouse that acts as a center piece to handle all that data? When I see the following definition of a data warehouse I found in the internet it is exactly the use case I have:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Data warehouses are commonly used primarily for combining data from one or more sources, reducing load on operational systems, tracking historical changes in data and providing a single source of truth.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;However, on the other side its main purpose (by definition) is to provide analytical capabilities, which are also to some extent necessary, but the main focus for us would be to use the data warehouse as an intermediate step, where our web software is not only the source of the data but also the target of data that was cleaned, checked and processed in the data warehouse. Or should everything happen in the existing OLTP Postgres database and a data warehouse is not necessary?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b22r8x", "is_robot_indexable": true, "report_reasons": null, "author": "rick854", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b22r8x/olap_vs_oltp_which_system_to_use_to_handle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b22r8x/olap_vs_oltp_which_system_to_use_to_handle/", "subreddit_subscribers": 164578, "created_utc": 1709115533.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}