{"kind": "Listing", "data": {"after": "t3_1atjjzz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_n9n0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who needs pooled drives??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 59, "top_awarded_type": null, "hide_score": false, "name": "t3_1at629u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 437, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 437, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/md8w3xdp_PG-_jZKxfD6ZLmcBTnYuAj2iahT4i7fsnw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708187952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jvg8v3lqb6jc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jvg8v3lqb6jc1.jpeg?auto=webp&amp;s=92561e88b4670bd2727dd8cea6f8a8a7d1382594", "width": 801, "height": 339}, "resolutions": [{"url": "https://preview.redd.it/jvg8v3lqb6jc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=44e14268ba620f898e2c5be8605e227433272556", "width": 108, "height": 45}, {"url": "https://preview.redd.it/jvg8v3lqb6jc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6107b1cac072bf2e9f80fb8ff1c821bd3346112f", "width": 216, "height": 91}, {"url": "https://preview.redd.it/jvg8v3lqb6jc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5708f9a7458c1b3c33d6f4ff138e68038bfb93ae", "width": 320, "height": 135}, {"url": "https://preview.redd.it/jvg8v3lqb6jc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b78756783ddc17bce7adbb6c019f68e981873f6d", "width": 640, "height": 270}], "variants": {}, "id": "UTD_6Ep6bmwwC5NOqERro9llBMNksB-fWUcyHeg3tcc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at629u", "is_robot_indexable": true, "report_reasons": null, "author": "Ilegator", "discussion_type": null, "num_comments": 199, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at629u/who_needs_pooled_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jvg8v3lqb6jc1.jpeg", "subreddit_subscribers": 732775, "created_utc": 1708187952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Also looking for a better and more organized solution so open to suggestion - There are maybe 20TB+ of files here and another 10TB+ elsewhere (mostly family files and photos and such, with some backups)", "author_fullname": "t2_36r73af9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data + drive hoarding on a tight budget", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1asypiu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 139, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 139, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-rHH7PeSSfGrz_X7ah-iuEBznhmSww4byFFivq_PNRU.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708164720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Also looking for a better and more organized solution so open to suggestion - There are maybe 20TB+ of files here and another 10TB+ elsewhere (mostly family files and photos and such, with some backups)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/req1dxlpe4jc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/req1dxlpe4jc1.jpeg?auto=webp&amp;s=5c97e8c2a7f3b9f4d1ecc229dcb6b70580febe99", "width": 4032, "height": 3025}, "resolutions": [{"url": "https://preview.redd.it/req1dxlpe4jc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ebac6220c32a7f573e82a632c5a57efcb5c66add", "width": 108, "height": 81}, {"url": "https://preview.redd.it/req1dxlpe4jc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2eeab7f1403a5159f7c38e33db633e567062953", "width": 216, "height": 162}, {"url": "https://preview.redd.it/req1dxlpe4jc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99fe2e5dd17dd76a09155434d95fcc1267dd322d", "width": 320, "height": 240}, {"url": "https://preview.redd.it/req1dxlpe4jc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=74348c95bd85dc837b682ada6b2c02659c77c932", "width": 640, "height": 480}, {"url": "https://preview.redd.it/req1dxlpe4jc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=78d5840db072a46300f2b0d41729b0d44a4e1b73", "width": 960, "height": 720}, {"url": "https://preview.redd.it/req1dxlpe4jc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=04f829b979e113662afcb1e9e533ddfb9b4cb8a8", "width": 1080, "height": 810}], "variants": {}, "id": "hzLMTX0_rxIrgh0dlaBhQD9BdX7xizHXxxBlSwqvpRg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "30+TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1asypiu", "is_robot_indexable": true, "report_reasons": null, "author": "TsuyoshiHaruka", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1asypiu/data_drive_hoarding_on_a_tight_budget/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/req1dxlpe4jc1.jpeg", "subreddit_subscribers": 732775, "created_utc": 1708164720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_fo3rgj5ua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great video on the difference between a NAS and a Home Server and the Hardware gatekeeping in the Homelab Community", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1at6k63", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 38, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/_M3UDU2GTrc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"NAS vs. Home Server \u2013 What&amp;#39;s the difference?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "NAS vs. Home Server \u2013 What's the difference?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/_M3UDU2GTrc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"NAS vs. Home Server \u2013 What&amp;#39;s the difference?\"&gt;&lt;/iframe&gt;", "author_name": "Wolfgang's Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/_M3UDU2GTrc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WolfgangsChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/_M3UDU2GTrc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"NAS vs. Home Server \u2013 What&amp;#39;s the difference?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1at6k63", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0JPdyJvytb2a_6QKIxqHEPm4wc-s1S9hnnTSdjuLH6c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708189219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=_M3UDU2GTrc", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uTcsR9J4E0B2Cuyq-R90ysMInP7RlRRkrl33lT8s_Kg.jpg?auto=webp&amp;s=60bef7de14da1c2972cee621a371b5167df307d2", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/uTcsR9J4E0B2Cuyq-R90ysMInP7RlRRkrl33lT8s_Kg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=438acc827a88f9393d10d1032d9d23a0ae5e69c8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/uTcsR9J4E0B2Cuyq-R90ysMInP7RlRRkrl33lT8s_Kg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a18daeb253e2df4e7751c05e6c3c932058ffcea9", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/uTcsR9J4E0B2Cuyq-R90ysMInP7RlRRkrl33lT8s_Kg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b26651d7f13ce2f0963213331ae15c9260f4ac3", "width": 320, "height": 240}], "variants": {}, "id": "DpwMHN7kpNOFc8QrlnPhMmqgoSzAJXJxFy6T00db1LU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1at6k63", "is_robot_indexable": true, "report_reasons": null, "author": "leavemealonexoxo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at6k63/great_video_on_the_difference_between_a_nas_and_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=_M3UDU2GTrc", "subreddit_subscribers": 732775, "created_utc": 1708189219.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "NAS vs. Home Server \u2013 What's the difference?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/_M3UDU2GTrc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"NAS vs. Home Server \u2013 What&amp;#39;s the difference?\"&gt;&lt;/iframe&gt;", "author_name": "Wolfgang's Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/_M3UDU2GTrc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WolfgangsChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_14uv2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a little bit of digital archeology ;)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1at1vfu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HMPOsVeRnxIREJMUymVzCZEaZb_1OWEWPWv_KaKCHSo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708176173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/eez9nq7nc5jc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/eez9nq7nc5jc1.jpeg?auto=webp&amp;s=f405e8fe19e9d8818f96f2c886e8fb4ca3008475", "width": 4096, "height": 2304}, "resolutions": [{"url": "https://preview.redd.it/eez9nq7nc5jc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=80f4acf900b8b4ec43fe587dd4a1a52e1f2dfac8", "width": 108, "height": 60}, {"url": "https://preview.redd.it/eez9nq7nc5jc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=57525a5cf585581963103996d06f3f6a2a7cca96", "width": 216, "height": 121}, {"url": "https://preview.redd.it/eez9nq7nc5jc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2408ca6cf966422e912bafbcfe0949a4398927a1", "width": 320, "height": 180}, {"url": "https://preview.redd.it/eez9nq7nc5jc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d36eaed018f24f5417fa47767efdf655db605902", "width": 640, "height": 360}, {"url": "https://preview.redd.it/eez9nq7nc5jc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=18b88bbdc7795a1fdb5ea6e4f909c84befbfdcff", "width": 960, "height": 540}, {"url": "https://preview.redd.it/eez9nq7nc5jc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f29ab71d0df60c03b23b4766877ac85f4ebc640a", "width": 1080, "height": 607}], "variants": {}, "id": "mZRBO_Pvx4BaLRv2HaAJxo-lsZ2Fo6AjLwfgNsrOYe8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at1vfu", "is_robot_indexable": true, "report_reasons": null, "author": "paprok", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at1vfu/a_little_bit_of_digital_archeology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/eez9nq7nc5jc1.jpeg", "subreddit_subscribers": 732775, "created_utc": 1708176173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "To all the data hoarders out there, your dedication makes the world of learning truly enjoyable. Approaching the world as an endless resource, as highlighted in the book \"Super-Infinite,\" has inspired numerous authors and content creators. A sincere thank you for your valuable contributions to this ongoing process.", "author_fullname": "t2_605fkc9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keep going data hoarders, you are what makes learning enjoyable ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1ataa1w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CPoR7ZK_aQitZAkPSaYVA7KsRficMNPpAuLIMpwH_60.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708198712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To all the data hoarders out there, your dedication makes the world of learning truly enjoyable. Approaching the world as an endless resource, as highlighted in the book &amp;quot;Super-Infinite,&amp;quot; has inspired numerous authors and content creators. A sincere thank you for your valuable contributions to this ongoing process.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1s04xt7s77jc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1s04xt7s77jc1.jpeg?auto=webp&amp;s=de5077e13fb40a0dae6059b223426df1ecae77ba", "width": 3072, "height": 4096}, "resolutions": [{"url": "https://preview.redd.it/1s04xt7s77jc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d293b12c067f5bf9123ac8e3010e1ec9f7683ae", "width": 108, "height": 144}, {"url": "https://preview.redd.it/1s04xt7s77jc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=847ad63361c2038b56b4b17c38364ecc25d261b1", "width": 216, "height": 288}, {"url": "https://preview.redd.it/1s04xt7s77jc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b536fa38c963947089cc4086fb493ec3bba44df", "width": 320, "height": 426}, {"url": "https://preview.redd.it/1s04xt7s77jc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1686769fb10150541400787204d80fac4e7fce74", "width": 640, "height": 853}, {"url": "https://preview.redd.it/1s04xt7s77jc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8f3298e2e2c4609bd4fac0983225b0ff1bfef337", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/1s04xt7s77jc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3580bfd55af9e4865b6c6cb4f6ae03c91e540e59", "width": 1080, "height": 1440}], "variants": {}, "id": "OkLooLO24fJQiO09Z4AsV4dD_CyWKF5fOfPqnZWs6cs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1ataa1w", "is_robot_indexable": true, "report_reasons": null, "author": "nandy000032467", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ataa1w/keep_going_data_hoarders_you_are_what_makes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1s04xt7s77jc1.jpeg", "subreddit_subscribers": 732775, "created_utc": 1708198712.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Been using the stash app to organize my porn collection. Is there a plugin for Rule 34 specifically that can scrape all the tags for an image?", "author_fullname": "t2_48x4qyzd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rule 34 plugin for stash app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1at5z3n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708187711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been using the stash app to organize my porn collection. Is there a plugin for Rule 34 specifically that can scrape all the tags for an image?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at5z3n", "is_robot_indexable": true, "report_reasons": null, "author": "HoraryZappy222", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at5z3n/rule_34_plugin_for_stash_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1at5z3n/rule_34_plugin_for_stash_app/", "subreddit_subscribers": 732775, "created_utc": 1708187711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to understand how rellocating bad sectors works. If it finds a bad sector, does it take free sectors from some backup sectors, or from the ones where my files could be written?\n\nSo if i fill up 930,99GB of files into a 931GB hdd, am i disabling the rellocating function? \n\nI have a few years old 1 TB hdd, it doesn't have any bad sectors and is in good condition. I just happen to have gaming footage on other disc in few archive parts which would match perfectly that HDD capacity, leaving only few MBs. It's not super important data for me, I want to store that HDD in a box for few years until the SSDs get cheaper and larger, or something.", "author_fullname": "t2_brnwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If I fill up an external HDD to almost 100% can it still rellocate bad sectors in the future?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ata8hj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708198600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to understand how rellocating bad sectors works. If it finds a bad sector, does it take free sectors from some backup sectors, or from the ones where my files could be written?&lt;/p&gt;\n\n&lt;p&gt;So if i fill up 930,99GB of files into a 931GB hdd, am i disabling the rellocating function? &lt;/p&gt;\n\n&lt;p&gt;I have a few years old 1 TB hdd, it doesn&amp;#39;t have any bad sectors and is in good condition. I just happen to have gaming footage on other disc in few archive parts which would match perfectly that HDD capacity, leaving only few MBs. It&amp;#39;s not super important data for me, I want to store that HDD in a box for few years until the SSDs get cheaper and larger, or something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ata8hj", "is_robot_indexable": true, "report_reasons": null, "author": "Poonker", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ata8hj/if_i_fill_up_an_external_hdd_to_almost_100_can_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ata8hj/if_i_fill_up_an_external_hdd_to_almost_100_can_it/", "subreddit_subscribers": 732775, "created_utc": 1708198600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I created a post in Veeam sub-reddit when I was asking why Veeam has such a big incremental images\n\n [Reddit - Dive into anything](https://www.reddit.com/r/Veeam/comments/1an026i/big_size_of_incremental_backup_with_windows_agent/)  \n\nEven if nothing happened with Windows11, veeam backup image will be 15GB each day. I was told that it is fine, even 20GB is fine incremental size for system drive.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/jy1q8bf6l8jc1.png?width=370&amp;format=png&amp;auto=webp&amp;s=197223bcfdd1217d1ebef5996a5d85c44a65cb77\n\nSo, I decided to try my favorite Macrium Reflect, trial version with Full-Differenial-Incremental strategy and was shocked that incremental image size is only 130 MB, differential is 3-4GB.\n\nWith Veeam even if you do a few backups one by one - each will have a size 5GB.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/omsmtn12l8jc1.png?width=329&amp;format=png&amp;auto=webp&amp;s=31dc7783805491b122eea1dd965804e552bb2265\n\nFull - Monthly, Differential - Weekly and Incremental - Daily.\n\nDecided to leave Macrium now, probably will buy license.   \n\n&amp;#x200B;", "author_fullname": "t2_xrw08sk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Veeam windows agent incremental image size is huge.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jy1q8bf6l8jc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 48, "x": 108, "u": "https://preview.redd.it/jy1q8bf6l8jc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c8d2ab09fded8b20a0964a1fb52e91e60cba683"}, {"y": 96, "x": 216, "u": "https://preview.redd.it/jy1q8bf6l8jc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e3164d7ed80a1f7e452a780092117d5d6115939"}, {"y": 142, "x": 320, "u": "https://preview.redd.it/jy1q8bf6l8jc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b96ebd039f3715f738d279a34a11edb7f716853a"}], "s": {"y": 165, "x": 370, "u": "https://preview.redd.it/jy1q8bf6l8jc1.png?width=370&amp;format=png&amp;auto=webp&amp;s=197223bcfdd1217d1ebef5996a5d85c44a65cb77"}, "id": "jy1q8bf6l8jc1"}, "omsmtn12l8jc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/omsmtn12l8jc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=13c8fd5c7dba057a7431662ba578c0c61c4520cf"}, {"y": 70, "x": 216, "u": "https://preview.redd.it/omsmtn12l8jc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=87e676ec76baf2b31a35955ae938668e9c61c008"}, {"y": 104, "x": 320, "u": "https://preview.redd.it/omsmtn12l8jc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=307e278a1d61866c4789b42ce3701c1c870b268b"}], "s": {"y": 107, "x": 329, "u": "https://preview.redd.it/omsmtn12l8jc1.png?width=329&amp;format=png&amp;auto=webp&amp;s=31dc7783805491b122eea1dd965804e552bb2265"}, "id": "omsmtn12l8jc1"}}, "name": "t3_1atgozn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rbAO__TQlA9H_tAvxrqHRg7AYysy0Y4mUih3MOilsDc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708215515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created a post in Veeam sub-reddit when I was asking why Veeam has such a big incremental images&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/Veeam/comments/1an026i/big_size_of_incremental_backup_with_windows_agent/\"&gt;Reddit - Dive into anything&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Even if nothing happened with Windows11, veeam backup image will be 15GB each day. I was told that it is fine, even 20GB is fine incremental size for system drive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jy1q8bf6l8jc1.png?width=370&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=197223bcfdd1217d1ebef5996a5d85c44a65cb77\"&gt;https://preview.redd.it/jy1q8bf6l8jc1.png?width=370&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=197223bcfdd1217d1ebef5996a5d85c44a65cb77&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So, I decided to try my favorite Macrium Reflect, trial version with Full-Differenial-Incremental strategy and was shocked that incremental image size is only 130 MB, differential is 3-4GB.&lt;/p&gt;\n\n&lt;p&gt;With Veeam even if you do a few backups one by one - each will have a size 5GB.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/omsmtn12l8jc1.png?width=329&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31dc7783805491b122eea1dd965804e552bb2265\"&gt;https://preview.redd.it/omsmtn12l8jc1.png?width=329&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31dc7783805491b122eea1dd965804e552bb2265&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Full - Monthly, Differential - Weekly and Incremental - Daily.&lt;/p&gt;\n\n&lt;p&gt;Decided to leave Macrium now, probably will buy license.   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atgozn", "is_robot_indexable": true, "report_reasons": null, "author": "d13m3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atgozn/veeam_windows_agent_incremental_image_size_is_huge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atgozn/veeam_windows_agent_incremental_image_size_is_huge/", "subreddit_subscribers": 732775, "created_utc": 1708215515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a server with a very big btrfs raid array that I need to backup to external disk(s). There are no disks large enough to fit all data so I need to use multiple disks. In my case, 2 disks are enough (for now). Previously, I have 1 external disk and used rsync to just clone everything to that disk. Now I need to do something similar but have the files be split between the 2 disks, that also has different size.\n\nDisk 2 is 4 times smaller than disk 1.   \n\n\nHow can this be acomplished? Are there any good software that can handle my use case? Preferebly open source.  \n\n\nMy current method would be to write a script that takes all files and writes the files to the 2 disks in an alternating fashion until the smaller disk is full, then it only writes to the large disk. This would ensure that if one disk breaks, I should still have as much of the data as possible. But I would prefer if there were some ready made software for this? Any suggestions?", "author_fullname": "t2_nanndmsx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to backup Linux to external disks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1at4e9p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708183456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a server with a very big btrfs raid array that I need to backup to external disk(s). There are no disks large enough to fit all data so I need to use multiple disks. In my case, 2 disks are enough (for now). Previously, I have 1 external disk and used rsync to just clone everything to that disk. Now I need to do something similar but have the files be split between the 2 disks, that also has different size.&lt;/p&gt;\n\n&lt;p&gt;Disk 2 is 4 times smaller than disk 1.   &lt;/p&gt;\n\n&lt;p&gt;How can this be acomplished? Are there any good software that can handle my use case? Preferebly open source.  &lt;/p&gt;\n\n&lt;p&gt;My current method would be to write a script that takes all files and writes the files to the 2 disks in an alternating fashion until the smaller disk is full, then it only writes to the large disk. This would ensure that if one disk breaks, I should still have as much of the data as possible. But I would prefer if there were some ready made software for this? Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at4e9p", "is_robot_indexable": true, "report_reasons": null, "author": "EByteNBits", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at4e9p/how_to_backup_linux_to_external_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1at4e9p/how_to_backup_linux_to_external_disks/", "subreddit_subscribers": 732775, "created_utc": 1708183456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have thousands of photos and many important files saved. Currently most of them are on my iPhone and in iCloud. I also have a 1TB external SSD as well. What way can I have the photos automatically update, if I have to manually update them, how often should I do this? I am currently trying to create some standard operating procedures around my file system since they are very disorganized. First, I take a photo. It is saved to iCloud. It is then synced to my PC through iCloud. However, I am unsure if my PC is actually storing the photo, and it is just accessing the iCloud photo. I then have to MANUALLY move new photos/file folders into new file folders in my external SSD every few months, which I make time to do in my calendar, and can be difficult as iCloud doesn't show me which photos are new. \n\nHow do I best manage the photos and keep them updated in case of theft, SSD failure (from my PC or my iPhone, or my External SSD)? My files are only kept on the external SSD, and not in the cloud. What would you recommend I do for my standard operating procedures?", "author_fullname": "t2_5qw2layww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a more efficient way to store my data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ata009", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708197998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have thousands of photos and many important files saved. Currently most of them are on my iPhone and in iCloud. I also have a 1TB external SSD as well. What way can I have the photos automatically update, if I have to manually update them, how often should I do this? I am currently trying to create some standard operating procedures around my file system since they are very disorganized. First, I take a photo. It is saved to iCloud. It is then synced to my PC through iCloud. However, I am unsure if my PC is actually storing the photo, and it is just accessing the iCloud photo. I then have to MANUALLY move new photos/file folders into new file folders in my external SSD every few months, which I make time to do in my calendar, and can be difficult as iCloud doesn&amp;#39;t show me which photos are new. &lt;/p&gt;\n\n&lt;p&gt;How do I best manage the photos and keep them updated in case of theft, SSD failure (from my PC or my iPhone, or my External SSD)? My files are only kept on the external SSD, and not in the cloud. What would you recommend I do for my standard operating procedures?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1ata009", "is_robot_indexable": true, "report_reasons": null, "author": "misterflocka", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1ata009/is_there_a_more_efficient_way_to_store_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1ata009/is_there_a_more_efficient_way_to_store_my_data/", "subreddit_subscribers": 732775, "created_utc": 1708197998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hello! my beloved great grandmother's service was livestreamed on this [website](https://view.oneroomstreaming.com/index.php?data=MTcwMDM0OTIxMzI4MTczMyZvbmVyb29tLWFkbWluJmNvcHlfbGluaw==), and while they offer the option of downloading it, they want you to pay $40(or something like that) for it!\n\nheck no, screw that!!\n\ncould you guys please assist me in this endeavor? I've dabbled with developer tools and the like, but goddamn I am really out of touch, I haven't had any success.\n\nthank you guys! \ud83d\udc97", "author_fullname": "t2_rdye144", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I download my loved one's funeral service from this website?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1atm2xr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1708232429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "view.oneroomstreaming.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello! my beloved great grandmother&amp;#39;s service was livestreamed on this &lt;a href=\"https://view.oneroomstreaming.com/index.php?data=MTcwMDM0OTIxMzI4MTczMyZvbmVyb29tLWFkbWluJmNvcHlfbGluaw==\"&gt;website&lt;/a&gt;, and while they offer the option of downloading it, they want you to pay $40(or something like that) for it!&lt;/p&gt;\n\n&lt;p&gt;heck no, screw that!!&lt;/p&gt;\n\n&lt;p&gt;could you guys please assist me in this endeavor? I&amp;#39;ve dabbled with developer tools and the like, but goddamn I am really out of touch, I haven&amp;#39;t had any success.&lt;/p&gt;\n\n&lt;p&gt;thank you guys! \ud83d\udc97&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://view.oneroomstreaming.com/index.php?data=MTcwMDM0OTIxMzI4MTczMyZvbmVyb29tLWFkbWluJmNvcHlfbGluaw==", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atm2xr", "is_robot_indexable": true, "report_reasons": null, "author": "lovenet99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atm2xr/how_can_i_download_my_loved_ones_funeral_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://view.oneroomstreaming.com/index.php?data=MTcwMDM0OTIxMzI4MTczMyZvbmVyb29tLWFkbWluJmNvcHlfbGluaw==", "subreddit_subscribers": 732775, "created_utc": 1708232429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any one run theses in bulk or have experience with them? I bought some \"refurbished\" at about $10/TB. 80% are barley old with only 200hours on them with less than 100 load cycles. The other 20% I am worried about. I ran a SMART long test before I put any drive in service and all passed. But the 20% are 5k hours+(Not really an issue seeing the specs are 1.5mil or something, memory fails to recall) \\~300 load cycles, and 1500+ TB/yr R /W(Calculated from the SMART report using logical sectors R /W divided by total hours)  This figure is slightly worrying has spec is 500? TB/yr. And the truly worrying figure is the g sense error at 100+ with one at \\~700 :O\n\nSo with that information should I be worried about theses couple of drives with high R /W opps and g sense error. I see nothing in the SMART report about a Read/Write error. So could the g sensor be faulty? As I would expect a Read/Write error in the SMART log accompanying a g sense error, especially when I have \\~700 on one drive. I have written about 70TB to the drives and no complaints from ZFS or SMART. I perform daily short test and biweekly long with a ZFS scrub on the alternating week. All drives are in a raidz2(I am not brave enough to run raidz1)\n\nHere is a pastebin of the SMART report on the worse offending drive [https://pastebin.com/2jBZ8BRy](https://pastebin.com/2jBZ8BRy) if anyone wants to take a gander. I hope this is the right place to post this, I am just looking for feedback or maybe some other tool I can use to see if these drives will fail sooner than the others. As some of theses drive were abused and defiantly was not looked after.\n\nOne final question it sounds like a bag rocks on write operations(No metal on metal or bearing failure sounds). I know enterprise drives run loud but I had some 6TB WD Reds that run quiet as a mouse. Is this normal for a Toshiba?", "author_fullname": "t2_eifwg1c96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toshiba Enterprise HDD Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1atifbm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708220747.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708220560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any one run theses in bulk or have experience with them? I bought some &amp;quot;refurbished&amp;quot; at about $10/TB. 80% are barley old with only 200hours on them with less than 100 load cycles. The other 20% I am worried about. I ran a SMART long test before I put any drive in service and all passed. But the 20% are 5k hours+(Not really an issue seeing the specs are 1.5mil or something, memory fails to recall) ~300 load cycles, and 1500+ TB/yr R /W(Calculated from the SMART report using logical sectors R /W divided by total hours)  This figure is slightly worrying has spec is 500? TB/yr. And the truly worrying figure is the g sense error at 100+ with one at ~700 :O&lt;/p&gt;\n\n&lt;p&gt;So with that information should I be worried about theses couple of drives with high R /W opps and g sense error. I see nothing in the SMART report about a Read/Write error. So could the g sensor be faulty? As I would expect a Read/Write error in the SMART log accompanying a g sense error, especially when I have ~700 on one drive. I have written about 70TB to the drives and no complaints from ZFS or SMART. I perform daily short test and biweekly long with a ZFS scrub on the alternating week. All drives are in a raidz2(I am not brave enough to run raidz1)&lt;/p&gt;\n\n&lt;p&gt;Here is a pastebin of the SMART report on the worse offending drive &lt;a href=\"https://pastebin.com/2jBZ8BRy\"&gt;https://pastebin.com/2jBZ8BRy&lt;/a&gt; if anyone wants to take a gander. I hope this is the right place to post this, I am just looking for feedback or maybe some other tool I can use to see if these drives will fail sooner than the others. As some of theses drive were abused and defiantly was not looked after.&lt;/p&gt;\n\n&lt;p&gt;One final question it sounds like a bag rocks on write operations(No metal on metal or bearing failure sounds). I know enterprise drives run loud but I had some 6TB WD Reds that run quiet as a mouse. Is this normal for a Toshiba?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/P8lS0kk6BFe2IEo6TxCZd1LVwksc34IkzGTVx_SCc8w.jpg?auto=webp&amp;s=b9f5c4e4867fbffb2c1ff45dd70aa338d1e3f40c", "width": 150, "height": 150}, "resolutions": [{"url": "https://external-preview.redd.it/P8lS0kk6BFe2IEo6TxCZd1LVwksc34IkzGTVx_SCc8w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3d74dbe4f1d67cc8b587db9aa01762f26e269bcf", "width": 108, "height": 108}], "variants": {}, "id": "OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atifbm", "is_robot_indexable": true, "report_reasons": null, "author": "poptrek", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atifbm/toshiba_enterprise_hdd_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atifbm/toshiba_enterprise_hdd_questions/", "subreddit_subscribers": 732775, "created_utc": 1708220560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm still in the planning stage of my next server with enterprise SSDs and I've been running into some NAND descriptions that I've never seen before (in title).  \n\n[https://www.techpowerup.com/ssd-specs/solidigm-d7-p5510-7-5-tb.d1331](https://www.techpowerup.com/ssd-specs/solidigm-d7-p5510-7-5-tb.d1331)\n\n[https://www.techpowerup.com/ssd-specs/solidigm-d7-p5810-800-gb.d1674](https://www.techpowerup.com/ssd-specs/solidigm-d7-p5810-800-gb.d1674)\n\nAside from just the names, I'm unclear on how Techpowerup lists the NAND on those Solidigm drives as Fortishflash (Micron) and the part numbers are also Micron, not Solidigm.  Unless there is some kind of agreement between Micron and Solidigm and they are remarked chips, it seems to be a mistake.\n\nDrives like this one marked as pQLC (PLC) confuse me as I thought there were serious error correction issues with PLC NAND that were not overcome as of yet.\n\n[https://www.techpowerup.com/ssd-specs/solidigm-p5430-31-tb.d1485](https://www.techpowerup.com/ssd-specs/solidigm-p5430-31-tb.d1485)\n\nExample pSLC:  It almost seems as if some portion of the NAND die is SLC for speed, with the majority actually configured as MLC or TLC.  That's the only thing that could make sense to me, but I can't find any reference to this.\n\nI have a DRAM-less 4TB Silicon Power ace 55 that's using some type of configuration similar to that.\n\nAnyone actually know for sure?", "author_fullname": "t2_ldhe3aze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What, exactly, is pSLC, pTLC and pQLC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1atgoso", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708215500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m still in the planning stage of my next server with enterprise SSDs and I&amp;#39;ve been running into some NAND descriptions that I&amp;#39;ve never seen before (in title).  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.techpowerup.com/ssd-specs/solidigm-d7-p5510-7-5-tb.d1331\"&gt;https://www.techpowerup.com/ssd-specs/solidigm-d7-p5510-7-5-tb.d1331&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.techpowerup.com/ssd-specs/solidigm-d7-p5810-800-gb.d1674\"&gt;https://www.techpowerup.com/ssd-specs/solidigm-d7-p5810-800-gb.d1674&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Aside from just the names, I&amp;#39;m unclear on how Techpowerup lists the NAND on those Solidigm drives as Fortishflash (Micron) and the part numbers are also Micron, not Solidigm.  Unless there is some kind of agreement between Micron and Solidigm and they are remarked chips, it seems to be a mistake.&lt;/p&gt;\n\n&lt;p&gt;Drives like this one marked as pQLC (PLC) confuse me as I thought there were serious error correction issues with PLC NAND that were not overcome as of yet.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.techpowerup.com/ssd-specs/solidigm-p5430-31-tb.d1485\"&gt;https://www.techpowerup.com/ssd-specs/solidigm-p5430-31-tb.d1485&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Example pSLC:  It almost seems as if some portion of the NAND die is SLC for speed, with the majority actually configured as MLC or TLC.  That&amp;#39;s the only thing that could make sense to me, but I can&amp;#39;t find any reference to this.&lt;/p&gt;\n\n&lt;p&gt;I have a DRAM-less 4TB Silicon Power ace 55 that&amp;#39;s using some type of configuration similar to that.&lt;/p&gt;\n\n&lt;p&gt;Anyone actually know for sure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7Zl__chOO8dKoulkw324G0ctb9aw8lqpM3-0UtiFMsc.jpg?auto=webp&amp;s=9556533ee8ee2600a86d626034c775229e7c0dc6", "width": 1137, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/7Zl__chOO8dKoulkw324G0ctb9aw8lqpM3-0UtiFMsc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1b80ca1342fb384831e6f1b8ed42057f19035c55", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/7Zl__chOO8dKoulkw324G0ctb9aw8lqpM3-0UtiFMsc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9f9d871d7578e017aab853ef92efb5dc3c5b74b", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/7Zl__chOO8dKoulkw324G0ctb9aw8lqpM3-0UtiFMsc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d776d5dfaa12517feefbc5e84a9b21d5645c3e96", "width": 320, "height": 225}, {"url": "https://external-preview.redd.it/7Zl__chOO8dKoulkw324G0ctb9aw8lqpM3-0UtiFMsc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab74911cf80d0f5fcebcab33d9face7d441f3dc2", "width": 640, "height": 450}, {"url": "https://external-preview.redd.it/7Zl__chOO8dKoulkw324G0ctb9aw8lqpM3-0UtiFMsc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=300c97c922d77e0cbd416d48b54963c375c080d5", "width": 960, "height": 675}, {"url": "https://external-preview.redd.it/7Zl__chOO8dKoulkw324G0ctb9aw8lqpM3-0UtiFMsc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=063d1c1dc7934be9046f22fe94ab3cb92830375d", "width": 1080, "height": 759}], "variants": {}, "id": "iGE1QK6BOoved2-titpS5eF1zVAjprFFxBQbcx22Zwc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atgoso", "is_robot_indexable": true, "report_reasons": null, "author": "Kennyw88", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atgoso/what_exactly_is_pslc_ptlc_and_pqlc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atgoso/what_exactly_is_pslc_ptlc_and_pqlc/", "subreddit_subscribers": 732775, "created_utc": 1708215500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/u7m6vd8e98jc1.png?width=677&amp;format=png&amp;auto=webp&amp;s=e770e90a3c7658881ff30be8be874a2365fafa35\n\nAs you can see, a bit new-ish drive. When filling it up with data, following errors occured. \n\nI have not tested this drive previously with badblocks, which in hindsight maybe i should have...  \nWD Red Pro 8 TB\n\nWhat do I do now?", "author_fullname": "t2_38zesk7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this toast?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"u7m6vd8e98jc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 124, "x": 108, "u": "https://preview.redd.it/u7m6vd8e98jc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9997c08e0d5e0ebf500a0c2c2dad3a3a929dffa"}, {"y": 248, "x": 216, "u": "https://preview.redd.it/u7m6vd8e98jc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4d528bf5f308eb50ed78d06c2aa5f062c75779b"}, {"y": 367, "x": 320, "u": "https://preview.redd.it/u7m6vd8e98jc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3d071e09a808b9407c1617243ddd2f8e7f73d3f"}, {"y": 735, "x": 640, "u": "https://preview.redd.it/u7m6vd8e98jc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9e5512bcc64ee62065d61f574a61966a385de37a"}], "s": {"y": 778, "x": 677, "u": "https://preview.redd.it/u7m6vd8e98jc1.png?width=677&amp;format=png&amp;auto=webp&amp;s=e770e90a3c7658881ff30be8be874a2365fafa35"}, "id": "u7m6vd8e98jc1"}}, "name": "t3_1atf7rr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nL-Kbj9e8i_nbD1jYQocGefDGt73b80Hb4Ab4bUW7EM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708211478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/u7m6vd8e98jc1.png?width=677&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e770e90a3c7658881ff30be8be874a2365fafa35\"&gt;https://preview.redd.it/u7m6vd8e98jc1.png?width=677&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e770e90a3c7658881ff30be8be874a2365fafa35&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As you can see, a bit new-ish drive. When filling it up with data, following errors occured. &lt;/p&gt;\n\n&lt;p&gt;I have not tested this drive previously with badblocks, which in hindsight maybe i should have...&lt;br/&gt;\nWD Red Pro 8 TB&lt;/p&gt;\n\n&lt;p&gt;What do I do now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atf7rr", "is_robot_indexable": true, "report_reasons": null, "author": "lightbringer0209", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atf7rr/is_this_toast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atf7rr/is_this_toast/", "subreddit_subscribers": 732775, "created_utc": 1708211478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nIm really glad i stumbled on this sub after countless hours of researching online. So basically, i am a photographer who is expanding in video editing and cinematography.  I am getting ready to scale my business and i am getting ready to be working with lots and lots of data. RAW files, JPEGS and countless MP4 files as well as some video files H.265/XAVC HS etc.\n\nMy current setup is\n\n* 1 Internal SSD of 256GB (33GB free) (Windows on here as well as my programs)\n* Internal HDD 1TB(703GB free) (Miscellaneous files) \n* 1 External Lacie Drive 2TB (1.18TB free) (Lightroom catalog and all photos and videos) \n\nI would like to add to my setup and optimize it for scalability and performance as well as long term storage. In addition i have been looking at Cloud storage as a backup if anyone has some recommendations there. Does anyone have any advice for possible hardware to upgrade as well as any tips for handling and storing lots and lots of photos.\n\n\n\n\\*\\*\\*Currently i use Lightroom and Photoshop for editing as well as Davinci Resolve, Premiere Pro and After effects for video. I want to be able to import my files as quickly and efficiently as possible. Looking at upgrading my GPU as well to handle the software demands as well\\*\\*\\*\n\n\n\nAll feedback is really greatly appreciated :) Thank you!\n\n\n\n", "author_fullname": "t2_hv61cul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have some cash, looking to optimize my system and data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1atcr09", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708205684.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708205072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Im really glad i stumbled on this sub after countless hours of researching online. So basically, i am a photographer who is expanding in video editing and cinematography.  I am getting ready to scale my business and i am getting ready to be working with lots and lots of data. RAW files, JPEGS and countless MP4 files as well as some video files H.265/XAVC HS etc.&lt;/p&gt;\n\n&lt;p&gt;My current setup is&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;1 Internal SSD of 256GB (33GB free) (Windows on here as well as my programs)&lt;/li&gt;\n&lt;li&gt;Internal HDD 1TB(703GB free) (Miscellaneous files) &lt;/li&gt;\n&lt;li&gt;1 External Lacie Drive 2TB (1.18TB free) (Lightroom catalog and all photos and videos) &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would like to add to my setup and optimize it for scalability and performance as well as long term storage. In addition i have been looking at Cloud storage as a backup if anyone has some recommendations there. Does anyone have any advice for possible hardware to upgrade as well as any tips for handling and storing lots and lots of photos.&lt;/p&gt;\n\n&lt;p&gt;***Currently i use Lightroom and Photoshop for editing as well as Davinci Resolve, Premiere Pro and After effects for video. I want to be able to import my files as quickly and efficiently as possible. Looking at upgrading my GPU as well to handle the software demands as well***&lt;/p&gt;\n\n&lt;p&gt;All feedback is really greatly appreciated :) Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atcr09", "is_robot_indexable": true, "report_reasons": null, "author": "FFunSize", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atcr09/have_some_cash_looking_to_optimize_my_system_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atcr09/have_some_cash_looking_to_optimize_my_system_and/", "subreddit_subscribers": 732775, "created_utc": 1708205072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Here are two samples that I have used to test various dupe finders.  These are the same photo but one was a scan of a negative and the other one was a scan of a print.  So there are some differences in lighting and positioning.  Ideally, it would highlight both of these as potential dupes and I could then manually confirm.\n\n[https://imgur.com/IRvoRmN](https://imgur.com/IRvoRmN)\n\n[https://imgur.com/eNDNLxr](https://imgur.com/eNDNLxr)\n\nI have tried a few dupe finders (such as DupeGuru and Czkawka) and neither of them identified my test photos as potential dupes.\n\nMy primary purpose is to identify dupes between negative scans vs. print scans, so there will be differences in coloration and lighting (due to the quality of the originals).\n\nThanks all.", "author_fullname": "t2_bkpa4dwyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for software that will identify exact or similar images.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1atcf53", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708204194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here are two samples that I have used to test various dupe finders.  These are the same photo but one was a scan of a negative and the other one was a scan of a print.  So there are some differences in lighting and positioning.  Ideally, it would highlight both of these as potential dupes and I could then manually confirm.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/IRvoRmN\"&gt;https://imgur.com/IRvoRmN&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/eNDNLxr\"&gt;https://imgur.com/eNDNLxr&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have tried a few dupe finders (such as DupeGuru and Czkawka) and neither of them identified my test photos as potential dupes.&lt;/p&gt;\n\n&lt;p&gt;My primary purpose is to identify dupes between negative scans vs. print scans, so there will be differences in coloration and lighting (due to the quality of the originals).&lt;/p&gt;\n\n&lt;p&gt;Thanks all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ugc3TbOq5bUlOKyK65M0chRNCWOAju8QhuAW5kOtyeQ.jpg?auto=webp&amp;s=f67c9ba552ea1c60c50dfa532a153176ab52ea1c", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/ugc3TbOq5bUlOKyK65M0chRNCWOAju8QhuAW5kOtyeQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ebcc7edd617ebd6ddc8d7a9bcf6d18a1a0e1164f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ugc3TbOq5bUlOKyK65M0chRNCWOAju8QhuAW5kOtyeQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=000ce95daac7cc144ad6b421e9f6009bc69fcbaf", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ugc3TbOq5bUlOKyK65M0chRNCWOAju8QhuAW5kOtyeQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c3f0797ecf1e7836b716c4929fd0631e95543e7f", "width": 320, "height": 168}], "variants": {}, "id": "yYJP3dBT6HKv3bb84ZtQ1p4plcsIeXFc8fX1hZrozIY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atcf53", "is_robot_indexable": true, "report_reasons": null, "author": "bluegambit875", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atcf53/looking_for_software_that_will_identify_exact_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atcf53/looking_for_software_that_will_identify_exact_or/", "subreddit_subscribers": 732775, "created_utc": 1708204194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have thousands of ecomics and more coming weekly.\n\nSo i have them all on a 2TB WD portable HD that i keep in a bank safe.\nI take it out to add new comics about once every 2 months.\n\nThen i got another 2TB WD portable HD in my living room with the same data on it.\n\nThen since i started years ago on DVD+R, i have like 4-5 shoeboxes full of them in an upstairs bedroom.\nI must now get only 20-30 new comics monthly.\nSo i still burn on DVD+R.\n\nSo i D/L on my PC, and when i get quite a few, i back them up on the 3 various storage setup i have.\n\nThen i delete them from my PC.\n\nI figure if one day one of the 3 storage solution is compromised, i can just replace it.\n\nI don\u2019t want to do the upload route anywhere with encryption or stuff like this.\n\nWhat do you think?\n\nThxs a lot", "author_fullname": "t2_64d06bai", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my back up routine good enough for comics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1at6nmq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708189438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have thousands of ecomics and more coming weekly.&lt;/p&gt;\n\n&lt;p&gt;So i have them all on a 2TB WD portable HD that i keep in a bank safe.\nI take it out to add new comics about once every 2 months.&lt;/p&gt;\n\n&lt;p&gt;Then i got another 2TB WD portable HD in my living room with the same data on it.&lt;/p&gt;\n\n&lt;p&gt;Then since i started years ago on DVD+R, i have like 4-5 shoeboxes full of them in an upstairs bedroom.\nI must now get only 20-30 new comics monthly.\nSo i still burn on DVD+R.&lt;/p&gt;\n\n&lt;p&gt;So i D/L on my PC, and when i get quite a few, i back them up on the 3 various storage setup i have.&lt;/p&gt;\n\n&lt;p&gt;Then i delete them from my PC.&lt;/p&gt;\n\n&lt;p&gt;I figure if one day one of the 3 storage solution is compromised, i can just replace it.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t want to do the upload route anywhere with encryption or stuff like this.&lt;/p&gt;\n\n&lt;p&gt;What do you think?&lt;/p&gt;\n\n&lt;p&gt;Thxs a lot&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at6nmq", "is_robot_indexable": true, "report_reasons": null, "author": "vaindioux", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at6nmq/is_my_back_up_routine_good_enough_for_comics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1at6nmq/is_my_back_up_routine_good_enough_for_comics/", "subreddit_subscribers": 732775, "created_utc": 1708189438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have some questions that I am hoping this community can help me with. I am in the market for a new NAS and currently the two most compelling options for me seem to be the TrueNAS Mini X and the Synology DS1522+.\n\nI have used Synology a little bit years ago and it seemed ok, but I have never used TrueNAS. I am looking to buy a prebuilt solution and this is why I am specifically looking at these two models. Though I will install the Drives (Five 16 or 18TBs) myself. I know the Mini X looks like it will be more expensive out of the gate, but if it meets my asks (see below) better, than it would be worth the cost.\n\nMy biggest ask is for data integrity and system reliability. I would like to get the NAS that would do the best job keeping may data intact while also having the system/chassis itself run well for years and be extremely reliable. It will be used largely for file access. Mounting it via SMB on my computers for both data storage and for Plex. I do not expect either to encode, I already have a computer that will do that. Any insight would be greatly appreciated. Thank you in advance.", "author_fullname": "t2_4dx9vii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TrueNAS Mini X vs. Synology DS1522+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1at6ik9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708190428.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708189112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some questions that I am hoping this community can help me with. I am in the market for a new NAS and currently the two most compelling options for me seem to be the TrueNAS Mini X and the Synology DS1522+.&lt;/p&gt;\n\n&lt;p&gt;I have used Synology a little bit years ago and it seemed ok, but I have never used TrueNAS. I am looking to buy a prebuilt solution and this is why I am specifically looking at these two models. Though I will install the Drives (Five 16 or 18TBs) myself. I know the Mini X looks like it will be more expensive out of the gate, but if it meets my asks (see below) better, than it would be worth the cost.&lt;/p&gt;\n\n&lt;p&gt;My biggest ask is for data integrity and system reliability. I would like to get the NAS that would do the best job keeping may data intact while also having the system/chassis itself run well for years and be extremely reliable. It will be used largely for file access. Mounting it via SMB on my computers for both data storage and for Plex. I do not expect either to encode, I already have a computer that will do that. Any insight would be greatly appreciated. Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at6ik9", "is_robot_indexable": true, "report_reasons": null, "author": "PersonSuitTV", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at6ik9/truenas_mini_x_vs_synology_ds1522/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1at6ik9/truenas_mini_x_vs_synology_ds1522/", "subreddit_subscribers": 732775, "created_utc": 1708189112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have enough storage that no backup strategy except tape is feasible.\n\nCurrently, LTO-8 is cheaper per TB and for the initial library (38EUR/12TB, 5300EUR for 24-slot 1-drive library) vs LTO-9 (80EUR/18TB, 6100EUR for library).\n\nIs there any reason to go LTO-9 in this scenario?", "author_fullname": "t2_4nvac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO-8 vs LTO-9", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1at666v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708188229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have enough storage that no backup strategy except tape is feasible.&lt;/p&gt;\n\n&lt;p&gt;Currently, LTO-8 is cheaper per TB and for the initial library (38EUR/12TB, 5300EUR for 24-slot 1-drive library) vs LTO-9 (80EUR/18TB, 6100EUR for library).&lt;/p&gt;\n\n&lt;p&gt;Is there any reason to go LTO-9 in this scenario?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at666v", "is_robot_indexable": true, "report_reasons": null, "author": "KaneTW", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at666v/lto8_vs_lto9/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1at666v/lto8_vs_lto9/", "subreddit_subscribers": 732775, "created_utc": 1708188229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\nI have an old Mac that finally died as a file server to the multitude of mobile devices and laptops I have.  I am looking to replace that.  \n\nI started to look at NAS devices such as the 4bay Synology ds224+.  I like the idea of being able to run a docker container or whatever on that device, but it looks like in order to do that I will have to buy a device that has more than the 2GB of RAM that device has.  I also like the idea of maybe being able to use it for a NVR; not really a requirement though.  \n\nThen, I started to think about buying a Mac mini, and hanging some devices off of it.  However, I have an iMac that is on all the time, so why worry with another computer I don't need.  \n\nI think I am leaning toward some fast storage like a thunderbolt enclosure hanging off the iMac.  I can still use Time Machine for backups with a drive caddy and some cheap drives for onsite and offsite backups.  The only hesitation I have had is many years ago, I had an enclosure power supply go, and take with it 4 drives.  \n\nAny holes in this thinking?  Any reason I might want to rethink the NAS approach?  Does anyone have any ideas for fast storage if the iMac is the way to go?  I was looking at some of the OWC Thunderbolt enclosures.", "author_fullname": "t2_3p4eakf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File server replacement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1at4odr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708184237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI have an old Mac that finally died as a file server to the multitude of mobile devices and laptops I have.  I am looking to replace that.  &lt;/p&gt;\n\n&lt;p&gt;I started to look at NAS devices such as the 4bay Synology ds224+.  I like the idea of being able to run a docker container or whatever on that device, but it looks like in order to do that I will have to buy a device that has more than the 2GB of RAM that device has.  I also like the idea of maybe being able to use it for a NVR; not really a requirement though.  &lt;/p&gt;\n\n&lt;p&gt;Then, I started to think about buying a Mac mini, and hanging some devices off of it.  However, I have an iMac that is on all the time, so why worry with another computer I don&amp;#39;t need.  &lt;/p&gt;\n\n&lt;p&gt;I think I am leaning toward some fast storage like a thunderbolt enclosure hanging off the iMac.  I can still use Time Machine for backups with a drive caddy and some cheap drives for onsite and offsite backups.  The only hesitation I have had is many years ago, I had an enclosure power supply go, and take with it 4 drives.  &lt;/p&gt;\n\n&lt;p&gt;Any holes in this thinking?  Any reason I might want to rethink the NAS approach?  Does anyone have any ideas for fast storage if the iMac is the way to go?  I was looking at some of the OWC Thunderbolt enclosures.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at4odr", "is_robot_indexable": true, "report_reasons": null, "author": "Next_Confusion3262", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at4odr/file_server_replacement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1at4odr/file_server_replacement/", "subreddit_subscribers": 732775, "created_utc": 1708184237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm using Arq to backup from 170 192Tib from one NAS to another onsite (for now). The network is 10G-baseT with pretty darn good throughput. It seems to be good and doing the job well enough. I have a couple questions.\n\n1. Who understands the threads? Because I don't. I put the max thread count from 2 to 4 and it ground to a walking speed. I put it back down to 2 and it seems great again.\n2. Are there alternative solutions I should text before committing to Arq? I'm open to any and all suggestions.\n\nThanks, and cheers!  \n\n\nEDIT: Oddly, the upload number in Arq is going up consistently regardless of adjustments I make to the backup plan, but the size of the target folder seems to have gone down by an entire 10 TiB overnight. Is that de-duping? Or is something screwy? ", "author_fullname": "t2_7k45la1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Arq 7... seems to be good, but alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1at47z0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708183295.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708182967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Arq to backup from 170 192Tib from one NAS to another onsite (for now). The network is 10G-baseT with pretty darn good throughput. It seems to be good and doing the job well enough. I have a couple questions.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Who understands the threads? Because I don&amp;#39;t. I put the max thread count from 2 to 4 and it ground to a walking speed. I put it back down to 2 and it seems great again.&lt;/li&gt;\n&lt;li&gt;Are there alternative solutions I should text before committing to Arq? I&amp;#39;m open to any and all suggestions.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks, and cheers!  &lt;/p&gt;\n\n&lt;p&gt;EDIT: Oddly, the upload number in Arq is going up consistently regardless of adjustments I make to the backup plan, but the size of the target folder seems to have gone down by an entire 10 TiB overnight. Is that de-duping? Or is something screwy? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at47z0", "is_robot_indexable": true, "report_reasons": null, "author": "phospholipid77", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at47z0/arq_7_seems_to_be_good_but_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1at47z0/arq_7_seems_to_be_good_but_alternatives/", "subreddit_subscribers": 732775, "created_utc": 1708182967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a good label printer, price ain't an issue, be creative, I need something reliable to mark a LOT of eth jacks and hardware.", "author_fullname": "t2_6p4cun75", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Label Printer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1at2jfb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708178192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a good label printer, price ain&amp;#39;t an issue, be creative, I need something reliable to mark a LOT of eth jacks and hardware.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1at2jfb", "is_robot_indexable": true, "report_reasons": null, "author": "PiccoloSea", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1at2jfb/best_label_printer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1at2jfb/best_label_printer/", "subreddit_subscribers": 732775, "created_utc": 1708178192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Newbie here - a WD My Passport 2TB hard drive failed recently - lost years worth of data.  I did a quick search to understand possible reliable options - realised that 3.5 CMR hard drives are better.\n\nSome suggested options I've come across are WD 8TB or Seagate 10TB. \n\n1. Would really appreciate if I could get exact product/ model recommendations. Portability is not necessary (don't mind plugging to power).\n2. In case suggested options require a separate case - recos on the same would be helpful.\n\nThanks.", "author_fullname": "t2_re3m4d0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External Hard Drive Recommendations (already searched the sub)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1atllmb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708230728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newbie here - a WD My Passport 2TB hard drive failed recently - lost years worth of data.  I did a quick search to understand possible reliable options - realised that 3.5 CMR hard drives are better.&lt;/p&gt;\n\n&lt;p&gt;Some suggested options I&amp;#39;ve come across are WD 8TB or Seagate 10TB. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Would really appreciate if I could get exact product/ model recommendations. Portability is not necessary (don&amp;#39;t mind plugging to power).&lt;/li&gt;\n&lt;li&gt;In case suggested options require a separate case - recos on the same would be helpful.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atllmb", "is_robot_indexable": true, "report_reasons": null, "author": "KAL-511", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atllmb/external_hard_drive_recommendations_already/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atllmb/external_hard_drive_recommendations_already/", "subreddit_subscribers": 732775, "created_utc": 1708230728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m a verbal person and have taken a lot of voice memos / notes on my phone and handheld voice recorders. I\u2019m at the point where I need to offload everything again. \n\nBefore I do, I wanted to know how ya\u2019ll store and organize your voice memos (i.e by topic, date, type etc). Do you change the name of the file to reflect that? Because right now I just have them all dumped in a main folder in my general backup hard drive.\n\n\n", "author_fullname": "t2_vfuhm3n8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle voice memos? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1atk85j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708226131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a verbal person and have taken a lot of voice memos / notes on my phone and handheld voice recorders. I\u2019m at the point where I need to offload everything again. &lt;/p&gt;\n\n&lt;p&gt;Before I do, I wanted to know how ya\u2019ll store and organize your voice memos (i.e by topic, date, type etc). Do you change the name of the file to reflect that? Because right now I just have them all dumped in a main folder in my general backup hard drive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atk85j", "is_robot_indexable": true, "report_reasons": null, "author": "inquisitiveinquirer1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atk85j/how_do_you_handle_voice_memos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atk85j/how_do_you_handle_voice_memos/", "subreddit_subscribers": 732775, "created_utc": 1708226131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've finally found a command-line tool to deduplicate that does most of what dupeguru does EXCEPT provide the option of MOVING files instead of DELETING them.\n\nSince I've never used rmlint and have to apply it to drives with millions of duplicates, I'd like the option of moving duplicates to a separate drive and then delete them only after I'm certain.\n\nI think it's possible to change the RM command in the rmlint output to MV. But then it doesn't retain the directory structure.\n\nI'm assuming RMLINT is more efficient in RAM utilization and CPU time. If not, I might as well stick to dupeguru.\n\nSuggestions? Thanks.", "author_fullname": "t2_4tyix39s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Make RMLINT move files/folders instead of deleting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1atjjzz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708223993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve finally found a command-line tool to deduplicate that does most of what dupeguru does EXCEPT provide the option of MOVING files instead of DELETING them.&lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;ve never used rmlint and have to apply it to drives with millions of duplicates, I&amp;#39;d like the option of moving duplicates to a separate drive and then delete them only after I&amp;#39;m certain.&lt;/p&gt;\n\n&lt;p&gt;I think it&amp;#39;s possible to change the RM command in the rmlint output to MV. But then it doesn&amp;#39;t retain the directory structure.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m assuming RMLINT is more efficient in RAM utilization and CPU time. If not, I might as well stick to dupeguru.&lt;/p&gt;\n\n&lt;p&gt;Suggestions? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1atjjzz", "is_robot_indexable": true, "report_reasons": null, "author": "ericlindellnyc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1atjjzz/make_rmlint_move_filesfolders_instead_of_deleting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1atjjzz/make_rmlint_move_filesfolders_instead_of_deleting/", "subreddit_subscribers": 732775, "created_utc": 1708223993.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}