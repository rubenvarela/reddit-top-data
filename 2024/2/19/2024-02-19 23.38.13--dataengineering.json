{"kind": "Listing", "data": {"after": "t3_1auwziw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Source: twitter", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How true is this!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1aujhqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 377, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 377, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XNSemjSE_pbJQZzM3w6Pc_1qoBmpLCEFyFH99PGD5ms.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708335562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Source: twitter&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rs9mkuppiijc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?auto=webp&amp;s=cf849cd1680a9f30565e3a92c1d51ddd9a0a0ebd", "width": 1242, "height": 1351}, "resolutions": [{"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d8e248e20c8cc7877b203517a8d891756043a16", "width": 108, "height": 117}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b2ea26c85a4cad901d8881291635110a9add191c", "width": 216, "height": 234}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=92b8ac12c466031b63d1e2347878ee72ab3826db", "width": 320, "height": 348}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=578bd97b55a217e6e2eeb16168ec4296a78b8644", "width": 640, "height": 696}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3b5730963b7e0b4709db8d0e3bd2021f860e27d", "width": 960, "height": 1044}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0c1f6c144bf693d4e853dfc88fe59c840ecefb1b", "width": 1080, "height": 1174}], "variants": {}, "id": "TZHebl6IK1uzPf1uvef7vy4HGDXI9n8wnxcwqtZbtWg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1aujhqw", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aujhqw/how_true_is_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rs9mkuppiijc1.jpeg", "subreddit_subscribers": 162059, "created_utc": 1708335562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I see a lot of folks here asking how to break into Data Engineering, and I wanted to offer some advice beyond the fundamentals of learning tool X. I've hired and trained dozens of people in this field, and at this point I've got a pretty solid sense of what makes someone successful in it. This is what I'd personally recommend.\n\n\n1. Focus on SWE fundamentals. The algorithms and algebra you learned in school can feel a little impractical for day-to-day work, but they're the core of the powerful distributed processing engines you work with in DE. Moving data around efficiently requires a strong understanding of hardware behavior and memory management. Orchestration tools like Airflow are just regular applications with servers and API's like anything else. Realistically, you're not going to walk into your first DE job with experience with DE tools, but you can reason through solutions based on what you know about software in general. The rest will come with time and training.\n\n\n2. Learn battle-tested modeling and architecture patterns and where to apply them. Again, the fundamentals will serve you very well here. Data teams are often tasked with handling data from all over the company, across many contexts and business domains. Trying to keep all of that straight and building bespoke solutions for each one will not only drive you insane, but will end up wasting a ton of time and money reinventing the wheel and reverse-engineering long-forgotten one-offs. Using durable, repeatable patterns is one way to avoid that. Get some books on the subject and start reading.\n\n\n3. Have a clear Definition of Done for your projects that includes quality controls and ongoing monitoring. Data pipelines are uniquely vulnerable to changes entirely outside of your control, since it's highly unlikely that you are the producer of the input data. Think carefully about how eventual changes in upstream data would affect your workload - where are the fragile points, and how you can build resiliency into them. You don't have to (and realistically can't) account for every scenario upfront, but you can take simple steps to catch issues before they reach the CEO's dashboard.\n\n\n4. This is a team sport. Empathy for stakeholders and teammates, in particular assuming good intentions and that previous decisions were made for a good reason, is the #1 thing I look for in a candidate outside of reasoning skills. I have disqualified candidates for off-handed comments about colleagues \"not knowing what they're talking about\", or dragging previous work when talking about refactoring a pipeline. Your job as a steward for the data platform is to understand your stakeholders and build something that allows them to safely and effectively interact with it. It's a unique and complex system which they likely don't, and shouldn't have to, have as deep an understanding of as you do. Behave accordingly. \n\n\n5. Understand what responsible data stewardship looks like. Data is often one of, if not the most, expensive line item for a company. As a DE you are being trusted with the thing that can make or break a company's success both from a cost and legal liability perspective. In my role I regularly make architecture decisions that will cost or pay someone's salary - while it will probably take you a long time to get to that point, being conscientious of the financial impact/risk of your projects makes the jobs of people who do have to make those decisions (the ones who hire and promote you) much easier. \n\n\n6. Beware hype trains and silver bullets. Again, I have disqualified candidates of all levels for falling into this trap. Every tool, language, and framework was built (at least initially) to solve a specific problem, and when you choose to use it you should understand what that problem is. You're absolutely allowed to have a preferred toolbox, but over-indexing on one solution is an indicator that you don't really understand the problem space or the pitfalls of that thing. I've noticed a significant uptick in this problem with the recent popularity of AI; if you're going to use/advocate for it, you'd better be prepared to also speak to the implications and drawbacks.\n\n\nHonorable mention: this may be controversial but I strongly caution against inflating your work experience in this field. Trust me, they'll know. It's okay and expected that you don't have big data experience when you're starting out - it would be ridiculous for me to expect you to know how to scale a Spark pipeline without access to an enterprise system. Just show enthusiasm for learning and use what you've got to your advantage.\n\n\nI believe in you! You got this.\n\nEdit: starter book recommendations in this thread https://www.reddit.com/r/dataengineering/s/sDLpyObrAx", "author_fullname": "t2_v9jthku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New DE advice from a Principal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au9s4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 273, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 273, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708364927.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708302646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I see a lot of folks here asking how to break into Data Engineering, and I wanted to offer some advice beyond the fundamentals of learning tool X. I&amp;#39;ve hired and trained dozens of people in this field, and at this point I&amp;#39;ve got a pretty solid sense of what makes someone successful in it. This is what I&amp;#39;d personally recommend.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Focus on SWE fundamentals. The algorithms and algebra you learned in school can feel a little impractical for day-to-day work, but they&amp;#39;re the core of the powerful distributed processing engines you work with in DE. Moving data around efficiently requires a strong understanding of hardware behavior and memory management. Orchestration tools like Airflow are just regular applications with servers and API&amp;#39;s like anything else. Realistically, you&amp;#39;re not going to walk into your first DE job with experience with DE tools, but you can reason through solutions based on what you know about software in general. The rest will come with time and training.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Learn battle-tested modeling and architecture patterns and where to apply them. Again, the fundamentals will serve you very well here. Data teams are often tasked with handling data from all over the company, across many contexts and business domains. Trying to keep all of that straight and building bespoke solutions for each one will not only drive you insane, but will end up wasting a ton of time and money reinventing the wheel and reverse-engineering long-forgotten one-offs. Using durable, repeatable patterns is one way to avoid that. Get some books on the subject and start reading.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Have a clear Definition of Done for your projects that includes quality controls and ongoing monitoring. Data pipelines are uniquely vulnerable to changes entirely outside of your control, since it&amp;#39;s highly unlikely that you are the producer of the input data. Think carefully about how eventual changes in upstream data would affect your workload - where are the fragile points, and how you can build resiliency into them. You don&amp;#39;t have to (and realistically can&amp;#39;t) account for every scenario upfront, but you can take simple steps to catch issues before they reach the CEO&amp;#39;s dashboard.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;This is a team sport. Empathy for stakeholders and teammates, in particular assuming good intentions and that previous decisions were made for a good reason, is the #1 thing I look for in a candidate outside of reasoning skills. I have disqualified candidates for off-handed comments about colleagues &amp;quot;not knowing what they&amp;#39;re talking about&amp;quot;, or dragging previous work when talking about refactoring a pipeline. Your job as a steward for the data platform is to understand your stakeholders and build something that allows them to safely and effectively interact with it. It&amp;#39;s a unique and complex system which they likely don&amp;#39;t, and shouldn&amp;#39;t have to, have as deep an understanding of as you do. Behave accordingly. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Understand what responsible data stewardship looks like. Data is often one of, if not the most, expensive line item for a company. As a DE you are being trusted with the thing that can make or break a company&amp;#39;s success both from a cost and legal liability perspective. In my role I regularly make architecture decisions that will cost or pay someone&amp;#39;s salary - while it will probably take you a long time to get to that point, being conscientious of the financial impact/risk of your projects makes the jobs of people who do have to make those decisions (the ones who hire and promote you) much easier. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Beware hype trains and silver bullets. Again, I have disqualified candidates of all levels for falling into this trap. Every tool, language, and framework was built (at least initially) to solve a specific problem, and when you choose to use it you should understand what that problem is. You&amp;#39;re absolutely allowed to have a preferred toolbox, but over-indexing on one solution is an indicator that you don&amp;#39;t really understand the problem space or the pitfalls of that thing. I&amp;#39;ve noticed a significant uptick in this problem with the recent popularity of AI; if you&amp;#39;re going to use/advocate for it, you&amp;#39;d better be prepared to also speak to the implications and drawbacks.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Honorable mention: this may be controversial but I strongly caution against inflating your work experience in this field. Trust me, they&amp;#39;ll know. It&amp;#39;s okay and expected that you don&amp;#39;t have big data experience when you&amp;#39;re starting out - it would be ridiculous for me to expect you to know how to scale a Spark pipeline without access to an enterprise system. Just show enthusiasm for learning and use what you&amp;#39;ve got to your advantage.&lt;/p&gt;\n\n&lt;p&gt;I believe in you! You got this.&lt;/p&gt;\n\n&lt;p&gt;Edit: starter book recommendations in this thread &lt;a href=\"https://www.reddit.com/r/dataengineering/s/sDLpyObrAx\"&gt;https://www.reddit.com/r/dataengineering/s/sDLpyObrAx&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1au9s4s", "is_robot_indexable": true, "report_reasons": null, "author": "ithinkiboughtadingo", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au9s4s/new_de_advice_from_a_principal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au9s4s/new_de_advice_from_a_principal/", "subreddit_subscribers": 162059, "created_utc": 1708302646.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I start, this is hooks (pre_hooks and post_hooks) allowing to run any sql code on your DB !", "author_fullname": "t2_ie6cij4nf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the DBT function you discovered recently and you use everywhere?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auwjek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708371894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I start, this is hooks (pre_hooks and post_hooks) allowing to run any sql code on your DB !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1auwjek", "is_robot_indexable": true, "report_reasons": null, "author": "Advanced_Addition321", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auwjek/what_is_the_dbt_function_you_discovered_recently/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auwjek/what_is_the_dbt_function_you_discovered_recently/", "subreddit_subscribers": 162059, "created_utc": 1708371894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey there,  \nIv been asked by my boss to change a DAG that is currently written with python operator to kuberenets operator.\n\nI have no knowledge about Kubernetes but we have a devops team that handles all that stuff, I wanted to ask how complicated will it be for me to change that code (the code itself is really simple, only one python operator and one task, but extremely heavy task).  \nconsidering devops can help me write the dockerfile\n\n  \nand how do I actually pull this off? instead of my python operator I use kuberenets operator, or I use both, or I use image + Kubernetes and no python operator?\n\n  \nand also would like to ask, why/when one should run a Kubernetes operator and when to use normal operators.  \n\n\nthat's a lot of questions so that's it for now.  \nThanks in advance!", "author_fullname": "t2_w6u9u77n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How / When to use Kuberenets operator in airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aumchk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708346402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey there,&lt;br/&gt;\nIv been asked by my boss to change a DAG that is currently written with python operator to kuberenets operator.&lt;/p&gt;\n\n&lt;p&gt;I have no knowledge about Kubernetes but we have a devops team that handles all that stuff, I wanted to ask how complicated will it be for me to change that code (the code itself is really simple, only one python operator and one task, but extremely heavy task).&lt;br/&gt;\nconsidering devops can help me write the dockerfile&lt;/p&gt;\n\n&lt;p&gt;and how do I actually pull this off? instead of my python operator I use kuberenets operator, or I use both, or I use image + Kubernetes and no python operator?&lt;/p&gt;\n\n&lt;p&gt;and also would like to ask, why/when one should run a Kubernetes operator and when to use normal operators.  &lt;/p&gt;\n\n&lt;p&gt;that&amp;#39;s a lot of questions so that&amp;#39;s it for now.&lt;br/&gt;\nThanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aumchk", "is_robot_indexable": true, "report_reasons": null, "author": "PhilosopherRemote177", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aumchk/how_when_to_use_kuberenets_operator_in_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aumchk/how_when_to_use_kuberenets_operator_in_airflow/", "subreddit_subscribers": 162059, "created_utc": 1708346402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. What has caused you or your company to break-up with a particular data vendor (broken SLAs, better features elsewhere, price increases, change in decision makers, etc.)\n\n2. What has prompted you or your company in the past to seek new data vendors, how did options get onto your radar and what were the factors that made the biggest difference in your eventual decision (performance, price, relationship)\n\nDiscuss, would love to to hear everyone\u2019s thoughts.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vendor Break-ups and Hook-ups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aua374", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708303502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What has caused you or your company to break-up with a particular data vendor (broken SLAs, better features elsewhere, price increases, change in decision makers, etc.)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What has prompted you or your company in the past to seek new data vendors, how did options get onto your radar and what were the factors that made the biggest difference in your eventual decision (performance, price, relationship)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Discuss, would love to to hear everyone\u2019s thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aua374", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aua374/vendor_breakups_and_hookups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aua374/vendor_breakups_and_hookups/", "subreddit_subscribers": 162059, "created_utc": 1708303502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently firing off a few POCs on data catalog/data discovery tools for my organization. I am not a data engineer, but I work on the security side of things. Our goal is to have max visibility into the data we have, so we can ensure security best practices are being followed. That being said, we are rolling this out to our data engineering teams for their use as well. After polling our data teams, several features were listed as high in demand, such as data lineage, data glossary, and the ability to collaborate between data assets owned by different teams. Perhaps you folks could shed some light as to what you would like to see in a catalog/discovery tool?\n\n&amp;#x200B;\n\nEdit: I kant spel.", "author_fullname": "t2_dq4h698", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some key features of a data catalog would engineers find useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1auzzx9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708379878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently firing off a few POCs on data catalog/data discovery tools for my organization. I am not a data engineer, but I work on the security side of things. Our goal is to have max visibility into the data we have, so we can ensure security best practices are being followed. That being said, we are rolling this out to our data engineering teams for their use as well. After polling our data teams, several features were listed as high in demand, such as data lineage, data glossary, and the ability to collaborate between data assets owned by different teams. Perhaps you folks could shed some light as to what you would like to see in a catalog/discovery tool?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: I kant spel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1auzzx9", "is_robot_indexable": true, "report_reasons": null, "author": "Wentz_ylvania", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auzzx9/what_are_some_key_features_of_a_data_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auzzx9/what_are_some_key_features_of_a_data_catalog/", "subreddit_subscribers": 162059, "created_utc": 1708379878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to build my own data lake for some DE personal projects in AWS. Really just to upskill in data lakes and related technologies (i.e. Iceberg) since I don't have good opportunities to work on these things in my day job.\n\nI found two pretty thorough articles, [one from from Microsoft](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/cloud-scale-analytics/best-practices/data-lake-zones) and [one from AWS](https://docs.aws.amazon.com/prescriptive-guidance/latest/defining-bucket-names-data-lakes/welcome.html) on basic data lake organization and infrastructure, and I was wondering whether the community had any opinion on which of these would be the better model to follow when building out a new data lake architecture?\n\nBoth are very similar in design, but I like how the Microsoft design includes the conformance container for data passing QC and converted into the lake format. Other then which design is better, my only other questions are:\n\n1. How many S3 buckets should I use to build this out? 1 per layer? Also in the Microsoft design what's the difference between a lake and a container??\n2. How important is it to actually have a curated/analytics layer? I'm struggling to see how the enriched/stage layer differs from the curated/analytics layer, and I'm hesitant to add complexity before it's needed...", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help deciding on new data lake design for DE personal projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auxvo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708374961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to build my own data lake for some DE personal projects in AWS. Really just to upskill in data lakes and related technologies (i.e. Iceberg) since I don&amp;#39;t have good opportunities to work on these things in my day job.&lt;/p&gt;\n\n&lt;p&gt;I found two pretty thorough articles, &lt;a href=\"https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/cloud-scale-analytics/best-practices/data-lake-zones\"&gt;one from from Microsoft&lt;/a&gt; and &lt;a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/defining-bucket-names-data-lakes/welcome.html\"&gt;one from AWS&lt;/a&gt; on basic data lake organization and infrastructure, and I was wondering whether the community had any opinion on which of these would be the better model to follow when building out a new data lake architecture?&lt;/p&gt;\n\n&lt;p&gt;Both are very similar in design, but I like how the Microsoft design includes the conformance container for data passing QC and converted into the lake format. Other then which design is better, my only other questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How many S3 buckets should I use to build this out? 1 per layer? Also in the Microsoft design what&amp;#39;s the difference between a lake and a container??&lt;/li&gt;\n&lt;li&gt;How important is it to actually have a curated/analytics layer? I&amp;#39;m struggling to see how the enriched/stage layer differs from the curated/analytics layer, and I&amp;#39;m hesitant to add complexity before it&amp;#39;s needed...&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?auto=webp&amp;s=41fa146938cd97da5abfeff0d092a2cc151e65fa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3881e36da92b82c6947f6ca4ff3804ca47f2aea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17b5b01e50a969ac9e2353bebb062cd52a99d108", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=acadaf004e8aeb6919eabdb0d93065a34f7e89df", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=883009d39175a2f03b76275ed0f7c6011d94a3a7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc62aef83f192d102fa78c83c8f4fcfa85057e3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ca6913f202be9a9f83b266dd459edc90adbf9dd", "width": 1080, "height": 567}], "variants": {}, "id": "RCFh0Kid3SAqWEkALMGNW1e9Vu6ayZpftekoayP00hY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1auxvo3", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auxvo3/need_help_deciding_on_new_data_lake_design_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auxvo3/need_help_deciding_on_new_data_lake_design_for_de/", "subreddit_subscribers": 162059, "created_utc": 1708374961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When your data sources and ETL pipelines live in AWS for examples as S3, Glue Jobs and RDS, then when you want to intagre it with a data warehouse, isn't the choice of Snowflake a bad decision cost-wise? Does it not cost extra to move data between AWS Cloud and Snowflake Cloud? Does it not make more sense to use Redshift then to avoid moving data via public internet?", "author_fullname": "t2_34tfcgtu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Isn't Snowflake expensive when your other infrastructure is on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ausru6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708363185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When your data sources and ETL pipelines live in AWS for examples as S3, Glue Jobs and RDS, then when you want to intagre it with a data warehouse, isn&amp;#39;t the choice of Snowflake a bad decision cost-wise? Does it not cost extra to move data between AWS Cloud and Snowflake Cloud? Does it not make more sense to use Redshift then to avoid moving data via public internet?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ausru6", "is_robot_indexable": true, "report_reasons": null, "author": "rental_car_abuse", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ausru6/isnt_snowflake_expensive_when_your_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ausru6/isnt_snowflake_expensive_when_your_other/", "subreddit_subscribers": 162059, "created_utc": 1708363185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am glad to share with you my first web scraping project done on an e-commerce site. The goal was to come up with a list of products on discount for customers to select. I would appreciate any feedback or ways to make the project way better.\n\n[https://github.com/ennock/Webscraping-an-Ecommerce-site-](https://github.com/ennock/Webscraping-an-Ecommerce-site-)", "author_fullname": "t2_iiwc5106k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web Scraping an E-commerce Site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aujo8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708336339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am glad to share with you my first web scraping project done on an e-commerce site. The goal was to come up with a list of products on discount for customers to select. I would appreciate any feedback or ways to make the project way better.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ennock/Webscraping-an-Ecommerce-site-\"&gt;https://github.com/ennock/Webscraping-an-Ecommerce-site-&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?auto=webp&amp;s=10839024ca3d2c7630c8fa8c25b1f3fcdb4dbed6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e02c3ffe7c84c3f11c64713e6325c6d56c0bbd2e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a560e1c64d846cef6294d8554cfedb00977806b8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ce9e0348f652876624ae84de77fa8717bf87707", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bcc243132e475952766213ad8441b2fd653ec0dd", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=01a97466b9aad7c65f2b04bd1d6e04eeed30f890", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0599ed2b9152d12c39b08c4bc7fed2f816cc8991", "width": 1080, "height": 540}], "variants": {}, "id": "NUwfFAkGXTYjfIDiB2qmDaeOp993mbAs0b-u5vrNV2U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1aujo8q", "is_robot_indexable": true, "report_reasons": null, "author": "xscri", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aujo8q/web_scraping_an_ecommerce_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aujo8q/web_scraping_an_ecommerce_site/", "subreddit_subscribers": 162059, "created_utc": 1708336339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have about 10 years professional experience in data related roles. Over half that time I\u2019ve been at my current company. I started as a staff and was recently promoted to manager and I don\u2019t really enjoy it but at my company the only path seems to be management. \n\nI am thinking of leaving but feel like my experience/skills are limiting me for either path. I have some management experience on paper but I am not the best at it and don\u2019t really enjoy it, although I feel like that\u2019s a path I have to take with my age and experience. \n\nI\u2019d prefer to get into a more engineering focused job but my coding/programming skills/experience are heavily limited with my current work environment. I feel like I\u2019m stuck between both and not experienced/skilled enough for either outside my current company", "author_fullname": "t2_9ac91rpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career crossroads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au9kg4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708302072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 10 years professional experience in data related roles. Over half that time I\u2019ve been at my current company. I started as a staff and was recently promoted to manager and I don\u2019t really enjoy it but at my company the only path seems to be management. &lt;/p&gt;\n\n&lt;p&gt;I am thinking of leaving but feel like my experience/skills are limiting me for either path. I have some management experience on paper but I am not the best at it and don\u2019t really enjoy it, although I feel like that\u2019s a path I have to take with my age and experience. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d prefer to get into a more engineering focused job but my coding/programming skills/experience are heavily limited with my current work environment. I feel like I\u2019m stuck between both and not experienced/skilled enough for either outside my current company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1au9kg4", "is_robot_indexable": true, "report_reasons": null, "author": "Maw-installation", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au9kg4/career_crossroads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au9kg4/career_crossroads/", "subreddit_subscribers": 162059, "created_utc": 1708302072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was thinking about a POC for AWS MSK and it sort of raised a question in mind: what are your use cases for real time data? If it helps, expand the question to using Kafka in general. \n\nLet me give some quick background and where I\u2019m coming from. I built real-time pipelines a long ago (8+ years). My use case initially was real time product analytics; we had nightly batch jobs, so, at the time, this was a significant improvement. \n\nHowever, since then, we have tools like Segment that handle most use cases. Other than bringing Segment in-house to help reduce costs, why would one build their own realtime pipeline instead of leveraging existing tools? I thought about multiple consumers in Kafka, but Segment takes care of that as well, e.g. you can use Segment to send data to your DW, to Amplitude and to your CRM tool, all in near real-time. \n\nOther than a couple of companies I worked at, the data volume is not that significant, i.e. 100\u2019s of TBs, not PBs, so the tools generally work fine. Consequently, as a leader, I tend to lean more towards using tools as they help increase team velocity and I have the team focus on stakeholder needs &amp; deriving insights from the data, more than the data pipelines themselves. \n\nGiven all that, I\u2019m curious about your use cases and why you chose to build a realtime pipeline yourself instead of leveraging an existing tool like Segment?", "author_fullname": "t2_16b1dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your use case for a realtime data pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1av0oth", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708381460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking about a POC for AWS MSK and it sort of raised a question in mind: what are your use cases for real time data? If it helps, expand the question to using Kafka in general. &lt;/p&gt;\n\n&lt;p&gt;Let me give some quick background and where I\u2019m coming from. I built real-time pipelines a long ago (8+ years). My use case initially was real time product analytics; we had nightly batch jobs, so, at the time, this was a significant improvement. &lt;/p&gt;\n\n&lt;p&gt;However, since then, we have tools like Segment that handle most use cases. Other than bringing Segment in-house to help reduce costs, why would one build their own realtime pipeline instead of leveraging existing tools? I thought about multiple consumers in Kafka, but Segment takes care of that as well, e.g. you can use Segment to send data to your DW, to Amplitude and to your CRM tool, all in near real-time. &lt;/p&gt;\n\n&lt;p&gt;Other than a couple of companies I worked at, the data volume is not that significant, i.e. 100\u2019s of TBs, not PBs, so the tools generally work fine. Consequently, as a leader, I tend to lean more towards using tools as they help increase team velocity and I have the team focus on stakeholder needs &amp;amp; deriving insights from the data, more than the data pipelines themselves. &lt;/p&gt;\n\n&lt;p&gt;Given all that, I\u2019m curious about your use cases and why you chose to build a realtime pipeline yourself instead of leveraging an existing tool like Segment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1av0oth", "is_robot_indexable": true, "report_reasons": null, "author": "jawabdey", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1av0oth/what_is_your_use_case_for_a_realtime_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1av0oth/what_is_your_use_case_for_a_realtime_data_pipeline/", "subreddit_subscribers": 162059, "created_utc": 1708381460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ctd40uoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Podcast: Using Trino And Iceberg As The Foundation Of Your Data Lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1auxetw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/-4Dik-FyeSJpSLw-jbXD2GjKV7cWZOWsUwh84W2XrY0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708373870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringpodcast.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dataengineeringpodcast.com/starburst-trino-iceberg-data-lakehouse-episode-413", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?auto=webp&amp;s=2120aa9314091ca630e69926832b5fbc04ca756f", "width": 1400, "height": 1400}, "resolutions": [{"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aaf640634e9da8c03b7edc9f09ca7e31f6aee921", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d88217a29fa71c5c662c7d324035df8ba72fecca", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0034038dbb6753ab8fb8490b14b6bf2819656cf3", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f8b617a7c6583a41fb510d3334de668dec2a38e3", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=235cd7229206b22708fdca688c95c3648c246479", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9448afa1d602f1ff1c49cf168a73076130d1cb10", "width": 1080, "height": 1080}], "variants": {}, "id": "T69lnyzJjP6GC8oxXuuJPHNQnXgo_9t63cJnvtec6xw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1auxetw", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Relationship-207", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auxetw/data_engineering_podcast_using_trino_and_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dataengineeringpodcast.com/starburst-trino-iceberg-data-lakehouse-episode-413", "subreddit_subscribers": 162059, "created_utc": 1708373870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\nSo I've been poking around merge statements with delta tables over the last few days.\nI've done it before in Databricks and it went fine, different story now in Synapse.\n\nI'm attempting to, basically, do an incremental load. The target table has a few columns and a modifiedTimestamp (Unix) and so does the update source. I presume the issue stems from not using deterministic columns (timestamp is basically produced with datetime.now())\n\nIn the merge statements, regardless if I use whenMatchedUpdateAll() and whenNotMatchedInsertAll().\nOr Update and Insert with a set and values respectively, it actually acts as if nothing was updated with the Matched statement and it pretty much inserts everything, once again, with the Not Matched statement.\nThe issue, I suppose, is that there's no primary key column, so the merge condition is target.col1 = source.col1 and target.col2 = source.col2, and so on, for about 8 columns, and the timestamp is always different.\n\nSo the Matched statement works fine and doesn't create duplicates (running it with a set inserts everything correctly and works idempotently), but the Not Matched one creates many duplicates.\n\nTo put it simply: I merge some data with When Matched, and then I test more data that also contains the data that's already present. Instead of using the merge condition columns as a sort of PK (unique) and skipping whatever is matched, when the Not matched statement runs it merges everything, matched and unmatched both.\n\nAny tips for dealing with this?", "author_fullname": "t2_6a86w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some Delta Merge Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aux9l6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708373945.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708373545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,\nSo I&amp;#39;ve been poking around merge statements with delta tables over the last few days.\nI&amp;#39;ve done it before in Databricks and it went fine, different story now in Synapse.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m attempting to, basically, do an incremental load. The target table has a few columns and a modifiedTimestamp (Unix) and so does the update source. I presume the issue stems from not using deterministic columns (timestamp is basically produced with datetime.now())&lt;/p&gt;\n\n&lt;p&gt;In the merge statements, regardless if I use whenMatchedUpdateAll() and whenNotMatchedInsertAll().\nOr Update and Insert with a set and values respectively, it actually acts as if nothing was updated with the Matched statement and it pretty much inserts everything, once again, with the Not Matched statement.\nThe issue, I suppose, is that there&amp;#39;s no primary key column, so the merge condition is target.col1 = source.col1 and target.col2 = source.col2, and so on, for about 8 columns, and the timestamp is always different.&lt;/p&gt;\n\n&lt;p&gt;So the Matched statement works fine and doesn&amp;#39;t create duplicates (running it with a set inserts everything correctly and works idempotently), but the Not Matched one creates many duplicates.&lt;/p&gt;\n\n&lt;p&gt;To put it simply: I merge some data with When Matched, and then I test more data that also contains the data that&amp;#39;s already present. Instead of using the merge condition columns as a sort of PK (unique) and skipping whatever is matched, when the Not matched statement runs it merges everything, matched and unmatched both.&lt;/p&gt;\n\n&lt;p&gt;Any tips for dealing with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aux9l6", "is_robot_indexable": true, "report_reasons": null, "author": "Hear7y", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aux9l6/need_some_delta_merge_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aux9l6/need_some_delta_merge_advice/", "subreddit_subscribers": 162059, "created_utc": 1708373545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm thinking of joining an asset management company on their data engineering team. Seems like a pretty well doing team that's more focused on SQL and data modeling. They have ci/cd already built and integrated, but I see some opportunities down the road to do some Python and build some orchestration tools. \n\nFor those who work or have worked in finance, do you think it's easy to switch from asset management to a PE firm or any other type of finance company? I'm not hoping for any type of switch already, but finance is a pretty big industry in the area I live and am trying to gauge the feasibility of hopping around within the industry if I ever get bored or just want to switch. Any technical skills that are sought after within finance? Other things to know about data engineering within finance?", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone work in finance? What's it like to switch between different types of companies within finance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aux6nq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708373361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of joining an asset management company on their data engineering team. Seems like a pretty well doing team that&amp;#39;s more focused on SQL and data modeling. They have ci/cd already built and integrated, but I see some opportunities down the road to do some Python and build some orchestration tools. &lt;/p&gt;\n\n&lt;p&gt;For those who work or have worked in finance, do you think it&amp;#39;s easy to switch from asset management to a PE firm or any other type of finance company? I&amp;#39;m not hoping for any type of switch already, but finance is a pretty big industry in the area I live and am trying to gauge the feasibility of hopping around within the industry if I ever get bored or just want to switch. Any technical skills that are sought after within finance? Other things to know about data engineering within finance?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aux6nq", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aux6nq/anyone_work_in_finance_whats_it_like_to_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aux6nq/anyone_work_in_finance_whats_it_like_to_switch/", "subreddit_subscribers": 162059, "created_utc": 1708373361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've built some data pipelines in the past and I'd love to get some feedback on what can be done to improve them. Any advice is appreciated!\n\n&amp;#x200B;\n\nSimple Side Project Pipeline:\n\nReddit -&gt; PRAW (on local machine) -&gt; SQLite DB -&gt; report software\n\n&amp;#x200B;\n\nActual Work Pipeline:\n\nVarious Sources -&gt; Custom Python on a VM -&gt; Oracle On-Prem -&gt; dbt -&gt; report software\n\n&amp;#x200B;\n\nHypothetical Pipeline if my company let me use fancy tools:\n\nVarious Sources -&gt; AWS Glue -&gt; S3 -&gt; Redshift -&gt; dbt -&gt; report software \n\nwith optional additions for things like AWS Lamda/Aurora/Athena depending on the situation\n\n&amp;#x200B;\n\nWhat kinds of things am I missing? Is there a better way to ensure security or alert for failures?", "author_fullname": "t2_1gyiwuuv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipeline Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auhtcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708328742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve built some data pipelines in the past and I&amp;#39;d love to get some feedback on what can be done to improve them. Any advice is appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Simple Side Project Pipeline:&lt;/p&gt;\n\n&lt;p&gt;Reddit -&amp;gt; PRAW (on local machine) -&amp;gt; SQLite DB -&amp;gt; report software&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Actual Work Pipeline:&lt;/p&gt;\n\n&lt;p&gt;Various Sources -&amp;gt; Custom Python on a VM -&amp;gt; Oracle On-Prem -&amp;gt; dbt -&amp;gt; report software&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hypothetical Pipeline if my company let me use fancy tools:&lt;/p&gt;\n\n&lt;p&gt;Various Sources -&amp;gt; AWS Glue -&amp;gt; S3 -&amp;gt; Redshift -&amp;gt; dbt -&amp;gt; report software &lt;/p&gt;\n\n&lt;p&gt;with optional additions for things like AWS Lamda/Aurora/Athena depending on the situation&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What kinds of things am I missing? Is there a better way to ensure security or alert for failures?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1auhtcp", "is_robot_indexable": true, "report_reasons": null, "author": "trianglesteve", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auhtcp/data_pipeline_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auhtcp/data_pipeline_feedback/", "subreddit_subscribers": 162059, "created_utc": 1708328742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Guys,\n\nI have 20 excel sheets, with an average shape of 300,000+/-80K, 120+/-10. I am trying to maintain a local data repository. I have tried the following and have not succeeded, please give me your insights.\n\nThing I did:\n\n1. Use pandas to read the xlsx and dump each workbook as a table in my local mysql db. I did the above step hoping that although the tables have slightly different columns (names are the same, but the column position is different a some tables/xlsx book have extra columns) I can union them to form a central repository. When I use `\"select &lt;column&gt; from table_1\"`, I get an error saying the column doesn't exist. I gave up trying to figure out why pandas can read the column name in a df, but not when queried from mysql\n2. Then, I tried to extract the data from mysql and load it to mongodb so the schema change does not really affect the db, meaning nulls would be filled in if the xlsx sheet doesn't have the same exact column. But mongo db connection always times out\n3. I tried to use Databricks(Azure) and the free tier won't let me do anything of this size\n\nwhat strategies do you use to load 4+ million rows?\n\n&amp;#x200B;", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for maintaining a central repository in my local machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au9jia", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708302006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys,&lt;/p&gt;\n\n&lt;p&gt;I have 20 excel sheets, with an average shape of 300,000+/-80K, 120+/-10. I am trying to maintain a local data repository. I have tried the following and have not succeeded, please give me your insights.&lt;/p&gt;\n\n&lt;p&gt;Thing I did:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use pandas to read the xlsx and dump each workbook as a table in my local mysql db. I did the above step hoping that although the tables have slightly different columns (names are the same, but the column position is different a some tables/xlsx book have extra columns) I can union them to form a central repository. When I use &lt;code&gt;&amp;quot;select &amp;lt;column&amp;gt; from table_1&amp;quot;&lt;/code&gt;, I get an error saying the column doesn&amp;#39;t exist. I gave up trying to figure out why pandas can read the column name in a df, but not when queried from mysql&lt;/li&gt;\n&lt;li&gt;Then, I tried to extract the data from mysql and load it to mongodb so the schema change does not really affect the db, meaning nulls would be filled in if the xlsx sheet doesn&amp;#39;t have the same exact column. But mongo db connection always times out&lt;/li&gt;\n&lt;li&gt;I tried to use Databricks(Azure) and the free tier won&amp;#39;t let me do anything of this size&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;what strategies do you use to load 4+ million rows?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1au9jia", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au9jia/ideas_for_maintaining_a_central_repository_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au9jia/ideas_for_maintaining_a_central_repository_in_my/", "subreddit_subscribers": 162059, "created_utc": 1708302006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for suggestions on an (ideally opens source) tool to help setup an extract and load process between two databases. I have a JDBC driver for the source database, and the target database is postgresql.\n\nThe number of tables is quite large, though the volume of data itself is not that large. Additionally, the schema in the source database will regularly change. Is there any tool that will auto-create and update the schema on the second database? Ideally with options for incremental/complete replication?", "author_fullname": "t2_dei36", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extract and load tool with target table creation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1auzk3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708378834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for suggestions on an (ideally opens source) tool to help setup an extract and load process between two databases. I have a JDBC driver for the source database, and the target database is postgresql.&lt;/p&gt;\n\n&lt;p&gt;The number of tables is quite large, though the volume of data itself is not that large. Additionally, the schema in the source database will regularly change. Is there any tool that will auto-create and update the schema on the second database? Ideally with options for incremental/complete replication?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1auzk3d", "is_robot_indexable": true, "report_reasons": null, "author": "corycorycory09", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auzk3d/extract_and_load_tool_with_target_table_creation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auzk3d/extract_and_load_tool_with_target_table_creation/", "subreddit_subscribers": 162059, "created_utc": 1708378834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my first job was a a cloud engineer with database administration in which I learned a lot because of my seniors. Now my current job (3 months) is as a data engineer where we run our pipelines (python scripts) in a VM with task scheduler. We are slowly migrating our things to azure. My senior is leaving the company leaving me alone until they find a replacement (he came from a data scientist background and is self taught)\n\n&amp;#x200B;\n\nAm I missing a lot from not having a mentor and being on a company where data engineering lacks maturity? When I came to this company I made it clear my goal was to learn the ropes as a data engineer and most of what is keeping me is to not have a job with only 3 months in my CV.  \n\n\nFor the most experienced how common are companies like this? Should I look for other options?", "author_fullname": "t2_scb32bzm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is mentoring for a junior data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1auzjli", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708378805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my first job was a a cloud engineer with database administration in which I learned a lot because of my seniors. Now my current job (3 months) is as a data engineer where we run our pipelines (python scripts) in a VM with task scheduler. We are slowly migrating our things to azure. My senior is leaving the company leaving me alone until they find a replacement (he came from a data scientist background and is self taught)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Am I missing a lot from not having a mentor and being on a company where data engineering lacks maturity? When I came to this company I made it clear my goal was to learn the ropes as a data engineer and most of what is keeping me is to not have a job with only 3 months in my CV.  &lt;/p&gt;\n\n&lt;p&gt;For the most experienced how common are companies like this? Should I look for other options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1auzjli", "is_robot_indexable": true, "report_reasons": null, "author": "CrazyKey4744", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auzjli/how_important_is_mentoring_for_a_junior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auzjli/how_important_is_mentoring_for_a_junior_data/", "subreddit_subscribers": 162059, "created_utc": 1708378805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! \n\nI have a modelling question. Suposse that i have one fact that talk about contract of students and each contract has a data\\_activation and if student evade it has data\\_deactivation. Thinking  about this context, its a good approach have two fact table one for evasion and one for current students or have all in one and filter based on date columns?\n\nThanks!", "author_fullname": "t2_8jc0mwfh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Split a fact table into two differente context?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aurhd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708360202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;I have a modelling question. Suposse that i have one fact that talk about contract of students and each contract has a data_activation and if student evade it has data_deactivation. Thinking  about this context, its a good approach have two fact table one for evasion and one for current students or have all in one and filter based on date columns?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aurhd4", "is_robot_indexable": true, "report_reasons": null, "author": "Andremallmann", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aurhd4/split_a_fact_table_into_two_differente_context/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aurhd4/split_a_fact_table_into_two_differente_context/", "subreddit_subscribers": 162059, "created_utc": 1708360202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will be starting a new role soon at a company that uses Spark (PySpark) on HPC clusters. I\u2019ve never used HPC clusters before but from googling I understand you have to submit jobs to a workload manager whereas in Databricks stuff like this is usually taken care of for you?\n\nSince I\u2019m new to working with HPC I was hoping for some advice from others who have used PySpark on HPC Clusters in production and was hoping for a list of \u201cDo\u2019s and Don\u2019t\u201d along with any resources or advice that could be helpful for someone in my situation. \n\nAlso, do HPC clusters have any advantages over Databricks? \n\n\n", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking HPC Cluster advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aup1o4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708354188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will be starting a new role soon at a company that uses Spark (PySpark) on HPC clusters. I\u2019ve never used HPC clusters before but from googling I understand you have to submit jobs to a workload manager whereas in Databricks stuff like this is usually taken care of for you?&lt;/p&gt;\n\n&lt;p&gt;Since I\u2019m new to working with HPC I was hoping for some advice from others who have used PySpark on HPC Clusters in production and was hoping for a list of \u201cDo\u2019s and Don\u2019t\u201d along with any resources or advice that could be helpful for someone in my situation. &lt;/p&gt;\n\n&lt;p&gt;Also, do HPC clusters have any advantages over Databricks? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aup1o4", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aup1o4/seeking_hpc_cluster_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aup1o4/seeking_hpc_cluster_advice/", "subreddit_subscribers": 162059, "created_utc": 1708354188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm handed a project to research applications that produce automated visuals and calculations. The twist here is that there is user input and sort database from where information is stretched for calculations. This tool was originally in excel which allowed everything to be at one place. However, it got cumbersome with a lot of data. Is there any ready-made software to use or develop? Thank you", "author_fullname": "t2_7658exh7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Application for visualization and calculations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aunya1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708351222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m handed a project to research applications that produce automated visuals and calculations. The twist here is that there is user input and sort database from where information is stretched for calculations. This tool was originally in excel which allowed everything to be at one place. However, it got cumbersome with a lot of data. Is there any ready-made software to use or develop? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aunya1", "is_robot_indexable": true, "report_reasons": null, "author": "Warm-Consideration-5", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aunya1/application_for_visualization_and_calculations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aunya1/application_for_visualization_and_calculations/", "subreddit_subscribers": 162059, "created_utc": 1708351222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you were asked today, what\u2019s your take?\n\n[View Poll](https://www.reddit.com/poll/1aux2by)", "author_fullname": "t2_c6r0b2zx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting perspective from folks in the trenches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aux2by", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708373083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were asked today, what\u2019s your take?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1aux2by\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aux2by", "is_robot_indexable": true, "report_reasons": null, "author": "SwingTip", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1708632283738, "options": [{"text": "Would recommend implementing Palantir", "id": "27147822"}, {"text": "Would advise against implementing Palantir", "id": "27147823"}, {"text": "Leave me alone, send caffeine", "id": "27147824"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 23, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aux2by/wanting_perspective_from_folks_in_the_trenches/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/1aux2by/wanting_perspective_from_folks_in_the_trenches/", "subreddit_subscribers": 162059, "created_utc": 1708373083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If somebody got offered:\n-data engineering position\n-analytics engineering position\n-devops engineering position\n-test engineering position \n-technical consultancy position\nAll entry levels with all very similar salaries, and the person doesn't really mind any field.. what field would be best pursuing and potentially making more money in the future generally?", "author_fullname": "t2_789r8q3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au9ov8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708302401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If somebody got offered:\n-data engineering position\n-analytics engineering position\n-devops engineering position\n-test engineering position \n-technical consultancy position\nAll entry levels with all very similar salaries, and the person doesn&amp;#39;t really mind any field.. what field would be best pursuing and potentially making more money in the future generally?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1au9ov8", "is_robot_indexable": true, "report_reasons": null, "author": "elitek7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au9ov8/career_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au9ov8/career_options/", "subreddit_subscribers": 162059, "created_utc": 1708302401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hpr5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Data Engineering Is Key to Digital Transformation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_1augxjt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.42, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RWgKnHy2i3TLWVmLGbxrp0GJCbbJUxtxKzUh_zB6fXc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708325363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "futurismtechnologies.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.futurismtechnologies.com/blog/why-data-engineering-is-key-to-digital-transformation/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?auto=webp&amp;s=b5775efe92170e36119900ef32bf242bafe88904", "width": 800, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf0e3923f6eaaa455b3c7cd3381d88c3195216ca", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=178437dc5fcc42d4ff0478bccce4224fd2dba5f1", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f6b9d0e5f40a57c5c6472445a55e8d83163997a", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a6cf6656af429e1e4482ad649a994e5fbb6123f", "width": 640, "height": 400}], "variants": {}, "id": "cEgIoW4lhrbCcDhR7buNZVVzhfnAsqhCk4xl-PgteEI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1augxjt", "is_robot_indexable": true, "report_reasons": null, "author": "Futurismtechnologies", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1augxjt/why_data_engineering_is_key_to_digital/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.futurismtechnologies.com/blog/why-data-engineering-is-key-to-digital-transformation/", "subreddit_subscribers": 162059, "created_utc": 1708325363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\"Data Engineer\" is a horribly esoteric job title which tends to result in a lot of blank stares and confused looks from all the \"normal\" people in my life. How do you describe data engineering to normal folk in as few sentences as possible?\n\nMy favourite: \"I'm like a plumber for data, i.e. I do for number and computers what a plumber does for water and toilets.\"", "author_fullname": "t2_6mxelrxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you describe your job to normies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auwziw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708372901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Data Engineer&amp;quot; is a horribly esoteric job title which tends to result in a lot of blank stares and confused looks from all the &amp;quot;normal&amp;quot; people in my life. How do you describe data engineering to normal folk in as few sentences as possible?&lt;/p&gt;\n\n&lt;p&gt;My favourite: &amp;quot;I&amp;#39;m like a plumber for data, i.e. I do for number and computers what a plumber does for water and toilets.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1auwziw", "is_robot_indexable": true, "report_reasons": null, "author": "Creyke", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auwziw/how_do_you_describe_your_job_to_normies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auwziw/how_do_you_describe_your_job_to_normies/", "subreddit_subscribers": 162059, "created_utc": 1708372901.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}