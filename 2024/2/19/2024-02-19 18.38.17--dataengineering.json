{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I see a lot of folks here asking how to break into Data Engineering, and I wanted to offer some advice beyond the fundamentals of learning tool X. I've hired and trained dozens of people in this field, and at this point I've got a pretty solid sense of what makes someone successful in it. This is what I'd personally recommend.\n\n\n1. Focus on SWE fundamentals. The algorithms and algebra you learned in school can feel a little impractical for day-to-day work, but they're the core of the powerful distributed processing engines you work with in DE. Moving data around efficiently requires a strong understanding of hardware behavior and memory management. Orchestration tools like Airflow are just regular applications with servers and API's like anything else. Realistically, you're not going to walk into your first DE job with experience with DE tools, but you can reason through solutions based on what you know about software in general. The rest will come with time and training.\n\n\n2. Learn battle-tested modeling and architecture patterns and where to apply them. Again, the fundamentals will serve you very well here. Data teams are often tasked with handling data from all over the company, across many contexts and business domains. Trying to keep all of that straight and building bespoke solutions for each one will not only drive you insane, but will end up wasting a ton of time and money reinventing the wheel and reverse-engineering long-forgotten one-offs. Using durable, repeatable patterns is one way to avoid that. Get some books on the subject and start reading.\n\n\n3. Have a clear Definition of Done for your projects that includes quality controls and ongoing monitoring. Data pipelines are uniquely vulnerable to changes entirely outside of your control, since it's highly unlikely that you are the producer of the input data. Think carefully about how eventual changes in upstream data would affect your workload - where are the fragile points, and how you can build resiliency into them. You don't have to (and realistically can't) account for every scenario upfront, but you can take simple steps to catch issues before they reach the CEO's dashboard.\n\n\n4. This is a team sport. Empathy for stakeholders and teammates, in particular assuming good intentions and that previous decisions were made for a good reason, is the #1 thing I look for in a candidate outside of reasoning skills. I have disqualified candidates for off-handed comments about colleagues \"not knowing what they're talking about\", or dragging previous work when talking about refactoring a pipeline. Your job as a steward for the data platform is to understand your stakeholders and build something that allows them to safely and effectively interact with it. It's a unique and complex system which they likely don't, and shouldn't have to, have as deep an understanding of as you do. Behave accordingly. \n\n\n5. Understand what responsible data stewardship looks like. Data is often one of, if not the most, expensive line item for a company. As a DE you are being trusted with the thing that can make or break a company's success both from a cost and legal liability perspective. In my role I regularly make architecture decisions that will cost or pay someone's salary - while it will probably take you a long time to get to that point, being conscientious of the financial impact/risk of your projects makes the jobs of people who do have to make those decisions (the ones who hire and promote you) much easier. \n\n\n6. Beware hype trains and silver bullets. Again, I have disqualified candidates of all levels for falling into this trap. Every tool, language, and framework was built (at least initially) to solve a specific problem, and when you choose to use it you should understand what that problem is. You're absolutely allowed to have a preferred toolbox, but over-indexing on one solution is an indicator that you don't really understand the problem space or the pitfalls of that thing. I've noticed a significant uptick in this problem with the recent popularity of AI; if you're going to use/advocate for it, you'd better be prepared to also speak to the implications and drawbacks.\n\n\nHonorable mention: this may be controversial but I strongly caution against inflating your work experience in this field. Trust me, they'll know. It's okay and expected that you don't have big data experience when you're starting out - it would be ridiculous for me to expect you to know how to scale a Spark pipeline without access to an enterprise system. Just show enthusiasm for learning and use what you've got to your advantage.\n\n\nI believe in you! You got this.\n\nEdit: starter book recommendations in this thread https://www.reddit.com/r/dataengineering/s/sDLpyObrAx", "author_fullname": "t2_v9jthku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New DE advice from a Principal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au9s4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 245, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 245, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708364927.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708302646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I see a lot of folks here asking how to break into Data Engineering, and I wanted to offer some advice beyond the fundamentals of learning tool X. I&amp;#39;ve hired and trained dozens of people in this field, and at this point I&amp;#39;ve got a pretty solid sense of what makes someone successful in it. This is what I&amp;#39;d personally recommend.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Focus on SWE fundamentals. The algorithms and algebra you learned in school can feel a little impractical for day-to-day work, but they&amp;#39;re the core of the powerful distributed processing engines you work with in DE. Moving data around efficiently requires a strong understanding of hardware behavior and memory management. Orchestration tools like Airflow are just regular applications with servers and API&amp;#39;s like anything else. Realistically, you&amp;#39;re not going to walk into your first DE job with experience with DE tools, but you can reason through solutions based on what you know about software in general. The rest will come with time and training.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Learn battle-tested modeling and architecture patterns and where to apply them. Again, the fundamentals will serve you very well here. Data teams are often tasked with handling data from all over the company, across many contexts and business domains. Trying to keep all of that straight and building bespoke solutions for each one will not only drive you insane, but will end up wasting a ton of time and money reinventing the wheel and reverse-engineering long-forgotten one-offs. Using durable, repeatable patterns is one way to avoid that. Get some books on the subject and start reading.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Have a clear Definition of Done for your projects that includes quality controls and ongoing monitoring. Data pipelines are uniquely vulnerable to changes entirely outside of your control, since it&amp;#39;s highly unlikely that you are the producer of the input data. Think carefully about how eventual changes in upstream data would affect your workload - where are the fragile points, and how you can build resiliency into them. You don&amp;#39;t have to (and realistically can&amp;#39;t) account for every scenario upfront, but you can take simple steps to catch issues before they reach the CEO&amp;#39;s dashboard.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;This is a team sport. Empathy for stakeholders and teammates, in particular assuming good intentions and that previous decisions were made for a good reason, is the #1 thing I look for in a candidate outside of reasoning skills. I have disqualified candidates for off-handed comments about colleagues &amp;quot;not knowing what they&amp;#39;re talking about&amp;quot;, or dragging previous work when talking about refactoring a pipeline. Your job as a steward for the data platform is to understand your stakeholders and build something that allows them to safely and effectively interact with it. It&amp;#39;s a unique and complex system which they likely don&amp;#39;t, and shouldn&amp;#39;t have to, have as deep an understanding of as you do. Behave accordingly. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Understand what responsible data stewardship looks like. Data is often one of, if not the most, expensive line item for a company. As a DE you are being trusted with the thing that can make or break a company&amp;#39;s success both from a cost and legal liability perspective. In my role I regularly make architecture decisions that will cost or pay someone&amp;#39;s salary - while it will probably take you a long time to get to that point, being conscientious of the financial impact/risk of your projects makes the jobs of people who do have to make those decisions (the ones who hire and promote you) much easier. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Beware hype trains and silver bullets. Again, I have disqualified candidates of all levels for falling into this trap. Every tool, language, and framework was built (at least initially) to solve a specific problem, and when you choose to use it you should understand what that problem is. You&amp;#39;re absolutely allowed to have a preferred toolbox, but over-indexing on one solution is an indicator that you don&amp;#39;t really understand the problem space or the pitfalls of that thing. I&amp;#39;ve noticed a significant uptick in this problem with the recent popularity of AI; if you&amp;#39;re going to use/advocate for it, you&amp;#39;d better be prepared to also speak to the implications and drawbacks.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Honorable mention: this may be controversial but I strongly caution against inflating your work experience in this field. Trust me, they&amp;#39;ll know. It&amp;#39;s okay and expected that you don&amp;#39;t have big data experience when you&amp;#39;re starting out - it would be ridiculous for me to expect you to know how to scale a Spark pipeline without access to an enterprise system. Just show enthusiasm for learning and use what you&amp;#39;ve got to your advantage.&lt;/p&gt;\n\n&lt;p&gt;I believe in you! You got this.&lt;/p&gt;\n\n&lt;p&gt;Edit: starter book recommendations in this thread &lt;a href=\"https://www.reddit.com/r/dataengineering/s/sDLpyObrAx\"&gt;https://www.reddit.com/r/dataengineering/s/sDLpyObrAx&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1au9s4s", "is_robot_indexable": true, "report_reasons": null, "author": "ithinkiboughtadingo", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au9s4s/new_de_advice_from_a_principal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au9s4s/new_de_advice_from_a_principal/", "subreddit_subscribers": 161993, "created_utc": 1708302646.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Source: twitter", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How true is this!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1aujhqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 250, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 250, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XNSemjSE_pbJQZzM3w6Pc_1qoBmpLCEFyFH99PGD5ms.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708335562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Source: twitter&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rs9mkuppiijc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?auto=webp&amp;s=cf849cd1680a9f30565e3a92c1d51ddd9a0a0ebd", "width": 1242, "height": 1351}, "resolutions": [{"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d8e248e20c8cc7877b203517a8d891756043a16", "width": 108, "height": 117}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b2ea26c85a4cad901d8881291635110a9add191c", "width": 216, "height": 234}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=92b8ac12c466031b63d1e2347878ee72ab3826db", "width": 320, "height": 348}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=578bd97b55a217e6e2eeb16168ec4296a78b8644", "width": 640, "height": 696}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3b5730963b7e0b4709db8d0e3bd2021f860e27d", "width": 960, "height": 1044}, {"url": "https://preview.redd.it/rs9mkuppiijc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0c1f6c144bf693d4e853dfc88fe59c840ecefb1b", "width": 1080, "height": 1174}], "variants": {}, "id": "TZHebl6IK1uzPf1uvef7vy4HGDXI9n8wnxcwqtZbtWg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1aujhqw", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aujhqw/how_true_is_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rs9mkuppiijc1.jpeg", "subreddit_subscribers": 161993, "created_utc": 1708335562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Running Doom on random things will always amuse me. (Not my article)", "author_fullname": "t2_v7fvlqc8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Doom on Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "name": "t3_1au3t2l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WgXLJTG2pa_K3qLr7Du72IiC-ZPeT9D38ayIWT88K5I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708287844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arecadata.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Running Doom on random things will always amuse me. (Not my article)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arecadata.com/running-doom-on-snowflake/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6oWjOJV-nsTH5Fl_QZNeNoB-Lhmxnk5Gmu_pPtaJhi8.jpg?auto=webp&amp;s=3da9e0b85f62d31ecbde6b96ede37513734765a4", "width": 1200, "height": 651}, "resolutions": [{"url": "https://external-preview.redd.it/6oWjOJV-nsTH5Fl_QZNeNoB-Lhmxnk5Gmu_pPtaJhi8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c99b9df6158a8dd12eacc1c55fd8f8423c5fdfc9", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/6oWjOJV-nsTH5Fl_QZNeNoB-Lhmxnk5Gmu_pPtaJhi8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fa5d13ac6e6dbb428009e135f3dc4d10feb92150", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/6oWjOJV-nsTH5Fl_QZNeNoB-Lhmxnk5Gmu_pPtaJhi8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7f1facc2d3c3978dbf5d9c075466380dc8af3939", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/6oWjOJV-nsTH5Fl_QZNeNoB-Lhmxnk5Gmu_pPtaJhi8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=81348fe59f55668bbc34505a0cfdc6653e76d21e", "width": 640, "height": 347}, {"url": "https://external-preview.redd.it/6oWjOJV-nsTH5Fl_QZNeNoB-Lhmxnk5Gmu_pPtaJhi8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f3d5ab77c5e1144c5959c9bf8f6b9afc23aa64c4", "width": 960, "height": 520}, {"url": "https://external-preview.redd.it/6oWjOJV-nsTH5Fl_QZNeNoB-Lhmxnk5Gmu_pPtaJhi8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ac60e90a6fb3be6e81a59ad1f1b2cd36cb721667", "width": 1080, "height": 585}], "variants": {}, "id": "J05-ZJ5DV3zhbmZJpbrj25Yessx-OZEatX9tI4J_iOI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1au3t2l", "is_robot_indexable": true, "report_reasons": null, "author": "on_the_mark_data", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au3t2l/running_doom_on_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arecadata.com/running-doom-on-snowflake/", "subreddit_subscribers": 161993, "created_utc": 1708287844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello there!\n\nI am currently designing a new model for our Data Warehouse (BigQuery in this case and I am leaning towards Star Schema). The structure of the problem / data for which I want to design the model for is giving me some headache though and I would love to get some opinions on it to check that I am making the best possible design.\n\nEssentially the problem is that the data consists of nested scores. Image the following structure:\n\n* Record\n   * Part A\n      * Score A\n      * Score B\n   * Part B\n      * Score C\n      * Score D\n\nIn a nutshell we have a single record that is split into different parts. Each part is then scored according to some criteria (different ones for each part). The scores are then combined to a single score for a part. Then the combined scores for each part are further combined to compute a score for the entire record. The calculation of the \"combining\" might not be a simple sum, therefore it shouldn't be computed on the fly and instead already when transforming the data.\n\nTo make matters worse the nesting could go deeper than this, for example Part C could consist of Part C1 and Part C2 with their own scores. Also the granularity of the parts might not be 1:1 - a record might have 2 or 3 Part D(s).\n\nAs a side note, each record has an ID, which I would have put into a dimension table (there is some other metadata associated with the ID). This dimension could be connected to all parts, as it might be of interest to break down only the scores of a certain part by some of the metadata associated with that ID.\n\nI know this is probably quite tricky to work with - especially with that limited information I can give you guys, sorry. Would you also choose Star Schema or something else? If yes, would you create a fact table per Part (e.g. fact\\_part\\_c1) and then a fact table for each level of combination (e.g. fact\\_part\\_c and then fact\\_record)? How would you deal with the different granularities that might exist? By pre-aggregating them to bring everything to the same granularity? Would you try to create a very large fact table, like an OBT and just work with many different columns?\n\nI know that it might be hard to answer some of this without the exact use-cases and requirements at hand but just imagine that we are actually interested in gaining a deep understanding of the different scores, therefore we might be interested to investigate and breakdown the scores only for a given part or subpart.\n\nLet me know what you would do and thank for the help in advance!", "author_fullname": "t2_1u69ldaj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Star Schema: How to best model nested data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au3l53", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708287314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there!&lt;/p&gt;\n\n&lt;p&gt;I am currently designing a new model for our Data Warehouse (BigQuery in this case and I am leaning towards Star Schema). The structure of the problem / data for which I want to design the model for is giving me some headache though and I would love to get some opinions on it to check that I am making the best possible design.&lt;/p&gt;\n\n&lt;p&gt;Essentially the problem is that the data consists of nested scores. Image the following structure:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Record\n\n&lt;ul&gt;\n&lt;li&gt;Part A\n\n&lt;ul&gt;\n&lt;li&gt;Score A&lt;/li&gt;\n&lt;li&gt;Score B&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Part B\n\n&lt;ul&gt;\n&lt;li&gt;Score C&lt;/li&gt;\n&lt;li&gt;Score D&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In a nutshell we have a single record that is split into different parts. Each part is then scored according to some criteria (different ones for each part). The scores are then combined to a single score for a part. Then the combined scores for each part are further combined to compute a score for the entire record. The calculation of the &amp;quot;combining&amp;quot; might not be a simple sum, therefore it shouldn&amp;#39;t be computed on the fly and instead already when transforming the data.&lt;/p&gt;\n\n&lt;p&gt;To make matters worse the nesting could go deeper than this, for example Part C could consist of Part C1 and Part C2 with their own scores. Also the granularity of the parts might not be 1:1 - a record might have 2 or 3 Part D(s).&lt;/p&gt;\n\n&lt;p&gt;As a side note, each record has an ID, which I would have put into a dimension table (there is some other metadata associated with the ID). This dimension could be connected to all parts, as it might be of interest to break down only the scores of a certain part by some of the metadata associated with that ID.&lt;/p&gt;\n\n&lt;p&gt;I know this is probably quite tricky to work with - especially with that limited information I can give you guys, sorry. Would you also choose Star Schema or something else? If yes, would you create a fact table per Part (e.g. fact_part_c1) and then a fact table for each level of combination (e.g. fact_part_c and then fact_record)? How would you deal with the different granularities that might exist? By pre-aggregating them to bring everything to the same granularity? Would you try to create a very large fact table, like an OBT and just work with many different columns?&lt;/p&gt;\n\n&lt;p&gt;I know that it might be hard to answer some of this without the exact use-cases and requirements at hand but just imagine that we are actually interested in gaining a deep understanding of the different scores, therefore we might be interested to investigate and breakdown the scores only for a given part or subpart.&lt;/p&gt;\n\n&lt;p&gt;Let me know what you would do and thank for the help in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1au3l53", "is_robot_indexable": true, "report_reasons": null, "author": "YannickAlex07", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au3l53/star_schema_how_to_best_model_nested_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au3l53/star_schema_how_to_best_model_nested_data/", "subreddit_subscribers": 161993, "created_utc": 1708287314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey there,  \nIv been asked by my boss to change a DAG that is currently written with python operator to kuberenets operator.\n\nI have no knowledge about Kubernetes but we have a devops team that handles all that stuff, I wanted to ask how complicated will it be for me to change that code (the code itself is really simple, only one python operator and one task, but extremely heavy task).  \nconsidering devops can help me write the dockerfile\n\n  \nand how do I actually pull this off? instead of my python operator I use kuberenets operator, or I use both, or I use image + Kubernetes and no python operator?\n\n  \nand also would like to ask, why/when one should run a Kubernetes operator and when to use normal operators.  \n\n\nthat's a lot of questions so that's it for now.  \nThanks in advance!", "author_fullname": "t2_w6u9u77n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How / When to use Kuberenets operator in airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aumchk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708346402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey there,&lt;br/&gt;\nIv been asked by my boss to change a DAG that is currently written with python operator to kuberenets operator.&lt;/p&gt;\n\n&lt;p&gt;I have no knowledge about Kubernetes but we have a devops team that handles all that stuff, I wanted to ask how complicated will it be for me to change that code (the code itself is really simple, only one python operator and one task, but extremely heavy task).&lt;br/&gt;\nconsidering devops can help me write the dockerfile&lt;/p&gt;\n\n&lt;p&gt;and how do I actually pull this off? instead of my python operator I use kuberenets operator, or I use both, or I use image + Kubernetes and no python operator?&lt;/p&gt;\n\n&lt;p&gt;and also would like to ask, why/when one should run a Kubernetes operator and when to use normal operators.  &lt;/p&gt;\n\n&lt;p&gt;that&amp;#39;s a lot of questions so that&amp;#39;s it for now.&lt;br/&gt;\nThanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aumchk", "is_robot_indexable": true, "report_reasons": null, "author": "PhilosopherRemote177", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aumchk/how_when_to_use_kuberenets_operator_in_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aumchk/how_when_to_use_kuberenets_operator_in_airflow/", "subreddit_subscribers": 161993, "created_utc": 1708346402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. What has caused you or your company to break-up with a particular data vendor (broken SLAs, better features elsewhere, price increases, change in decision makers, etc.)\n\n2. What has prompted you or your company in the past to seek new data vendors, how did options get onto your radar and what were the factors that made the biggest difference in your eventual decision (performance, price, relationship)\n\nDiscuss, would love to to hear everyone\u2019s thoughts.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vendor Break-ups and Hook-ups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aua374", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708303502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What has caused you or your company to break-up with a particular data vendor (broken SLAs, better features elsewhere, price increases, change in decision makers, etc.)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What has prompted you or your company in the past to seek new data vendors, how did options get onto your radar and what were the factors that made the biggest difference in your eventual decision (performance, price, relationship)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Discuss, would love to to hear everyone\u2019s thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aua374", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aua374/vendor_breakups_and_hookups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aua374/vendor_breakups_and_hookups/", "subreddit_subscribers": 161993, "created_utc": 1708303502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone! Can you please help me with this issue?   \n\nI'm dealing with data that is partitioned in the format of \"s3://bucket/folder1/.../folder4/year= 2024/month=2/day=18/\" and I'm trying to create a python/pyspark function to return me the latest year, month and day or the full path of the latest partition, but it's being too hard to get it to work properly.   \n\nHas anyone done this before? Can you give me any tips? I could create a function to return the latest partition when it was like \"snap=2024\\_2\\_18\" but when it has subfolders it's getting messy.   \n\nThank you so much for your help. ", "author_fullname": "t2_tnl4h5c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a Glue/Pyspark function to get latest partition from a S3 bucket", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au5lfg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708292155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! Can you please help me with this issue?   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m dealing with data that is partitioned in the format of &amp;quot;s3://bucket/folder1/.../folder4/year= 2024/month=2/day=18/&amp;quot; and I&amp;#39;m trying to create a python/pyspark function to return me the latest year, month and day or the full path of the latest partition, but it&amp;#39;s being too hard to get it to work properly.   &lt;/p&gt;\n\n&lt;p&gt;Has anyone done this before? Can you give me any tips? I could create a function to return the latest partition when it was like &amp;quot;snap=2024_2_18&amp;quot; but when it has subfolders it&amp;#39;s getting messy.   &lt;/p&gt;\n\n&lt;p&gt;Thank you so much for your help. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1au5lfg", "is_robot_indexable": true, "report_reasons": null, "author": "IWantAGoodBattery", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au5lfg/creating_a_gluepyspark_function_to_get_latest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au5lfg/creating_a_gluepyspark_function_to_get_latest/", "subreddit_subscribers": 161993, "created_utc": 1708292155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am glad to share with you my first web scraping project done on an e-commerce site. The goal was to come up with a list of products on discount for customers to select. I would appreciate any feedback or ways to make the project way better.\n\n[https://github.com/ennock/Webscraping-an-Ecommerce-site-](https://github.com/ennock/Webscraping-an-Ecommerce-site-)", "author_fullname": "t2_iiwc5106k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web Scraping an E-commerce Site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aujo8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708336339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am glad to share with you my first web scraping project done on an e-commerce site. The goal was to come up with a list of products on discount for customers to select. I would appreciate any feedback or ways to make the project way better.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ennock/Webscraping-an-Ecommerce-site-\"&gt;https://github.com/ennock/Webscraping-an-Ecommerce-site-&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?auto=webp&amp;s=10839024ca3d2c7630c8fa8c25b1f3fcdb4dbed6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e02c3ffe7c84c3f11c64713e6325c6d56c0bbd2e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a560e1c64d846cef6294d8554cfedb00977806b8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ce9e0348f652876624ae84de77fa8717bf87707", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bcc243132e475952766213ad8441b2fd653ec0dd", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=01a97466b9aad7c65f2b04bd1d6e04eeed30f890", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JdTyaPfvPKO9pRyhpOjkfIq3WfMg2-Ntkv0FC7BQvQY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0599ed2b9152d12c39b08c4bc7fed2f816cc8991", "width": 1080, "height": 540}], "variants": {}, "id": "NUwfFAkGXTYjfIDiB2qmDaeOp993mbAs0b-u5vrNV2U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1aujo8q", "is_robot_indexable": true, "report_reasons": null, "author": "xscri", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aujo8q/web_scraping_an_ecommerce_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aujo8q/web_scraping_an_ecommerce_site/", "subreddit_subscribers": 161993, "created_utc": 1708336339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have about 10 years professional experience in data related roles. Over half that time I\u2019ve been at my current company. I started as a staff and was recently promoted to manager and I don\u2019t really enjoy it but at my company the only path seems to be management. \n\nI am thinking of leaving but feel like my experience/skills are limiting me for either path. I have some management experience on paper but I am not the best at it and don\u2019t really enjoy it, although I feel like that\u2019s a path I have to take with my age and experience. \n\nI\u2019d prefer to get into a more engineering focused job but my coding/programming skills/experience are heavily limited with my current work environment. I feel like I\u2019m stuck between both and not experienced/skilled enough for either outside my current company", "author_fullname": "t2_9ac91rpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career crossroads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au9kg4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708302072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 10 years professional experience in data related roles. Over half that time I\u2019ve been at my current company. I started as a staff and was recently promoted to manager and I don\u2019t really enjoy it but at my company the only path seems to be management. &lt;/p&gt;\n\n&lt;p&gt;I am thinking of leaving but feel like my experience/skills are limiting me for either path. I have some management experience on paper but I am not the best at it and don\u2019t really enjoy it, although I feel like that\u2019s a path I have to take with my age and experience. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d prefer to get into a more engineering focused job but my coding/programming skills/experience are heavily limited with my current work environment. I feel like I\u2019m stuck between both and not experienced/skilled enough for either outside my current company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1au9kg4", "is_robot_indexable": true, "report_reasons": null, "author": "Maw-installation", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au9kg4/career_crossroads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au9kg4/career_crossroads/", "subreddit_subscribers": 161993, "created_utc": 1708302072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would anyone like to connect and talk improvements to data movement at their job? Mainly pertaining to ETL.", "author_fullname": "t2_hkywph80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data movement improvements", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aut8m6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708364283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would anyone like to connect and talk improvements to data movement at their job? Mainly pertaining to ETL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aut8m6", "is_robot_indexable": true, "report_reasons": null, "author": "mattid12", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aut8m6/data_movement_improvements/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aut8m6/data_movement_improvements/", "subreddit_subscribers": 161993, "created_utc": 1708364283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've built some data pipelines in the past and I'd love to get some feedback on what can be done to improve them. Any advice is appreciated!\n\n&amp;#x200B;\n\nSimple Side Project Pipeline:\n\nReddit -&gt; PRAW (on local machine) -&gt; SQLite DB -&gt; report software\n\n&amp;#x200B;\n\nActual Work Pipeline:\n\nVarious Sources -&gt; Custom Python on a VM -&gt; Oracle On-Prem -&gt; dbt -&gt; report software\n\n&amp;#x200B;\n\nHypothetical Pipeline if my company let me use fancy tools:\n\nVarious Sources -&gt; AWS Glue -&gt; S3 -&gt; Redshift -&gt; dbt -&gt; report software \n\nwith optional additions for things like AWS Lamda/Aurora/Athena depending on the situation\n\n&amp;#x200B;\n\nWhat kinds of things am I missing? Is there a better way to ensure security or alert for failures?", "author_fullname": "t2_1gyiwuuv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipeline Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auhtcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708328742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve built some data pipelines in the past and I&amp;#39;d love to get some feedback on what can be done to improve them. Any advice is appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Simple Side Project Pipeline:&lt;/p&gt;\n\n&lt;p&gt;Reddit -&amp;gt; PRAW (on local machine) -&amp;gt; SQLite DB -&amp;gt; report software&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Actual Work Pipeline:&lt;/p&gt;\n\n&lt;p&gt;Various Sources -&amp;gt; Custom Python on a VM -&amp;gt; Oracle On-Prem -&amp;gt; dbt -&amp;gt; report software&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hypothetical Pipeline if my company let me use fancy tools:&lt;/p&gt;\n\n&lt;p&gt;Various Sources -&amp;gt; AWS Glue -&amp;gt; S3 -&amp;gt; Redshift -&amp;gt; dbt -&amp;gt; report software &lt;/p&gt;\n\n&lt;p&gt;with optional additions for things like AWS Lamda/Aurora/Athena depending on the situation&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What kinds of things am I missing? Is there a better way to ensure security or alert for failures?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1auhtcp", "is_robot_indexable": true, "report_reasons": null, "author": "trianglesteve", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auhtcp/data_pipeline_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auhtcp/data_pipeline_feedback/", "subreddit_subscribers": 161993, "created_utc": 1708328742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Guys,\n\nI have 20 excel sheets, with an average shape of 300,000+/-80K, 120+/-10. I am trying to maintain a local data repository. I have tried the following and have not succeeded, please give me your insights.\n\nThing I did:\n\n1. Use pandas to read the xlsx and dump each workbook as a table in my local mysql db. I did the above step hoping that although the tables have slightly different columns (names are the same, but the column position is different a some tables/xlsx book have extra columns) I can union them to form a central repository. When I use `\"select &lt;column&gt; from table_1\"`, I get an error saying the column doesn't exist. I gave up trying to figure out why pandas can read the column name in a df, but not when queried from mysql\n2. Then, I tried to extract the data from mysql and load it to mongodb so the schema change does not really affect the db, meaning nulls would be filled in if the xlsx sheet doesn't have the same exact column. But mongo db connection always times out\n3. I tried to use Databricks(Azure) and the free tier won't let me do anything of this size\n\nwhat strategies do you use to load 4+ million rows?\n\n&amp;#x200B;", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for maintaining a central repository in my local machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au9jia", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708302006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys,&lt;/p&gt;\n\n&lt;p&gt;I have 20 excel sheets, with an average shape of 300,000+/-80K, 120+/-10. I am trying to maintain a local data repository. I have tried the following and have not succeeded, please give me your insights.&lt;/p&gt;\n\n&lt;p&gt;Thing I did:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use pandas to read the xlsx and dump each workbook as a table in my local mysql db. I did the above step hoping that although the tables have slightly different columns (names are the same, but the column position is different a some tables/xlsx book have extra columns) I can union them to form a central repository. When I use &lt;code&gt;&amp;quot;select &amp;lt;column&amp;gt; from table_1&amp;quot;&lt;/code&gt;, I get an error saying the column doesn&amp;#39;t exist. I gave up trying to figure out why pandas can read the column name in a df, but not when queried from mysql&lt;/li&gt;\n&lt;li&gt;Then, I tried to extract the data from mysql and load it to mongodb so the schema change does not really affect the db, meaning nulls would be filled in if the xlsx sheet doesn&amp;#39;t have the same exact column. But mongo db connection always times out&lt;/li&gt;\n&lt;li&gt;I tried to use Databricks(Azure) and the free tier won&amp;#39;t let me do anything of this size&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;what strategies do you use to load 4+ million rows?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1au9jia", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au9jia/ideas_for_maintaining_a_central_repository_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au9jia/ideas_for_maintaining_a_central_repository_in_my/", "subreddit_subscribers": 161993, "created_utc": 1708302006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am trying to implement a role based auth system to connecting to a PostgreSql DB system. I have routine functions and triggers that I created that perform select statements and such on the database. How do I create a Role that can only perform the actions in the Executable Functions, while also not having general Select functions on the table? I originally gave the role execute only permissions, but they give a permission error since the functions require a select  statement on certain tables.\n\n\nThank you!", "author_fullname": "t2_39utoy9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on Roles in PostgreSql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au3vk2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708288007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am trying to implement a role based auth system to connecting to a PostgreSql DB system. I have routine functions and triggers that I created that perform select statements and such on the database. How do I create a Role that can only perform the actions in the Executable Functions, while also not having general Select functions on the table? I originally gave the role execute only permissions, but they give a permission error since the functions require a select  statement on certain tables.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1au3vk2", "is_robot_indexable": true, "report_reasons": null, "author": "scuffed12s", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au3vk2/question_on_roles_in_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au3vk2/question_on_roles_in_postgresql/", "subreddit_subscribers": 161993, "created_utc": 1708288007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When your data sources and ETL pipelines live in AWS for examples as S3, Glue Jobs and RDS, then when you want to intagre it with a data warehouse, isn't the choice of Snowflake a bad decision cost-wise? Does it not cost extra to move data between AWS Cloud and Snowflake Cloud? Does it not make more sense to use Redshift then to avoid moving data via public internet?", "author_fullname": "t2_34tfcgtu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Isn't Snowflake expensive when your other infrastructure is on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1ausru6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708363185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When your data sources and ETL pipelines live in AWS for examples as S3, Glue Jobs and RDS, then when you want to intagre it with a data warehouse, isn&amp;#39;t the choice of Snowflake a bad decision cost-wise? Does it not cost extra to move data between AWS Cloud and Snowflake Cloud? Does it not make more sense to use Redshift then to avoid moving data via public internet?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ausru6", "is_robot_indexable": true, "report_reasons": null, "author": "rental_car_abuse", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ausru6/isnt_snowflake_expensive_when_your_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ausru6/isnt_snowflake_expensive_when_your_other/", "subreddit_subscribers": 161993, "created_utc": 1708363185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! \n\nI have a modelling question. Suposse that i have one fact that talk about contract of students and each contract has a data\\_activation and if student evade it has data\\_deactivation. Thinking  about this context, its a good approach have two fact table one for evasion and one for current students or have all in one and filter based on date columns?\n\nThanks!", "author_fullname": "t2_8jc0mwfh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Split a fact table into two differente context?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aurhd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708360202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;I have a modelling question. Suposse that i have one fact that talk about contract of students and each contract has a data_activation and if student evade it has data_deactivation. Thinking  about this context, its a good approach have two fact table one for evasion and one for current students or have all in one and filter based on date columns?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aurhd4", "is_robot_indexable": true, "report_reasons": null, "author": "Andremallmann", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aurhd4/split_a_fact_table_into_two_differente_context/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aurhd4/split_a_fact_table_into_two_differente_context/", "subreddit_subscribers": 161993, "created_utc": 1708360202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will be starting a new role soon at a company that uses Spark (PySpark) on HPC clusters. I\u2019ve never used HPC clusters before but from googling I understand you have to submit jobs to a workload manager whereas in Databricks stuff like this is usually taken care of for you?\n\nSince I\u2019m new to working with HPC I was hoping for some advice from others who have used PySpark on HPC Clusters in production and was hoping for a list of \u201cDo\u2019s and Don\u2019t\u201d along with any resources or advice that could be helpful for someone in my situation. \n\nAlso, do HPC clusters have any advantages over Databricks? \n\n\n", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking HPC Cluster advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aup1o4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708354188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will be starting a new role soon at a company that uses Spark (PySpark) on HPC clusters. I\u2019ve never used HPC clusters before but from googling I understand you have to submit jobs to a workload manager whereas in Databricks stuff like this is usually taken care of for you?&lt;/p&gt;\n\n&lt;p&gt;Since I\u2019m new to working with HPC I was hoping for some advice from others who have used PySpark on HPC Clusters in production and was hoping for a list of \u201cDo\u2019s and Don\u2019t\u201d along with any resources or advice that could be helpful for someone in my situation. &lt;/p&gt;\n\n&lt;p&gt;Also, do HPC clusters have any advantages over Databricks? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aup1o4", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aup1o4/seeking_hpc_cluster_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aup1o4/seeking_hpc_cluster_advice/", "subreddit_subscribers": 161993, "created_utc": 1708354188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm handed a project to research applications that produce automated visuals and calculations. The twist here is that there is user input and sort database from where information is stretched for calculations. This tool was originally in excel which allowed everything to be at one place. However, it got cumbersome with a lot of data. Is there any ready-made software to use or develop? Thank you", "author_fullname": "t2_7658exh7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Application for visualization and calculations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aunya1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708351222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m handed a project to research applications that produce automated visuals and calculations. The twist here is that there is user input and sort database from where information is stretched for calculations. This tool was originally in excel which allowed everything to be at one place. However, it got cumbersome with a lot of data. Is there any ready-made software to use or develop? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aunya1", "is_robot_indexable": true, "report_reasons": null, "author": "Warm-Consideration-5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aunya1/application_for_visualization_and_calculations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aunya1/application_for_visualization_and_calculations/", "subreddit_subscribers": 161993, "created_utc": 1708351222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I am trying to follow the zoomcamp and already getting stuck with the first video. \n\nI understand Linux is an OS. There are 2 ways I can install on top of window os - hypervisor or partition. \n\nI watched an hour video on Docker. I understood the concept. \n\n&amp;#x200B;\n\nNow on the implementation, what should be the step? \n\n1. like what to do install? how to install?\n2. can i use docker desktop? \n\nthanks a lot guys!!!!! \n\n&amp;#x200B;\n\nYou may be interested in Data Engineering Zoomcamp from Data Talks Club. It's free. Come joint the fun! [https://github.com/DataTalksClub/data-engineering-zoomcamp](https://github.com/DataTalksClub/data-engineering-zoomcamp) ", "author_fullname": "t2_5cph20ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data engineering zoomcamp - docker session", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au1jn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708282380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I am trying to follow the zoomcamp and already getting stuck with the first video. &lt;/p&gt;\n\n&lt;p&gt;I understand Linux is an OS. There are 2 ways I can install on top of window os - hypervisor or partition. &lt;/p&gt;\n\n&lt;p&gt;I watched an hour video on Docker. I understood the concept. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now on the implementation, what should be the step? &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;like what to do install? how to install?&lt;/li&gt;\n&lt;li&gt;can i use docker desktop? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;thanks a lot guys!!!!! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;You may be interested in Data Engineering Zoomcamp from Data Talks Club. It&amp;#39;s free. Come joint the fun! &lt;a href=\"https://github.com/DataTalksClub/data-engineering-zoomcamp\"&gt;https://github.com/DataTalksClub/data-engineering-zoomcamp&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-0d-xLZytOTjLZSYsOdot331NosZGmYKPBlnakeIDu0.jpg?auto=webp&amp;s=79a1bd4691546a6905addce5e7bab632a2b4d4ee", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/-0d-xLZytOTjLZSYsOdot331NosZGmYKPBlnakeIDu0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=31b3d0b97c00f2570130cba2df38ee7914001808", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/-0d-xLZytOTjLZSYsOdot331NosZGmYKPBlnakeIDu0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=13e31b17e0fc3c840558415cb4c16730a47f1616", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/-0d-xLZytOTjLZSYsOdot331NosZGmYKPBlnakeIDu0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fdd70651021566e5fe13602f0cd046068724bac6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/-0d-xLZytOTjLZSYsOdot331NosZGmYKPBlnakeIDu0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=06cbcf772dbeccbb5c76fda4acb1fe966b54bd9f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/-0d-xLZytOTjLZSYsOdot331NosZGmYKPBlnakeIDu0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=57b3ee46a4e6083df88794ad777785e6d0fe0247", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/-0d-xLZytOTjLZSYsOdot331NosZGmYKPBlnakeIDu0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f25cdfde8ebcce58efd5eb66b8d9ea4dcfcf5cd", "width": 1080, "height": 540}], "variants": {}, "id": "50yHaKcsYip4vdPqV45Ec0WYI6SfzcEdX0mT7H03oEA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1au1jn0", "is_robot_indexable": true, "report_reasons": null, "author": "themagnificent1906", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au1jn0/data_engineering_zoomcamp_docker_session/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au1jn0/data_engineering_zoomcamp_docker_session/", "subreddit_subscribers": 161993, "created_utc": 1708282380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If somebody got offered:\n-data engineering position\n-analytics engineering position\n-devops engineering position\n-test engineering position \n-technical consultancy position\nAll entry levels with all very similar salaries, and the person doesn't really mind any field.. what field would be best pursuing and potentially making more money in the future generally?", "author_fullname": "t2_789r8q3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1au9ov8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708302401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If somebody got offered:\n-data engineering position\n-analytics engineering position\n-devops engineering position\n-test engineering position \n-technical consultancy position\nAll entry levels with all very similar salaries, and the person doesn&amp;#39;t really mind any field.. what field would be best pursuing and potentially making more money in the future generally?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1au9ov8", "is_robot_indexable": true, "report_reasons": null, "author": "elitek7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1au9ov8/career_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1au9ov8/career_options/", "subreddit_subscribers": 161993, "created_utc": 1708302401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hpr5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Data Engineering Is Key to Digital Transformation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_1augxjt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RWgKnHy2i3TLWVmLGbxrp0GJCbbJUxtxKzUh_zB6fXc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708325363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "futurismtechnologies.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.futurismtechnologies.com/blog/why-data-engineering-is-key-to-digital-transformation/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?auto=webp&amp;s=b5775efe92170e36119900ef32bf242bafe88904", "width": 800, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf0e3923f6eaaa455b3c7cd3381d88c3195216ca", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=178437dc5fcc42d4ff0478bccce4224fd2dba5f1", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f6b9d0e5f40a57c5c6472445a55e8d83163997a", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/Ers-Jh4H37Cu4XdKhpI9UMBm5AsUTieQXIix-SPaVm8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a6cf6656af429e1e4482ad649a994e5fbb6123f", "width": 640, "height": 400}], "variants": {}, "id": "cEgIoW4lhrbCcDhR7buNZVVzhfnAsqhCk4xl-PgteEI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1augxjt", "is_robot_indexable": true, "report_reasons": null, "author": "Futurismtechnologies", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1augxjt/why_data_engineering_is_key_to_digital/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.futurismtechnologies.com/blog/why-data-engineering-is-key-to-digital-transformation/", "subreddit_subscribers": 161993, "created_utc": 1708325363.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}