{"kind": "Listing", "data": {"after": "t3_1b0i9k7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious what you guys see as the romantic market force and best platform. If you had to marry just one? Which is it and why? What does your company use? \n\nThanks. You are deciding my life and future right now. ", "author_fullname": "t2_nb0ef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Marry, F, kill\u2026 databricks, snowflake, ms fabric?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b04b8j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708908509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious what you guys see as the romantic market force and best platform. If you had to marry just one? Which is it and why? What does your company use? &lt;/p&gt;\n\n&lt;p&gt;Thanks. You are deciding my life and future right now. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b04b8j", "is_robot_indexable": true, "report_reasons": null, "author": "JamesGarrison", "discussion_type": null, "num_comments": 93, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b04b8j/marry_f_kill_databricks_snowflake_ms_fabric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b04b8j/marry_f_kill_databricks_snowflake_ms_fabric/", "subreddit_subscribers": 163835, "created_utc": 1708908509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_phodw6t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Browsing through twitter/x, I came across the following post about snowflake/dbt. Any thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0f3ie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 42, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;From 2019-2023 I ran a data analytics consulting firm, Upright Analytics.&lt;br&gt;&lt;br&gt;My firm is named &amp;quot;Upright&amp;quot; Analytics because I always want to do the right thing and be upright in a sea of IT con artists selling weird compute toys.&lt;br&gt;&lt;br&gt;My firm&amp;#39;s name is the direct result of the behaviors\u2026&lt;/p&gt;&amp;mdash; Lauren Balik (@laurenbalik) &lt;a href=\"https://twitter.com/laurenbalik/status/1761804446114230312?ref_src=twsrc%5Etfw\"&gt;February 25, 2024&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/laurenbalik/status/1761804446114230312", "author_name": "Lauren Balik", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;From 2019-2023 I ran a data analytics consulting firm, Upright Analytics.&lt;br&gt;&lt;br&gt;My firm is named &amp;quot;Upright&amp;quot; Analytics because I always want to do the right thing and be upright in a sea of IT con artists selling weird compute toys.&lt;br&gt;&lt;br&gt;My firm&amp;#39;s name is the direct result of the behaviors\u2026&lt;/p&gt;&amp;mdash; Lauren Balik (@laurenbalik) &lt;a href=\"https://twitter.com/laurenbalik/status/1761804446114230312?ref_src=twsrc%5Etfw\"&gt;February 25, 2024&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "author_url": "https://twitter.com/laurenbalik", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;From 2019-2023 I ran a data analytics consulting firm, Upright Analytics.&lt;br&gt;&lt;br&gt;My firm is named &amp;quot;Upright&amp;quot; Analytics because I always want to do the right thing and be upright in a sea of IT con artists selling weird compute toys.&lt;br&gt;&lt;br&gt;My firm&amp;#39;s name is the direct result of the behaviors\u2026&lt;/p&gt;&amp;mdash; Lauren Balik (@laurenbalik) &lt;a href=\"https://twitter.com/laurenbalik/status/1761804446114230312?ref_src=twsrc%5Etfw\"&gt;February 25, 2024&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1b0f3ie", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/t4ePAVC4aDSWBM7UxzPEeNYr2Df4ryuqLQ8VNkESUW0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708946175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/laurenbalik/status/1761804446114230312", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qR5aaBkRq9Jjjeq8GFUmUNtoWhZaw2zRaMuy2yrwIVA.jpg?auto=webp&amp;s=51d64f7e5993981c3e3ddb81418779f056ed6552", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/qR5aaBkRq9Jjjeq8GFUmUNtoWhZaw2zRaMuy2yrwIVA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b790b76f46a8c042bb78b201fe77f0516b1f5eff", "width": 108, "height": 108}], "variants": {}, "id": "-HMX-XcWOngZfxevcSvnam63aH_pyBU8nzrbIYt4aRs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b0f3ie", "is_robot_indexable": true, "report_reasons": null, "author": "SPORTSfANALYTICS", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0f3ie/browsing_through_twitterx_i_came_across_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/laurenbalik/status/1761804446114230312", "subreddit_subscribers": 163835, "created_utc": 1708946175.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/laurenbalik/status/1761804446114230312", "author_name": "Lauren Balik", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;From 2019-2023 I ran a data analytics consulting firm, Upright Analytics.&lt;br&gt;&lt;br&gt;My firm is named &amp;quot;Upright&amp;quot; Analytics because I always want to do the right thing and be upright in a sea of IT con artists selling weird compute toys.&lt;br&gt;&lt;br&gt;My firm&amp;#39;s name is the direct result of the behaviors\u2026&lt;/p&gt;&amp;mdash; Lauren Balik (@laurenbalik) &lt;a href=\"https://twitter.com/laurenbalik/status/1761804446114230312?ref_src=twsrc%5Etfw\"&gt;February 25, 2024&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "author_url": "https://twitter.com/laurenbalik", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "   \n\n\nI see that Arrow in general is gaining a lot of popularity. [Meta](https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/)and [Apple](https://thenewstack.io/apple-comet-brings-fast-vector-processing-to-apache-spark/), are building data infrastructure that strongly depended on it.\n\nI am also embracing it as a fundamental piece in our infra.  \nHowever, I see that, at least for Pyarrow, there is a deficit of blogs/tutorials that explain fundamental topics or best practices on how to benefit from it.   \n[I read a book, by Matthew Topol,](https://www.amazon.com/Memory-Analytics-Apache-Arrow-hierarchical/dp/1801071039) that was really informative but still there are many issues that I wish to better understand.\n\n1. What is the difference between pa.Table and RecordBatch and when we should prefer one over another?\n2. How parallelism works in general but especially for pa.compute? Does it assign a core per ChunkedArray? What if I concat many tables and each ChunkedArray is in a different physical location, does it still work with the same strategy? \n3. Pyarrow native Filesystem vs  \u201cthe Python ecosystem Filesystems\u201d. I see in the documents there is a way to work with both, but what is the real difference?  Is there a real drawback to using the Python one? \n\nFor all those issues,  I was able to find some info but not in the level that I expected before integrating it in the production system.   \n\nI wonder why this is and if someone can point me to good resources about those topics?\n\nThanks,  \nLeon", "author_fullname": "t2_ll7atfr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyarrow is popular but lacking of tutorials and resources.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azwb09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708888856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see that Arrow in general is gaining a lot of popularity. &lt;a href=\"https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/\"&gt;Meta&lt;/a&gt;and &lt;a href=\"https://thenewstack.io/apple-comet-brings-fast-vector-processing-to-apache-spark/\"&gt;Apple&lt;/a&gt;, are building data infrastructure that strongly depended on it.&lt;/p&gt;\n\n&lt;p&gt;I am also embracing it as a fundamental piece in our infra.&lt;br/&gt;\nHowever, I see that, at least for Pyarrow, there is a deficit of blogs/tutorials that explain fundamental topics or best practices on how to benefit from it.&lt;br/&gt;\n&lt;a href=\"https://www.amazon.com/Memory-Analytics-Apache-Arrow-hierarchical/dp/1801071039\"&gt;I read a book, by Matthew Topol,&lt;/a&gt; that was really informative but still there are many issues that I wish to better understand.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What is the difference between pa.Table and RecordBatch and when we should prefer one over another?&lt;/li&gt;\n&lt;li&gt;How parallelism works in general but especially for pa.compute? Does it assign a core per ChunkedArray? What if I concat many tables and each ChunkedArray is in a different physical location, does it still work with the same strategy? &lt;/li&gt;\n&lt;li&gt;Pyarrow native Filesystem vs  \u201cthe Python ecosystem Filesystems\u201d. I see in the documents there is a way to work with both, but what is the real difference?  Is there a real drawback to using the Python one? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For all those issues,  I was able to find some info but not in the level that I expected before integrating it in the production system.   &lt;/p&gt;\n\n&lt;p&gt;I wonder why this is and if someone can point me to good resources about those topics?&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;br/&gt;\nLeon&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?auto=webp&amp;s=44ab0f03ed7f603f8782bbd188e996ad17c77502", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f2085f904a50b3e53975fb7137bec4c25983982", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=000e9a1509c279a23bdac011f0bf3f50b1c25c63", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6088d7b42f1a420908f02ebe9522e78a3693e0ab", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d9bd16fdee41d441ec79d3960e425fb811b5739", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c44265f6811ff5c6dc68d26c531095ca8808679f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=907539619f060dd8a859ef77e81ef965224a45a7", "width": 1080, "height": 607}], "variants": {}, "id": "rKGSSC8ZiCD9gbOKh05G5ntySpFbt_LVVJ1vd4XJm9o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azwb09", "is_robot_indexable": true, "report_reasons": null, "author": "Leon_Bam", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azwb09/pyarrow_is_popular_but_lacking_of_tutorials_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azwb09/pyarrow_is_popular_but_lacking_of_tutorials_and/", "subreddit_subscribers": 163835, "created_utc": 1708888856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, UK based here. I'm transitioning from a data analyst role to a junior data engineer. I've been offered a job that uses the Google stack (GCP, BigQuery etc). From what I can tell, Google is the least common of the three big cloud providers with AWS being the most popular. As I am a junior, do you think it is worth holding out for an AWS based role or is it relatively easy to transition between the three?\nThanks", "author_fullname": "t2_ro8dcljg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google stack worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0e99f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708942918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, UK based here. I&amp;#39;m transitioning from a data analyst role to a junior data engineer. I&amp;#39;ve been offered a job that uses the Google stack (GCP, BigQuery etc). From what I can tell, Google is the least common of the three big cloud providers with AWS being the most popular. As I am a junior, do you think it is worth holding out for an AWS based role or is it relatively easy to transition between the three?\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b0e99f", "is_robot_indexable": true, "report_reasons": null, "author": "mybigolthrowaway1234", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0e99f/google_stack_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0e99f/google_stack_worth_it/", "subreddit_subscribers": 163835, "created_utc": 1708942918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm about to start my very first Dbt project and I'd like to do things as best as possible. \n\nDo you guys have an example of a Dbt project that you consider \"clean\" and coded according to the best practices? Could be a blog post, or a Udemy course, or anything as long as it's detailed.\n\nThe project I'm looking to build will be very standard: integration of raw data, with DQ, historization of dimension attributes (SCD2), incremental load on some fact tables, some external Excel files to be ingested, and finally some denormaliezed datasets that will be connected to Tableau.\n\nDo you have anything I could look up to in order to avoid the common pitfalls of Dbt ?\n\nThank you !!\n\n\n\n\n", "author_fullname": "t2_rz2xn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a Dbt Best Practice Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b01klb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708901431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to start my very first Dbt project and I&amp;#39;d like to do things as best as possible. &lt;/p&gt;\n\n&lt;p&gt;Do you guys have an example of a Dbt project that you consider &amp;quot;clean&amp;quot; and coded according to the best practices? Could be a blog post, or a Udemy course, or anything as long as it&amp;#39;s detailed.&lt;/p&gt;\n\n&lt;p&gt;The project I&amp;#39;m looking to build will be very standard: integration of raw data, with DQ, historization of dimension attributes (SCD2), incremental load on some fact tables, some external Excel files to be ingested, and finally some denormaliezed datasets that will be connected to Tableau.&lt;/p&gt;\n\n&lt;p&gt;Do you have anything I could look up to in order to avoid the common pitfalls of Dbt ?&lt;/p&gt;\n\n&lt;p&gt;Thank you !!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b01klb", "is_robot_indexable": true, "report_reasons": null, "author": "Ownards", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b01klb/looking_for_a_dbt_best_practice_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b01klb/looking_for_a_dbt_best_practice_project/", "subreddit_subscribers": 163835, "created_utc": 1708901431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have problem which I don't really know how to solve properly. I have a table with billions of rows in ClickHouse (will go up to tens of billions). I want to create various analytical charts about subsets of this data (those charts can be updated once a day). Unfortunately those charts are quite complex and most of them need some window functions / cross joins to work properly. For some bigger subsets queries can take more than 1 minute, which is unacceptable (I expect them to work in seconds). Pre-generating  reports for all subsets of data with such queries would probably take a day which is terrible.\n\nI tried solving it with ClickHouse materialized view - I created a view that gives me enough info so that I can easily create all charts in seconds. But it's terrible to manage: it has hundreds of billions of rows, takes up terabytes of storage and takes days to create. I want to get rid of it.\n\nI'm thinking about other solution: next thing I want to try is to just stop writing ClickHouse queries and process my data in RAM. So I would export my whole table (or just changes of it) every day, load it into Python and process it there, maybe using Polars? Or Spark? (although I should be able to fit data in RAM - it would be like 100gb uncompressed) I feel like I would be able to write some simple iteration over my data that would achieve effects of 100 lines of SQL and it would take seconds instead of minutes. I would generate reports for all subsets of data I need and just export it to ClickHouse for access.\n\nSo basically my question is how would you solve such a problem? And if this loading-and-processing data in Python every day is a good idea.  (FYI I'm NOT experienced in Python/Spark etc. so my question might seem silly. But SQL just seems not enough)\n\nEdit: I just wanted to mention that the biggest issue I have with creating queries for this table is that in order to calculate some state for (Category1, Category2, Day) I might need to find entry before Day with (Category1, Category2) if it doesnt exist for given day. My materialized view solved it by just snapshotting full state for each day but it was huge.", "author_fullname": "t2_j3zjmd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Patterns for processing lots of data with window functions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b005l7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708932572.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708898069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have problem which I don&amp;#39;t really know how to solve properly. I have a table with billions of rows in ClickHouse (will go up to tens of billions). I want to create various analytical charts about subsets of this data (those charts can be updated once a day). Unfortunately those charts are quite complex and most of them need some window functions / cross joins to work properly. For some bigger subsets queries can take more than 1 minute, which is unacceptable (I expect them to work in seconds). Pre-generating  reports for all subsets of data with such queries would probably take a day which is terrible.&lt;/p&gt;\n\n&lt;p&gt;I tried solving it with ClickHouse materialized view - I created a view that gives me enough info so that I can easily create all charts in seconds. But it&amp;#39;s terrible to manage: it has hundreds of billions of rows, takes up terabytes of storage and takes days to create. I want to get rid of it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about other solution: next thing I want to try is to just stop writing ClickHouse queries and process my data in RAM. So I would export my whole table (or just changes of it) every day, load it into Python and process it there, maybe using Polars? Or Spark? (although I should be able to fit data in RAM - it would be like 100gb uncompressed) I feel like I would be able to write some simple iteration over my data that would achieve effects of 100 lines of SQL and it would take seconds instead of minutes. I would generate reports for all subsets of data I need and just export it to ClickHouse for access.&lt;/p&gt;\n\n&lt;p&gt;So basically my question is how would you solve such a problem? And if this loading-and-processing data in Python every day is a good idea.  (FYI I&amp;#39;m NOT experienced in Python/Spark etc. so my question might seem silly. But SQL just seems not enough)&lt;/p&gt;\n\n&lt;p&gt;Edit: I just wanted to mention that the biggest issue I have with creating queries for this table is that in order to calculate some state for (Category1, Category2, Day) I might need to find entry before Day with (Category1, Category2) if it doesnt exist for given day. My materialized view solved it by just snapshotting full state for each day but it was huge.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b005l7", "is_robot_indexable": true, "report_reasons": null, "author": "rottensunday", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b005l7/patterns_for_processing_lots_of_data_with_window/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b005l7/patterns_for_processing_lots_of_data_with_window/", "subreddit_subscribers": 163835, "created_utc": 1708898069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nURL: https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\n\nI'm excited to share my latest blog post where I delve into the fascinating world of Parquet metadata and its role in optimizing data storage and retrieval. If you're working with big data or interested in efficient data storage techniques, this post is for you!\nIn this blog post, I explore:\n- Deciphering Data Serialization: Unpacking the various types of data serialization, their respective benefits, and how Parquet utilizes them. \n- Understanding Parquet Metadata: I break down what Parquet metadata is, why it's important, and how it contributes to the efficiency of data storage.\n- Metadata Structure: Dive into the nuts and bolts of Parquet metadata structure, including file metadata, row group metadata, and column metadata.\n\nWhether you're a data engineer, data scientist, or just someone curious about how data is stored and managed efficiently, this blog post has something for you.\n\nCheck out the full post [here](https://rr43.net/posts/2024/2/parquet-metadata-dataserde/) and let me know your thoughts in the comments. I'm also open to questions and discussions about Parquet metadata or any related topics!\nHappy reading and happy data exploring! \ud83d\ude80", "author_fullname": "t2_dbozei2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Parquet Metadata: A Deep Dive into Efficient Data Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azy2nt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708893104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;URL: &lt;a href=\"https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\"&gt;https://rr43.net/posts/2024/2/parquet-metadata-dataserde/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to share my latest blog post where I delve into the fascinating world of Parquet metadata and its role in optimizing data storage and retrieval. If you&amp;#39;re working with big data or interested in efficient data storage techniques, this post is for you!\nIn this blog post, I explore:\n- Deciphering Data Serialization: Unpacking the various types of data serialization, their respective benefits, and how Parquet utilizes them. \n- Understanding Parquet Metadata: I break down what Parquet metadata is, why it&amp;#39;s important, and how it contributes to the efficiency of data storage.\n- Metadata Structure: Dive into the nuts and bolts of Parquet metadata structure, including file metadata, row group metadata, and column metadata.&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re a data engineer, data scientist, or just someone curious about how data is stored and managed efficiently, this blog post has something for you.&lt;/p&gt;\n\n&lt;p&gt;Check out the full post &lt;a href=\"https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\"&gt;here&lt;/a&gt; and let me know your thoughts in the comments. I&amp;#39;m also open to questions and discussions about Parquet metadata or any related topics!\nHappy reading and happy data exploring! \ud83d\ude80&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1azy2nt", "is_robot_indexable": true, "report_reasons": null, "author": "InstitutionalizedSon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azy2nt/exploring_parquet_metadata_a_deep_dive_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azy2nt/exploring_parquet_metadata_a_deep_dive_into/", "subreddit_subscribers": 163835, "created_utc": 1708893104.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the general feedback of AWS Glue, Amazon Redshift and Amazon Data Zone?    \n\n\nHave you used it? If yes, what do you like and what do you not like?\n\n&amp;#x200B;\n\n  \n", "author_fullname": "t2_ineht0nke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "General feedback of AWS Glue / Amazon Redshift / Amazon Data Zone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0cnzw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708936301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the general feedback of AWS Glue, Amazon Redshift and Amazon Data Zone?    &lt;/p&gt;\n\n&lt;p&gt;Have you used it? If yes, what do you like and what do you not like?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b0cnzw", "is_robot_indexable": true, "report_reasons": null, "author": "DirectionPrize3281", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0cnzw/general_feedback_of_aws_glue_amazon_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0cnzw/general_feedback_of_aws_glue_amazon_redshift/", "subreddit_subscribers": 163835, "created_utc": 1708936301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8vv7mvb57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When marketing needs your help (heard through Hightouch)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0lgyz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/z6JK0URsKazrZJg_1gchcdXyEKI2mLBxUtYAHvvFXgc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708964375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dnivh4m3gykc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dnivh4m3gykc1.jpeg?auto=webp&amp;s=5a0f919391c9cf55fccee5f9470f236e70ed34e9", "width": 500, "height": 558}, "resolutions": [{"url": "https://preview.redd.it/dnivh4m3gykc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a5d662aee614780ed8cdff0d32f83f7b693a78a3", "width": 108, "height": 120}, {"url": "https://preview.redd.it/dnivh4m3gykc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8bd1af3f1d325c442bee2d285ca13fdb1418076", "width": 216, "height": 241}, {"url": "https://preview.redd.it/dnivh4m3gykc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb4c6fc9c2668ccb4c4d43afc1c045d76c772f7f", "width": 320, "height": 357}], "variants": {}, "id": "-Bx4u7D20iRyvf7K1LxxOqyjpLczguKZv4s96kNoWWo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1b0lgyz", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Cartographer4232", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0lgyz/when_marketing_needs_your_help_heard_through/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dnivh4m3gykc1.jpeg", "subreddit_subscribers": 163835, "created_utc": 1708964375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve landed a junior role which has its focus on visualization (pbi). Any tips on how to make the most of it?", "author_fullname": "t2_65m8bm7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get the most of a junior data engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azyg1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708893997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve landed a junior role which has its focus on visualization (pbi). Any tips on how to make the most of it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azyg1q", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic-Video-1595", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azyg1q/how_to_get_the_most_of_a_junior_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azyg1q/how_to_get_the_most_of_a_junior_data_engineering/", "subreddit_subscribers": 163835, "created_utc": 1708893997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n**Introduction**\n\nAs a developer with a passion for music and open-source technologies, I recently created EventMusic Producer, a Dockerized application that reads data and outputs it to a Kafka topic, using Avro schemas for data serialization. This application seamlessly integrates with Kafka and Schema Registry to manage the flow of event data related to music event information.\n\n**Key Features**\n\nEventMusic Producer offers a comprehensive set of features for efficiently managing music event data:\n\n* **Kafka Integration**: Sends event data to Kafka topics for real-time processing and analysis.\n* **Avro Serialization**: Utilizes Avro schemas to serialize event data, ensuring efficiency and data validation.\n* **Docker Support**: Fully Dockerized for easy deployment and scaling in any environment.\n* **Batch Processing**: Sends event data in batches to optimize network usage and processing times.\n* **Flexible Configuration**: Easily configurable using environment variables for Kafka, Schema Registry, and other settings.\n\n**Event Types**\n\nEventMusic Producer supports three types of events:\n\n* **Page View Events**: Generated when users browse a music-related website.\n\n{  \n \"ts\": 151302389,  \n \"sessionId\": \"4301\",  \n \"page\": \"/my-music\",  \n \"auth\": \"Logged Out\",  \n \"method\": \"GET\",  \n \"status\": \"500\",  \n \"level\": \"paid\",  \n \"itemInSession\": \"40\",  \n \"city\": {  \n \"string\": \"Valentin\"  \n },  \n \"zip\": {  \n \"string\": \"11136\"  \n },  \n \"state\": {  \n \"string\": \"\"  \n },  \n \"userAgent\": \"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10\\_7\\_9 rv:6.0; bn-IN) AppleWebKit/533.8.5 (KHTML, like Gecko) Version/4.0.2 Safari/533.8.5\",  \n \"lon\": \"-30.419926\",  \n \"lat\": \"-11.5486195\",  \n \"userId\": \"57982\",  \n \"lastName\": \"Watson\",  \n \"firstName\": \"Courtney\",  \n \"gender\": \"M\",  \n \"registration\": \"337305197\",  \n \"artist\": \"David Bowie\",  \n \"song\": \"Let\u2019s Dance\",  \n \"duration\": \"224.5126215638037\"  \n}\n\n* **Listen Events**: Generated when users listen to songs or albums.\n\nlisten\\_events: {  \n \"artist\": \"The Rolling Stones\",  \n \"song\": \"(I Can\u2019t Get No) Satisfaction\",  \n \"duration\": \"473.79469057974416\",  \n \"ts\": 6678921,  \n \"sessionid\": \"8202\",  \n \"auth\": \"Logged Out\",  \n \"level\": \"free\",  \n \"itemInSession\": \"18\",  \n \"city\": \"New Sandrachester\",  \n \"zip\": \"22955\",  \n \"state\": \"MS\",  \n \"country\": \"US\",  \n \"userAgent\": \"Mozilla/5.0 (iPod; U; CPU iPhone OS 3\\_3 like Mac OS X; hi-IN) AppleWebKit/535.47.6 (KHTML, like Gecko) Version/3.0.5 Mobile/8B118 Safari/6535.47.6\",  \n \"lon\": \"-99.431258\",  \n \"lat\": \"75.0709225\",  \n \"userId\": \"78902\",  \n \"lastName\": \"Williams\",  \n \"firstName\": \"Matthew\",  \n \"gender\": \"M\",  \n \"registration\": \"1584877204\"  \n}\n\n* **Authentication Events**: Generated when users log in or out of a music-related service.\n\nauth\\_events: {  \n \"ts\": 380291172,  \n \"sessionId\": \"6616\",  \n \"level\": \"paid\",  \n \"itemInSession\": \"79\",  \n \"city\": {  \n \"string\": \"West Coletown\"  \n },  \n \"zip\": {  \n \"string\": \"03297\"  \n },  \n \"state\": {  \n \"string\": \"MI\"  \n },  \n \"userAgent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10\\_6\\_5) AppleWebKit/533.1 (KHTML, like Gecko) Chrome/35.0.812.0 Safari/533.1\",  \n \"lon\": \"-95.78613\",  \n \"lat\": \"57.1778745\",  \n \"userId\": \"91224\",  \n \"lastName\": \"Thomas\",  \n \"firstName\": \"Greg\",  \n \"gender\": \"M\",  \n \"registration\": \"341396702\",  \n \"success\": \"False\"  \n}\n\n**Benefits**\n\nEventMusic Producer provides numerous benefits for managing music event data:\n\n* **Easy Deployment and Scaling**: Docker support enables quick deployment and seamless scaling.\n* **Performance Optimization**: Batch processing optimizes network usage and reduces processing times.\n* **Efficient Data Validation**: Avro serialization ensures the integrity and validity of event data.\n* **Flexibility and Customization**: Flexible configuration allows the application to be tailored to specific needs.\n\n**Conclusion**\n\nEventMusic Producer is a valuable tool for developers, data analysts, and music enthusiasts looking to manage and analyze music event data. Its seamless integration with Kafka, efficient Avro serialization, and flexible features make it an ideal solution for real-time applications and data analytics.\n\n**Links**\n\n* Source Code: [https://github.com/Stefen-Taime/eventmusic](https://github.com/Stefen-Taime/eventmusic)\n* Docker Hub Project URL: [https://hub.docker.com/r/stefen2020/eventmusic](https://hub.docker.com/r/stefen2020/eventmusic)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EventMusic Producer: An Open-Source Application for Managing Music Event Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b09m4g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708924644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As a developer with a passion for music and open-source technologies, I recently created EventMusic Producer, a Dockerized application that reads data and outputs it to a Kafka topic, using Avro schemas for data serialization. This application seamlessly integrates with Kafka and Schema Registry to manage the flow of event data related to music event information.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Key Features&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;EventMusic Producer offers a comprehensive set of features for efficiently managing music event data:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Kafka Integration&lt;/strong&gt;: Sends event data to Kafka topics for real-time processing and analysis.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Avro Serialization&lt;/strong&gt;: Utilizes Avro schemas to serialize event data, ensuring efficiency and data validation.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Docker Support&lt;/strong&gt;: Fully Dockerized for easy deployment and scaling in any environment.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Batch Processing&lt;/strong&gt;: Sends event data in batches to optimize network usage and processing times.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Flexible Configuration&lt;/strong&gt;: Easily configurable using environment variables for Kafka, Schema Registry, and other settings.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Event Types&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;EventMusic Producer supports three types of events:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Page View Events&lt;/strong&gt;: Generated when users browse a music-related website.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;{&lt;br/&gt;\n &amp;quot;ts&amp;quot;: 151302389,&lt;br/&gt;\n &amp;quot;sessionId&amp;quot;: &amp;quot;4301&amp;quot;,&lt;br/&gt;\n &amp;quot;page&amp;quot;: &amp;quot;/my-music&amp;quot;,&lt;br/&gt;\n &amp;quot;auth&amp;quot;: &amp;quot;Logged Out&amp;quot;,&lt;br/&gt;\n &amp;quot;method&amp;quot;: &amp;quot;GET&amp;quot;,&lt;br/&gt;\n &amp;quot;status&amp;quot;: &amp;quot;500&amp;quot;,&lt;br/&gt;\n &amp;quot;level&amp;quot;: &amp;quot;paid&amp;quot;,&lt;br/&gt;\n &amp;quot;itemInSession&amp;quot;: &amp;quot;40&amp;quot;,&lt;br/&gt;\n &amp;quot;city&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;Valentin&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;zip&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;11136&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;state&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;userAgent&amp;quot;: &amp;quot;Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_7_9 rv:6.0; bn-IN) AppleWebKit/533.8.5 (KHTML, like Gecko) Version/4.0.2 Safari/533.8.5&amp;quot;,&lt;br/&gt;\n &amp;quot;lon&amp;quot;: &amp;quot;-30.419926&amp;quot;,&lt;br/&gt;\n &amp;quot;lat&amp;quot;: &amp;quot;-11.5486195&amp;quot;,&lt;br/&gt;\n &amp;quot;userId&amp;quot;: &amp;quot;57982&amp;quot;,&lt;br/&gt;\n &amp;quot;lastName&amp;quot;: &amp;quot;Watson&amp;quot;,&lt;br/&gt;\n &amp;quot;firstName&amp;quot;: &amp;quot;Courtney&amp;quot;,&lt;br/&gt;\n &amp;quot;gender&amp;quot;: &amp;quot;M&amp;quot;,&lt;br/&gt;\n &amp;quot;registration&amp;quot;: &amp;quot;337305197&amp;quot;,&lt;br/&gt;\n &amp;quot;artist&amp;quot;: &amp;quot;David Bowie&amp;quot;,&lt;br/&gt;\n &amp;quot;song&amp;quot;: &amp;quot;Let\u2019s Dance&amp;quot;,&lt;br/&gt;\n &amp;quot;duration&amp;quot;: &amp;quot;224.5126215638037&amp;quot;&lt;br/&gt;\n}&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Listen Events&lt;/strong&gt;: Generated when users listen to songs or albums.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;listen_events: {&lt;br/&gt;\n &amp;quot;artist&amp;quot;: &amp;quot;The Rolling Stones&amp;quot;,&lt;br/&gt;\n &amp;quot;song&amp;quot;: &amp;quot;(I Can\u2019t Get No) Satisfaction&amp;quot;,&lt;br/&gt;\n &amp;quot;duration&amp;quot;: &amp;quot;473.79469057974416&amp;quot;,&lt;br/&gt;\n &amp;quot;ts&amp;quot;: 6678921,&lt;br/&gt;\n &amp;quot;sessionid&amp;quot;: &amp;quot;8202&amp;quot;,&lt;br/&gt;\n &amp;quot;auth&amp;quot;: &amp;quot;Logged Out&amp;quot;,&lt;br/&gt;\n &amp;quot;level&amp;quot;: &amp;quot;free&amp;quot;,&lt;br/&gt;\n &amp;quot;itemInSession&amp;quot;: &amp;quot;18&amp;quot;,&lt;br/&gt;\n &amp;quot;city&amp;quot;: &amp;quot;New Sandrachester&amp;quot;,&lt;br/&gt;\n &amp;quot;zip&amp;quot;: &amp;quot;22955&amp;quot;,&lt;br/&gt;\n &amp;quot;state&amp;quot;: &amp;quot;MS&amp;quot;,&lt;br/&gt;\n &amp;quot;country&amp;quot;: &amp;quot;US&amp;quot;,&lt;br/&gt;\n &amp;quot;userAgent&amp;quot;: &amp;quot;Mozilla/5.0 (iPod; U; CPU iPhone OS 3_3 like Mac OS X; hi-IN) AppleWebKit/535.47.6 (KHTML, like Gecko) Version/3.0.5 Mobile/8B118 Safari/6535.47.6&amp;quot;,&lt;br/&gt;\n &amp;quot;lon&amp;quot;: &amp;quot;-99.431258&amp;quot;,&lt;br/&gt;\n &amp;quot;lat&amp;quot;: &amp;quot;75.0709225&amp;quot;,&lt;br/&gt;\n &amp;quot;userId&amp;quot;: &amp;quot;78902&amp;quot;,&lt;br/&gt;\n &amp;quot;lastName&amp;quot;: &amp;quot;Williams&amp;quot;,&lt;br/&gt;\n &amp;quot;firstName&amp;quot;: &amp;quot;Matthew&amp;quot;,&lt;br/&gt;\n &amp;quot;gender&amp;quot;: &amp;quot;M&amp;quot;,&lt;br/&gt;\n &amp;quot;registration&amp;quot;: &amp;quot;1584877204&amp;quot;&lt;br/&gt;\n}&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Authentication Events&lt;/strong&gt;: Generated when users log in or out of a music-related service.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;auth_events: {&lt;br/&gt;\n &amp;quot;ts&amp;quot;: 380291172,&lt;br/&gt;\n &amp;quot;sessionId&amp;quot;: &amp;quot;6616&amp;quot;,&lt;br/&gt;\n &amp;quot;level&amp;quot;: &amp;quot;paid&amp;quot;,&lt;br/&gt;\n &amp;quot;itemInSession&amp;quot;: &amp;quot;79&amp;quot;,&lt;br/&gt;\n &amp;quot;city&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;West Coletown&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;zip&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;03297&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;state&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;MI&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;userAgent&amp;quot;: &amp;quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_5) AppleWebKit/533.1 (KHTML, like Gecko) Chrome/35.0.812.0 Safari/533.1&amp;quot;,&lt;br/&gt;\n &amp;quot;lon&amp;quot;: &amp;quot;-95.78613&amp;quot;,&lt;br/&gt;\n &amp;quot;lat&amp;quot;: &amp;quot;57.1778745&amp;quot;,&lt;br/&gt;\n &amp;quot;userId&amp;quot;: &amp;quot;91224&amp;quot;,&lt;br/&gt;\n &amp;quot;lastName&amp;quot;: &amp;quot;Thomas&amp;quot;,&lt;br/&gt;\n &amp;quot;firstName&amp;quot;: &amp;quot;Greg&amp;quot;,&lt;br/&gt;\n &amp;quot;gender&amp;quot;: &amp;quot;M&amp;quot;,&lt;br/&gt;\n &amp;quot;registration&amp;quot;: &amp;quot;341396702&amp;quot;,&lt;br/&gt;\n &amp;quot;success&amp;quot;: &amp;quot;False&amp;quot;&lt;br/&gt;\n}&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Benefits&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;EventMusic Producer provides numerous benefits for managing music event data:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Easy Deployment and Scaling&lt;/strong&gt;: Docker support enables quick deployment and seamless scaling.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Performance Optimization&lt;/strong&gt;: Batch processing optimizes network usage and reduces processing times.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Efficient Data Validation&lt;/strong&gt;: Avro serialization ensures the integrity and validity of event data.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Flexibility and Customization&lt;/strong&gt;: Flexible configuration allows the application to be tailored to specific needs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;EventMusic Producer is a valuable tool for developers, data analysts, and music enthusiasts looking to manage and analyze music event data. Its seamless integration with Kafka, efficient Avro serialization, and flexible features make it an ideal solution for real-time applications and data analytics.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Source Code: &lt;a href=\"https://github.com/Stefen-Taime/eventmusic\"&gt;https://github.com/Stefen-Taime/eventmusic&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Docker Hub Project URL: &lt;a href=\"https://hub.docker.com/r/stefen2020/eventmusic\"&gt;https://hub.docker.com/r/stefen2020/eventmusic&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?auto=webp&amp;s=6ea41bbdb354b573a166bc6d38f2539259bb18f8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ffe54081a924754cf01bfb4a1ea623c0fdef551", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9b9e4e35db8930ef0ef27407a7d06aeb0ef32b4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=abe5294e0289bd8d9194da3a7d9b9540c85a6ea1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a759996a5ee8513cf72c32f3955bb7a6bf2e987e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d688168a4212cdb91be81f9805ccf457258ce95d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e281991bee112258ea88fe5b1541a58234eea85a", "width": 1080, "height": 540}], "variants": {}, "id": "9OtvRzUFOuuWyX-6JGGTFrr2d7OU05-Ngkc80mkeQ7k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1b09m4g", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b09m4g/eventmusic_producer_an_opensource_application_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b09m4g/eventmusic_producer_an_opensource_application_for/", "subreddit_subscribers": 163835, "created_utc": 1708924644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer, and while I know the basics of data modeling, I feel like I should learn more. Do you know of any platforms, books, or study materials that teach data modeling in-depth? If you can share, it would be a great help for everyone \n", "author_fullname": "t2_84ztczxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to Dive Deeper into Data Modeling. Recommendations for In-Depth Learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_1b0o4bb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/t6bucAzFX9Qv_76pKS6_eTpWtudZ6I3_jAXjfmSeHoQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708970629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer, and while I know the basics of data modeling, I feel like I should learn more. Do you know of any platforms, books, or study materials that teach data modeling in-depth? If you can share, it would be a great help for everyone &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1q4grlv2zykc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1q4grlv2zykc1.jpeg?auto=webp&amp;s=ad493fc45be45cf6330afbc6a218203f0a401e8c", "width": 700, "height": 394}, "resolutions": [{"url": "https://preview.redd.it/1q4grlv2zykc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b02fb77805dc60307c2937b0bbef70bdc98d7d1", "width": 108, "height": 60}, {"url": "https://preview.redd.it/1q4grlv2zykc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a57ee70754f3c7aa563aaeebbc32f7297678a46", "width": 216, "height": 121}, {"url": "https://preview.redd.it/1q4grlv2zykc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c58659241bb8f3c8658c432e2e84698657b98a1", "width": 320, "height": 180}, {"url": "https://preview.redd.it/1q4grlv2zykc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=050eb410f54f8b7a8ea8a4b1799151bf0c72aafe", "width": 640, "height": 360}], "variants": {}, "id": "iwWyl6t2YUzpOC_MCfgLg7f7JQrgL8tB9oFp9H92Rnk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b0o4bb", "is_robot_indexable": true, "report_reasons": null, "author": "chaachans", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0o4bb/looking_to_dive_deeper_into_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1q4grlv2zykc1.jpeg", "subreddit_subscribers": 163835, "created_utc": 1708970629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ll be transitioning positions from financial reporting where speed to market is more important than efficiency to IoT devices where efficiency is more important than speed to market. Some data sets range into the billions to tens of billions of records.\n\nThe stack consists of Azure and Snowflake, with source code handling API calls. I\u2019ve been reading up a bit on utilizing Go/Rust to handle the extract and load through continuous Functions for real time streaming and then DBT through a Logic App with functions as the runtime per DBT node (think tests and models).\n\nCurious to hear if other folks have advice for things to consider when working with IoT, larger data sets, and Azure (my experience is in AWS so it\u2019s a minor pivot).", "author_fullname": "t2_708ooj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Finance to IoT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0m2b3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708965814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll be transitioning positions from financial reporting where speed to market is more important than efficiency to IoT devices where efficiency is more important than speed to market. Some data sets range into the billions to tens of billions of records.&lt;/p&gt;\n\n&lt;p&gt;The stack consists of Azure and Snowflake, with source code handling API calls. I\u2019ve been reading up a bit on utilizing Go/Rust to handle the extract and load through continuous Functions for real time streaming and then DBT through a Logic App with functions as the runtime per DBT node (think tests and models).&lt;/p&gt;\n\n&lt;p&gt;Curious to hear if other folks have advice for things to consider when working with IoT, larger data sets, and Azure (my experience is in AWS so it\u2019s a minor pivot).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b0m2b3", "is_robot_indexable": true, "report_reasons": null, "author": "ExistentialFajitas", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1b0m2b3/from_finance_to_iot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0m2b3/from_finance_to_iot/", "subreddit_subscribers": 163835, "created_utc": 1708965814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We extract data using Talend from multiple tables in Oracle DB, Salesforce and load it in Redshift. There is no transformation in the process. Just extract and load. We perform the transformations once it is in redshift. We want to replace talend with another tool/technology and would like to know suggestions for this. I wish to not use low code tools for this because I believe it might hamper my learning/career. Which technology should I use if I want to the tick off the three things below :\n1. Well suited and less complex \n2. Good learning and skill development by getting exposed to state of the art DE/SWE tool/tech\n3. I want to have an option of moving to SWE so I want to use this opportunity for learning SWE skills which will help me market myself as an SWE once I am active in the job market ", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0bhh1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708931474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We extract data using Talend from multiple tables in Oracle DB, Salesforce and load it in Redshift. There is no transformation in the process. Just extract and load. We perform the transformations once it is in redshift. We want to replace talend with another tool/technology and would like to know suggestions for this. I wish to not use low code tools for this because I believe it might hamper my learning/career. Which technology should I use if I want to the tick off the three things below :\n1. Well suited and less complex \n2. Good learning and skill development by getting exposed to state of the art DE/SWE tool/tech\n3. I want to have an option of moving to SWE so I want to use this opportunity for learning SWE skills which will help me market myself as an SWE once I am active in the job market &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b0bhh1", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0bhh1/elt_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0bhh1/elt_options/", "subreddit_subscribers": 163835, "created_utc": 1708931474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, \nBased in London I am a founding engineer in a early stage startup, we've been building a MVP for a year at my work (haven't sold and no real clients/users). It's a niche game changer (as per the demo-ers of product) in fintech for analysts specially. \n\nIt wasn't easy at first but my CEO and I together designed an ETL kind of system for that using all fancy tech(dagster, timescale cloud) . Streamlined the data investigation/QA process with python and started ingestion, it took a while (about 5 months ) just to get the process ready. \n\nNow for the last three months I have been manually cherry picking data to upload in the dB using  excel sheets from our source database (OECD/IMF and such). \n\nI am on a visa in UK so I cannot afford to not have a job (as in take a break and prepare/look for new job at my own pace) and I also need to find a sponsorship before my visa expires. The reason I am not feeling confident to apply for DE roles is that I have worked with big data framework like Hadoop and Spark at uni only and on my own pet project very little but haven't done so in a professional setting. \n\nI have been learning Data bricks/DBT one step at a time in my free time but haven't gotten the bigger pictureon their implication.Been reading \"Foundation of data engineering\" and \"Designing data intensive applications\". Basically as much I can after working 12hrs a day.\n\nSo bottom line, my question to all the nice people of this sub is would it be worth it for me to learn data modelling properly, sharpen my sql and learn the mordern datastack and apply for only DE job or should I rather just go and have a general approach where I do the job my skills can get my right away. \n\nIf you've read this far a word of advice would mean a lot. \n\nThank you", "author_fullname": "t2_cdqy9ph6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice/suggestion on my next switch as an Data Engineer.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b07n9i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708918215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, \nBased in London I am a founding engineer in a early stage startup, we&amp;#39;ve been building a MVP for a year at my work (haven&amp;#39;t sold and no real clients/users). It&amp;#39;s a niche game changer (as per the demo-ers of product) in fintech for analysts specially. &lt;/p&gt;\n\n&lt;p&gt;It wasn&amp;#39;t easy at first but my CEO and I together designed an ETL kind of system for that using all fancy tech(dagster, timescale cloud) . Streamlined the data investigation/QA process with python and started ingestion, it took a while (about 5 months ) just to get the process ready. &lt;/p&gt;\n\n&lt;p&gt;Now for the last three months I have been manually cherry picking data to upload in the dB using  excel sheets from our source database (OECD/IMF and such). &lt;/p&gt;\n\n&lt;p&gt;I am on a visa in UK so I cannot afford to not have a job (as in take a break and prepare/look for new job at my own pace) and I also need to find a sponsorship before my visa expires. The reason I am not feeling confident to apply for DE roles is that I have worked with big data framework like Hadoop and Spark at uni only and on my own pet project very little but haven&amp;#39;t done so in a professional setting. &lt;/p&gt;\n\n&lt;p&gt;I have been learning Data bricks/DBT one step at a time in my free time but haven&amp;#39;t gotten the bigger pictureon their implication.Been reading &amp;quot;Foundation of data engineering&amp;quot; and &amp;quot;Designing data intensive applications&amp;quot;. Basically as much I can after working 12hrs a day.&lt;/p&gt;\n\n&lt;p&gt;So bottom line, my question to all the nice people of this sub is would it be worth it for me to learn data modelling properly, sharpen my sql and learn the mordern datastack and apply for only DE job or should I rather just go and have a general approach where I do the job my skills can get my right away. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve read this far a word of advice would mean a lot. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b07n9i", "is_robot_indexable": true, "report_reasons": null, "author": "miloplyat", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b07n9i/looking_for_advicesuggestion_on_my_next_switch_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b07n9i/looking_for_advicesuggestion_on_my_next_switch_as/", "subreddit_subscribers": 163835, "created_utc": 1708918215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data geniuses. \n\nWorking currently to Develop a new Dataplatform in Synapse and was wondering if you had any good ideas, on how to implement Incremental Load to our Pipeline. \n\nWe're utilizing the Medallion Architecture with Bronze, Silver &amp; Gold layer like any other. \n\nAll the files we retrieve gets converted to Parquet files in our bronze layer and stored in our Datalake.   \nWhen I look at the functionality in Data Factory can't I come up with a good solution to track Change Data Feed or functionality like AWS Glue Bookmarks. \n\nIt looks like Data Factory functionality is very limited, when you not are using SQL Databases. \n\nWas wondering if I should look into Azure Databricks instead - since it looks like their DLT makes it quite easy to handle Incremental load - but that is something I would need to skill up in and my timeline is limited. ", "author_fullname": "t2_184yei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Incremental Load", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b00r3a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708899488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data geniuses. &lt;/p&gt;\n\n&lt;p&gt;Working currently to Develop a new Dataplatform in Synapse and was wondering if you had any good ideas, on how to implement Incremental Load to our Pipeline. &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re utilizing the Medallion Architecture with Bronze, Silver &amp;amp; Gold layer like any other. &lt;/p&gt;\n\n&lt;p&gt;All the files we retrieve gets converted to Parquet files in our bronze layer and stored in our Datalake.&lt;br/&gt;\nWhen I look at the functionality in Data Factory can&amp;#39;t I come up with a good solution to track Change Data Feed or functionality like AWS Glue Bookmarks. &lt;/p&gt;\n\n&lt;p&gt;It looks like Data Factory functionality is very limited, when you not are using SQL Databases. &lt;/p&gt;\n\n&lt;p&gt;Was wondering if I should look into Azure Databricks instead - since it looks like their DLT makes it quite easy to handle Incremental load - but that is something I would need to skill up in and my timeline is limited. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b00r3a", "is_robot_indexable": true, "report_reasons": null, "author": "TheData_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b00r3a/azure_synapse_incremental_load/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b00r3a/azure_synapse_incremental_load/", "subreddit_subscribers": 163835, "created_utc": 1708899488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am embarking on a new internship for my end-of-studies project at a major production unit. The company relies on an ERP system that generates substantial data, but currently lacks a data infrastructure. The primary objective is to develop a real-time dashboard, utilizing three Excel files as the initial data source.\n\nTo ensure future scalability and accommodate the company's cautious approach to innovation, I aim to build a prototype that not only addresses the immediate need for a dashboard but also lays the foundation for seamless integration with the ERP system. My ultimate goal is to showcase the untapped potential of their data.\n\nMy proposed approach involves loading the CSV files into a database, followed by migration into a data warehouse, and finally using Power BI for visualization. However, I understand that this goes beyond mere data processing; I need to create a robust and scalable infrastructure.\n\nGiven the ambitious timeline of two months, I aim to deliver a solution that not only meets the current requirements but also encourages management to take on future data integration plans. This project will serve as a convincing prototype, illustrating the significant value that can be unlocked through effective data utilization.\n\nPlease experts share with me your holy knowledge on how would you start this project.", "author_fullname": "t2_5ycsuz07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic Infrastructure : Prototyping a Scalable Solution in 8 Weeks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azx72m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708891003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am embarking on a new internship for my end-of-studies project at a major production unit. The company relies on an ERP system that generates substantial data, but currently lacks a data infrastructure. The primary objective is to develop a real-time dashboard, utilizing three Excel files as the initial data source.&lt;/p&gt;\n\n&lt;p&gt;To ensure future scalability and accommodate the company&amp;#39;s cautious approach to innovation, I aim to build a prototype that not only addresses the immediate need for a dashboard but also lays the foundation for seamless integration with the ERP system. My ultimate goal is to showcase the untapped potential of their data.&lt;/p&gt;\n\n&lt;p&gt;My proposed approach involves loading the CSV files into a database, followed by migration into a data warehouse, and finally using Power BI for visualization. However, I understand that this goes beyond mere data processing; I need to create a robust and scalable infrastructure.&lt;/p&gt;\n\n&lt;p&gt;Given the ambitious timeline of two months, I aim to deliver a solution that not only meets the current requirements but also encourages management to take on future data integration plans. This project will serve as a convincing prototype, illustrating the significant value that can be unlocked through effective data utilization.&lt;/p&gt;\n\n&lt;p&gt;Please experts share with me your holy knowledge on how would you start this project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azx72m", "is_robot_indexable": true, "report_reasons": null, "author": "mahdyy_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azx72m/basic_infrastructure_prototyping_a_scalable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azx72m/basic_infrastructure_prototyping_a_scalable/", "subreddit_subscribers": 163835, "created_utc": 1708891003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am running multiple flink jobs in one yarn session and all the logs are written in \"taskmanager.log\" and \"job manager.log\" files which makes it difficult to check logs of a specific job. Is there any way to create seperate log files for each flink job?", "author_fullname": "t2_rckks0bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache flink logs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b09p0n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708924919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running multiple flink jobs in one yarn session and all the logs are written in &amp;quot;taskmanager.log&amp;quot; and &amp;quot;job manager.log&amp;quot; files which makes it difficult to check logs of a specific job. Is there any way to create seperate log files for each flink job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b09p0n", "is_robot_indexable": true, "report_reasons": null, "author": "TKMater", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b09p0n/apache_flink_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b09p0n/apache_flink_logs/", "subreddit_subscribers": 163835, "created_utc": 1708924919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am presenting a data engineering project to an audience that is technical but unfamiliar with the specific topic. I want to cover the usual aspects - business case, data sources, architecture, data transformation/cleaning, validation, etc, basically a summary of the project from inception to delivery.\n\nCan anyone recommend their favorite technical presentations on YouTube that I can watch for some design and content inspiration? I'm specifically interested in talks where someone discusses an actual project (e.g. building some kind of data pipeline) that they worked on rather than a general technical concept  (e.g. how data pipelines work). Thank you!", "author_fullname": "t2_1h1nyytl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any examples of great presentations on data engineering projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b02129", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708902550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am presenting a data engineering project to an audience that is technical but unfamiliar with the specific topic. I want to cover the usual aspects - business case, data sources, architecture, data transformation/cleaning, validation, etc, basically a summary of the project from inception to delivery.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend their favorite technical presentations on YouTube that I can watch for some design and content inspiration? I&amp;#39;m specifically interested in talks where someone discusses an actual project (e.g. building some kind of data pipeline) that they worked on rather than a general technical concept  (e.g. how data pipelines work). Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b02129", "is_robot_indexable": true, "report_reasons": null, "author": "jblue322", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b02129/any_examples_of_great_presentations_on_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b02129/any_examples_of_great_presentations_on_data/", "subreddit_subscribers": 163835, "created_utc": 1708902550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, I have asked a question about a similar topic here before and got amazing answers that helped me understand how things work.\n\n  \nNow, I need to understand how to connect my airflow to kubernets (and from what iv heard, this is the hard part).  \nwe have a DevOps team that hosts both airflow env and Kubernetes.  \n**My goal is simple: to print \"Hello world\" using kubernetesPodOperator (just to make sure I connected well)**  \nWhat files/settings in airflow do I need to edit to create this connection between my Kubernetes and my airflow?  \nsome examples I saw online: (airflow) requirements.txt, the connection tab (in airflow UI)  \n\n\nI'm sure there are a lot more, and would like to ask for your help.  \nplease, name everything (and please explain about the file / setting a bit, I am a beginner in this field) that comes to your mind when trying to make this connection.  \n\n\nThanks a lot!  \n", "author_fullname": "t2_w6u9u77n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to connect Kubernetes to airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azxiez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708891759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, I have asked a question about a similar topic here before and got amazing answers that helped me understand how things work.&lt;/p&gt;\n\n&lt;p&gt;Now, I need to understand how to connect my airflow to kubernets (and from what iv heard, this is the hard part).&lt;br/&gt;\nwe have a DevOps team that hosts both airflow env and Kubernetes.&lt;br/&gt;\n&lt;strong&gt;My goal is simple: to print &amp;quot;Hello world&amp;quot; using kubernetesPodOperator (just to make sure I connected well)&lt;/strong&gt;&lt;br/&gt;\nWhat files/settings in airflow do I need to edit to create this connection between my Kubernetes and my airflow?&lt;br/&gt;\nsome examples I saw online: (airflow) requirements.txt, the connection tab (in airflow UI)  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there are a lot more, and would like to ask for your help.&lt;br/&gt;\nplease, name everything (and please explain about the file / setting a bit, I am a beginner in this field) that comes to your mind when trying to make this connection.  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azxiez", "is_robot_indexable": true, "report_reasons": null, "author": "PhilosopherRemote177", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azxiez/how_to_connect_kubernetes_to_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azxiez/how_to_connect_kubernetes_to_airflow/", "subreddit_subscribers": 163835, "created_utc": 1708891759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My manager along with one of her HR buddies have had an informal conversation about what cert I should do as industry-standard in order to get me an in-role promotion from a data analyst to a data engineer\n\nThey have collectively agreed on the \"Certified Data Professional\", which is offered by the institute for certification of computing professionals, or ICCP, as part of its general database professional program.\n\n&amp;#x200B;\n\nI posted on this sub earlier regarding vendor-specific certs and looks like AWS is the better one to take, even though its the harder one! But alongside that, shall I agree to take this ICCP one also? All will be paid for by the company so money is not an issue.\n\n&amp;#x200B;\n\nAre there any udemy courses out there that walk me through this ICCP one? as their website seems abit old fashioned and I dont want to be stuck with just a big book to read from, need something more interactive!", "author_fullname": "t2_2btsrky1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Certified Data Professional cert, offered by ICCP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0kypc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708963154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My manager along with one of her HR buddies have had an informal conversation about what cert I should do as industry-standard in order to get me an in-role promotion from a data analyst to a data engineer&lt;/p&gt;\n\n&lt;p&gt;They have collectively agreed on the &amp;quot;Certified Data Professional&amp;quot;, which is offered by the institute for certification of computing professionals, or ICCP, as part of its general database professional program.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I posted on this sub earlier regarding vendor-specific certs and looks like AWS is the better one to take, even though its the harder one! But alongside that, shall I agree to take this ICCP one also? All will be paid for by the company so money is not an issue.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are there any udemy courses out there that walk me through this ICCP one? as their website seems abit old fashioned and I dont want to be stuck with just a big book to read from, need something more interactive!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b0kypc", "is_robot_indexable": true, "report_reasons": null, "author": "yungfilly", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0kypc/thoughts_on_certified_data_professional_cert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0kypc/thoughts_on_certified_data_professional_cert/", "subreddit_subscribers": 163835, "created_utc": 1708963154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will try to summarize as succinctly as I can. We're using datastage parallel and sequencer jobs to handle extract load and transform for our warehouse. We more or less learned as we went here with our processes. We used to have a Netezza on-premises and are now migrated to Netezza on Azure. Before we took for granted, just to get the job done, moving data from netezza, into a parallel job, then back to Netezza. Over time we shifted our processes so that all of the joins and, where possible, transformations are done with NZSQL code. Due to a lacking orchestration tool we're still running the data through the datastage server (on-prem) via parallel jobs that are called/scheduled with sequencer jobs. Its a pretty minor step from this point to edit the code a little further to change from a SELECT statement to an INSERT INTO. A good number of our tables are truncated before batch processing, we're simply loading data from the updated source data tables.   \n\n\nNow to my question, I could use a parallel job to execute the INSERT statement but only in a BEFORE or AFTER statement, which means i have to write a dummy query for the job to not fail. Something like a count of the table records, or even just 'select 1'. I've done this on some larger data jobs that we needed to regain performance on, but I am not a fan of losing some of the logging capability of datastage. If a BEFORE or AFTER statement succeeds or fails, thats all I get in the log, no error or return is captured from executing the statement. In Datastage there is an 'optimize' feature that is supposed to take the job design and write SQL code to push up or push down the processing to the source or target server. This is basically what we've done manually, but we want to take it a step further. Out of necessity, its all I have, I need to have datastage execute the SQL, but I don't need/want it to touch the data.   \n\n\nDoes anyone have experience with this? I am also open to hearing about non-datastage options that I can learn about for potential use in the future for our department. TYIA!", "author_fullname": "t2_ir7m9j5mo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datastage as Orchestration Tool? (Best Practices for non ETL data loading with datastage?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0kx5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708963047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will try to summarize as succinctly as I can. We&amp;#39;re using datastage parallel and sequencer jobs to handle extract load and transform for our warehouse. We more or less learned as we went here with our processes. We used to have a Netezza on-premises and are now migrated to Netezza on Azure. Before we took for granted, just to get the job done, moving data from netezza, into a parallel job, then back to Netezza. Over time we shifted our processes so that all of the joins and, where possible, transformations are done with NZSQL code. Due to a lacking orchestration tool we&amp;#39;re still running the data through the datastage server (on-prem) via parallel jobs that are called/scheduled with sequencer jobs. Its a pretty minor step from this point to edit the code a little further to change from a SELECT statement to an INSERT INTO. A good number of our tables are truncated before batch processing, we&amp;#39;re simply loading data from the updated source data tables.   &lt;/p&gt;\n\n&lt;p&gt;Now to my question, I could use a parallel job to execute the INSERT statement but only in a BEFORE or AFTER statement, which means i have to write a dummy query for the job to not fail. Something like a count of the table records, or even just &amp;#39;select 1&amp;#39;. I&amp;#39;ve done this on some larger data jobs that we needed to regain performance on, but I am not a fan of losing some of the logging capability of datastage. If a BEFORE or AFTER statement succeeds or fails, thats all I get in the log, no error or return is captured from executing the statement. In Datastage there is an &amp;#39;optimize&amp;#39; feature that is supposed to take the job design and write SQL code to push up or push down the processing to the source or target server. This is basically what we&amp;#39;ve done manually, but we want to take it a step further. Out of necessity, its all I have, I need to have datastage execute the SQL, but I don&amp;#39;t need/want it to touch the data.   &lt;/p&gt;\n\n&lt;p&gt;Does anyone have experience with this? I am also open to hearing about non-datastage options that I can learn about for potential use in the future for our department. TYIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b0kx5g", "is_robot_indexable": true, "report_reasons": null, "author": "I_Am_Jacks_Voice", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0kx5g/datastage_as_orchestration_tool_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0kx5g/datastage_as_orchestration_tool_best_practices/", "subreddit_subscribers": 163835, "created_utc": 1708963047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. I want to dump my company's db to parquet files in S3. In my understanding, once it is dumped to parquet files it won't update again if there are changes in the db. \n\nWhat's the best way to update those parquet files with the latest data changes? Example, if a user is suddenly blocked. \n\nData is around 10GB", "author_fullname": "t2_4rpxclpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using MongoDB Data Federation to dump to parquet files, how do I keep them updated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0ixnq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708958032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. I want to dump my company&amp;#39;s db to parquet files in S3. In my understanding, once it is dumped to parquet files it won&amp;#39;t update again if there are changes in the db. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to update those parquet files with the latest data changes? Example, if a user is suddenly blocked. &lt;/p&gt;\n\n&lt;p&gt;Data is around 10GB&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b0ixnq", "is_robot_indexable": true, "report_reasons": null, "author": "RedBlueWhiteBlack", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0ixnq/using_mongodb_data_federation_to_dump_to_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0ixnq/using_mongodb_data_federation_to_dump_to_parquet/", "subreddit_subscribers": 163835, "created_utc": 1708958032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team,\n\nSmall example: Let's say we need to ingest data from a Postgres DB server which has 10 DBs, and each DB having 10 tables.\n\nQuestion: How would one best organize the Debezium Kafka Connectors?\n\n* 1 Connector per DB\n* 1 Connecter for everything\n* 1 Connector per table\n* something else\n\nPlease and thank you", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debezium and Connector organization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0ia9b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708956271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team,&lt;/p&gt;\n\n&lt;p&gt;Small example: Let&amp;#39;s say we need to ingest data from a Postgres DB server which has 10 DBs, and each DB having 10 tables.&lt;/p&gt;\n\n&lt;p&gt;Question: How would one best organize the Debezium Kafka Connectors?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;1 Connector per DB&lt;/li&gt;\n&lt;li&gt;1 Connecter for everything&lt;/li&gt;\n&lt;li&gt;1 Connector per table&lt;/li&gt;\n&lt;li&gt;something else&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please and thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b0ia9b", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0ia9b/debezium_and_connector_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0ia9b/debezium_and_connector_organization/", "subreddit_subscribers": 163835, "created_utc": 1708956271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all. I'm new to creating database. In my company (medium sized), data are stored in multiple Excel spreadsheets, ranging from 300 rows to as much as 20k rows. It's slowing down the file opening by a lot the more data is added.\n\nI understand Excel is never the suitable tool for database management. Is MS Access something I should use? My company also uses an SQL editor called Hue, but only certain user is allowed to use it due to the pricey license. We have about 20 users to use/query the data.\n\nI did some simple searches on the internet, it seems like MS Access is not a likable solution among many. How should I go about it in my case? Can Hue be connected with Excel or Access? Any recommendation is much appreciated.", "author_fullname": "t2_1757k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating Database with Limited tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0i9k7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708956212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. I&amp;#39;m new to creating database. In my company (medium sized), data are stored in multiple Excel spreadsheets, ranging from 300 rows to as much as 20k rows. It&amp;#39;s slowing down the file opening by a lot the more data is added.&lt;/p&gt;\n\n&lt;p&gt;I understand Excel is never the suitable tool for database management. Is MS Access something I should use? My company also uses an SQL editor called Hue, but only certain user is allowed to use it due to the pricey license. We have about 20 users to use/query the data.&lt;/p&gt;\n\n&lt;p&gt;I did some simple searches on the internet, it seems like MS Access is not a likable solution among many. How should I go about it in my case? Can Hue be connected with Excel or Access? Any recommendation is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b0i9k7", "is_robot_indexable": true, "report_reasons": null, "author": "imcrazyzzz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0i9k7/creating_database_with_limited_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0i9k7/creating_database_with_limited_tool/", "subreddit_subscribers": 163835, "created_utc": 1708956212.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}