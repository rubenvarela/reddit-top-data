{"kind": "Listing", "data": {"after": "t3_1azvzeo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey beautiful people, I recently got a data engineering role after trying for a while. It wouldn't have been possible with the support of this group. I would like to thank you guys for this. \nI would like to know what should my next steps be? Though I got the job, i still have that imposter syndrome even though my team members are super supportive. I want to take my learnings to a next level but I feel that I lack the basics so want to start from the very scratch like learning the alphabets.\nSo if you were to start a job in IT, how you would have started? I want to become an engineer in true sense. I am ready to devote sufficient time along with my job. \nSuggestions are most welcome.\n\nThank you!!\nHave a great day!", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Landing a data engineering role with the help of this group", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azl4lz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708858006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey beautiful people, I recently got a data engineering role after trying for a while. It wouldn&amp;#39;t have been possible with the support of this group. I would like to thank you guys for this. \nI would like to know what should my next steps be? Though I got the job, i still have that imposter syndrome even though my team members are super supportive. I want to take my learnings to a next level but I feel that I lack the basics so want to start from the very scratch like learning the alphabets.\nSo if you were to start a job in IT, how you would have started? I want to become an engineer in true sense. I am ready to devote sufficient time along with my job. \nSuggestions are most welcome.&lt;/p&gt;\n\n&lt;p&gt;Thank you!!\nHave a great day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azl4lz", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azl4lz/landing_a_data_engineering_role_with_the_help_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azl4lz/landing_a_data_engineering_role_with_the_help_of/", "subreddit_subscribers": 163643, "created_utc": 1708858006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**\\[Repo\\]** [https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven)\n\n# Hello Data enthusiasts! \ud83d\ude4b\ud83c\udffd\u200d\u2642\ufe0f\n\nhttps://preview.redd.it/70u7nk1sknkc1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=bbe7a09f4e45c4313b6c21b7716e347a54ed8646\n\nI\u2019m an engineer by heart and a data enthusiast by passion. I have been working with data teams for the past 10 years and have seen the data landscape evolve from **traditional databases** to **modern data lakes** and **data warehouses**.\n\nIn previous roles, I\u2019ve been working closely with customers of AdTech, MarTech and Fintech companies. As an engineer, I\u2019ve built features and products that helped marketers, advertisers and B2C companies engage with their customers better. Dealing with vast amounts of data, that either came from online or offline sources, I always found myself in the middle of newer challenges that came with the data.\n\nOne of the biggest challenges I\u2019ve faced is the ability to move data from one system to another. This is a problem that has been around for a long time and is often referred to as **Extract, Transform, Load (ETL)**. Consolidating data from multiple sources and storing it in a single place is a common problem and while working with teams, I have built custom ETL pipelines to solve this problem.\n\nHowever, there were no mature platforms that could solve this problem at scale. Then as **AWS Glue, Google Dataflow and Apache Nifi** came into the picture, I started to see a shift in the way data was being moved around. Many OSS platforms like *Airbyte, Meltano and Dagster* have come up in recent years to solve this problem.\n\nNow that we are at the cusp of a new era in modern data stacks, 7 out of 10 are using cloud data warehouses and data lakes.\n\nThis has now made life easier for data engineers, especially when I was struggling with ETL pipelines. But later in my career, I started to see a new problem emerge. When marketers, sales teams and growth teams operate with top-of-the-funnel data, while most of the data is stored in the data warehouse, it is not accessible to them, which is a big problem.\n\nThen I saw data teams and growth teams operate in silos. Data teams were busy building ETL pipelines and maintaining the data warehouse. In contrast, growth teams were busy using tools like **Braze, Facebook Ads, Google Ads, Salesforce, Hubspot**, etc. to engage with their customers.\n\n# \ud83d\udcab The Genesis of Multiwoven\n\nAt the initial stages of Multiwoven, our initial idea was to build a product notification platform for product teams, to help them send targeted notifications to their users. But as we started to talk to more customers, we realized that the problem of data silos was much bigger than we thought. We realized that the problem of data silos was not just limited to product teams, but was a problem that was faced by every team in the company.\n\nThat\u2019s when we decided to pivot and build Multiwoven, a **reverse ETL** platform that helps companies move data from their data warehouse to their SaaS platforms. We wanted to build a platform that would help companies make their data actionable across different SaaS platforms.\n\n# \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb Why Open Source?\n\nAs a team, we are strong believers in open source, and the reason behind going open source was twofold. Firstly, cost was always a counterproductive aspect for teams using commercial SAAS platforms. Secondly, we wanted to build a flexible and customizable platform that could give companies the control and governance they needed.\n\n***This has been our humble beginning and we are excited to see where this journey takes us. We are excited to see the impact we can make in the data activation landscape.***\n\n&gt;*Please \u2b50 star our* [*repo on Github*](https://github.com/Multiwoven/multiwoven) *and show us some love. We are always looking for feedback and would love to hear from you.*\n\n**\\[Repo\\]** [https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven)", "author_fullname": "t2_rtrd3q97v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why I Decided to Build Multiwoven: an Open-source Reverse ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"70u7nk1sknkc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c6d84875ad9fe5b5384172183347cf448fdcfb0"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd6516d2e51489dc8606d32ec9b79b4fd4e50bd3"}, {"y": 150, "x": 320, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=aae6942bf1338a4b2ce06405ced4fc71a639fad0"}, {"y": 301, "x": 640, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d3e630aa87bd6d294e84b1f5d222023bcd78b0e2"}, {"y": 451, "x": 960, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9f4bf4e36b2298f0e7b75acf8252dfdff2549f62"}, {"y": 507, "x": 1080, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=74ebf30a798c3c304ae8ff369a9d63761e168396"}], "s": {"y": 1204, "x": 2560, "u": "https://preview.redd.it/70u7nk1sknkc1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=bbe7a09f4e45c4313b6c21b7716e347a54ed8646"}, "id": "70u7nk1sknkc1"}}, "name": "t3_1aze7db", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ba02ywnsMpACZ9VFplAkrz0QVt53tVe9DKUaRPfiIfE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1708832648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;[Repo]&lt;/strong&gt; &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Hello Data enthusiasts! \ud83d\ude4b\ud83c\udffd\u200d\u2642\ufe0f&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/70u7nk1sknkc1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bbe7a09f4e45c4313b6c21b7716e347a54ed8646\"&gt;https://preview.redd.it/70u7nk1sknkc1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bbe7a09f4e45c4313b6c21b7716e347a54ed8646&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I\u2019m an engineer by heart and a data enthusiast by passion. I have been working with data teams for the past 10 years and have seen the data landscape evolve from &lt;strong&gt;traditional databases&lt;/strong&gt; to &lt;strong&gt;modern data lakes&lt;/strong&gt; and &lt;strong&gt;data warehouses&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;In previous roles, I\u2019ve been working closely with customers of AdTech, MarTech and Fintech companies. As an engineer, I\u2019ve built features and products that helped marketers, advertisers and B2C companies engage with their customers better. Dealing with vast amounts of data, that either came from online or offline sources, I always found myself in the middle of newer challenges that came with the data.&lt;/p&gt;\n\n&lt;p&gt;One of the biggest challenges I\u2019ve faced is the ability to move data from one system to another. This is a problem that has been around for a long time and is often referred to as &lt;strong&gt;Extract, Transform, Load (ETL)&lt;/strong&gt;. Consolidating data from multiple sources and storing it in a single place is a common problem and while working with teams, I have built custom ETL pipelines to solve this problem.&lt;/p&gt;\n\n&lt;p&gt;However, there were no mature platforms that could solve this problem at scale. Then as &lt;strong&gt;AWS Glue, Google Dataflow and Apache Nifi&lt;/strong&gt; came into the picture, I started to see a shift in the way data was being moved around. Many OSS platforms like &lt;em&gt;Airbyte, Meltano and Dagster&lt;/em&gt; have come up in recent years to solve this problem.&lt;/p&gt;\n\n&lt;p&gt;Now that we are at the cusp of a new era in modern data stacks, 7 out of 10 are using cloud data warehouses and data lakes.&lt;/p&gt;\n\n&lt;p&gt;This has now made life easier for data engineers, especially when I was struggling with ETL pipelines. But later in my career, I started to see a new problem emerge. When marketers, sales teams and growth teams operate with top-of-the-funnel data, while most of the data is stored in the data warehouse, it is not accessible to them, which is a big problem.&lt;/p&gt;\n\n&lt;p&gt;Then I saw data teams and growth teams operate in silos. Data teams were busy building ETL pipelines and maintaining the data warehouse. In contrast, growth teams were busy using tools like &lt;strong&gt;Braze, Facebook Ads, Google Ads, Salesforce, Hubspot&lt;/strong&gt;, etc. to engage with their customers.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udcab The Genesis of Multiwoven&lt;/h1&gt;\n\n&lt;p&gt;At the initial stages of Multiwoven, our initial idea was to build a product notification platform for product teams, to help them send targeted notifications to their users. But as we started to talk to more customers, we realized that the problem of data silos was much bigger than we thought. We realized that the problem of data silos was not just limited to product teams, but was a problem that was faced by every team in the company.&lt;/p&gt;\n\n&lt;p&gt;That\u2019s when we decided to pivot and build Multiwoven, a &lt;strong&gt;reverse ETL&lt;/strong&gt; platform that helps companies move data from their data warehouse to their SaaS platforms. We wanted to build a platform that would help companies make their data actionable across different SaaS platforms.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb Why Open Source?&lt;/h1&gt;\n\n&lt;p&gt;As a team, we are strong believers in open source, and the reason behind going open source was twofold. Firstly, cost was always a counterproductive aspect for teams using commercial SAAS platforms. Secondly, we wanted to build a flexible and customizable platform that could give companies the control and governance they needed.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;This has been our humble beginning and we are excited to see where this journey takes us. We are excited to see the impact we can make in the data activation landscape.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;em&gt;Please \u2b50 star our&lt;/em&gt; &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;&lt;em&gt;repo on Github&lt;/em&gt;&lt;/a&gt; &lt;em&gt;and show us some love. We are always looking for feedback and would love to hear from you.&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;[Repo]&lt;/strong&gt; &lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?auto=webp&amp;s=7bee046b00e43a80d51ec06b5b03fab8fe50e8a6", "width": 2560, "height": 1280}, "resolutions": [{"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c820e531bd69e73f8ab0a6ae0beacd99c2b46eb", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c80be54ff0c4e74ab2f7726675fcebd3a845b46", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ac265f606906d37f473536da1c0f1402f557f04", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f31b53a48c8d26b2abdbd514797bd69ea9539bcf", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d338fcd1ab24aecad9b1dcf39d5649f7cff2a29", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3be250d32cd9b8a61ac25ca44aa1a3ab73cb70a", "width": 1080, "height": 540}], "variants": {}, "id": "KXdCRFA3PFw6uZLyGfHzBPQBTSPbN50XvrsQE2m5iOI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1aze7db", "is_robot_indexable": true, "report_reasons": null, "author": "nagstler", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aze7db/why_i_decided_to_build_multiwoven_an_opensource/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aze7db/why_i_decided_to_build_multiwoven_an_opensource/", "subreddit_subscribers": 163643, "created_utc": 1708832648.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have just received an offer for the position of data warehouse engineer for a FinTech based out of UK. The company is working on creating a data team, and i will be a part of it. \n\nI have been working as a data engineer for 1.5 years and rn i am a data engineer in ETL and data migration department of a health care EHR provider. The work here is pretty stale, running old sql scripts, some python work, working on local servers etc.\n\nNow that i have received a job offer, my current employer has matched the offer (slighter higher). My manager has said he will change my team whatever i want he will give me but I don\u2019t believe him much, he is a toxic manager. \n\nI don\u2019t know what to do because the new place will be more challenging, new thing to work on, more independence etc. but will be paid a little less and the hours are 2-10pm and in a remote town away from where i am living (during the probation period for three months, will move to my current city office after that). \n\nHonestly i am in a comfort zone with my current employer. I am almost 25, want to excel in DE domain. I want to be convinced that i need to move to make something out of my career. \n\nEdit\n\nAnother option is i take the counter and look for a better opportunity in the next 3-5 months because ultimately i want to leave my current employer. ", "author_fullname": "t2_4p33upbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Received an offer. Don\u2019t know what to do now. ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azosgr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708872680.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708870205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have just received an offer for the position of data warehouse engineer for a FinTech based out of UK. The company is working on creating a data team, and i will be a part of it. &lt;/p&gt;\n\n&lt;p&gt;I have been working as a data engineer for 1.5 years and rn i am a data engineer in ETL and data migration department of a health care EHR provider. The work here is pretty stale, running old sql scripts, some python work, working on local servers etc.&lt;/p&gt;\n\n&lt;p&gt;Now that i have received a job offer, my current employer has matched the offer (slighter higher). My manager has said he will change my team whatever i want he will give me but I don\u2019t believe him much, he is a toxic manager. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know what to do because the new place will be more challenging, new thing to work on, more independence etc. but will be paid a little less and the hours are 2-10pm and in a remote town away from where i am living (during the probation period for three months, will move to my current city office after that). &lt;/p&gt;\n\n&lt;p&gt;Honestly i am in a comfort zone with my current employer. I am almost 25, want to excel in DE domain. I want to be convinced that i need to move to make something out of my career. &lt;/p&gt;\n\n&lt;p&gt;Edit&lt;/p&gt;\n\n&lt;p&gt;Another option is i take the counter and look for a better opportunity in the next 3-5 months because ultimately i want to leave my current employer. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azosgr", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Law7386", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azosgr/received_an_offer_dont_know_what_to_do_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azosgr/received_an_offer_dont_know_what_to_do_now/", "subreddit_subscribers": 163643, "created_utc": 1708870205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "- List a podcast once as an individual comment\n- if you favorite podcast already listed, like the comment\n- if you host a podcast, list it if not already listed\n- feel free to separately post comments about what you like in a podcast (long or short, conversations/interviews, etc.)", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Listing Data Podcasts (Your Podcast or One You Like)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azvaad", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708886450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;List a podcast once as an individual comment&lt;/li&gt;\n&lt;li&gt;if you favorite podcast already listed, like the comment&lt;/li&gt;\n&lt;li&gt;if you host a podcast, list it if not already listed&lt;/li&gt;\n&lt;li&gt;feel free to separately post comments about what you like in a podcast (long or short, conversations/interviews, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azvaad", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azvaad/listing_data_podcasts_your_podcast_or_one_you_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azvaad/listing_data_podcasts_your_podcast_or_one_you_like/", "subreddit_subscribers": 163643, "created_utc": 1708886450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious what you guys see as the romantic market force and best platform. If you had to marry just one? Which is it and why? What does your company use? \n\nThanks. You are deciding my life and future right now. ", "author_fullname": "t2_nb0ef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Marry, F, kill\u2026 databricks, snowflake, ms fabric?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b04b8j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708908509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious what you guys see as the romantic market force and best platform. If you had to marry just one? Which is it and why? What does your company use? &lt;/p&gt;\n\n&lt;p&gt;Thanks. You are deciding my life and future right now. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b04b8j", "is_robot_indexable": true, "report_reasons": null, "author": "JamesGarrison", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b04b8j/marry_f_kill_databricks_snowflake_ms_fabric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b04b8j/marry_f_kill_databricks_snowflake_ms_fabric/", "subreddit_subscribers": 163643, "created_utc": 1708908509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "   \n\n\nI see that Arrow in general is gaining a lot of popularity. [Meta](https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/)and [Apple](https://thenewstack.io/apple-comet-brings-fast-vector-processing-to-apache-spark/), are building data infrastructure that strongly depended on it.\n\nI am also embracing it as a fundamental piece in our infra.  \nHowever, I see that, at least for Pyarrow, there is a deficit of blogs/tutorials that explain fundamental topics or best practices on how to benefit from it.   \n[I read a book, by Matthew Topol,](https://www.amazon.com/Memory-Analytics-Apache-Arrow-hierarchical/dp/1801071039) that was really informative but still there are many issues that I wish to better understand.\n\n1. What is the difference between pa.Table and RecordBatch and when we should prefer one over another?\n2. How parallelism works in general but especially for pa.compute? Does it assign a core per ChunkedArray? What if I concat many tables and each ChunkedArray is in a different physical location, does it still work with the same strategy? \n3. Pyarrow native Filesystem vs  \u201cthe Python ecosystem Filesystems\u201d. I see in the documents there is a way to work with both, but what is the real difference?  Is there a real drawback to using the Python one? \n\nFor all those issues,  I was able to find some info but not in the level that I expected before integrating it in the production system.   \n\nI wonder why this is and if someone can point me to good resources about those topics?\n\nThanks,  \nLeon", "author_fullname": "t2_ll7atfr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyarrow is popular but lacking of tutorials and resources.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azwb09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708888856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see that Arrow in general is gaining a lot of popularity. &lt;a href=\"https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/\"&gt;Meta&lt;/a&gt;and &lt;a href=\"https://thenewstack.io/apple-comet-brings-fast-vector-processing-to-apache-spark/\"&gt;Apple&lt;/a&gt;, are building data infrastructure that strongly depended on it.&lt;/p&gt;\n\n&lt;p&gt;I am also embracing it as a fundamental piece in our infra.&lt;br/&gt;\nHowever, I see that, at least for Pyarrow, there is a deficit of blogs/tutorials that explain fundamental topics or best practices on how to benefit from it.&lt;br/&gt;\n&lt;a href=\"https://www.amazon.com/Memory-Analytics-Apache-Arrow-hierarchical/dp/1801071039\"&gt;I read a book, by Matthew Topol,&lt;/a&gt; that was really informative but still there are many issues that I wish to better understand.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What is the difference between pa.Table and RecordBatch and when we should prefer one over another?&lt;/li&gt;\n&lt;li&gt;How parallelism works in general but especially for pa.compute? Does it assign a core per ChunkedArray? What if I concat many tables and each ChunkedArray is in a different physical location, does it still work with the same strategy? &lt;/li&gt;\n&lt;li&gt;Pyarrow native Filesystem vs  \u201cthe Python ecosystem Filesystems\u201d. I see in the documents there is a way to work with both, but what is the real difference?  Is there a real drawback to using the Python one? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For all those issues,  I was able to find some info but not in the level that I expected before integrating it in the production system.   &lt;/p&gt;\n\n&lt;p&gt;I wonder why this is and if someone can point me to good resources about those topics?&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;br/&gt;\nLeon&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?auto=webp&amp;s=44ab0f03ed7f603f8782bbd188e996ad17c77502", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f2085f904a50b3e53975fb7137bec4c25983982", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=000e9a1509c279a23bdac011f0bf3f50b1c25c63", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6088d7b42f1a420908f02ebe9522e78a3693e0ab", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d9bd16fdee41d441ec79d3960e425fb811b5739", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c44265f6811ff5c6dc68d26c531095ca8808679f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=907539619f060dd8a859ef77e81ef965224a45a7", "width": 1080, "height": 607}], "variants": {}, "id": "rKGSSC8ZiCD9gbOKh05G5ntySpFbt_LVVJ1vd4XJm9o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azwb09", "is_robot_indexable": true, "report_reasons": null, "author": "Leon_Bam", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azwb09/pyarrow_is_popular_but_lacking_of_tutorials_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azwb09/pyarrow_is_popular_but_lacking_of_tutorials_and/", "subreddit_subscribers": 163643, "created_utc": 1708888856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to transition to a data engineering role (to a DS role later)  from a full-stack developer role (mostly web development).\n\nI have to be honest that my current role is a dead-end and I have no proofs of actually using python etc on the daily, even though we do use SQL from time to time. So, I went back to school to do an Honors degree(1 more year as I graduated in 2020 with a Bachelor's in CS and Math) where I wrote a thesis. I was exposed to a deeper use of the python in the data world. My thesis was in the fields of bioinformatics and realized that I do have an appreciation for data (ETL, Math etc)\n\nI consider myself as a good python and an Ok sql developer. I also have a good understanding of math (linear algebra, statistics etc ). Since my current role has nothing to do with data engineering, I am taking the IBM Data engineering certification. It is a good start but not enough as  I am hoping to be job ready by May. \n\n&amp;#x200B;\n\nMy question is: What certifications, courses and projects should I do so that I can maximize the chance of landing a job? I am in Ontario for reference.", "author_fullname": "t2_kel54afu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What courses/certifications should I do as a sofware developer with 3+ years of experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aztcw0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708881857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to transition to a data engineering role (to a DS role later)  from a full-stack developer role (mostly web development).&lt;/p&gt;\n\n&lt;p&gt;I have to be honest that my current role is a dead-end and I have no proofs of actually using python etc on the daily, even though we do use SQL from time to time. So, I went back to school to do an Honors degree(1 more year as I graduated in 2020 with a Bachelor&amp;#39;s in CS and Math) where I wrote a thesis. I was exposed to a deeper use of the python in the data world. My thesis was in the fields of bioinformatics and realized that I do have an appreciation for data (ETL, Math etc)&lt;/p&gt;\n\n&lt;p&gt;I consider myself as a good python and an Ok sql developer. I also have a good understanding of math (linear algebra, statistics etc ). Since my current role has nothing to do with data engineering, I am taking the IBM Data engineering certification. It is a good start but not enough as  I am hoping to be job ready by May. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is: What certifications, courses and projects should I do so that I can maximize the chance of landing a job? I am in Ontario for reference.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aztcw0", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent_Tough_651", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aztcw0/what_coursescertifications_should_i_do_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aztcw0/what_coursescertifications_should_i_do_as_a/", "subreddit_subscribers": 163643, "created_utc": 1708881857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have problem which I don't really know how to solve properly. I have a table with billions of rows in ClickHouse (will go up to tens of billions). I want to create various analytical charts about subsets of this data (those charts can be updated once a day). Unfortunately those charts are quite complex and most of them need some window functions / cross joins to work properly. For some bigger subsets queries can take more than 1 minute, which is unacceptable (I expect them to work in seconds). Pre-generating  reports for all subsets of data with such queries would probably take a day which is terrible.\n\nI tried solving it with ClickHouse materialized view - I created a view that gives me enough info so that I can easily create all charts in seconds. But it's terrible to manage: it has hundreds of billions of rows, takes up terabytes of storage and takes days to create. I want to get rid of it.\n\nI'm thinking about other solution: next thing I want to try is to just stop writing ClickHouse queries and process my data in RAM. So I would export my whole table (or just changes of it) every day, load it into Python and process it there, maybe using Polars? Or Spark? (although I should be able to fit data in RAM - it would be like 100gb uncompressed) I feel like I would be able to write some simple iteration over my data that would achieve effects of 100 lines of SQL and it would take seconds instead of minutes. I would generate reports for all subsets of data I need and just export it to ClickHouse for access.\n\nSo basically my question is how would you solve such a problem? And if this loading-and-processing data in Python every day is a good idea.  (FYI I'm NOT experienced in Python/Spark etc. so my question might seem silly. But SQL just seems not enough)", "author_fullname": "t2_j3zjmd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Patterns for processing lots of data with window functions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b005l7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708898069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have problem which I don&amp;#39;t really know how to solve properly. I have a table with billions of rows in ClickHouse (will go up to tens of billions). I want to create various analytical charts about subsets of this data (those charts can be updated once a day). Unfortunately those charts are quite complex and most of them need some window functions / cross joins to work properly. For some bigger subsets queries can take more than 1 minute, which is unacceptable (I expect them to work in seconds). Pre-generating  reports for all subsets of data with such queries would probably take a day which is terrible.&lt;/p&gt;\n\n&lt;p&gt;I tried solving it with ClickHouse materialized view - I created a view that gives me enough info so that I can easily create all charts in seconds. But it&amp;#39;s terrible to manage: it has hundreds of billions of rows, takes up terabytes of storage and takes days to create. I want to get rid of it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about other solution: next thing I want to try is to just stop writing ClickHouse queries and process my data in RAM. So I would export my whole table (or just changes of it) every day, load it into Python and process it there, maybe using Polars? Or Spark? (although I should be able to fit data in RAM - it would be like 100gb uncompressed) I feel like I would be able to write some simple iteration over my data that would achieve effects of 100 lines of SQL and it would take seconds instead of minutes. I would generate reports for all subsets of data I need and just export it to ClickHouse for access.&lt;/p&gt;\n\n&lt;p&gt;So basically my question is how would you solve such a problem? And if this loading-and-processing data in Python every day is a good idea.  (FYI I&amp;#39;m NOT experienced in Python/Spark etc. so my question might seem silly. But SQL just seems not enough)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b005l7", "is_robot_indexable": true, "report_reasons": null, "author": "rottensunday", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b005l7/patterns_for_processing_lots_of_data_with_window/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b005l7/patterns_for_processing_lots_of_data_with_window/", "subreddit_subscribers": 163643, "created_utc": 1708898069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nURL: https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\n\nI'm excited to share my latest blog post where I delve into the fascinating world of Parquet metadata and its role in optimizing data storage and retrieval. If you're working with big data or interested in efficient data storage techniques, this post is for you!\nIn this blog post, I explore:\n- Deciphering Data Serialization: Unpacking the various types of data serialization, their respective benefits, and how Parquet utilizes them. \n- Understanding Parquet Metadata: I break down what Parquet metadata is, why it's important, and how it contributes to the efficiency of data storage.\n- Metadata Structure: Dive into the nuts and bolts of Parquet metadata structure, including file metadata, row group metadata, and column metadata.\n\nWhether you're a data engineer, data scientist, or just someone curious about how data is stored and managed efficiently, this blog post has something for you.\n\nCheck out the full post [here](https://rr43.net/posts/2024/2/parquet-metadata-dataserde/) and let me know your thoughts in the comments. I'm also open to questions and discussions about Parquet metadata or any related topics!\nHappy reading and happy data exploring! \ud83d\ude80", "author_fullname": "t2_dbozei2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Parquet Metadata: A Deep Dive into Efficient Data Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azy2nt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708893104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;URL: &lt;a href=\"https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\"&gt;https://rr43.net/posts/2024/2/parquet-metadata-dataserde/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to share my latest blog post where I delve into the fascinating world of Parquet metadata and its role in optimizing data storage and retrieval. If you&amp;#39;re working with big data or interested in efficient data storage techniques, this post is for you!\nIn this blog post, I explore:\n- Deciphering Data Serialization: Unpacking the various types of data serialization, their respective benefits, and how Parquet utilizes them. \n- Understanding Parquet Metadata: I break down what Parquet metadata is, why it&amp;#39;s important, and how it contributes to the efficiency of data storage.\n- Metadata Structure: Dive into the nuts and bolts of Parquet metadata structure, including file metadata, row group metadata, and column metadata.&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re a data engineer, data scientist, or just someone curious about how data is stored and managed efficiently, this blog post has something for you.&lt;/p&gt;\n\n&lt;p&gt;Check out the full post &lt;a href=\"https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\"&gt;here&lt;/a&gt; and let me know your thoughts in the comments. I&amp;#39;m also open to questions and discussions about Parquet metadata or any related topics!\nHappy reading and happy data exploring! \ud83d\ude80&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1azy2nt", "is_robot_indexable": true, "report_reasons": null, "author": "InstitutionalizedSon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azy2nt/exploring_parquet_metadata_a_deep_dive_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azy2nt/exploring_parquet_metadata_a_deep_dive_into/", "subreddit_subscribers": 163643, "created_utc": 1708893104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm about to start my very first Dbt project and I'd like to do things as best as possible. \n\nDo you guys have an example of a Dbt project that you consider \"clean\" and coded according to the best practices? Could be a blog post, or a Udemy course, or anything as long as it's detailed.\n\nThe project I'm looking to build will be very standard: integration of raw data, with DQ, historization of dimension attributes (SCD2), incremental load on some fact tables, some external Excel files to be ingested, and finally some denormaliezed datasets that will be connected to Tableau.\n\nDo you have anything I could look up to in order to avoid the common pitfalls of Dbt ?\n\nThank you !!\n\n\n\n\n", "author_fullname": "t2_rz2xn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a Dbt Best Practice Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b01klb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708901431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to start my very first Dbt project and I&amp;#39;d like to do things as best as possible. &lt;/p&gt;\n\n&lt;p&gt;Do you guys have an example of a Dbt project that you consider &amp;quot;clean&amp;quot; and coded according to the best practices? Could be a blog post, or a Udemy course, or anything as long as it&amp;#39;s detailed.&lt;/p&gt;\n\n&lt;p&gt;The project I&amp;#39;m looking to build will be very standard: integration of raw data, with DQ, historization of dimension attributes (SCD2), incremental load on some fact tables, some external Excel files to be ingested, and finally some denormaliezed datasets that will be connected to Tableau.&lt;/p&gt;\n\n&lt;p&gt;Do you have anything I could look up to in order to avoid the common pitfalls of Dbt ?&lt;/p&gt;\n\n&lt;p&gt;Thank you !!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b01klb", "is_robot_indexable": true, "report_reasons": null, "author": "Ownards", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b01klb/looking_for_a_dbt_best_practice_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b01klb/looking_for_a_dbt_best_practice_project/", "subreddit_subscribers": 163643, "created_utc": 1708901431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, quick question. I'm trying to understand the differences between a Data Lake and a Data Warehouse. Can you store unstructured data in snowflake (like pictures, audio etc)? If yes, is Snowflake a DW or a DL?\n\nLastly, can the same tool be called a DW or a DL depending on your store data in that tool (structured vs unstructured)?\n\nThanks so much!", "author_fullname": "t2_a4d2j3fh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake - Data Lake or Data Warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azvbd8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708886524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, quick question. I&amp;#39;m trying to understand the differences between a Data Lake and a Data Warehouse. Can you store unstructured data in snowflake (like pictures, audio etc)? If yes, is Snowflake a DW or a DL?&lt;/p&gt;\n\n&lt;p&gt;Lastly, can the same tool be called a DW or a DL depending on your store data in that tool (structured vs unstructured)?&lt;/p&gt;\n\n&lt;p&gt;Thanks so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azvbd8", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Nobody-2727", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azvbd8/snowflake_data_lake_or_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azvbd8/snowflake_data_lake_or_data_warehouse/", "subreddit_subscribers": 163643, "created_utc": 1708886524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nI currently work as a BI Engineer, and I am so interested about ML engineering that I started learning about Data Engineering (gcp, docker, terraform Python, spark, airflow etc ) as I think it might take me closer to ML. \n\nI finally got an an offer as a Data Engineer, but it\u2019s in the banking industry, mainly ETL and informatica. \n\nNow I am not sure is this taking me closer even to Data Engineering as I am learning it now? \n\nIt\u2019s also worth to mention that this offer is only 2k above my current salary. I would have taking it if it\u2019s data engineering using the toold I mentioned above. \n\nBut this way I am afraid I\u2019d be stuck in etl developement using informatica! \n\nAt the same time I am afraid that this\u2019s an opportunity into DE that I will miss. \n\nPlease give me your honest advice\u2026", "author_fullname": "t2_6or8m0hm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So confused whether to take this DE opportunity or wait for a better pne", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azt074", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708881002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I currently work as a BI Engineer, and I am so interested about ML engineering that I started learning about Data Engineering (gcp, docker, terraform Python, spark, airflow etc ) as I think it might take me closer to ML. &lt;/p&gt;\n\n&lt;p&gt;I finally got an an offer as a Data Engineer, but it\u2019s in the banking industry, mainly ETL and informatica. &lt;/p&gt;\n\n&lt;p&gt;Now I am not sure is this taking me closer even to Data Engineering as I am learning it now? &lt;/p&gt;\n\n&lt;p&gt;It\u2019s also worth to mention that this offer is only 2k above my current salary. I would have taking it if it\u2019s data engineering using the toold I mentioned above. &lt;/p&gt;\n\n&lt;p&gt;But this way I am afraid I\u2019d be stuck in etl developement using informatica! &lt;/p&gt;\n\n&lt;p&gt;At the same time I am afraid that this\u2019s an opportunity into DE that I will miss. &lt;/p&gt;\n\n&lt;p&gt;Please give me your honest advice\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azt074", "is_robot_indexable": true, "report_reasons": null, "author": "Judessaa", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azt074/so_confused_whether_to_take_this_de_opportunity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azt074/so_confused_whether_to_take_this_de_opportunity/", "subreddit_subscribers": 163643, "created_utc": 1708881002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've had an interesting discussion this week that got me thinking on the utility of feature stores in MLOps. I was wondering how you think about this.\n\nFor a long time I thought feature stores mainly target online (real-time) prediction workloads. You want fast access to the current version of a feature (the \"online\" layer) during inference, bulk access to data during training (offline layer), and wish that your inference and training API are the same so you can share code paths.\n\nHowever, now I realized that feature stores also advertise their \"time-travel\" capability, i.e., they have a built-in SCD mechanism to allow you to train on consistent snapshots of historical data.\n\nDid I missunderstand the purpose of a feature store and the \"killer feature\" isnt the fast cache of the latest version of a record, but rather the built-in SCD? Is CDC capture via SCD a common feature of a feature?", "author_fullname": "t2_frdb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did i missunderstand feature stores?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azm6q1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708862028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had an interesting discussion this week that got me thinking on the utility of feature stores in MLOps. I was wondering how you think about this.&lt;/p&gt;\n\n&lt;p&gt;For a long time I thought feature stores mainly target online (real-time) prediction workloads. You want fast access to the current version of a feature (the &amp;quot;online&amp;quot; layer) during inference, bulk access to data during training (offline layer), and wish that your inference and training API are the same so you can share code paths.&lt;/p&gt;\n\n&lt;p&gt;However, now I realized that feature stores also advertise their &amp;quot;time-travel&amp;quot; capability, i.e., they have a built-in SCD mechanism to allow you to train on consistent snapshots of historical data.&lt;/p&gt;\n\n&lt;p&gt;Did I missunderstand the purpose of a feature store and the &amp;quot;killer feature&amp;quot; isnt the fast cache of the latest version of a record, but rather the built-in SCD? Is CDC capture via SCD a common feature of a feature?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azm6q1", "is_robot_indexable": true, "report_reasons": null, "author": "FirefoxMetzger", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azm6q1/did_i_missunderstand_feature_stores/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azm6q1/did_i_missunderstand_feature_stores/", "subreddit_subscribers": 163643, "created_utc": 1708862028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm currently embarking on a project to revamp customer segmentation for an e-commerce company.\n\nWe've got lots of data already, but I'm not sure what exactly I need to make this work well. Figuring out customer groups helps us make shopping better for everyone.\n\nHere's what I'm wondering:\n\n1. **Important Data Stuff:** What kind of information should we have in our data to understand our customers better?\n2. **Fixing Data:** How can we make sure the data we have is good enough to help us understand our customers?\n3. **Good Ways to Sort Customers:** Do you know any good tricks or tools to help us figure out what groups our customers belong to?\n4. **Checking if it Works:** Once we have our groups, how can we tell if they're helping us make shopping better?\n\nWe've got loads of data, but making sense of it all is tough. I'd really appreciate any advice you can give. Whether it's from your job, what you've learned, or just good ideas, I'm all ears. Thanks a bunch for your help!", "author_fullname": "t2_6laijtqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Customer Segmentation for E-commerce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aztu7p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708883006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently embarking on a project to revamp customer segmentation for an e-commerce company.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve got lots of data already, but I&amp;#39;m not sure what exactly I need to make this work well. Figuring out customer groups helps us make shopping better for everyone.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;m wondering:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Important Data Stuff:&lt;/strong&gt; What kind of information should we have in our data to understand our customers better?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fixing Data:&lt;/strong&gt; How can we make sure the data we have is good enough to help us understand our customers?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Good Ways to Sort Customers:&lt;/strong&gt; Do you know any good tricks or tools to help us figure out what groups our customers belong to?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Checking if it Works:&lt;/strong&gt; Once we have our groups, how can we tell if they&amp;#39;re helping us make shopping better?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We&amp;#39;ve got loads of data, but making sense of it all is tough. I&amp;#39;d really appreciate any advice you can give. Whether it&amp;#39;s from your job, what you&amp;#39;ve learned, or just good ideas, I&amp;#39;m all ears. Thanks a bunch for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aztu7p", "is_robot_indexable": true, "report_reasons": null, "author": "Appropriate_Union_58", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aztu7p/seeking_advice_on_customer_segmentation_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aztu7p/seeking_advice_on_customer_segmentation_for/", "subreddit_subscribers": 163643, "created_utc": 1708883006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a pipeline i use foreachbatch for writing one stream to different sinks. I have the feeling this is not really considered best practice because it kind of feels like perverting streaming principles to enforce a type of batch processing\u2026 what are your experiences with foreaxhbatch or how do you handle such kind of problems? \n", "author_fullname": "t2_q4hy00qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Streaming - foreachBatch bad practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azlz5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708861221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a pipeline i use foreachbatch for writing one stream to different sinks. I have the feeling this is not really considered best practice because it kind of feels like perverting streaming principles to enforce a type of batch processing\u2026 what are your experiences with foreaxhbatch or how do you handle such kind of problems? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azlz5r", "is_robot_indexable": true, "report_reasons": null, "author": "ShipWild9022", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azlz5r/spark_streaming_foreachbatch_bad_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azlz5r/spark_streaming_foreachbatch_bad_practice/", "subreddit_subscribers": 163643, "created_utc": 1708861221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve landed a junior role which has its focus on visualization (pbi). Any tips on how to make the most of it?", "author_fullname": "t2_65m8bm7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get the most of a junior data engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azyg1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708893997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve landed a junior role which has its focus on visualization (pbi). Any tips on how to make the most of it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azyg1q", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic-Video-1595", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azyg1q/how_to_get_the_most_of_a_junior_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azyg1q/how_to_get_the_most_of_a_junior_data_engineering/", "subreddit_subscribers": 163643, "created_utc": 1708893997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am embarking on a new internship for my end-of-studies project at a major production unit. The company relies on an ERP system that generates substantial data, but currently lacks a data infrastructure. The primary objective is to develop a real-time dashboard, utilizing three Excel files as the initial data source.\n\nTo ensure future scalability and accommodate the company's cautious approach to innovation, I aim to build a prototype that not only addresses the immediate need for a dashboard but also lays the foundation for seamless integration with the ERP system. My ultimate goal is to showcase the untapped potential of their data.\n\nMy proposed approach involves loading the CSV files into a database, followed by migration into a data warehouse, and finally using Power BI for visualization. However, I understand that this goes beyond mere data processing; I need to create a robust and scalable infrastructure.\n\nGiven the ambitious timeline of two months, I aim to deliver a solution that not only meets the current requirements but also encourages management to take on future data integration plans. This project will serve as a convincing prototype, illustrating the significant value that can be unlocked through effective data utilization.\n\nPlease experts share with me your holy knowledge on how would you start this project.", "author_fullname": "t2_5ycsuz07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic Infrastructure : Prototyping a Scalable Solution in 8 Weeks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azx72m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708891003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am embarking on a new internship for my end-of-studies project at a major production unit. The company relies on an ERP system that generates substantial data, but currently lacks a data infrastructure. The primary objective is to develop a real-time dashboard, utilizing three Excel files as the initial data source.&lt;/p&gt;\n\n&lt;p&gt;To ensure future scalability and accommodate the company&amp;#39;s cautious approach to innovation, I aim to build a prototype that not only addresses the immediate need for a dashboard but also lays the foundation for seamless integration with the ERP system. My ultimate goal is to showcase the untapped potential of their data.&lt;/p&gt;\n\n&lt;p&gt;My proposed approach involves loading the CSV files into a database, followed by migration into a data warehouse, and finally using Power BI for visualization. However, I understand that this goes beyond mere data processing; I need to create a robust and scalable infrastructure.&lt;/p&gt;\n\n&lt;p&gt;Given the ambitious timeline of two months, I aim to deliver a solution that not only meets the current requirements but also encourages management to take on future data integration plans. This project will serve as a convincing prototype, illustrating the significant value that can be unlocked through effective data utilization.&lt;/p&gt;\n\n&lt;p&gt;Please experts share with me your holy knowledge on how would you start this project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azx72m", "is_robot_indexable": true, "report_reasons": null, "author": "mahdyy_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azx72m/basic_infrastructure_prototyping_a_scalable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azx72m/basic_infrastructure_prototyping_a_scalable/", "subreddit_subscribers": 163643, "created_utc": 1708891003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working with a finance reporting queries. Let's say I have one table called 'finance_entries'. I am using python in my codebase. I set up a connection to a postgressql dB set up on gcp. \nI need to query this table to get different information such as no_of_transactions (as an int) , invalid_tractions(as a data frame), etc.\n\nWould it be better to have one giant query extracting a data frame/ or view with all my conditions, where I have separate functions to get the data I need from that data frame. \n\nOR\n\nWould it be better to have each function have its own query to the table. \n\nI personally think option 2 is cleaner. Would like everyone's opinion and if possible some supporting resource for the rationale. Because I'm gonna need to convince my manager. \n", "author_fullname": "t2_ng90q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Single query or split queries by function", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azhvje", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708845228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with a finance reporting queries. Let&amp;#39;s say I have one table called &amp;#39;finance_entries&amp;#39;. I am using python in my codebase. I set up a connection to a postgressql dB set up on gcp. \nI need to query this table to get different information such as no_of_transactions (as an int) , invalid_tractions(as a data frame), etc.&lt;/p&gt;\n\n&lt;p&gt;Would it be better to have one giant query extracting a data frame/ or view with all my conditions, where I have separate functions to get the data I need from that data frame. &lt;/p&gt;\n\n&lt;p&gt;OR&lt;/p&gt;\n\n&lt;p&gt;Would it be better to have each function have its own query to the table. &lt;/p&gt;\n\n&lt;p&gt;I personally think option 2 is cleaner. Would like everyone&amp;#39;s opinion and if possible some supporting resource for the rationale. Because I&amp;#39;m gonna need to convince my manager. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azhvje", "is_robot_indexable": true, "report_reasons": null, "author": "Pooop69", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azhvje/single_query_or_split_queries_by_function/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azhvje/single_query_or_split_queries_by_function/", "subreddit_subscribers": 163643, "created_utc": 1708845228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am presenting a data engineering project to an audience that is technical but unfamiliar with the specific topic. I want to cover the usual aspects - business case, data sources, architecture, data transformation/cleaning, validation, etc, basically a summary of the project from inception to delivery.\n\nCan anyone recommend their favorite technical presentations on YouTube that I can watch for some design and content inspiration? I'm specifically interested in talks where someone discusses an actual project (e.g. building some kind of data pipeline) that they worked on rather than a general technical concept  (e.g. how data pipelines work). Thank you!", "author_fullname": "t2_1h1nyytl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any examples of great presentations on data engineering projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b02129", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708902550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am presenting a data engineering project to an audience that is technical but unfamiliar with the specific topic. I want to cover the usual aspects - business case, data sources, architecture, data transformation/cleaning, validation, etc, basically a summary of the project from inception to delivery.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend their favorite technical presentations on YouTube that I can watch for some design and content inspiration? I&amp;#39;m specifically interested in talks where someone discusses an actual project (e.g. building some kind of data pipeline) that they worked on rather than a general technical concept  (e.g. how data pipelines work). Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b02129", "is_robot_indexable": true, "report_reasons": null, "author": "jblue322", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b02129/any_examples_of_great_presentations_on_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b02129/any_examples_of_great_presentations_on_data/", "subreddit_subscribers": 163643, "created_utc": 1708902550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For background, I'm a novice DE working for a large company with low data maturity (at least in my domain). While I'm working on improving my fundamentals (Python, SQL, DevOps) and learning Azure, I'd like to have some quick wins. I've been playing around with Copilot, and it told me about Copilot for Data Science and Data Engineering which was added to Fabric in November. Has anyone used it yet? Worth learning for a novice? I couldn't find any posts on Reddit about it.\n\n[https://learn.microsoft.com/en-us/fabric/get-started/copilot-notebooks-chat-pane](https://learn.microsoft.com/en-us/fabric/get-started/copilot-notebooks-chat-pane?source=docs)", "author_fullname": "t2_hzhwo5em", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Copilot for Data Science and Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azvf2u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708886768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For background, I&amp;#39;m a novice DE working for a large company with low data maturity (at least in my domain). While I&amp;#39;m working on improving my fundamentals (Python, SQL, DevOps) and learning Azure, I&amp;#39;d like to have some quick wins. I&amp;#39;ve been playing around with Copilot, and it told me about Copilot for Data Science and Data Engineering which was added to Fabric in November. Has anyone used it yet? Worth learning for a novice? I couldn&amp;#39;t find any posts on Reddit about it.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/fabric/get-started/copilot-notebooks-chat-pane?source=docs\"&gt;https://learn.microsoft.com/en-us/fabric/get-started/copilot-notebooks-chat-pane&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?auto=webp&amp;s=41fa146938cd97da5abfeff0d092a2cc151e65fa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3881e36da92b82c6947f6ca4ff3804ca47f2aea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17b5b01e50a969ac9e2353bebb062cd52a99d108", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=acadaf004e8aeb6919eabdb0d93065a34f7e89df", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=883009d39175a2f03b76275ed0f7c6011d94a3a7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc62aef83f192d102fa78c83c8f4fcfa85057e3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ca6913f202be9a9f83b266dd459edc90adbf9dd", "width": 1080, "height": 567}], "variants": {}, "id": "RCFh0Kid3SAqWEkALMGNW1e9Vu6ayZpftekoayP00hY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azvf2u", "is_robot_indexable": true, "report_reasons": null, "author": "1085alt0176C", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azvf2u/copilot_for_data_science_and_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azvf2u/copilot_for_data_science_and_data_engineering/", "subreddit_subscribers": 163643, "created_utc": 1708886768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know it's pretty hard to find an entry level job as a data engineer especially lately but I would love to know if there's hope in the dark tunnel and people who managed to get that\n\n\nThanks in advance ", "author_fullname": "t2_hxue1umo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Was your first job as a junior remote?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azs3w5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708878838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s pretty hard to find an entry level job as a data engineer especially lately but I would love to know if there&amp;#39;s hope in the dark tunnel and people who managed to get that&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azs3w5", "is_robot_indexable": true, "report_reasons": null, "author": "Single-Sound-1865", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azs3w5/was_your_first_job_as_a_junior_remote/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azs3w5/was_your_first_job_as_a_junior_remote/", "subreddit_subscribers": 163643, "created_utc": 1708878838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im looking to build a system that aims to provide better ability to create and manage schedules in resource-constrained projects.\n\nWhat I mean by \u201cresource-constrained\u201d is actually kind of interesting when you think about the effects. Let\u2019s say you\u2019re building a house: you can get the flooring guys in and out within a day (maybe). Scale that project to a hotel though, now your flooring guys can only complete several units in a day. This constraint to select spaces is what I mean.\n\nFlooring might be a dependancy of walls though. And roofing might depend on walls. So you end up with task dependancies, and on a resource-constrained schedule that has an effect of causing all tasks to sort of cascade to completion throughout the project.\n\nThis produces a natural grouping of spaces. Spaces can now be grouped based on where tasks will be completed. For example, if spaces 1, 2, and 3 get flooring done on day 1, spaces 1, 2, and 3 would be a grouping. Similarly, space 4. 5, and 6 might get flooring done on day 2 while the wall guys are in spaces 1, 2, and 3. Spaces 4, 5, and 6 would be another grouping.\n\nOne advantageous effect of these groupings is that a manager can reassign a not-on-schedule space to a different group\u2026 a group performing tasks which are more downstream\u2026 in order to put that space back on-schedule. Though this has the adverse effect of making the new grouping\u2019s workload larger for the remaining duration of the project. Also, this kind of adjustment would be impossible for any spaces in the most downstream grouping.\n\nTypically, there\u2019s a project level set of tasks that all spaces inherit. This is good for easing the schedule creation process but might not precisely represent the reality of the project.\n\nTypically, this is managed via an Excel spreadsheet where tasks are laid out as column headers, space groupings as indices, and expected start dates as matrix values. The space groupings are just CSV formatted text of the spaces contained, making recognition easy. Cell formatting is used to indicate completion of a task within a space grouping. This encoding for status is unfortunate because if status between spaces within a group are desynchronized, say because one space is late, there is no good way to represent that on the schedule.\n\nOne benefit the guys using this thing don\u2019t want to give up is the ease of status changes though. They can open the Excel file, highlight the necessary cells, and accurately update the status for hundreds of spaces in a given second, forgoing any desynchronized spaces within their groups.\n\nWhatever the solution, they want better reporting into the overall state of completion and tardiness for all spaces, groupings, and tasks. They also want the data recorded for analysis of historical trends.\n\nSo Im mining these details for design requirements, like how spaces can elegantly swap between groups in order to be put \u201cback on-schedule.\u201d That would suggest that spaces are assigned tasks but not due dates for those tasks. Rather, spaces inherit their task due dates from the space grouping they\u2019re assigned to.\n\nAnyhow, I believe I can build the necessary backend logic, such as the application database. Perhaps even some basic forms to input data, as well as dashboards. As I\u2019m going through this though, the scheduling aspect feels like I\u2019m reinventing the wheel a bit. Secondly, I worry that a complex frontend will need to be built and that is not my expertise.\n\nI\u2019ve tested various less data-engineering solutions like MS Project, figuring those should be good enough. They\u2019re not good enough for various reasons but mostly because none are designed to manage thousands of tasks, spaces, etc. in elegant ways. The work to manage the project becomes too much when using many of these existing tools, especially when they don\u2019t have an API.\n\nEffectively, I\u2019m wondering if there\u2019s a tool or framework that\u2019s better suited for engineering these types of solutions. Handling schedule data in ways that I mention, helping users perform schedule changes and update statuses?\n\nI\u2019m about to build the whole thing from scratch. Are there tools out there to lift off segments of this workload and lighten the burden?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools For Schedule Management Systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azhkj0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708845763.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708844100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking to build a system that aims to provide better ability to create and manage schedules in resource-constrained projects.&lt;/p&gt;\n\n&lt;p&gt;What I mean by \u201cresource-constrained\u201d is actually kind of interesting when you think about the effects. Let\u2019s say you\u2019re building a house: you can get the flooring guys in and out within a day (maybe). Scale that project to a hotel though, now your flooring guys can only complete several units in a day. This constraint to select spaces is what I mean.&lt;/p&gt;\n\n&lt;p&gt;Flooring might be a dependancy of walls though. And roofing might depend on walls. So you end up with task dependancies, and on a resource-constrained schedule that has an effect of causing all tasks to sort of cascade to completion throughout the project.&lt;/p&gt;\n\n&lt;p&gt;This produces a natural grouping of spaces. Spaces can now be grouped based on where tasks will be completed. For example, if spaces 1, 2, and 3 get flooring done on day 1, spaces 1, 2, and 3 would be a grouping. Similarly, space 4. 5, and 6 might get flooring done on day 2 while the wall guys are in spaces 1, 2, and 3. Spaces 4, 5, and 6 would be another grouping.&lt;/p&gt;\n\n&lt;p&gt;One advantageous effect of these groupings is that a manager can reassign a not-on-schedule space to a different group\u2026 a group performing tasks which are more downstream\u2026 in order to put that space back on-schedule. Though this has the adverse effect of making the new grouping\u2019s workload larger for the remaining duration of the project. Also, this kind of adjustment would be impossible for any spaces in the most downstream grouping.&lt;/p&gt;\n\n&lt;p&gt;Typically, there\u2019s a project level set of tasks that all spaces inherit. This is good for easing the schedule creation process but might not precisely represent the reality of the project.&lt;/p&gt;\n\n&lt;p&gt;Typically, this is managed via an Excel spreadsheet where tasks are laid out as column headers, space groupings as indices, and expected start dates as matrix values. The space groupings are just CSV formatted text of the spaces contained, making recognition easy. Cell formatting is used to indicate completion of a task within a space grouping. This encoding for status is unfortunate because if status between spaces within a group are desynchronized, say because one space is late, there is no good way to represent that on the schedule.&lt;/p&gt;\n\n&lt;p&gt;One benefit the guys using this thing don\u2019t want to give up is the ease of status changes though. They can open the Excel file, highlight the necessary cells, and accurately update the status for hundreds of spaces in a given second, forgoing any desynchronized spaces within their groups.&lt;/p&gt;\n\n&lt;p&gt;Whatever the solution, they want better reporting into the overall state of completion and tardiness for all spaces, groupings, and tasks. They also want the data recorded for analysis of historical trends.&lt;/p&gt;\n\n&lt;p&gt;So Im mining these details for design requirements, like how spaces can elegantly swap between groups in order to be put \u201cback on-schedule.\u201d That would suggest that spaces are assigned tasks but not due dates for those tasks. Rather, spaces inherit their task due dates from the space grouping they\u2019re assigned to.&lt;/p&gt;\n\n&lt;p&gt;Anyhow, I believe I can build the necessary backend logic, such as the application database. Perhaps even some basic forms to input data, as well as dashboards. As I\u2019m going through this though, the scheduling aspect feels like I\u2019m reinventing the wheel a bit. Secondly, I worry that a complex frontend will need to be built and that is not my expertise.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tested various less data-engineering solutions like MS Project, figuring those should be good enough. They\u2019re not good enough for various reasons but mostly because none are designed to manage thousands of tasks, spaces, etc. in elegant ways. The work to manage the project becomes too much when using many of these existing tools, especially when they don\u2019t have an API.&lt;/p&gt;\n\n&lt;p&gt;Effectively, I\u2019m wondering if there\u2019s a tool or framework that\u2019s better suited for engineering these types of solutions. Handling schedule data in ways that I mention, helping users perform schedule changes and update statuses?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to build the whole thing from scratch. Are there tools out there to lift off segments of this workload and lighten the burden?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azhkj0", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azhkj0/tools_for_schedule_management_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azhkj0/tools_for_schedule_management_systems/", "subreddit_subscribers": 163643, "created_utc": 1708844100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data geniuses. \n\nWorking currently to Develop a new Dataplatform in Synapse and was wondering if you had any good ideas, on how to implement Incremental Load to our Pipeline. \n\nWe're utilizing the Medallion Architecture with Bronze, Silver &amp; Gold layer like any other. \n\nAll the files we retrieve gets converted to Parquet files in our bronze layer and stored in our Datalake.   \nWhen I look at the functionality in Data Factory can't I come up with a good solution to track Change Data Feed or functionality like AWS Glue Bookmarks. \n\nIt looks like Data Factory functionality is very limited, when you not are using SQL Databases. \n\nWas wondering if I should look into Azure Databricks instead - since it looks like their DLT makes it quite easy to handle Incremental load - but that is something I would need to skill up in and my timeline is limited. ", "author_fullname": "t2_184yei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Incremental Load", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b00r3a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708899488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data geniuses. &lt;/p&gt;\n\n&lt;p&gt;Working currently to Develop a new Dataplatform in Synapse and was wondering if you had any good ideas, on how to implement Incremental Load to our Pipeline. &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re utilizing the Medallion Architecture with Bronze, Silver &amp;amp; Gold layer like any other. &lt;/p&gt;\n\n&lt;p&gt;All the files we retrieve gets converted to Parquet files in our bronze layer and stored in our Datalake.&lt;br/&gt;\nWhen I look at the functionality in Data Factory can&amp;#39;t I come up with a good solution to track Change Data Feed or functionality like AWS Glue Bookmarks. &lt;/p&gt;\n\n&lt;p&gt;It looks like Data Factory functionality is very limited, when you not are using SQL Databases. &lt;/p&gt;\n\n&lt;p&gt;Was wondering if I should look into Azure Databricks instead - since it looks like their DLT makes it quite easy to handle Incremental load - but that is something I would need to skill up in and my timeline is limited. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b00r3a", "is_robot_indexable": true, "report_reasons": null, "author": "TheData_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b00r3a/azure_synapse_incremental_load/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b00r3a/azure_synapse_incremental_load/", "subreddit_subscribers": 163643, "created_utc": 1708899488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, I have asked a question about a similar topic here before and got amazing answers that helped me understand how things work.\n\n  \nNow, I need to understand how to connect my airflow to kubernets (and from what iv heard, this is the hard part).  \nwe have a DevOps team that hosts both airflow env and Kubernetes.  \n**My goal is simple: to print \"Hello world\" using kubernetesPodOperator (just to make sure I connected well)**  \nWhat files/settings in airflow do I need to edit to create this connection between my Kubernetes and my airflow?  \nsome examples I saw online: (airflow) requirements.txt, the connection tab (in airflow UI)  \n\n\nI'm sure there are a lot more, and would like to ask for your help.  \nplease, name everything (and please explain about the file / setting a bit, I am a beginner in this field) that comes to your mind when trying to make this connection.  \n\n\nThanks a lot!  \n", "author_fullname": "t2_w6u9u77n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to connect Kubernetes to airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azxiez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708891759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, I have asked a question about a similar topic here before and got amazing answers that helped me understand how things work.&lt;/p&gt;\n\n&lt;p&gt;Now, I need to understand how to connect my airflow to kubernets (and from what iv heard, this is the hard part).&lt;br/&gt;\nwe have a DevOps team that hosts both airflow env and Kubernetes.&lt;br/&gt;\n&lt;strong&gt;My goal is simple: to print &amp;quot;Hello world&amp;quot; using kubernetesPodOperator (just to make sure I connected well)&lt;/strong&gt;&lt;br/&gt;\nWhat files/settings in airflow do I need to edit to create this connection between my Kubernetes and my airflow?&lt;br/&gt;\nsome examples I saw online: (airflow) requirements.txt, the connection tab (in airflow UI)  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there are a lot more, and would like to ask for your help.&lt;br/&gt;\nplease, name everything (and please explain about the file / setting a bit, I am a beginner in this field) that comes to your mind when trying to make this connection.  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azxiez", "is_robot_indexable": true, "report_reasons": null, "author": "PhilosopherRemote177", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azxiez/how_to_connect_kubernetes_to_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azxiez/how_to_connect_kubernetes_to_airflow/", "subreddit_subscribers": 163643, "created_utc": 1708891759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a slight interest in ontology engineering but wondering if there are DBaaS available that would fit the need? Presumably graph dbs  are going to be a strong match, are there any that match the UX and small scale like supabase or pocketbase, or am I bound to roll my own solution with one of the cloud providers or spring for Neo4j or something?\n\nBeyond, just considering an idea to provide this development service for niche set of clients who are certainly low tech and would need a ton of work to both \u201cdigitize\u201d their works, develop ontologies and digitize/access their sources for creating more work, and using the final systems. Generally full service b2b is going to be too big and expensive - and not designed for their domain. And I can\u2019t expect them to host their own nor maintain their own infra. \n\nMaybe it\u2019d be more something I\u2019d have to host with partitions between clients and charge subscription to keep their data? I\u2019m not thinking that would be a good selling point with this crowd (especially with AI scares in their industries). \n\nMaybe my idea is still too immature. I\u2019m being purposefully vague here. Basically looking for ideas for simple interface graph db or alternatives that are suitable for small scale and low cost ontology engineering.", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suitable databases for ontology engineering projects and recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azvzeo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708888097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a slight interest in ontology engineering but wondering if there are DBaaS available that would fit the need? Presumably graph dbs  are going to be a strong match, are there any that match the UX and small scale like supabase or pocketbase, or am I bound to roll my own solution with one of the cloud providers or spring for Neo4j or something?&lt;/p&gt;\n\n&lt;p&gt;Beyond, just considering an idea to provide this development service for niche set of clients who are certainly low tech and would need a ton of work to both \u201cdigitize\u201d their works, develop ontologies and digitize/access their sources for creating more work, and using the final systems. Generally full service b2b is going to be too big and expensive - and not designed for their domain. And I can\u2019t expect them to host their own nor maintain their own infra. &lt;/p&gt;\n\n&lt;p&gt;Maybe it\u2019d be more something I\u2019d have to host with partitions between clients and charge subscription to keep their data? I\u2019m not thinking that would be a good selling point with this crowd (especially with AI scares in their industries). &lt;/p&gt;\n\n&lt;p&gt;Maybe my idea is still too immature. I\u2019m being purposefully vague here. Basically looking for ideas for simple interface graph db or alternatives that are suitable for small scale and low cost ontology engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azvzeo", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azvzeo/suitable_databases_for_ontology_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azvzeo/suitable_databases_for_ontology_engineering/", "subreddit_subscribers": 163643, "created_utc": 1708888097.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}