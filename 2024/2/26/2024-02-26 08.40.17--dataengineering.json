{"kind": "Listing", "data": {"after": "t3_1b0772d", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey beautiful people, I recently got a data engineering role after trying for a while. It wouldn't have been possible with the support of this group. I would like to thank you guys for this. \nI would like to know what should my next steps be? Though I got the job, i still have that imposter syndrome even though my team members are super supportive. I want to take my learnings to a next level but I feel that I lack the basics so want to start from the very scratch like learning the alphabets.\nSo if you were to start a job in IT, how you would have started? I want to become an engineer in true sense. I am ready to devote sufficient time along with my job. \nSuggestions are most welcome.\n\nThank you!!\nHave a great day!", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Landing a data engineering role with the help of this group", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azl4lz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 65, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708858006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey beautiful people, I recently got a data engineering role after trying for a while. It wouldn&amp;#39;t have been possible with the support of this group. I would like to thank you guys for this. \nI would like to know what should my next steps be? Though I got the job, i still have that imposter syndrome even though my team members are super supportive. I want to take my learnings to a next level but I feel that I lack the basics so want to start from the very scratch like learning the alphabets.\nSo if you were to start a job in IT, how you would have started? I want to become an engineer in true sense. I am ready to devote sufficient time along with my job. \nSuggestions are most welcome.&lt;/p&gt;\n\n&lt;p&gt;Thank you!!\nHave a great day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azl4lz", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azl4lz/landing_a_data_engineering_role_with_the_help_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azl4lz/landing_a_data_engineering_role_with_the_help_of/", "subreddit_subscribers": 163704, "created_utc": 1708858006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have just received an offer for the position of data warehouse engineer for a FinTech based out of UK. The company is working on creating a data team, and i will be a part of it. \n\nI have been working as a data engineer for 1.5 years and rn i am a data engineer in ETL and data migration department of a health care EHR provider. The work here is pretty stale, running old sql scripts, some python work, working on local servers etc.\n\nNow that i have received a job offer, my current employer has matched the offer (slighter higher). My manager has said he will change my team whatever i want he will give me but I don\u2019t believe him much, he is a toxic manager. \n\nI don\u2019t know what to do because the new place will be more challenging, new thing to work on, more independence etc. but will be paid a little less and the hours are 2-10pm and in a remote town away from where i am living (during the probation period for three months, will move to my current city office after that). \n\nHonestly i am in a comfort zone with my current employer. I am almost 25, want to excel in DE domain. I want to be convinced that i need to move to make something out of my career. \n\nEdit\n\nAnother option is i take the counter and look for a better opportunity in the next 3-5 months because ultimately i want to leave my current employer. ", "author_fullname": "t2_4p33upbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Received an offer. Don\u2019t know what to do now. ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azosgr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708872680.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708870205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have just received an offer for the position of data warehouse engineer for a FinTech based out of UK. The company is working on creating a data team, and i will be a part of it. &lt;/p&gt;\n\n&lt;p&gt;I have been working as a data engineer for 1.5 years and rn i am a data engineer in ETL and data migration department of a health care EHR provider. The work here is pretty stale, running old sql scripts, some python work, working on local servers etc.&lt;/p&gt;\n\n&lt;p&gt;Now that i have received a job offer, my current employer has matched the offer (slighter higher). My manager has said he will change my team whatever i want he will give me but I don\u2019t believe him much, he is a toxic manager. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know what to do because the new place will be more challenging, new thing to work on, more independence etc. but will be paid a little less and the hours are 2-10pm and in a remote town away from where i am living (during the probation period for three months, will move to my current city office after that). &lt;/p&gt;\n\n&lt;p&gt;Honestly i am in a comfort zone with my current employer. I am almost 25, want to excel in DE domain. I want to be convinced that i need to move to make something out of my career. &lt;/p&gt;\n\n&lt;p&gt;Edit&lt;/p&gt;\n\n&lt;p&gt;Another option is i take the counter and look for a better opportunity in the next 3-5 months because ultimately i want to leave my current employer. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azosgr", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Law7386", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azosgr/received_an_offer_dont_know_what_to_do_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azosgr/received_an_offer_dont_know_what_to_do_now/", "subreddit_subscribers": 163704, "created_utc": 1708870205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious what you guys see as the romantic market force and best platform. If you had to marry just one? Which is it and why? What does your company use? \n\nThanks. You are deciding my life and future right now. ", "author_fullname": "t2_nb0ef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Marry, F, kill\u2026 databricks, snowflake, ms fabric?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b04b8j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708908509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious what you guys see as the romantic market force and best platform. If you had to marry just one? Which is it and why? What does your company use? &lt;/p&gt;\n\n&lt;p&gt;Thanks. You are deciding my life and future right now. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b04b8j", "is_robot_indexable": true, "report_reasons": null, "author": "JamesGarrison", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b04b8j/marry_f_kill_databricks_snowflake_ms_fabric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b04b8j/marry_f_kill_databricks_snowflake_ms_fabric/", "subreddit_subscribers": 163704, "created_utc": 1708908509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "- List a podcast once as an individual comment\n- if you favorite podcast already listed, like the comment\n- if you host a podcast, list it if not already listed\n- feel free to separately post comments about what you like in a podcast (long or short, conversations/interviews, etc.)", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Listing Data Podcasts (Your Podcast or One You Like)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azvaad", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708886450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;List a podcast once as an individual comment&lt;/li&gt;\n&lt;li&gt;if you favorite podcast already listed, like the comment&lt;/li&gt;\n&lt;li&gt;if you host a podcast, list it if not already listed&lt;/li&gt;\n&lt;li&gt;feel free to separately post comments about what you like in a podcast (long or short, conversations/interviews, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azvaad", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azvaad/listing_data_podcasts_your_podcast_or_one_you_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azvaad/listing_data_podcasts_your_podcast_or_one_you_like/", "subreddit_subscribers": 163704, "created_utc": 1708886450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "   \n\n\nI see that Arrow in general is gaining a lot of popularity. [Meta](https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/)and [Apple](https://thenewstack.io/apple-comet-brings-fast-vector-processing-to-apache-spark/), are building data infrastructure that strongly depended on it.\n\nI am also embracing it as a fundamental piece in our infra.  \nHowever, I see that, at least for Pyarrow, there is a deficit of blogs/tutorials that explain fundamental topics or best practices on how to benefit from it.   \n[I read a book, by Matthew Topol,](https://www.amazon.com/Memory-Analytics-Apache-Arrow-hierarchical/dp/1801071039) that was really informative but still there are many issues that I wish to better understand.\n\n1. What is the difference between pa.Table and RecordBatch and when we should prefer one over another?\n2. How parallelism works in general but especially for pa.compute? Does it assign a core per ChunkedArray? What if I concat many tables and each ChunkedArray is in a different physical location, does it still work with the same strategy? \n3. Pyarrow native Filesystem vs  \u201cthe Python ecosystem Filesystems\u201d. I see in the documents there is a way to work with both, but what is the real difference?  Is there a real drawback to using the Python one? \n\nFor all those issues,  I was able to find some info but not in the level that I expected before integrating it in the production system.   \n\nI wonder why this is and if someone can point me to good resources about those topics?\n\nThanks,  \nLeon", "author_fullname": "t2_ll7atfr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyarrow is popular but lacking of tutorials and resources.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azwb09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708888856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see that Arrow in general is gaining a lot of popularity. &lt;a href=\"https://engineering.fb.com/2024/02/20/developer-tools/velox-apache-arrow-15-composable-data-management/\"&gt;Meta&lt;/a&gt;and &lt;a href=\"https://thenewstack.io/apple-comet-brings-fast-vector-processing-to-apache-spark/\"&gt;Apple&lt;/a&gt;, are building data infrastructure that strongly depended on it.&lt;/p&gt;\n\n&lt;p&gt;I am also embracing it as a fundamental piece in our infra.&lt;br/&gt;\nHowever, I see that, at least for Pyarrow, there is a deficit of blogs/tutorials that explain fundamental topics or best practices on how to benefit from it.&lt;br/&gt;\n&lt;a href=\"https://www.amazon.com/Memory-Analytics-Apache-Arrow-hierarchical/dp/1801071039\"&gt;I read a book, by Matthew Topol,&lt;/a&gt; that was really informative but still there are many issues that I wish to better understand.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What is the difference between pa.Table and RecordBatch and when we should prefer one over another?&lt;/li&gt;\n&lt;li&gt;How parallelism works in general but especially for pa.compute? Does it assign a core per ChunkedArray? What if I concat many tables and each ChunkedArray is in a different physical location, does it still work with the same strategy? &lt;/li&gt;\n&lt;li&gt;Pyarrow native Filesystem vs  \u201cthe Python ecosystem Filesystems\u201d. I see in the documents there is a way to work with both, but what is the real difference?  Is there a real drawback to using the Python one? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For all those issues,  I was able to find some info but not in the level that I expected before integrating it in the production system.   &lt;/p&gt;\n\n&lt;p&gt;I wonder why this is and if someone can point me to good resources about those topics?&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;br/&gt;\nLeon&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?auto=webp&amp;s=44ab0f03ed7f603f8782bbd188e996ad17c77502", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f2085f904a50b3e53975fb7137bec4c25983982", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=000e9a1509c279a23bdac011f0bf3f50b1c25c63", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6088d7b42f1a420908f02ebe9522e78a3693e0ab", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d9bd16fdee41d441ec79d3960e425fb811b5739", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c44265f6811ff5c6dc68d26c531095ca8808679f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/1rQXVsSUb6mExF0pElHDe3KYq0-u1vcu-Pjj3YlfLMk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=907539619f060dd8a859ef77e81ef965224a45a7", "width": 1080, "height": 607}], "variants": {}, "id": "rKGSSC8ZiCD9gbOKh05G5ntySpFbt_LVVJ1vd4XJm9o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azwb09", "is_robot_indexable": true, "report_reasons": null, "author": "Leon_Bam", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azwb09/pyarrow_is_popular_but_lacking_of_tutorials_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azwb09/pyarrow_is_popular_but_lacking_of_tutorials_and/", "subreddit_subscribers": 163704, "created_utc": 1708888856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to transition to a data engineering role (to a DS role later)  from a full-stack developer role (mostly web development).\n\nI have to be honest that my current role is a dead-end and I have no proofs of actually using python etc on the daily, even though we do use SQL from time to time. So, I went back to school to do an Honors degree(1 more year as I graduated in 2020 with a Bachelor's in CS and Math) where I wrote a thesis. I was exposed to a deeper use of the python in the data world. My thesis was in the fields of bioinformatics and realized that I do have an appreciation for data (ETL, Math etc)\n\nI consider myself as a good python and an Ok sql developer. I also have a good understanding of math (linear algebra, statistics etc ). Since my current role has nothing to do with data engineering, I am taking the IBM Data engineering certification. It is a good start but not enough as  I am hoping to be job ready by May. \n\n&amp;#x200B;\n\nMy question is: What certifications, courses and projects should I do so that I can maximize the chance of landing a job? I am in Ontario for reference.", "author_fullname": "t2_kel54afu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What courses/certifications should I do as a sofware developer with 3+ years of experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aztcw0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708881857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to transition to a data engineering role (to a DS role later)  from a full-stack developer role (mostly web development).&lt;/p&gt;\n\n&lt;p&gt;I have to be honest that my current role is a dead-end and I have no proofs of actually using python etc on the daily, even though we do use SQL from time to time. So, I went back to school to do an Honors degree(1 more year as I graduated in 2020 with a Bachelor&amp;#39;s in CS and Math) where I wrote a thesis. I was exposed to a deeper use of the python in the data world. My thesis was in the fields of bioinformatics and realized that I do have an appreciation for data (ETL, Math etc)&lt;/p&gt;\n\n&lt;p&gt;I consider myself as a good python and an Ok sql developer. I also have a good understanding of math (linear algebra, statistics etc ). Since my current role has nothing to do with data engineering, I am taking the IBM Data engineering certification. It is a good start but not enough as  I am hoping to be job ready by May. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is: What certifications, courses and projects should I do so that I can maximize the chance of landing a job? I am in Ontario for reference.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aztcw0", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent_Tough_651", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aztcw0/what_coursescertifications_should_i_do_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aztcw0/what_coursescertifications_should_i_do_as_a/", "subreddit_subscribers": 163704, "created_utc": 1708881857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nURL: https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\n\nI'm excited to share my latest blog post where I delve into the fascinating world of Parquet metadata and its role in optimizing data storage and retrieval. If you're working with big data or interested in efficient data storage techniques, this post is for you!\nIn this blog post, I explore:\n- Deciphering Data Serialization: Unpacking the various types of data serialization, their respective benefits, and how Parquet utilizes them. \n- Understanding Parquet Metadata: I break down what Parquet metadata is, why it's important, and how it contributes to the efficiency of data storage.\n- Metadata Structure: Dive into the nuts and bolts of Parquet metadata structure, including file metadata, row group metadata, and column metadata.\n\nWhether you're a data engineer, data scientist, or just someone curious about how data is stored and managed efficiently, this blog post has something for you.\n\nCheck out the full post [here](https://rr43.net/posts/2024/2/parquet-metadata-dataserde/) and let me know your thoughts in the comments. I'm also open to questions and discussions about Parquet metadata or any related topics!\nHappy reading and happy data exploring! \ud83d\ude80", "author_fullname": "t2_dbozei2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Parquet Metadata: A Deep Dive into Efficient Data Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azy2nt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708893104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;URL: &lt;a href=\"https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\"&gt;https://rr43.net/posts/2024/2/parquet-metadata-dataserde/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to share my latest blog post where I delve into the fascinating world of Parquet metadata and its role in optimizing data storage and retrieval. If you&amp;#39;re working with big data or interested in efficient data storage techniques, this post is for you!\nIn this blog post, I explore:\n- Deciphering Data Serialization: Unpacking the various types of data serialization, their respective benefits, and how Parquet utilizes them. \n- Understanding Parquet Metadata: I break down what Parquet metadata is, why it&amp;#39;s important, and how it contributes to the efficiency of data storage.\n- Metadata Structure: Dive into the nuts and bolts of Parquet metadata structure, including file metadata, row group metadata, and column metadata.&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re a data engineer, data scientist, or just someone curious about how data is stored and managed efficiently, this blog post has something for you.&lt;/p&gt;\n\n&lt;p&gt;Check out the full post &lt;a href=\"https://rr43.net/posts/2024/2/parquet-metadata-dataserde/\"&gt;here&lt;/a&gt; and let me know your thoughts in the comments. I&amp;#39;m also open to questions and discussions about Parquet metadata or any related topics!\nHappy reading and happy data exploring! \ud83d\ude80&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1azy2nt", "is_robot_indexable": true, "report_reasons": null, "author": "InstitutionalizedSon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azy2nt/exploring_parquet_metadata_a_deep_dive_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azy2nt/exploring_parquet_metadata_a_deep_dive_into/", "subreddit_subscribers": 163704, "created_utc": 1708893104.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have problem which I don't really know how to solve properly. I have a table with billions of rows in ClickHouse (will go up to tens of billions). I want to create various analytical charts about subsets of this data (those charts can be updated once a day). Unfortunately those charts are quite complex and most of them need some window functions / cross joins to work properly. For some bigger subsets queries can take more than 1 minute, which is unacceptable (I expect them to work in seconds). Pre-generating  reports for all subsets of data with such queries would probably take a day which is terrible.\n\nI tried solving it with ClickHouse materialized view - I created a view that gives me enough info so that I can easily create all charts in seconds. But it's terrible to manage: it has hundreds of billions of rows, takes up terabytes of storage and takes days to create. I want to get rid of it.\n\nI'm thinking about other solution: next thing I want to try is to just stop writing ClickHouse queries and process my data in RAM. So I would export my whole table (or just changes of it) every day, load it into Python and process it there, maybe using Polars? Or Spark? (although I should be able to fit data in RAM - it would be like 100gb uncompressed) I feel like I would be able to write some simple iteration over my data that would achieve effects of 100 lines of SQL and it would take seconds instead of minutes. I would generate reports for all subsets of data I need and just export it to ClickHouse for access.\n\nSo basically my question is how would you solve such a problem? And if this loading-and-processing data in Python every day is a good idea.  (FYI I'm NOT experienced in Python/Spark etc. so my question might seem silly. But SQL just seems not enough)\n\nEdit: I just wanted to mention that the biggest issue I have with creating queries for this table is that in order to calculate some state for (Category1, Category2, Day) I might need to find entry before Day with (Category1, Category2) if it doesnt exist for given day. My materialized view solved it by just snapshotting full state for each day but it was huge.", "author_fullname": "t2_j3zjmd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Patterns for processing lots of data with window functions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b005l7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708932572.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708898069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have problem which I don&amp;#39;t really know how to solve properly. I have a table with billions of rows in ClickHouse (will go up to tens of billions). I want to create various analytical charts about subsets of this data (those charts can be updated once a day). Unfortunately those charts are quite complex and most of them need some window functions / cross joins to work properly. For some bigger subsets queries can take more than 1 minute, which is unacceptable (I expect them to work in seconds). Pre-generating  reports for all subsets of data with such queries would probably take a day which is terrible.&lt;/p&gt;\n\n&lt;p&gt;I tried solving it with ClickHouse materialized view - I created a view that gives me enough info so that I can easily create all charts in seconds. But it&amp;#39;s terrible to manage: it has hundreds of billions of rows, takes up terabytes of storage and takes days to create. I want to get rid of it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about other solution: next thing I want to try is to just stop writing ClickHouse queries and process my data in RAM. So I would export my whole table (or just changes of it) every day, load it into Python and process it there, maybe using Polars? Or Spark? (although I should be able to fit data in RAM - it would be like 100gb uncompressed) I feel like I would be able to write some simple iteration over my data that would achieve effects of 100 lines of SQL and it would take seconds instead of minutes. I would generate reports for all subsets of data I need and just export it to ClickHouse for access.&lt;/p&gt;\n\n&lt;p&gt;So basically my question is how would you solve such a problem? And if this loading-and-processing data in Python every day is a good idea.  (FYI I&amp;#39;m NOT experienced in Python/Spark etc. so my question might seem silly. But SQL just seems not enough)&lt;/p&gt;\n\n&lt;p&gt;Edit: I just wanted to mention that the biggest issue I have with creating queries for this table is that in order to calculate some state for (Category1, Category2, Day) I might need to find entry before Day with (Category1, Category2) if it doesnt exist for given day. My materialized view solved it by just snapshotting full state for each day but it was huge.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b005l7", "is_robot_indexable": true, "report_reasons": null, "author": "rottensunday", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b005l7/patterns_for_processing_lots_of_data_with_window/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b005l7/patterns_for_processing_lots_of_data_with_window/", "subreddit_subscribers": 163704, "created_utc": 1708898069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm about to start my very first Dbt project and I'd like to do things as best as possible. \n\nDo you guys have an example of a Dbt project that you consider \"clean\" and coded according to the best practices? Could be a blog post, or a Udemy course, or anything as long as it's detailed.\n\nThe project I'm looking to build will be very standard: integration of raw data, with DQ, historization of dimension attributes (SCD2), incremental load on some fact tables, some external Excel files to be ingested, and finally some denormaliezed datasets that will be connected to Tableau.\n\nDo you have anything I could look up to in order to avoid the common pitfalls of Dbt ?\n\nThank you !!\n\n\n\n\n", "author_fullname": "t2_rz2xn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a Dbt Best Practice Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b01klb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708901431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to start my very first Dbt project and I&amp;#39;d like to do things as best as possible. &lt;/p&gt;\n\n&lt;p&gt;Do you guys have an example of a Dbt project that you consider &amp;quot;clean&amp;quot; and coded according to the best practices? Could be a blog post, or a Udemy course, or anything as long as it&amp;#39;s detailed.&lt;/p&gt;\n\n&lt;p&gt;The project I&amp;#39;m looking to build will be very standard: integration of raw data, with DQ, historization of dimension attributes (SCD2), incremental load on some fact tables, some external Excel files to be ingested, and finally some denormaliezed datasets that will be connected to Tableau.&lt;/p&gt;\n\n&lt;p&gt;Do you have anything I could look up to in order to avoid the common pitfalls of Dbt ?&lt;/p&gt;\n\n&lt;p&gt;Thank you !!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b01klb", "is_robot_indexable": true, "report_reasons": null, "author": "Ownards", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b01klb/looking_for_a_dbt_best_practice_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b01klb/looking_for_a_dbt_best_practice_project/", "subreddit_subscribers": 163704, "created_utc": 1708901431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve landed a junior role which has its focus on visualization (pbi). Any tips on how to make the most of it?", "author_fullname": "t2_65m8bm7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get the most of a junior data engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azyg1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708893997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve landed a junior role which has its focus on visualization (pbi). Any tips on how to make the most of it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azyg1q", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic-Video-1595", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azyg1q/how_to_get_the_most_of_a_junior_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azyg1q/how_to_get_the_most_of_a_junior_data_engineering/", "subreddit_subscribers": 163704, "created_utc": 1708893997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n**Introduction**\n\nAs a developer with a passion for music and open-source technologies, I recently created EventMusic Producer, a Dockerized application that reads data and outputs it to a Kafka topic, using Avro schemas for data serialization. This application seamlessly integrates with Kafka and Schema Registry to manage the flow of event data related to music event information.\n\n**Key Features**\n\nEventMusic Producer offers a comprehensive set of features for efficiently managing music event data:\n\n* **Kafka Integration**: Sends event data to Kafka topics for real-time processing and analysis.\n* **Avro Serialization**: Utilizes Avro schemas to serialize event data, ensuring efficiency and data validation.\n* **Docker Support**: Fully Dockerized for easy deployment and scaling in any environment.\n* **Batch Processing**: Sends event data in batches to optimize network usage and processing times.\n* **Flexible Configuration**: Easily configurable using environment variables for Kafka, Schema Registry, and other settings.\n\n**Event Types**\n\nEventMusic Producer supports three types of events:\n\n* **Page View Events**: Generated when users browse a music-related website.\n\n{  \n \"ts\": 151302389,  \n \"sessionId\": \"4301\",  \n \"page\": \"/my-music\",  \n \"auth\": \"Logged Out\",  \n \"method\": \"GET\",  \n \"status\": \"500\",  \n \"level\": \"paid\",  \n \"itemInSession\": \"40\",  \n \"city\": {  \n \"string\": \"Valentin\"  \n },  \n \"zip\": {  \n \"string\": \"11136\"  \n },  \n \"state\": {  \n \"string\": \"\"  \n },  \n \"userAgent\": \"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10\\_7\\_9 rv:6.0; bn-IN) AppleWebKit/533.8.5 (KHTML, like Gecko) Version/4.0.2 Safari/533.8.5\",  \n \"lon\": \"-30.419926\",  \n \"lat\": \"-11.5486195\",  \n \"userId\": \"57982\",  \n \"lastName\": \"Watson\",  \n \"firstName\": \"Courtney\",  \n \"gender\": \"M\",  \n \"registration\": \"337305197\",  \n \"artist\": \"David Bowie\",  \n \"song\": \"Let\u2019s Dance\",  \n \"duration\": \"224.5126215638037\"  \n}\n\n* **Listen Events**: Generated when users listen to songs or albums.\n\nlisten\\_events: {  \n \"artist\": \"The Rolling Stones\",  \n \"song\": \"(I Can\u2019t Get No) Satisfaction\",  \n \"duration\": \"473.79469057974416\",  \n \"ts\": 6678921,  \n \"sessionid\": \"8202\",  \n \"auth\": \"Logged Out\",  \n \"level\": \"free\",  \n \"itemInSession\": \"18\",  \n \"city\": \"New Sandrachester\",  \n \"zip\": \"22955\",  \n \"state\": \"MS\",  \n \"country\": \"US\",  \n \"userAgent\": \"Mozilla/5.0 (iPod; U; CPU iPhone OS 3\\_3 like Mac OS X; hi-IN) AppleWebKit/535.47.6 (KHTML, like Gecko) Version/3.0.5 Mobile/8B118 Safari/6535.47.6\",  \n \"lon\": \"-99.431258\",  \n \"lat\": \"75.0709225\",  \n \"userId\": \"78902\",  \n \"lastName\": \"Williams\",  \n \"firstName\": \"Matthew\",  \n \"gender\": \"M\",  \n \"registration\": \"1584877204\"  \n}\n\n* **Authentication Events**: Generated when users log in or out of a music-related service.\n\nauth\\_events: {  \n \"ts\": 380291172,  \n \"sessionId\": \"6616\",  \n \"level\": \"paid\",  \n \"itemInSession\": \"79\",  \n \"city\": {  \n \"string\": \"West Coletown\"  \n },  \n \"zip\": {  \n \"string\": \"03297\"  \n },  \n \"state\": {  \n \"string\": \"MI\"  \n },  \n \"userAgent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10\\_6\\_5) AppleWebKit/533.1 (KHTML, like Gecko) Chrome/35.0.812.0 Safari/533.1\",  \n \"lon\": \"-95.78613\",  \n \"lat\": \"57.1778745\",  \n \"userId\": \"91224\",  \n \"lastName\": \"Thomas\",  \n \"firstName\": \"Greg\",  \n \"gender\": \"M\",  \n \"registration\": \"341396702\",  \n \"success\": \"False\"  \n}\n\n**Benefits**\n\nEventMusic Producer provides numerous benefits for managing music event data:\n\n* **Easy Deployment and Scaling**: Docker support enables quick deployment and seamless scaling.\n* **Performance Optimization**: Batch processing optimizes network usage and reduces processing times.\n* **Efficient Data Validation**: Avro serialization ensures the integrity and validity of event data.\n* **Flexibility and Customization**: Flexible configuration allows the application to be tailored to specific needs.\n\n**Conclusion**\n\nEventMusic Producer is a valuable tool for developers, data analysts, and music enthusiasts looking to manage and analyze music event data. Its seamless integration with Kafka, efficient Avro serialization, and flexible features make it an ideal solution for real-time applications and data analytics.\n\n**Links**\n\n* Source Code: [https://github.com/Stefen-Taime/eventmusic](https://github.com/Stefen-Taime/eventmusic)\n* Docker Hub Project URL: [https://hub.docker.com/r/stefen2020/eventmusic](https://hub.docker.com/r/stefen2020/eventmusic)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EventMusic Producer: An Open-Source Application for Managing Music Event Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b09m4g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708924644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As a developer with a passion for music and open-source technologies, I recently created EventMusic Producer, a Dockerized application that reads data and outputs it to a Kafka topic, using Avro schemas for data serialization. This application seamlessly integrates with Kafka and Schema Registry to manage the flow of event data related to music event information.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Key Features&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;EventMusic Producer offers a comprehensive set of features for efficiently managing music event data:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Kafka Integration&lt;/strong&gt;: Sends event data to Kafka topics for real-time processing and analysis.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Avro Serialization&lt;/strong&gt;: Utilizes Avro schemas to serialize event data, ensuring efficiency and data validation.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Docker Support&lt;/strong&gt;: Fully Dockerized for easy deployment and scaling in any environment.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Batch Processing&lt;/strong&gt;: Sends event data in batches to optimize network usage and processing times.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Flexible Configuration&lt;/strong&gt;: Easily configurable using environment variables for Kafka, Schema Registry, and other settings.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Event Types&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;EventMusic Producer supports three types of events:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Page View Events&lt;/strong&gt;: Generated when users browse a music-related website.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;{&lt;br/&gt;\n &amp;quot;ts&amp;quot;: 151302389,&lt;br/&gt;\n &amp;quot;sessionId&amp;quot;: &amp;quot;4301&amp;quot;,&lt;br/&gt;\n &amp;quot;page&amp;quot;: &amp;quot;/my-music&amp;quot;,&lt;br/&gt;\n &amp;quot;auth&amp;quot;: &amp;quot;Logged Out&amp;quot;,&lt;br/&gt;\n &amp;quot;method&amp;quot;: &amp;quot;GET&amp;quot;,&lt;br/&gt;\n &amp;quot;status&amp;quot;: &amp;quot;500&amp;quot;,&lt;br/&gt;\n &amp;quot;level&amp;quot;: &amp;quot;paid&amp;quot;,&lt;br/&gt;\n &amp;quot;itemInSession&amp;quot;: &amp;quot;40&amp;quot;,&lt;br/&gt;\n &amp;quot;city&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;Valentin&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;zip&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;11136&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;state&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;userAgent&amp;quot;: &amp;quot;Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_7_9 rv:6.0; bn-IN) AppleWebKit/533.8.5 (KHTML, like Gecko) Version/4.0.2 Safari/533.8.5&amp;quot;,&lt;br/&gt;\n &amp;quot;lon&amp;quot;: &amp;quot;-30.419926&amp;quot;,&lt;br/&gt;\n &amp;quot;lat&amp;quot;: &amp;quot;-11.5486195&amp;quot;,&lt;br/&gt;\n &amp;quot;userId&amp;quot;: &amp;quot;57982&amp;quot;,&lt;br/&gt;\n &amp;quot;lastName&amp;quot;: &amp;quot;Watson&amp;quot;,&lt;br/&gt;\n &amp;quot;firstName&amp;quot;: &amp;quot;Courtney&amp;quot;,&lt;br/&gt;\n &amp;quot;gender&amp;quot;: &amp;quot;M&amp;quot;,&lt;br/&gt;\n &amp;quot;registration&amp;quot;: &amp;quot;337305197&amp;quot;,&lt;br/&gt;\n &amp;quot;artist&amp;quot;: &amp;quot;David Bowie&amp;quot;,&lt;br/&gt;\n &amp;quot;song&amp;quot;: &amp;quot;Let\u2019s Dance&amp;quot;,&lt;br/&gt;\n &amp;quot;duration&amp;quot;: &amp;quot;224.5126215638037&amp;quot;&lt;br/&gt;\n}&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Listen Events&lt;/strong&gt;: Generated when users listen to songs or albums.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;listen_events: {&lt;br/&gt;\n &amp;quot;artist&amp;quot;: &amp;quot;The Rolling Stones&amp;quot;,&lt;br/&gt;\n &amp;quot;song&amp;quot;: &amp;quot;(I Can\u2019t Get No) Satisfaction&amp;quot;,&lt;br/&gt;\n &amp;quot;duration&amp;quot;: &amp;quot;473.79469057974416&amp;quot;,&lt;br/&gt;\n &amp;quot;ts&amp;quot;: 6678921,&lt;br/&gt;\n &amp;quot;sessionid&amp;quot;: &amp;quot;8202&amp;quot;,&lt;br/&gt;\n &amp;quot;auth&amp;quot;: &amp;quot;Logged Out&amp;quot;,&lt;br/&gt;\n &amp;quot;level&amp;quot;: &amp;quot;free&amp;quot;,&lt;br/&gt;\n &amp;quot;itemInSession&amp;quot;: &amp;quot;18&amp;quot;,&lt;br/&gt;\n &amp;quot;city&amp;quot;: &amp;quot;New Sandrachester&amp;quot;,&lt;br/&gt;\n &amp;quot;zip&amp;quot;: &amp;quot;22955&amp;quot;,&lt;br/&gt;\n &amp;quot;state&amp;quot;: &amp;quot;MS&amp;quot;,&lt;br/&gt;\n &amp;quot;country&amp;quot;: &amp;quot;US&amp;quot;,&lt;br/&gt;\n &amp;quot;userAgent&amp;quot;: &amp;quot;Mozilla/5.0 (iPod; U; CPU iPhone OS 3_3 like Mac OS X; hi-IN) AppleWebKit/535.47.6 (KHTML, like Gecko) Version/3.0.5 Mobile/8B118 Safari/6535.47.6&amp;quot;,&lt;br/&gt;\n &amp;quot;lon&amp;quot;: &amp;quot;-99.431258&amp;quot;,&lt;br/&gt;\n &amp;quot;lat&amp;quot;: &amp;quot;75.0709225&amp;quot;,&lt;br/&gt;\n &amp;quot;userId&amp;quot;: &amp;quot;78902&amp;quot;,&lt;br/&gt;\n &amp;quot;lastName&amp;quot;: &amp;quot;Williams&amp;quot;,&lt;br/&gt;\n &amp;quot;firstName&amp;quot;: &amp;quot;Matthew&amp;quot;,&lt;br/&gt;\n &amp;quot;gender&amp;quot;: &amp;quot;M&amp;quot;,&lt;br/&gt;\n &amp;quot;registration&amp;quot;: &amp;quot;1584877204&amp;quot;&lt;br/&gt;\n}&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Authentication Events&lt;/strong&gt;: Generated when users log in or out of a music-related service.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;auth_events: {&lt;br/&gt;\n &amp;quot;ts&amp;quot;: 380291172,&lt;br/&gt;\n &amp;quot;sessionId&amp;quot;: &amp;quot;6616&amp;quot;,&lt;br/&gt;\n &amp;quot;level&amp;quot;: &amp;quot;paid&amp;quot;,&lt;br/&gt;\n &amp;quot;itemInSession&amp;quot;: &amp;quot;79&amp;quot;,&lt;br/&gt;\n &amp;quot;city&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;West Coletown&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;zip&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;03297&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;state&amp;quot;: {&lt;br/&gt;\n &amp;quot;string&amp;quot;: &amp;quot;MI&amp;quot;&lt;br/&gt;\n },&lt;br/&gt;\n &amp;quot;userAgent&amp;quot;: &amp;quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_5) AppleWebKit/533.1 (KHTML, like Gecko) Chrome/35.0.812.0 Safari/533.1&amp;quot;,&lt;br/&gt;\n &amp;quot;lon&amp;quot;: &amp;quot;-95.78613&amp;quot;,&lt;br/&gt;\n &amp;quot;lat&amp;quot;: &amp;quot;57.1778745&amp;quot;,&lt;br/&gt;\n &amp;quot;userId&amp;quot;: &amp;quot;91224&amp;quot;,&lt;br/&gt;\n &amp;quot;lastName&amp;quot;: &amp;quot;Thomas&amp;quot;,&lt;br/&gt;\n &amp;quot;firstName&amp;quot;: &amp;quot;Greg&amp;quot;,&lt;br/&gt;\n &amp;quot;gender&amp;quot;: &amp;quot;M&amp;quot;,&lt;br/&gt;\n &amp;quot;registration&amp;quot;: &amp;quot;341396702&amp;quot;,&lt;br/&gt;\n &amp;quot;success&amp;quot;: &amp;quot;False&amp;quot;&lt;br/&gt;\n}&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Benefits&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;EventMusic Producer provides numerous benefits for managing music event data:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Easy Deployment and Scaling&lt;/strong&gt;: Docker support enables quick deployment and seamless scaling.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Performance Optimization&lt;/strong&gt;: Batch processing optimizes network usage and reduces processing times.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Efficient Data Validation&lt;/strong&gt;: Avro serialization ensures the integrity and validity of event data.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Flexibility and Customization&lt;/strong&gt;: Flexible configuration allows the application to be tailored to specific needs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;EventMusic Producer is a valuable tool for developers, data analysts, and music enthusiasts looking to manage and analyze music event data. Its seamless integration with Kafka, efficient Avro serialization, and flexible features make it an ideal solution for real-time applications and data analytics.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Source Code: &lt;a href=\"https://github.com/Stefen-Taime/eventmusic\"&gt;https://github.com/Stefen-Taime/eventmusic&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Docker Hub Project URL: &lt;a href=\"https://hub.docker.com/r/stefen2020/eventmusic\"&gt;https://hub.docker.com/r/stefen2020/eventmusic&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?auto=webp&amp;s=6ea41bbdb354b573a166bc6d38f2539259bb18f8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ffe54081a924754cf01bfb4a1ea623c0fdef551", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9b9e4e35db8930ef0ef27407a7d06aeb0ef32b4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=abe5294e0289bd8d9194da3a7d9b9540c85a6ea1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a759996a5ee8513cf72c32f3955bb7a6bf2e987e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d688168a4212cdb91be81f9805ccf457258ce95d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5Mpf_5iEhexkrFK8aVpQgjJqregrCb26-zhpAoSDesk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e281991bee112258ea88fe5b1541a58234eea85a", "width": 1080, "height": 540}], "variants": {}, "id": "9OtvRzUFOuuWyX-6JGGTFrr2d7OU05-Ngkc80mkeQ7k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1b09m4g", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b09m4g/eventmusic_producer_an_opensource_application_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b09m4g/eventmusic_producer_an_opensource_application_for/", "subreddit_subscribers": 163704, "created_utc": 1708924644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, quick question. I'm trying to understand the differences between a Data Lake and a Data Warehouse. Can you store unstructured data in snowflake (like pictures, audio etc)? If yes, is Snowflake a DW or a DL?\n\nLastly, can the same tool be called a DW or a DL depending on your store data in that tool (structured vs unstructured)?\n\nThanks so much!", "author_fullname": "t2_a4d2j3fh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake - Data Lake or Data Warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azvbd8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708886524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, quick question. I&amp;#39;m trying to understand the differences between a Data Lake and a Data Warehouse. Can you store unstructured data in snowflake (like pictures, audio etc)? If yes, is Snowflake a DW or a DL?&lt;/p&gt;\n\n&lt;p&gt;Lastly, can the same tool be called a DW or a DL depending on your store data in that tool (structured vs unstructured)?&lt;/p&gt;\n\n&lt;p&gt;Thanks so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azvbd8", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Nobody-2727", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azvbd8/snowflake_data_lake_or_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azvbd8/snowflake_data_lake_or_data_warehouse/", "subreddit_subscribers": 163704, "created_utc": 1708886524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm currently embarking on a project to revamp customer segmentation for an e-commerce company.\n\nWe've got lots of data already, but I'm not sure what exactly I need to make this work well. Figuring out customer groups helps us make shopping better for everyone.\n\nHere's what I'm wondering:\n\n1. **Important Data Stuff:** What kind of information should we have in our data to understand our customers better?\n2. **Fixing Data:** How can we make sure the data we have is good enough to help us understand our customers?\n3. **Good Ways to Sort Customers:** Do you know any good tricks or tools to help us figure out what groups our customers belong to?\n4. **Checking if it Works:** Once we have our groups, how can we tell if they're helping us make shopping better?\n\nWe've got loads of data, but making sense of it all is tough. I'd really appreciate any advice you can give. Whether it's from your job, what you've learned, or just good ideas, I'm all ears. Thanks a bunch for your help!", "author_fullname": "t2_6laijtqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Customer Segmentation for E-commerce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aztu7p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708883006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently embarking on a project to revamp customer segmentation for an e-commerce company.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve got lots of data already, but I&amp;#39;m not sure what exactly I need to make this work well. Figuring out customer groups helps us make shopping better for everyone.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;m wondering:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Important Data Stuff:&lt;/strong&gt; What kind of information should we have in our data to understand our customers better?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fixing Data:&lt;/strong&gt; How can we make sure the data we have is good enough to help us understand our customers?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Good Ways to Sort Customers:&lt;/strong&gt; Do you know any good tricks or tools to help us figure out what groups our customers belong to?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Checking if it Works:&lt;/strong&gt; Once we have our groups, how can we tell if they&amp;#39;re helping us make shopping better?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We&amp;#39;ve got loads of data, but making sense of it all is tough. I&amp;#39;d really appreciate any advice you can give. Whether it&amp;#39;s from your job, what you&amp;#39;ve learned, or just good ideas, I&amp;#39;m all ears. Thanks a bunch for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aztu7p", "is_robot_indexable": true, "report_reasons": null, "author": "Appropriate_Union_58", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aztu7p/seeking_advice_on_customer_segmentation_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aztu7p/seeking_advice_on_customer_segmentation_for/", "subreddit_subscribers": 163704, "created_utc": 1708883006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nI currently work as a BI Engineer, and I am so interested about ML engineering that I started learning about Data Engineering (gcp, docker, terraform Python, spark, airflow etc ) as I think it might take me closer to ML. \n\nI finally got an an offer as a Data Engineer, but it\u2019s in the banking industry, mainly ETL and informatica. \n\nNow I am not sure is this taking me closer even to Data Engineering as I am learning it now? \n\nIt\u2019s also worth to mention that this offer is only 2k above my current salary. I would have taking it if it\u2019s data engineering using the toold I mentioned above. \n\nBut this way I am afraid I\u2019d be stuck in etl developement using informatica! \n\nAt the same time I am afraid that this\u2019s an opportunity into DE that I will miss. \n\nPlease give me your honest advice\u2026", "author_fullname": "t2_6or8m0hm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So confused whether to take this DE opportunity or wait for a better pne", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azt074", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708881002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I currently work as a BI Engineer, and I am so interested about ML engineering that I started learning about Data Engineering (gcp, docker, terraform Python, spark, airflow etc ) as I think it might take me closer to ML. &lt;/p&gt;\n\n&lt;p&gt;I finally got an an offer as a Data Engineer, but it\u2019s in the banking industry, mainly ETL and informatica. &lt;/p&gt;\n\n&lt;p&gt;Now I am not sure is this taking me closer even to Data Engineering as I am learning it now? &lt;/p&gt;\n\n&lt;p&gt;It\u2019s also worth to mention that this offer is only 2k above my current salary. I would have taking it if it\u2019s data engineering using the toold I mentioned above. &lt;/p&gt;\n\n&lt;p&gt;But this way I am afraid I\u2019d be stuck in etl developement using informatica! &lt;/p&gt;\n\n&lt;p&gt;At the same time I am afraid that this\u2019s an opportunity into DE that I will miss. &lt;/p&gt;\n\n&lt;p&gt;Please give me your honest advice\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1azt074", "is_robot_indexable": true, "report_reasons": null, "author": "Judessaa", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azt074/so_confused_whether_to_take_this_de_opportunity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azt074/so_confused_whether_to_take_this_de_opportunity/", "subreddit_subscribers": 163704, "created_utc": 1708881002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've had an interesting discussion this week that got me thinking on the utility of feature stores in MLOps. I was wondering how you think about this.\n\nFor a long time I thought feature stores mainly target online (real-time) prediction workloads. You want fast access to the current version of a feature (the \"online\" layer) during inference, bulk access to data during training (offline layer), and wish that your inference and training API are the same so you can share code paths.\n\nHowever, now I realized that feature stores also advertise their \"time-travel\" capability, i.e., they have a built-in SCD mechanism to allow you to train on consistent snapshots of historical data.\n\nDid I missunderstand the purpose of a feature store and the \"killer feature\" isnt the fast cache of the latest version of a record, but rather the built-in SCD? Is CDC capture via SCD a common feature of a feature store?", "author_fullname": "t2_frdb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did i missunderstand feature stores?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azm6q1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708923186.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708862028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had an interesting discussion this week that got me thinking on the utility of feature stores in MLOps. I was wondering how you think about this.&lt;/p&gt;\n\n&lt;p&gt;For a long time I thought feature stores mainly target online (real-time) prediction workloads. You want fast access to the current version of a feature (the &amp;quot;online&amp;quot; layer) during inference, bulk access to data during training (offline layer), and wish that your inference and training API are the same so you can share code paths.&lt;/p&gt;\n\n&lt;p&gt;However, now I realized that feature stores also advertise their &amp;quot;time-travel&amp;quot; capability, i.e., they have a built-in SCD mechanism to allow you to train on consistent snapshots of historical data.&lt;/p&gt;\n\n&lt;p&gt;Did I missunderstand the purpose of a feature store and the &amp;quot;killer feature&amp;quot; isnt the fast cache of the latest version of a record, but rather the built-in SCD? Is CDC capture via SCD a common feature of a feature store?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azm6q1", "is_robot_indexable": true, "report_reasons": null, "author": "FirefoxMetzger", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azm6q1/did_i_missunderstand_feature_stores/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azm6q1/did_i_missunderstand_feature_stores/", "subreddit_subscribers": 163704, "created_utc": 1708862028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a pipeline i use foreachbatch for writing one stream to different sinks. I have the feeling this is not really considered best practice because it kind of feels like perverting streaming principles to enforce a type of batch processing\u2026 what are your experiences with foreaxhbatch or how do you handle such kind of problems? \n", "author_fullname": "t2_q4hy00qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Streaming - foreachBatch bad practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azlz5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708861221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a pipeline i use foreachbatch for writing one stream to different sinks. I have the feeling this is not really considered best practice because it kind of feels like perverting streaming principles to enforce a type of batch processing\u2026 what are your experiences with foreaxhbatch or how do you handle such kind of problems? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azlz5r", "is_robot_indexable": true, "report_reasons": null, "author": "ShipWild9022", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azlz5r/spark_streaming_foreachbatch_bad_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azlz5r/spark_streaming_foreachbatch_bad_practice/", "subreddit_subscribers": 163704, "created_utc": 1708861221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data geniuses. \n\nWorking currently to Develop a new Dataplatform in Synapse and was wondering if you had any good ideas, on how to implement Incremental Load to our Pipeline. \n\nWe're utilizing the Medallion Architecture with Bronze, Silver &amp; Gold layer like any other. \n\nAll the files we retrieve gets converted to Parquet files in our bronze layer and stored in our Datalake.   \nWhen I look at the functionality in Data Factory can't I come up with a good solution to track Change Data Feed or functionality like AWS Glue Bookmarks. \n\nIt looks like Data Factory functionality is very limited, when you not are using SQL Databases. \n\nWas wondering if I should look into Azure Databricks instead - since it looks like their DLT makes it quite easy to handle Incremental load - but that is something I would need to skill up in and my timeline is limited. ", "author_fullname": "t2_184yei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Incremental Load", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b00r3a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708899488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data geniuses. &lt;/p&gt;\n\n&lt;p&gt;Working currently to Develop a new Dataplatform in Synapse and was wondering if you had any good ideas, on how to implement Incremental Load to our Pipeline. &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re utilizing the Medallion Architecture with Bronze, Silver &amp;amp; Gold layer like any other. &lt;/p&gt;\n\n&lt;p&gt;All the files we retrieve gets converted to Parquet files in our bronze layer and stored in our Datalake.&lt;br/&gt;\nWhen I look at the functionality in Data Factory can&amp;#39;t I come up with a good solution to track Change Data Feed or functionality like AWS Glue Bookmarks. &lt;/p&gt;\n\n&lt;p&gt;It looks like Data Factory functionality is very limited, when you not are using SQL Databases. &lt;/p&gt;\n\n&lt;p&gt;Was wondering if I should look into Azure Databricks instead - since it looks like their DLT makes it quite easy to handle Incremental load - but that is something I would need to skill up in and my timeline is limited. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b00r3a", "is_robot_indexable": true, "report_reasons": null, "author": "TheData_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b00r3a/azure_synapse_incremental_load/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b00r3a/azure_synapse_incremental_load/", "subreddit_subscribers": 163704, "created_utc": 1708899488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am embarking on a new internship for my end-of-studies project at a major production unit. The company relies on an ERP system that generates substantial data, but currently lacks a data infrastructure. The primary objective is to develop a real-time dashboard, utilizing three Excel files as the initial data source.\n\nTo ensure future scalability and accommodate the company's cautious approach to innovation, I aim to build a prototype that not only addresses the immediate need for a dashboard but also lays the foundation for seamless integration with the ERP system. My ultimate goal is to showcase the untapped potential of their data.\n\nMy proposed approach involves loading the CSV files into a database, followed by migration into a data warehouse, and finally using Power BI for visualization. However, I understand that this goes beyond mere data processing; I need to create a robust and scalable infrastructure.\n\nGiven the ambitious timeline of two months, I aim to deliver a solution that not only meets the current requirements but also encourages management to take on future data integration plans. This project will serve as a convincing prototype, illustrating the significant value that can be unlocked through effective data utilization.\n\nPlease experts share with me your holy knowledge on how would you start this project.", "author_fullname": "t2_5ycsuz07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic Infrastructure : Prototyping a Scalable Solution in 8 Weeks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azx72m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708891003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am embarking on a new internship for my end-of-studies project at a major production unit. The company relies on an ERP system that generates substantial data, but currently lacks a data infrastructure. The primary objective is to develop a real-time dashboard, utilizing three Excel files as the initial data source.&lt;/p&gt;\n\n&lt;p&gt;To ensure future scalability and accommodate the company&amp;#39;s cautious approach to innovation, I aim to build a prototype that not only addresses the immediate need for a dashboard but also lays the foundation for seamless integration with the ERP system. My ultimate goal is to showcase the untapped potential of their data.&lt;/p&gt;\n\n&lt;p&gt;My proposed approach involves loading the CSV files into a database, followed by migration into a data warehouse, and finally using Power BI for visualization. However, I understand that this goes beyond mere data processing; I need to create a robust and scalable infrastructure.&lt;/p&gt;\n\n&lt;p&gt;Given the ambitious timeline of two months, I aim to deliver a solution that not only meets the current requirements but also encourages management to take on future data integration plans. This project will serve as a convincing prototype, illustrating the significant value that can be unlocked through effective data utilization.&lt;/p&gt;\n\n&lt;p&gt;Please experts share with me your holy knowledge on how would you start this project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azx72m", "is_robot_indexable": true, "report_reasons": null, "author": "mahdyy_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azx72m/basic_infrastructure_prototyping_a_scalable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azx72m/basic_infrastructure_prototyping_a_scalable/", "subreddit_subscribers": 163704, "created_utc": 1708891003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know it's pretty hard to find an entry level job as a data engineer especially lately but I would love to know if there's hope in the dark tunnel and people who managed to get that\n\n\nThanks in advance ", "author_fullname": "t2_hxue1umo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Was your first job as a junior remote?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azs3w5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708878838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s pretty hard to find an entry level job as a data engineer especially lately but I would love to know if there&amp;#39;s hope in the dark tunnel and people who managed to get that&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1azs3w5", "is_robot_indexable": true, "report_reasons": null, "author": "Single-Sound-1865", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azs3w5/was_your_first_job_as_a_junior_remote/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azs3w5/was_your_first_job_as_a_junior_remote/", "subreddit_subscribers": 163704, "created_utc": 1708878838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, \nBased in London I am a founding engineer in a early stage startup, we've been building a MVP for a year at my work (haven't sold and no real clients/users). It's a niche game changer (as per the demo-ers of product) in fintech for analysts specially. \n\nIt wasn't easy at first but my CEO and I together designed an ETL kind of system for that using all fancy tech(dagster, timescale cloud) . Streamlined the data investigation/QA process with python and started ingestion, it took a while (about 5 months ) just to get the process ready. \n\nNow for the last three months I have been manually cherry picking data to upload in the dB using  excel sheets from our source database (OECD/IMF and such). \n\nI am on a visa in UK so I cannot afford to not have a job (as in take a break and prepare/look for new job at my own pace) and I also need to find a sponsorship before my visa expires. The reason I am not feeling confident to apply for DE roles is that I have worked with big data framework like Hadoop and Spark at uni only and on my own pet project very little but haven't done so in a professional setting. \n\nI have been learning Data bricks/DBT one step at a time in my free time but haven't gotten the bigger pictureon their implication.Been reading \"Foundation of data engineering\" and \"Designing data intensive applications\". Basically as much I can after working 12hrs a day.\n\nSo bottom line, my question to all the nice people of this sub is would it be worth it for me to learn data modelling properly, sharpen my sql and learn the mordern datastack and apply for only DE job or should I rather just go and have a general approach where I do the job my skills can get my right away. \n\nIf you've read this far a word of advice would mean a lot. \n\nThank you", "author_fullname": "t2_cdqy9ph6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice/suggestion on my next switch as an Data Engineer.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b07n9i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708918215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, \nBased in London I am a founding engineer in a early stage startup, we&amp;#39;ve been building a MVP for a year at my work (haven&amp;#39;t sold and no real clients/users). It&amp;#39;s a niche game changer (as per the demo-ers of product) in fintech for analysts specially. &lt;/p&gt;\n\n&lt;p&gt;It wasn&amp;#39;t easy at first but my CEO and I together designed an ETL kind of system for that using all fancy tech(dagster, timescale cloud) . Streamlined the data investigation/QA process with python and started ingestion, it took a while (about 5 months ) just to get the process ready. &lt;/p&gt;\n\n&lt;p&gt;Now for the last three months I have been manually cherry picking data to upload in the dB using  excel sheets from our source database (OECD/IMF and such). &lt;/p&gt;\n\n&lt;p&gt;I am on a visa in UK so I cannot afford to not have a job (as in take a break and prepare/look for new job at my own pace) and I also need to find a sponsorship before my visa expires. The reason I am not feeling confident to apply for DE roles is that I have worked with big data framework like Hadoop and Spark at uni only and on my own pet project very little but haven&amp;#39;t done so in a professional setting. &lt;/p&gt;\n\n&lt;p&gt;I have been learning Data bricks/DBT one step at a time in my free time but haven&amp;#39;t gotten the bigger pictureon their implication.Been reading &amp;quot;Foundation of data engineering&amp;quot; and &amp;quot;Designing data intensive applications&amp;quot;. Basically as much I can after working 12hrs a day.&lt;/p&gt;\n\n&lt;p&gt;So bottom line, my question to all the nice people of this sub is would it be worth it for me to learn data modelling properly, sharpen my sql and learn the mordern datastack and apply for only DE job or should I rather just go and have a general approach where I do the job my skills can get my right away. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve read this far a word of advice would mean a lot. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b07n9i", "is_robot_indexable": true, "report_reasons": null, "author": "miloplyat", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b07n9i/looking_for_advicesuggestion_on_my_next_switch_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b07n9i/looking_for_advicesuggestion_on_my_next_switch_as/", "subreddit_subscribers": 163704, "created_utc": 1708918215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am presenting a data engineering project to an audience that is technical but unfamiliar with the specific topic. I want to cover the usual aspects - business case, data sources, architecture, data transformation/cleaning, validation, etc, basically a summary of the project from inception to delivery.\n\nCan anyone recommend their favorite technical presentations on YouTube that I can watch for some design and content inspiration? I'm specifically interested in talks where someone discusses an actual project (e.g. building some kind of data pipeline) that they worked on rather than a general technical concept  (e.g. how data pipelines work). Thank you!", "author_fullname": "t2_1h1nyytl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any examples of great presentations on data engineering projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b02129", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708902550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am presenting a data engineering project to an audience that is technical but unfamiliar with the specific topic. I want to cover the usual aspects - business case, data sources, architecture, data transformation/cleaning, validation, etc, basically a summary of the project from inception to delivery.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend their favorite technical presentations on YouTube that I can watch for some design and content inspiration? I&amp;#39;m specifically interested in talks where someone discusses an actual project (e.g. building some kind of data pipeline) that they worked on rather than a general technical concept  (e.g. how data pipelines work). Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b02129", "is_robot_indexable": true, "report_reasons": null, "author": "jblue322", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b02129/any_examples_of_great_presentations_on_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b02129/any_examples_of_great_presentations_on_data/", "subreddit_subscribers": 163704, "created_utc": 1708902550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, I have asked a question about a similar topic here before and got amazing answers that helped me understand how things work.\n\n  \nNow, I need to understand how to connect my airflow to kubernets (and from what iv heard, this is the hard part).  \nwe have a DevOps team that hosts both airflow env and Kubernetes.  \n**My goal is simple: to print \"Hello world\" using kubernetesPodOperator (just to make sure I connected well)**  \nWhat files/settings in airflow do I need to edit to create this connection between my Kubernetes and my airflow?  \nsome examples I saw online: (airflow) requirements.txt, the connection tab (in airflow UI)  \n\n\nI'm sure there are a lot more, and would like to ask for your help.  \nplease, name everything (and please explain about the file / setting a bit, I am a beginner in this field) that comes to your mind when trying to make this connection.  \n\n\nThanks a lot!  \n", "author_fullname": "t2_w6u9u77n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to connect Kubernetes to airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1azxiez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708891759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, I have asked a question about a similar topic here before and got amazing answers that helped me understand how things work.&lt;/p&gt;\n\n&lt;p&gt;Now, I need to understand how to connect my airflow to kubernets (and from what iv heard, this is the hard part).&lt;br/&gt;\nwe have a DevOps team that hosts both airflow env and Kubernetes.&lt;br/&gt;\n&lt;strong&gt;My goal is simple: to print &amp;quot;Hello world&amp;quot; using kubernetesPodOperator (just to make sure I connected well)&lt;/strong&gt;&lt;br/&gt;\nWhat files/settings in airflow do I need to edit to create this connection between my Kubernetes and my airflow?&lt;br/&gt;\nsome examples I saw online: (airflow) requirements.txt, the connection tab (in airflow UI)  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there are a lot more, and would like to ask for your help.&lt;br/&gt;\nplease, name everything (and please explain about the file / setting a bit, I am a beginner in this field) that comes to your mind when trying to make this connection.  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1azxiez", "is_robot_indexable": true, "report_reasons": null, "author": "PhilosopherRemote177", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1azxiez/how_to_connect_kubernetes_to_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1azxiez/how_to_connect_kubernetes_to_airflow/", "subreddit_subscribers": 163704, "created_utc": 1708891759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We extract data using Talend from multiple tables in Oracle DB, Salesforce and load it in Redshift. There is no transformation in the process. Just extract and load. We perform the transformations once it is in redshift. We want to replace talend with another tool/technology and would like to know suggestions for this. I wish to not use low code tools for this because I believe it might hamper my learning/career. Which technology should I use if I want to the tick off the three things below :\n1. Well suited and less complex \n2. Good learning and skill development by getting exposed to state of the art DE/SWE tool/tech\n3. I want to have an option of moving to SWE so I want to use this opportunity for learning SWE skills which will help me market myself as an SWE once I am active in the job market ", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b0bhh1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708931474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We extract data using Talend from multiple tables in Oracle DB, Salesforce and load it in Redshift. There is no transformation in the process. Just extract and load. We perform the transformations once it is in redshift. We want to replace talend with another tool/technology and would like to know suggestions for this. I wish to not use low code tools for this because I believe it might hamper my learning/career. Which technology should I use if I want to the tick off the three things below :\n1. Well suited and less complex \n2. Good learning and skill development by getting exposed to state of the art DE/SWE tool/tech\n3. I want to have an option of moving to SWE so I want to use this opportunity for learning SWE skills which will help me market myself as an SWE once I am active in the job market &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b0bhh1", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0bhh1/elt_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0bhh1/elt_options/", "subreddit_subscribers": 163704, "created_utc": 1708931474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am running multiple flink jobs in one yarn session and all the logs are written in \"taskmanager.log\" and \"job manager.log\" files which makes it difficult to check logs of a specific job. Is there any way to create seperate log files for each flink job?", "author_fullname": "t2_rckks0bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache flink logs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b09p0n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708924919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running multiple flink jobs in one yarn session and all the logs are written in &amp;quot;taskmanager.log&amp;quot; and &amp;quot;job manager.log&amp;quot; files which makes it difficult to check logs of a specific job. Is there any way to create seperate log files for each flink job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b09p0n", "is_robot_indexable": true, "report_reasons": null, "author": "TKMater", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b09p0n/apache_flink_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b09p0n/apache_flink_logs/", "subreddit_subscribers": 163704, "created_utc": 1708924919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here are some of my higher-level tables:\n\n    CREATE TABLE workcenter_task (\n        id SERIAL PRIMARY KEY,\n        workcenter_id INT,\n        task_id INT\n    );\n    \n    CREATE TABLE space_task (\n        id SERIAL PRIMARY KEY,\n        space_id INT,\n        task_id INT\n    );\n    \n    CREATE TABLE workcenter_space (\n        id SERIAL PRIMARY KEY,\n        workcenter_id INT,\n        space_id INT,\n    \n        CONSTRAINT chk_space_task_workcenter \n            CHECK (NOT EXISTS (\n                SELECT 1\n                FROM space_task st\n                LEFT JOIN workcenter_task wt ON st.task_id = wt.task_id\n                WHERE st.space_id = workcenter_space.space_id\n                AND wt.workcenter_id != workcenter_space.workcenter_id\n            ))\n    );\n    \n\nNotice the \\`chk\\_space\\_task\\_workcenter\\` constraint. It is designed to make sure, on insert, that the newly inserted workcenter contains all tasks associated with the newly inserted space. If the space is assigned a task (within \\`space\\_task\\`) that the workcenter does not also have assigned to it (within \\`workcenter\\_task\\`), the insert should fail.\n\n&amp;#x200B;\n\nThis is great for maintaining integrity on insert, but it does very little to maintain integrity after that point. For example, a user could satisfy the requirements for insert but then delete the record in \\`workcenter\\_task\\` that allowed the insert in the first place. This is a violation of system integrity.\n\n&amp;#x200B;\n\nWould something like a partial index be usable for my desired outcome, such that a user can not make this type of violation? I want to avoid triggers because I understand they can get out of hand over time. Would this work : ?  \n\n\n    CREATE UNIQUE INDEX idx_space_task_workcenter\n    ON workcenter_space (space_id)\n    WHERE NOT EXISTS (\n        SELECT 1\n        FROM space_task st\n        LEFT JOIN workcenter_task wt ON st.task_id = wt.task_id\n        WHERE st.space_id = workcenter_space.space_id\n        AND wt.workcenter_id != workcenter_space.workcenter_id\n    );\n\nI'm not sure if this work be considered reliable and guarantee that users can not violate the relationship where a workcenter must always have the tasks associated with it that can be found in any one of its associated spaces.  \n\n\nCan someone levy in on this approach? Thanks! I am using postgres.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrity of Partial Indexes for Complex Relationships Between Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b0772d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708917855.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708916831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here are some of my higher-level tables:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE TABLE workcenter_task (\n    id SERIAL PRIMARY KEY,\n    workcenter_id INT,\n    task_id INT\n);\n\nCREATE TABLE space_task (\n    id SERIAL PRIMARY KEY,\n    space_id INT,\n    task_id INT\n);\n\nCREATE TABLE workcenter_space (\n    id SERIAL PRIMARY KEY,\n    workcenter_id INT,\n    space_id INT,\n\n    CONSTRAINT chk_space_task_workcenter \n        CHECK (NOT EXISTS (\n            SELECT 1\n            FROM space_task st\n            LEFT JOIN workcenter_task wt ON st.task_id = wt.task_id\n            WHERE st.space_id = workcenter_space.space_id\n            AND wt.workcenter_id != workcenter_space.workcenter_id\n        ))\n);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Notice the `chk_space_task_workcenter` constraint. It is designed to make sure, on insert, that the newly inserted workcenter contains all tasks associated with the newly inserted space. If the space is assigned a task (within `space_task`) that the workcenter does not also have assigned to it (within `workcenter_task`), the insert should fail.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is great for maintaining integrity on insert, but it does very little to maintain integrity after that point. For example, a user could satisfy the requirements for insert but then delete the record in `workcenter_task` that allowed the insert in the first place. This is a violation of system integrity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would something like a partial index be usable for my desired outcome, such that a user can not make this type of violation? I want to avoid triggers because I understand they can get out of hand over time. Would this work : ?  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE UNIQUE INDEX idx_space_task_workcenter\nON workcenter_space (space_id)\nWHERE NOT EXISTS (\n    SELECT 1\n    FROM space_task st\n    LEFT JOIN workcenter_task wt ON st.task_id = wt.task_id\n    WHERE st.space_id = workcenter_space.space_id\n    AND wt.workcenter_id != workcenter_space.workcenter_id\n);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if this work be considered reliable and guarantee that users can not violate the relationship where a workcenter must always have the tasks associated with it that can be found in any one of its associated spaces.  &lt;/p&gt;\n\n&lt;p&gt;Can someone levy in on this approach? Thanks! I am using postgres.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b0772d", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b0772d/integrity_of_partial_indexes_for_complex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b0772d/integrity_of_partial_indexes_for_complex/", "subreddit_subscribers": 163704, "created_utc": 1708916831.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}