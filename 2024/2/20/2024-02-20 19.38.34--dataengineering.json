{"kind": "Listing", "data": {"after": "t3_1avh111", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\"Data Engineer\" is a horribly esoteric job title which tends to result in a lot of blank stares and confused looks from all the \"normal\" people in my life. How do you describe data engineering to normal folk in as few sentences as possible?\n\nMy favourite: \"I'm like a plumber for data, i.e. I do for number and computers what a plumber does for water and toilets.\"", "author_fullname": "t2_6mxelrxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you describe your job to normies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auwziw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708372901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Data Engineer&amp;quot; is a horribly esoteric job title which tends to result in a lot of blank stares and confused looks from all the &amp;quot;normal&amp;quot; people in my life. How do you describe data engineering to normal folk in as few sentences as possible?&lt;/p&gt;\n\n&lt;p&gt;My favourite: &amp;quot;I&amp;#39;m like a plumber for data, i.e. I do for number and computers what a plumber does for water and toilets.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1auwziw", "is_robot_indexable": true, "report_reasons": null, "author": "Creyke", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auwziw/how_do_you_describe_your_job_to_normies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auwziw/how_do_you_describe_your_job_to_normies/", "subreddit_subscribers": 162285, "created_utc": 1708372901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I start, this is hooks (pre_hooks and post_hooks) allowing to run any sql code on your DB !", "author_fullname": "t2_ie6cij4nf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the DBT function you discovered recently and you use everywhere?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auwjek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708371894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I start, this is hooks (pre_hooks and post_hooks) allowing to run any sql code on your DB !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1auwjek", "is_robot_indexable": true, "report_reasons": null, "author": "Advanced_Addition321", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auwjek/what_is_the_dbt_function_you_discovered_recently/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auwjek/what_is_the_dbt_function_you_discovered_recently/", "subreddit_subscribers": 162285, "created_utc": 1708371894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last week I was hired as a Data Analyst at a small 200 employees company and the expectations for my role are to automate a lot of manually generated reports, and also build dashboards to provide insights to Sales, Marketing, Product teams. \n\nI found out there is absolutely **no data and analytics infrastructure**!! The reporting is based solely on Salesforce reports exported to Gsheets and a lot of manual formulas and calcs. \n\nWhat would be a low-cost tool or tools that let me build ETLs pulling data mostly from Salesforce and build custom queries for dashboards that I would build in Looker? The main source of data will be Salesforce, but would want to include others like Gainsight, NetSuite, HubSpot, Google Analytics, etc.\n\nIn my experience I have worked with already built datawarehouses in Snowflake, Redshift, PostgreSQL, etc. but I have no experience setting them up!\n\nNote: a guy from finance gave me access to Fivetran but I have absolutely no idea of how it works. Would it be useful to continue using it or should I pick another one?", "author_fullname": "t2_i9w9s17d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hired as Data Analyst but the Company has no Data Infrastructure/Strategy/Governance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1av26rw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708385017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week I was hired as a Data Analyst at a small 200 employees company and the expectations for my role are to automate a lot of manually generated reports, and also build dashboards to provide insights to Sales, Marketing, Product teams. &lt;/p&gt;\n\n&lt;p&gt;I found out there is absolutely &lt;strong&gt;no data and analytics infrastructure&lt;/strong&gt;!! The reporting is based solely on Salesforce reports exported to Gsheets and a lot of manual formulas and calcs. &lt;/p&gt;\n\n&lt;p&gt;What would be a low-cost tool or tools that let me build ETLs pulling data mostly from Salesforce and build custom queries for dashboards that I would build in Looker? The main source of data will be Salesforce, but would want to include others like Gainsight, NetSuite, HubSpot, Google Analytics, etc.&lt;/p&gt;\n\n&lt;p&gt;In my experience I have worked with already built datawarehouses in Snowflake, Redshift, PostgreSQL, etc. but I have no experience setting them up!&lt;/p&gt;\n\n&lt;p&gt;Note: a guy from finance gave me access to Fivetran but I have absolutely no idea of how it works. Would it be useful to continue using it or should I pick another one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1av26rw", "is_robot_indexable": true, "report_reasons": null, "author": "JaviReds", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1av26rw/hired_as_data_analyst_but_the_company_has_no_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1av26rw/hired_as_data_analyst_but_the_company_has_no_data/", "subreddit_subscribers": 162285, "created_utc": 1708385017.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our data team has been working really hard on our platform. We know many teams that develop pipelines using many technologies, we wanted to create our platform in order to decentralize our data team\n\nHere\u2019s a quick overview of what our platform brings to the table:\n\n\t\u2022\tHarnesses the power of Spark clusters over Kubernetes for scalability and efficiency.\n\t\u2022\tSeamlessly integrates with Hive or Glue for robust data storage and management. At the moment we use s3 and iceberg as our table format, but it could be gcs/adls2.\n\t\u2022\tExecutes DBT commands effortlessly via an integrated image with DBT and Spark clusters.\n\t\u2022\tAll of the jobs created on the platform, run on ephemeral clusters to optimize resource utilization and cut down costs.\n\t\u2022\tOffers Airflow integration for easy pipeline scheduling, configurable through a user-friendly interface.\n\t\u2022\twe can download data from Kafka topics, to the lake or We can extract data from any database using our connectors.\n\t\u2022\tEnables resource management by assigning distinct resources to different groups within organizations. \n\nWe use permissions, a data catalogue is integrated and you can create spark jobs (python , java, sparksql) in order to create transformations or ml model training. You can run on a normal cluster or one with gpu's. \n\nAre we missing something? Would you use something like this? Or is it over engineered?", "author_fullname": "t2_4alt9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We've created a Data Engineering Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1av7fdf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708400012.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708399067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our data team has been working really hard on our platform. We know many teams that develop pipelines using many technologies, we wanted to create our platform in order to decentralize our data team&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s a quick overview of what our platform brings to the table:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 Harnesses the power of Spark clusters over Kubernetes for scalability and efficiency.\n\u2022 Seamlessly integrates with Hive or Glue for robust data storage and management. At the moment we use s3 and iceberg as our table format, but it could be gcs/adls2.\n\u2022 Executes DBT commands effortlessly via an integrated image with DBT and Spark clusters.\n\u2022 All of the jobs created on the platform, run on ephemeral clusters to optimize resource utilization and cut down costs.\n\u2022 Offers Airflow integration for easy pipeline scheduling, configurable through a user-friendly interface.\n\u2022 we can download data from Kafka topics, to the lake or We can extract data from any database using our connectors.\n\u2022 Enables resource management by assigning distinct resources to different groups within organizations. \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;We use permissions, a data catalogue is integrated and you can create spark jobs (python , java, sparksql) in order to create transformations or ml model training. You can run on a normal cluster or one with gpu&amp;#39;s. &lt;/p&gt;\n\n&lt;p&gt;Are we missing something? Would you use something like this? Or is it over engineered?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1av7fdf", "is_robot_indexable": true, "report_reasons": null, "author": "Matunguito", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1av7fdf/weve_created_a_data_engineering_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1av7fdf/weve_created_a_data_engineering_platform/", "subreddit_subscribers": 162285, "created_utc": 1708399067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "E.g. for me, one challenge is that I could never really practice on the cloud platforms unless I was using it at work (unless I pay for it myself). Also, it's hard to learn best practices in engineering with only fake / clean data (since the complexities, volumes, watchouts just arent the same)-- in which case, making pipelines with real data is just more effective, and hence only doable again in a work setting", "author_fullname": "t2_7ki1otgv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was your biggest challenge getting into data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avj2k2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708439683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;E.g. for me, one challenge is that I could never really practice on the cloud platforms unless I was using it at work (unless I pay for it myself). Also, it&amp;#39;s hard to learn best practices in engineering with only fake / clean data (since the complexities, volumes, watchouts just arent the same)-- in which case, making pipelines with real data is just more effective, and hence only doable again in a work setting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1avj2k2", "is_robot_indexable": true, "report_reasons": null, "author": "Sensitive-Soup4733", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avj2k2/what_was_your_biggest_challenge_getting_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avj2k2/what_was_your_biggest_challenge_getting_into_data/", "subreddit_subscribers": 162285, "created_utc": 1708439683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm just curious what is out there in the real world.\n\nMine has grown to 320 models with about 4000 tests across 5 hops and the required thought/impact analysis that is put into changes has multiplied by 10x than what it was with 100 models.  Within the next year, there will be a hundred or so more models and I expect the complexity to continue to rise.\n\nWhat do you use to maintain your DBT project?  Do you manually build out the models or is there a tool you use?", "author_fullname": "t2_33sjvqg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How big are your DBT projects and how do you build/manage them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1av9i90", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708405649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just curious what is out there in the real world.&lt;/p&gt;\n\n&lt;p&gt;Mine has grown to 320 models with about 4000 tests across 5 hops and the required thought/impact analysis that is put into changes has multiplied by 10x than what it was with 100 models.  Within the next year, there will be a hundred or so more models and I expect the complexity to continue to rise.&lt;/p&gt;\n\n&lt;p&gt;What do you use to maintain your DBT project?  Do you manually build out the models or is there a tool you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1av9i90", "is_robot_indexable": true, "report_reasons": null, "author": "Captain_Coffee_III", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1av9i90/how_big_are_your_dbt_projects_and_how_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1av9i90/how_big_are_your_dbt_projects_and_how_do_you/", "subreddit_subscribers": 162285, "created_utc": 1708405649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you or are you implementing a lakehouse?\n\nIf so what have been some of the biggest hurdles or things you\u2019ve learned?\n\nWhat were big decisions you were happy with or would do differently if you could start over.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most important parts of implementing a lakehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avhmkt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708435683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you or are you implementing a lakehouse?&lt;/p&gt;\n\n&lt;p&gt;If so what have been some of the biggest hurdles or things you\u2019ve learned?&lt;/p&gt;\n\n&lt;p&gt;What were big decisions you were happy with or would do differently if you could start over.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1avhmkt", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avhmkt/most_important_parts_of_implementing_a_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avhmkt/most_important_parts_of_implementing_a_lakehouse/", "subreddit_subscribers": 162285, "created_utc": 1708435683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently firing off a few POCs on data catalog/data discovery tools for my organization. I am not a data engineer, but I work on the security side of things. Our goal is to have max visibility into the data we have, so we can ensure security best practices are being followed. That being said, we are rolling this out to our data engineering teams for their use as well. After polling our data teams, several features were listed as high in demand, such as data lineage, data glossary, and the ability to collaborate between data assets owned by different teams. Perhaps you folks could shed some light as to what you would like to see in a catalog/discovery tool?\n\n&amp;#x200B;\n\nEdit: I kant spel.", "author_fullname": "t2_dq4h698", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some key features of a data catalog would engineers find useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auzzx9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708379878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently firing off a few POCs on data catalog/data discovery tools for my organization. I am not a data engineer, but I work on the security side of things. Our goal is to have max visibility into the data we have, so we can ensure security best practices are being followed. That being said, we are rolling this out to our data engineering teams for their use as well. After polling our data teams, several features were listed as high in demand, such as data lineage, data glossary, and the ability to collaborate between data assets owned by different teams. Perhaps you folks could shed some light as to what you would like to see in a catalog/discovery tool?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: I kant spel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1auzzx9", "is_robot_indexable": true, "report_reasons": null, "author": "Wentz_ylvania", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auzzx9/what_are_some_key_features_of_a_data_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auzzx9/what_are_some_key_features_of_a_data_catalog/", "subreddit_subscribers": 162285, "created_utc": 1708379878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was hired 2 years ago to migrate my organization's data from absolute shit-show format (random spreadsheets, a legacy php/sql web applications, written forms, and literal smartphone photos of computer screens) into a more standard format using commercial industry database applications.\n\nMy field is extremely specialized and there are only a small handful of options available that fit this criteria (had to be commercial software for purchase, had to be specific to our industry, had to have x, y, and z features). I made a judgement call with a specific vendor and although it started off to a rocky start they're openness/willingness to collaborate has paid off.\n\nBut it's become increasingly clear that this project was doomed from the start (it was planned and budgeted for before I was employed). The data going into this new platform is inconsistent at best and completely lacking integrity at worst. The new platform also sports many features that our users do not need and lead to confusion, but it was also the only platform to host the features we need.\n\nWithout going into further detail, this has just become a mess with no end in sight. On one hand I relish the freedom/independence I'm given in my role, on the other hand I am frustrated that I have no support. Additionally, the project has no defined outcomes. Basically it just has to pass a general \"vibe check\" from management to determine when the migration is complete. This is a double edged sword as it's basically impossible for me to fail, but also to a certain extent it's impossible for me succeed.\n\nHas anyone dealt projects like this? How did you handle them/yourself while going through them. I'm encountering a fair amount of mental distress as this never-ending projects drags from months into years.", "author_fullname": "t2_hrrbq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on dealing with \"impossible\" projects.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avccpj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708415981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was hired 2 years ago to migrate my organization&amp;#39;s data from absolute shit-show format (random spreadsheets, a legacy php/sql web applications, written forms, and literal smartphone photos of computer screens) into a more standard format using commercial industry database applications.&lt;/p&gt;\n\n&lt;p&gt;My field is extremely specialized and there are only a small handful of options available that fit this criteria (had to be commercial software for purchase, had to be specific to our industry, had to have x, y, and z features). I made a judgement call with a specific vendor and although it started off to a rocky start they&amp;#39;re openness/willingness to collaborate has paid off.&lt;/p&gt;\n\n&lt;p&gt;But it&amp;#39;s become increasingly clear that this project was doomed from the start (it was planned and budgeted for before I was employed). The data going into this new platform is inconsistent at best and completely lacking integrity at worst. The new platform also sports many features that our users do not need and lead to confusion, but it was also the only platform to host the features we need.&lt;/p&gt;\n\n&lt;p&gt;Without going into further detail, this has just become a mess with no end in sight. On one hand I relish the freedom/independence I&amp;#39;m given in my role, on the other hand I am frustrated that I have no support. Additionally, the project has no defined outcomes. Basically it just has to pass a general &amp;quot;vibe check&amp;quot; from management to determine when the migration is complete. This is a double edged sword as it&amp;#39;s basically impossible for me to fail, but also to a certain extent it&amp;#39;s impossible for me succeed.&lt;/p&gt;\n\n&lt;p&gt;Has anyone dealt projects like this? How did you handle them/yourself while going through them. I&amp;#39;m encountering a fair amount of mental distress as this never-ending projects drags from months into years.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1avccpj", "is_robot_indexable": true, "report_reasons": null, "author": "shittypaintjpeg", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avccpj/advice_on_dealing_with_impossible_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avccpj/advice_on_dealing_with_impossible_projects/", "subreddit_subscribers": 162285, "created_utc": 1708415981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my first job was a a cloud engineer with database administration in which I learned a lot because of my seniors. Now my current job (3 months) is as a data engineer where we run our pipelines (python scripts) in a VM with task scheduler. We are slowly migrating our things to azure. My senior is leaving the company leaving me alone until they find a replacement (he came from a data scientist background and is self taught)\n\n&amp;#x200B;\n\nAm I missing a lot from not having a mentor and being on a company where data engineering lacks maturity? When I came to this company I made it clear my goal was to learn the ropes as a data engineer and most of what is keeping me is to not have a job with only 3 months in my CV.  \n\n\nFor the most experienced how common are companies like this? Should I look for other options?", "author_fullname": "t2_scb32bzm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is mentoring for a junior data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auzjli", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708378805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my first job was a a cloud engineer with database administration in which I learned a lot because of my seniors. Now my current job (3 months) is as a data engineer where we run our pipelines (python scripts) in a VM with task scheduler. We are slowly migrating our things to azure. My senior is leaving the company leaving me alone until they find a replacement (he came from a data scientist background and is self taught)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Am I missing a lot from not having a mentor and being on a company where data engineering lacks maturity? When I came to this company I made it clear my goal was to learn the ropes as a data engineer and most of what is keeping me is to not have a job with only 3 months in my CV.  &lt;/p&gt;\n\n&lt;p&gt;For the most experienced how common are companies like this? Should I look for other options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1auzjli", "is_robot_indexable": true, "report_reasons": null, "author": "CrazyKey4744", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auzjli/how_important_is_mentoring_for_a_junior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auzjli/how_important_is_mentoring_for_a_junior_data/", "subreddit_subscribers": 162285, "created_utc": 1708378805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analyst, mostly developing ETL pipelines with Python and SQL, lots of data transformations with pandas. I don't generate any business insights with my work. In accounting/audit, there's not much insight to derive from. I think I would like a more business analytics role with stats, but I also enjoy pure coding and database work. Both data engineering and data science at the highest level fascinate me, at this rate I think I'm going down the data engineering path. Can anyone share some insight, anyone in similar situations? Does anyone ever think about going for a more client/business facing role as opposed to the behind the scenes data engineering work?", "author_fullname": "t2_tt7gml0lp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why data engineering over business insights?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1av4a9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708390348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst, mostly developing ETL pipelines with Python and SQL, lots of data transformations with pandas. I don&amp;#39;t generate any business insights with my work. In accounting/audit, there&amp;#39;s not much insight to derive from. I think I would like a more business analytics role with stats, but I also enjoy pure coding and database work. Both data engineering and data science at the highest level fascinate me, at this rate I think I&amp;#39;m going down the data engineering path. Can anyone share some insight, anyone in similar situations? Does anyone ever think about going for a more client/business facing role as opposed to the behind the scenes data engineering work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1av4a9j", "is_robot_indexable": true, "report_reasons": null, "author": "date_uh", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1av4a9j/why_data_engineering_over_business_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1av4a9j/why_data_engineering_over_business_insights/", "subreddit_subscribers": 162285, "created_utc": 1708390348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to build my own data lake for some DE personal projects in AWS. Really just to upskill in data lakes and related technologies (i.e. Iceberg) since I don't have good opportunities to work on these things in my day job.\n\nI found two pretty thorough articles, [one from from Microsoft](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/cloud-scale-analytics/best-practices/data-lake-zones) and [one from AWS](https://docs.aws.amazon.com/prescriptive-guidance/latest/defining-bucket-names-data-lakes/welcome.html) on basic data lake organization and infrastructure, and I was wondering whether the community had any opinion on which of these would be the better model to follow when building out a new data lake architecture?\n\nBoth are very similar in design, but I like how the Microsoft design includes the conformance container for data passing QC and converted into the lake format. Other then which design is better, my only other questions are:\n\n1. How many S3 buckets should I use to build this out? 1 per layer? Also in the Microsoft design what's the difference between a lake and a container??\n2. How important is it to actually have a curated/analytics layer? I'm struggling to see how the enriched/stage layer differs from the curated/analytics layer, and I'm hesitant to add complexity before it's needed...", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help deciding on new data lake design for DE personal projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auxvo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708374961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to build my own data lake for some DE personal projects in AWS. Really just to upskill in data lakes and related technologies (i.e. Iceberg) since I don&amp;#39;t have good opportunities to work on these things in my day job.&lt;/p&gt;\n\n&lt;p&gt;I found two pretty thorough articles, &lt;a href=\"https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/cloud-scale-analytics/best-practices/data-lake-zones\"&gt;one from from Microsoft&lt;/a&gt; and &lt;a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/defining-bucket-names-data-lakes/welcome.html\"&gt;one from AWS&lt;/a&gt; on basic data lake organization and infrastructure, and I was wondering whether the community had any opinion on which of these would be the better model to follow when building out a new data lake architecture?&lt;/p&gt;\n\n&lt;p&gt;Both are very similar in design, but I like how the Microsoft design includes the conformance container for data passing QC and converted into the lake format. Other then which design is better, my only other questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How many S3 buckets should I use to build this out? 1 per layer? Also in the Microsoft design what&amp;#39;s the difference between a lake and a container??&lt;/li&gt;\n&lt;li&gt;How important is it to actually have a curated/analytics layer? I&amp;#39;m struggling to see how the enriched/stage layer differs from the curated/analytics layer, and I&amp;#39;m hesitant to add complexity before it&amp;#39;s needed...&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?auto=webp&amp;s=41fa146938cd97da5abfeff0d092a2cc151e65fa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3881e36da92b82c6947f6ca4ff3804ca47f2aea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17b5b01e50a969ac9e2353bebb062cd52a99d108", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=acadaf004e8aeb6919eabdb0d93065a34f7e89df", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=883009d39175a2f03b76275ed0f7c6011d94a3a7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc62aef83f192d102fa78c83c8f4fcfa85057e3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ca6913f202be9a9f83b266dd459edc90adbf9dd", "width": 1080, "height": 567}], "variants": {}, "id": "RCFh0Kid3SAqWEkALMGNW1e9Vu6ayZpftekoayP00hY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1auxvo3", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auxvo3/need_help_deciding_on_new_data_lake_design_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1auxvo3/need_help_deciding_on_new_data_lake_design_for_de/", "subreddit_subscribers": 162285, "created_utc": 1708374961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ctd40uoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Podcast: Using Trino And Iceberg As The Foundation Of Your Data Lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1auxetw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/-4Dik-FyeSJpSLw-jbXD2GjKV7cWZOWsUwh84W2XrY0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708373870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringpodcast.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dataengineeringpodcast.com/starburst-trino-iceberg-data-lakehouse-episode-413", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?auto=webp&amp;s=2120aa9314091ca630e69926832b5fbc04ca756f", "width": 1400, "height": 1400}, "resolutions": [{"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aaf640634e9da8c03b7edc9f09ca7e31f6aee921", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d88217a29fa71c5c662c7d324035df8ba72fecca", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0034038dbb6753ab8fb8490b14b6bf2819656cf3", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f8b617a7c6583a41fb510d3334de668dec2a38e3", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=235cd7229206b22708fdca688c95c3648c246479", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/wrAtDXyezXa8uJlV1VdXTIX8bGWtYFscPm9kyLMGhTg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9448afa1d602f1ff1c49cf168a73076130d1cb10", "width": 1080, "height": 1080}], "variants": {}, "id": "T69lnyzJjP6GC8oxXuuJPHNQnXgo_9t63cJnvtec6xw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1auxetw", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Relationship-207", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1auxetw/data_engineering_podcast_using_trino_and_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dataengineeringpodcast.com/starburst-trino-iceberg-data-lakehouse-episode-413", "subreddit_subscribers": 162285, "created_utc": 1708373870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for internships/entry-level/junior positions in various office jobs, exact positions are not important right now. In my CV I have listed \u201eSQL Basics\u201d and \u201ePython Basics\u201d under my skills section, I am still learning. What would you understand by that, what exact skills would you expect from me, and what you wouldn\u2019t require from someone with \u201ebasic\u201d skills? ", "author_fullname": "t2_17a3gi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you understand by \u201eSQL Basics\u201d and \u201ePython Basics\u201d in CV, what exact skills would you expect from that person?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avi583", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708437174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for internships/entry-level/junior positions in various office jobs, exact positions are not important right now. In my CV I have listed \u201eSQL Basics\u201d and \u201ePython Basics\u201d under my skills section, I am still learning. What would you understand by that, what exact skills would you expect from me, and what you wouldn\u2019t require from someone with \u201ebasic\u201d skills? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1avi583", "is_robot_indexable": true, "report_reasons": null, "author": "ItsGonnaBeGreatYear", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avi583/what_would_you_understand_by_sql_basics_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avi583/what_would_you_understand_by_sql_basics_and/", "subreddit_subscribers": 162285, "created_utc": 1708437174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was thinking about a POC for AWS MSK and it sort of raised a question in mind: what are your use cases for real time data? If it helps, expand the question to using Kafka in general. \n\nLet me give some quick background and where I\u2019m coming from. I built real-time pipelines a long ago (8+ years). My use case initially was real time product analytics; we had nightly batch jobs, so, at the time, this was a significant improvement. \n\nHowever, since then, we have tools like Segment that handle most use cases. Other than bringing Segment in-house to help reduce costs, why would one build their own realtime pipeline instead of leveraging existing tools? I thought about multiple consumers in Kafka, but Segment takes care of that as well, e.g. you can use Segment to send data to your DW, to Amplitude and to your CRM tool, all in near real-time. \n\nOther than a couple of companies I worked at, the data volume is not that significant, i.e. 100\u2019s of TBs, not PBs, so the tools generally work fine. Consequently, as a leader, I tend to lean more towards using tools as they help increase team velocity and I have the team focus on stakeholder needs &amp; deriving insights from the data, more than the data pipelines themselves. \n\nGiven all that, I\u2019m curious about your use cases and why you chose to build a realtime pipeline yourself instead of leveraging an existing tool like Segment?", "author_fullname": "t2_16b1dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your use case for a realtime data pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1av0oth", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708381460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking about a POC for AWS MSK and it sort of raised a question in mind: what are your use cases for real time data? If it helps, expand the question to using Kafka in general. &lt;/p&gt;\n\n&lt;p&gt;Let me give some quick background and where I\u2019m coming from. I built real-time pipelines a long ago (8+ years). My use case initially was real time product analytics; we had nightly batch jobs, so, at the time, this was a significant improvement. &lt;/p&gt;\n\n&lt;p&gt;However, since then, we have tools like Segment that handle most use cases. Other than bringing Segment in-house to help reduce costs, why would one build their own realtime pipeline instead of leveraging existing tools? I thought about multiple consumers in Kafka, but Segment takes care of that as well, e.g. you can use Segment to send data to your DW, to Amplitude and to your CRM tool, all in near real-time. &lt;/p&gt;\n\n&lt;p&gt;Other than a couple of companies I worked at, the data volume is not that significant, i.e. 100\u2019s of TBs, not PBs, so the tools generally work fine. Consequently, as a leader, I tend to lean more towards using tools as they help increase team velocity and I have the team focus on stakeholder needs &amp;amp; deriving insights from the data, more than the data pipelines themselves. &lt;/p&gt;\n\n&lt;p&gt;Given all that, I\u2019m curious about your use cases and why you chose to build a realtime pipeline yourself instead of leveraging an existing tool like Segment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1av0oth", "is_robot_indexable": true, "report_reasons": null, "author": "jawabdey", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1av0oth/what_is_your_use_case_for_a_realtime_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1av0oth/what_is_your_use_case_for_a_realtime_data_pipeline/", "subreddit_subscribers": 162285, "created_utc": 1708381460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nSo, I am currently working on a problem where I have to find duplicates in my data. The data has columns C1, C2, C3 and T. T stores timestamps. The received data is not sorted by timestamp. A duplicate is defined as when columns C1, C2 and C3 have same value but column T should have time difference of less than 120 seconds. The duplicates should be returned in groups.\n\nE.g.\n\n`C1:\"xyz\", C2:\"abc\", C3: \"def\", \"T:2024-02-10T12:00:00.000\"`\n\n`C1:\"xxx\", C2:\"yyy\", C3: \"zzz\", \"T:2024-02-10T12:05:00.000\"`\n\n`C1:\"xyz\", C2:\"abc\", C3: \"def\", \"T:2024-02-10T12:05:00.000\"`\n\n`C1:\"xyx\", C2:\"aba\", C3: \"ded\", \"T:2024-02-10T12:00:00.000\"`\n\n`C1:\"xxx\", C2:\"yyy\", C3: \"zzz\", \"T:2024-02-10T12:05:01.000\"`\n\n`C1:\"xyz\", C2:\"abc\", C3: \"def\", \"T:2024-02-10T12:01:05.000\"`\n\n`C1:\"aaa\", C2:\"bbb\", C3: \"ccc\", \"T:2024-02-10T12:00:00.000\"`\n\n`C1:\"xyz\", C2:\"abc\", C3: \"def\", \"T:2024-02-10T12:02:10.000\"`\n\nThe output for this would be:\n\n`[[C1:\"xyz\", C2:\"abc\", C3: \"def\", \"T:2024-02-10T12:00:00.000\"`\n\n`C1:\"xyz\", C2:\"abc\", C3: \"def\", \"T:2024-02-10T12:01:05.000\"`\n\n`C1:\"xyz\", C2:\"abc\", C3: \"def\", \"T:2024-02-10T12:02:10.000\"]`\n\n`[C1:\"xxx\", C2:\"yyy\", C3: \"zzz\", \"T:2024-02-10T12:05:00.000\"`\n\n`C1:\"xxx\", C2:\"yyy\", C3: \"zzz\", \"T:2024-02-10T12:05:01.000\"]]`\n\nMy current solution for small data does not use Pandas or Spark and works by sorting the data over T column, then grouping them on (C1, C2, C3) and removing any duplicates which do not uphold the time difference criteria. And finally,, sorting the discovered duplicate groups over T again.\n\nHow would I approach this problem when I have say 1 billion rows? Should I use Spark or process with pandas in batches? I am not able to get an intuition of how sorting and grouping would work when the data is distributed or processed in batches?\n\n", "author_fullname": "t2_bmxda7ioc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you approach this problem for very large datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1averfs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708430799.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708425818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;So, I am currently working on a problem where I have to find duplicates in my data. The data has columns C1, C2, C3 and T. T stores timestamps. The received data is not sorted by timestamp. A duplicate is defined as when columns C1, C2 and C3 have same value but column T should have time difference of less than 120 seconds. The duplicates should be returned in groups.&lt;/p&gt;\n\n&lt;p&gt;E.g.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xyz&amp;quot;, C2:&amp;quot;abc&amp;quot;, C3: &amp;quot;def&amp;quot;, &amp;quot;T:2024-02-10T12:00:00.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xxx&amp;quot;, C2:&amp;quot;yyy&amp;quot;, C3: &amp;quot;zzz&amp;quot;, &amp;quot;T:2024-02-10T12:05:00.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xyz&amp;quot;, C2:&amp;quot;abc&amp;quot;, C3: &amp;quot;def&amp;quot;, &amp;quot;T:2024-02-10T12:05:00.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xyx&amp;quot;, C2:&amp;quot;aba&amp;quot;, C3: &amp;quot;ded&amp;quot;, &amp;quot;T:2024-02-10T12:00:00.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xxx&amp;quot;, C2:&amp;quot;yyy&amp;quot;, C3: &amp;quot;zzz&amp;quot;, &amp;quot;T:2024-02-10T12:05:01.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xyz&amp;quot;, C2:&amp;quot;abc&amp;quot;, C3: &amp;quot;def&amp;quot;, &amp;quot;T:2024-02-10T12:01:05.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;aaa&amp;quot;, C2:&amp;quot;bbb&amp;quot;, C3: &amp;quot;ccc&amp;quot;, &amp;quot;T:2024-02-10T12:00:00.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xyz&amp;quot;, C2:&amp;quot;abc&amp;quot;, C3: &amp;quot;def&amp;quot;, &amp;quot;T:2024-02-10T12:02:10.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;The output for this would be:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;[[C1:&amp;quot;xyz&amp;quot;, C2:&amp;quot;abc&amp;quot;, C3: &amp;quot;def&amp;quot;, &amp;quot;T:2024-02-10T12:00:00.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xyz&amp;quot;, C2:&amp;quot;abc&amp;quot;, C3: &amp;quot;def&amp;quot;, &amp;quot;T:2024-02-10T12:01:05.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xyz&amp;quot;, C2:&amp;quot;abc&amp;quot;, C3: &amp;quot;def&amp;quot;, &amp;quot;T:2024-02-10T12:02:10.000&amp;quot;]&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;[C1:&amp;quot;xxx&amp;quot;, C2:&amp;quot;yyy&amp;quot;, C3: &amp;quot;zzz&amp;quot;, &amp;quot;T:2024-02-10T12:05:00.000&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;C1:&amp;quot;xxx&amp;quot;, C2:&amp;quot;yyy&amp;quot;, C3: &amp;quot;zzz&amp;quot;, &amp;quot;T:2024-02-10T12:05:01.000&amp;quot;]]&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;My current solution for small data does not use Pandas or Spark and works by sorting the data over T column, then grouping them on (C1, C2, C3) and removing any duplicates which do not uphold the time difference criteria. And finally,, sorting the discovered duplicate groups over T again.&lt;/p&gt;\n\n&lt;p&gt;How would I approach this problem when I have say 1 billion rows? Should I use Spark or process with pandas in batches? I am not able to get an intuition of how sorting and grouping would work when the data is distributed or processed in batches?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1averfs", "is_robot_indexable": true, "report_reasons": null, "author": "Even_Work_7995", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1averfs/how_would_you_approach_this_problem_for_very/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1averfs/how_would_you_approach_this_problem_for_very/", "subreddit_subscribers": 162285, "created_utc": 1708425818.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I had started a blog series to guide people on the path I felt they should follow, to transition into Azure Data Engineer role as a way back of doing good to the community and help people in making their careers and providing for their family. The blog where I mentioned this received tremendous response which really motivated me to go for it.\n\nHowever that is where things changed. The first blog titled, structured way to get into DE, though received very good response on upvotes and shares, was filled with negative comments. Some questioned why only Azure, some questioned why I had given timelines, some questioned why am I focusing on only X number of things, etc etc. Very very few people had something positive to say. Still I ignored it as helping community was more important but the next two blogs, SQL and ADF had a drastic decrease in engagement. Almost 80% engagement was gone.\n\nThis brings me to the question, are the blogs still needed by the community, are they helping you in any way or it's something unnecessary and should be stopped?\n\nNote: If this ends up on the positive side, I will be needing at least 50 upvotes or shares (as karma farming comments will come so I am fine with just shares too) for the already published blogs (SQL and ADF) and the ones to follow from now. This way it can be ensured that people are engaging with the content and I am not spending time creating something nobody is reading :)\n\n[View Poll](https://www.reddit.com/poll/1avnq5y)", "author_fullname": "t2_f86nbjeq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The End?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1avnq5y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708455800.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708451004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had started a blog series to guide people on the path I felt they should follow, to transition into Azure Data Engineer role as a way back of doing good to the community and help people in making their careers and providing for their family. The blog where I mentioned this received tremendous response which really motivated me to go for it.&lt;/p&gt;\n\n&lt;p&gt;However that is where things changed. The first blog titled, structured way to get into DE, though received very good response on upvotes and shares, was filled with negative comments. Some questioned why only Azure, some questioned why I had given timelines, some questioned why am I focusing on only X number of things, etc etc. Very very few people had something positive to say. Still I ignored it as helping community was more important but the next two blogs, SQL and ADF had a drastic decrease in engagement. Almost 80% engagement was gone.&lt;/p&gt;\n\n&lt;p&gt;This brings me to the question, are the blogs still needed by the community, are they helping you in any way or it&amp;#39;s something unnecessary and should be stopped?&lt;/p&gt;\n\n&lt;p&gt;Note: If this ends up on the positive side, I will be needing at least 50 upvotes or shares (as karma farming comments will come so I am fine with just shares too) for the already published blogs (SQL and ADF) and the ones to follow from now. This way it can be ensured that people are engaging with the content and I am not spending time creating something nobody is reading :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1avnq5y\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1avnq5y", "is_robot_indexable": true, "report_reasons": null, "author": "Vikinghehe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1708537404984, "options": [{"text": "Continue with the blogs.", "id": "27157742"}, {"text": "Stop the blogs.", "id": "27157743"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 12, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avnq5y/the_end/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/1avnq5y/the_end/", "subreddit_subscribers": 162285, "created_utc": 1708451004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nJust started my first data engineering position, but it\u2019s not at a company dealing with order/customer/deal data - the position has to do more with political and corporate data, which is very interesting, but it\u2019s much harder to figure out how to apply some of these data engineering concepts (like reading Kimball) without the same data types. For example, I\u2019m trying to set up a data warehouse from scratch for our data that\u2019s currently in PostgreSQL, but having a hard time figuring out where to start in terms of what to stage and how to go about dimensionally modeling this data. Does anybody have any tips for data engineering for atypical data? ", "author_fullname": "t2_2ivpdou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering for Non-Business Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avka8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708442797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Just started my first data engineering position, but it\u2019s not at a company dealing with order/customer/deal data - the position has to do more with political and corporate data, which is very interesting, but it\u2019s much harder to figure out how to apply some of these data engineering concepts (like reading Kimball) without the same data types. For example, I\u2019m trying to set up a data warehouse from scratch for our data that\u2019s currently in PostgreSQL, but having a hard time figuring out where to start in terms of what to stage and how to go about dimensionally modeling this data. Does anybody have any tips for data engineering for atypical data? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1avka8p", "is_robot_indexable": true, "report_reasons": null, "author": "Butterhero_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avka8p/data_engineering_for_nonbusiness_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avka8p/data_engineering_for_nonbusiness_data/", "subreddit_subscribers": 162285, "created_utc": 1708442797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks!   \n[https://github.com/Multiwoven/multiwoven](https://github.com/Multiwoven/multiwoven)  \n\n\n I'm Subin, co-founder at Multiwoven .Multiwoven is a OSS reverse ETL platform that helps dev &amp; data teams to sync data from databases to business tools. Multiwoven is built using Ruby on Rails . Our data sync orchestration is built on top of Temporal using temporal-ruby SDK.I would greatly appreciate any feedback. Our codebase is available at Github. Please star us to get updates.", "author_fullname": "t2_9bibppzm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiwoven - Open-source reverse ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avew2o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708426332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks!&lt;br/&gt;\n&lt;a href=\"https://github.com/Multiwoven/multiwoven\"&gt;https://github.com/Multiwoven/multiwoven&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m Subin, co-founder at Multiwoven .Multiwoven is a OSS reverse ETL platform that helps dev &amp;amp; data teams to sync data from databases to business tools. Multiwoven is built using Ruby on Rails . Our data sync orchestration is built on top of Temporal using temporal-ruby SDK.I would greatly appreciate any feedback. Our codebase is available at Github. Please star us to get updates.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?auto=webp&amp;s=7bee046b00e43a80d51ec06b5b03fab8fe50e8a6", "width": 2560, "height": 1280}, "resolutions": [{"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c820e531bd69e73f8ab0a6ae0beacd99c2b46eb", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c80be54ff0c4e74ab2f7726675fcebd3a845b46", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ac265f606906d37f473536da1c0f1402f557f04", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f31b53a48c8d26b2abdbd514797bd69ea9539bcf", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d338fcd1ab24aecad9b1dcf39d5649f7cff2a29", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aom3cnBNH14gDW_dvebtl5pxJssgJVZB1OrLyKDYO9s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3be250d32cd9b8a61ac25ca44aa1a3ab73cb70a", "width": 1080, "height": 540}], "variants": {}, "id": "KXdCRFA3PFw6uZLyGfHzBPQBTSPbN50XvrsQE2m5iOI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1avew2o", "is_robot_indexable": true, "report_reasons": null, "author": "BobcatOutrageous2152", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avew2o/multiwoven_opensource_reverse_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avew2o/multiwoven_opensource_reverse_etl/", "subreddit_subscribers": 162285, "created_utc": 1708426332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interesting writeup from Grab on the evolution of their architecture and what drove it, also covers the tool stack\n\n[https://engineering.grab.com/attribution-platform](https://engineering.grab.com/attribution-platform)", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ad-attribution toolstack and architecture evolution Kappa -&gt; Lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ave5me", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708423386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interesting writeup from Grab on the evolution of their architecture and what drove it, also covers the tool stack&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://engineering.grab.com/attribution-platform\"&gt;https://engineering.grab.com/attribution-platform&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dus5HaHSWGwIWNsjetAVnCinorLaf2mk2zT9edtnT6I.jpg?auto=webp&amp;s=d7f3d72292945fabad7e425d6dac8116bc8d6e8e", "width": 820, "height": 410}, "resolutions": [{"url": "https://external-preview.redd.it/dus5HaHSWGwIWNsjetAVnCinorLaf2mk2zT9edtnT6I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eb2280b5de657ab5aa7ccf3f8db3ffe8fa589c64", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/dus5HaHSWGwIWNsjetAVnCinorLaf2mk2zT9edtnT6I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9eb75e1d7b5d9afd7cc95933569c8da0e34d9cbb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/dus5HaHSWGwIWNsjetAVnCinorLaf2mk2zT9edtnT6I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f45878784b7396c1a4b9f8a18f3451d77b8aaabc", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/dus5HaHSWGwIWNsjetAVnCinorLaf2mk2zT9edtnT6I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5b9b9331c902ce00b15be8ab905704d531385cf7", "width": 640, "height": 320}], "variants": {}, "id": "NcKcYtUrZALKPPo2SThdpWDUuQIC8J5ZFrY4ANzdEiA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1ave5me", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ave5me/adattribution_toolstack_and_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ave5me/adattribution_toolstack_and_architecture/", "subreddit_subscribers": 162285, "created_utc": 1708423386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are your suggestions for \"exceptional\" requirements gathering and test cases for data tables and analytical views for a GCP implementation? At a superficial level, I understand both to be straightforward.\n\n**Requirements gathering**: I work with end-users to document their needs. The documentation is used to develop some portion of the data architecture. In my case, we're using the requirements to build analytical views.\n\n**Test-case development**: This is a bit trickier for me as I'm accustomed to developing unit tests. I understand that a different approach is required with data lakes and data pipelines.\n\nI believe that these two tasks are frequently underappreciated. What should I do to ensure that my team/I perform these tasks at an above-average level? What details are commonly overlooked?\n\n&amp;#x200B;\n\nP.S. I asked this question on a subreddit, but I am curious to hear other's thoughts\n\n&amp;#x200B;\n\nEdit: Link to my initial question and ithinkiboughtadingo's insightful response - [https://www.reddit.com/r/dataengineering/comments/1au9s4s/comment/kr6p7a6/?context=3](https://www.reddit.com/r/dataengineering/comments/1au9s4s/comment/kr6p7a6/?context=3)", "author_fullname": "t2_6cc9wqbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for Requirements Gathering and Test Cases in Building/Testing Data Tables and Analytical Views for Cloud Migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1av5w74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1708441009.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708394778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your suggestions for &amp;quot;exceptional&amp;quot; requirements gathering and test cases for data tables and analytical views for a GCP implementation? At a superficial level, I understand both to be straightforward.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Requirements gathering&lt;/strong&gt;: I work with end-users to document their needs. The documentation is used to develop some portion of the data architecture. In my case, we&amp;#39;re using the requirements to build analytical views.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Test-case development&lt;/strong&gt;: This is a bit trickier for me as I&amp;#39;m accustomed to developing unit tests. I understand that a different approach is required with data lakes and data pipelines.&lt;/p&gt;\n\n&lt;p&gt;I believe that these two tasks are frequently underappreciated. What should I do to ensure that my team/I perform these tasks at an above-average level? What details are commonly overlooked?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;P.S. I asked this question on a subreddit, but I am curious to hear other&amp;#39;s thoughts&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: Link to my initial question and ithinkiboughtadingo&amp;#39;s insightful response - &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/1au9s4s/comment/kr6p7a6/?context=3\"&gt;https://www.reddit.com/r/dataengineering/comments/1au9s4s/comment/kr6p7a6/?context=3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1av5w74", "is_robot_indexable": true, "report_reasons": null, "author": "Cultured_dude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1av5w74/suggestions_for_requirements_gathering_and_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1av5w74/suggestions_for_requirements_gathering_and_test/", "subreddit_subscribers": 162285, "created_utc": 1708394778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a small website to help people brand new to Spark get started. The goal is to teach all of the basics in an afternoon, along with some opinionated style suggestions on how to write Spark code. However, before someone can get started though, they need somewhere to run their Spark code. \n\nI'm wondering what people found most helpful as they were getting started. Personally, I tend to prefer working locally with Docker, but I can see that being a small hurdle if folks aren't already familiar with running Docker (even though docker-compose simplifies this a lot IMO).\n\nWhat helped you with writing and testing out Spark when you were starting out?", "author_fullname": "t2_uyd9mc1b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you find it easier to learn Spark using a cloud notebook environment or locally with Docker?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1avoont", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708453239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a small website to help people brand new to Spark get started. The goal is to teach all of the basics in an afternoon, along with some opinionated style suggestions on how to write Spark code. However, before someone can get started though, they need somewhere to run their Spark code. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what people found most helpful as they were getting started. Personally, I tend to prefer working locally with Docker, but I can see that being a small hurdle if folks aren&amp;#39;t already familiar with running Docker (even though docker-compose simplifies this a lot IMO).&lt;/p&gt;\n\n&lt;p&gt;What helped you with writing and testing out Spark when you were starting out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1avoont", "is_robot_indexable": true, "report_reasons": null, "author": "zchtsk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avoont/do_you_find_it_easier_to_learn_spark_using_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avoont/do_you_find_it_easier_to_learn_spark_using_a/", "subreddit_subscribers": 162285, "created_utc": 1708453239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ez8d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Review: Deciphering Data Architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avne6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1708450239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mullins.pro", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://mullins.pro/posts/deciphering_data_architectures/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1avne6e", "is_robot_indexable": true, "report_reasons": null, "author": "Bazencourt", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avne6e/review_deciphering_data_architectures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mullins.pro/posts/deciphering_data_architectures/", "subreddit_subscribers": 162285, "created_utc": 1708450239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello there,\n\nwe work with Databricks on Azure.\n\nThrough the years we created a few projects, each of them has their own SQL Warehouse. Each warehouse serves a couple of schemas. Nothing too big data and mainly used for reporting (so far) and some data analytics. PowerBI users also use them and also people accessing them directly on Databricks.\n\nWe are interested in reducing our running costs, so I am exploring if it makes sense to merge these warehouses, currently I doubt we are using either of the warehouses to their potential and it's wasted money. \n\nWhat's your architectural approach to this? Maybe a separate CICD pipeline that is only responsible for the warehouse and who has access to it? Security considerations are a must, currently users who are member of a certain AD group (or as renamed, Entra groups) can have access to a certain schema through the respective warehouse that is dedicated to a project.", "author_fullname": "t2_hp7r8vez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks SQL Warehouses: one to serve them all or one for each project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1avhrth", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708436105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there,&lt;/p&gt;\n\n&lt;p&gt;we work with Databricks on Azure.&lt;/p&gt;\n\n&lt;p&gt;Through the years we created a few projects, each of them has their own SQL Warehouse. Each warehouse serves a couple of schemas. Nothing too big data and mainly used for reporting (so far) and some data analytics. PowerBI users also use them and also people accessing them directly on Databricks.&lt;/p&gt;\n\n&lt;p&gt;We are interested in reducing our running costs, so I am exploring if it makes sense to merge these warehouses, currently I doubt we are using either of the warehouses to their potential and it&amp;#39;s wasted money. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your architectural approach to this? Maybe a separate CICD pipeline that is only responsible for the warehouse and who has access to it? Security considerations are a must, currently users who are member of a certain AD group (or as renamed, Entra groups) can have access to a certain schema through the respective warehouse that is dedicated to a project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1avhrth", "is_robot_indexable": true, "report_reasons": null, "author": "Labanc_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1avhrth/databricks_sql_warehouses_one_to_serve_them_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1avhrth/databricks_sql_warehouses_one_to_serve_them_all/", "subreddit_subscribers": 162285, "created_utc": 1708436105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Versioning, Cataloging, and Decommissioning Data Products", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "name": "t3_1avh111", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gB_ZjJKC3197XhodvkkYWTDrjINSJ_rc0q8f7ibLLaQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708433867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/managing-the-evolving-data-products-landscape-p2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MmyYDSrycbY7HMY_ZiBcFTZzei7DLAEN2Maxh8CzP88.jpg?auto=webp&amp;s=b45c9b290ad8b6c7c2763d4ba3fc9f7d69a4d9d8", "width": 700, "height": 378}, "resolutions": [{"url": "https://external-preview.redd.it/MmyYDSrycbY7HMY_ZiBcFTZzei7DLAEN2Maxh8CzP88.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2e1fbb5dbacab22ce5c5bdb3a0ac1d16a6ee6be", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/MmyYDSrycbY7HMY_ZiBcFTZzei7DLAEN2Maxh8CzP88.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=226b1f43fa2918ebe8b0a3dd752f37c180ad5c67", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/MmyYDSrycbY7HMY_ZiBcFTZzei7DLAEN2Maxh8CzP88.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a9a0ba30cb74687bc66030c20d31517a641216bf", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/MmyYDSrycbY7HMY_ZiBcFTZzei7DLAEN2Maxh8CzP88.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=133772bc0f8d87f8a49b52a21cd9f6da38b18adc", "width": 640, "height": 345}], "variants": {}, "id": "pJ8tPpgSlQhmlrsiqx50_VPVXrM4UCN658AcFCzyXbY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1avh111", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1avh111/versioning_cataloging_and_decommissioning_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/managing-the-evolving-data-products-landscape-p2", "subreddit_subscribers": 162285, "created_utc": 1708433867.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}