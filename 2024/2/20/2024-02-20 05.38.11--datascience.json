{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "1. In what world does a Director of DS only make $200k, and the VP of Anything only make $210k???\n\n2. In what world does the compensation increase become smaller, the higher the promotion? \n\n3. They present it as if this is completely achievable just by \u201cfollowing the path\u201d, while in reality it takes a lot of luck and politics to become anything higher than a DS manager, and it happens very rarely. ", "author_fullname": "t2_1ihcfil3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The BS they tell about Data Science\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1augdle", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 867, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 867, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a4sgoM4r1keJTwcfRAA_Jag-KT8OcIrZWWy6Ir8LOxY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1708323275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;In what world does a Director of DS only make $200k, and the VP of Anything only make $210k???&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In what world does the compensation increase become smaller, the higher the promotion? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;They present it as if this is completely achievable just by \u201cfollowing the path\u201d, while in reality it takes a lot of luck and politics to become anything higher than a DS manager, and it happens very rarely. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3zl80ug6ihjc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3zl80ug6ihjc1.jpeg?auto=webp&amp;s=cc3c9fb608df34cc1707254fe92be4b0e74b33fe", "width": 787, "height": 802}, "resolutions": [{"url": "https://preview.redd.it/3zl80ug6ihjc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e7c7e19263ee94b40918b7d2725e60055632d1f5", "width": 108, "height": 110}, {"url": "https://preview.redd.it/3zl80ug6ihjc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7856337be3629e56a5b3e0e90b4eb3e72913c203", "width": 216, "height": 220}, {"url": "https://preview.redd.it/3zl80ug6ihjc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2922ff0541e2804810857b7fd04ec61a5cd47b0", "width": 320, "height": 326}, {"url": "https://preview.redd.it/3zl80ug6ihjc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3afe4906be5a21d67ec1e7f3a78a864efce17d98", "width": 640, "height": 652}], "variants": {}, "id": "ou2cd7pX9jxAfzbYEuM2r37n9DW6_3STjEy6wGOi5F4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1augdle", "is_robot_indexable": true, "report_reasons": null, "author": "zi_ang", "discussion_type": null, "num_comments": 287, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1augdle/the_bs_they_tell_about_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3zl80ug6ihjc1.jpeg", "subreddit_subscribers": 1350793, "created_utc": 1708323275.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a rookie blogger in this space, trying to get more inspired on how I should build content.\n\nSo if you guys are regular readers to Data Science blogs, can you refer to your favourites?\n\nPrefer the person over publication since publications quality varies a lot. \n\nAlso if you're a blogger yourself you can say you're your favorite :) ", "author_fullname": "t2_2u7dh8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best bloggers you guys follow for data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aujl41", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708335952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a rookie blogger in this space, trying to get more inspired on how I should build content.&lt;/p&gt;\n\n&lt;p&gt;So if you guys are regular readers to Data Science blogs, can you refer to your favourites?&lt;/p&gt;\n\n&lt;p&gt;Prefer the person over publication since publications quality varies a lot. &lt;/p&gt;\n\n&lt;p&gt;Also if you&amp;#39;re a blogger yourself you can say you&amp;#39;re your favorite :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1aujl41", "is_robot_indexable": true, "report_reasons": null, "author": "phicreative1997", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aujl41/what_are_the_best_bloggers_you_guys_follow_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aujl41/what_are_the_best_bloggers_you_guys_follow_for/", "subreddit_subscribers": 1350793, "created_utc": 1708335952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This sub has been nice to me so I am back and bring gifts to you. I created an automated tech skills report that updates several times a day. This is a deep yet manageable dive into the U.S. tech job market; the report currently has no analog that I know of.\n\nThe nutshell: tech jobs are scraped from Indeed, a transformer-based pipeline extracts skills and classifies the jobs, and Power BI presents the visualizations. \n\nNotable changes from the report I shared a few months back are:\n\n* Skills have a custom fuzzy match to resolve their canonical form\n* Years of experience is pulled from each span the skill is found within the posting and calculated\n* Pay is extracted and calculated for multiple frequencies (annual, monthly, weekly, etc.)\n* Job titles and skills are embedded using the latest OpenAI model (Large) and then clustered\n* Skill count and pay percentile (what are the top skills for the job and which skills pay the most)\n   * Ordered by highest to lowest in the table\n* Apple is hiring a shit ton of AI/ML (translation: the singularity is *nearer*)\n\nThe full report is available at my website [hazon.fyi](https://hazon.fyi)\n\nSome things I want to do next:\n\n* NER: Education and certifications\n   * Easy to do but boring\n* Subcategories: Add subcats to large categories (i.e. Software Engineering &gt; DevOps)\n* Assistant API: Build a resume builder that leverages the OpenAI Assistant API\n* Observable Framework: Build some decent visuals now that I have a website\n\nPlease let me know what you think, critique first.\n\nThanks!  \n\n\nhttps://preview.redd.it/juvh4x4thhjc1.jpg?width=2270&amp;format=pjpg&amp;auto=webp&amp;s=cb44af7712030b52694c279ccdd87db6d7c9b239", "author_fullname": "t2_6xp1skf7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tech Skill Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "media_metadata": {"juvh4x4thhjc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/juvh4x4thhjc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=472925660bba0a2159974d65808490329b95848f"}, {"y": 140, "x": 216, "u": "https://preview.redd.it/juvh4x4thhjc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8668b88986d650e416623c54d861722574fb0278"}, {"y": 208, "x": 320, "u": "https://preview.redd.it/juvh4x4thhjc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ea7114e50a2859a107d6bd046ae8950c27ff8647"}, {"y": 416, "x": 640, "u": "https://preview.redd.it/juvh4x4thhjc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=200a0972f1514d043255722de01bb772ca1bd427"}, {"y": 625, "x": 960, "u": "https://preview.redd.it/juvh4x4thhjc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6d4a468941860b937af2f125c4ad5c092840e4dc"}, {"y": 703, "x": 1080, "u": "https://preview.redd.it/juvh4x4thhjc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=76762d1ba2fb0ebb961afae0fbea49f88f054d7e"}], "s": {"y": 1478, "x": 2270, "u": "https://preview.redd.it/juvh4x4thhjc1.jpg?width=2270&amp;format=pjpg&amp;auto=webp&amp;s=cb44af7712030b52694c279ccdd87db6d7c9b239"}, "id": "juvh4x4thhjc1"}}, "name": "t3_1auh3n1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hIxswc5XbZfPiVuol4SYRAuDRVyzmNjuiJ1ReQP1vKs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708325992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This sub has been nice to me so I am back and bring gifts to you. I created an automated tech skills report that updates several times a day. This is a deep yet manageable dive into the U.S. tech job market; the report currently has no analog that I know of.&lt;/p&gt;\n\n&lt;p&gt;The nutshell: tech jobs are scraped from Indeed, a transformer-based pipeline extracts skills and classifies the jobs, and Power BI presents the visualizations. &lt;/p&gt;\n\n&lt;p&gt;Notable changes from the report I shared a few months back are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Skills have a custom fuzzy match to resolve their canonical form&lt;/li&gt;\n&lt;li&gt;Years of experience is pulled from each span the skill is found within the posting and calculated&lt;/li&gt;\n&lt;li&gt;Pay is extracted and calculated for multiple frequencies (annual, monthly, weekly, etc.)&lt;/li&gt;\n&lt;li&gt;Job titles and skills are embedded using the latest OpenAI model (Large) and then clustered&lt;/li&gt;\n&lt;li&gt;Skill count and pay percentile (what are the top skills for the job and which skills pay the most)\n\n&lt;ul&gt;\n&lt;li&gt;Ordered by highest to lowest in the table&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Apple is hiring a shit ton of AI/ML (translation: the singularity is &lt;em&gt;nearer&lt;/em&gt;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The full report is available at my website &lt;a href=\"https://hazon.fyi\"&gt;hazon.fyi&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Some things I want to do next:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;NER: Education and certifications\n\n&lt;ul&gt;\n&lt;li&gt;Easy to do but boring&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Subcategories: Add subcats to large categories (i.e. Software Engineering &amp;gt; DevOps)&lt;/li&gt;\n&lt;li&gt;Assistant API: Build a resume builder that leverages the OpenAI Assistant API&lt;/li&gt;\n&lt;li&gt;Observable Framework: Build some decent visuals now that I have a website&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please let me know what you think, critique first.&lt;/p&gt;\n\n&lt;p&gt;Thanks!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/juvh4x4thhjc1.jpg?width=2270&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=cb44af7712030b52694c279ccdd87db6d7c9b239\"&gt;https://preview.redd.it/juvh4x4thhjc1.jpg?width=2270&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=cb44af7712030b52694c279ccdd87db6d7c9b239&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1auh3n1", "is_robot_indexable": true, "report_reasons": null, "author": "Kbig22", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1auh3n1/tech_skill_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1auh3n1/tech_skill_insights/", "subreddit_subscribers": 1350793, "created_utc": 1708325992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Situation:** 2022, joined a consumer product team in FAANG. 1B+ users. Didn't have a good mental model for how to evaluate user success so was looking at in-product metrics like task completion. Eventually came across an article about **daily retention curves** and it opened my mind to a new way to analyze user metrics. Super insightful, and I've been the voice of retention on the team since. \n\n**Problem:** With analytics and DS, I don't know what I don't know until I learn about it. But I don't have a good model for learning expect for reading a ton online. Analytics, especially statistics, is not always intuitive and finding a new way to look at data can sometimes open your mind. \n\n**My question:** How do you discover what analyses to apply to a situation? Is it still mostly tribal knowledge? Your education background? Or is there some resource out there that you refer to? Interested in the community's process here. \n\nThe article in question: [https://articles.sequoiacap.com/retention](https://articles.sequoiacap.com/retention)", "author_fullname": "t2_tszztjadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you learn about new analyses to apply to a situation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1av27da", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708385059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Situation:&lt;/strong&gt; 2022, joined a consumer product team in FAANG. 1B+ users. Didn&amp;#39;t have a good mental model for how to evaluate user success so was looking at in-product metrics like task completion. Eventually came across an article about &lt;strong&gt;daily retention curves&lt;/strong&gt; and it opened my mind to a new way to analyze user metrics. Super insightful, and I&amp;#39;ve been the voice of retention on the team since. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; With analytics and DS, I don&amp;#39;t know what I don&amp;#39;t know until I learn about it. But I don&amp;#39;t have a good model for learning expect for reading a ton online. Analytics, especially statistics, is not always intuitive and finding a new way to look at data can sometimes open your mind. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My question:&lt;/strong&gt; How do you discover what analyses to apply to a situation? Is it still mostly tribal knowledge? Your education background? Or is there some resource out there that you refer to? Interested in the community&amp;#39;s process here. &lt;/p&gt;\n\n&lt;p&gt;The article in question: &lt;a href=\"https://articles.sequoiacap.com/retention\"&gt;https://articles.sequoiacap.com/retention&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1av27da", "is_robot_indexable": true, "report_reasons": null, "author": "jmack_startups", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1av27da/how_do_you_learn_about_new_analyses_to_apply_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1av27da/how_do_you_learn_about_new_analyses_to_apply_to_a/", "subreddit_subscribers": 1350793, "created_utc": 1708385059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Many times  write a  long code and a major portion of the code needs to be changed, but I might need the old code for reference. Is there a way to version control the entire notebook?", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to version control Jupyter notebook?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1av71k9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708397979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Many times  write a  long code and a major portion of the code needs to be changed, but I might need the old code for reference. Is there a way to version control the entire notebook?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1av71k9", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1av71k9/how_to_version_control_jupyter_notebook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1av71k9/how_to_version_control_jupyter_notebook/", "subreddit_subscribers": 1350793, "created_utc": 1708397979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am developing a protocol for an N-of-1 study on headache pain and migraine occurrence.\n\nThis will be an exploratory Path model, and there are 2 DVs: Migraine=Yes/No and Headache intensity 0-10. Several physiological and psychological IVs. That in and of itself isn't the main issue.\n\nI want to collect data for the participant 3x per day and an additional time if an acute migraine occurs (to capture the IVs at the time of occurrence). If this were one collection per day, it would make sense to me how to do the analysis. However, how do I handle the data for multiple collections per day? Do I throw all the data together and consider the time of day as another IV? This *isn't a time series or longitudinal study* but a study of the antecedents to migraines and general headache pain.", "author_fullname": "t2_okwnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "N=1 data analysis with multiple daily data points", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1autrid", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708365494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am developing a protocol for an N-of-1 study on headache pain and migraine occurrence.&lt;/p&gt;\n\n&lt;p&gt;This will be an exploratory Path model, and there are 2 DVs: Migraine=Yes/No and Headache intensity 0-10. Several physiological and psychological IVs. That in and of itself isn&amp;#39;t the main issue.&lt;/p&gt;\n\n&lt;p&gt;I want to collect data for the participant 3x per day and an additional time if an acute migraine occurs (to capture the IVs at the time of occurrence). If this were one collection per day, it would make sense to me how to do the analysis. However, how do I handle the data for multiple collections per day? Do I throw all the data together and consider the time of day as another IV? This &lt;em&gt;isn&amp;#39;t a time series or longitudinal study&lt;/em&gt; but a study of the antecedents to migraines and general headache pain.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1autrid", "is_robot_indexable": true, "report_reasons": null, "author": "jrdubbleu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1autrid/n1_data_analysis_with_multiple_daily_data_points/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1autrid/n1_data_analysis_with_multiple_daily_data_points/", "subreddit_subscribers": 1350793, "created_utc": 1708365494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I made a CLI tool called [womp](https://github.com/ndwarshuis/womp) (what's on my plate) to calculate nutrient data in a meal plan based on the USDA Food Data Central (FDC) database.\n\nThe general idea is that one specifies a meal plan using foods in the FDC database (or custom if they don't exist) and `womp` will aggregate and present the results either as a tree (JSON) or table (tsv). Many of the expected operations such as filtering/sorting/grouping/normalizing (by date, time interval, meal type, nutrient etc) are supported natively using CLI flags. If one wants to perform more complex analysis, the output formats lend themselves easily to consumption by more-powerful data analysis workflows based in python/R/etc.\n\nI realize there are already tools such as [cronometer](https://cronometer.com/) and other web apps like [this](https://www.nutritionvalue.org/nutritioncalculator.php) that can perform these functions. However, I wanted a tool that was lightweight, scriptable, and open source. Furthermore, the existing projects I could find on github that presented as \"FDC frontends\" did not meet my needs in terms of functionality or quality.\n\n`womp` more or less does what I need at the moment, so this is mostly a PSA for others who might be interested. I have the bandwith to fix bugs and review PRs, and add small new features. See \"potential future additions\" at the bottom of the readme (many of which are not \"small\" features so I would want help adding if someone actually wants them), or present the case for a new feature not already listed there.\n\nEnjoy :)", "author_fullname": "t2_69gfnoac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "presenting womp: an FDC-based nutrition calculator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auunuq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1708367537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made a CLI tool called &lt;a href=\"https://github.com/ndwarshuis/womp\"&gt;womp&lt;/a&gt; (what&amp;#39;s on my plate) to calculate nutrient data in a meal plan based on the USDA Food Data Central (FDC) database.&lt;/p&gt;\n\n&lt;p&gt;The general idea is that one specifies a meal plan using foods in the FDC database (or custom if they don&amp;#39;t exist) and &lt;code&gt;womp&lt;/code&gt; will aggregate and present the results either as a tree (JSON) or table (tsv). Many of the expected operations such as filtering/sorting/grouping/normalizing (by date, time interval, meal type, nutrient etc) are supported natively using CLI flags. If one wants to perform more complex analysis, the output formats lend themselves easily to consumption by more-powerful data analysis workflows based in python/R/etc.&lt;/p&gt;\n\n&lt;p&gt;I realize there are already tools such as &lt;a href=\"https://cronometer.com/\"&gt;cronometer&lt;/a&gt; and other web apps like &lt;a href=\"https://www.nutritionvalue.org/nutritioncalculator.php\"&gt;this&lt;/a&gt; that can perform these functions. However, I wanted a tool that was lightweight, scriptable, and open source. Furthermore, the existing projects I could find on github that presented as &amp;quot;FDC frontends&amp;quot; did not meet my needs in terms of functionality or quality.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;womp&lt;/code&gt; more or less does what I need at the moment, so this is mostly a PSA for others who might be interested. I have the bandwith to fix bugs and review PRs, and add small new features. See &amp;quot;potential future additions&amp;quot; at the bottom of the readme (many of which are not &amp;quot;small&amp;quot; features so I would want help adding if someone actually wants them), or present the case for a new feature not already listed there.&lt;/p&gt;\n\n&lt;p&gt;Enjoy :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/blAxToXCPBOp84BcvnewqQJ5KZaDVknvQex3BgW9feo.jpg?auto=webp&amp;s=ebd8900e69389bfb89f2a10a9ae4d1cf12b5aa35", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/blAxToXCPBOp84BcvnewqQJ5KZaDVknvQex3BgW9feo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc94f786f5afcaaa21c97de7e1b2844820b07f15", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/blAxToXCPBOp84BcvnewqQJ5KZaDVknvQex3BgW9feo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fb63e570416208c738377ae8aa7c987362390729", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/blAxToXCPBOp84BcvnewqQJ5KZaDVknvQex3BgW9feo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b03510ca9c5d2401705d5e3cfbafd429cdafd1c9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/blAxToXCPBOp84BcvnewqQJ5KZaDVknvQex3BgW9feo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4fc5cf5d12079184ede8e9affa286a64a2ae5d11", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/blAxToXCPBOp84BcvnewqQJ5KZaDVknvQex3BgW9feo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9449a7f7c3b3dc01ec0c3aac441de7233c3986bf", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/blAxToXCPBOp84BcvnewqQJ5KZaDVknvQex3BgW9feo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=94765cf600f7756749cd8e83a615b64c802b1a83", "width": 1080, "height": 540}], "variants": {}, "id": "Jj2sIJ5L6n2FTzmwI6MttcS6wRDihuK7UmeFD4V8tCU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1auunuq", "is_robot_indexable": true, "report_reasons": null, "author": "petrucci4prez", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1auunuq/presenting_womp_an_fdcbased_nutrition_calculator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1auunuq/presenting_womp_an_fdcbased_nutrition_calculator/", "subreddit_subscribers": 1350793, "created_utc": 1708367537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "First, I am adding the great thread from [here](https://www.reddit.com/r/datascience/comments/y3ty7k/what_are_your_thoughts_on_a_daily_standup/) about daily meetings for DS teams.\n\nDaily meetings are used for data scientists to briefly summarize what they did, well, in the last day. As mentioned in the first thread, it should not be longer than 90 sec per person, in some of the companies it is called stand-up meeting and it is done literally while standing in order to make it quick.\n\nHowever, I still have a few problems with it. Some context - I am a team lead in a mainly remote position.\n\nOur head of the department treats it as a place to mingle and get updated with everyone, that is, a mixture between a professional meeting and a social event. It usually makes this meeting being 25-30 minutes.\n\nIt seems that the team members join only because they must. They don't participate in a conversation, they don't exchange ideas, and basically just wait for the meeting to end. My head of the department, on the other side, is a big talker, and usually at the end of the daily starts with a five-seven minutes monologue about what he is going to do, what he did, and usually it is the same stuff that he already went over yesterday.\n\nMoreover, and sorry in advance for my French, it is the first meeting in the morning, so after one has their coffee and would prefer a silent morning/a meeting with the toilet, we have to nod for 30 minutes.\n\nLastly, and most importantly, things in DS are moving slowly. Not everyday we have things to update about. I have meetings with my team members every two days, which are profound, we brainstorm and derive tasks. This is the place where I track their progress and give them feedback. I don't need to see them every day (unless they need me).\n\n&amp;#x200B;\n\nI would like to ask my manager (head of) to make the daily meetings actually twice/three times a week, and instead, I will brief him myself, on 1on1, even on a daily for just the management.\n\n&amp;#x200B;", "author_fullname": "t2_4udseb4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do I politely ask the head of the department to cancel the daily meetings routine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1av80sc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708400853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First, I am adding the great thread from &lt;a href=\"https://www.reddit.com/r/datascience/comments/y3ty7k/what_are_your_thoughts_on_a_daily_standup/\"&gt;here&lt;/a&gt; about daily meetings for DS teams.&lt;/p&gt;\n\n&lt;p&gt;Daily meetings are used for data scientists to briefly summarize what they did, well, in the last day. As mentioned in the first thread, it should not be longer than 90 sec per person, in some of the companies it is called stand-up meeting and it is done literally while standing in order to make it quick.&lt;/p&gt;\n\n&lt;p&gt;However, I still have a few problems with it. Some context - I am a team lead in a mainly remote position.&lt;/p&gt;\n\n&lt;p&gt;Our head of the department treats it as a place to mingle and get updated with everyone, that is, a mixture between a professional meeting and a social event. It usually makes this meeting being 25-30 minutes.&lt;/p&gt;\n\n&lt;p&gt;It seems that the team members join only because they must. They don&amp;#39;t participate in a conversation, they don&amp;#39;t exchange ideas, and basically just wait for the meeting to end. My head of the department, on the other side, is a big talker, and usually at the end of the daily starts with a five-seven minutes monologue about what he is going to do, what he did, and usually it is the same stuff that he already went over yesterday.&lt;/p&gt;\n\n&lt;p&gt;Moreover, and sorry in advance for my French, it is the first meeting in the morning, so after one has their coffee and would prefer a silent morning/a meeting with the toilet, we have to nod for 30 minutes.&lt;/p&gt;\n\n&lt;p&gt;Lastly, and most importantly, things in DS are moving slowly. Not everyday we have things to update about. I have meetings with my team members every two days, which are profound, we brainstorm and derive tasks. This is the place where I track their progress and give them feedback. I don&amp;#39;t need to see them every day (unless they need me).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would like to ask my manager (head of) to make the daily meetings actually twice/three times a week, and instead, I will brief him myself, on 1on1, even on a daily for just the management.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1av80sc", "is_robot_indexable": true, "report_reasons": null, "author": "David202023", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1av80sc/how_do_i_politely_ask_the_head_of_the_department/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1av80sc/how_do_i_politely_ask_the_head_of_the_department/", "subreddit_subscribers": 1350793, "created_utc": 1708400853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I used to work with SQL server and teradata as data sources. It was fairly easy using SQL with them.\n\nNow there are new data sources in the data lake. And it's becoming confusing for me. Please help me understand what these are, why are they being used and how do I navigate best.\n\nWe're using mapR, hadoop, hive, hue, dremio, pyspark, yarn etc. In pyspark especially it's even more confusing because there are SQL statements that create a dataframe and then we create a view and then we store it somewhere only to read it on dremio later. \n\nPlease also give references of resources that I can go to and read about all these. But it would be awesome if somebody first give me a starter on these technologies.", "author_fullname": "t2_t8udov", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help understanding different data sources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aukoyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708340425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to work with SQL server and teradata as data sources. It was fairly easy using SQL with them.&lt;/p&gt;\n\n&lt;p&gt;Now there are new data sources in the data lake. And it&amp;#39;s becoming confusing for me. Please help me understand what these are, why are they being used and how do I navigate best.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re using mapR, hadoop, hive, hue, dremio, pyspark, yarn etc. In pyspark especially it&amp;#39;s even more confusing because there are SQL statements that create a dataframe and then we create a view and then we store it somewhere only to read it on dremio later. &lt;/p&gt;\n\n&lt;p&gt;Please also give references of resources that I can go to and read about all these. But it would be awesome if somebody first give me a starter on these technologies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1aukoyi", "is_robot_indexable": true, "report_reasons": null, "author": "maverick_css", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aukoyi/need_help_understanding_different_data_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aukoyi/need_help_understanding_different_data_sources/", "subreddit_subscribers": 1350793, "created_utc": 1708340425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I came to DS via a psychology/public health route, so have always been interested in bringing in reflective and reflexive practice into my workflow as a whole - and most times it's unavoidable as I've worked with health data etc. I came across this interesting primer paper on how reflexivity could be integrated to a workflow for those interested in doing it. Thoughts? \n\n[Here's the paper \n](https://compass.onlinelibrary.wiley.com/doi/full/10.1111/spc3.12735)", "author_fullname": "t2_21xnows", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reflexive practice in ds/quants as a whole", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ausgxy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708362489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came to DS via a psychology/public health route, so have always been interested in bringing in reflective and reflexive practice into my workflow as a whole - and most times it&amp;#39;s unavoidable as I&amp;#39;ve worked with health data etc. I came across this interesting primer paper on how reflexivity could be integrated to a workflow for those interested in doing it. Thoughts? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://compass.onlinelibrary.wiley.com/doi/full/10.1111/spc3.12735\"&gt;Here&amp;#39;s the paper \n&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "1ausgxy", "is_robot_indexable": true, "report_reasons": null, "author": "sellshell", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1ausgxy/reflexive_practice_in_dsquants_as_a_whole/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1ausgxy/reflexive_practice_in_dsquants_as_a_whole/", "subreddit_subscribers": 1350793, "created_utc": 1708362489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im working on a personal project for my data science portfolio which mostly consists of binary classifications so far. It's a CNN model to classify a news article as Real or Fake.\n\nAt first I was trying to train it on my laptop (RTX 3060 16gb RAM) but I was running into memory issues. I bough a google colab pro subscription and now have access to a machine with 51gb RAM, but I still get memory errors. What can I do to deal with this? I have attempted to split the data in half and train half at a time and I've also tried to train the data in batches but that doesn't seem to work, what should I do?", "author_fullname": "t2_ohgtbvx2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I deal with memory errors when training my model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auz9dp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.14, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708378134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im working on a personal project for my data science portfolio which mostly consists of binary classifications so far. It&amp;#39;s a CNN model to classify a news article as Real or Fake.&lt;/p&gt;\n\n&lt;p&gt;At first I was trying to train it on my laptop (RTX 3060 16gb RAM) but I was running into memory issues. I bough a google colab pro subscription and now have access to a machine with 51gb RAM, but I still get memory errors. What can I do to deal with this? I have attempted to split the data in half and train half at a time and I&amp;#39;ve also tried to train the data in batches but that doesn&amp;#39;t seem to work, what should I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1auz9dp", "is_robot_indexable": true, "report_reasons": null, "author": "MLMerchant", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1auz9dp/how_do_i_deal_with_memory_errors_when_training_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1auz9dp/how_do_i_deal_with_memory_errors_when_training_my/", "subreddit_subscribers": 1350793, "created_utc": 1708378134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "AI will surely cause major layoffs in the future. In 2000s there was an IT boom. In this age what will that boom be in? CS or Data jobs aren't growing exponentially or even linearly. Is the future the economy of gig/freelance work?", "author_fullname": "t2_dbamh5ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are really the jobs of the future? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aurxt5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708361277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;AI will surely cause major layoffs in the future. In 2000s there was an IT boom. In this age what will that boom be in? CS or Data jobs aren&amp;#39;t growing exponentially or even linearly. Is the future the economy of gig/freelance work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1aurxt5", "is_robot_indexable": true, "report_reasons": null, "author": "PresidentOfSerenland", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1aurxt5/what_are_really_the_jobs_of_the_future/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1aurxt5/what_are_really_the_jobs_of_the_future/", "subreddit_subscribers": 1350793, "created_utc": 1708361277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "All the recent breakthroughs in AI got me thinking. I think the question is pretty self-explanatory.\n\nIn my opinion, there will be 2 \"safe\" jobs.\n\nOne, high level ML engineer in big tech - the people who automate everybody's job - but not the ones in small companies who only do ML for local purposes, they won't be needed once the tools created by big software companies get good enough to easily implement anywhere.\n\nTwo, BI analyst - won't need to know how to do the math or programming, rather will be somebody who's an expert in the domain, knows the business needs, understands how to tell a story and what needs to be analyzed. Basically a \"soft skills\" person with power of AI at the click of a button, but still has some tech skills to understand the limitations. Main focus will be to bridge the gap between the AI and the purely business people, visualize, make dashboards, use the automated tools (similar to how BI analysts currently are, but due to the automation might take over some of the tasks that originally required a lot of math/programming and now will be simplified to the difficulty of Excel).\n\nData science and data analyst jobs (who spend time writing Python code and SQL queries) will imo be severely reduced or transform into BI analyst.\n\nNo opinion on Data Engineers as I'm not very familiar with it.", "author_fullname": "t2_r3n08loo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which DS/BI/analytics job will be the safest from automation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1auk2om", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1708337946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All the recent breakthroughs in AI got me thinking. I think the question is pretty self-explanatory.&lt;/p&gt;\n\n&lt;p&gt;In my opinion, there will be 2 &amp;quot;safe&amp;quot; jobs.&lt;/p&gt;\n\n&lt;p&gt;One, high level ML engineer in big tech - the people who automate everybody&amp;#39;s job - but not the ones in small companies who only do ML for local purposes, they won&amp;#39;t be needed once the tools created by big software companies get good enough to easily implement anywhere.&lt;/p&gt;\n\n&lt;p&gt;Two, BI analyst - won&amp;#39;t need to know how to do the math or programming, rather will be somebody who&amp;#39;s an expert in the domain, knows the business needs, understands how to tell a story and what needs to be analyzed. Basically a &amp;quot;soft skills&amp;quot; person with power of AI at the click of a button, but still has some tech skills to understand the limitations. Main focus will be to bridge the gap between the AI and the purely business people, visualize, make dashboards, use the automated tools (similar to how BI analysts currently are, but due to the automation might take over some of the tasks that originally required a lot of math/programming and now will be simplified to the difficulty of Excel).&lt;/p&gt;\n\n&lt;p&gt;Data science and data analyst jobs (who spend time writing Python code and SQL queries) will imo be severely reduced or transform into BI analyst.&lt;/p&gt;\n\n&lt;p&gt;No opinion on Data Engineers as I&amp;#39;m not very familiar with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1auk2om", "is_robot_indexable": true, "report_reasons": null, "author": "JabClotVanDamn", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1auk2om/which_dsbianalytics_job_will_be_the_safest_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1auk2om/which_dsbianalytics_job_will_be_the_safest_from/", "subreddit_subscribers": 1350793, "created_utc": 1708337946.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}