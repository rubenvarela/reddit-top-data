{"kind": "Listing", "data": {"after": "t3_1alqpq0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ok, to preface, I'm venting a bit here but it's also somewhat of a genuine question.   \nStory - I recently applied to a senior DE position for a well known consulting company. For the record, I've worked in Senior DE/BI roles over the past few years and I have a number of former colleagues and friends who work at this specific company so I know their tech stack and business fairly well. Also, for the record I am not a software engineer. I can hack my way through python or an OOP/functional language but SQL is my native dialect. Anyways, I applied for this role and the only glaring omission on my resume was Python experience. Given that I qualified in every other way the recruiter had me move forward to the technical assessment. The assessment was conducted in codility and there were three parts, a python coding portion, a sql coding portion and AWS questions. Coming out of the assessment I felt pretty good but I knew full well that my python solution was pretty rudimentary (admittedly), however it was functional and passed the test cases correctly. Anyways, I find out a few days later from the internal recruiter that my test results didn't fare so well. Although my sql solution was excellent and most of the AWS questions I answered correctly, my python solution wasn't efficient enough and failed on too many edge cases. As such the technical team couldn't recommend I move forward with the interview process (much to my dismay). Now, again... I never said I was a competent Python programmer, in fact I fully admitted that I had very little hands on experience in a business setting coding with python but I'm very familiar with OOP concepts and can pick up any language if/when needed. Either way it seemed like in this case my solution needed to impress the team more than it did.   \nSo, this brings me back to something the recruiter told me initially... her exact words were \"our data engineers are really software engineers at heart\". I'm wondering if this is becoming more and more the case as time goes on. When I got into BI and DE years ago SQL was the language of most importance (at least in my past roles)... now it seems that that isn't quite the case anymore. Thoughts?", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data engineers really just \"software engineers\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al3d2f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707313855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok, to preface, I&amp;#39;m venting a bit here but it&amp;#39;s also somewhat of a genuine question.&lt;br/&gt;\nStory - I recently applied to a senior DE position for a well known consulting company. For the record, I&amp;#39;ve worked in Senior DE/BI roles over the past few years and I have a number of former colleagues and friends who work at this specific company so I know their tech stack and business fairly well. Also, for the record I am not a software engineer. I can hack my way through python or an OOP/functional language but SQL is my native dialect. Anyways, I applied for this role and the only glaring omission on my resume was Python experience. Given that I qualified in every other way the recruiter had me move forward to the technical assessment. The assessment was conducted in codility and there were three parts, a python coding portion, a sql coding portion and AWS questions. Coming out of the assessment I felt pretty good but I knew full well that my python solution was pretty rudimentary (admittedly), however it was functional and passed the test cases correctly. Anyways, I find out a few days later from the internal recruiter that my test results didn&amp;#39;t fare so well. Although my sql solution was excellent and most of the AWS questions I answered correctly, my python solution wasn&amp;#39;t efficient enough and failed on too many edge cases. As such the technical team couldn&amp;#39;t recommend I move forward with the interview process (much to my dismay). Now, again... I never said I was a competent Python programmer, in fact I fully admitted that I had very little hands on experience in a business setting coding with python but I&amp;#39;m very familiar with OOP concepts and can pick up any language if/when needed. Either way it seemed like in this case my solution needed to impress the team more than it did.&lt;br/&gt;\nSo, this brings me back to something the recruiter told me initially... her exact words were &amp;quot;our data engineers are really software engineers at heart&amp;quot;. I&amp;#39;m wondering if this is becoming more and more the case as time goes on. When I got into BI and DE years ago SQL was the language of most importance (at least in my past roles)... now it seems that that isn&amp;#39;t quite the case anymore. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1al3d2f", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 107, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al3d2f/are_data_engineers_really_just_software_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al3d2f/are_data_engineers_really_just_software_engineers/", "subreddit_subscribers": 159160, "created_utc": 1707313855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I really liked the simplicity of the [One Billion Row Challenge (1BRC)](https://github.com/gunnarmorling/1brc) that took off last month.  It was fun to see lots of people apply different tools to the same simple-yet-clear problem \u201cHow do you parse, process, and aggregate a large CSV file as quickly as possible?\u201dFor fun, my colleagues and I made a One Trillion Row Challenge (1TRC) dataset \ud83d\ude42.  \n\nData lives on S3 in Parquet format (CSV made zero sense here) in a public bucket at s3://coiled-datasets-rp/1trc and is roughly 12 TiB uncompressed.\n\nWe (the Dask team) were able to complete the TRC query in around six minutes for around $1.10.For more information see [this blogpost](https://medium.com/coiled-hq/one-trillion-row-challenge-5bfd4c3b8aef) and [this repository](https://github.com/coiled/1trc/)", "author_fullname": "t2_ay1q1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One Trillion Row Challenge (1TRC)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al2r0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 113, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 113, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707312672.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707311999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really liked the simplicity of the &lt;a href=\"https://github.com/gunnarmorling/1brc\"&gt;One Billion Row Challenge (1BRC)&lt;/a&gt; that took off last month.  It was fun to see lots of people apply different tools to the same simple-yet-clear problem \u201cHow do you parse, process, and aggregate a large CSV file as quickly as possible?\u201dFor fun, my colleagues and I made a One Trillion Row Challenge (1TRC) dataset \ud83d\ude42.  &lt;/p&gt;\n\n&lt;p&gt;Data lives on S3 in Parquet format (CSV made zero sense here) in a public bucket at s3://coiled-datasets-rp/1trc and is roughly 12 TiB uncompressed.&lt;/p&gt;\n\n&lt;p&gt;We (the Dask team) were able to complete the TRC query in around six minutes for around $1.10.For more information see &lt;a href=\"https://medium.com/coiled-hq/one-trillion-row-challenge-5bfd4c3b8aef\"&gt;this blogpost&lt;/a&gt; and &lt;a href=\"https://github.com/coiled/1trc/\"&gt;this repository&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?auto=webp&amp;s=558d446820ecd10674797b0e6f49fdc49856cf1e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da65835d0e6cbeef974df8d596e45ac5dc483843", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b51501ef584c9420dcd557eeb630dae5484b90f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2dec7f7846841361ae42f1ff5a57c5c64305bbfa", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac5329409c2cd1ff7938f6f90ffc364fe33e65d9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=91ddd2cd259cedfb6aed6c8a05275dab5dff7375", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4ac4b5bfa44aaa021bee7aa7a99a716955fb1674", "width": 1080, "height": 540}], "variants": {}, "id": "G7IWiakRJ9OfkjMXOnB1vYS7kjkkSa22LpbV5hcjxvA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1al2r0o", "is_robot_indexable": true, "report_reasons": null, "author": "mrocklin", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al2r0o/one_trillion_row_challenge_1trc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al2r0o/one_trillion_row_challenge_1trc/", "subreddit_subscribers": 159160, "created_utc": 1707311999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a student of data engineering, and I just built my first pipelines using terraform, airflow, dbt, cosmos, snowflake, bigquery etc..\n\nBut all the tools I used were free... How the heck does Hashicorp (for terraform), Apache (for airflow), DBT labs (for dbt), and Astronomer (for cosmos) make any money? \n\nSorry just one of those embarrasingly basic questions but I still don't get it", "author_fullname": "t2_fq68u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do these companies make money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aldl7r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707339789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a student of data engineering, and I just built my first pipelines using terraform, airflow, dbt, cosmos, snowflake, bigquery etc..&lt;/p&gt;\n\n&lt;p&gt;But all the tools I used were free... How the heck does Hashicorp (for terraform), Apache (for airflow), DBT labs (for dbt), and Astronomer (for cosmos) make any money? &lt;/p&gt;\n\n&lt;p&gt;Sorry just one of those embarrasingly basic questions but I still don&amp;#39;t get it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aldl7r", "is_robot_indexable": true, "report_reasons": null, "author": "KimchiFitness", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aldl7r/how_do_these_companies_make_money/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aldl7r/how_do_these_companies_make_money/", "subreddit_subscribers": 159160, "created_utc": 1707339789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we use S3 for ingesting raw source data. We save it in unchanged format from source. Then in the next stage we transform them using python apps and save them as parquet files to S3 again. After that we take parquet files and load them into Postgres as final stage for consumers. \n\nHow do you handle realtime events data in such architecture to make them available to consumers within lets say 1-5s? I think dumping data from Kafka/RabbitMQ to go through the entire pipeline (raw, parquet, postgres) would take longer and saving them directly into postgres is probably not a good idea. Maybe dumping into S3 AND into Postgres? Or having another database for \u201crealtime\u201d events? Or is there any best practice for such case?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cLakehouse\u201d - Realtime data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al96or", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707328839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we use S3 for ingesting raw source data. We save it in unchanged format from source. Then in the next stage we transform them using python apps and save them as parquet files to S3 again. After that we take parquet files and load them into Postgres as final stage for consumers. &lt;/p&gt;\n\n&lt;p&gt;How do you handle realtime events data in such architecture to make them available to consumers within lets say 1-5s? I think dumping data from Kafka/RabbitMQ to go through the entire pipeline (raw, parquet, postgres) would take longer and saving them directly into postgres is probably not a good idea. Maybe dumping into S3 AND into Postgres? Or having another database for \u201crealtime\u201d events? Or is there any best practice for such case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1al96or", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al96or/lakehouse_realtime_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al96or/lakehouse_realtime_data/", "subreddit_subscribers": 159160, "created_utc": 1707328839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If I can help a large company save $30k dollars per month, by moving a data pipeline from pure S3 batch processing, to near real time, S3 event driven processing.\n\nAnd also save the company 100s of TB of data per month, by interacting with both Data Producers and consumers and finding the right columns and schema/data model to reduce external API calls and reduce data size at data lake.\n\nWhat more do companies want when they see my resume or take an initial round of interview? Whatever interviews I have given so far, don't seem to focus too much on my achievements, rather pin point shortcomings in my understanding of certain terms/concepts they want me to know.\n\nI am honestly asking you guys, why won't Engg Managers or Team Leads look past shortcomings to see that a person csn actively identify gaps and be really productive, while in the age of ChatGPT learn and understand the concepts or terms in Data engg that he/she may not be aware of?\n\nPlease give me detailed answers no matter how you see me question here", "author_fullname": "t2_pd3iqwqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What more do companies want? [Rant/RealityCheck]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1algpln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707347556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I can help a large company save $30k dollars per month, by moving a data pipeline from pure S3 batch processing, to near real time, S3 event driven processing.&lt;/p&gt;\n\n&lt;p&gt;And also save the company 100s of TB of data per month, by interacting with both Data Producers and consumers and finding the right columns and schema/data model to reduce external API calls and reduce data size at data lake.&lt;/p&gt;\n\n&lt;p&gt;What more do companies want when they see my resume or take an initial round of interview? Whatever interviews I have given so far, don&amp;#39;t seem to focus too much on my achievements, rather pin point shortcomings in my understanding of certain terms/concepts they want me to know.&lt;/p&gt;\n\n&lt;p&gt;I am honestly asking you guys, why won&amp;#39;t Engg Managers or Team Leads look past shortcomings to see that a person csn actively identify gaps and be really productive, while in the age of ChatGPT learn and understand the concepts or terms in Data engg that he/she may not be aware of?&lt;/p&gt;\n\n&lt;p&gt;Please give me detailed answers no matter how you see me question here&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1algpln", "is_robot_indexable": true, "report_reasons": null, "author": "sid_reddit141", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1algpln/what_more_do_companies_want_rantrealitycheck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1algpln/what_more_do_companies_want_rantrealitycheck/", "subreddit_subscribers": 159160, "created_utc": 1707347556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there! I'm a dev advocate at Airbyte, and we put together a list of industry trends all data engineers should know about - as well as some practical tips to make sure you're ahead of the curve. We also spoke with experts across the industry to get their take!  \n\n\nWhat trends are you most worried/excited/nonplussed by?\n\n[https://airbyte.com/blog/data-engineering-landscape-2024](https://airbyte.com/blog/data-engineering-landscape-2024)", "author_fullname": "t2_5h5nqi7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Navigating the Data Engineering Landscape 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al8dni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707326881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there! I&amp;#39;m a dev advocate at Airbyte, and we put together a list of industry trends all data engineers should know about - as well as some practical tips to make sure you&amp;#39;re ahead of the curve. We also spoke with experts across the industry to get their take!  &lt;/p&gt;\n\n&lt;p&gt;What trends are you most worried/excited/nonplussed by?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://airbyte.com/blog/data-engineering-landscape-2024\"&gt;https://airbyte.com/blog/data-engineering-landscape-2024&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?auto=webp&amp;s=4f84d1ff281c2afb45a43770d330187581e49ee7", "width": 2540, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dca99d3398b6ff856a22035090962d34f333209c", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b962bc4ee1b866402194e0c06f399b2f35306755", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=db7540334ec37e3fa5f8ed2d4bf0c35f39cebed0", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=24f667e9fc90cd33ef4964813a4138a54b2f6f9a", "width": 640, "height": 362}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d06cac90f5421b6d157974af24c383386576be78", "width": 960, "height": 544}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=41edd56cf0d23b7d3f94badbe058b5501de55c39", "width": 1080, "height": 612}], "variants": {}, "id": "fQIhx03Js0q7C-jgMTsBiCcEfNmX0A-1cp8NthF0avY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1al8dni", "is_robot_indexable": true, "report_reasons": null, "author": "Chemical-Treat6596", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al8dni/navigating_the_data_engineering_landscape_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al8dni/navigating_the_data_engineering_landscape_2024/", "subreddit_subscribers": 159160, "created_utc": 1707326881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Like Hadoop has mapreduce \nDatabricks and Aws glue use Spark\nWhat does snowflake use for computing?", "author_fullname": "t2_pp1jtay3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is compute engine in SnowFlake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1akzzx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707301930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like Hadoop has mapreduce \nDatabricks and Aws glue use Spark\nWhat does snowflake use for computing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1akzzx2", "is_robot_indexable": true, "report_reasons": null, "author": "mysticsoul1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1akzzx2/what_is_compute_engine_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1akzzx2/what_is_compute_engine_in_snowflake/", "subreddit_subscribers": 159160, "created_utc": 1707301930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently found out that my manager wants to assign me to a project in my company that will be in PySpark. The thing is that I have never really worked in Python, I've always been a Java/Scala dev. Should I agree to participate in that project, or should I stick with Scala/Java? Maybe if they don't find a Scala project for me, I'll have to find another job, idk.\n\nI'd switch to Python, but it feels to me like some toy language that is a wrapper around something written in other languages, I've seen code bases in Python, they get messy, there's just a bunch of functions in each file, instead of having a class per each file with some name that tells you what it does. Also the absence of type safety is kind of annoying. Today I also found a bug in Apache Iceberg for which there's a workaround in Scala, but no workaround in Python, which made me think that Scala is better, once again.\n\nOn the other hand, I've been thinking that I should probably delve deeper into Airflow, I've always just kind of coded in Spark, maybe I'd write some simple stuff in Airflow, but I never actually coded anything complicated in it. Airflow is in Python and there's pretty much no alternatives, because everyone uses it. Can one consider themselves a data engineer without actually knowing much of Airflow?\n\nI know some people will probably say \"Why not learn both?\" or whatever. In my experience it's not a good idea, because sometimes, in job interviews they ask in-depth questions about a particular language, for example how the GC works in the JVM, you may even be given some code and asked if it compiles... etc. You may have to write some stuff in Java or Scala using functional programming, and if you have been focusing on Python for a few months, you literally forget certain details of the syntax and tell the interviewer \"Sorry, I forgot how to do this one little thing in Scala, I need to google, because I've been doing some python recently\" and they may think that you are not the right fit for this job, you know?\n\nWhat's your opinion on all this? As you can see I lean towards sticking with Scala, but I know almost nothing about Python, so maybe you guys can convince me that I should switch.", "author_fullname": "t2_537mfbyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is switching to Python from Scala/Java in big data worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alffov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707344385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently found out that my manager wants to assign me to a project in my company that will be in PySpark. The thing is that I have never really worked in Python, I&amp;#39;ve always been a Java/Scala dev. Should I agree to participate in that project, or should I stick with Scala/Java? Maybe if they don&amp;#39;t find a Scala project for me, I&amp;#39;ll have to find another job, idk.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d switch to Python, but it feels to me like some toy language that is a wrapper around something written in other languages, I&amp;#39;ve seen code bases in Python, they get messy, there&amp;#39;s just a bunch of functions in each file, instead of having a class per each file with some name that tells you what it does. Also the absence of type safety is kind of annoying. Today I also found a bug in Apache Iceberg for which there&amp;#39;s a workaround in Scala, but no workaround in Python, which made me think that Scala is better, once again.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, I&amp;#39;ve been thinking that I should probably delve deeper into Airflow, I&amp;#39;ve always just kind of coded in Spark, maybe I&amp;#39;d write some simple stuff in Airflow, but I never actually coded anything complicated in it. Airflow is in Python and there&amp;#39;s pretty much no alternatives, because everyone uses it. Can one consider themselves a data engineer without actually knowing much of Airflow?&lt;/p&gt;\n\n&lt;p&gt;I know some people will probably say &amp;quot;Why not learn both?&amp;quot; or whatever. In my experience it&amp;#39;s not a good idea, because sometimes, in job interviews they ask in-depth questions about a particular language, for example how the GC works in the JVM, you may even be given some code and asked if it compiles... etc. You may have to write some stuff in Java or Scala using functional programming, and if you have been focusing on Python for a few months, you literally forget certain details of the syntax and tell the interviewer &amp;quot;Sorry, I forgot how to do this one little thing in Scala, I need to google, because I&amp;#39;ve been doing some python recently&amp;quot; and they may think that you are not the right fit for this job, you know?&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your opinion on all this? As you can see I lean towards sticking with Scala, but I know almost nothing about Python, so maybe you guys can convince me that I should switch.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1alffov", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous-Heat-6353", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alffov/is_switching_to_python_from_scalajava_in_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alffov/is_switching_to_python_from_scalajava_in_big_data/", "subreddit_subscribers": 159160, "created_utc": 1707344385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am a data engineer and I was wondering if there is any information security certification (like CISSP, etc) I can take to boost my career in DE field.\n\nRegards,", "author_fullname": "t2_dcnhwe2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Information Security skills for Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ale3kb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707341055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer and I was wondering if there is any information security certification (like CISSP, etc) I can take to boost my career in DE field.&lt;/p&gt;\n\n&lt;p&gt;Regards,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ale3kb", "is_robot_indexable": true, "report_reasons": null, "author": "MediumCat4064", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ale3kb/information_security_skills_for_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ale3kb/information_security_skills_for_data_engineer/", "subreddit_subscribers": 159160, "created_utc": 1707341055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone successfully tried the 250 MB Lambda Layer limit workaround by packaging their dependencies in EFS? Does it affect Lambda init time? What about concurrency - how many concurrent lambda executions can read from the shared EFS? Can serverless be used to deploy such lambda functions that use EFS for the importing the modules? Please don't suggest using containerized lambda functions .", "author_fullname": "t2_v8qhw4wd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using EFS for bigger python packages in AWS Lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al0znu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707306667.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707305959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone successfully tried the 250 MB Lambda Layer limit workaround by packaging their dependencies in EFS? Does it affect Lambda init time? What about concurrency - how many concurrent lambda executions can read from the shared EFS? Can serverless be used to deploy such lambda functions that use EFS for the importing the modules? Please don&amp;#39;t suggest using containerized lambda functions .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1al0znu", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Love_648", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al0znu/using_efs_for_bigger_python_packages_in_aws_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al0znu/using_efs_for_bigger_python_packages_in_aws_lambda/", "subreddit_subscribers": 159160, "created_utc": 1707305959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have read plenty of times that building projects can help me a lot to land a job (Although lately I have also read that recruiters don't really put much attention to this), so I'm here to ask for advice, how do you showcase your projects? Do you have custom webpages? Or you just post them in LinkedIn? Maybe you use GitHub? How you get interviewers to see what you worked on? \n\nAlso, can you share your projects portfolio with us? So I can see what type of projects are you building and maybe find some inspiration. \n\nThank you all", "author_fullname": "t2_4iz2pipg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you showcase your projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1almgy7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707363961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have read plenty of times that building projects can help me a lot to land a job (Although lately I have also read that recruiters don&amp;#39;t really put much attention to this), so I&amp;#39;m here to ask for advice, how do you showcase your projects? Do you have custom webpages? Or you just post them in LinkedIn? Maybe you use GitHub? How you get interviewers to see what you worked on? &lt;/p&gt;\n\n&lt;p&gt;Also, can you share your projects portfolio with us? So I can see what type of projects are you building and maybe find some inspiration. &lt;/p&gt;\n\n&lt;p&gt;Thank you all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1almgy7", "is_robot_indexable": true, "report_reasons": null, "author": "_Lavender_Brown_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1almgy7/how_do_you_showcase_your_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1almgy7/how_do_you_showcase_your_projects/", "subreddit_subscribers": 159160, "created_utc": 1707363961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I built an AI Agent that can connect to your database and run queries: [https://www.chaturdata.com/](https://www.chaturdata.com/)\n\nIt works like a SQL copilot for advanced SQL and you can use it through ChatGPT as a CustomGPT too.\n\nThere's a lot of text-to-sql ai tools out there, here are the 2 key differences about my approach:\n\n1. AI Agent - I give the Agent a bunch of tools and let it decide what tools to call, in what order, with which parameters, in order to help the user. this means you can ask super vague questions and the agent helps you think through coming up with good SQL\n2. AI-generated Data Dictionary &amp; embeddings - I use an LLM to create metadata about the db schemas including things like join keys, column descriptions, and table contents. I also convert this metadata into embeddings. this powers a kNN search that the agent can use to find the right data in the db.\n\nIt's free, would love your feedback if you get to try it out!", "author_fullname": "t2_ar4fq81f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI Copilot for writing and running SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alftfc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707345323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I built an AI Agent that can connect to your database and run queries: &lt;a href=\"https://www.chaturdata.com/\"&gt;https://www.chaturdata.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It works like a SQL copilot for advanced SQL and you can use it through ChatGPT as a CustomGPT too.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a lot of text-to-sql ai tools out there, here are the 2 key differences about my approach:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;AI Agent - I give the Agent a bunch of tools and let it decide what tools to call, in what order, with which parameters, in order to help the user. this means you can ask super vague questions and the agent helps you think through coming up with good SQL&lt;/li&gt;\n&lt;li&gt;AI-generated Data Dictionary &amp;amp; embeddings - I use an LLM to create metadata about the db schemas including things like join keys, column descriptions, and table contents. I also convert this metadata into embeddings. this powers a kNN search that the agent can use to find the right data in the db.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;It&amp;#39;s free, would love your feedback if you get to try it out!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1alftfc", "is_robot_indexable": true, "report_reasons": null, "author": "p5256", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alftfc/ai_copilot_for_writing_and_running_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alftfc/ai_copilot_for_writing_and_running_sql/", "subreddit_subscribers": 159160, "created_utc": 1707345323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm asking here because I assume you all know so much better.\n\nI'm not a data engineer and I'm working now just using Colab for a project I need to automate. It fetches data from BigQuery, then process the data, does NLP inference with a few APIs (hosting the models elsewhere) and then processes it back to another BigQuery table. Not difficult stuff but because it will process maybe around 10,000 - 20,000 rows and uses several NLPs to analyze it, it can take up to 30-45 mins, longer if there are errors and so on. \n\nI have looked at Prefect? I'm not picky for the tool and can really work with low-code solutions as long as it is intuitive. Would be great to have it serverless and then obviously run on a schedule (in batches - one time per day) so it's easy to set up and run. Is there a tool like this that isn't super expensive? I have one like this but it's with NodeJS so no dice. \n\nIf not, what are the best choices here? Would love some suggestions!", "author_fullname": "t2_n8b2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best option for automated \"long-running\" ETL pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alcsfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707337764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m asking here because I assume you all know so much better.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not a data engineer and I&amp;#39;m working now just using Colab for a project I need to automate. It fetches data from BigQuery, then process the data, does NLP inference with a few APIs (hosting the models elsewhere) and then processes it back to another BigQuery table. Not difficult stuff but because it will process maybe around 10,000 - 20,000 rows and uses several NLPs to analyze it, it can take up to 30-45 mins, longer if there are errors and so on. &lt;/p&gt;\n\n&lt;p&gt;I have looked at Prefect? I&amp;#39;m not picky for the tool and can really work with low-code solutions as long as it is intuitive. Would be great to have it serverless and then obviously run on a schedule (in batches - one time per day) so it&amp;#39;s easy to set up and run. Is there a tool like this that isn&amp;#39;t super expensive? I have one like this but it&amp;#39;s with NodeJS so no dice. &lt;/p&gt;\n\n&lt;p&gt;If not, what are the best choices here? Would love some suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1alcsfo", "is_robot_indexable": true, "report_reasons": null, "author": "ilsilfverskiold", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alcsfo/whats_the_best_option_for_automated_longrunning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alcsfo/whats_the_best_option_for_automated_longrunning/", "subreddit_subscribers": 159160, "created_utc": 1707337764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a 1 YOE Java/Scala developer working for a corporate tech company located in Turkey. During my time here im trying to improve myself in used technologies in the Data Engineering field to land a more Data focused job. I heard that due to Data being a trend in general nowadays , many companies also would like candidates to have a masters degree , how true is this? Also if its true, is it worth to get a distance education degree from major european countries(I cant attend to classes if its not distance education due to my work hours). I would also love some advices about getting into Data Engineering as a beginner :)\n\nThank you all for your help", "author_fullname": "t2_13mcsa6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is masters necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1alrme0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707383345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a 1 YOE Java/Scala developer working for a corporate tech company located in Turkey. During my time here im trying to improve myself in used technologies in the Data Engineering field to land a more Data focused job. I heard that due to Data being a trend in general nowadays , many companies also would like candidates to have a masters degree , how true is this? Also if its true, is it worth to get a distance education degree from major european countries(I cant attend to classes if its not distance education due to my work hours). I would also love some advices about getting into Data Engineering as a beginner :)&lt;/p&gt;\n\n&lt;p&gt;Thank you all for your help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1alrme0", "is_robot_indexable": true, "report_reasons": null, "author": "Chediras", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alrme0/is_masters_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alrme0/is_masters_necessary/", "subreddit_subscribers": 159160, "created_utc": 1707383345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title basically. Should I write about the projects differently to highlight the skills/features, etc.? Please suggest me some improvements. TIA  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/sxnbwv2yfbhc1.png?width=584&amp;format=png&amp;auto=webp&amp;s=c8f3eb7ddaf8080ad52df740c6240eb1f9af09b8", "author_fullname": "t2_o9rz9jf35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need feedback on my resume, I am not getting many calls. Your inputs would be valuable.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sxnbwv2yfbhc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 198, "x": 108, "u": "https://preview.redd.it/sxnbwv2yfbhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d3cd658463a35792c1e3307a1dca079142d41ed5"}, {"y": 397, "x": 216, "u": "https://preview.redd.it/sxnbwv2yfbhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=59a5b97088210abee121bca677470e242b1ef2aa"}, {"y": 589, "x": 320, "u": "https://preview.redd.it/sxnbwv2yfbhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b0e50f69f62561feadf965f633f0a1cd1f871e4"}], "s": {"y": 1075, "x": 584, "u": "https://preview.redd.it/sxnbwv2yfbhc1.png?width=584&amp;format=png&amp;auto=webp&amp;s=c8f3eb7ddaf8080ad52df740c6240eb1f9af09b8"}, "id": "sxnbwv2yfbhc1"}}, "name": "t3_1alqfqe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/tQqtoxqMmHjpkWS9LOj66YwfQWR1L9urykFwv-GCq24.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707378227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title basically. Should I write about the projects differently to highlight the skills/features, etc.? Please suggest me some improvements. TIA  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sxnbwv2yfbhc1.png?width=584&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c8f3eb7ddaf8080ad52df740c6240eb1f9af09b8\"&gt;https://preview.redd.it/sxnbwv2yfbhc1.png?width=584&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c8f3eb7ddaf8080ad52df740c6240eb1f9af09b8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1alqfqe", "is_robot_indexable": true, "report_reasons": null, "author": "No_Register_7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alqfqe/need_feedback_on_my_resume_i_am_not_getting_many/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alqfqe/need_feedback_on_my_resume_i_am_not_getting_many/", "subreddit_subscribers": 159160, "created_utc": 1707378227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys, i was just brainstorming on an alternative selfhosted data platform setup. Here is what I got from chatgpt :P feel free to comment and give suggestions / alternatives -- if it makes sense or no etc. I'm planning to set it up on my home lab as a personal experiment / project.\n\n## Components Overview\n\n* **MinIO**: Serves as the scalable object storage layer, compatible with Amazon S3 APIs, for storing structured and unstructured data.\n* **Apache Spark**: Provides large-scale data processing capabilities, useful for ETL jobs, batch processing, and stream processing.\n* **Trino**: A distributed SQL query engine designed for querying big data sets quickly across different data sources.\n* **Airflow**: Workflow orchestration tool used to schedule and monitor workflows, integrating with Spark, Trino, and other data processing tools.\n* **Apache Iceberg**: A table format for large-scale analytics, providing capabilities like schema evolution, hidden partitioning, and efficient upserts, which works well with both Trino and Spark for managing datasets in object storage like MinIO.\n\n## What Might Be Missing?\n\n* **Monitoring and Logging**: Tools like Prometheus, Grafana for monitoring, and ELK Stack (Elasticsearch, Logstash, Kibana) for logging and visualization. These are crucial for observing the health and performance of the data pipeline and infrastructure.\n* **Metadata Management**: Although Apache Iceberg provides table format and schema evolution, you might also consider a centralized metadata repository like Apache Atlas or Amundsen for data governance, lineage, and metadata discovery across your ecosystem.\n* **Security**: Integration with security and identity management tools, such as Apache Ranger for access control and Apache Knox for edge security, to ensure that data access is secure and compliant with policies.", "author_fullname": "t2_56myc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "open source data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alq9aj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707378225.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707377462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys, i was just brainstorming on an alternative selfhosted data platform setup. Here is what I got from chatgpt :P feel free to comment and give suggestions / alternatives -- if it makes sense or no etc. I&amp;#39;m planning to set it up on my home lab as a personal experiment / project.&lt;/p&gt;\n\n&lt;h2&gt;Components Overview&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;MinIO&lt;/strong&gt;: Serves as the scalable object storage layer, compatible with Amazon S3 APIs, for storing structured and unstructured data.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Apache Spark&lt;/strong&gt;: Provides large-scale data processing capabilities, useful for ETL jobs, batch processing, and stream processing.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Trino&lt;/strong&gt;: A distributed SQL query engine designed for querying big data sets quickly across different data sources.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Airflow&lt;/strong&gt;: Workflow orchestration tool used to schedule and monitor workflows, integrating with Spark, Trino, and other data processing tools.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Apache Iceberg&lt;/strong&gt;: A table format for large-scale analytics, providing capabilities like schema evolution, hidden partitioning, and efficient upserts, which works well with both Trino and Spark for managing datasets in object storage like MinIO.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;What Might Be Missing?&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Monitoring and Logging&lt;/strong&gt;: Tools like Prometheus, Grafana for monitoring, and ELK Stack (Elasticsearch, Logstash, Kibana) for logging and visualization. These are crucial for observing the health and performance of the data pipeline and infrastructure.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Metadata Management&lt;/strong&gt;: Although Apache Iceberg provides table format and schema evolution, you might also consider a centralized metadata repository like Apache Atlas or Amundsen for data governance, lineage, and metadata discovery across your ecosystem.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: Integration with security and identity management tools, such as Apache Ranger for access control and Apache Knox for edge security, to ensure that data access is secure and compliant with policies.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1alq9aj", "is_robot_indexable": true, "report_reasons": null, "author": "saintmichel", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alq9aj/open_source_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alq9aj/open_source_data_platform/", "subreddit_subscribers": 159160, "created_utc": 1707377462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While it seems like many DA and DS is thinking to transition into DE, I have the opposite thought. 'm considering a career change and would sincerely appreciate any advice!\n\nMy background includes a non-technical Bachelor's degree, followed by a Master's in Business Information Systems.\n\nIn my current Junior DE role, I work with BigQuery and SQL Server for managing data marts, and manage ETL pipelines using Airflow (though I didn't set it up).\n\nI very enjoyed tasks like data modeling, database design, data cleansing, SQL query and optimization, but my interest in Python programming is low (very actually). While I do use Airflow extensively, I rely on custom Airflow Operators for typical pipeline tasks and often seek guidance online/ChatGPT for issues like CSV delimiter conversion with Python.\n\nAlthough I'm okay with the level of Python programming aspect for my current role, I'm considering future career growth staying in DE, as I believe I won't go far if I don't enjoy programming.\n\nOn the flip side, I'm interested in data analysis and visualization, which I don't have hands-on experience in my current role but learning online in my free time. I'm wondering if transitioning to a Data Analyst role might better suit my long-term career goal. I have started seeking out for both role recently, one challenge is that many companies in my country still heavily rely on Excel for DA tasks rather than SQL.\n\nAny insights or recommendations would be greatly appreciated. Thank you in advance", "author_fullname": "t2_yb4x7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DA/DE: Any advice is appreciated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1almqhx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707364829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While it seems like many DA and DS is thinking to transition into DE, I have the opposite thought. &amp;#39;m considering a career change and would sincerely appreciate any advice!&lt;/p&gt;\n\n&lt;p&gt;My background includes a non-technical Bachelor&amp;#39;s degree, followed by a Master&amp;#39;s in Business Information Systems.&lt;/p&gt;\n\n&lt;p&gt;In my current Junior DE role, I work with BigQuery and SQL Server for managing data marts, and manage ETL pipelines using Airflow (though I didn&amp;#39;t set it up).&lt;/p&gt;\n\n&lt;p&gt;I very enjoyed tasks like data modeling, database design, data cleansing, SQL query and optimization, but my interest in Python programming is low (very actually). While I do use Airflow extensively, I rely on custom Airflow Operators for typical pipeline tasks and often seek guidance online/ChatGPT for issues like CSV delimiter conversion with Python.&lt;/p&gt;\n\n&lt;p&gt;Although I&amp;#39;m okay with the level of Python programming aspect for my current role, I&amp;#39;m considering future career growth staying in DE, as I believe I won&amp;#39;t go far if I don&amp;#39;t enjoy programming.&lt;/p&gt;\n\n&lt;p&gt;On the flip side, I&amp;#39;m interested in data analysis and visualization, which I don&amp;#39;t have hands-on experience in my current role but learning online in my free time. I&amp;#39;m wondering if transitioning to a Data Analyst role might better suit my long-term career goal. I have started seeking out for both role recently, one challenge is that many companies in my country still heavily rely on Excel for DA tasks rather than SQL.&lt;/p&gt;\n\n&lt;p&gt;Any insights or recommendations would be greatly appreciated. Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1almqhx", "is_robot_indexable": true, "report_reasons": null, "author": "Yenrusu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1almqhx/dade_any_advice_is_appreciated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1almqhx/dade_any_advice_is_appreciated/", "subreddit_subscribers": 159160, "created_utc": 1707364829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say that you have 10 compute engine that last for 20 minutes with minimum specs and you have one databricks cluster with 10 notebooks.\n\nThey do the same process, same code, same resources (ELT), which one is better in terms of cost?", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better databricks cluster or compute engine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1algef8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707346787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say that you have 10 compute engine that last for 20 minutes with minimum specs and you have one databricks cluster with 10 notebooks.&lt;/p&gt;\n\n&lt;p&gt;They do the same process, same code, same resources (ELT), which one is better in terms of cost?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1algef8", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1algef8/is_it_better_databricks_cluster_or_compute_engine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1algef8/is_it_better_databricks_cluster_or_compute_engine/", "subreddit_subscribers": 159160, "created_utc": 1707346787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my team's warehouse is an on-prem SQL warehouse and we use a mixture of stored procedures, CData Sync (3rd party tool), Synapse for ETL. \n\nSince the data is growing, we need scalibility in the warehouse. The different ETL procedures for different sources is an headacheare and we are highly dependent on CData Sync, which is another pain in the ars\u00eb. Our plan is to to shift our warehouse from on-prem to cloud, and keep a standardized ETL tool.\n\nI am responsible for the analysis, but this is my first company and I've only worked here for 1.5 year (So I don't have much idea on what is going on in the industry as such). I don't know why I'm given this responsibility but I am interested in doing the analysis. Now the internet is full of amazing suggestions, however I would want to know the answers and suggestions from people who have experience working on different warehouses and ETL tools in the industry. Hence, it would be really helpful if you answer these questions - \n\nAny amount of questions answered would be helpful.\n\n1. What warehouses and ETL tools were used in your past companies and your present company?\n\n2. Which warehouse did you prefer the most and why?\n\n3. Which ETL tool did you prefer the most and why?\n\n4. Any recommendations?\n\n5. What would you look for when changing the warehouse and ETL tool?\n\nP.S. Advice and tips appreciated \u2728", "author_fullname": "t2_svkuxhv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions on warehouse and etl", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aldru6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707340239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my team&amp;#39;s warehouse is an on-prem SQL warehouse and we use a mixture of stored procedures, CData Sync (3rd party tool), Synapse for ETL. &lt;/p&gt;\n\n&lt;p&gt;Since the data is growing, we need scalibility in the warehouse. The different ETL procedures for different sources is an headacheare and we are highly dependent on CData Sync, which is another pain in the ars\u00eb. Our plan is to to shift our warehouse from on-prem to cloud, and keep a standardized ETL tool.&lt;/p&gt;\n\n&lt;p&gt;I am responsible for the analysis, but this is my first company and I&amp;#39;ve only worked here for 1.5 year (So I don&amp;#39;t have much idea on what is going on in the industry as such). I don&amp;#39;t know why I&amp;#39;m given this responsibility but I am interested in doing the analysis. Now the internet is full of amazing suggestions, however I would want to know the answers and suggestions from people who have experience working on different warehouses and ETL tools in the industry. Hence, it would be really helpful if you answer these questions - &lt;/p&gt;\n\n&lt;p&gt;Any amount of questions answered would be helpful.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What warehouses and ETL tools were used in your past companies and your present company?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Which warehouse did you prefer the most and why?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Which ETL tool did you prefer the most and why?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Any recommendations?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What would you look for when changing the warehouse and ETL tool?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;P.S. Advice and tips appreciated \u2728&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aldru6", "is_robot_indexable": true, "report_reasons": null, "author": "beeneww", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aldru6/suggestions_on_warehouse_and_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aldru6/suggestions_on_warehouse_and_etl/", "subreddit_subscribers": 159160, "created_utc": 1707340239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I couldn't find a subreddit for dbt or an answer to this on Google so I'll put this to you guys\n\nI want to generate a database documentation for my dbt models which contains a list of columns contained in each table. I know I can use `dbt docs generate`  to create the documentation but as far as I understand I need to manually document the existing columns in the schema.yml so that they show in the documentation? So every time someone delete/add a column in the SQL they would need to reflect that change in the schema.yml file?  \n\n\nIt seems like there should be a way to automatically sync that column list from the corresponding SQL file but I don't seem to find how to do it. Does anyone have a solution?  \n", "author_fullname": "t2_grnvlbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically syncing DBT column schema with actual columns in corresponding SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al7hv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707324726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I couldn&amp;#39;t find a subreddit for dbt or an answer to this on Google so I&amp;#39;ll put this to you guys&lt;/p&gt;\n\n&lt;p&gt;I want to generate a database documentation for my dbt models which contains a list of columns contained in each table. I know I can use &lt;code&gt;dbt docs generate&lt;/code&gt;  to create the documentation but as far as I understand I need to manually document the existing columns in the schema.yml so that they show in the documentation? So every time someone delete/add a column in the SQL they would need to reflect that change in the schema.yml file?  &lt;/p&gt;\n\n&lt;p&gt;It seems like there should be a way to automatically sync that column list from the corresponding SQL file but I don&amp;#39;t seem to find how to do it. Does anyone have a solution?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1al7hv9", "is_robot_indexable": true, "report_reasons": null, "author": "Kenoai", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al7hv9/automatically_syncing_dbt_column_schema_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al7hv9/automatically_syncing_dbt_column_schema_with/", "subreddit_subscribers": 159160, "created_utc": 1707324726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " In today's fast-paced digital landscape, businesses are constantly evolving, and so is their data. Whether you're upgrading systems, transitioning to the cloud, or undergoing a merger, ensuring a seamless data migration process is critical for success. That's where our expert team comes in!\n\nWith years of experience and a proven track record, our [Data Migration Consulting Services](https://www.softwebsolutions.com/data-migration-services.html) are designed to streamline the entire migration journey, from assessment and planning to execution and validation. We leverage cutting-edge tools and best practices to minimize downtime, mitigate risks, and maximize the value of your data assets.\n\nHere's what sets us apart:  \n\ud83d\udd0d Comprehensive Assessment: We start by gaining a deep understanding of your unique data landscape, identifying potential challenges, and defining clear objectives.\n\n\ud83d\udcdd Tailored Strategy: Based on our assessment, we develop a customized migration strategy that aligns with your business goals, timelines, and budget.\n\n\ud83d\udee0\ufe0f Seamless Execution: Our team of experts handles every aspect of the migration process with precision and care, ensuring minimal disruption to your operations.\n\n\ud83d\udd12 Rigorous Validation: We conduct thorough testing and validation to ensure data integrity and accuracy post-migration, providing you with peace of mind.\n\n\ud83d\udca1 Ongoing Support: Our commitment doesn't end with the migration. We offer continuous support and optimization services to help you maximize the value of your newly migrated data.\n\nWhether you're migrating to a new platform, consolidating data sources, or modernizing your infrastructure, our Data Migration Consulting Services are here to guide you every step of the way.\n\nReady to unlock the full potential of your data? Contact us today to learn more!", "author_fullname": "t2_i09kr7uj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\ude80 Excited to announce the launch of our new Data Migration Consulting Services! \ud83d\udcca\ud83d\udcbc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1alsd5j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707386567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In today&amp;#39;s fast-paced digital landscape, businesses are constantly evolving, and so is their data. Whether you&amp;#39;re upgrading systems, transitioning to the cloud, or undergoing a merger, ensuring a seamless data migration process is critical for success. That&amp;#39;s where our expert team comes in!&lt;/p&gt;\n\n&lt;p&gt;With years of experience and a proven track record, our &lt;a href=\"https://www.softwebsolutions.com/data-migration-services.html\"&gt;Data Migration Consulting Services&lt;/a&gt; are designed to streamline the entire migration journey, from assessment and planning to execution and validation. We leverage cutting-edge tools and best practices to minimize downtime, mitigate risks, and maximize the value of your data assets.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what sets us apart:&lt;br/&gt;\n\ud83d\udd0d Comprehensive Assessment: We start by gaining a deep understanding of your unique data landscape, identifying potential challenges, and defining clear objectives.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcdd Tailored Strategy: Based on our assessment, we develop a customized migration strategy that aligns with your business goals, timelines, and budget.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udee0\ufe0f Seamless Execution: Our team of experts handles every aspect of the migration process with precision and care, ensuring minimal disruption to your operations.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd12 Rigorous Validation: We conduct thorough testing and validation to ensure data integrity and accuracy post-migration, providing you with peace of mind.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udca1 Ongoing Support: Our commitment doesn&amp;#39;t end with the migration. We offer continuous support and optimization services to help you maximize the value of your newly migrated data.&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re migrating to a new platform, consolidating data sources, or modernizing your infrastructure, our Data Migration Consulting Services are here to guide you every step of the way.&lt;/p&gt;\n\n&lt;p&gt;Ready to unlock the full potential of your data? Contact us today to learn more!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZQSn-jF2IE53mnVd5c5ZzTE5XBoNSlTIyIUC6Uk2FDE.jpg?auto=webp&amp;s=2f51145b210d54a63ab1ceb498613ae959719b10", "width": 780, "height": 496}, "resolutions": [{"url": "https://external-preview.redd.it/ZQSn-jF2IE53mnVd5c5ZzTE5XBoNSlTIyIUC6Uk2FDE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6e1ac9a7e4070034b84c9b4a99c68b3cbfa9ce90", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/ZQSn-jF2IE53mnVd5c5ZzTE5XBoNSlTIyIUC6Uk2FDE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f162f987878b1e8552b9368e5fe91c0edacaa2b", "width": 216, "height": 137}, {"url": "https://external-preview.redd.it/ZQSn-jF2IE53mnVd5c5ZzTE5XBoNSlTIyIUC6Uk2FDE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c10c639f75d91808c280af161f09b1e8ab8c108", "width": 320, "height": 203}, {"url": "https://external-preview.redd.it/ZQSn-jF2IE53mnVd5c5ZzTE5XBoNSlTIyIUC6Uk2FDE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8bd279bc1a2f343285802a0f030f703dfc516a42", "width": 640, "height": 406}], "variants": {}, "id": "3YYTJTitO-qwZnOMYk-08MU9lImbR1ONRhZFtQ4trJo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1alsd5j", "is_robot_indexable": true, "report_reasons": null, "author": "shreyasoftweb21", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alsd5j/excited_to_announce_the_launch_of_our_new_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alsd5j/excited_to_announce_the_launch_of_our_new_data/", "subreddit_subscribers": 159160, "created_utc": 1707386567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all \n\nI am transitioning from humanities into data with a hope to become an ML Engineer over time. I completed an MSc in AI at a good uni with the intention of joining a grad scheme after. Unfortunately I made a wrong turn by accepting a bad job offer for the wrong reasons. Fortunately I got a 'data job' as a data analyst at a multi national financial services company in UK. However the work is non-technical and I'm conscious of losing my technical skillset. \n\nIs it realistic to do DA &gt; DE &gt; MLE? And, if so, what hints, tips or steps should I take to help me get there?\n\nAny words of wisdom would be gratefully appreciated.", "author_fullname": "t2_tituct1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accepted Wrong Job - Have I F*****d it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1alrdj0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707382302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all &lt;/p&gt;\n\n&lt;p&gt;I am transitioning from humanities into data with a hope to become an ML Engineer over time. I completed an MSc in AI at a good uni with the intention of joining a grad scheme after. Unfortunately I made a wrong turn by accepting a bad job offer for the wrong reasons. Fortunately I got a &amp;#39;data job&amp;#39; as a data analyst at a multi national financial services company in UK. However the work is non-technical and I&amp;#39;m conscious of losing my technical skillset. &lt;/p&gt;\n\n&lt;p&gt;Is it realistic to do DA &amp;gt; DE &amp;gt; MLE? And, if so, what hints, tips or steps should I take to help me get there?&lt;/p&gt;\n\n&lt;p&gt;Any words of wisdom would be gratefully appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1alrdj0", "is_robot_indexable": true, "report_reasons": null, "author": "Due-Cap9761", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alrdj0/accepted_wrong_job_have_i_fd_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alrdj0/accepted_wrong_job_have_i_fd_it/", "subreddit_subscribers": 159160, "created_utc": 1707382302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instacart Creates Real-Time Item Availability Architecture with ML and Event Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_1alr9vq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dVRO-eqILiRqiZZejrpHb73Mcb6oOuulZZu2dvidYMo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707381866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2024/02/instacart-item-availability/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?auto=webp&amp;s=85ea2d7e4c33b36d21f7dcbfbec1dce723ee7c68", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e577e70a6e3d1971f8bb6ebfe8594adfbbca595c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a2bef1ae60dda26d289543fa4d23f2c89f61896", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad59f9bdc2ed4ab9b905f4483222da0bf8cbf6a5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca4eb6358b1c1d4221987ef6e89e70eea76faf5a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1659aede80371b2186da7b095e2cec314fd7558", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4952a46d13f1003ca42579b35b575619fba6f899", "width": 1080, "height": 567}], "variants": {}, "id": "XSahxUUd5FVHPhY4TdDVnFOJxZooJMAfLE1-aM_-Ups"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1alr9vq", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alr9vq/instacart_creates_realtime_item_availability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2024/02/instacart-item-availability/", "subreddit_subscribers": 159160, "created_utc": 1707381866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uwe2fsd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solving Streamlit's Authentication Problems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1alqxwj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ST0JMe5ErgM7FyA1Z6bKxbcuqs5pWCbcf7ofc_blpG4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707380393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "propelauth.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.propelauth.com/post/streamlit-authentication", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DPkFQ45L62ej9dxqvUl43kgcsuRTP0H4OG6pPEnzrQY.jpg?auto=webp&amp;s=f5e55311412d88209b6d143206f8ca70ab9c6339", "width": 1600, "height": 836}, "resolutions": [{"url": "https://external-preview.redd.it/DPkFQ45L62ej9dxqvUl43kgcsuRTP0H4OG6pPEnzrQY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=092d7a59e4d3de2d8f2d1fc0f617c65ee1ee5872", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/DPkFQ45L62ej9dxqvUl43kgcsuRTP0H4OG6pPEnzrQY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=40d5cd534b1c3e3d37ec3c82f0242c48e11b323d", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/DPkFQ45L62ej9dxqvUl43kgcsuRTP0H4OG6pPEnzrQY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=46b89fe60355dc41dd64528cbd4276891c43aa35", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/DPkFQ45L62ej9dxqvUl43kgcsuRTP0H4OG6pPEnzrQY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=82b3aaced8f85ad0de1751a49021d8a5eca551f4", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/DPkFQ45L62ej9dxqvUl43kgcsuRTP0H4OG6pPEnzrQY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=04937d76f1e17d4d6ec1b8fa11b4f4a64998f8d0", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/DPkFQ45L62ej9dxqvUl43kgcsuRTP0H4OG6pPEnzrQY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=939dbe0c066cf6226d14123c042f0dda555e0f84", "width": 1080, "height": 564}], "variants": {}, "id": "wFaQW74cJjLcQGktmGB7eUHS4CeOGaowaqybve2PRgY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1alqxwj", "is_robot_indexable": true, "report_reasons": null, "author": "TheLostWanderer47", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alqxwj/solving_streamlits_authentication_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.propelauth.com/post/streamlit-authentication", "subreddit_subscribers": 159160, "created_utc": 1707380393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need assistance in selecting the appropriate tool or application for a specific requirement in my MySQL database. The goal is to trigger a Jenkins job whenever there is an update in the database. After exploring options such as Nifi, Kafka, Argo-Events, and Flink, I'm unsure which tool would be most suitable for this use case. Any guidance or suggestions on how to proceed with this decision would be appreciated.", "author_fullname": "t2_cf09qk8i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a Webhook to Monitor MySQL Database Changes and Automate Jenkins Job Execution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alqpq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707379381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need assistance in selecting the appropriate tool or application for a specific requirement in my MySQL database. The goal is to trigger a Jenkins job whenever there is an update in the database. After exploring options such as Nifi, Kafka, Argo-Events, and Flink, I&amp;#39;m unsure which tool would be most suitable for this use case. Any guidance or suggestions on how to proceed with this decision would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1alqpq0", "is_robot_indexable": true, "report_reasons": null, "author": "Anxious_Reputation87", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alqpq0/creating_a_webhook_to_monitor_mysql_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alqpq0/creating_a_webhook_to_monitor_mysql_database/", "subreddit_subscribers": 159160, "created_utc": 1707379381.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}