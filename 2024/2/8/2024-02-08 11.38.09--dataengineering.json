{"kind": "Listing", "data": {"after": "t3_1alr9vq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ok, to preface, I'm venting a bit here but it's also somewhat of a genuine question.   \nStory - I recently applied to a senior DE position for a well known consulting company. For the record, I've worked in Senior DE/BI roles over the past few years and I have a number of former colleagues and friends who work at this specific company so I know their tech stack and business fairly well. Also, for the record I am not a software engineer. I can hack my way through python or an OOP/functional language but SQL is my native dialect. Anyways, I applied for this role and the only glaring omission on my resume was Python experience. Given that I qualified in every other way the recruiter had me move forward to the technical assessment. The assessment was conducted in codility and there were three parts, a python coding portion, a sql coding portion and AWS questions. Coming out of the assessment I felt pretty good but I knew full well that my python solution was pretty rudimentary (admittedly), however it was functional and passed the test cases correctly. Anyways, I find out a few days later from the internal recruiter that my test results didn't fare so well. Although my sql solution was excellent and most of the AWS questions I answered correctly, my python solution wasn't efficient enough and failed on too many edge cases. As such the technical team couldn't recommend I move forward with the interview process (much to my dismay). Now, again... I never said I was a competent Python programmer, in fact I fully admitted that I had very little hands on experience in a business setting coding with python but I'm very familiar with OOP concepts and can pick up any language if/when needed. Either way it seemed like in this case my solution needed to impress the team more than it did.   \nSo, this brings me back to something the recruiter told me initially... her exact words were \"our data engineers are really software engineers at heart\". I'm wondering if this is becoming more and more the case as time goes on. When I got into BI and DE years ago SQL was the language of most importance (at least in my past roles)... now it seems that that isn't quite the case anymore. Thoughts?", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data engineers really just \"software engineers\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al3d2f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707313855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok, to preface, I&amp;#39;m venting a bit here but it&amp;#39;s also somewhat of a genuine question.&lt;br/&gt;\nStory - I recently applied to a senior DE position for a well known consulting company. For the record, I&amp;#39;ve worked in Senior DE/BI roles over the past few years and I have a number of former colleagues and friends who work at this specific company so I know their tech stack and business fairly well. Also, for the record I am not a software engineer. I can hack my way through python or an OOP/functional language but SQL is my native dialect. Anyways, I applied for this role and the only glaring omission on my resume was Python experience. Given that I qualified in every other way the recruiter had me move forward to the technical assessment. The assessment was conducted in codility and there were three parts, a python coding portion, a sql coding portion and AWS questions. Coming out of the assessment I felt pretty good but I knew full well that my python solution was pretty rudimentary (admittedly), however it was functional and passed the test cases correctly. Anyways, I find out a few days later from the internal recruiter that my test results didn&amp;#39;t fare so well. Although my sql solution was excellent and most of the AWS questions I answered correctly, my python solution wasn&amp;#39;t efficient enough and failed on too many edge cases. As such the technical team couldn&amp;#39;t recommend I move forward with the interview process (much to my dismay). Now, again... I never said I was a competent Python programmer, in fact I fully admitted that I had very little hands on experience in a business setting coding with python but I&amp;#39;m very familiar with OOP concepts and can pick up any language if/when needed. Either way it seemed like in this case my solution needed to impress the team more than it did.&lt;br/&gt;\nSo, this brings me back to something the recruiter told me initially... her exact words were &amp;quot;our data engineers are really software engineers at heart&amp;quot;. I&amp;#39;m wondering if this is becoming more and more the case as time goes on. When I got into BI and DE years ago SQL was the language of most importance (at least in my past roles)... now it seems that that isn&amp;#39;t quite the case anymore. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1al3d2f", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 109, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al3d2f/are_data_engineers_really_just_software_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al3d2f/are_data_engineers_really_just_software_engineers/", "subreddit_subscribers": 159172, "created_utc": 1707313855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I really liked the simplicity of the [One Billion Row Challenge (1BRC)](https://github.com/gunnarmorling/1brc) that took off last month.  It was fun to see lots of people apply different tools to the same simple-yet-clear problem \u201cHow do you parse, process, and aggregate a large CSV file as quickly as possible?\u201dFor fun, my colleagues and I made a One Trillion Row Challenge (1TRC) dataset \ud83d\ude42.  \n\nData lives on S3 in Parquet format (CSV made zero sense here) in a public bucket at s3://coiled-datasets-rp/1trc and is roughly 12 TiB uncompressed.\n\nWe (the Dask team) were able to complete the TRC query in around six minutes for around $1.10.For more information see [this blogpost](https://medium.com/coiled-hq/one-trillion-row-challenge-5bfd4c3b8aef) and [this repository](https://github.com/coiled/1trc/)", "author_fullname": "t2_ay1q1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One Trillion Row Challenge (1TRC)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al2r0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 117, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 117, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707312672.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707311999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really liked the simplicity of the &lt;a href=\"https://github.com/gunnarmorling/1brc\"&gt;One Billion Row Challenge (1BRC)&lt;/a&gt; that took off last month.  It was fun to see lots of people apply different tools to the same simple-yet-clear problem \u201cHow do you parse, process, and aggregate a large CSV file as quickly as possible?\u201dFor fun, my colleagues and I made a One Trillion Row Challenge (1TRC) dataset \ud83d\ude42.  &lt;/p&gt;\n\n&lt;p&gt;Data lives on S3 in Parquet format (CSV made zero sense here) in a public bucket at s3://coiled-datasets-rp/1trc and is roughly 12 TiB uncompressed.&lt;/p&gt;\n\n&lt;p&gt;We (the Dask team) were able to complete the TRC query in around six minutes for around $1.10.For more information see &lt;a href=\"https://medium.com/coiled-hq/one-trillion-row-challenge-5bfd4c3b8aef\"&gt;this blogpost&lt;/a&gt; and &lt;a href=\"https://github.com/coiled/1trc/\"&gt;this repository&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?auto=webp&amp;s=558d446820ecd10674797b0e6f49fdc49856cf1e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da65835d0e6cbeef974df8d596e45ac5dc483843", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b51501ef584c9420dcd557eeb630dae5484b90f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2dec7f7846841361ae42f1ff5a57c5c64305bbfa", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac5329409c2cd1ff7938f6f90ffc364fe33e65d9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=91ddd2cd259cedfb6aed6c8a05275dab5dff7375", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/pdudUKqg1ppT11_6ZsY7IYKKLZso-5yFA5dsZzxBhCE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4ac4b5bfa44aaa021bee7aa7a99a716955fb1674", "width": 1080, "height": 540}], "variants": {}, "id": "G7IWiakRJ9OfkjMXOnB1vYS7kjkkSa22LpbV5hcjxvA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1al2r0o", "is_robot_indexable": true, "report_reasons": null, "author": "mrocklin", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al2r0o/one_trillion_row_challenge_1trc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al2r0o/one_trillion_row_challenge_1trc/", "subreddit_subscribers": 159172, "created_utc": 1707311999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a student of data engineering, and I just built my first pipelines using terraform, airflow, dbt, cosmos, snowflake, bigquery etc..\n\nBut all the tools I used were free... How the heck does Hashicorp (for terraform), Apache (for airflow), DBT labs (for dbt), and Astronomer (for cosmos) make any money? \n\nSorry just one of those embarrasingly basic questions but I still don't get it", "author_fullname": "t2_fq68u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do these companies make money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aldl7r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707339789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a student of data engineering, and I just built my first pipelines using terraform, airflow, dbt, cosmos, snowflake, bigquery etc..&lt;/p&gt;\n\n&lt;p&gt;But all the tools I used were free... How the heck does Hashicorp (for terraform), Apache (for airflow), DBT labs (for dbt), and Astronomer (for cosmos) make any money? &lt;/p&gt;\n\n&lt;p&gt;Sorry just one of those embarrasingly basic questions but I still don&amp;#39;t get it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aldl7r", "is_robot_indexable": true, "report_reasons": null, "author": "KimchiFitness", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aldl7r/how_do_these_companies_make_money/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aldl7r/how_do_these_companies_make_money/", "subreddit_subscribers": 159172, "created_utc": 1707339789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we use S3 for ingesting raw source data. We save it in unchanged format from source. Then in the next stage we transform them using python apps and save them as parquet files to S3 again. After that we take parquet files and load them into Postgres as final stage for consumers. \n\nHow do you handle realtime events data in such architecture to make them available to consumers within lets say 1-5s? I think dumping data from Kafka/RabbitMQ to go through the entire pipeline (raw, parquet, postgres) would take longer and saving them directly into postgres is probably not a good idea. Maybe dumping into S3 AND into Postgres? Or having another database for \u201crealtime\u201d events? Or is there any best practice for such case?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cLakehouse\u201d - Realtime data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al96or", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707328839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we use S3 for ingesting raw source data. We save it in unchanged format from source. Then in the next stage we transform them using python apps and save them as parquet files to S3 again. After that we take parquet files and load them into Postgres as final stage for consumers. &lt;/p&gt;\n\n&lt;p&gt;How do you handle realtime events data in such architecture to make them available to consumers within lets say 1-5s? I think dumping data from Kafka/RabbitMQ to go through the entire pipeline (raw, parquet, postgres) would take longer and saving them directly into postgres is probably not a good idea. Maybe dumping into S3 AND into Postgres? Or having another database for \u201crealtime\u201d events? Or is there any best practice for such case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1al96or", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al96or/lakehouse_realtime_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al96or/lakehouse_realtime_data/", "subreddit_subscribers": 159172, "created_utc": 1707328839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If I can help a large company save $30k dollars per month, by moving a data pipeline from pure S3 batch processing, to near real time, S3 event driven processing.\n\nAnd also save the company 100s of TB of data per month, by interacting with both Data Producers and consumers and finding the right columns and schema/data model to reduce external API calls and reduce data size at data lake.\n\nWhat more do companies want when they see my resume or take an initial round of interview? Whatever interviews I have given so far, don't seem to focus too much on my achievements, rather pin point shortcomings in my understanding of certain terms/concepts they want me to know.\n\nI am honestly asking you guys, why won't Engg Managers or Team Leads look past shortcomings to see that a person csn actively identify gaps and be really productive, while in the age of ChatGPT learn and understand the concepts or terms in Data engg that he/she may not be aware of?\n\nPlease give me detailed answers no matter how you see me question here", "author_fullname": "t2_pd3iqwqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What more do companies want? [Rant/RealityCheck]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1algpln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707347556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I can help a large company save $30k dollars per month, by moving a data pipeline from pure S3 batch processing, to near real time, S3 event driven processing.&lt;/p&gt;\n\n&lt;p&gt;And also save the company 100s of TB of data per month, by interacting with both Data Producers and consumers and finding the right columns and schema/data model to reduce external API calls and reduce data size at data lake.&lt;/p&gt;\n\n&lt;p&gt;What more do companies want when they see my resume or take an initial round of interview? Whatever interviews I have given so far, don&amp;#39;t seem to focus too much on my achievements, rather pin point shortcomings in my understanding of certain terms/concepts they want me to know.&lt;/p&gt;\n\n&lt;p&gt;I am honestly asking you guys, why won&amp;#39;t Engg Managers or Team Leads look past shortcomings to see that a person csn actively identify gaps and be really productive, while in the age of ChatGPT learn and understand the concepts or terms in Data engg that he/she may not be aware of?&lt;/p&gt;\n\n&lt;p&gt;Please give me detailed answers no matter how you see me question here&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1algpln", "is_robot_indexable": true, "report_reasons": null, "author": "sid_reddit141", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1algpln/what_more_do_companies_want_rantrealitycheck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1algpln/what_more_do_companies_want_rantrealitycheck/", "subreddit_subscribers": 159172, "created_utc": 1707347556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there! I'm a dev advocate at Airbyte, and we put together a list of industry trends all data engineers should know about - as well as some practical tips to make sure you're ahead of the curve. We also spoke with experts across the industry to get their take!  \n\n\nWhat trends are you most worried/excited/nonplussed by?\n\n[https://airbyte.com/blog/data-engineering-landscape-2024](https://airbyte.com/blog/data-engineering-landscape-2024)", "author_fullname": "t2_5h5nqi7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Navigating the Data Engineering Landscape 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al8dni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707326881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there! I&amp;#39;m a dev advocate at Airbyte, and we put together a list of industry trends all data engineers should know about - as well as some practical tips to make sure you&amp;#39;re ahead of the curve. We also spoke with experts across the industry to get their take!  &lt;/p&gt;\n\n&lt;p&gt;What trends are you most worried/excited/nonplussed by?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://airbyte.com/blog/data-engineering-landscape-2024\"&gt;https://airbyte.com/blog/data-engineering-landscape-2024&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?auto=webp&amp;s=4f84d1ff281c2afb45a43770d330187581e49ee7", "width": 2540, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dca99d3398b6ff856a22035090962d34f333209c", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b962bc4ee1b866402194e0c06f399b2f35306755", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=db7540334ec37e3fa5f8ed2d4bf0c35f39cebed0", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=24f667e9fc90cd33ef4964813a4138a54b2f6f9a", "width": 640, "height": 362}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d06cac90f5421b6d157974af24c383386576be78", "width": 960, "height": 544}, {"url": "https://external-preview.redd.it/SwJhwtl1x6Cah75-2N41Azx681vNJlGK71zGA5z-dfc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=41edd56cf0d23b7d3f94badbe058b5501de55c39", "width": 1080, "height": 612}], "variants": {}, "id": "fQIhx03Js0q7C-jgMTsBiCcEfNmX0A-1cp8NthF0avY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1al8dni", "is_robot_indexable": true, "report_reasons": null, "author": "Chemical-Treat6596", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al8dni/navigating_the_data_engineering_landscape_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al8dni/navigating_the_data_engineering_landscape_2024/", "subreddit_subscribers": 159172, "created_utc": 1707326881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently found out that my manager wants to assign me to a project in my company that will be in PySpark. The thing is that I have never really worked in Python, I've always been a Java/Scala dev. Should I agree to participate in that project, or should I stick with Scala/Java? Maybe if they don't find a Scala project for me, I'll have to find another job, idk.\n\nI'd switch to Python, but it feels to me like some toy language that is a wrapper around something written in other languages, I've seen code bases in Python, they get messy, there's just a bunch of functions in each file, instead of having a class per each file with some name that tells you what it does. Also the absence of type safety is kind of annoying. Today I also found a bug in Apache Iceberg for which there's a workaround in Scala, but no workaround in Python, which made me think that Scala is better, once again.\n\nOn the other hand, I've been thinking that I should probably delve deeper into Airflow, I've always just kind of coded in Spark, maybe I'd write some simple stuff in Airflow, but I never actually coded anything complicated in it. Airflow is in Python and there's pretty much no alternatives, because everyone uses it. Can one consider themselves a data engineer without actually knowing much of Airflow?\n\nI know some people will probably say \"Why not learn both?\" or whatever. In my experience it's not a good idea, because sometimes, in job interviews they ask in-depth questions about a particular language, for example how the GC works in the JVM, you may even be given some code and asked if it compiles... etc. You may have to write some stuff in Java or Scala using functional programming, and if you have been focusing on Python for a few months, you literally forget certain details of the syntax and tell the interviewer \"Sorry, I forgot how to do this one little thing in Scala, I need to google, because I've been doing some python recently\" and they may think that you are not the right fit for this job, you know?\n\nWhat's your opinion on all this? As you can see I lean towards sticking with Scala, but I know almost nothing about Python, so maybe you guys can convince me that I should switch.", "author_fullname": "t2_537mfbyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is switching to Python from Scala/Java in big data worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alffov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707344385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently found out that my manager wants to assign me to a project in my company that will be in PySpark. The thing is that I have never really worked in Python, I&amp;#39;ve always been a Java/Scala dev. Should I agree to participate in that project, or should I stick with Scala/Java? Maybe if they don&amp;#39;t find a Scala project for me, I&amp;#39;ll have to find another job, idk.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d switch to Python, but it feels to me like some toy language that is a wrapper around something written in other languages, I&amp;#39;ve seen code bases in Python, they get messy, there&amp;#39;s just a bunch of functions in each file, instead of having a class per each file with some name that tells you what it does. Also the absence of type safety is kind of annoying. Today I also found a bug in Apache Iceberg for which there&amp;#39;s a workaround in Scala, but no workaround in Python, which made me think that Scala is better, once again.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, I&amp;#39;ve been thinking that I should probably delve deeper into Airflow, I&amp;#39;ve always just kind of coded in Spark, maybe I&amp;#39;d write some simple stuff in Airflow, but I never actually coded anything complicated in it. Airflow is in Python and there&amp;#39;s pretty much no alternatives, because everyone uses it. Can one consider themselves a data engineer without actually knowing much of Airflow?&lt;/p&gt;\n\n&lt;p&gt;I know some people will probably say &amp;quot;Why not learn both?&amp;quot; or whatever. In my experience it&amp;#39;s not a good idea, because sometimes, in job interviews they ask in-depth questions about a particular language, for example how the GC works in the JVM, you may even be given some code and asked if it compiles... etc. You may have to write some stuff in Java or Scala using functional programming, and if you have been focusing on Python for a few months, you literally forget certain details of the syntax and tell the interviewer &amp;quot;Sorry, I forgot how to do this one little thing in Scala, I need to google, because I&amp;#39;ve been doing some python recently&amp;quot; and they may think that you are not the right fit for this job, you know?&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your opinion on all this? As you can see I lean towards sticking with Scala, but I know almost nothing about Python, so maybe you guys can convince me that I should switch.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1alffov", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous-Heat-6353", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alffov/is_switching_to_python_from_scalajava_in_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alffov/is_switching_to_python_from_scalajava_in_big_data/", "subreddit_subscribers": 159172, "created_utc": 1707344385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a 1 YOE Java/Scala developer working for a corporate tech company located in Turkey. During my time here im trying to improve myself in used technologies in the Data Engineering field to land a more Data focused job. I heard that due to Data being a trend in general nowadays , many companies also would like candidates to have a masters degree , how true is this? Also if its true, is it worth to get a distance education degree from major european countries(I cant attend to classes if its not distance education due to my work hours). I would also love some advices about getting into Data Engineering as a beginner :)\n\nThank you all for your help", "author_fullname": "t2_13mcsa6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is masters necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alrme0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707383345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a 1 YOE Java/Scala developer working for a corporate tech company located in Turkey. During my time here im trying to improve myself in used technologies in the Data Engineering field to land a more Data focused job. I heard that due to Data being a trend in general nowadays , many companies also would like candidates to have a masters degree , how true is this? Also if its true, is it worth to get a distance education degree from major european countries(I cant attend to classes if its not distance education due to my work hours). I would also love some advices about getting into Data Engineering as a beginner :)&lt;/p&gt;\n\n&lt;p&gt;Thank you all for your help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1alrme0", "is_robot_indexable": true, "report_reasons": null, "author": "Chediras", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alrme0/is_masters_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alrme0/is_masters_necessary/", "subreddit_subscribers": 159172, "created_utc": 1707383345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am a data engineer and I was wondering if there is any information security certification (like CISSP, etc) I can take to boost my career in DE field.\n\nRegards,", "author_fullname": "t2_dcnhwe2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Information Security skills for Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ale3kb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707341055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer and I was wondering if there is any information security certification (like CISSP, etc) I can take to boost my career in DE field.&lt;/p&gt;\n\n&lt;p&gt;Regards,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ale3kb", "is_robot_indexable": true, "report_reasons": null, "author": "MediumCat4064", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ale3kb/information_security_skills_for_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ale3kb/information_security_skills_for_data_engineer/", "subreddit_subscribers": 159172, "created_utc": 1707341055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone successfully tried the 250 MB Lambda Layer limit workaround by packaging their dependencies in EFS? Does it affect Lambda init time? What about concurrency - how many concurrent lambda executions can read from the shared EFS? Can serverless be used to deploy such lambda functions that use EFS for the importing the modules? Please don't suggest using containerized lambda functions .", "author_fullname": "t2_v8qhw4wd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using EFS for bigger python packages in AWS Lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al0znu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707306667.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707305959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone successfully tried the 250 MB Lambda Layer limit workaround by packaging their dependencies in EFS? Does it affect Lambda init time? What about concurrency - how many concurrent lambda executions can read from the shared EFS? Can serverless be used to deploy such lambda functions that use EFS for the importing the modules? Please don&amp;#39;t suggest using containerized lambda functions .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1al0znu", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Love_648", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al0znu/using_efs_for_bigger_python_packages_in_aws_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al0znu/using_efs_for_bigger_python_packages_in_aws_lambda/", "subreddit_subscribers": 159172, "created_utc": 1707305959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title basically. Should I write about the projects differently to highlight the skills/features, etc.? Please suggest me some improvements. TIA  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/sxnbwv2yfbhc1.png?width=584&amp;format=png&amp;auto=webp&amp;s=c8f3eb7ddaf8080ad52df740c6240eb1f9af09b8", "author_fullname": "t2_o9rz9jf35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need feedback on my resume, I am not getting many calls. Your inputs would be valuable.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sxnbwv2yfbhc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 198, "x": 108, "u": "https://preview.redd.it/sxnbwv2yfbhc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d3cd658463a35792c1e3307a1dca079142d41ed5"}, {"y": 397, "x": 216, "u": "https://preview.redd.it/sxnbwv2yfbhc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=59a5b97088210abee121bca677470e242b1ef2aa"}, {"y": 589, "x": 320, "u": "https://preview.redd.it/sxnbwv2yfbhc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b0e50f69f62561feadf965f633f0a1cd1f871e4"}], "s": {"y": 1075, "x": 584, "u": "https://preview.redd.it/sxnbwv2yfbhc1.png?width=584&amp;format=png&amp;auto=webp&amp;s=c8f3eb7ddaf8080ad52df740c6240eb1f9af09b8"}, "id": "sxnbwv2yfbhc1"}}, "name": "t3_1alqfqe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/tQqtoxqMmHjpkWS9LOj66YwfQWR1L9urykFwv-GCq24.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707378227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title basically. Should I write about the projects differently to highlight the skills/features, etc.? Please suggest me some improvements. TIA  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sxnbwv2yfbhc1.png?width=584&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c8f3eb7ddaf8080ad52df740c6240eb1f9af09b8\"&gt;https://preview.redd.it/sxnbwv2yfbhc1.png?width=584&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c8f3eb7ddaf8080ad52df740c6240eb1f9af09b8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1alqfqe", "is_robot_indexable": true, "report_reasons": null, "author": "No_Register_7", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alqfqe/need_feedback_on_my_resume_i_am_not_getting_many/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alqfqe/need_feedback_on_my_resume_i_am_not_getting_many/", "subreddit_subscribers": 159172, "created_utc": 1707378227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have read plenty of times that building projects can help me a lot to land a job (Although lately I have also read that recruiters don't really put much attention to this), so I'm here to ask for advice, how do you showcase your projects? Do you have custom webpages? Or you just post them in LinkedIn? Maybe you use GitHub? How you get interviewers to see what you worked on? \n\nAlso, can you share your projects portfolio with us? So I can see what type of projects are you building and maybe find some inspiration. \n\nThank you all", "author_fullname": "t2_4iz2pipg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you showcase your projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1almgy7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707363961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have read plenty of times that building projects can help me a lot to land a job (Although lately I have also read that recruiters don&amp;#39;t really put much attention to this), so I&amp;#39;m here to ask for advice, how do you showcase your projects? Do you have custom webpages? Or you just post them in LinkedIn? Maybe you use GitHub? How you get interviewers to see what you worked on? &lt;/p&gt;\n\n&lt;p&gt;Also, can you share your projects portfolio with us? So I can see what type of projects are you building and maybe find some inspiration. &lt;/p&gt;\n\n&lt;p&gt;Thank you all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1almgy7", "is_robot_indexable": true, "report_reasons": null, "author": "_Lavender_Brown_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1almgy7/how_do_you_showcase_your_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1almgy7/how_do_you_showcase_your_projects/", "subreddit_subscribers": 159172, "created_utc": 1707363961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I built an AI Agent that can connect to your database and run queries: [https://www.chaturdata.com/](https://www.chaturdata.com/)\n\nIt works like a SQL copilot for advanced SQL and you can use it through ChatGPT as a CustomGPT too.\n\nThere's a lot of text-to-sql ai tools out there, here are the 2 key differences about my approach:\n\n1. AI Agent - I give the Agent a bunch of tools and let it decide what tools to call, in what order, with which parameters, in order to help the user. this means you can ask super vague questions and the agent helps you think through coming up with good SQL\n2. AI-generated Data Dictionary &amp; embeddings - I use an LLM to create metadata about the db schemas including things like join keys, column descriptions, and table contents. I also convert this metadata into embeddings. this powers a kNN search that the agent can use to find the right data in the db.\n\nIt's free, would love your feedback if you get to try it out!", "author_fullname": "t2_ar4fq81f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI Copilot for writing and running SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alftfc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707345323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I built an AI Agent that can connect to your database and run queries: &lt;a href=\"https://www.chaturdata.com/\"&gt;https://www.chaturdata.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It works like a SQL copilot for advanced SQL and you can use it through ChatGPT as a CustomGPT too.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a lot of text-to-sql ai tools out there, here are the 2 key differences about my approach:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;AI Agent - I give the Agent a bunch of tools and let it decide what tools to call, in what order, with which parameters, in order to help the user. this means you can ask super vague questions and the agent helps you think through coming up with good SQL&lt;/li&gt;\n&lt;li&gt;AI-generated Data Dictionary &amp;amp; embeddings - I use an LLM to create metadata about the db schemas including things like join keys, column descriptions, and table contents. I also convert this metadata into embeddings. this powers a kNN search that the agent can use to find the right data in the db.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;It&amp;#39;s free, would love your feedback if you get to try it out!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1alftfc", "is_robot_indexable": true, "report_reasons": null, "author": "p5256", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alftfc/ai_copilot_for_writing_and_running_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alftfc/ai_copilot_for_writing_and_running_sql/", "subreddit_subscribers": 159172, "created_utc": 1707345323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm asking here because I assume you all know so much better.\n\nI'm not a data engineer and I'm working now just using Colab for a project I need to automate. It fetches data from BigQuery, then process the data, does NLP inference with a few APIs (hosting the models elsewhere) and then processes it back to another BigQuery table. Not difficult stuff but because it will process maybe around 10,000 - 20,000 rows and uses several NLPs to analyze it, it can take up to 30-45 mins, longer if there are errors and so on. \n\nI have looked at Prefect? I'm not picky for the tool and can really work with low-code solutions as long as it is intuitive. Would be great to have it serverless and then obviously run on a schedule (in batches - one time per day) so it's easy to set up and run. Is there a tool like this that isn't super expensive? I have one like this but it's with NodeJS so no dice. \n\nIf not, what are the best choices here? Would love some suggestions!", "author_fullname": "t2_n8b2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best option for automated \"long-running\" ETL pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alcsfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707337764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m asking here because I assume you all know so much better.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not a data engineer and I&amp;#39;m working now just using Colab for a project I need to automate. It fetches data from BigQuery, then process the data, does NLP inference with a few APIs (hosting the models elsewhere) and then processes it back to another BigQuery table. Not difficult stuff but because it will process maybe around 10,000 - 20,000 rows and uses several NLPs to analyze it, it can take up to 30-45 mins, longer if there are errors and so on. &lt;/p&gt;\n\n&lt;p&gt;I have looked at Prefect? I&amp;#39;m not picky for the tool and can really work with low-code solutions as long as it is intuitive. Would be great to have it serverless and then obviously run on a schedule (in batches - one time per day) so it&amp;#39;s easy to set up and run. Is there a tool like this that isn&amp;#39;t super expensive? I have one like this but it&amp;#39;s with NodeJS so no dice. &lt;/p&gt;\n\n&lt;p&gt;If not, what are the best choices here? Would love some suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1alcsfo", "is_robot_indexable": true, "report_reasons": null, "author": "ilsilfverskiold", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alcsfo/whats_the_best_option_for_automated_longrunning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alcsfo/whats_the_best_option_for_automated_longrunning/", "subreddit_subscribers": 159172, "created_utc": 1707337764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data Enthusiasts!\n\nI've been exploring a fascinating aspect of data quality and integrity that's crucial for anyone working with historical data, especially in the context of dbt (Data Build Tool): **Drift Testing**. This method is not just about identifying issues; it's about proactively ensuring our data's reliability over time, particularly through dbt's snapshotting capabilities.\n\n**What is Drift Testing with dbt?**\n\nDrift testing in the realm of dbt involves analyzing and monitoring changes in your data over time to ensure consistency and accuracy. It's particularly relevant when using dbt's snapshot feature, which captures and stores historical data changes. By applying drift testing to these snapshots, we can detect any unintended alterations in our data's behavior or structure, ensuring our historical records remain a reliable foundation for analysis and decision-making.\n\n**Implementing Drift Testing in dbt**\n\nImplementing drift testing with dbt involves a few key steps:\n\n* **Snapshotting Your Data**: Utilize dbt's snapshot feature to capture the state of your data at regular intervals. This forms the basis of your historical dataset for drift testing.\n* **Defining Drift Tests**: \n\n1. Create a *\\*.datadrift.py*  tests file that define what constitutes an acceptable change in your data. This could involve statistical measures or specific business rules relevant to your data's context. [Follow this doc](https://github.com/data-drift/data-drift/blob/main/tools/driftdb/dbt-snapshot-testing-docs/dbt-snapshot-testing.md)\n2. Then run `driftdb snapshot check`  \n\n* **Automating Tests**: \n\n1. Configure an alert transport to create github issues or slack message\n2. Incorporate these tests into your dbt workflows to run automatically, ensuring continuous monitoring of your data's quality and consistency.\n\n* **Troubleshoot:**\n\n1. Within the alert you have the context of the drift and a command `driftdb snaphsot show` to understand the lineage change, or the code change that introduce the drift.  \n\n\nIf you like the subject please star us: [https://github.com/data-drift/data-drift](https://github.com/data-drift/data-drift) and [join the waitlist](https://www.data-drift.io/).\n\nThanks for reading \ud83d\udc9a", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unveiling Drift Testing: The Unsung Hero in Maintaining Historical Data Integrity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1alszxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1707389279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Enthusiasts!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been exploring a fascinating aspect of data quality and integrity that&amp;#39;s crucial for anyone working with historical data, especially in the context of dbt (Data Build Tool): &lt;strong&gt;Drift Testing&lt;/strong&gt;. This method is not just about identifying issues; it&amp;#39;s about proactively ensuring our data&amp;#39;s reliability over time, particularly through dbt&amp;#39;s snapshotting capabilities.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What is Drift Testing with dbt?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Drift testing in the realm of dbt involves analyzing and monitoring changes in your data over time to ensure consistency and accuracy. It&amp;#39;s particularly relevant when using dbt&amp;#39;s snapshot feature, which captures and stores historical data changes. By applying drift testing to these snapshots, we can detect any unintended alterations in our data&amp;#39;s behavior or structure, ensuring our historical records remain a reliable foundation for analysis and decision-making.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Implementing Drift Testing in dbt&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Implementing drift testing with dbt involves a few key steps:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Snapshotting Your Data&lt;/strong&gt;: Utilize dbt&amp;#39;s snapshot feature to capture the state of your data at regular intervals. This forms the basis of your historical dataset for drift testing.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Defining Drift Tests&lt;/strong&gt;: &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a &lt;em&gt;\\&lt;/em&gt;.datadrift.py*  tests file that define what constitutes an acceptable change in your data. This could involve statistical measures or specific business rules relevant to your data&amp;#39;s context. &lt;a href=\"https://github.com/data-drift/data-drift/blob/main/tools/driftdb/dbt-snapshot-testing-docs/dbt-snapshot-testing.md\"&gt;Follow this doc&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Then run &lt;code&gt;driftdb snapshot check&lt;/code&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Automating Tests&lt;/strong&gt;: &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Configure an alert transport to create github issues or slack message&lt;/li&gt;\n&lt;li&gt;Incorporate these tests into your dbt workflows to run automatically, ensuring continuous monitoring of your data&amp;#39;s quality and consistency.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Troubleshoot:&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Within the alert you have the context of the drift and a command &lt;code&gt;driftdb snaphsot show&lt;/code&gt; to understand the lineage change, or the code change that introduce the drift.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If you like the subject please star us: &lt;a href=\"https://github.com/data-drift/data-drift\"&gt;https://github.com/data-drift/data-drift&lt;/a&gt; and &lt;a href=\"https://www.data-drift.io/\"&gt;join the waitlist&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading \ud83d\udc9a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pWFchKI7Gw-l_QmNG2jrV52vRvTnmgNGpUFgClPM5EY.jpg?auto=webp&amp;s=93b9a72a2fee42a1c8a395309744d3457659ab66", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/pWFchKI7Gw-l_QmNG2jrV52vRvTnmgNGpUFgClPM5EY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=90d48a5d1b1db785658c9f697cb221ce2f6bff3a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/pWFchKI7Gw-l_QmNG2jrV52vRvTnmgNGpUFgClPM5EY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab7a1926026900b16a5069821cd4a6e2b30d6300", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/pWFchKI7Gw-l_QmNG2jrV52vRvTnmgNGpUFgClPM5EY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf3d0dc43584169da2388b26c52ea28ea848568e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/pWFchKI7Gw-l_QmNG2jrV52vRvTnmgNGpUFgClPM5EY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6e162cff3bea910695932d1c4657248196a7932d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/pWFchKI7Gw-l_QmNG2jrV52vRvTnmgNGpUFgClPM5EY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d929d3eeaea4772c6f8af1ee914ad7bea39e57e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/pWFchKI7Gw-l_QmNG2jrV52vRvTnmgNGpUFgClPM5EY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6db029d0eb8ecaa818bda6b6ac32ab0e102c8924", "width": 1080, "height": 540}], "variants": {}, "id": "NdVpd_L1aet6td7wIRL3qXYuXQxAWXiMdrPxuedItNk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1alszxs", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alszxs/unveiling_drift_testing_the_unsung_hero_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alszxs/unveiling_drift_testing_the_unsung_hero_in/", "subreddit_subscribers": 159172, "created_utc": 1707389279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys, i was just brainstorming on an alternative selfhosted data platform setup. Here is what I got from chatgpt :P feel free to comment and give suggestions / alternatives -- if it makes sense or no etc. I'm planning to set it up on my home lab as a personal experiment / project.\n\n## Components Overview\n\n* **MinIO**: Serves as the scalable object storage layer, compatible with Amazon S3 APIs, for storing structured and unstructured data.\n* **Apache Spark**: Provides large-scale data processing capabilities, useful for ETL jobs, batch processing, and stream processing.\n* **Trino**: A distributed SQL query engine designed for querying big data sets quickly across different data sources.\n* **Airflow**: Workflow orchestration tool used to schedule and monitor workflows, integrating with Spark, Trino, and other data processing tools.\n* **Apache Iceberg**: A table format for large-scale analytics, providing capabilities like schema evolution, hidden partitioning, and efficient upserts, which works well with both Trino and Spark for managing datasets in object storage like MinIO.\n\n## What Might Be Missing?\n\n* **Monitoring and Logging**: Tools like Prometheus, Grafana for monitoring, and ELK Stack (Elasticsearch, Logstash, Kibana) for logging and visualization. These are crucial for observing the health and performance of the data pipeline and infrastructure.\n* **Metadata Management**: Although Apache Iceberg provides table format and schema evolution, you might also consider a centralized metadata repository like Apache Atlas or Amundsen for data governance, lineage, and metadata discovery across your ecosystem.\n* **Security**: Integration with security and identity management tools, such as Apache Ranger for access control and Apache Knox for edge security, to ensure that data access is secure and compliant with policies.", "author_fullname": "t2_56myc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "open source data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alq9aj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707378225.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707377462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys, i was just brainstorming on an alternative selfhosted data platform setup. Here is what I got from chatgpt :P feel free to comment and give suggestions / alternatives -- if it makes sense or no etc. I&amp;#39;m planning to set it up on my home lab as a personal experiment / project.&lt;/p&gt;\n\n&lt;h2&gt;Components Overview&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;MinIO&lt;/strong&gt;: Serves as the scalable object storage layer, compatible with Amazon S3 APIs, for storing structured and unstructured data.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Apache Spark&lt;/strong&gt;: Provides large-scale data processing capabilities, useful for ETL jobs, batch processing, and stream processing.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Trino&lt;/strong&gt;: A distributed SQL query engine designed for querying big data sets quickly across different data sources.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Airflow&lt;/strong&gt;: Workflow orchestration tool used to schedule and monitor workflows, integrating with Spark, Trino, and other data processing tools.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Apache Iceberg&lt;/strong&gt;: A table format for large-scale analytics, providing capabilities like schema evolution, hidden partitioning, and efficient upserts, which works well with both Trino and Spark for managing datasets in object storage like MinIO.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;What Might Be Missing?&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Monitoring and Logging&lt;/strong&gt;: Tools like Prometheus, Grafana for monitoring, and ELK Stack (Elasticsearch, Logstash, Kibana) for logging and visualization. These are crucial for observing the health and performance of the data pipeline and infrastructure.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Metadata Management&lt;/strong&gt;: Although Apache Iceberg provides table format and schema evolution, you might also consider a centralized metadata repository like Apache Atlas or Amundsen for data governance, lineage, and metadata discovery across your ecosystem.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: Integration with security and identity management tools, such as Apache Ranger for access control and Apache Knox for edge security, to ensure that data access is secure and compliant with policies.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1alq9aj", "is_robot_indexable": true, "report_reasons": null, "author": "saintmichel", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alq9aj/open_source_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alq9aj/open_source_data_platform/", "subreddit_subscribers": 159172, "created_utc": 1707377462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While it seems like many DA and DS is thinking to transition into DE, I have the opposite thought. 'm considering a career change and would sincerely appreciate any advice!\n\nMy background includes a non-technical Bachelor's degree, followed by a Master's in Business Information Systems.\n\nIn my current Junior DE role, I work with BigQuery and SQL Server for managing data marts, and manage ETL pipelines using Airflow (though I didn't set it up).\n\nI very enjoyed tasks like data modeling, database design, data cleansing, SQL query and optimization, but my interest in Python programming is low (very actually). While I do use Airflow extensively, I rely on custom Airflow Operators for typical pipeline tasks and often seek guidance online/ChatGPT for issues like CSV delimiter conversion with Python.\n\nAlthough I'm okay with the level of Python programming aspect for my current role, I'm considering future career growth staying in DE, as I believe I won't go far if I don't enjoy programming.\n\nOn the flip side, I'm interested in data analysis and visualization, which I don't have hands-on experience in my current role but learning online in my free time. I'm wondering if transitioning to a Data Analyst role might better suit my long-term career goal. I have started seeking out for both role recently, one challenge is that many companies in my country still heavily rely on Excel for DA tasks rather than SQL.\n\nAny insights or recommendations would be greatly appreciated. Thank you in advance", "author_fullname": "t2_yb4x7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DA/DE: Any advice is appreciated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1almqhx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707364829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While it seems like many DA and DS is thinking to transition into DE, I have the opposite thought. &amp;#39;m considering a career change and would sincerely appreciate any advice!&lt;/p&gt;\n\n&lt;p&gt;My background includes a non-technical Bachelor&amp;#39;s degree, followed by a Master&amp;#39;s in Business Information Systems.&lt;/p&gt;\n\n&lt;p&gt;In my current Junior DE role, I work with BigQuery and SQL Server for managing data marts, and manage ETL pipelines using Airflow (though I didn&amp;#39;t set it up).&lt;/p&gt;\n\n&lt;p&gt;I very enjoyed tasks like data modeling, database design, data cleansing, SQL query and optimization, but my interest in Python programming is low (very actually). While I do use Airflow extensively, I rely on custom Airflow Operators for typical pipeline tasks and often seek guidance online/ChatGPT for issues like CSV delimiter conversion with Python.&lt;/p&gt;\n\n&lt;p&gt;Although I&amp;#39;m okay with the level of Python programming aspect for my current role, I&amp;#39;m considering future career growth staying in DE, as I believe I won&amp;#39;t go far if I don&amp;#39;t enjoy programming.&lt;/p&gt;\n\n&lt;p&gt;On the flip side, I&amp;#39;m interested in data analysis and visualization, which I don&amp;#39;t have hands-on experience in my current role but learning online in my free time. I&amp;#39;m wondering if transitioning to a Data Analyst role might better suit my long-term career goal. I have started seeking out for both role recently, one challenge is that many companies in my country still heavily rely on Excel for DA tasks rather than SQL.&lt;/p&gt;\n\n&lt;p&gt;Any insights or recommendations would be greatly appreciated. Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1almqhx", "is_robot_indexable": true, "report_reasons": null, "author": "Yenrusu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1almqhx/dade_any_advice_is_appreciated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1almqhx/dade_any_advice_is_appreciated/", "subreddit_subscribers": 159172, "created_utc": 1707364829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say that you have 10 compute engine that last for 20 minutes with minimum specs and you have one databricks cluster with 10 notebooks.\n\nThey do the same process, same code, same resources (ELT), which one is better in terms of cost?", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better databricks cluster or compute engine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1algef8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707346787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say that you have 10 compute engine that last for 20 minutes with minimum specs and you have one databricks cluster with 10 notebooks.&lt;/p&gt;\n\n&lt;p&gt;They do the same process, same code, same resources (ELT), which one is better in terms of cost?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1algef8", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1algef8/is_it_better_databricks_cluster_or_compute_engine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1algef8/is_it_better_databricks_cluster_or_compute_engine/", "subreddit_subscribers": 159172, "created_utc": 1707346787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my team's warehouse is an on-prem SQL warehouse and we use a mixture of stored procedures, CData Sync (3rd party tool), Synapse for ETL. \n\nSince the data is growing, we need scalibility in the warehouse. The different ETL procedures for different sources is an headacheare and we are highly dependent on CData Sync, which is another pain in the ars\u00eb. Our plan is to to shift our warehouse from on-prem to cloud, and keep a standardized ETL tool.\n\nI am responsible for the analysis, but this is my first company and I've only worked here for 1.5 year (So I don't have much idea on what is going on in the industry as such). I don't know why I'm given this responsibility but I am interested in doing the analysis. Now the internet is full of amazing suggestions, however I would want to know the answers and suggestions from people who have experience working on different warehouses and ETL tools in the industry. Hence, it would be really helpful if you answer these questions - \n\nAny amount of questions answered would be helpful.\n\n1. What warehouses and ETL tools were used in your past companies and your present company?\n\n2. Which warehouse did you prefer the most and why?\n\n3. Which ETL tool did you prefer the most and why?\n\n4. Any recommendations?\n\n5. What would you look for when changing the warehouse and ETL tool?\n\nP.S. Advice and tips appreciated \u2728", "author_fullname": "t2_svkuxhv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions on warehouse and etl", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aldru6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707340239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my team&amp;#39;s warehouse is an on-prem SQL warehouse and we use a mixture of stored procedures, CData Sync (3rd party tool), Synapse for ETL. &lt;/p&gt;\n\n&lt;p&gt;Since the data is growing, we need scalibility in the warehouse. The different ETL procedures for different sources is an headacheare and we are highly dependent on CData Sync, which is another pain in the ars\u00eb. Our plan is to to shift our warehouse from on-prem to cloud, and keep a standardized ETL tool.&lt;/p&gt;\n\n&lt;p&gt;I am responsible for the analysis, but this is my first company and I&amp;#39;ve only worked here for 1.5 year (So I don&amp;#39;t have much idea on what is going on in the industry as such). I don&amp;#39;t know why I&amp;#39;m given this responsibility but I am interested in doing the analysis. Now the internet is full of amazing suggestions, however I would want to know the answers and suggestions from people who have experience working on different warehouses and ETL tools in the industry. Hence, it would be really helpful if you answer these questions - &lt;/p&gt;\n\n&lt;p&gt;Any amount of questions answered would be helpful.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What warehouses and ETL tools were used in your past companies and your present company?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Which warehouse did you prefer the most and why?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Which ETL tool did you prefer the most and why?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Any recommendations?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What would you look for when changing the warehouse and ETL tool?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;P.S. Advice and tips appreciated \u2728&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aldru6", "is_robot_indexable": true, "report_reasons": null, "author": "beeneww", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aldru6/suggestions_on_warehouse_and_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aldru6/suggestions_on_warehouse_and_etl/", "subreddit_subscribers": 159172, "created_utc": 1707340239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I couldn't find a subreddit for dbt or an answer to this on Google so I'll put this to you guys\n\nI want to generate a database documentation for my dbt models which contains a list of columns contained in each table. I know I can use `dbt docs generate`  to create the documentation but as far as I understand I need to manually document the existing columns in the schema.yml so that they show in the documentation? So every time someone delete/add a column in the SQL they would need to reflect that change in the schema.yml file?  \n\n\nIt seems like there should be a way to automatically sync that column list from the corresponding SQL file but I don't seem to find how to do it. Does anyone have a solution?  \n", "author_fullname": "t2_grnvlbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically syncing DBT column schema with actual columns in corresponding SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1al7hv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707324726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I couldn&amp;#39;t find a subreddit for dbt or an answer to this on Google so I&amp;#39;ll put this to you guys&lt;/p&gt;\n\n&lt;p&gt;I want to generate a database documentation for my dbt models which contains a list of columns contained in each table. I know I can use &lt;code&gt;dbt docs generate&lt;/code&gt;  to create the documentation but as far as I understand I need to manually document the existing columns in the schema.yml so that they show in the documentation? So every time someone delete/add a column in the SQL they would need to reflect that change in the schema.yml file?  &lt;/p&gt;\n\n&lt;p&gt;It seems like there should be a way to automatically sync that column list from the corresponding SQL file but I don&amp;#39;t seem to find how to do it. Does anyone have a solution?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1al7hv9", "is_robot_indexable": true, "report_reasons": null, "author": "Kenoai", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1al7hv9/automatically_syncing_dbt_column_schema_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1al7hv9/automatically_syncing_dbt_column_schema_with/", "subreddit_subscribers": 159172, "created_utc": 1707324726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!\n\nI'm currently facing an issue at work and this one is called anomaly detection on time series data.\n\nOut data is currently located in a transactional DB buy we're looking into migrating to a cloud data warehouse.\n\nWe are looking for ML-based platforms. We have considered Monte Carlo and BigEye but they don't offer anomaly detection for transactional DBs.\n\nDo you have any other platforms to suggest? Thanks!", "author_fullname": "t2_ce7do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series anomaly detection platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1alt5xb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707390010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently facing an issue at work and this one is called anomaly detection on time series data.&lt;/p&gt;\n\n&lt;p&gt;Out data is currently located in a transactional DB buy we&amp;#39;re looking into migrating to a cloud data warehouse.&lt;/p&gt;\n\n&lt;p&gt;We are looking for ML-based platforms. We have considered Monte Carlo and BigEye but they don&amp;#39;t offer anomaly detection for transactional DBs.&lt;/p&gt;\n\n&lt;p&gt;Do you have any other platforms to suggest? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1alt5xb", "is_robot_indexable": true, "report_reasons": null, "author": "ulysses_black", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1alt5xb/time_series_anomaly_detection_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alt5xb/time_series_anomaly_detection_platform/", "subreddit_subscribers": 159172, "created_utc": 1707390010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello lovely people,\n\nI'm the only Data Engineer left at my company (London) managing our Data Platform on Databricks. I don't get many requests these days other than cost optimization, so I want to spend more time on learning while keeping the ship afloat. \n\nWe use Delta and Pyspark on Databricks and have some AWS processes such as lambdas, kinesis streams etc. \n\nMost of the data modeling is handled by our BI Developer on DBT, which I'm not very involved with. That's one area I could lean into but I honestly find it very boring.\n\nI have some Data Science-y projects that solve specific problems within the business using external data ingestion/integration and machine learning. These give me great visibility within the business and add a ton of value, but are not standard data engineering tasks that would help me get my next DE role - unless I'm applying to a startup. \n\nMore personal context: The company is not doing so well. I have been here for 2 years (3 years experience in total) but I ended up Senior after people quitting/laid off. I have high job security since I'm the last DE remaining and plenty of freedom. Ideally I would want a DE/DS hybrid role if possible. I'm a creative person and thrive when working on open-ended business problems.\n\nWhat should I focus on at this point?\n\n1. Databricks\n2. AWS (Going for the Developer and ML certificates)\n3. DBT/Data Modelling\n4. Transition to MLE/MLOps (or even DS)\n5. Keep thinking of ways to add value to the company, stop worrying about the CV. \n6. &lt;Other DE fundamentals that I might be missing&gt;", "author_fullname": "t2_grx7q9lo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I focus on next?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1alt185", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707389430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello lovely people,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the only Data Engineer left at my company (London) managing our Data Platform on Databricks. I don&amp;#39;t get many requests these days other than cost optimization, so I want to spend more time on learning while keeping the ship afloat. &lt;/p&gt;\n\n&lt;p&gt;We use Delta and Pyspark on Databricks and have some AWS processes such as lambdas, kinesis streams etc. &lt;/p&gt;\n\n&lt;p&gt;Most of the data modeling is handled by our BI Developer on DBT, which I&amp;#39;m not very involved with. That&amp;#39;s one area I could lean into but I honestly find it very boring.&lt;/p&gt;\n\n&lt;p&gt;I have some Data Science-y projects that solve specific problems within the business using external data ingestion/integration and machine learning. These give me great visibility within the business and add a ton of value, but are not standard data engineering tasks that would help me get my next DE role - unless I&amp;#39;m applying to a startup. &lt;/p&gt;\n\n&lt;p&gt;More personal context: The company is not doing so well. I have been here for 2 years (3 years experience in total) but I ended up Senior after people quitting/laid off. I have high job security since I&amp;#39;m the last DE remaining and plenty of freedom. Ideally I would want a DE/DS hybrid role if possible. I&amp;#39;m a creative person and thrive when working on open-ended business problems.&lt;/p&gt;\n\n&lt;p&gt;What should I focus on at this point?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Databricks&lt;/li&gt;\n&lt;li&gt;AWS (Going for the Developer and ML certificates)&lt;/li&gt;\n&lt;li&gt;DBT/Data Modelling&lt;/li&gt;\n&lt;li&gt;Transition to MLE/MLOps (or even DS)&lt;/li&gt;\n&lt;li&gt;Keep thinking of ways to add value to the company, stop worrying about the CV. &lt;/li&gt;\n&lt;li&gt;&amp;lt;Other DE fundamentals that I might be missing&amp;gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1alt185", "is_robot_indexable": true, "report_reasons": null, "author": "the_underfitter", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alt185/what_should_i_focus_on_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alt185/what_should_i_focus_on_next/", "subreddit_subscribers": 159172, "created_utc": 1707389430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In US it seems to be more commonly used to mean analytics engineer/data modeler doing more SQL and dbt type stuff, maybe even doing reports and dashboards. Whereas in Europe it seems to more commonly mean data platform/ingestion engineer with SWE skills, doing more python, possibly java/scala, maybe a bit of streaming and more competency with devops stuff like infra-as-code, ci/cd. I still see the term BI developer a lot in Europe for essentially analytics engineer type roles.\n\nWhat do people think? Am i off base or anyone else notice this pattern?", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone else experienced differences in what a DE is defined as in US vs Europe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1alsmkd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707387700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In US it seems to be more commonly used to mean analytics engineer/data modeler doing more SQL and dbt type stuff, maybe even doing reports and dashboards. Whereas in Europe it seems to more commonly mean data platform/ingestion engineer with SWE skills, doing more python, possibly java/scala, maybe a bit of streaming and more competency with devops stuff like infra-as-code, ci/cd. I still see the term BI developer a lot in Europe for essentially analytics engineer type roles.&lt;/p&gt;\n\n&lt;p&gt;What do people think? Am i off base or anyone else notice this pattern?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1alsmkd", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alsmkd/has_anyone_else_experienced_differences_in_what_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alsmkd/has_anyone_else_experienced_differences_in_what_a/", "subreddit_subscribers": 159172, "created_utc": 1707387700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all \n\nI am transitioning from humanities into data with a hope to become an ML Engineer over time. I completed an MSc in AI at a good uni with the intention of joining a grad scheme after. Unfortunately I made a wrong turn by accepting a bad job offer for the wrong reasons. Fortunately I got a 'data job' as a data analyst at a multi national financial services company in UK. However the work is non-technical and I'm conscious of losing my technical skillset. \n\nIs it realistic to do DA &gt; DE &gt; MLE? And, if so, what hints, tips or steps should I take to help me get there?\n\nAny words of wisdom would be gratefully appreciated.\n\n[edit]\n\nTo those asking: my manager sees my position as analytical rather than technical; access to underlying database is heavily restricted due to business' risk appetite; my manager is great and has set up a project that could give me the chance to access the database - I'm not 100% convinced it'll work as the business is providing 2 DS (who are experienced and have access to database already).", "author_fullname": "t2_tituct1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accepted Wrong Job - Have I F*****d it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1alrdj0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1707391010.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1707382302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all &lt;/p&gt;\n\n&lt;p&gt;I am transitioning from humanities into data with a hope to become an ML Engineer over time. I completed an MSc in AI at a good uni with the intention of joining a grad scheme after. Unfortunately I made a wrong turn by accepting a bad job offer for the wrong reasons. Fortunately I got a &amp;#39;data job&amp;#39; as a data analyst at a multi national financial services company in UK. However the work is non-technical and I&amp;#39;m conscious of losing my technical skillset. &lt;/p&gt;\n\n&lt;p&gt;Is it realistic to do DA &amp;gt; DE &amp;gt; MLE? And, if so, what hints, tips or steps should I take to help me get there?&lt;/p&gt;\n\n&lt;p&gt;Any words of wisdom would be gratefully appreciated.&lt;/p&gt;\n\n&lt;p&gt;[edit]&lt;/p&gt;\n\n&lt;p&gt;To those asking: my manager sees my position as analytical rather than technical; access to underlying database is heavily restricted due to business&amp;#39; risk appetite; my manager is great and has set up a project that could give me the chance to access the database - I&amp;#39;m not 100% convinced it&amp;#39;ll work as the business is providing 2 DS (who are experienced and have access to database already).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1alrdj0", "is_robot_indexable": true, "report_reasons": null, "author": "Due-Cap9761", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alrdj0/accepted_wrong_job_have_i_fd_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1alrdj0/accepted_wrong_job_have_i_fd_it/", "subreddit_subscribers": 159172, "created_utc": 1707382302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instacart Creates Real-Time Item Availability Architecture with ML and Event Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1alr9vq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dVRO-eqILiRqiZZejrpHb73Mcb6oOuulZZu2dvidYMo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1707381866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2024/02/instacart-item-availability/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?auto=webp&amp;s=85ea2d7e4c33b36d21f7dcbfbec1dce723ee7c68", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e577e70a6e3d1971f8bb6ebfe8594adfbbca595c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a2bef1ae60dda26d289543fa4d23f2c89f61896", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad59f9bdc2ed4ab9b905f4483222da0bf8cbf6a5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca4eb6358b1c1d4221987ef6e89e70eea76faf5a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1659aede80371b2186da7b095e2cec314fd7558", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Hw23K3c7e8R50jf697xNljjo1FRNnjyIdnS5qr7fGW4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4952a46d13f1003ca42579b35b575619fba6f899", "width": 1080, "height": 567}], "variants": {}, "id": "XSahxUUd5FVHPhY4TdDVnFOJxZooJMAfLE1-aM_-Ups"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1alr9vq", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1alr9vq/instacart_creates_realtime_item_availability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2024/02/instacart-item-availability/", "subreddit_subscribers": 159172, "created_utc": 1707381866.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}