{"kind": "Listing", "data": {"after": "t3_19eqaen", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI work for a retail firm and we are running an incentive over 6 months. I produce the incentive reports using python code and we usually share it with a few important salespeople.\n\nHowever this year, management is looking at creating something like a powerbi report and allowing access to all salespeople. The number of salespeople will be about 35,000. \n\nI'm experienced with python and powerbi but I've never done something that needs to be accessed by such a wide audience.\n\nDoes anyone have any experience with such a scenario where a lot of people need access to a report and how it was achieved?\n\nEdit: I forgot to mention that the salespeople are in a hierarchical structure and one should not see details of another hierarchy ", "author_fullname": "t2_t05ji4fs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Allowing report access to 35000 people", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19eio7f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706107431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I work for a retail firm and we are running an incentive over 6 months. I produce the incentive reports using python code and we usually share it with a few important salespeople.&lt;/p&gt;\n\n&lt;p&gt;However this year, management is looking at creating something like a powerbi report and allowing access to all salespeople. The number of salespeople will be about 35,000. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m experienced with python and powerbi but I&amp;#39;ve never done something that needs to be accessed by such a wide audience.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience with such a scenario where a lot of people need access to a report and how it was achieved?&lt;/p&gt;\n\n&lt;p&gt;Edit: I forgot to mention that the salespeople are in a hierarchical structure and one should not see details of another hierarchy &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19eio7f", "is_robot_indexable": true, "report_reasons": null, "author": "kkchn001", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19eio7f/allowing_report_access_to_35000_people/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19eio7f/allowing_report_access_to_35000_people/", "subreddit_subscribers": 155457, "created_utc": 1706107431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example if I have a dataframe like:\n\n    root\n     |-- Col1: struct (nullable = true)\n     |    |-- Col2: struct (nullable = true)\n     |    |    |-- Col3: struct (nullable = true)\n     |    |    |    |-- Col4: array (nullable = true)\n     |    |    |    |    |-- Col5: struct (containsNull = true)\n     |    |    |    |    |    |-- Col6: string (nullable = true)\n     |    |    |    |    |    |-- Col7: string (nullable = true)\n     |    |    |    |    |    |-- Col8: string (nullable = true)\n     |    |    |-- Col9: string (nullable = true)\n     |    |    |-- Col10: struct (nullable = true)\n     |    |    |    |-- Col11: array (nullable = true)\n     |    |    |    |    |-- Col12: struct (containsNull = true)\n     |    |    |    |    |    |-- Col13: struct (nullable = true)\n     |    |    |    |    |    |    |-- Col14: string (nullable = true)\n     |    |    |    |    |    |-- Col15: string (nullable = true)\n     |    |    |    |-- Col16: string (nullable = true)\n     |-- Col17: struct (nullable = true)\n     |    |-- Col18: struct (nullable = true)\n     |    |    |-- Col19: array (nullable = true)\n     |    |    |    |-- Col20: struct (containsNull = true)\n     |    |    |    |    |-- Col21: string (nullable = true)\n     |    |    |    |    |-- Col22: string (nullable = true)\n     |    |-- Col23: string (nullable = true)\n     |    |-- Col24: struct (nullable = true)\n     |    |    |-- Col25: array (nullable = true)\n     |    |    |    |-- Col26: struct (containsNull = true)\n     |    |    |    |    |-- Col27: struct (nullable = true)\n     |    |    |    |    |    |-- col28: struct (nullable = true)\n     |    |    |    |    |    |    |-- Col29: string (nullable = true)\n     |    |    |    |    |    |    |-- Col30: long (nullable = true)\n     |    |    |    |    |-- Col31: string (nullable = true)\n\nHow do you guys flatten this? Do you first do like unnest all structs and then leave arrays at the end and then explode arrays. Or go like level by level. Like expand all structs at level 1 and then explode arrays at level 1. And then go to next level.", "author_fullname": "t2_r509bej6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you flatten nested json/xml?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ecjrn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706085428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example if I have a dataframe like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;root\n |-- Col1: struct (nullable = true)\n |    |-- Col2: struct (nullable = true)\n |    |    |-- Col3: struct (nullable = true)\n |    |    |    |-- Col4: array (nullable = true)\n |    |    |    |    |-- Col5: struct (containsNull = true)\n |    |    |    |    |    |-- Col6: string (nullable = true)\n |    |    |    |    |    |-- Col7: string (nullable = true)\n |    |    |    |    |    |-- Col8: string (nullable = true)\n |    |    |-- Col9: string (nullable = true)\n |    |    |-- Col10: struct (nullable = true)\n |    |    |    |-- Col11: array (nullable = true)\n |    |    |    |    |-- Col12: struct (containsNull = true)\n |    |    |    |    |    |-- Col13: struct (nullable = true)\n |    |    |    |    |    |    |-- Col14: string (nullable = true)\n |    |    |    |    |    |-- Col15: string (nullable = true)\n |    |    |    |-- Col16: string (nullable = true)\n |-- Col17: struct (nullable = true)\n |    |-- Col18: struct (nullable = true)\n |    |    |-- Col19: array (nullable = true)\n |    |    |    |-- Col20: struct (containsNull = true)\n |    |    |    |    |-- Col21: string (nullable = true)\n |    |    |    |    |-- Col22: string (nullable = true)\n |    |-- Col23: string (nullable = true)\n |    |-- Col24: struct (nullable = true)\n |    |    |-- Col25: array (nullable = true)\n |    |    |    |-- Col26: struct (containsNull = true)\n |    |    |    |    |-- Col27: struct (nullable = true)\n |    |    |    |    |    |-- col28: struct (nullable = true)\n |    |    |    |    |    |    |-- Col29: string (nullable = true)\n |    |    |    |    |    |    |-- Col30: long (nullable = true)\n |    |    |    |    |-- Col31: string (nullable = true)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How do you guys flatten this? Do you first do like unnest all structs and then leave arrays at the end and then explode arrays. Or go like level by level. Like expand all structs at level 1 and then explode arrays at level 1. And then go to next level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19ecjrn", "is_robot_indexable": true, "report_reasons": null, "author": "mediocrX", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ecjrn/how_do_you_flatten_nested_jsonxml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19ecjrn/how_do_you_flatten_nested_jsonxml/", "subreddit_subscribers": 155457, "created_utc": 1706085428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI\u2019m trying to improve a system that maintains a local copy of a dataset retrieved via API. The dataset can fluctuate by having records added, removed, or changed. It gets synchronized hourly via the results of an ETL job moving API data into the database.\n\nAt the moment, the pipeline queries API for the full dataset, normalizes the data, and compares against the database data in memory. Python code getting both the API data and database data in the same place, normalizing the API data, and doing in memory comparisons. Missing records get added to the database. Gone records get removed. Changed records get updated.\n\nI\u2019m thinking it would be better to just truncate the whole dataset every hour and reload all the data, regardless of whether it\u2019s changed or not. This sounds less expensive.\n\nCurious if there\u2019s an even more efficient approach given records can be deleted- we don\u2019t know if the set of records will be the same set after each update.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to efficiently maintain a current state of dataset from an API when records can be removed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19e4sc5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706059125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to improve a system that maintains a local copy of a dataset retrieved via API. The dataset can fluctuate by having records added, removed, or changed. It gets synchronized hourly via the results of an ETL job moving API data into the database.&lt;/p&gt;\n\n&lt;p&gt;At the moment, the pipeline queries API for the full dataset, normalizes the data, and compares against the database data in memory. Python code getting both the API data and database data in the same place, normalizing the API data, and doing in memory comparisons. Missing records get added to the database. Gone records get removed. Changed records get updated.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking it would be better to just truncate the whole dataset every hour and reload all the data, regardless of whether it\u2019s changed or not. This sounds less expensive.&lt;/p&gt;\n\n&lt;p&gt;Curious if there\u2019s an even more efficient approach given records can be deleted- we don\u2019t know if the set of records will be the same set after each update.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19e4sc5", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19e4sc5/how_to_efficiently_maintain_a_current_state_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19e4sc5/how_to_efficiently_maintain_a_current_state_of/", "subreddit_subscribers": 155457, "created_utc": 1706059125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone else having a real tough time landing a new position in the current market? I have just over 3 yoe, and the best I've gotten is either a deferral (passed interview process but they don't have any new projects to bill me on yet, don't ask) or a denial after final round. Seems the market is oversaturated with all these layoffs, plus companies are able to be very picky right now. They said tech jobs are abundant, but I've been searching for almost a year with no written offer! Luckily I do have a job, but I've been trying to switch companies for quite a while now.", "author_fullname": "t2_4icmd6xt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Search Struggles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ekul8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706113149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone else having a real tough time landing a new position in the current market? I have just over 3 yoe, and the best I&amp;#39;ve gotten is either a deferral (passed interview process but they don&amp;#39;t have any new projects to bill me on yet, don&amp;#39;t ask) or a denial after final round. Seems the market is oversaturated with all these layoffs, plus companies are able to be very picky right now. They said tech jobs are abundant, but I&amp;#39;ve been searching for almost a year with no written offer! Luckily I do have a job, but I&amp;#39;ve been trying to switch companies for quite a while now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19ekul8", "is_robot_indexable": true, "report_reasons": null, "author": "emjaycu3", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ekul8/job_search_struggles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19ekul8/job_search_struggles/", "subreddit_subscribers": 155457, "created_utc": 1706113149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys ! Just want your opinion on which one to buy. I work as both a data scientist as well as a data engineer and develop deep learning models as well host databases. Which laptop would you guys recommend. Price is not much of an issue but your opinions would help a lot \ud83d\ude4f\ud83c\udffb.", "author_fullname": "t2_9sfh3rih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac book pro or gaming laptop for programming ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ef60x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706096444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys ! Just want your opinion on which one to buy. I work as both a data scientist as well as a data engineer and develop deep learning models as well host databases. Which laptop would you guys recommend. Price is not much of an issue but your opinions would help a lot \ud83d\ude4f\ud83c\udffb.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19ef60x", "is_robot_indexable": true, "report_reasons": null, "author": "Automatic_Will_5137", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ef60x/mac_book_pro_or_gaming_laptop_for_programming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19ef60x/mac_book_pro_or_gaming_laptop_for_programming/", "subreddit_subscribers": 155457, "created_utc": 1706096444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a table set up with 3 foreign keys. In the case of one of those foreign keys, the lack of a value (NULL) is considered important information.\n\nIt works out something like this:\n\n```\nCREATE TABLE foo (\n    id SERIAL,\n    name TEXT UNIQUE\n);\n\nCREATE TABLE bar (\n    id SERIAL\n    name TEXT UNIQUE\n);\n\nCREATE TABLE baz (\n    id SERIAL\n    name TEXT UNIQUE\n);\n\nCREATE TABLE foobarbaz (\n    id SERIAL\n    foo_id FK NOT NULL\n    bar_id FK NOT NULL\n    baz_id FK\n    value INT\n\n    CONSTRAINT uniq_distnct_baz UNIQUE NULL NOT DISTINCT baz_id\n);\n```\n\nThe thing is, does this make it impossible to reliably insert rows using subqueries?\n\n```\nINSERT INTO foobarbaz (foo_id, bar_id, baz_id, value)\nVALUES (\n    (SELECT id FROM foo WHERE name = \u201cpea\u201d),\n    (SELECT id FROM bar WHERE name = \u201cnut\u201d)\n     (SELECT id FROM baz WHERE name = \u201cfan\u201d),\n    100\n);\n```\n\nIn this case, the existence of the subquery for `name = \u201cfan\u201d` on `baz` indicates that the user **knows** a record should exist for this. If the record does not exist, the INSERT should fail. If there was not supposed to be a value there, the INSERT would use NULL in place of that subquery,\n\nHowever, it\u2019s possible that the condition `name = \u201cfan\u201d` on `baz` doesn\u2019t exist. This would return a NULL value, and that would be acceptable by the tables constraints so long as a similar record doesn\u2019t already exist. \n\nThis makes the INSERT statement inherently risky, as you must first confirm that the record you seek actually exists.\n\nIs there a way to leverage the database to take care of this automatically? Make the INSERT fail if it should. \n\nIs the only way a VIEW with an INSTEAD OF INSERT trigger?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to make an INSERT statement fail if a subquery returns NULL? (Postgres)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19e88iq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706069337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a table set up with 3 foreign keys. In the case of one of those foreign keys, the lack of a value (NULL) is considered important information.&lt;/p&gt;\n\n&lt;p&gt;It works out something like this:&lt;/p&gt;\n\n&lt;p&gt;```\nCREATE TABLE foo (\n    id SERIAL,\n    name TEXT UNIQUE\n);&lt;/p&gt;\n\n&lt;p&gt;CREATE TABLE bar (\n    id SERIAL\n    name TEXT UNIQUE\n);&lt;/p&gt;\n\n&lt;p&gt;CREATE TABLE baz (\n    id SERIAL\n    name TEXT UNIQUE\n);&lt;/p&gt;\n\n&lt;p&gt;CREATE TABLE foobarbaz (\n    id SERIAL\n    foo_id FK NOT NULL\n    bar_id FK NOT NULL\n    baz_id FK\n    value INT&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CONSTRAINT uniq_distnct_baz UNIQUE NULL NOT DISTINCT baz_id\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;);\n```&lt;/p&gt;\n\n&lt;p&gt;The thing is, does this make it impossible to reliably insert rows using subqueries?&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\nINSERT INTO foobarbaz (foo_id, bar_id, baz_id, value)\nVALUES (\n    (SELECT id FROM foo WHERE name = \u201cpea\u201d),\n    (SELECT id FROM bar WHERE name = \u201cnut\u201d)\n     (SELECT id FROM baz WHERE name = \u201cfan\u201d),\n    100\n);\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;In this case, the existence of the subquery for &lt;code&gt;name = \u201cfan\u201d&lt;/code&gt; on &lt;code&gt;baz&lt;/code&gt; indicates that the user &lt;strong&gt;knows&lt;/strong&gt; a record should exist for this. If the record does not exist, the INSERT should fail. If there was not supposed to be a value there, the INSERT would use NULL in place of that subquery,&lt;/p&gt;\n\n&lt;p&gt;However, it\u2019s possible that the condition &lt;code&gt;name = \u201cfan\u201d&lt;/code&gt; on &lt;code&gt;baz&lt;/code&gt; doesn\u2019t exist. This would return a NULL value, and that would be acceptable by the tables constraints so long as a similar record doesn\u2019t already exist. &lt;/p&gt;\n\n&lt;p&gt;This makes the INSERT statement inherently risky, as you must first confirm that the record you seek actually exists.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to leverage the database to take care of this automatically? Make the INSERT fail if it should. &lt;/p&gt;\n\n&lt;p&gt;Is the only way a VIEW with an INSTEAD OF INSERT trigger?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19e88iq", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19e88iq/any_way_to_make_an_insert_statement_fail_if_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19e88iq/any_way_to_make_an_insert_statement_fail_if_a/", "subreddit_subscribers": 155457, "created_utc": 1706069337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What should i focus on developing my skills to move to Data Architect from a Data Engineer? Is it worth it career wise? \nAlso if i could get a good resource or links to projects to learn data architecture that would be much appreciated.", "author_fullname": "t2_2p6kp22l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switch career from Data Engineer to Data Architect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19en4gl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706121692.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706120345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What should i focus on developing my skills to move to Data Architect from a Data Engineer? Is it worth it career wise? \nAlso if i could get a good resource or links to projects to learn data architecture that would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19en4gl", "is_robot_indexable": true, "report_reasons": null, "author": "bhoo1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19en4gl/switch_career_from_data_engineer_to_data_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19en4gl/switch_career_from_data_engineer_to_data_architect/", "subreddit_subscribers": 155457, "created_utc": 1706120345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you\u2019ve worked with Apache Iceberg, there are metadata tables to assess a tables files, snapshots, partitions, etc.\n\nHave you used them?\n\nWhat have been the most useful ways to use them for you?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Iceberg Metadata tables, how have you used them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19eg9yk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706100349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you\u2019ve worked with Apache Iceberg, there are metadata tables to assess a tables files, snapshots, partitions, etc.&lt;/p&gt;\n\n&lt;p&gt;Have you used them?&lt;/p&gt;\n\n&lt;p&gt;What have been the most useful ways to use them for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19eg9yk", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19eg9yk/apache_iceberg_metadata_tables_how_have_you_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19eg9yk/apache_iceberg_metadata_tables_how_have_you_used/", "subreddit_subscribers": 155457, "created_utc": 1706100349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an ETL pipeline in a GCP and Snowflake technology stack that is currently being refactored from manual into an automated process for ETL along with data validations and executing python based models. The source data is mostly API calls and CSV files. We have the following options to trigger this process in each phase from extraction and load with validations. Any suggestions which could be the best tool to orchestrate/trigger out of the following?\n\n* Google Cloud Functions\n* Google Pub/Sub\n* Cloud Scheduler\n* Snowflake Tasks\n* Informatica ICS\n* UC4\n\n**Note**: Cloud Composer/Airflow is NOT an option due to compliance concerns.\n\nThank you in advance!", "author_fullname": "t2_8b0w9ipt9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestrating a Trigger based ETL Pipeline in GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19eoqz0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706132666.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706124156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an ETL pipeline in a GCP and Snowflake technology stack that is currently being refactored from manual into an automated process for ETL along with data validations and executing python based models. The source data is mostly API calls and CSV files. We have the following options to trigger this process in each phase from extraction and load with validations. Any suggestions which could be the best tool to orchestrate/trigger out of the following?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Google Cloud Functions&lt;/li&gt;\n&lt;li&gt;Google Pub/Sub&lt;/li&gt;\n&lt;li&gt;Cloud Scheduler&lt;/li&gt;\n&lt;li&gt;Snowflake Tasks&lt;/li&gt;\n&lt;li&gt;Informatica ICS&lt;/li&gt;\n&lt;li&gt;UC4&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Cloud Composer/Airflow is NOT an option due to compliance concerns.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19eoqz0", "is_robot_indexable": true, "report_reasons": null, "author": "JoseyWales10", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19eoqz0/orchestrating_a_trigger_based_etl_pipeline_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19eoqz0/orchestrating_a_trigger_based_etl_pipeline_in_gcp/", "subreddit_subscribers": 155457, "created_utc": 1706124156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys. I have a problem with Apache Superset. I'm creating a cash flow table, I need to get the total value of one day to be the value that starts the next, how can I set up a table that understands this structure in the superset, always the total value of one day will start the other... In the power bi I can do this easily, but in the superset I have encountered difficulties... Maybe some different modeling, but with the current model I have no difficulties in the power bi\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/v15foa493eec1.png?width=1076&amp;format=png&amp;auto=webp&amp;s=de4df643f051991efc83030459900579b362dc7a", "author_fullname": "t2_lwkd7au4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cash Flow in Apache Superset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "media_metadata": {"v15foa493eec1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/v15foa493eec1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=892ea7d15b7e151c4784a1d9a7d963989069d079"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/v15foa493eec1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=89b78697e1fd3806e93e04247ef4bd61c5140bbe"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/v15foa493eec1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=29dbd3180b4d8625d9c3014eb674d32f4ac0c779"}, {"y": 400, "x": 640, "u": "https://preview.redd.it/v15foa493eec1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=874232a3b6cddfa58c926efcedbc56994583f5c8"}, {"y": 600, "x": 960, "u": "https://preview.redd.it/v15foa493eec1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e7d858cdd1b24940d5ecd0178a9d9c3148df2e60"}], "s": {"y": 673, "x": 1076, "u": "https://preview.redd.it/v15foa493eec1.png?width=1076&amp;format=png&amp;auto=webp&amp;s=de4df643f051991efc83030459900579b362dc7a"}, "id": "v15foa493eec1"}}, "name": "t3_19eh12q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/B1KSLeZZzyx_4gDRULlevVNPKIusxfsGLZFDAi7Ix5M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706102719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. I have a problem with Apache Superset. I&amp;#39;m creating a cash flow table, I need to get the total value of one day to be the value that starts the next, how can I set up a table that understands this structure in the superset, always the total value of one day will start the other... In the power bi I can do this easily, but in the superset I have encountered difficulties... Maybe some different modeling, but with the current model I have no difficulties in the power bi&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v15foa493eec1.png?width=1076&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=de4df643f051991efc83030459900579b362dc7a\"&gt;https://preview.redd.it/v15foa493eec1.png?width=1076&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=de4df643f051991efc83030459900579b362dc7a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19eh12q", "is_robot_indexable": true, "report_reasons": null, "author": "carlosandradeds", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19eh12q/cash_flow_in_apache_superset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19eh12q/cash_flow_in_apache_superset/", "subreddit_subscribers": 155457, "created_utc": 1706102719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A newbie here, so please, have mercy.\n\nI am just trying to migrate from the amateur `pickle` and `numpy.save()` to a db-based approach for my Data Science projects. However, I have no idea which db I should start. What would be your advice?", "author_fullname": "t2_a54rlcm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the way-to-go database for Data Science applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ebd3a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706080409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A newbie here, so please, have mercy.&lt;/p&gt;\n\n&lt;p&gt;I am just trying to migrate from the amateur &lt;code&gt;pickle&lt;/code&gt; and &lt;code&gt;numpy.save()&lt;/code&gt; to a db-based approach for my Data Science projects. However, I have no idea which db I should start. What would be your advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19ebd3a", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Egg_184", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ebd3a/which_is_the_waytogo_database_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19ebd3a/which_is_the_waytogo_database_for_data_science/", "subreddit_subscribers": 155457, "created_utc": 1706080409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a massive growth in SaaS data tools, and I was wondering how much people rely on such product. Excluding cloud data warehouses (Snowflake/Redshift/Data bricks).\n\nHow much does your company rely on Salas tools for orchestration, data quality, data catalogs, ingestion, transformation? How big is your data team and your company's revenue? \n\nWhich products do you use as Salas and which do you self-host? Why? \n\nWhat are the pros and cons of each?", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does your data team rely on SaaS products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19e1jv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706050292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a massive growth in SaaS data tools, and I was wondering how much people rely on such product. Excluding cloud data warehouses (Snowflake/Redshift/Data bricks).&lt;/p&gt;\n\n&lt;p&gt;How much does your company rely on Salas tools for orchestration, data quality, data catalogs, ingestion, transformation? How big is your data team and your company&amp;#39;s revenue? &lt;/p&gt;\n\n&lt;p&gt;Which products do you use as Salas and which do you self-host? Why? &lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of each?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19e1jv5", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19e1jv5/how_much_does_your_data_team_rely_on_saas_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19e1jv5/how_much_does_your_data_team_rely_on_saas_products/", "subreddit_subscribers": 155457, "created_utc": 1706050292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I\u2019m preparing for interviews and want to get your inputs on a leetcode list similar to blind75 for data engineers", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blind75 for data engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19enwgo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706122141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I\u2019m preparing for interviews and want to get your inputs on a leetcode list similar to blind75 for data engineers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "19enwgo", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19enwgo/blind75_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19enwgo/blind75_for_data_engineers/", "subreddit_subscribers": 155457, "created_utc": 1706122141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to introduce Airflow into my teams tech stack and getting a lot of resistance from data architecture as they are of the opinion that our existing Autosys setup can by and large do the same thing as Airflow. \n\nI disagree for a number of reasons:\n\n- airflow has more dynamic and complex options for triggering jobs \n- airflow has sensors and hooks into other platforms to trigger jobs based on outside variables\n- airflow has a better UI for monitoring jobs\n\n\nAlthough python is clearly an advantage, that won\u2019t fly in the decisioning. \n\nWhat else can I suggest?", "author_fullname": "t2_93oocbjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Autosys vs Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19eh507", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706103058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to introduce Airflow into my teams tech stack and getting a lot of resistance from data architecture as they are of the opinion that our existing Autosys setup can by and large do the same thing as Airflow. &lt;/p&gt;\n\n&lt;p&gt;I disagree for a number of reasons:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;airflow has more dynamic and complex options for triggering jobs &lt;/li&gt;\n&lt;li&gt;airflow has sensors and hooks into other platforms to trigger jobs based on outside variables&lt;/li&gt;\n&lt;li&gt;airflow has a better UI for monitoring jobs&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Although python is clearly an advantage, that won\u2019t fly in the decisioning. &lt;/p&gt;\n\n&lt;p&gt;What else can I suggest?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19eh507", "is_robot_indexable": true, "report_reasons": null, "author": "GlasgowGunner", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19eh507/autosys_vs_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19eh507/autosys_vs_airflow/", "subreddit_subscribers": 155457, "created_utc": 1706103058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, i have some questions for you about Apache Superset.\n\n  \nThe my first doubt is how to use percentages in the tool. I'll explain it better: basically i'm trying to values in a bar chart in percentages instead of values (the total being the sum of values).\n\nMy second doubt instead is on displaying data from a pivot table into a heatmap. Basically, since i nedd rows from the table to be values on the Y axis i need to transform my data by using a pivot table, but i'm unable to use that transformed data into my heatmap, so i'd need to use custom SQL queries, which i'd like to avoid.\n\nThanks", "author_fullname": "t2_lvw1j2uy2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Superset: Percentages and Pivot table with heatmap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19edyrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706091743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, i have some questions for you about Apache Superset.&lt;/p&gt;\n\n&lt;p&gt;The my first doubt is how to use percentages in the tool. I&amp;#39;ll explain it better: basically i&amp;#39;m trying to values in a bar chart in percentages instead of values (the total being the sum of values).&lt;/p&gt;\n\n&lt;p&gt;My second doubt instead is on displaying data from a pivot table into a heatmap. Basically, since i nedd rows from the table to be values on the Y axis i need to transform my data by using a pivot table, but i&amp;#39;m unable to use that transformed data into my heatmap, so i&amp;#39;d need to use custom SQL queries, which i&amp;#39;d like to avoid.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19edyrx", "is_robot_indexable": true, "report_reasons": null, "author": "Disastrous-Tune2889", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19edyrx/apache_superset_percentages_and_pivot_table_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19edyrx/apache_superset_percentages_and_pivot_table_with/", "subreddit_subscribers": 155457, "created_utc": 1706091743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Must watch if you have ever been confused/frustrated with Python paths and packaging.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_19e7pf8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/v6tALyc4C10?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Packaging Your Python Code With pyproject.toml | Complete Code Conversation\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Packaging Your Python Code With pyproject.toml | Complete Code Conversation", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/v6tALyc4C10?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Packaging Your Python Code With pyproject.toml | Complete Code Conversation\"&gt;&lt;/iframe&gt;", "author_name": "Real Python", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/v6tALyc4C10/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@realpython"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/v6tALyc4C10?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Packaging Your Python Code With pyproject.toml | Complete Code Conversation\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/19e7pf8", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/3kuudUaEorxNEiKRX0XoC9rQXM9Np4-y2MFhrMBzX30.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706067632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=v6tALyc4C10", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/35v3F8X8Bkp_U7u5tlU6rkZop4WfJXKIdtzxehCbdfY.jpg?auto=webp&amp;s=15c96d0a57990daad9ceb7044847115735098688", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/35v3F8X8Bkp_U7u5tlU6rkZop4WfJXKIdtzxehCbdfY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c1796fdee5b48e6ac8851ca7b8d236a56c250b8e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/35v3F8X8Bkp_U7u5tlU6rkZop4WfJXKIdtzxehCbdfY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1d482728dd5c3d0b6d3c4845255f7cbdf6816cc6", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/35v3F8X8Bkp_U7u5tlU6rkZop4WfJXKIdtzxehCbdfY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=336ce71509e721be4da6454ebd7c7ac9571a465d", "width": 320, "height": 240}], "variants": {}, "id": "bJ82cZJ_dSSei8mziFPvY5jwtpPYIZMcrX7dkta6BY0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19e7pf8", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19e7pf8/must_watch_if_you_have_ever_been/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=v6tALyc4C10", "subreddit_subscribers": 155457, "created_utc": 1706067632.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Packaging Your Python Code With pyproject.toml | Complete Code Conversation", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/v6tALyc4C10?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Packaging Your Python Code With pyproject.toml | Complete Code Conversation\"&gt;&lt;/iframe&gt;", "author_name": "Real Python", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/v6tALyc4C10/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@realpython"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all! \n\nWe have about 1 PB worth of data to move from onPrem storage to Aws. We are considering using Deep Archive as an archive storage solution until we can get more on prem storage. This data is expected to never be used again but cannot be deleted. I have a few questions now\n\n1. Does it make sense to use Deep Archive as an Archive solution if we plan to get on prem capacity in 6-12 months?\n\n2. Are there costs to upload data? Or only to store and download the data? \n\n3. Is there a method to transfer the data from the regular S3 bucket to Deep archive without setting the 24 hour rule?\n\nThanks!!", "author_fullname": "t2_624odrt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Large Data Migration to AWS Glacier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19epl1b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706126182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! &lt;/p&gt;\n\n&lt;p&gt;We have about 1 PB worth of data to move from onPrem storage to Aws. We are considering using Deep Archive as an archive storage solution until we can get more on prem storage. This data is expected to never be used again but cannot be deleted. I have a few questions now&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Does it make sense to use Deep Archive as an Archive solution if we plan to get on prem capacity in 6-12 months?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Are there costs to upload data? Or only to store and download the data? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is there a method to transfer the data from the regular S3 bucket to Deep archive without setting the 24 hour rule?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19epl1b", "is_robot_indexable": true, "report_reasons": null, "author": "Helium0205", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19epl1b/large_data_migration_to_aws_glacier/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19epl1b/large_data_migration_to_aws_glacier/", "subreddit_subscribers": 155457, "created_utc": 1706126182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7lbbuuh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2024 Data Engineering Trends - do you agree with these? What do you consider the most relevant trends in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ejjrf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1706109773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2024-01-24-2024-data-engineering-trends", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19ejjrf", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Following1532", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ejjrf/2024_data_engineering_trends_do_you_agree_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2024-01-24-2024-data-engineering-trends", "subreddit_subscribers": 155457, "created_utc": 1706109773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a data warehousing background and just started learning Spark. Naturally, I started looking for similarities and analogies between the two systems, and I'm very confused. It seems so very different than typical dwh scenario. Here are my questions:\n\n* Data warehouses typically have a star schema data model. I know spark is just a processing engine, but do spark projects have a \"typical\" data model? Is it also star schema? Or do you have everything-joined one big table for every data load?\n* How do you handle daily data insertion? Are techniques like dimension upserts and scds, fact upserts, etc even done in spark?\n* Is using data catalog necessary? Or just good to have?\n* Are raw parquet files ever used? Or you pretty much must use Iceberg/Delta table?\n* How is spark processed data consumed at the end? Do analysts use tools like Presto/Athena? Are BI tools pointed to S3?\n* Are these questions even spark questions or data lake questions?\n* Finally, are there any articles, videos, or courses about spark design patterns that answer above questions or similar? Am I even asking the right questions?\n\nThanks!", "author_fullname": "t2_4ajys98ob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark questions coming from DWH background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ecfst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706084936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data warehousing background and just started learning Spark. Naturally, I started looking for similarities and analogies between the two systems, and I&amp;#39;m very confused. It seems so very different than typical dwh scenario. Here are my questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data warehouses typically have a star schema data model. I know spark is just a processing engine, but do spark projects have a &amp;quot;typical&amp;quot; data model? Is it also star schema? Or do you have everything-joined one big table for every data load?&lt;/li&gt;\n&lt;li&gt;How do you handle daily data insertion? Are techniques like dimension upserts and scds, fact upserts, etc even done in spark?&lt;/li&gt;\n&lt;li&gt;Is using data catalog necessary? Or just good to have?&lt;/li&gt;\n&lt;li&gt;Are raw parquet files ever used? Or you pretty much must use Iceberg/Delta table?&lt;/li&gt;\n&lt;li&gt;How is spark processed data consumed at the end? Do analysts use tools like Presto/Athena? Are BI tools pointed to S3?&lt;/li&gt;\n&lt;li&gt;Are these questions even spark questions or data lake questions?&lt;/li&gt;\n&lt;li&gt;Finally, are there any articles, videos, or courses about spark design patterns that answer above questions or similar? Am I even asking the right questions?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19ecfst", "is_robot_indexable": true, "report_reasons": null, "author": "PakumCakum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ecfst/spark_questions_coming_from_dwh_background/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19ecfst/spark_questions_coming_from_dwh_background/", "subreddit_subscribers": 155457, "created_utc": 1706084936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, we are planning on using Fivetran as our data ingestion tool and also leverage its capabilities for hosting dbt projects\nI see that it\u2019s on beta currently and so far we haven\u2019t faced any issues on our development warehouse when it comes to using the platform\nI would like to know when it\u2019s going to be released as a stable version.", "author_fullname": "t2_6y1og8oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran with DBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ec88e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706084033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, we are planning on using Fivetran as our data ingestion tool and also leverage its capabilities for hosting dbt projects\nI see that it\u2019s on beta currently and so far we haven\u2019t faced any issues on our development warehouse when it comes to using the platform\nI would like to know when it\u2019s going to be released as a stable version.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19ec88e", "is_robot_indexable": true, "report_reasons": null, "author": "Professional-Ninja70", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ec88e/fivetran_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19ec88e/fivetran_with_dbt/", "subreddit_subscribers": 155457, "created_utc": 1706084033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m reading avro messages from Kafka by connecting to the schema registry through a Delta Live Tables pipeline (DLT). I then use the from_avro method to deserialize this message stream. The records are present as json objects, how do I use from_json to load this data inside delta? It\u2019s asking me for the schema, is there any way I can dynamically infer the schema? \n\nTL;DR: how to dynamically infer schema from a JSON stream and load inside delta?", "author_fullname": "t2_htau4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deserialize json data from an avro message stream in Databricks using DLT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ea6tf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706075987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m reading avro messages from Kafka by connecting to the schema registry through a Delta Live Tables pipeline (DLT). I then use the from_avro method to deserialize this message stream. The records are present as json objects, how do I use from_json to load this data inside delta? It\u2019s asking me for the schema, is there any way I can dynamically infer the schema? &lt;/p&gt;\n\n&lt;p&gt;TL;DR: how to dynamically infer schema from a JSON stream and load inside delta?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19ea6tf", "is_robot_indexable": true, "report_reasons": null, "author": "sampasha007", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ea6tf/how_to_deserialize_json_data_from_an_avro_message/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19ea6tf/how_to_deserialize_json_data_from_an_avro_message/", "subreddit_subscribers": 155457, "created_utc": 1706075987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm currently doing Masters in Ai and Data and I don't have a CS bachelor degree not even related to it. It's in Finance/Business. \n\nI have a few months till I graduate. I have had few projects using Python, I'm familiar with SQL. I know I need to get better at both of them. \n\nI also wanted to do the Microsoft DP-203 and the AWS Data Engineer Associate / Solution Architect. 1. To fill cv and 2. To be familiar with cloud. \n\nWhat else should I spend the next few months doing? And do I have a chance at landing my first job soon or no? Is this enough or not? \n\nI'm in London (UK) if that helps.", "author_fullname": "t2_rrtbk3gwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you do it? Make my plan better.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19e2m1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706053071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m currently doing Masters in Ai and Data and I don&amp;#39;t have a CS bachelor degree not even related to it. It&amp;#39;s in Finance/Business. &lt;/p&gt;\n\n&lt;p&gt;I have a few months till I graduate. I have had few projects using Python, I&amp;#39;m familiar with SQL. I know I need to get better at both of them. &lt;/p&gt;\n\n&lt;p&gt;I also wanted to do the Microsoft DP-203 and the AWS Data Engineer Associate / Solution Architect. 1. To fill cv and 2. To be familiar with cloud. &lt;/p&gt;\n\n&lt;p&gt;What else should I spend the next few months doing? And do I have a chance at landing my first job soon or no? Is this enough or not? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in London (UK) if that helps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19e2m1m", "is_robot_indexable": true, "report_reasons": null, "author": "Timeframe98", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19e2m1m/how_would_you_do_it_make_my_plan_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19e2m1m/how_would_you_do_it_make_my_plan_better/", "subreddit_subscribers": 155457, "created_utc": 1706053071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I interviewed for a F500 pharmaceutical company and was wondering whether I should be expecting more steps based off what I've done so far:\n\n1. (30 min) HR screening HireVue\n2. (90 min) Hackerrank take-home assessment on Python/REST APIS, SQL, Git, and Docker\n3. (45 min) Interview with HM discussing about my skill set, experiences, and some technical questions related to the things I've done. \n\nI had a great talk with the HM but forgot to discuss next steps.  I emailed my recruiter a few days ago and haven't gotten a response yet, so I just wanted to get some opinions whether this would be the last step of the interview process or if there'd be more to come.", "author_fullname": "t2_33bgrbrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Entry Level Data Platform Engineer Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19er4bk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706129938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I interviewed for a F500 pharmaceutical company and was wondering whether I should be expecting more steps based off what I&amp;#39;ve done so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;(30 min) HR screening HireVue&lt;/li&gt;\n&lt;li&gt;(90 min) Hackerrank take-home assessment on Python/REST APIS, SQL, Git, and Docker&lt;/li&gt;\n&lt;li&gt;(45 min) Interview with HM discussing about my skill set, experiences, and some technical questions related to the things I&amp;#39;ve done. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I had a great talk with the HM but forgot to discuss next steps.  I emailed my recruiter a few days ago and haven&amp;#39;t gotten a response yet, so I just wanted to get some opinions whether this would be the last step of the interview process or if there&amp;#39;d be more to come.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "19er4bk", "is_robot_indexable": true, "report_reasons": null, "author": "c9zellsis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19er4bk/entry_level_data_platform_engineer_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19er4bk/entry_level_data_platform_engineer_interview/", "subreddit_subscribers": 155457, "created_utc": 1706129938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_d321jhgdp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverless Storage with Knative and Ceph", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_19eqx1m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/wh8T3wtxYK_CB-yPYIqDYcmiB3UIDOZDDzgUMKovFI4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706129451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "koor.tech", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://koor.tech/blog/2024/serverless-storage-knative-ceph/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/H_gMycOQaL-wduvgBEWb_GKH3GgfojqvVQysy0xdnS0.jpg?auto=webp&amp;s=752d8ce59afd526f396ebba589fc3290a5bb7ba1", "width": 1000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/H_gMycOQaL-wduvgBEWb_GKH3GgfojqvVQysy0xdnS0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=767b6427b19a74005d0434d92edb70e13a886573", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/H_gMycOQaL-wduvgBEWb_GKH3GgfojqvVQysy0xdnS0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1d0699579b1a90eb8fe9c87127425dbca77fb25b", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/H_gMycOQaL-wduvgBEWb_GKH3GgfojqvVQysy0xdnS0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4fdce9f199d80b6f6f7a2b930475434b65a4155b", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/H_gMycOQaL-wduvgBEWb_GKH3GgfojqvVQysy0xdnS0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1db1d0a8d6f87fab5ce54ea5b4c7dba1a5d9adea", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/H_gMycOQaL-wduvgBEWb_GKH3GgfojqvVQysy0xdnS0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a9e7d5023d639bca5524939b3966e6efa6cafac4", "width": 960, "height": 960}], "variants": {}, "id": "KU96moolwDSiBsI-3GZnwNFe-2pabct7jEiDx7EMU6w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19eqx1m", "is_robot_indexable": true, "report_reasons": null, "author": "Dave-at-Koor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19eqx1m/serverless_storage_with_knative_and_ceph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://koor.tech/blog/2024/serverless-storage-knative-ceph/", "subreddit_subscribers": 155457, "created_utc": 1706129451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for tools/framework to query s3 compatible object data stores hosted on prem. I know trino/presto can provide sql layer on top of object storage, are there any other simple and efficient tools available?", "author_fullname": "t2_2u4w55mk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "tools to query s3 compatible on-prem object stores", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19eqaen", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706127884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for tools/framework to query s3 compatible object data stores hosted on prem. I know trino/presto can provide sql layer on top of object storage, are there any other simple and efficient tools available?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19eqaen", "is_robot_indexable": true, "report_reasons": null, "author": "przx2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19eqaen/tools_to_query_s3_compatible_onprem_object_stores/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19eqaen/tools_to_query_s3_compatible_onprem_object_stores/", "subreddit_subscribers": 155457, "created_utc": 1706127884.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}