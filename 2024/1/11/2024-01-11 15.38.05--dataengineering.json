{"kind": "Listing", "data": {"after": "t3_193wa6n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been at companies before in a DS role and observed round after round analysts and DS impacted. But sole DE responsible for critical infra related to billing etc was the last holdout. This, in addition to fun of learning something new, inspired me to transition to DE years ago. I can see an impending storm this year based off many corporate red flags and hints.\n\nI\u2019m wondering if I should go to greener pastures like city or utility type DE work. I have made myself the sole DE responsible for critical billing calculations and infra at current company but my comfort level when layoffs start isn\u2019t very high and I maybe have 4-5 months of savings not the 1 year that is vaunted. \n\nThe last thing I want is to be impacted and forced to get a job that I\u2019m not excited about or find out the wait to get an offer is 9+ months for an experienced DE", "author_fullname": "t2_kdvor", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are DE\u2019s less prone to first wave layoffs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193dqrc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704907910.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704907701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been at companies before in a DS role and observed round after round analysts and DS impacted. But sole DE responsible for critical infra related to billing etc was the last holdout. This, in addition to fun of learning something new, inspired me to transition to DE years ago. I can see an impending storm this year based off many corporate red flags and hints.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering if I should go to greener pastures like city or utility type DE work. I have made myself the sole DE responsible for critical billing calculations and infra at current company but my comfort level when layoffs start isn\u2019t very high and I maybe have 4-5 months of savings not the 1 year that is vaunted. &lt;/p&gt;\n\n&lt;p&gt;The last thing I want is to be impacted and forced to get a job that I\u2019m not excited about or find out the wait to get an offer is 9+ months for an experienced DE&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "193dqrc", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Dork", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193dqrc/are_des_less_prone_to_first_wave_layoffs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193dqrc/are_des_less_prone_to_first_wave_layoffs/", "subreddit_subscribers": 151897, "created_utc": 1704907701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen a major uptick in job posting asking for Spark and Kafka. \n\nKafka I understand why it's asked for, but aside from setting up a consumer every now and then, from what I've seen, it isn't a significant part of a lot of warehouse data pipelines. \n\nFor Spark, most workloads for most data products can be handled without a Spark setup, or is abstracted with current database/datawarehousing solutions. \n\nWhile I understand that there are a growing amount of products and applications that require or would largely benefit from these two technologies, I imagine that there also an overwhelming amount of data pipelines that don't really need or use it. \n\nHowever it feels like 30-40% of recent job listings are asking for experience with those. \n\nDo you think it's because companies are trying to setup to leverage real time data AI solutions? or do you think it's mostly employers that ask for skills for the sake of putting skills?", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think that most job posts that ask for distributed computing actually require distributed computing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193dhko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704907072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen a major uptick in job posting asking for Spark and Kafka. &lt;/p&gt;\n\n&lt;p&gt;Kafka I understand why it&amp;#39;s asked for, but aside from setting up a consumer every now and then, from what I&amp;#39;ve seen, it isn&amp;#39;t a significant part of a lot of warehouse data pipelines. &lt;/p&gt;\n\n&lt;p&gt;For Spark, most workloads for most data products can be handled without a Spark setup, or is abstracted with current database/datawarehousing solutions. &lt;/p&gt;\n\n&lt;p&gt;While I understand that there are a growing amount of products and applications that require or would largely benefit from these two technologies, I imagine that there also an overwhelming amount of data pipelines that don&amp;#39;t really need or use it. &lt;/p&gt;\n\n&lt;p&gt;However it feels like 30-40% of recent job listings are asking for experience with those. &lt;/p&gt;\n\n&lt;p&gt;Do you think it&amp;#39;s because companies are trying to setup to leverage real time data AI solutions? or do you think it&amp;#39;s mostly employers that ask for skills for the sake of putting skills?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193dhko", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/193dhko/do_you_think_that_most_job_posts_that_ask_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193dhko/do_you_think_that_most_job_posts_that_ask_for/", "subreddit_subscribers": 151897, "created_utc": 1704907072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm hearing more and more about dashboards dying and moving to \"interactive data apps\". I wonder if this is vendor marketing fluff or if this is actually happening. Thoughts?", "author_fullname": "t2_jg3w8gbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will you stop using dashboards?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193xq76", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704968069.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704965374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m hearing more and more about dashboards dying and moving to &amp;quot;interactive data apps&amp;quot;. I wonder if this is vendor marketing fluff or if this is actually happening. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193xq76", "is_robot_indexable": true, "report_reasons": null, "author": "tamargal91", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193xq76/will_you_stop_using_dashboards/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193xq76/will_you_stop_using_dashboards/", "subreddit_subscribers": 151897, "created_utc": 1704965374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some members of my team have raised some points about not having enough focus time, due to: \n\n* general email\n* data issues (via slack/email\n* slack messages (within team or outside)\n* meetings (fairly minimal but still disruptive of the flow)\n* in-person questions - usually from within team (we have semi-open floorplan)\n\na senior data engineer mentioned he rarely gets 90 minutes  of uninterrupted development work per day. Our small team  manages about a dozen third party clients (with unclean data sometimes) plus our own internal processes and . Some weeks, it's not bad, other times there are a string of issues/interruptions. \n\nWhat are some specific techniques y'all have employed to focus?\n\n* snooze slack\n* focus time slack status (do people respect this?)\n* custom slack status\n* block calendar time\n* how to handle in-person chatter/questions? \n   * headphones on means focus?", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage uninterrupted focus time amid job failures, slack messages, emails, meetings?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193mypp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704930159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some members of my team have raised some points about not having enough focus time, due to: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;general email&lt;/li&gt;\n&lt;li&gt;data issues (via slack/email&lt;/li&gt;\n&lt;li&gt;slack messages (within team or outside)&lt;/li&gt;\n&lt;li&gt;meetings (fairly minimal but still disruptive of the flow)&lt;/li&gt;\n&lt;li&gt;in-person questions - usually from within team (we have semi-open floorplan)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;a senior data engineer mentioned he rarely gets 90 minutes  of uninterrupted development work per day. Our small team  manages about a dozen third party clients (with unclean data sometimes) plus our own internal processes and . Some weeks, it&amp;#39;s not bad, other times there are a string of issues/interruptions. &lt;/p&gt;\n\n&lt;p&gt;What are some specific techniques y&amp;#39;all have employed to focus?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;snooze slack&lt;/li&gt;\n&lt;li&gt;focus time slack status (do people respect this?)&lt;/li&gt;\n&lt;li&gt;custom slack status&lt;/li&gt;\n&lt;li&gt;block calendar time&lt;/li&gt;\n&lt;li&gt;how to handle in-person chatter/questions? \n\n&lt;ul&gt;\n&lt;li&gt;headphones on means focus?&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193mypp", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193mypp/how_do_you_manage_uninterrupted_focus_time_amid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193mypp/how_do_you_manage_uninterrupted_focus_time_amid/", "subreddit_subscribers": 151897, "created_utc": 1704930159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data changed from few thousand records to millions of records. Everything is well organized, tracked and validated. \n\nI\u2019m struggling to learn so many frameworks, and understanding huge data with a lot of attributes for data modeling. \n\nNot able to handle the pressure and feeling of not belonging here, as everyone seems to know what they are doing and deploying lot of changes to production, every week. \n\nI have been working here for 2 months and I got a feedback that I should be faster. I\u2019m not able to progress due to fear of getting fired. People who joined few months before seem to be performing better or meeting expectations.\n\nDid any face these challenges while changing organisation? How did you handle it? Any suggestions?", "author_fullname": "t2_q9ou4icln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moved from a small company, which uses simple cloud services to a big corporation, that uses robust frameworks for ETL, processing and validations.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193vm5s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704956576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data changed from few thousand records to millions of records. Everything is well organized, tracked and validated. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m struggling to learn so many frameworks, and understanding huge data with a lot of attributes for data modeling. &lt;/p&gt;\n\n&lt;p&gt;Not able to handle the pressure and feeling of not belonging here, as everyone seems to know what they are doing and deploying lot of changes to production, every week. &lt;/p&gt;\n\n&lt;p&gt;I have been working here for 2 months and I got a feedback that I should be faster. I\u2019m not able to progress due to fear of getting fired. People who joined few months before seem to be performing better or meeting expectations.&lt;/p&gt;\n\n&lt;p&gt;Did any face these challenges while changing organisation? How did you handle it? Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "193vm5s", "is_robot_indexable": true, "report_reasons": null, "author": "Agile-Letterhead6262", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193vm5s/moved_from_a_small_company_which_uses_simple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193vm5s/moved_from_a_small_company_which_uses_simple/", "subreddit_subscribers": 151897, "created_utc": 1704956576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I hear Great Expectations (GX) banded about a lot on forum posts and from Medium articles etc.\n \n\nI understand that it's a data quality tool, but so far I don't really understand why I would use it over just writing tests for my DBT models? I think maybe some of the examples I've seen are just too trivial to do GX justice?\n\n\nTo give you an idea of my current \"data engineering\" role (because as we know it's a vast space) I'm using Meltano to connect a bunch of app databases and third party sources to a warehouse then using DBT to create models for either analytics or dashboards. More of the time I'm doing backend and infra/kubernetes work.\n\n\nI'd love to hear your thoughts and use cases!", "author_fullname": "t2_elooc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why should I use Great Expectations if I already have tests in DBT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193eced", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704909139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hear Great Expectations (GX) banded about a lot on forum posts and from Medium articles etc.&lt;/p&gt;\n\n&lt;p&gt;I understand that it&amp;#39;s a data quality tool, but so far I don&amp;#39;t really understand why I would use it over just writing tests for my DBT models? I think maybe some of the examples I&amp;#39;ve seen are just too trivial to do GX justice?&lt;/p&gt;\n\n&lt;p&gt;To give you an idea of my current &amp;quot;data engineering&amp;quot; role (because as we know it&amp;#39;s a vast space) I&amp;#39;m using Meltano to connect a bunch of app databases and third party sources to a warehouse then using DBT to create models for either analytics or dashboards. More of the time I&amp;#39;m doing backend and infra/kubernetes work.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your thoughts and use cases!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193eced", "is_robot_indexable": true, "report_reasons": null, "author": "trhyst", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193eced/why_should_i_use_great_expectations_if_i_already/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193eced/why_should_i_use_great_expectations_if_i_already/", "subreddit_subscribers": 151897, "created_utc": 1704909139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data Engineering Streaming Pipeline Architectures from my experiences working in multiple companies leveraging AWS, GCP and open source services. \n\nA templated approach for building a pipeline, solving two common types of patterns:\n- Event Sourcing\n- Change Data Capture\n\n\nRead here: https://www.junaideffendi.com/blog/5-real-time-pipeline-architecture/\n\n\nLet me know what pipelines have you worked on.", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real Time Pipeline Architectures on Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193c2jn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704903590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Engineering Streaming Pipeline Architectures from my experiences working in multiple companies leveraging AWS, GCP and open source services. &lt;/p&gt;\n\n&lt;p&gt;A templated approach for building a pipeline, solving two common types of patterns:\n- Event Sourcing\n- Change Data Capture&lt;/p&gt;\n\n&lt;p&gt;Read here: &lt;a href=\"https://www.junaideffendi.com/blog/5-real-time-pipeline-architecture/\"&gt;https://www.junaideffendi.com/blog/5-real-time-pipeline-architecture/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let me know what pipelines have you worked on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WMRXOvRnDl15aOhYvPm8m6tUf1BgsBTFNaCzdjbsVtU.jpg?auto=webp&amp;s=a845224c53c51be3c6188387f0beb3e8b6affd48", "width": 1200, "height": 730}, "resolutions": [{"url": "https://external-preview.redd.it/WMRXOvRnDl15aOhYvPm8m6tUf1BgsBTFNaCzdjbsVtU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0e92f6615fce335e86369d2febea8088db5609df", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/WMRXOvRnDl15aOhYvPm8m6tUf1BgsBTFNaCzdjbsVtU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ad9082aec6c56170ed3fe978184a4cd0faad33a", "width": 216, "height": 131}, {"url": "https://external-preview.redd.it/WMRXOvRnDl15aOhYvPm8m6tUf1BgsBTFNaCzdjbsVtU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b5882f1aa636c627ff3724a80ef03bcc11b6452", "width": 320, "height": 194}, {"url": "https://external-preview.redd.it/WMRXOvRnDl15aOhYvPm8m6tUf1BgsBTFNaCzdjbsVtU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9eba533cfb1f23ecac44068bf23e1ba2dab09696", "width": 640, "height": 389}, {"url": "https://external-preview.redd.it/WMRXOvRnDl15aOhYvPm8m6tUf1BgsBTFNaCzdjbsVtU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=21c6a6cd622b4a1e97b5dc286ac91f4ca9a56306", "width": 960, "height": 584}, {"url": "https://external-preview.redd.it/WMRXOvRnDl15aOhYvPm8m6tUf1BgsBTFNaCzdjbsVtU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b26f8cbe4f918c7b0df58deff233c743d7619ef", "width": 1080, "height": 657}], "variants": {}, "id": "i_syJT1_eTrBV0FUapmPmpEIF1PP28dxxavor6Amt0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "193c2jn", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193c2jn/real_time_pipeline_architectures_on_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193c2jn/real_time_pipeline_architectures_on_cloud/", "subreddit_subscribers": 151897, "created_utc": 1704903590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why the Modern Data Stack sucks for data consultancies looking to productize", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_1940jpl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z80amFoGZF4uKOW3ePYmKPJw815hUsMMEdqHJ_f3Rmg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704976019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arch.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arch.dev/blog/why-the-modern-data-stack-sucks-for-data-consultancies-looking-to-productize/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?auto=webp&amp;s=d881a43f6049b89e4e066fdec179ca867234699a", "width": 1792, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d50965a9c8e4dfb95d059efbb0ca8874a7e9fd24", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d51552db0d7f00af72c2917c137535e480b083fb", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=abada4d1af8927e2dee9a58e9931ad829e98a32b", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7129035f695679de5a1082d9bad5e24b3cf5f9ff", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0fca419eef28bf35b5f5827f58a0d8841aab8355", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0509de0824804f288d0bc095bfdf0d6bad45829a", "width": 1080, "height": 617}], "variants": {}, "id": "WpZH0isc5AN4ZOJ6PliPBgbg_B4B6TaTgAHr3YBSZII"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1940jpl", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1940jpl/why_the_modern_data_stack_sucks_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arch.dev/blog/why-the-modern-data-stack-sucks-for-data-consultancies-looking-to-productize/", "subreddit_subscribers": 151897, "created_utc": 1704976019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn how to integrate Airbyte with data orchestrators: Airflow, Dagster and Prefect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_19422ta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6X1H2SM0LVO51H25EVG0a7bZhIpgPeD7hiefG1nJd5g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704980778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/integrating-airbyte-with-data-orchestrators-airflow-dagster-and-prefect", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eyFIgZDQkKd9rib0_emrSFDiX05KIgb0e1RhZueOzMQ.jpg?auto=webp&amp;s=f15ba17a8a6eb32a4ec015010e500183f8509f67", "width": 1800, "height": 942}, "resolutions": [{"url": "https://external-preview.redd.it/eyFIgZDQkKd9rib0_emrSFDiX05KIgb0e1RhZueOzMQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95bdb685c772ef231c0aef6c9423c82d5315bcb0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/eyFIgZDQkKd9rib0_emrSFDiX05KIgb0e1RhZueOzMQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f57537753fe0f3962b63f73794d43b3d1304f325", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/eyFIgZDQkKd9rib0_emrSFDiX05KIgb0e1RhZueOzMQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=961cb0eb4e9cb87a0058b140292733e354cf5a00", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/eyFIgZDQkKd9rib0_emrSFDiX05KIgb0e1RhZueOzMQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=30b511ea78bd62cf5c6bc24fc6f56979168a86eb", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/eyFIgZDQkKd9rib0_emrSFDiX05KIgb0e1RhZueOzMQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b887ea703f9d45e8fbef12cacb71846c3535db07", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/eyFIgZDQkKd9rib0_emrSFDiX05KIgb0e1RhZueOzMQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec07b9ceeaf4c3e89289c8f9fd4addd821ee992d", "width": 1080, "height": 565}], "variants": {}, "id": "pb9gkDAaPRocoO1Nyl8AaZ2AHezf-cWBCImf6e_C00A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19422ta", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19422ta/learn_how_to_integrate_airbyte_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/integrating-airbyte-with-data-orchestrators-airflow-dagster-and-prefect", "subreddit_subscribers": 151897, "created_utc": 1704980778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "we\u2019re currently working on our data, and we just entered the the phase where we\u2019re transforming our data using dbt. \n\nI\u2019m trying to watch closely what my team (1 person) is doing and tbh i didn\u2019t notice any changes!\n\nI mean, I find it exactly replicating the data from the data source. that\u2019s it. I can\u2019t see the added value. \n\nWe only re-group data into facts and dimensions, remove duplicates and rename the columns\u2026 I thought this phase will hold A LOT more. So, it\u2019s clear that we didn\u2019t understand how to use it properly. \n\nas an example, hubspot is one of our data sources and I found the transformed data not adding any value.. and we only have 7 tables from this source (?) leads, deals, quotations and contacts.\n\nI\u2019d appreciate if you can give examples of data transformation the people usually use and apply (I totally understand that this depends on the data/business/ business logic) but I\u2019m here trying to understand what are we missing and why i find it useless here.", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data transformation; what does it really mean?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1941wzt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704980310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;we\u2019re currently working on our data, and we just entered the the phase where we\u2019re transforming our data using dbt. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to watch closely what my team (1 person) is doing and tbh i didn\u2019t notice any changes!&lt;/p&gt;\n\n&lt;p&gt;I mean, I find it exactly replicating the data from the data source. that\u2019s it. I can\u2019t see the added value. &lt;/p&gt;\n\n&lt;p&gt;We only re-group data into facts and dimensions, remove duplicates and rename the columns\u2026 I thought this phase will hold A LOT more. So, it\u2019s clear that we didn\u2019t understand how to use it properly. &lt;/p&gt;\n\n&lt;p&gt;as an example, hubspot is one of our data sources and I found the transformed data not adding any value.. and we only have 7 tables from this source (?) leads, deals, quotations and contacts.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d appreciate if you can give examples of data transformation the people usually use and apply (I totally understand that this depends on the data/business/ business logic) but I\u2019m here trying to understand what are we missing and why i find it useless here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1941wzt", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1941wzt/data_transformation_what_does_it_really_mean/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1941wzt/data_transformation_what_does_it_really_mean/", "subreddit_subscribers": 151897, "created_utc": 1704980310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got an offer from a consulting company as Expert Level Support - Level 3 (There's no Level 4). I originally applied for Big Data Engineer, which they changed later during my interview process. My team manager uses DevOps Manager on his LinkedIn.\n\nI read that some people have tried to negotiate their titles during the job offer stage. Is it a good idea to negotiate it to Staff Data Engineer / Principal Data Engineer or even DevOps Engineer? Which title aligns better with expectations in the industry?\n\nThe thing is, I'm not sure if I would apply to another DE role in the future or try DevOps. Perhaps the vagueness of the current title could work in my favor if I ever want to explore other opportunities, perhaps not. Are there significantly more remote opportunities for DE over DevOps? That could be a factor.", "author_fullname": "t2_5qu7qetq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Negotiating job title - Staff Data Engineer or Expert Level Support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19412ic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704977724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got an offer from a consulting company as Expert Level Support - Level 3 (There&amp;#39;s no Level 4). I originally applied for Big Data Engineer, which they changed later during my interview process. My team manager uses DevOps Manager on his LinkedIn.&lt;/p&gt;\n\n&lt;p&gt;I read that some people have tried to negotiate their titles during the job offer stage. Is it a good idea to negotiate it to Staff Data Engineer / Principal Data Engineer or even DevOps Engineer? Which title aligns better with expectations in the industry?&lt;/p&gt;\n\n&lt;p&gt;The thing is, I&amp;#39;m not sure if I would apply to another DE role in the future or try DevOps. Perhaps the vagueness of the current title could work in my favor if I ever want to explore other opportunities, perhaps not. Are there significantly more remote opportunities for DE over DevOps? That could be a factor.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19412ic", "is_robot_indexable": true, "report_reasons": null, "author": "aguhon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19412ic/negotiating_job_title_staff_data_engineer_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19412ic/negotiating_job_title_staff_data_engineer_or/", "subreddit_subscribers": 151897, "created_utc": 1704977724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what would be the best language to learn as an accessory, the main reason being, I want to learn a low level language to understand Software Engineering better, that would benefit my DE career as well. ", "author_fullname": "t2_68ja65ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "accessory language to python for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193vaqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704955354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what would be the best language to learn as an accessory, the main reason being, I want to learn a low level language to understand Software Engineering better, that would benefit my DE career as well. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193vaqk", "is_robot_indexable": true, "report_reasons": null, "author": "alphamalet997", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193vaqk/accessory_language_to_python_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193vaqk/accessory_language_to_python_for_de/", "subreddit_subscribers": 151897, "created_utc": 1704955354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\u2026how good is it possible, and let\u2019s say only one person in charge plus a remote support person (freelancer, consultant), in case of vacation, longer absence etc.\n\nHow low can be the monthly costs for productive 300 GB data warehouse ?\n\nIt can be cloud based or on-premise.\n\nDo you have ideas or experiences - in midsize companies (below 250 persons) or small companies (1-25 persons)?", "author_fullname": "t2_h8o6jb9k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a (semi) automatic DWH for small midsize companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193uz6t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704954172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\u2026how good is it possible, and let\u2019s say only one person in charge plus a remote support person (freelancer, consultant), in case of vacation, longer absence etc.&lt;/p&gt;\n\n&lt;p&gt;How low can be the monthly costs for productive 300 GB data warehouse ?&lt;/p&gt;\n\n&lt;p&gt;It can be cloud based or on-premise.&lt;/p&gt;\n\n&lt;p&gt;Do you have ideas or experiences - in midsize companies (below 250 persons) or small companies (1-25 persons)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193uz6t", "is_robot_indexable": true, "report_reasons": null, "author": "volvoboy-85", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193uz6t/build_a_semi_automatic_dwh_for_small_midsize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193uz6t/build_a_semi_automatic_dwh_for_small_midsize/", "subreddit_subscribers": 151897, "created_utc": 1704954172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work on the azure stack (sql, adls, adf, databricks) with a team of about 7 total plus some contractors/consultants at time. \n\nIn the past year I have put a lot of effort into creating documentation not only for our environment but also the systems and pipelines we develop and maintain. At the moment these are just word docs on our SharePoint that take a fair bit of time to manage and maintain especially when everyone does it slightly differently. \n\nHow have others approached this? What has worked/not worked? What key information is essential for a pipeline/system? \n\n[View Poll](https://www.reddit.com/poll/193uvbq)", "author_fullname": "t2_qc6h84ym", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you document systems and pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193uvbq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704954262.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704953787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work on the azure stack (sql, adls, adf, databricks) with a team of about 7 total plus some contractors/consultants at time. &lt;/p&gt;\n\n&lt;p&gt;In the past year I have put a lot of effort into creating documentation not only for our environment but also the systems and pipelines we develop and maintain. At the moment these are just word docs on our SharePoint that take a fair bit of time to manage and maintain especially when everyone does it slightly differently. &lt;/p&gt;\n\n&lt;p&gt;How have others approached this? What has worked/not worked? What key information is essential for a pipeline/system? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/193uvbq\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193uvbq", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated-Western1788", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1705558587576, "options": [{"text": "It\u2019s a well oiled machine", "id": "26695945"}, {"text": "It\u2019s a mess", "id": "26695946"}, {"text": "We don\u2019t document anything", "id": "26695947"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 21, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193uvbq/how_do_you_document_systems_and_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/193uvbq/how_do_you_document_systems_and_pipelines/", "subreddit_subscribers": 151897, "created_utc": 1704953787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was recently hired as a Lead Data Engineer of a pipeline that will serve ML (Machine Learning) models on a Google Cloud &amp; Snowflake stack. I always learned that  is best to understand the end goal of the data pipeline and if it will serve reporting, analytics, or machine learning. I come from a background of pipelines for mostly reporting and analytics use cases. I will be responsible for architecting, modeling, enhancing, and managing the pipelines.\n\nI am curious as to how a ML use case will fundamentally impact my decisions/approach when it comes to some of following key considerations:\n\n* Data Sources\n* Determining Ingestion Strategy\n* Processing Plan\n* Storage Setup\n* Monitoring and Governance\n* Data Quality and Validation\n* Data Drift Monitoring\n* Consumption Layer\n* Currently ETL (Should I push for the more moden ELT approach)?\n\nThank you in advance for all guidance and insights!", "author_fullname": "t2_8b0w9ipt9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impact to Key Strategies When Serving a ML Use Case", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193sfou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704945938.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704945690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was recently hired as a Lead Data Engineer of a pipeline that will serve ML (Machine Learning) models on a Google Cloud &amp;amp; Snowflake stack. I always learned that  is best to understand the end goal of the data pipeline and if it will serve reporting, analytics, or machine learning. I come from a background of pipelines for mostly reporting and analytics use cases. I will be responsible for architecting, modeling, enhancing, and managing the pipelines.&lt;/p&gt;\n\n&lt;p&gt;I am curious as to how a ML use case will fundamentally impact my decisions/approach when it comes to some of following key considerations:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Sources&lt;/li&gt;\n&lt;li&gt;Determining Ingestion Strategy&lt;/li&gt;\n&lt;li&gt;Processing Plan&lt;/li&gt;\n&lt;li&gt;Storage Setup&lt;/li&gt;\n&lt;li&gt;Monitoring and Governance&lt;/li&gt;\n&lt;li&gt;Data Quality and Validation&lt;/li&gt;\n&lt;li&gt;Data Drift Monitoring&lt;/li&gt;\n&lt;li&gt;Consumption Layer&lt;/li&gt;\n&lt;li&gt;Currently ETL (Should I push for the more moden ELT approach)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you in advance for all guidance and insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193sfou", "is_robot_indexable": true, "report_reasons": null, "author": "JoseyWales10", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193sfou/impact_to_key_strategies_when_serving_a_ml_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193sfou/impact_to_key_strategies_when_serving_a_ml_use/", "subreddit_subscribers": 151897, "created_utc": 1704945690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nAt the moment, I organize my workload with a single machine per application instance. I am about to deploy an orchestration server to trigger some automations on a schedule.\n\nI\u2019ve got all my automations on my local machine. These aren\u2019t applications per se, just little scripts, ETL jobs, you name it. Now, I\u2019m trying to think of how I want to deploy workers and automations\u2026 it doesn\u2019t really fit in with my current model, does it? I see no sense in allocating an entire machine to a single automation of this scale.\n\nHow do you guys match machine to &lt;thing&gt; in your job? Do you guys have a high level architecture that you follow? Would you end up creating a machine designated for hosting several automation, or design it like how I do apps?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you host multiple apps on the same machine, even if they\u2019re all containers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193r7as", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704941988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;At the moment, I organize my workload with a single machine per application instance. I am about to deploy an orchestration server to trigger some automations on a schedule.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got all my automations on my local machine. These aren\u2019t applications per se, just little scripts, ETL jobs, you name it. Now, I\u2019m trying to think of how I want to deploy workers and automations\u2026 it doesn\u2019t really fit in with my current model, does it? I see no sense in allocating an entire machine to a single automation of this scale.&lt;/p&gt;\n\n&lt;p&gt;How do you guys match machine to &amp;lt;thing&amp;gt; in your job? Do you guys have a high level architecture that you follow? Would you end up creating a machine designated for hosting several automation, or design it like how I do apps?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193r7as", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193r7as/do_you_host_multiple_apps_on_the_same_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193r7as/do_you_host_multiple_apps_on_the_same_machine/", "subreddit_subscribers": 151897, "created_utc": 1704941988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I\u2019ve been working on this machine learning model to detect improper payments. \n\nThe performance isn\u2019t exceptional but it\u2019s acceptable given the data. \n\nThe model is saved and works well. The issue I\u2019m having now is deploying and automating the model to run everyday. \n\nThe process currently is I have a sql automation to export the features needed to input into the model into an excel file. \n\nI use python to open the excel and input the the features into the model and return the probability for each one. \n\nIm thinking the excel file is probably a bit excessive as I could use python to connect to database and gather the features from there then input in the model. Without opening an excel file directly. \n\n\nHowever, after the features are exported. Everything is done manually. What are some ways I could automate running the model daily. \n\n\nI\u2019m thinking of just using a batch file to run the python script. However, I\u2019m not sure if there\u2019s a more efficient way to do this. \n\nAfter that I wanna put this all on a tableau dashboard.\n\nAny suggested work around for this, trainings or whatever?", "author_fullname": "t2_8cjp70ft", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model Deployment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193qo6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704940423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019ve been working on this machine learning model to detect improper payments. &lt;/p&gt;\n\n&lt;p&gt;The performance isn\u2019t exceptional but it\u2019s acceptable given the data. &lt;/p&gt;\n\n&lt;p&gt;The model is saved and works well. The issue I\u2019m having now is deploying and automating the model to run everyday. &lt;/p&gt;\n\n&lt;p&gt;The process currently is I have a sql automation to export the features needed to input into the model into an excel file. &lt;/p&gt;\n\n&lt;p&gt;I use python to open the excel and input the the features into the model and return the probability for each one. &lt;/p&gt;\n\n&lt;p&gt;Im thinking the excel file is probably a bit excessive as I could use python to connect to database and gather the features from there then input in the model. Without opening an excel file directly. &lt;/p&gt;\n\n&lt;p&gt;However, after the features are exported. Everything is done manually. What are some ways I could automate running the model daily. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking of just using a batch file to run the python script. However, I\u2019m not sure if there\u2019s a more efficient way to do this. &lt;/p&gt;\n\n&lt;p&gt;After that I wanna put this all on a tableau dashboard.&lt;/p&gt;\n\n&lt;p&gt;Any suggested work around for this, trainings or whatever?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "193qo6p", "is_robot_indexable": true, "report_reasons": null, "author": "CaptainVJ", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193qo6p/model_deployment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193qo6p/model_deployment/", "subreddit_subscribers": 151897, "created_utc": 1704940423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm researching fuzzy entity linking and disambiguation in production environments and am interested in learning from your experiences. Specifically, I'd like to understand:\n\n* Sources and Schemas: What types of sources are you linking (details as permissible), and how many? How similar are their schemas? Can you provide examples of fuzzy or ambiguous cases?\n* Ground Truth: Do you use a standard knowledge base like Wikipedia as ground truth, or is your ground truth more dynamic, emerging from the disambiguation process itself?\n* Approach and Challenges: What's the general strategy of your approach? What aspects are particularly time-consuming, costly, or complex? Any notable edge cases?\n* Deterministic Methods: If using a deterministic approach, how do you balance false positives and negatives? How crucial is atomicity?\n* Tooling: Are there specific tools or strategies that you found effective?  Specifically interested in non-Wikipedia linking here, so excluding Azure AI Language.\n\nI appreciate any insights or strategies you can share, especially those backed by real-world examples. Thank you.", "author_fullname": "t2_tlb477sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Production Fuzzy Entity Linking / Disambiguation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193e279", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704908465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m researching fuzzy entity linking and disambiguation in production environments and am interested in learning from your experiences. Specifically, I&amp;#39;d like to understand:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Sources and Schemas: What types of sources are you linking (details as permissible), and how many? How similar are their schemas? Can you provide examples of fuzzy or ambiguous cases?&lt;/li&gt;\n&lt;li&gt;Ground Truth: Do you use a standard knowledge base like Wikipedia as ground truth, or is your ground truth more dynamic, emerging from the disambiguation process itself?&lt;/li&gt;\n&lt;li&gt;Approach and Challenges: What&amp;#39;s the general strategy of your approach? What aspects are particularly time-consuming, costly, or complex? Any notable edge cases?&lt;/li&gt;\n&lt;li&gt;Deterministic Methods: If using a deterministic approach, how do you balance false positives and negatives? How crucial is atomicity?&lt;/li&gt;\n&lt;li&gt;Tooling: Are there specific tools or strategies that you found effective?  Specifically interested in non-Wikipedia linking here, so excluding Azure AI Language.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I appreciate any insights or strategies you can share, especially those backed by real-world examples. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193e279", "is_robot_indexable": true, "report_reasons": null, "author": "emu-la-tor", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193e279/production_fuzzy_entity_linking_disambiguation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193e279/production_fuzzy_entity_linking_disambiguation/", "subreddit_subscribers": 151897, "created_utc": 1704908465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It should also be able to take care of functionalities like scheduling, error handling, auditing past runs , alerting for errors etc. \n\nThe main use case of this is exporting and importing data to and from Salesforce and AWS.\n\nI am very new to this, Sorry, if this is a ill informed question.\n\nEdit:\n\nWhere?\n\nI need to take the data usually from aws s3 and upload it Salesforce. Its usually in csv format but could be in any format. Also I am interested if it could use other aws services like secrets manger etc.\n\nWhy?\n\nThe reason for doing this is data integrations and migrations from 3rd party systems.\n\nAny transformations?\n\nYes, since there are all from 3rd party system. I need to do a lot of transformations for it to fit the data structure of salesforce.Changing the date format,Mapping the values to similar but different values present in salesforce,Integer to BigDecimal,Concatenating data,Splitting data,Being able to do queries to find lookup values that are already uploaded in the system(Salesforce) etc.\n\nHow much data?\n\nThe data is usually not very much around 50,000 rows of data on some of the biggest object exports. Other objects are usually much lower than that average would be 20k rows of data records.\n\nHow often?\n\nIntegrations needs to be done more often daily, weekly, monthly. And they take less time to build as well. Compared to full data migrations they are one time thing but take a lot of time to built. Since the data is coming from a 3rd party.", "author_fullname": "t2_9j8rqo2y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best code based ETL tool for working with Salesforce and AWS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193d288", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704908814.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704906041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It should also be able to take care of functionalities like scheduling, error handling, auditing past runs , alerting for errors etc. &lt;/p&gt;\n\n&lt;p&gt;The main use case of this is exporting and importing data to and from Salesforce and AWS.&lt;/p&gt;\n\n&lt;p&gt;I am very new to this, Sorry, if this is a ill informed question.&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;Where?&lt;/p&gt;\n\n&lt;p&gt;I need to take the data usually from aws s3 and upload it Salesforce. Its usually in csv format but could be in any format. Also I am interested if it could use other aws services like secrets manger etc.&lt;/p&gt;\n\n&lt;p&gt;Why?&lt;/p&gt;\n\n&lt;p&gt;The reason for doing this is data integrations and migrations from 3rd party systems.&lt;/p&gt;\n\n&lt;p&gt;Any transformations?&lt;/p&gt;\n\n&lt;p&gt;Yes, since there are all from 3rd party system. I need to do a lot of transformations for it to fit the data structure of salesforce.Changing the date format,Mapping the values to similar but different values present in salesforce,Integer to BigDecimal,Concatenating data,Splitting data,Being able to do queries to find lookup values that are already uploaded in the system(Salesforce) etc.&lt;/p&gt;\n\n&lt;p&gt;How much data?&lt;/p&gt;\n\n&lt;p&gt;The data is usually not very much around 50,000 rows of data on some of the biggest object exports. Other objects are usually much lower than that average would be 20k rows of data records.&lt;/p&gt;\n\n&lt;p&gt;How often?&lt;/p&gt;\n\n&lt;p&gt;Integrations needs to be done more often daily, weekly, monthly. And they take less time to build as well. Compared to full data migrations they are one time thing but take a lot of time to built. Since the data is coming from a 3rd party.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193d288", "is_robot_indexable": true, "report_reasons": null, "author": "Brilliant-Republic75", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193d288/whats_the_best_code_based_etl_tool_for_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193d288/whats_the_best_code_based_etl_tool_for_working/", "subreddit_subscribers": 151897, "created_utc": 1704906041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse Analytics - The Latency Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_193bc8w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tMA1RKB3KJe056qxx0qycqRGuxW2S4i0R__R65ZYwKg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704901724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/data-warehouse-analytics-latency", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/llr6iYmYHYMBPqXCc_mxLsSKAWx_yr1Io0vK3Tw0-xM.jpg?auto=webp&amp;s=14854cff73b48474f38e0f48168b8fcd9ac8462e", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/llr6iYmYHYMBPqXCc_mxLsSKAWx_yr1Io0vK3Tw0-xM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a8a63815d090e203226134bde7f95ed6f73b1e48", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/llr6iYmYHYMBPqXCc_mxLsSKAWx_yr1Io0vK3Tw0-xM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2c6b4008d4a17750337a12c66154eed3c9ab2152", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/llr6iYmYHYMBPqXCc_mxLsSKAWx_yr1Io0vK3Tw0-xM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9da766a3812e6820d4bc928715e67977090e4748", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/llr6iYmYHYMBPqXCc_mxLsSKAWx_yr1Io0vK3Tw0-xM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e4ccded7fe274cccf4405268763034dbc00fb133", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/llr6iYmYHYMBPqXCc_mxLsSKAWx_yr1Io0vK3Tw0-xM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=215f7f33b082fa49a887eae2b984362e195230c0", "width": 960, "height": 562}], "variants": {}, "id": "x4MSBBH20CT1wCVb1xFveniSTGMHjmOMDocFfhgeFHI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "193bc8w", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193bc8w/data_warehouse_analytics_the_latency_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/data-warehouse-analytics-latency", "subreddit_subscribers": 151897, "created_utc": 1704901724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I was looking for a useful and interactive program that could help equip me with the appropriate technical skills I need for my analyst role- I\u2019m moving more towards the data engineering side of my project but there are skill gaps I have that I need to fill. I\u2019m just looking for structure without bootcamp commitment. \n\nI came across Data Engineer Academy and looked through some of their content. Does anyone have any experience with DE Academy? How does it compare with other alternatives you can vouch for?", "author_fullname": "t2_4ehev28e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reviews on Data Engineer Academy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_194304v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1704983384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeracademy.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I was looking for a useful and interactive program that could help equip me with the appropriate technical skills I need for my analyst role- I\u2019m moving more towards the data engineering side of my project but there are skill gaps I have that I need to fill. I\u2019m just looking for structure without bootcamp commitment. &lt;/p&gt;\n\n&lt;p&gt;I came across Data Engineer Academy and looked through some of their content. Does anyone have any experience with DE Academy? How does it compare with other alternatives you can vouch for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dataengineeracademy.com", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194304v", "is_robot_indexable": true, "report_reasons": null, "author": "rae190", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194304v/reviews_on_data_engineer_academy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dataengineeracademy.com", "subreddit_subscribers": 151897, "created_utc": 1704983384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are folks using to ingest large tabular files from Java into Parquet and friends?\n\nThe data is ultimately going to be reprocessed/joined with other tables and queried through an engine like Trino.\n\nToday a dataset will come in as various tabular formats, our users clean and map it using the Java backend, and it's stored in PostgreSQL. I love postgres, but we're bumping up against size and cost limits for some of the larger datasets; each dataset gets its own postgres instance while it's actively being used. I'd like to try moving away from it and toward the Iceberg ecosystem with object storage and a caching layer.\n\nOnce the data is already in object storage, or in a relational database, there's lots of ways to convert between formats using Trino or Spark, and tons of benchmarks and guides. But what's the best way to get it in there in the first place? How is big data formed?\n\nI've used ParquetWriter and Avro GenericData.Record a bit in the past. It's quite low-level. I'd like to have a bit of control over how the Parquet files are sorted and partitioned, either during the ingestion process or with some post-processing. I'll bet you can do anything with ParquetWriter and the Iceberg library, but getting it right, so the sorting/partitioning I do in the app, matches what I put in the metadata, would be hard, and the kind of thing I'd normally want a DBMS to handle.\n\nI was wondering about bulk loading into Trino via JDBC. I haven't been able to find performance numbers or guidance on whether this is a sane approach. I'm open to almost anything: using ParquetWriter directly, or DuckDB, or a JDBC connection to Trino or StarRocks, whatever makes sense.", "author_fullname": "t2_4m8rzb2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting to Parquet/Iceberg/object storage from Java", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1941ulb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704980107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are folks using to ingest large tabular files from Java into Parquet and friends?&lt;/p&gt;\n\n&lt;p&gt;The data is ultimately going to be reprocessed/joined with other tables and queried through an engine like Trino.&lt;/p&gt;\n\n&lt;p&gt;Today a dataset will come in as various tabular formats, our users clean and map it using the Java backend, and it&amp;#39;s stored in PostgreSQL. I love postgres, but we&amp;#39;re bumping up against size and cost limits for some of the larger datasets; each dataset gets its own postgres instance while it&amp;#39;s actively being used. I&amp;#39;d like to try moving away from it and toward the Iceberg ecosystem with object storage and a caching layer.&lt;/p&gt;\n\n&lt;p&gt;Once the data is already in object storage, or in a relational database, there&amp;#39;s lots of ways to convert between formats using Trino or Spark, and tons of benchmarks and guides. But what&amp;#39;s the best way to get it in there in the first place? How is big data formed?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used ParquetWriter and Avro GenericData.Record a bit in the past. It&amp;#39;s quite low-level. I&amp;#39;d like to have a bit of control over how the Parquet files are sorted and partitioned, either during the ingestion process or with some post-processing. I&amp;#39;ll bet you can do anything with ParquetWriter and the Iceberg library, but getting it right, so the sorting/partitioning I do in the app, matches what I put in the metadata, would be hard, and the kind of thing I&amp;#39;d normally want a DBMS to handle.&lt;/p&gt;\n\n&lt;p&gt;I was wondering about bulk loading into Trino via JDBC. I haven&amp;#39;t been able to find performance numbers or guidance on whether this is a sane approach. I&amp;#39;m open to almost anything: using ParquetWriter directly, or DuckDB, or a JDBC connection to Trino or StarRocks, whatever makes sense.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1941ulb", "is_robot_indexable": true, "report_reasons": null, "author": "t0astix", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1941ulb/ingesting_to_parqueticebergobject_storage_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1941ulb/ingesting_to_parqueticebergobject_storage_from/", "subreddit_subscribers": 151897, "created_utc": 1704980107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,\n\nI have been tasked to pull data from Sage Business Account Software for the finance team and create a data warehouse.  \n\n\nI don't have an issue with the other process just I haven't connected Azure Data Factory or Synapse Pipeline with Sage Business Account Software before and there is little to no material online on how to go about it.  \n\n\nI would appreciate it if I could get any support, guidance or link on how to configure ADF/Synapes Pipeline to connect with Sage.  \n\n\nThanks house!  \n", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrate Azure Data Factory with Sage Business Account Software(Cloud)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193yc3e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704967841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been tasked to pull data from Sage Business Account Software for the finance team and create a data warehouse.  &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have an issue with the other process just I haven&amp;#39;t connected Azure Data Factory or Synapse Pipeline with Sage Business Account Software before and there is little to no material online on how to go about it.  &lt;/p&gt;\n\n&lt;p&gt;I would appreciate it if I could get any support, guidance or link on how to configure ADF/Synapes Pipeline to connect with Sage.  &lt;/p&gt;\n\n&lt;p&gt;Thanks house!  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "193yc3e", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193yc3e/integrate_azure_data_factory_with_sage_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193yc3e/integrate_azure_data_factory_with_sage_business/", "subreddit_subscribers": 151897, "created_utc": 1704967841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I was developing some internal documentation about phases in data engineering projects and I would love some feedback.\n\nBy now, the phases I have are:\n\n1. Requirements gathering\n2. Data architecture design\n3. Time planning\n3. Develop and implement\n4. Testing\n5. Deploy on production\n6. Maintenance\n7. Evaluation\n\nDid I forget something important? Obviously, each point is explained in detail in the docs.\n\nThank you all in advance!", "author_fullname": "t2_p4nzh8v1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering project phases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193y54p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704967083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I was developing some internal documentation about phases in data engineering projects and I would love some feedback.&lt;/p&gt;\n\n&lt;p&gt;By now, the phases I have are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Requirements gathering&lt;/li&gt;\n&lt;li&gt;Data architecture design&lt;/li&gt;\n&lt;li&gt;Time planning&lt;/li&gt;\n&lt;li&gt;Develop and implement&lt;/li&gt;\n&lt;li&gt;Testing&lt;/li&gt;\n&lt;li&gt;Deploy on production&lt;/li&gt;\n&lt;li&gt;Maintenance&lt;/li&gt;\n&lt;li&gt;Evaluation&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Did I forget something important? Obviously, each point is explained in detail in the docs.&lt;/p&gt;\n\n&lt;p&gt;Thank you all in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "193y54p", "is_robot_indexable": true, "report_reasons": null, "author": "data_macrolide", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/193y54p/data_engineering_project_phases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193y54p/data_engineering_project_phases/", "subreddit_subscribers": 151897, "created_utc": 1704967083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI\u2019m working as a data engineer from 3 to 4 years in service based startup company. \n\nI am the only one from my company working with a client team which consists of 3 to 4 data engineers. we are helping data scientists to create a data pipeline for their ML model. It is kind of MLOps ,where we industrialize the models and deploy into production. my main concern is I have worked on 3 to 4 industrialization of machine learning models, but I am not sure the impact of that. \n\nThe POC is done by data scientist and it and the model is given to our team, we create a pipeline with data quality, data ingestion, transformations, monitoring, etc. that would be deployed to the production. Application maintenance team take it further.\n\n I am trying to find out what Impact am I making to the team and the company but I am not able to understand from where I\u2019ll get to know what the Impact is. There are few models which has been, which has never been used by the business, but we still do some of the enhancements.\nWhat is the best way to create an impact in our projects, how did you do?", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impact on data engineering projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_193wa6n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704959288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I\u2019m working as a data engineer from 3 to 4 years in service based startup company. &lt;/p&gt;\n\n&lt;p&gt;I am the only one from my company working with a client team which consists of 3 to 4 data engineers. we are helping data scientists to create a data pipeline for their ML model. It is kind of MLOps ,where we industrialize the models and deploy into production. my main concern is I have worked on 3 to 4 industrialization of machine learning models, but I am not sure the impact of that. &lt;/p&gt;\n\n&lt;p&gt;The POC is done by data scientist and it and the model is given to our team, we create a pipeline with data quality, data ingestion, transformations, monitoring, etc. that would be deployed to the production. Application maintenance team take it further.&lt;/p&gt;\n\n&lt;p&gt;I am trying to find out what Impact am I making to the team and the company but I am not able to understand from where I\u2019ll get to know what the Impact is. There are few models which has been, which has never been used by the business, but we still do some of the enhancements.\nWhat is the best way to create an impact in our projects, how did you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "193wa6n", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/193wa6n/impact_on_data_engineering_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/193wa6n/impact_on_data_engineering_projects/", "subreddit_subscribers": 151897, "created_utc": 1704959288.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}