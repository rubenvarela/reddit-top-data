{"kind": "Listing", "data": {"after": "t3_18zf1fh", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Personally, I think that communication skills are one of the aspects at the top of the list. Additionally, a depth in database technology, distributed systems, ETL/ELT, and business use cases. But for how long will those aspects remain true, since many things evolve over time, especially rapidly?\n\nDo you think have intermediate ML engineering knowledge, high performance computing, or any other present tangential knowledge will become table stakes? ", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In your opinion, what makes for an \"elite\" data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z9z3x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704469824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Personally, I think that communication skills are one of the aspects at the top of the list. Additionally, a depth in database technology, distributed systems, ETL/ELT, and business use cases. But for how long will those aspects remain true, since many things evolve over time, especially rapidly?&lt;/p&gt;\n\n&lt;p&gt;Do you think have intermediate ML engineering knowledge, high performance computing, or any other present tangential knowledge will become table stakes? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18z9z3x", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z9z3x/in_your_opinion_what_makes_for_an_elite_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z9z3x/in_your_opinion_what_makes_for_an_elite_data/", "subreddit_subscribers": 150663, "created_utc": 1704469824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a developer for over a decade, but I'm new to Data Engineering. I set up a couple Iceberg tables in AWS Glue and S3. I've been replicating my production data to these tables for a couple of weeks (\\~100k-300k inserts per day) and saw that our S3 storage size was exploding. After a little analysis, 99% of this storage was metadata. In the worst case, one table had only 13GB of actual data and 66TB of metadata (I emptied that bucket pretty quickly). Several other buckets had 200 MB to 2GB of data and still had 5TB to 7TB of metadata.\n\nIs it normal for Iceberg to accumulate metadata so quickly? or is this just a factor of having so many inserts on a daily basis?\n\nI tried running the \"OPTIMIZE table\" query in Athena, which I got from the Athena documentation, but it only scans about 2GB and takes 30 mins per run, which is way too slow to do by hand on 5TB. After a couple days of Googling and reading the docs, I still don't feel like I'm getting anywhere. How does anybody manage this stuff? Seriously, any feedback, suggestions or links are appreciated.\n\nThanks!\n\n[Let's play \\\\\"Can you spot the Iceberg tables?\\\\\"](https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;format=png&amp;auto=webp&amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d)", "author_fullname": "t2_7bbdmrz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I manage Apache Iceberg metadata that grows exponentially in AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lcr99hk47kac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a1b7837f4fae1d7f68bbd90490b37a5f695c129"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d755a7f89ba18938b987d2b85ad07e8adcb077c6"}, {"y": 151, "x": 320, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e5303a9111265a2930a5a8d2e3056a665ed1588"}, {"y": 303, "x": 640, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8365e957704b3c8373b620e68dfa86a2432f846d"}, {"y": 455, "x": 960, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6c1a004e28ff5956dfcfed4060e280da34aa953"}, {"y": 512, "x": 1080, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c4617c6b32921be277786e1d1d76526717fcdcf"}], "s": {"y": 671, "x": 1413, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;format=png&amp;auto=webp&amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d"}, "id": "lcr99hk47kac1"}}, "name": "t3_18yzbp8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oVWz_Ai75gN3qXlNd_kDLeVGJGlYy6b1KcV2YtcfCMA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704433321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a developer for over a decade, but I&amp;#39;m new to Data Engineering. I set up a couple Iceberg tables in AWS Glue and S3. I&amp;#39;ve been replicating my production data to these tables for a couple of weeks (~100k-300k inserts per day) and saw that our S3 storage size was exploding. After a little analysis, 99% of this storage was metadata. In the worst case, one table had only 13GB of actual data and 66TB of metadata (I emptied that bucket pretty quickly). Several other buckets had 200 MB to 2GB of data and still had 5TB to 7TB of metadata.&lt;/p&gt;\n\n&lt;p&gt;Is it normal for Iceberg to accumulate metadata so quickly? or is this just a factor of having so many inserts on a daily basis?&lt;/p&gt;\n\n&lt;p&gt;I tried running the &amp;quot;OPTIMIZE table&amp;quot; query in Athena, which I got from the Athena documentation, but it only scans about 2GB and takes 30 mins per run, which is way too slow to do by hand on 5TB. After a couple days of Googling and reading the docs, I still don&amp;#39;t feel like I&amp;#39;m getting anywhere. How does anybody manage this stuff? Seriously, any feedback, suggestions or links are appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d\"&gt;Let&amp;#39;s play \\&amp;quot;Can you spot the Iceberg tables?\\&amp;quot;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18yzbp8", "is_robot_indexable": true, "report_reasons": null, "author": "EntrepreneurFitz", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yzbp8/how_do_i_manage_apache_iceberg_metadata_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yzbp8/how_do_i_manage_apache_iceberg_metadata_that/", "subreddit_subscribers": 150663, "created_utc": 1704433321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "how did you land your first proper paying data engineering role, i have worked in shadow for 2 senior data engineers in a MNC doing all their work all by myself for 700 USD/month. Despite having skill set and experience ,because i am in a third world country(Nepal) i cannot find a decent data engineering job.\n\nWould you guys care to join in and share your experience and guide DEs like me?", "author_fullname": "t2_b5mm0rim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having a very hard time as a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yy280", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704429276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how did you land your first proper paying data engineering role, i have worked in shadow for 2 senior data engineers in a MNC doing all their work all by myself for 700 USD/month. Despite having skill set and experience ,because i am in a third world country(Nepal) i cannot find a decent data engineering job.&lt;/p&gt;\n\n&lt;p&gt;Would you guys care to join in and share your experience and guide DEs like me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18yy280", "is_robot_indexable": true, "report_reasons": null, "author": "Horror_Comment6061", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yy280/having_a_very_hard_time_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yy280/having_a_very_hard_time_as_a_data_engineer/", "subreddit_subscribers": 150663, "created_utc": 1704429276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will try not to dox myself but the end goal for me is to end up as a Senior DE at a large tech company. At the moment I'm ambivalent on whether this results in Data Platform Engineering or Data Analytics Engineering.\n\nHere is my general framework for studying:\n\n1. LC Easy/Medium (Arrays &amp; Hashing, Two Pointers, Sliding Window, Stack, Binary Search, try to solve in 20-25 minutes with no/minimal help)\n2. SQL Medium/Hard (Try to solve in 3-5 minutes with no/minimal help)\n3. Data Modeling (Identify business needs using Product Sense and create a Star/Snowflake schema from this)\n4. Behavioral (standard STAR answers)\n\nI am decidedly not good at algorithmic questions, which is part of the reason why I transitioned to DE (also I think it's cooler, among other things). Is this a good framework to abide by to target dedicated DE roles at FAANG+ companies (I specifically have Meta and Amazon in mind)? Any comments or insight would be welcomed.", "author_fullname": "t2_o3ojm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for DE Interviews at FAANG+ companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zfz14", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704484799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will try not to dox myself but the end goal for me is to end up as a Senior DE at a large tech company. At the moment I&amp;#39;m ambivalent on whether this results in Data Platform Engineering or Data Analytics Engineering.&lt;/p&gt;\n\n&lt;p&gt;Here is my general framework for studying:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;LC Easy/Medium (Arrays &amp;amp; Hashing, Two Pointers, Sliding Window, Stack, Binary Search, try to solve in 20-25 minutes with no/minimal help)&lt;/li&gt;\n&lt;li&gt;SQL Medium/Hard (Try to solve in 3-5 minutes with no/minimal help)&lt;/li&gt;\n&lt;li&gt;Data Modeling (Identify business needs using Product Sense and create a Star/Snowflake schema from this)&lt;/li&gt;\n&lt;li&gt;Behavioral (standard STAR answers)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am decidedly not good at algorithmic questions, which is part of the reason why I transitioned to DE (also I think it&amp;#39;s cooler, among other things). Is this a good framework to abide by to target dedicated DE roles at FAANG+ companies (I specifically have Meta and Amazon in mind)? Any comments or insight would be welcomed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18zfz14", "is_robot_indexable": true, "report_reasons": null, "author": "KingTyranitar", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zfz14/preparing_for_de_interviews_at_faang_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zfz14/preparing_for_de_interviews_at_faang_companies/", "subreddit_subscribers": 150663, "created_utc": 1704484799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m still relatively new to the field of data engineering, and I\u2019ve noticed some patterns about the kind of work that data engineers handle and who that work benefits.\n  \nI did a data engineering internship this last summer at a midsized fintech company, which was my first time seeing \u201creal\u201d data engineering firsthand. The work itself was pretty interesting and I liked the people I worked with, but came to the conclusion that the only benefit that my work had on the company was getting data into the hands of the reporting team. \n\nI came to this realization because as I was updating my resume with my new internship experience, the only way that I could really quantify my work was essentially \u201csaved time and effort for the reporting team.\u201d I had no clue what my impact was on the business or my work was being used. It was kind of an alarming feeling.\n  \nI think I\u2019d like to ask: is this normal? Is most data engineering work geared toward just being data stewards, and getting the data to other people?\n  \nIs there such thing as a data engineer that works on a \u201ccustomer-facing\u201d product, where I\u2019d be able to tangibly explain how I impacted the product or business?", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there such thing as a \u201cproduct data engineer\u201d who isn\u2019t just a slave to the reporting team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zljvi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704498703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m still relatively new to the field of data engineering, and I\u2019ve noticed some patterns about the kind of work that data engineers handle and who that work benefits.&lt;/p&gt;\n\n&lt;p&gt;I did a data engineering internship this last summer at a midsized fintech company, which was my first time seeing \u201creal\u201d data engineering firsthand. The work itself was pretty interesting and I liked the people I worked with, but came to the conclusion that the only benefit that my work had on the company was getting data into the hands of the reporting team. &lt;/p&gt;\n\n&lt;p&gt;I came to this realization because as I was updating my resume with my new internship experience, the only way that I could really quantify my work was essentially \u201csaved time and effort for the reporting team.\u201d I had no clue what my impact was on the business or my work was being used. It was kind of an alarming feeling.&lt;/p&gt;\n\n&lt;p&gt;I think I\u2019d like to ask: is this normal? Is most data engineering work geared toward just being data stewards, and getting the data to other people?&lt;/p&gt;\n\n&lt;p&gt;Is there such thing as a data engineer that works on a \u201ccustomer-facing\u201d product, where I\u2019d be able to tangibly explain how I impacted the product or business?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18zljvi", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zljvi/is_there_such_thing_as_a_product_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zljvi/is_there_such_thing_as_a_product_data_engineer/", "subreddit_subscribers": 150663, "created_utc": 1704498703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dive into a hands-on data engineering project this weekend! This [GitHub repo](https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_prefect_bigquery) showcases the combined powers of Airbyte, Prefect, and dbt in a practical setting.\n\nIn under an hour, you can establish a complete data stack ready to manage e-commerce sample data. The project uses BigQuery, but you can adapt it to any other data platform with slight modifications. Just follow the instructions in the README.\n\nThis project is designed to be straightforward yet adaptable, perfect for professionals with limited time and those eager to learn.\n\nI look forward to your thoughts and suggestions for improvement!\n\nDisclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help fellow engineers experiment and learn\n\n&amp;#x200B;\n\n[Prefect DAG](https://preview.redd.it/58whu832dnac1.png?width=2388&amp;format=png&amp;auto=webp&amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6)", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrating Airbyte, Prefect &amp; dbt \ud83d\udc47", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": false, "media_metadata": {"58whu832dnac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/58whu832dnac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a58ca984976930763648cc1dfe4e6053c8669025"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/58whu832dnac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b17a25956b24085cf0f1cf2ba3115f314fb2d71e"}, {"y": 84, "x": 320, "u": "https://preview.redd.it/58whu832dnac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d38a2a0ab14b02b2e37948cb481079abf2b0db83"}, {"y": 169, "x": 640, "u": "https://preview.redd.it/58whu832dnac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9806e31765fb6a3777d17beac5081bf14c0e0b4d"}, {"y": 254, "x": 960, "u": "https://preview.redd.it/58whu832dnac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2ddacff7f196636cf939fd272cdc4cbac35ec38"}, {"y": 286, "x": 1080, "u": "https://preview.redd.it/58whu832dnac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c20869b901e5f98bc1c9ee68e6801f57416611a3"}], "s": {"y": 634, "x": 2388, "u": "https://preview.redd.it/58whu832dnac1.png?width=2388&amp;format=png&amp;auto=webp&amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6"}, "id": "58whu832dnac1"}}, "name": "t3_18za481", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DNJvLwFdru0gUEopvUO3gjJdp_FFUEhS5uW6kP7_lPE.jpg", "edited": 1704471581.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704470189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dive into a hands-on data engineering project this weekend! This &lt;a href=\"https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_prefect_bigquery\"&gt;GitHub repo&lt;/a&gt; showcases the combined powers of Airbyte, Prefect, and dbt in a practical setting.&lt;/p&gt;\n\n&lt;p&gt;In under an hour, you can establish a complete data stack ready to manage e-commerce sample data. The project uses BigQuery, but you can adapt it to any other data platform with slight modifications. Just follow the instructions in the README.&lt;/p&gt;\n\n&lt;p&gt;This project is designed to be straightforward yet adaptable, perfect for professionals with limited time and those eager to learn.&lt;/p&gt;\n\n&lt;p&gt;I look forward to your thoughts and suggestions for improvement!&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help fellow engineers experiment and learn&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/58whu832dnac1.png?width=2388&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6\"&gt;Prefect DAG&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18za481", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18za481/integrating_airbyte_prefect_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18za481/integrating_airbyte_prefect_dbt/", "subreddit_subscribers": 150663, "created_utc": 1704470189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Catch up to speed: Summer of 2023 Friend of mine told me to look into DE work as a career switch since I am already doing excel monkey work as an DA. Next 6 months I teach my self SQL, beginner Python and pass 2 Microsoft azure DE certs.\n\nCurrently applying to DE jobs and most of the jobs I am seeing seem to be like from consulting/contracting gigs. Are these legit in terms of job security? \n\nI would be leaving my current industry which is defense (think Lockheed or Boeing)  which I guess felt so \u201csecure\u201d because of all the govt fund we receive.\n\nTLDR: does anybody here work DE for a consulting/contracting gig, how\u2019s the job security? \n\nBonus question : if you don\u2019t work in consulting/contracting, what industry are you in and how\u2019s the job security? Thanks", "author_fullname": "t2_22q9pua0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Security", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zckja", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704476289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Catch up to speed: Summer of 2023 Friend of mine told me to look into DE work as a career switch since I am already doing excel monkey work as an DA. Next 6 months I teach my self SQL, beginner Python and pass 2 Microsoft azure DE certs.&lt;/p&gt;\n\n&lt;p&gt;Currently applying to DE jobs and most of the jobs I am seeing seem to be like from consulting/contracting gigs. Are these legit in terms of job security? &lt;/p&gt;\n\n&lt;p&gt;I would be leaving my current industry which is defense (think Lockheed or Boeing)  which I guess felt so \u201csecure\u201d because of all the govt fund we receive.&lt;/p&gt;\n\n&lt;p&gt;TLDR: does anybody here work DE for a consulting/contracting gig, how\u2019s the job security? &lt;/p&gt;\n\n&lt;p&gt;Bonus question : if you don\u2019t work in consulting/contracting, what industry are you in and how\u2019s the job security? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18zckja", "is_robot_indexable": true, "report_reasons": null, "author": "PoloParachutes", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zckja/job_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zckja/job_security/", "subreddit_subscribers": 150663, "created_utc": 1704476289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Engineers, quite a few years have passed and recently I am in need to use SSIS for a personal project. But when I see all the data engineering software landscape it seems like we're completely in a new era (DBT, Kafka, Databricks, Trino, Presto, Spark etc).\n\n**-Which are the current days use cases and if it has long future'?**  \n**-Is it becoming a classic outdated tool?**  \n**-Which are the tools considered SSIS replacement?**", "author_fullname": "t2_9sk2qr0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Microsoft Integration Services (SSIS) still being used?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zdo9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704483395.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704479003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Engineers, quite a few years have passed and recently I am in need to use SSIS for a personal project. But when I see all the data engineering software landscape it seems like we&amp;#39;re completely in a new era (DBT, Kafka, Databricks, Trino, Presto, Spark etc).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;-Which are the current days use cases and if it has long future&amp;#39;?&lt;/strong&gt;&lt;br/&gt;\n&lt;strong&gt;-Is it becoming a classic outdated tool?&lt;/strong&gt;&lt;br/&gt;\n&lt;strong&gt;-Which are the tools considered SSIS replacement?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18zdo9c", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Flow_465", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zdo9c/is_microsoft_integration_services_ssis_still/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zdo9c/is_microsoft_integration_services_ssis_still/", "subreddit_subscribers": 150663, "created_utc": 1704479003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learning Machine Learning, I\u2019ve always been interested in **PyTorch** and its **Autograd engine** (which creates the backprop automatically).\n\nIn [this project](https://github.com/eduardoleao052/Autograd-from-scratch.git), I tried to **reimplement most of PyTorch** (including the Autograd) from scratch in a **well-documented, unit tested, and interpretable** way. It was really useful for me, and I hope it can help you understand Autograd better as well! \n\nHope you enjoy! \n\nGitHub repository [here](https://github.com/eduardoleao052/Autograd-from-scratch.git)!", "author_fullname": "t2_jxw66snkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made an Educational Autograd from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7b0l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704462565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning Machine Learning, I\u2019ve always been interested in &lt;strong&gt;PyTorch&lt;/strong&gt; and its &lt;strong&gt;Autograd engine&lt;/strong&gt; (which creates the backprop automatically).&lt;/p&gt;\n\n&lt;p&gt;In &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;this project&lt;/a&gt;, I tried to &lt;strong&gt;reimplement most of PyTorch&lt;/strong&gt; (including the Autograd) from scratch in a &lt;strong&gt;well-documented, unit tested, and interpretable&lt;/strong&gt; way. It was really useful for me, and I hope it can help you understand Autograd better as well! &lt;/p&gt;\n\n&lt;p&gt;Hope you enjoy! &lt;/p&gt;\n\n&lt;p&gt;GitHub repository &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;here&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?auto=webp&amp;s=b08e23957e84e2548f84ee1a2e3edd55eddcdbc0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=715035611c8f0749273ffc8fca0f864e07c111dc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=357e021032137fbfd977589f8642a71656f1beeb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fedb49819520758e10657a49e29c3cb01f6bacc6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=55e700e4bd3ad5eccbac38718f8edeee778531c3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=46188ed2d9e02ebb2805572b76d6768aebc9faee", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69357870a81c7ee5e7c70ac602acf833079a1b5a", "width": 1080, "height": 540}], "variants": {}, "id": "vF4SW5Y1xXGDQ_lFUvafehmQT8uNb-Di9I6Ty9lBl5g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18z7b0l", "is_robot_indexable": true, "report_reasons": null, "author": "suspicious_beam", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z7b0l/i_made_an_educational_autograd_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z7b0l/i_made_an_educational_autograd_from_scratch/", "subreddit_subscribers": 150663, "created_utc": 1704462565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nHappy new year! I have a few friends that work at enterprise companies are pretty heavy in AWS and spending quite a lot on EMR. The topic came up on whether they should be switching those workloads from EMR over to Glue. Others have mentioned that they could save a lot of money by moving the workloads from EMR to Databricks. Does anyone have a perspective for companies trying to save money and achieve better performance on whether they should move to Glue or Databricks?\n\nI have started to go down the rabbit hole and have realized it is not as simple as I thought it would be...", "author_fullname": "t2_gm9wx145o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS EMR to AWS Glue or Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ze6v4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704480311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Happy new year! I have a few friends that work at enterprise companies are pretty heavy in AWS and spending quite a lot on EMR. The topic came up on whether they should be switching those workloads from EMR over to Glue. Others have mentioned that they could save a lot of money by moving the workloads from EMR to Databricks. Does anyone have a perspective for companies trying to save money and achieve better performance on whether they should move to Glue or Databricks?&lt;/p&gt;\n\n&lt;p&gt;I have started to go down the rabbit hole and have realized it is not as simple as I thought it would be...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ze6v4", "is_robot_indexable": true, "report_reasons": null, "author": "NYCDataGuy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ze6v4/aws_emr_to_aws_glue_or_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ze6v4/aws_emr_to_aws_glue_or_databricks/", "subreddit_subscribers": 150663, "created_utc": 1704480311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our security team has decreed that production data will no longer be permitted in dev environments (it will still be permitted in all other environments). The analysts on my team are upset because they don\u2019t believe they can create dashboards on the tiny static, synthetic dataset that\u2019s being proposed as a replacement, and given all the time series analysis they do I see their point (hard to compute sales in the last 30 days if your data only has timestamps from 2 years ago).\n\nHow do you handle this at your org? Do analysts build their reports solely against prod? Or have some other strategy?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dev data for reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z8lgr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704466153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our security team has decreed that production data will no longer be permitted in dev environments (it will still be permitted in all other environments). The analysts on my team are upset because they don\u2019t believe they can create dashboards on the tiny static, synthetic dataset that\u2019s being proposed as a replacement, and given all the time series analysis they do I see their point (hard to compute sales in the last 30 days if your data only has timestamps from 2 years ago).&lt;/p&gt;\n\n&lt;p&gt;How do you handle this at your org? Do analysts build their reports solely against prod? Or have some other strategy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z8lgr", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z8lgr/dev_data_for_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z8lgr/dev_data_for_reports/", "subreddit_subscribers": 150663, "created_utc": 1704466153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some serverless SaaS only provides the on demand payment scheme, which says you don\u2019t need to pay a lot of money periodically(usually once a year), just pay as you go. But on the other hand it\u2019s very hard for customers to decide the budget as they have no idea how much they will use.\n\nAFAIK, Snowflake, one of the biggest SaaS company, is a typical vendor who only allows the on demand payment. Some of the companies pay even millions dollars a year for them.\n\nI\u2019m curious about that how does the deal work when the price is likely unpredictable? For small companies they can just use a credit card to pay the bill, but this way won\u2019t work in a big company.", "author_fullname": "t2_43b95fn1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does the pay-as-you-go service work in the 2B market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zic2s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704490623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some serverless SaaS only provides the on demand payment scheme, which says you don\u2019t need to pay a lot of money periodically(usually once a year), just pay as you go. But on the other hand it\u2019s very hard for customers to decide the budget as they have no idea how much they will use.&lt;/p&gt;\n\n&lt;p&gt;AFAIK, Snowflake, one of the biggest SaaS company, is a typical vendor who only allows the on demand payment. Some of the companies pay even millions dollars a year for them.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious about that how does the deal work when the price is likely unpredictable? For small companies they can just use a credit card to pay the bill, but this way won\u2019t work in a big company.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18zic2s", "is_robot_indexable": true, "report_reasons": null, "author": "leiysky123", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zic2s/how_does_the_payasyougo_service_work_in_the_2b/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zic2s/how_does_the_payasyougo_service_work_in_the_2b/", "subreddit_subscribers": 150663, "created_utc": 1704490623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, came across this joins cheat sheet, and it seems to me like 'album' table is not referenced in this query so how could album title be in the result. Am I missing something?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wxtn8alvglac1.png?width=645&amp;format=png&amp;auto=webp&amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7\n\nhttps://preview.redd.it/oizzzwvuglac1.png?width=642&amp;format=png&amp;auto=webp&amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce", "author_fullname": "t2_qjx23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this SQL joins cheat sheet correct?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 43, "top_awarded_type": null, "hide_score": false, "media_metadata": {"oizzzwvuglac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=51d1bd7d2631aec22f118fc71e3fa9dc86ee5ad6"}, {"y": 69, "x": 216, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1268595805b32f89a98298a501457c5260fca98a"}, {"y": 103, "x": 320, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d22d01d2e9e8670796742b79d6ae197530814147"}, {"y": 207, "x": 640, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=56810c60188611bd327ab53759ac4edde0b00f39"}], "s": {"y": 208, "x": 642, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;format=png&amp;auto=webp&amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce"}, "id": "oizzzwvuglac1"}, "wxtn8alvglac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a00ab3eb11e56cabd2cccb2985d55c927ec8860d"}, {"y": 66, "x": 216, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f57f1e320ecf1e44ab102b255c45631c3342448b"}, {"y": 99, "x": 320, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d3ee7366e5fa5326962047deaa34ea5bf73d5e5e"}, {"y": 198, "x": 640, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7667f729196b6254e650f8d4268ca8e40044721b"}], "s": {"y": 200, "x": 645, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;format=png&amp;auto=webp&amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7"}, "id": "wxtn8alvglac1"}}, "name": "t3_18z3cl6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LrJgaKYu7kxOoyduyOuCvjVsernzGHh_eIkdkPfZ9CM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704448649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, came across this joins cheat sheet, and it seems to me like &amp;#39;album&amp;#39; table is not referenced in this query so how could album title be in the result. Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7\"&gt;https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce\"&gt;https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18z3cl6", "is_robot_indexable": true, "report_reasons": null, "author": "In_Dust_We_Trust", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18z3cl6/is_this_sql_joins_cheat_sheet_correct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z3cl6/is_this_sql_joins_cheat_sheet_correct/", "subreddit_subscribers": 150663, "created_utc": 1704448649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi community,\n\n**Context**: In my current company, we have a data-pipeline (one of the biggest pipelines), which in short works like this: \n\n* We get raw json events from Kafka dumped in s3. \n* We run a batch job (Airflow) daily, this job picks up the raw jsons in s3, enforces a data parser logic.\n* Data parser logic is simply, a service written in python where we explicitly define what attributes we want from raw json, these attributes are accordingly picked up from the json. There could be nested attributes as well which is taken care of.\n* Post this parsing, the final filtered json is loaded in a dataframe where later this parsed data is converted to CSV/parquet formats and dumped in s3 in another folder.\n* Later this processed CSV is loaded into tables, which is used for analytics, ml models, etc.\n\n**Problem**: \n\n* Today for every new event we generate and get from Kafka-S3 (raw event), we have to write a parser logic from scratch, if the event structure is different. In case of small changes in event we can update attributes we want to parse in code itself. \n* Post that we have to deploy the service changes (regardless of changes in a json event parser is small or big) which again takes time. \n* If there is someone from a different team publishing the event into Kafka and writes parser logic, he has to learn through our codebase, understand how to write a parser which is can be a time-taking learning curve.  \n\n**Solution** (I can think of):\n\n* Can we have a UI interface, where we abstract all this code (thereby making it language agnostic), and the engineer simply has to select the attributes from json (that could include nested attributes), and post selecting it, the batch job gets that information, applies the parser logic selected from UI and then runs rest of the pipeline as it is. \n* This could help us in avoiding tons of code for parsers, avoid or minimize deployments in for smaller changes, and as our data size grows I think it would be better to abstract things make it language agnostic and streamline stuff. There could be other benefits as well I suppose. \n\n**Other thoughts**: \n\n* Is there a smart way of doing it? \n* Do we have any open source alternatives here? \n* Or any good engineering blogs which has covered such/similar scenario?\n* How do big companies handle the humongous volume of data and parse relevant stuff into their tables or datalake, etc? \n\n&amp;#x200B;", "author_fullname": "t2_nbm4prsxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Big Data] How does data parsing happen in your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z0vko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704438742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;: In my current company, we have a data-pipeline (one of the biggest pipelines), which in short works like this: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We get raw json events from Kafka dumped in s3. &lt;/li&gt;\n&lt;li&gt;We run a batch job (Airflow) daily, this job picks up the raw jsons in s3, enforces a data parser logic.&lt;/li&gt;\n&lt;li&gt;Data parser logic is simply, a service written in python where we explicitly define what attributes we want from raw json, these attributes are accordingly picked up from the json. There could be nested attributes as well which is taken care of.&lt;/li&gt;\n&lt;li&gt;Post this parsing, the final filtered json is loaded in a dataframe where later this parsed data is converted to CSV/parquet formats and dumped in s3 in another folder.&lt;/li&gt;\n&lt;li&gt;Later this processed CSV is loaded into tables, which is used for analytics, ml models, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Today for every new event we generate and get from Kafka-S3 (raw event), we have to write a parser logic from scratch, if the event structure is different. In case of small changes in event we can update attributes we want to parse in code itself. &lt;/li&gt;\n&lt;li&gt;Post that we have to deploy the service changes (regardless of changes in a json event parser is small or big) which again takes time. &lt;/li&gt;\n&lt;li&gt;If there is someone from a different team publishing the event into Kafka and writes parser logic, he has to learn through our codebase, understand how to write a parser which is can be a time-taking learning curve.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt; (I can think of):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Can we have a UI interface, where we abstract all this code (thereby making it language agnostic), and the engineer simply has to select the attributes from json (that could include nested attributes), and post selecting it, the batch job gets that information, applies the parser logic selected from UI and then runs rest of the pipeline as it is. &lt;/li&gt;\n&lt;li&gt;This could help us in avoiding tons of code for parsers, avoid or minimize deployments in for smaller changes, and as our data size grows I think it would be better to abstract things make it language agnostic and streamline stuff. There could be other benefits as well I suppose. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Other thoughts&lt;/strong&gt;: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is there a smart way of doing it? &lt;/li&gt;\n&lt;li&gt;Do we have any open source alternatives here? &lt;/li&gt;\n&lt;li&gt;Or any good engineering blogs which has covered such/similar scenario?&lt;/li&gt;\n&lt;li&gt;How do big companies handle the humongous volume of data and parse relevant stuff into their tables or datalake, etc? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z0vko", "is_robot_indexable": true, "report_reasons": null, "author": "jarusv7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z0vko/big_data_how_does_data_parsing_happen_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z0vko/big_data_how_does_data_parsing_happen_in_your/", "subreddit_subscribers": 150663, "created_utc": 1704438742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I've got this personal finance webscraper project I'm building and I'd like to take it severless so it just goes without worry. My current issue is trying to get selenium to run on aws lambda and I see a number of approaches online, but not sure what's the best approach to take. Can I just upload the library with the rest of my code? Should I be doing this on Docker?\n\nThanks!", "author_fullname": "t2_3k4h7uai", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running selenium on aws lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zfat6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704483114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;ve got this personal finance webscraper project I&amp;#39;m building and I&amp;#39;d like to take it severless so it just goes without worry. My current issue is trying to get selenium to run on aws lambda and I see a number of approaches online, but not sure what&amp;#39;s the best approach to take. Can I just upload the library with the rest of my code? Should I be doing this on Docker?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18zfat6", "is_robot_indexable": true, "report_reasons": null, "author": "peepoo123", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zfat6/running_selenium_on_aws_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zfat6/running_selenium_on_aws_lambda/", "subreddit_subscribers": 150663, "created_utc": 1704483114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im pretty close to reaching my 2 year anniversary at my current role at a company that is all in on GCP. It has been super challenging and rewarding experience and I have a grown a ton as an engineer because I got exposed to a tech stack that gives you the nuts and bolts to build everything from the ground up.\n\nHowever for reasons that I will not get into, Im looking to make a move to a different role. One of the interviews I got lined is offering a lot more money but they are an Azure + Databricks shop. This makes me a bit concerned because I feel like career progression will not be as \u201chigh\u201d. Its worth mentioning that this was the impression I got because before the current role Im in, I used to be in a Databricks/Azure place where I felt everything was way more managed and handled for me.\n\nSo I want to know what you guys think? Is this me just being biased or is there some truth to it?\n\nBtw I have total 5 years in all my career.", "author_fullname": "t2_13uziq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP vs Azure/Databricks career progression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zn9e7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704506343.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704503166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im pretty close to reaching my 2 year anniversary at my current role at a company that is all in on GCP. It has been super challenging and rewarding experience and I have a grown a ton as an engineer because I got exposed to a tech stack that gives you the nuts and bolts to build everything from the ground up.&lt;/p&gt;\n\n&lt;p&gt;However for reasons that I will not get into, Im looking to make a move to a different role. One of the interviews I got lined is offering a lot more money but they are an Azure + Databricks shop. This makes me a bit concerned because I feel like career progression will not be as \u201chigh\u201d. Its worth mentioning that this was the impression I got because before the current role Im in, I used to be in a Databricks/Azure place where I felt everything was way more managed and handled for me.&lt;/p&gt;\n\n&lt;p&gt;So I want to know what you guys think? Is this me just being biased or is there some truth to it?&lt;/p&gt;\n\n&lt;p&gt;Btw I have total 5 years in all my career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18zn9e7", "is_robot_indexable": true, "report_reasons": null, "author": "fapb88ve", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zn9e7/gcp_vs_azuredatabricks_career_progression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zn9e7/gcp_vs_azuredatabricks_career_progression/", "subreddit_subscribers": 150663, "created_utc": 1704503166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has started to do a cloud migration from GCP -&gt; AWS and the data engineering team I'm part of has been very slow to move over because we'll need to refactor all of our ~50,000 lines of BigQuery specific SQL to Redshift.\n\nWe went all-in on complex data types in BQ because it was so easy to work with but Redshift seems to want everything to be normalized by nature of their feature set for complex types being so sparse.\n\nHas anyone done a migration like this before? Is there a better alternative on AWS other than Redshift?", "author_fullname": "t2_4vru7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the closest alternative to BigQuery on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zmnct", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704501503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has started to do a cloud migration from GCP -&amp;gt; AWS and the data engineering team I&amp;#39;m part of has been very slow to move over because we&amp;#39;ll need to refactor all of our ~50,000 lines of BigQuery specific SQL to Redshift.&lt;/p&gt;\n\n&lt;p&gt;We went all-in on complex data types in BQ because it was so easy to work with but Redshift seems to want everything to be normalized by nature of their feature set for complex types being so sparse.&lt;/p&gt;\n\n&lt;p&gt;Has anyone done a migration like this before? Is there a better alternative on AWS other than Redshift?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18zmnct", "is_robot_indexable": true, "report_reasons": null, "author": "iwipestandin", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zmnct/whats_the_closest_alternative_to_bigquery_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zmnct/whats_the_closest_alternative_to_bigquery_on_aws/", "subreddit_subscribers": 150663, "created_utc": 1704501503.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings Everyone !  \nI am creating a Project Recommendation System using ML which will recommend exciting projects for engineering students. Project Topics will be related to different domains.  \nI am looking for a project dataset containing Title, Description, Keywords etc. dwhich will help me train my model, I am unable to find such dataset on kaggle or dataworld.   \n\n\nIf you guys are aware about any such dataset do let me know .  \nThanks !", "author_fullname": "t2_dp9ta1x4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Topics Dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ze0yd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704479893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings Everyone !&lt;br/&gt;\nI am creating a Project Recommendation System using ML which will recommend exciting projects for engineering students. Project Topics will be related to different domains.&lt;br/&gt;\nI am looking for a project dataset containing Title, Description, Keywords etc. dwhich will help me train my model, I am unable to find such dataset on kaggle or dataworld.   &lt;/p&gt;\n\n&lt;p&gt;If you guys are aware about any such dataset do let me know .&lt;br/&gt;\nThanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ze0yd", "is_robot_indexable": true, "report_reasons": null, "author": "mangoresoham", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ze0yd/project_topics_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ze0yd/project_topics_dataset/", "subreddit_subscribers": 150663, "created_utc": 1704479893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just hoping for some clarity or suggestions so thank you in advance\n\nWe have an existing dev catalog and a test catalog is soon to be created.  The current plan of action it seems is that once the new environment(catalog) is up we will be creating the schemas and tables based on ddl exported from dev, essentially the same method we used to create the schemas and tables manually in dev.  Is there a simpler and/or better method of creating the schemas and tables (with or without data from dev)?", "author_fullname": "t2_8st0puwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks - Best way to create test or prod catalog based on existing dev catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zcxm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704477200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just hoping for some clarity or suggestions so thank you in advance&lt;/p&gt;\n\n&lt;p&gt;We have an existing dev catalog and a test catalog is soon to be created.  The current plan of action it seems is that once the new environment(catalog) is up we will be creating the schemas and tables based on ddl exported from dev, essentially the same method we used to create the schemas and tables manually in dev.  Is there a simpler and/or better method of creating the schemas and tables (with or without data from dev)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18zcxm4", "is_robot_indexable": true, "report_reasons": null, "author": "in-Ron-Howards-voice", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zcxm4/databricks_best_way_to_create_test_or_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zcxm4/databricks_best_way_to_create_test_or_prod/", "subreddit_subscribers": 150663, "created_utc": 1704477200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not sure if this is the right group but I am trying to get data from an API JSON to a CSV file hosted online. I would like to CSV file name to be static so I can read it into Excel and have the API automated to run daily. \n\nDoes one know of a site(s) I can look at to achieve this. I have been looking at: Make, retool and nocodb", "author_fullname": "t2_6mt3uar3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "JSON to CSV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zb1nw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704472498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if this is the right group but I am trying to get data from an API JSON to a CSV file hosted online. I would like to CSV file name to be static so I can read it into Excel and have the API automated to run daily. &lt;/p&gt;\n\n&lt;p&gt;Does one know of a site(s) I can look at to achieve this. I have been looking at: Make, retool and nocodb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18zb1nw", "is_robot_indexable": true, "report_reasons": null, "author": "bird_egg0", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zb1nw/json_to_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zb1nw/json_to_csv/", "subreddit_subscribers": 150663, "created_utc": 1704472498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a newer data engineer at a large health tech company and our company's ETL is mainly simple SSIS packages to load raw data, then extensive config tables in SQL containing snippets that are used to generate our transformations and subsequent loads entirely with dynamic SQL. \n\nIs this a design pattern any of you have heard of, or some SQL anti-pattern that went out of control? It seems like it would have been easier to debug if we had just used pandas since it has made working on our ETL pipelines a lot more difficult to get the hang of when Its not always obvious which table relates to which translation, or where validation takes place, but it at least has generally useful errors and a lot of validation behind the scenes.\n\nIs this a red flag or just a standard process I've never heard of?", "author_fullname": "t2_m1g1wym31", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL with extensive dynamic SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18za1m7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704473628.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704470000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a newer data engineer at a large health tech company and our company&amp;#39;s ETL is mainly simple SSIS packages to load raw data, then extensive config tables in SQL containing snippets that are used to generate our transformations and subsequent loads entirely with dynamic SQL. &lt;/p&gt;\n\n&lt;p&gt;Is this a design pattern any of you have heard of, or some SQL anti-pattern that went out of control? It seems like it would have been easier to debug if we had just used pandas since it has made working on our ETL pipelines a lot more difficult to get the hang of when Its not always obvious which table relates to which translation, or where validation takes place, but it at least has generally useful errors and a lot of validation behind the scenes.&lt;/p&gt;\n\n&lt;p&gt;Is this a red flag or just a standard process I&amp;#39;ve never heard of?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18za1m7", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Egg-561", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18za1m7/etl_with_extensive_dynamic_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18za1m7/etl_with_extensive_dynamic_sql/", "subreddit_subscribers": 150663, "created_utc": 1704470000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nCurious if this golden goose might exist. Are there any open source apps that I can just spin up as a docker service, that offer a frontend for login and user account management in Postgres? Maybe with an `admin` page just for manually managing accounts, though ideally it should be able to manage accounts in an automated fashion.\n\nI would want a reverse proxy to send new sessions to this for login, and upon successful login redirect the user to the desired service (based on url).\n\nI guess it can work by sending any request without a valid session cookie to the authentication service. The user performs login and gets a session cookie. The reverse proxy then sends them to their desired application. Invite only, no sign up.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any quick and easy dockerized authentication apps that I can run with an app and reverse proxy, preferably persisting user accounts in Postgres?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z9fbb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704468666.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704468376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Curious if this golden goose might exist. Are there any open source apps that I can just spin up as a docker service, that offer a frontend for login and user account management in Postgres? Maybe with an &lt;code&gt;admin&lt;/code&gt; page just for manually managing accounts, though ideally it should be able to manage accounts in an automated fashion.&lt;/p&gt;\n\n&lt;p&gt;I would want a reverse proxy to send new sessions to this for login, and upon successful login redirect the user to the desired service (based on url).&lt;/p&gt;\n\n&lt;p&gt;I guess it can work by sending any request without a valid session cookie to the authentication service. The user performs login and gets a session cookie. The reverse proxy then sends them to their desired application. Invite only, no sign up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z9fbb", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z9fbb/are_there_any_quick_and_easy_dockerized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z9fbb/are_there_any_quick_and_easy_dockerized/", "subreddit_subscribers": 150663, "created_utc": 1704468376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a QE - ETL Lead with over a decade experience having strong knowledge in SQL,  good knowledge on Python, ETL &amp; DW concepts, Data modelling. \n\nPlanning to switch into DE. Only reason for this switch is the routine tasks, which is not challenging in my current role. I\u2019m more inclined towards technical side of things.\n\nWant to understand the challenges switching my career option. I\u2019m a quick learner, how much time would it normally take to be data engineer. \n\nThank you", "author_fullname": "t2_numf636zk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions from QE to DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ywtl4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704425446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a QE - ETL Lead with over a decade experience having strong knowledge in SQL,  good knowledge on Python, ETL &amp;amp; DW concepts, Data modelling. &lt;/p&gt;\n\n&lt;p&gt;Planning to switch into DE. Only reason for this switch is the routine tasks, which is not challenging in my current role. I\u2019m more inclined towards technical side of things.&lt;/p&gt;\n\n&lt;p&gt;Want to understand the challenges switching my career option. I\u2019m a quick learner, how much time would it normally take to be data engineer. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18ywtl4", "is_robot_indexable": true, "report_reasons": null, "author": "FaithlessnessDry4116", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ywtl4/suggestions_from_qe_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ywtl4/suggestions_from_qe_to_de/", "subreddit_subscribers": 150663, "created_utc": 1704425446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How many people are unit testing their DBT macros. If you are what mechanism are you using?", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT - Unit Test Macros", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zl897", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704497916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many people are unit testing their DBT macros. If you are what mechanism are you using?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18zl897", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zl897/dbt_unit_test_macros/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zl897/dbt_unit_test_macros/", "subreddit_subscribers": 150663, "created_utc": 1704497916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone\nCan you folks share how much does FAANG companies pay to data engineers .\nI have heard that they pay lower salaries compared to the SDEs\nWould like to know about Meta, Microsoft, Netflix, Apple and Google other similar companies", "author_fullname": "t2_6fjkaogg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FAANG - Data engineer salaries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zf1fh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704482453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone\nCan you folks share how much does FAANG companies pay to data engineers .\nI have heard that they pay lower salaries compared to the SDEs\nWould like to know about Meta, Microsoft, Netflix, Apple and Google other similar companies&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18zf1fh", "is_robot_indexable": true, "report_reasons": null, "author": "UnbiasedGuy_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zf1fh/faang_data_engineer_salaries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zf1fh/faang_data_engineer_salaries/", "subreddit_subscribers": 150663, "created_utc": 1704482453.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}