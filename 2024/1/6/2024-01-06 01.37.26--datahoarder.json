{"kind": "Listing", "data": {"after": "t3_18zash0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Got em in a few days ago, I had a drive start failing in my raid (RAID6) so it was limping for like a week while I waited for these spinners to arrive. Some company was liquidating so I nabbed em up for 14$ a piece. Now I have basically unlimited spares. \n\n(Yes I know raid is not a backup. But I live in bumfuck internet land so my only option is to keep a stockpile of drives and pray to the RAID 6  gods)", "author_fullname": "t2_bzftzisl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Didn't know this sub was a thing but I'll start off with this", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xz1vqfsl8kac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/xz1vqfsl8kac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=59dc416180ffe8d927f83ae37229bd2045af86fa"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/xz1vqfsl8kac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0323f27be9347e0f3fd422312fb2c5c21c35e907"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/xz1vqfsl8kac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=47e5790c2a9bd7c274d8f5514817480c4e8b937d"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/xz1vqfsl8kac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=63045019fafee3019f38b7d60ffa29113b7e31f4"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/xz1vqfsl8kac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ff813d5e7db9fb056508178cb22dd88f39766387"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/xz1vqfsl8kac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=718092edb9391a87db45247b73c74af23e0c7003"}], "s": {"y": 5152, "x": 3864, "u": "https://preview.redd.it/xz1vqfsl8kac1.jpg?width=3864&amp;format=pjpg&amp;auto=webp&amp;s=95d9501e717256facb45375ddfefaeb4724594a1"}, "id": "xz1vqfsl8kac1"}, "uyj0ywol8kac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/uyj0ywol8kac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=368f611de3e3c6d17d6b5fd8d2c97f76692021f1"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/uyj0ywol8kac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f01751b1e92dafcee29f7ebbc4ecc6ebf56a810c"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/uyj0ywol8kac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=56e3f116a828251c9c1ad6e8eb3b0e833c056a76"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/uyj0ywol8kac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=28091dff594f0ac5ae68bc8befe4f6498e43ab5b"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/uyj0ywol8kac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=92bc5983b2e5796024f5ae1d5137f0f8565b8caf"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/uyj0ywol8kac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=892da8988ad38bcb874960ccb7d29618684ce67b"}], "s": {"y": 5152, "x": 3864, "u": "https://preview.redd.it/uyj0ywol8kac1.jpg?width=3864&amp;format=pjpg&amp;auto=webp&amp;s=5e1cf861c2de08c230eae696f7a7b3a1d78a25a2"}, "id": "uyj0ywol8kac1"}, "vd99zkjl8kac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/vd99zkjl8kac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f13b1c7d381bee7298af72e00b248d1de6b5db57"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/vd99zkjl8kac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=12a43748a81d57440b5ce7872c337477b10e628b"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/vd99zkjl8kac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=437102ec0d9c20bd2d5f6672ca8d8ca1eff1cf63"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/vd99zkjl8kac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a2b2676783ff8ad9a6d0bb5cdb344216348ec72f"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/vd99zkjl8kac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ac728c5266248e16049e05f87ce7b46062179d60"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/vd99zkjl8kac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5954cb512ec420e51d7c893bd9dd73888f1cd3fa"}], "s": {"y": 5152, "x": 3864, "u": "https://preview.redd.it/vd99zkjl8kac1.jpg?width=3864&amp;format=pjpg&amp;auto=webp&amp;s=687f8233f6fbe1a29b1bdbd72a79c53ea471c4ac"}, "id": "vd99zkjl8kac1"}}, "name": "t3_18yzgai", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 130, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "vd99zkjl8kac1", "id": 384365829}, {"media_id": "uyj0ywol8kac1", "id": 384365830}, {"media_id": "xz1vqfsl8kac1", "id": 384365831}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 130, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z9aUSRBGwAzbwryh3dVV7dfVb08Ifo0E9kcecu2wC4M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704433744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got em in a few days ago, I had a drive start failing in my raid (RAID6) so it was limping for like a week while I waited for these spinners to arrive. Some company was liquidating so I nabbed em up for 14$ a piece. Now I have basically unlimited spares. &lt;/p&gt;\n\n&lt;p&gt;(Yes I know raid is not a backup. But I live in bumfuck internet land so my only option is to keep a stockpile of drives and pray to the RAID 6  gods)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18yzgai", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yzgai", "is_robot_indexable": true, "report_reasons": null, "author": "CreepyWriter2501", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yzgai/didnt_know_this_sub_was_a_thing_but_ill_start_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18yzgai", "subreddit_subscribers": 723228, "created_utc": 1704433744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_evbrqzkf4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uninstalling some drives to determine where a major problem has just arisen. Wish me luck.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_18yxrmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lQZPos6XmPWeUzs-0RULnDWFV4IUxAQRJ0khogh2yLU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704428344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tk3beetjsjac1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tk3beetjsjac1.jpeg?auto=webp&amp;s=403d5db70467f5ae63dd36f50c8ba2e1118f80f2", "width": 1600, "height": 925}, "resolutions": [{"url": "https://preview.redd.it/tk3beetjsjac1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0a68cab623603f993a42c763b69e176ef1bdd68", "width": 108, "height": 62}, {"url": "https://preview.redd.it/tk3beetjsjac1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=22968342e05b0676be72c8e1e82723b89e20dde5", "width": 216, "height": 124}, {"url": "https://preview.redd.it/tk3beetjsjac1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c55d5accd90daed6c329c0b225909400f25d7a5", "width": 320, "height": 185}, {"url": "https://preview.redd.it/tk3beetjsjac1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dd2be1d9cd7c99a3f3d95e39b9115e229b436462", "width": 640, "height": 370}, {"url": "https://preview.redd.it/tk3beetjsjac1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3d764dbbc9ba1d9972893fb82b2f14f07ba1958a", "width": 960, "height": 555}, {"url": "https://preview.redd.it/tk3beetjsjac1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4de99b2482676aac50b688658f5811e9c7a1b22d", "width": 1080, "height": 624}], "variants": {}, "id": "wF-Ji59yw-vjeS8eLikBjoVsHurUEZwO1vsNnz9Dqr8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yxrmc", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial__Unit", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yxrmc/uninstalling_some_drives_to_determine_where_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tk3beetjsjac1.jpeg", "subreddit_subscribers": 723228, "created_utc": 1704428344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is the LaCie Big Disk Extreme 2TB, model 301201U\n\nMy dad bought and used a couple of these, and I'm trying to gauge between scrapping this or whether it's worth the effort to sell or offer up (without the HDDs, since wiping them is definitely not worth my time). \n\nWith only Firewire and USB 2.0 interfaces, the enclosure would have limited appeal, but these were designed with onboard RAID0 to turn the two 1 TB drives into a \"single\" 2 TB drive. \n\nThe circuit boards of these circa 2009 enclosures sometimes failed, so perhaps there's a market for people who need to access the (striped) data from a failed unit? \n\nDoes anybody have a suggestion for which way I should proceed?", "author_fullname": "t2_suissw8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LaCie external, worth the effort?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 107, "top_awarded_type": null, "hide_score": false, "name": "t3_18zhw9n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/l0kklg28J6OWMZVgrtDbPd8uToT3m8eTY9YQOg0cuD0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704489518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is the LaCie Big Disk Extreme 2TB, model 301201U&lt;/p&gt;\n\n&lt;p&gt;My dad bought and used a couple of these, and I&amp;#39;m trying to gauge between scrapping this or whether it&amp;#39;s worth the effort to sell or offer up (without the HDDs, since wiping them is definitely not worth my time). &lt;/p&gt;\n\n&lt;p&gt;With only Firewire and USB 2.0 interfaces, the enclosure would have limited appeal, but these were designed with onboard RAID0 to turn the two 1 TB drives into a &amp;quot;single&amp;quot; 2 TB drive. &lt;/p&gt;\n\n&lt;p&gt;The circuit boards of these circa 2009 enclosures sometimes failed, so perhaps there&amp;#39;s a market for people who need to access the (striped) data from a failed unit? &lt;/p&gt;\n\n&lt;p&gt;Does anybody have a suggestion for which way I should proceed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/lca9a98guoac1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/lca9a98guoac1.jpeg?auto=webp&amp;s=6e1821846edddd0f7f6d729a09e561e3a0e2b213", "width": 3744, "height": 2877}, "resolutions": [{"url": "https://preview.redd.it/lca9a98guoac1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2458c22394da4449e1f3148b681806fadbbda979", "width": 108, "height": 82}, {"url": "https://preview.redd.it/lca9a98guoac1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=de0af23c6e56717010f7af3442bb5a05d79721bc", "width": 216, "height": 165}, {"url": "https://preview.redd.it/lca9a98guoac1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=432b5a9c9a6284e30fdc0f055455c4ef2292a75c", "width": 320, "height": 245}, {"url": "https://preview.redd.it/lca9a98guoac1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a412023ac7f4ce1b8968ca3e68fa928b53216bc6", "width": 640, "height": 491}, {"url": "https://preview.redd.it/lca9a98guoac1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad74f28da7a794934652eb8e658141176a48d459", "width": 960, "height": 737}, {"url": "https://preview.redd.it/lca9a98guoac1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c874771e20f6196896a3b23644231a36c1105c40", "width": 1080, "height": 829}], "variants": {}, "id": "iNXG2cDdjc4EKval2WAMAGBbuoKohqignNlGRBtU72I"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zhw9n", "is_robot_indexable": true, "report_reasons": null, "author": "Redditations2u", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zhw9n/lacie_external_worth_the_effort/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/lca9a98guoac1.jpeg", "subreddit_subscribers": 723228, "created_utc": 1704489518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just copied a DVD called powder and the length of the movie is 01:51:44 and the file size is 3.51 GB and the file type is MKV. I would like to know if there is a easy way to make this smaller at all without losing to much of the quality or any of the quality at all. \n\n&amp;#x200B;\n\nI have makeMKV I just downloaded it this evening. I also have \"Handbrake\" which I have only ever used to add subtitles to movies or TV Show episodes. \n\n&amp;#x200B;\n\nI would like to know if there are any tips or guides or tutorials that can help me find the best settings for each thing I want to do.\n\n&amp;#x200B;\n\n(1) I want to back up all of my DVDs\n\n(2) Some of my DVDs are just movies \n\n(3) I want to be able to back up as many DVDs as possible without losing much \"Quality\" but in smaller sizes if possible\n\n&amp;#x200B;\n\n\"Powder\" had options like \"Subtitles\" which I didn't need so I unchecked them on \"Makemkv\" I thought that would help save me some room with file size and would make it so I didn't have burned in subtitles. Plus there was also a option for \"French Language\" which I also didn't need. So I also unchecked that option. So the only thing I left checked was \"The movie and the audio for 5.1\" I think I just re-looked at the stuff I left checked and it was \"Title 17 chapter(s). 3.7 GB (angle 1) Video Mpeg2 Audio DD Surround 5.1 English I unchecked Audio DD Stereo French, Subtitle English, Subtitle CC&gt;Text English Lossy conversion).\n\n&amp;#x200B;\n\nNow what I want to be able to do is make the file size smaller without losing to much quality. And then I will rename the file and go from there. I will not be re-burning these to DVD I will keep them on my Hard Drive to watch from my media PC. So file type I would like to make the best file type for watching on PC. And I do use vlc media player so file type should not be a issue. \n\n&amp;#x200B;\n\nSo here is what I need help with:\n\nShould I use handbrake to make these files smaller and if so how\n\nWhat file type should I make these videos once I do make them smaller\n\nWhat is the best free software to use and how should I use them for the best quality and the smallest file size\n\n&amp;#x200B;\n\nI'm still new to copying my DVDs so all I know about is makemkv and handbrake. So any advice would be greatly appreciated.\n\n&amp;#x200B;\n\nPlus I do understand by making a file to small you lose quality. But even if I can take the file down to 2GB or something its still making it smaller. I don't need to make it super small like 1mb I would just like to save a bit of space for more DVDs if possible. So any tips would be great thank you. \n\n&amp;#x200B;", "author_fullname": "t2_8gvbu38t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just used MakeMKV to backup a DVD now what do I do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yu0ws", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704417538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just copied a DVD called powder and the length of the movie is 01:51:44 and the file size is 3.51 GB and the file type is MKV. I would like to know if there is a easy way to make this smaller at all without losing to much of the quality or any of the quality at all. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have makeMKV I just downloaded it this evening. I also have &amp;quot;Handbrake&amp;quot; which I have only ever used to add subtitles to movies or TV Show episodes. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would like to know if there are any tips or guides or tutorials that can help me find the best settings for each thing I want to do.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(1) I want to back up all of my DVDs&lt;/p&gt;\n\n&lt;p&gt;(2) Some of my DVDs are just movies &lt;/p&gt;\n\n&lt;p&gt;(3) I want to be able to back up as many DVDs as possible without losing much &amp;quot;Quality&amp;quot; but in smaller sizes if possible&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Powder&amp;quot; had options like &amp;quot;Subtitles&amp;quot; which I didn&amp;#39;t need so I unchecked them on &amp;quot;Makemkv&amp;quot; I thought that would help save me some room with file size and would make it so I didn&amp;#39;t have burned in subtitles. Plus there was also a option for &amp;quot;French Language&amp;quot; which I also didn&amp;#39;t need. So I also unchecked that option. So the only thing I left checked was &amp;quot;The movie and the audio for 5.1&amp;quot; I think I just re-looked at the stuff I left checked and it was &amp;quot;Title 17 chapter(s). 3.7 GB (angle 1) Video Mpeg2 Audio DD Surround 5.1 English I unchecked Audio DD Stereo French, Subtitle English, Subtitle CC&amp;gt;Text English Lossy conversion).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now what I want to be able to do is make the file size smaller without losing to much quality. And then I will rename the file and go from there. I will not be re-burning these to DVD I will keep them on my Hard Drive to watch from my media PC. So file type I would like to make the best file type for watching on PC. And I do use vlc media player so file type should not be a issue. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So here is what I need help with:&lt;/p&gt;\n\n&lt;p&gt;Should I use handbrake to make these files smaller and if so how&lt;/p&gt;\n\n&lt;p&gt;What file type should I make these videos once I do make them smaller&lt;/p&gt;\n\n&lt;p&gt;What is the best free software to use and how should I use them for the best quality and the smallest file size&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m still new to copying my DVDs so all I know about is makemkv and handbrake. So any advice would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Plus I do understand by making a file to small you lose quality. But even if I can take the file down to 2GB or something its still making it smaller. I don&amp;#39;t need to make it super small like 1mb I would just like to save a bit of space for more DVDs if possible. So any tips would be great thank you. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yu0ws", "is_robot_indexable": true, "report_reasons": null, "author": "DawnRenee1988", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yu0ws/i_just_used_makemkv_to_backup_a_dvd_now_what_do_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yu0ws/i_just_used_makemkv_to_backup_a_dvd_now_what_do_i/", "subreddit_subscribers": 723228, "created_utc": 1704417538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Do you guys run disk check utilities after buying a new drive? Or do you just use it out of the box?\n\n&amp;#x200B;\n\nI've read bad sectors can exist even on new drives: [https://datarecovery.com/rd/what-are-bad-sectors/](https://datarecovery.com/rd/what-are-bad-sectors/)\n\n\"even if you buy a brand-new hard drive, it will probably have a few unusable sectors ... If your hard drive has a small number of bad sectors, error checking utilities may improve performance \u2014 but they won\u2019t restore the missing data.\"\n\nHowever, from what I understand, if there is a physical problem with a sector and the hard drive cannot write to it, it will mark it as a bad sector:\n\n[https://superuser.com/questions/1717234/how-does-a-hard-drive-know-if-its-writing-to-a-bad-sector-that-wasnt-bad-befor](https://superuser.com/questions/1717234/how-does-a-hard-drive-know-if-its-writing-to-a-bad-sector-that-wasnt-bad-befor)\n\n\"A bad block/sector is only detected on a read, and not on a write. The only error when writing would be if the sector/LBA could not be found.\"\n\nSo it seems unnecessary to do chkdsk or full format on a new hard drive as it won't write to a physically defective sector in the first place. I would like to hear your opinions thanks.", "author_fullname": "t2_hxw7xcf2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you run chkdsk or full format on a new hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zel0r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704481302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you guys run disk check utilities after buying a new drive? Or do you just use it out of the box?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read bad sectors can exist even on new drives: &lt;a href=\"https://datarecovery.com/rd/what-are-bad-sectors/\"&gt;https://datarecovery.com/rd/what-are-bad-sectors/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;even if you buy a brand-new hard drive, it will probably have a few unusable sectors ... If your hard drive has a small number of bad sectors, error checking utilities may improve performance \u2014 but they won\u2019t restore the missing data.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;However, from what I understand, if there is a physical problem with a sector and the hard drive cannot write to it, it will mark it as a bad sector:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://superuser.com/questions/1717234/how-does-a-hard-drive-know-if-its-writing-to-a-bad-sector-that-wasnt-bad-befor\"&gt;https://superuser.com/questions/1717234/how-does-a-hard-drive-know-if-its-writing-to-a-bad-sector-that-wasnt-bad-befor&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;A bad block/sector is only detected on a read, and not on a write. The only error when writing would be if the sector/LBA could not be found.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So it seems unnecessary to do chkdsk or full format on a new hard drive as it won&amp;#39;t write to a physically defective sector in the first place. I would like to hear your opinions thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OEbnDi_lG-X1yaZReUG2iCF3Ob3LzYMb4mt_Lf6ptck.jpg?auto=webp&amp;s=6373e812ea9284933040aa852b9affd80656b3df", "width": 521, "height": 545}, "resolutions": [{"url": "https://external-preview.redd.it/OEbnDi_lG-X1yaZReUG2iCF3Ob3LzYMb4mt_Lf6ptck.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b3d9dead6f8e2266fbab0861a49050ab463e0a3", "width": 108, "height": 112}, {"url": "https://external-preview.redd.it/OEbnDi_lG-X1yaZReUG2iCF3Ob3LzYMb4mt_Lf6ptck.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c307b7dcdf87640739f66395409581833dd237fb", "width": 216, "height": 225}, {"url": "https://external-preview.redd.it/OEbnDi_lG-X1yaZReUG2iCF3Ob3LzYMb4mt_Lf6ptck.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e30bf5656c2b5c2b567fb9c28b52be101d16da9", "width": 320, "height": 334}], "variants": {}, "id": "MHl-sQSUwkzS8k-IFPiSvFvCWBgfpn5rk7ka-lvqxAY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zel0r", "is_robot_indexable": true, "report_reasons": null, "author": "Average4B", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zel0r/do_you_run_chkdsk_or_full_format_on_a_new_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zel0r/do_you_run_chkdsk_or_full_format_on_a_new_hard/", "subreddit_subscribers": 723228, "created_utc": 1704481302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure if this is the right sub for this but imma ask anyways. I\u2019m getting a LSI 9207-8i for my server but after I ordered it I realized that all my remaining PCIE slots are all PCIE 1x slots. Will I be able to use the card or should I look into another option?", "author_fullname": "t2_51dfdxum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "8x pcie LSI card in a 1x slot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zi2ya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704489987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if this is the right sub for this but imma ask anyways. I\u2019m getting a LSI 9207-8i for my server but after I ordered it I realized that all my remaining PCIE slots are all PCIE 1x slots. Will I be able to use the card or should I look into another option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zi2ya", "is_robot_indexable": true, "report_reasons": null, "author": "opi098514", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zi2ya/8x_pcie_lsi_card_in_a_1x_slot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zi2ya/8x_pcie_lsi_card_in_a_1x_slot/", "subreddit_subscribers": 723228, "created_utc": 1704489987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI received two drives (Seagate Exos x18 18TB x 2) that were supposed to be brand new.  \n\nI went to Seagate's site to check on their warranty status using drives' serial numbers, WR5015CY &amp; WR5015FG, and got this message:\n\n\\*\\*\u201cThis product was originally sold as part of a larger system. Please contact the system manufacturer or your place of purchase for warranty support.\u201d\\*\\*\n\nI then checked the drives using HWInfo64. Here\u2019s one drives\u2019 read/write info (2nd drive is \\~ the same): \\*\\*Total Host Writes: 717,321 GB, Total Host Reads: 1,077,026 GB \\*\\*\n\nThe company has issued an RMA, but also says that the tech department will examine it, and if no fault is found, they may charge a testing fee (unspecified amount)\n\nI think the info I\u2019ve got on the drives proves that they can\u2019t be anything other than used, but I don\u2019t know that much about hard drives. So:\n\n1. Does what I have 100% prove that they are used drives?\n\n2. Is there some technical wiggle room that might allow them to declare them \u201cnew\u201d.\n\nThanks for any advice you can give", "author_fullname": "t2_ufrz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New or used 18TB hard drives? Info from Seagate's warranty site &amp; HWInfo64", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z5uhm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704457981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I received two drives (Seagate Exos x18 18TB x 2) that were supposed to be brand new.  &lt;/p&gt;\n\n&lt;p&gt;I went to Seagate&amp;#39;s site to check on their warranty status using drives&amp;#39; serial numbers, WR5015CY &amp;amp; WR5015FG, and got this message:&lt;/p&gt;\n\n&lt;p&gt;**\u201cThis product was originally sold as part of a larger system. Please contact the system manufacturer or your place of purchase for warranty support.\u201d**&lt;/p&gt;\n\n&lt;p&gt;I then checked the drives using HWInfo64. Here\u2019s one drives\u2019 read/write info (2nd drive is ~ the same): **Total Host Writes: 717,321 GB, Total Host Reads: 1,077,026 GB **&lt;/p&gt;\n\n&lt;p&gt;The company has issued an RMA, but also says that the tech department will examine it, and if no fault is found, they may charge a testing fee (unspecified amount)&lt;/p&gt;\n\n&lt;p&gt;I think the info I\u2019ve got on the drives proves that they can\u2019t be anything other than used, but I don\u2019t know that much about hard drives. So:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Does what I have 100% prove that they are used drives?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is there some technical wiggle room that might allow them to declare them \u201cnew\u201d.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks for any advice you can give&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18z5uhm", "is_robot_indexable": true, "report_reasons": null, "author": "IncisiveGuess", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18z5uhm/new_or_used_18tb_hard_drives_info_from_seagates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18z5uhm/new_or_used_18tb_hard_drives_info_from_seagates/", "subreddit_subscribers": 723228, "created_utc": 1704457981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I've been trying to download all of the newly-released court documents which contain information about a certain now-deceased evil billionaire and his island, from courtlistener.com.  \n\n\nHowever, when trying to 'wget -r \"https://www.courtlistener.com/docket/4355835/giuffre-v-maxwell\"', it gives me a 403 error; and it does so even when I try to feed it a cookies file.  \n\n\nShould I keep trying to use wget (if so, what other flags should I try). Or, since CourtListener is Open-Source, is there another way to go about downloading things-- I did find a questionably sorted Open Directory.  \n\n\nThanks.  \n\n\n&amp;#x200B;", "author_fullname": "t2_kh76tepm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk-Downloading from CourtListener", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zjqsq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704494171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been trying to download all of the newly-released court documents which contain information about a certain now-deceased evil billionaire and his island, from courtlistener.com.  &lt;/p&gt;\n\n&lt;p&gt;However, when trying to &amp;#39;wget -r &amp;quot;&lt;a href=\"https://www.courtlistener.com/docket/4355835/giuffre-v-maxwell%22\"&gt;https://www.courtlistener.com/docket/4355835/giuffre-v-maxwell&amp;quot;&lt;/a&gt;&amp;#39;, it gives me a 403 error; and it does so even when I try to feed it a cookies file.  &lt;/p&gt;\n\n&lt;p&gt;Should I keep trying to use wget (if so, what other flags should I try). Or, since CourtListener is Open-Source, is there another way to go about downloading things-- I did find a questionably sorted Open Directory.  &lt;/p&gt;\n\n&lt;p&gt;Thanks.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zjqsq", "is_robot_indexable": true, "report_reasons": null, "author": "Bringback-T_D", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zjqsq/bulkdownloading_from_courtlistener/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zjqsq/bulkdownloading_from_courtlistener/", "subreddit_subscribers": 723228, "created_utc": 1704494171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "just a little friendly reminder, Guys, please sort your files! I recently decided to buy a new set of drives, and sort everything, because my previous system consisted of a bunch of drives just plugged into the computer, no raid, no backup and a total mess, I also have about 6 drives full of data that did not fit into my computer anymore, and one of the things I did was that every time I made space somewhere, or sorted my desktop, documents, etc. I always just moved them somewhere in the style of \"Old desktop\", \"dcim1,2,3\". Now I have tons of hard drives full of old desktops and stuff like that, I've been digging in it for about 3 hours now and I'm only about 1/30 of the way through. So guys, sort your files, make backups and if you want to use old drives (I have one from about 2005, on which I still have important data), use them only as a backup, ideally as a second backup.", "author_fullname": "t2_2pt8iy3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keep your data save and Organized", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zdy07", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704479682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;just a little friendly reminder, Guys, please sort your files! I recently decided to buy a new set of drives, and sort everything, because my previous system consisted of a bunch of drives just plugged into the computer, no raid, no backup and a total mess, I also have about 6 drives full of data that did not fit into my computer anymore, and one of the things I did was that every time I made space somewhere, or sorted my desktop, documents, etc. I always just moved them somewhere in the style of &amp;quot;Old desktop&amp;quot;, &amp;quot;dcim1,2,3&amp;quot;. Now I have tons of hard drives full of old desktops and stuff like that, I&amp;#39;ve been digging in it for about 3 hours now and I&amp;#39;m only about 1/30 of the way through. So guys, sort your files, make backups and if you want to use old drives (I have one from about 2005, on which I still have important data), use them only as a backup, ideally as a second backup.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18zdy07", "is_robot_indexable": true, "report_reasons": null, "author": "Bago07", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zdy07/keep_your_data_save_and_organized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zdy07/keep_your_data_save_and_organized/", "subreddit_subscribers": 723228, "created_utc": 1704479682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a windows 10/11 rig in a fractal define XL case that I want to use a storage server for media. I am using windows because I also need to use it with adobe media encoder to process and encode from a watch folder for video editing, among a few other tasks.\n\nThe rig will have a dozen drives in it - mostly Exos 20TB drives. Boot drive is a 1TB SATA SSD.\n\nI\u2019m wondering if there is benefit to have a dedicated 1atB nvme SSD cache drive for accessing HDDs more efficiently. Does windows allow for this?", "author_fullname": "t2_cmfdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows 10/11 as quasi-server: SSD cache drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z0rsp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704438335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a windows 10/11 rig in a fractal define XL case that I want to use a storage server for media. I am using windows because I also need to use it with adobe media encoder to process and encode from a watch folder for video editing, among a few other tasks.&lt;/p&gt;\n\n&lt;p&gt;The rig will have a dozen drives in it - mostly Exos 20TB drives. Boot drive is a 1TB SATA SSD.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering if there is benefit to have a dedicated 1atB nvme SSD cache drive for accessing HDDs more efficiently. Does windows allow for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18z0rsp", "is_robot_indexable": true, "report_reasons": null, "author": "filmguy123", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18z0rsp/windows_1011_as_quasiserver_ssd_cache_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18z0rsp/windows_1011_as_quasiserver_ssd_cache_drive/", "subreddit_subscribers": 723228, "created_utc": 1704438335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All -\n\n I had an older WD Red drive start to report bad blocks.  Moved all the data off the drive without issues. Recommendation was to run a format /p:1 /x.\n\n I understand this is going to be slow. But I'm about 3 hours in and still showing \"0  percent.\"  \n\n Is the drive just dead?  Or should I really expect this to take \\~300 hours?\n\nThank you!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/c78qdn5g0oac1.png?width=711&amp;format=png&amp;auto=webp&amp;s=e400f1e914fb1a4a684fc57bea7166fcacaae6ab", "author_fullname": "t2_6oldcju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long to format a 2TB drive with /p:1", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "media_metadata": {"c78qdn5g0oac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/c78qdn5g0oac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b6907ed2a56182e836514cca667e5885f6bd6953"}, {"y": 116, "x": 216, "u": "https://preview.redd.it/c78qdn5g0oac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6a426918bcabdb1d3a1bf51c035c31b70652fa97"}, {"y": 172, "x": 320, "u": "https://preview.redd.it/c78qdn5g0oac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f880e4519efac608865278c5aae5e1145cb1b664"}, {"y": 345, "x": 640, "u": "https://preview.redd.it/c78qdn5g0oac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8696fab74753cf3dbb59ee8fc5405c32c2b8fc1f"}], "s": {"y": 384, "x": 711, "u": "https://preview.redd.it/c78qdn5g0oac1.png?width=711&amp;format=png&amp;auto=webp&amp;s=e400f1e914fb1a4a684fc57bea7166fcacaae6ab"}, "id": "c78qdn5g0oac1"}}, "name": "t3_18zdun4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RtHWob5i-nDa4oTpEy8QPcR4VN1lxWmqp6-aLgD9ZK4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704479447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All -&lt;/p&gt;\n\n&lt;p&gt;I had an older WD Red drive start to report bad blocks.  Moved all the data off the drive without issues. Recommendation was to run a format /p:1 /x.&lt;/p&gt;\n\n&lt;p&gt;I understand this is going to be slow. But I&amp;#39;m about 3 hours in and still showing &amp;quot;0  percent.&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;Is the drive just dead?  Or should I really expect this to take ~300 hours?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/c78qdn5g0oac1.png?width=711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e400f1e914fb1a4a684fc57bea7166fcacaae6ab\"&gt;https://preview.redd.it/c78qdn5g0oac1.png?width=711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e400f1e914fb1a4a684fc57bea7166fcacaae6ab&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zdun4", "is_robot_indexable": true, "report_reasons": null, "author": "nyc2pit", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zdun4/how_long_to_format_a_2tb_drive_with_p1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zdun4/how_long_to_format_a_2tb_drive_with_p1/", "subreddit_subscribers": 723228, "created_utc": 1704479447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currenty looking at different ways i coud create a backup of my data as day by data its getting bigger and all it will take is one of my drives dying and its gone. I was backing up to Mega.nz but my upload speed is rubbish to upload TB's of data. So i've been looking at Tapes as i've read that they have high capasity and dont have the same risks as HDD/SSD and if kept stored correctly have around 10+ year life span. But looking at LTO tapes theres LTO 9,8,7 etc other than probably the basic speed and storage size is there any difference between the verison.\n\n&amp;#x200B;\n\nAlso if you have any other ideas for back ideas I'd love to hear them. Just in planning stage atm", "author_fullname": "t2_ymrul07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Different LTO tape versions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zcc3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704475709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currenty looking at different ways i coud create a backup of my data as day by data its getting bigger and all it will take is one of my drives dying and its gone. I was backing up to Mega.nz but my upload speed is rubbish to upload TB&amp;#39;s of data. So i&amp;#39;ve been looking at Tapes as i&amp;#39;ve read that they have high capasity and dont have the same risks as HDD/SSD and if kept stored correctly have around 10+ year life span. But looking at LTO tapes theres LTO 9,8,7 etc other than probably the basic speed and storage size is there any difference between the verison.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also if you have any other ideas for back ideas I&amp;#39;d love to hear them. Just in planning stage atm&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "40TB \ud83c\udfe0 8TB \u2601\ufe0f", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zcc3v", "is_robot_indexable": true, "report_reasons": null, "author": "seleneVamp", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18zcc3v/different_lto_tape_versions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zcc3v/different_lto_tape_versions/", "subreddit_subscribers": 723228, "created_utc": 1704475709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have seen some of these questions being answered before but none of them had an answer for what I had in mind. \n\nI have a library of photos that is around 2tb large. In that library are a lot of duplicate photos because we save a variant of each photo in some different sizes (if that makes sense). If I ran a photo duplicate finder program it would show me every single one of these duplicate photos. But I only want to show the photos that are duplicates of one specific photo I have in another folder by itself. \n\nIs there any way to compare my library folder to my other folder with just the photo I want to find duplicates of without showing me every other duplicate that there is in the library folder? ", "author_fullname": "t2_ec3jqgob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Find every duplicate image that matches one specific image", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z763j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704462160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have seen some of these questions being answered before but none of them had an answer for what I had in mind. &lt;/p&gt;\n\n&lt;p&gt;I have a library of photos that is around 2tb large. In that library are a lot of duplicate photos because we save a variant of each photo in some different sizes (if that makes sense). If I ran a photo duplicate finder program it would show me every single one of these duplicate photos. But I only want to show the photos that are duplicates of one specific photo I have in another folder by itself. &lt;/p&gt;\n\n&lt;p&gt;Is there any way to compare my library folder to my other folder with just the photo I want to find duplicates of without showing me every other duplicate that there is in the library folder? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18z763j", "is_robot_indexable": true, "report_reasons": null, "author": "TallDudeV2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18z763j/find_every_duplicate_image_that_matches_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18z763j/find_every_duplicate_image_that_matches_one/", "subreddit_subscribers": 723228, "created_utc": 1704462160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an Asus at the moment that doesn't read discs consistently. It works fine enough but I'm looking to find one, where I can just Chuck in a disc and have it read without having to try multiple times just to get one read.\n\nCan anyone help me find a better option? Speed would probably be a necessity too as I'm archiving heaps of Lostwave/obscure albums. \n\nIf anyone can help that would be great, thank you.", "author_fullname": "t2_3cr4yjtz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best consistent external CD/Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z0r5c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704438266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an Asus at the moment that doesn&amp;#39;t read discs consistently. It works fine enough but I&amp;#39;m looking to find one, where I can just Chuck in a disc and have it read without having to try multiple times just to get one read.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help me find a better option? Speed would probably be a necessity too as I&amp;#39;m archiving heaps of Lostwave/obscure albums. &lt;/p&gt;\n\n&lt;p&gt;If anyone can help that would be great, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18z0r5c", "is_robot_indexable": true, "report_reasons": null, "author": "Dj_acclaim", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18z0r5c/best_consistent_external_cddrive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18z0r5c/best_consistent_external_cddrive/", "subreddit_subscribers": 723228, "created_utc": 1704438266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a friend who permanently rents out of a house that I own who desperately needs a MASSIVE storage solution for terabytes of video editing that they do. We are building this for fun just as much as the need for storage itself, so there isn't really a price ceiling on what we're willing to put into it but under $1,000 would be a good place to start. The storage solution must be on site, so off-site cloud storage services are a 100% no-go. We considered turning an old desktop into a Linux server and frankensteining a bunch of spin discs into it, but before I bite on the purchase we're looking for something with a little more fun or pizzazz. We talked about tape drives which seemed fun to figure out but I don't know where I would get one or even if it would be viable. If a Lennox server ends up being the best option, I'm looking for programs and features to put on to it since I'm kind of new to that field. I have no problem figuring out something new.\n\nFeatures and Requirements:\n\n- Must be on site. I mentioned it already but it is the main concern.\n- 20 terabytes at a bare minimum, but ideally it would have 100 terabytes or more.\n- Data should be shelf stable, that is, I should be able to leave the data storage unpowered for 10-20 years without any appreciable degradation\n- it would be convenient if it was network attached but the ratio of gigabytes per dollar is far more important\n- Space isn't too much of a concern but I would like to not have to give up an entire room for the project\n- It would be fun if I could play around with making it EMP safe, but that would really just be a toy that I don't need.\n- Noise isn't that much of an issue but it would be good if I could stop the sound with a wall and some soundproofing\n\nThank you in advance for all of you who took the time to read and reply, may your computers run smoothly and may your frame rates be high.\n\nEdit: noise limits", "author_fullname": "t2_70b7ow4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Large Data Backup/Storage Recommendations Needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zemxl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704485997.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704481441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a friend who permanently rents out of a house that I own who desperately needs a MASSIVE storage solution for terabytes of video editing that they do. We are building this for fun just as much as the need for storage itself, so there isn&amp;#39;t really a price ceiling on what we&amp;#39;re willing to put into it but under $1,000 would be a good place to start. The storage solution must be on site, so off-site cloud storage services are a 100% no-go. We considered turning an old desktop into a Linux server and frankensteining a bunch of spin discs into it, but before I bite on the purchase we&amp;#39;re looking for something with a little more fun or pizzazz. We talked about tape drives which seemed fun to figure out but I don&amp;#39;t know where I would get one or even if it would be viable. If a Lennox server ends up being the best option, I&amp;#39;m looking for programs and features to put on to it since I&amp;#39;m kind of new to that field. I have no problem figuring out something new.&lt;/p&gt;\n\n&lt;p&gt;Features and Requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Must be on site. I mentioned it already but it is the main concern.&lt;/li&gt;\n&lt;li&gt;20 terabytes at a bare minimum, but ideally it would have 100 terabytes or more.&lt;/li&gt;\n&lt;li&gt;Data should be shelf stable, that is, I should be able to leave the data storage unpowered for 10-20 years without any appreciable degradation&lt;/li&gt;\n&lt;li&gt;it would be convenient if it was network attached but the ratio of gigabytes per dollar is far more important&lt;/li&gt;\n&lt;li&gt;Space isn&amp;#39;t too much of a concern but I would like to not have to give up an entire room for the project&lt;/li&gt;\n&lt;li&gt;It would be fun if I could play around with making it EMP safe, but that would really just be a toy that I don&amp;#39;t need.&lt;/li&gt;\n&lt;li&gt;Noise isn&amp;#39;t that much of an issue but it would be good if I could stop the sound with a wall and some soundproofing&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you in advance for all of you who took the time to read and reply, may your computers run smoothly and may your frame rates be high.&lt;/p&gt;\n\n&lt;p&gt;Edit: noise limits&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zemxl", "is_robot_indexable": true, "report_reasons": null, "author": "Square_Style_2335", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zemxl/large_data_backupstorage_recommendations_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zemxl/large_data_backupstorage_recommendations_needed/", "subreddit_subscribers": 723228, "created_utc": 1704481441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've currently got a media library (the arrs) and all my drives in an UNRAID tower.  I'm going to be changing some things around and this time round, I'm just going to run plain Linux, probably Ubuntu server as that's what I'm familiar with.\n\nWhat RAID configuration would you recommend where I can start with 4 drives and add more as time goes on?  With regard to redundancy, I'm open minded.  This is replaceable data but it'd always be nice to not have to do that.  I'm a bit rusty on my RAID knowledge so I thought I might come here, asking advice on how best to set this machine up.  If I begin with two drives, I guess my only options are keeping full capacity with no drive fault tolerance, or halving my capacity with one drive fault tolerance.  There's got to be a better way to do this.\n\nThoughts?", "author_fullname": "t2_6eiisul2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question regarding Linux RAID", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zcfld", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704475947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve currently got a media library (the arrs) and all my drives in an UNRAID tower.  I&amp;#39;m going to be changing some things around and this time round, I&amp;#39;m just going to run plain Linux, probably Ubuntu server as that&amp;#39;s what I&amp;#39;m familiar with.&lt;/p&gt;\n\n&lt;p&gt;What RAID configuration would you recommend where I can start with 4 drives and add more as time goes on?  With regard to redundancy, I&amp;#39;m open minded.  This is replaceable data but it&amp;#39;d always be nice to not have to do that.  I&amp;#39;m a bit rusty on my RAID knowledge so I thought I might come here, asking advice on how best to set this machine up.  If I begin with two drives, I guess my only options are keeping full capacity with no drive fault tolerance, or halving my capacity with one drive fault tolerance.  There&amp;#39;s got to be a better way to do this.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zcfld", "is_robot_indexable": true, "report_reasons": null, "author": "Pleaseclap4", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zcfld/question_regarding_linux_raid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zcfld/question_regarding_linux_raid/", "subreddit_subscribers": 723228, "created_utc": 1704475947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got quite a few things saved to external drives but I'm looking to throw some M-discs into the mix for long-term cold storage. I'd like to catalog those the way I used to do with my DVDs and WhereIsIt so, for example, I could find the disc with a specific photo fairly easily through doing an EXIF search.\n\nI'd like to have a catalog that's not going to be locked into a proprietary format so I can export and possibly import it into another database program if the need arises.\n\nHow can I future-proof my catalogs? ", "author_fullname": "t2_f9q4jzo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on catalog software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18za6jg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704470351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got quite a few things saved to external drives but I&amp;#39;m looking to throw some M-discs into the mix for long-term cold storage. I&amp;#39;d like to catalog those the way I used to do with my DVDs and WhereIsIt so, for example, I could find the disc with a specific photo fairly easily through doing an EXIF search.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to have a catalog that&amp;#39;s not going to be locked into a proprietary format so I can export and possibly import it into another database program if the need arises.&lt;/p&gt;\n\n&lt;p&gt;How can I future-proof my catalogs? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18za6jg", "is_robot_indexable": true, "report_reasons": null, "author": "chlorculo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18za6jg/question_on_catalog_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18za6jg/question_on_catalog_software/", "subreddit_subscribers": 723228, "created_utc": 1704470351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI've two pool (Stablebit) : 1 \"prod\" &amp; 1 for recovery in case of.Every week I power up the backup one and do a sync (with FreeFileSync).\n\n\\-&gt; oldest files I didn't touch for year haven't been refresh for years on the backup side-&gt; I'd like to, over the time, smoothly, get the oldest disks emptied to get them back on the physical test bench (and so avoid very long one shot emptying).\n\n**So I'd like to have a tool or a script to \"touch\" (= alter the modification date) of the x oldest files to force them to be included in the next sync run (the solution shall be able to handle +/- 5 millions files).**\n\nAny idea ?", "author_fullname": "t2_vukgz0f2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to force oldest files to be included in the next sync ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z9x1s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704469684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve two pool (Stablebit) : 1 &amp;quot;prod&amp;quot; &amp;amp; 1 for recovery in case of.Every week I power up the backup one and do a sync (with FreeFileSync).&lt;/p&gt;\n\n&lt;p&gt;-&amp;gt; oldest files I didn&amp;#39;t touch for year haven&amp;#39;t been refresh for years on the backup side-&amp;gt; I&amp;#39;d like to, over the time, smoothly, get the oldest disks emptied to get them back on the physical test bench (and so avoid very long one shot emptying).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So I&amp;#39;d like to have a tool or a script to &amp;quot;touch&amp;quot; (= alter the modification date) of the x oldest files to force them to be included in the next sync run (the solution shall be able to handle +/- 5 millions files).&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Any idea ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18z9x1s", "is_robot_indexable": true, "report_reasons": null, "author": "JeanCompot", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18z9x1s/how_to_force_oldest_files_to_be_included_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18z9x1s/how_to_force_oldest_files_to_be_included_in_the/", "subreddit_subscribers": 723228, "created_utc": 1704469684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My setup involves: \n\n\\*\\*\\*Primary device\\*\\*\\*\n\nSynology Nas (1 drive)  \n\\*\\*\\*Back up device off-site\\*\\*\\*\n\nTruenas (3 disks in RaidZ1)\n\n\\*\\*\\*Backup Routine\\*\\*\\*\n\nEvery day I have a script that runs that rsyncs all my data from Synology to the Truenas.\n\n\\*\\*\\*My concern is\\*\\*\\*:\n\n should there be a RAM/HDD failure in the synology, all corrupted data will be copied over to the Truenas and I won't notice in time. \n\nGiven I have a very large distance between my off-site and my primary, I can't switch the devices. If I could, I'd trust the truenas over the synology given that it has error checking due to zfs.\n\nCan anyone suggest a mechanism to identify data rot? A potential option would be to have a 'canary file' - i.e. a file that sits on both Truenas and Synology that I'll never touch. If I see a change in the Canary File, then flag this up as data rot. However, this idea seems flawed in that data rot/corruption could occur anywhere in the drive, not just in my canary file. \n\nAppreciate this question may sound a little paranoid but I'd be very upset if hardware failures in my synology corrupted my data in my Truenas backups.\n\nPlease note,  I've turned on snapshots on my truenas which is very helpful, however, I don't view this as enough to guard against  datarot as it could take me some time to notice things have become corrupt on the synology. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n  \n", "author_fullname": "t2_d2ja9fnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on hoarding data integrity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7ws0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704464239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My setup involves: &lt;/p&gt;\n\n&lt;p&gt;***Primary device***&lt;/p&gt;\n\n&lt;p&gt;Synology Nas (1 drive)&lt;br/&gt;\n***Back up device off-site***&lt;/p&gt;\n\n&lt;p&gt;Truenas (3 disks in RaidZ1)&lt;/p&gt;\n\n&lt;p&gt;***Backup Routine***&lt;/p&gt;\n\n&lt;p&gt;Every day I have a script that runs that rsyncs all my data from Synology to the Truenas.&lt;/p&gt;\n\n&lt;p&gt;***My concern is***:&lt;/p&gt;\n\n&lt;p&gt;should there be a RAM/HDD failure in the synology, all corrupted data will be copied over to the Truenas and I won&amp;#39;t notice in time. &lt;/p&gt;\n\n&lt;p&gt;Given I have a very large distance between my off-site and my primary, I can&amp;#39;t switch the devices. If I could, I&amp;#39;d trust the truenas over the synology given that it has error checking due to zfs.&lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest a mechanism to identify data rot? A potential option would be to have a &amp;#39;canary file&amp;#39; - i.e. a file that sits on both Truenas and Synology that I&amp;#39;ll never touch. If I see a change in the Canary File, then flag this up as data rot. However, this idea seems flawed in that data rot/corruption could occur anywhere in the drive, not just in my canary file. &lt;/p&gt;\n\n&lt;p&gt;Appreciate this question may sound a little paranoid but I&amp;#39;d be very upset if hardware failures in my synology corrupted my data in my Truenas backups.&lt;/p&gt;\n\n&lt;p&gt;Please note,  I&amp;#39;ve turned on snapshots on my truenas which is very helpful, however, I don&amp;#39;t view this as enough to guard against  datarot as it could take me some time to notice things have become corrupt on the synology. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18z7ws0", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum-Warning-4186", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18z7ws0/question_on_hoarding_data_integrity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18z7ws0/question_on_hoarding_data_integrity/", "subreddit_subscribers": 723228, "created_utc": 1704464239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm building a separate tower PC to house a bunch of drives, and I'm unsure how to organize my drives.\n\nDo I keep them as individual drives, not in Raid with their own drive letters mapped.  A storage pool with no mirroring or two way mirroring but lose half the capacity.\n\nI plan on backing up to two large external drives, one will be kept offsite while the other connected and running a PS script that will use robocopy to back up new data.  \n\nI'm in the mindset that my backup method should be ok, to forfeit mirroring and just go for max storage but also unsure if I go this way do I go storage pool or individual drives.", "author_fullname": "t2_e6t86cb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data backup and storage advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z4br6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704452507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building a separate tower PC to house a bunch of drives, and I&amp;#39;m unsure how to organize my drives.&lt;/p&gt;\n\n&lt;p&gt;Do I keep them as individual drives, not in Raid with their own drive letters mapped.  A storage pool with no mirroring or two way mirroring but lose half the capacity.&lt;/p&gt;\n\n&lt;p&gt;I plan on backing up to two large external drives, one will be kept offsite while the other connected and running a PS script that will use robocopy to back up new data.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the mindset that my backup method should be ok, to forfeit mirroring and just go for max storage but also unsure if I go this way do I go storage pool or individual drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18z4br6", "is_robot_indexable": true, "report_reasons": null, "author": "Endeavour1988", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18z4br6/data_backup_and_storage_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18z4br6/data_backup_and_storage_advice/", "subreddit_subscribers": 723228, "created_utc": 1704452507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking to get some sort of data expansion as my new graphics card required me to remove my blu-ray from the sata port to fit it in. \n\nI have been wanting to get a pcie sata expansion card so I can plug my blu-ray drive in and potentially other drives. \n\nMy primary OS is Fedora on my m2 drive. I currently also have an SSD for Windows and an 8tb encrypted hardrive I use on linux. \n\nIn addition to this, I\u2019ve been wanting to get another drive to be an exact replica of my 8tb HDD (Is this RAID 1?) After a bit of reading I think getting an LSI Logic SAS 9207-8i from Amazon and using the for both 8TB drives, and using the old port on the motherboard for my blu-ray drive. \n\nI am wondering if there is another other hardware recommendations, and what softwares would I need to setup the drive duplicates? I haven\u2019t tried anything like Raid before so this is fairly new to me", "author_fullname": "t2_1kls1pde", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardware/Software Needed to Have a HardDrive Duplicate Another", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ywkaj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704424686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to get some sort of data expansion as my new graphics card required me to remove my blu-ray from the sata port to fit it in. &lt;/p&gt;\n\n&lt;p&gt;I have been wanting to get a pcie sata expansion card so I can plug my blu-ray drive in and potentially other drives. &lt;/p&gt;\n\n&lt;p&gt;My primary OS is Fedora on my m2 drive. I currently also have an SSD for Windows and an 8tb encrypted hardrive I use on linux. &lt;/p&gt;\n\n&lt;p&gt;In addition to this, I\u2019ve been wanting to get another drive to be an exact replica of my 8tb HDD (Is this RAID 1?) After a bit of reading I think getting an LSI Logic SAS 9207-8i from Amazon and using the for both 8TB drives, and using the old port on the motherboard for my blu-ray drive. &lt;/p&gt;\n\n&lt;p&gt;I am wondering if there is another other hardware recommendations, and what softwares would I need to setup the drive duplicates? I haven\u2019t tried anything like Raid before so this is fairly new to me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ywkaj", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial_Mistake", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ywkaj/hardwaresoftware_needed_to_have_a_harddrive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ywkaj/hardwaresoftware_needed_to_have_a_harddrive/", "subreddit_subscribers": 723228, "created_utc": 1704424686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I am currently trying to find a storage solution for around 10TB of research data. The primary data storage location will be a cloud storage service from my university and we would like to have it stored at a secondary physical external storage. \n\nI am leaning more towards SSD over HDD due to shock and drop resistance and general speed improvement. Upon further research, it seems like the highest consumer-grade SSD is 8TB (which we might exceed). Is there any way to properly integrate two SSDs together? Or we can only have a disk1 disk2 situation? Can a SATA docking station like the Sabrent 5-bay one help solve the issue?\n\nFurthermore, is there any performance and reliability difference between an external SSD and an internal SSD along with an SSD enclosure? And what enclosure should I look for since by looking at some of the posts here some SSDs might not work well with certain closures. \n\nPrice is not the utmost concern for us as long we can find a reliable, long-term, and fast-enough storage option. ", "author_fullname": "t2_6qmp8foz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for ~10TB storage solution for research data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zc8se", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704475475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am currently trying to find a storage solution for around 10TB of research data. The primary data storage location will be a cloud storage service from my university and we would like to have it stored at a secondary physical external storage. &lt;/p&gt;\n\n&lt;p&gt;I am leaning more towards SSD over HDD due to shock and drop resistance and general speed improvement. Upon further research, it seems like the highest consumer-grade SSD is 8TB (which we might exceed). Is there any way to properly integrate two SSDs together? Or we can only have a disk1 disk2 situation? Can a SATA docking station like the Sabrent 5-bay one help solve the issue?&lt;/p&gt;\n\n&lt;p&gt;Furthermore, is there any performance and reliability difference between an external SSD and an internal SSD along with an SSD enclosure? And what enclosure should I look for since by looking at some of the posts here some SSDs might not work well with certain closures. &lt;/p&gt;\n\n&lt;p&gt;Price is not the utmost concern for us as long we can find a reliable, long-term, and fast-enough storage option. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zc8se", "is_robot_indexable": true, "report_reasons": null, "author": "to-the-horizon", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zc8se/suggestions_for_10tb_storage_solution_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zc8se/suggestions_for_10tb_storage_solution_for/", "subreddit_subscribers": 723228, "created_utc": 1704475475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently got an 18TB external HDD which I have attached to my PC. I'm intending to have it \"live\" there and I will rarely (if ever) take it out. \n\nBut ever since adding it to the mix, opening file explorer (and subsequently, opening certain files...especially video files *whether or not* they're on the 18TB drive) has gotten very slow. Even just trying to open file explorer (which defaults to the desktop) takes longer than normal. When I try to open file explorer, I can hear my 18TB drive spin up and make some noises (it's normally quite quiet) before it finally opens. \n\nBefore adding this 18TB HDD to the mix, I was only using two nvme SSDs. So I'm wondering if this is just a side effect of adding a spinning disk to the mix... Is this normal? Is there any way to alleviate this?", "author_fullname": "t2_12ske0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File explorer/opening files/etc. slowed down after adding 18TB external to PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zbvuk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704474581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got an 18TB external HDD which I have attached to my PC. I&amp;#39;m intending to have it &amp;quot;live&amp;quot; there and I will rarely (if ever) take it out. &lt;/p&gt;\n\n&lt;p&gt;But ever since adding it to the mix, opening file explorer (and subsequently, opening certain files...especially video files &lt;em&gt;whether or not&lt;/em&gt; they&amp;#39;re on the 18TB drive) has gotten very slow. Even just trying to open file explorer (which defaults to the desktop) takes longer than normal. When I try to open file explorer, I can hear my 18TB drive spin up and make some noises (it&amp;#39;s normally quite quiet) before it finally opens. &lt;/p&gt;\n\n&lt;p&gt;Before adding this 18TB HDD to the mix, I was only using two nvme SSDs. So I&amp;#39;m wondering if this is just a side effect of adding a spinning disk to the mix... Is this normal? Is there any way to alleviate this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zbvuk", "is_robot_indexable": true, "report_reasons": null, "author": "clothing_throwaway", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zbvuk/file_exploreropening_filesetc_slowed_down_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zbvuk/file_exploreropening_filesetc_slowed_down_after/", "subreddit_subscribers": 723228, "created_utc": 1704474581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay I know this question might seem to be a bit odd but here goes anyways. I have some \"Full Movie\" DVDs which have \"Trailers\" and \"Extras\". The trailers I already no what I'm going to do with but I need advice on how to store the \"Extras\" if there are things I wish to keep. \n\n&amp;#x200B;\n\nPlus I would like to know what to do with Fitness/Exercise DVDs:\n\n\"The Biggest Loser (2006)\" I wish to copy the full DVD and then just remove the stuff I don't need. \n\nOn the back cover it shows:\n\nMix and match customize! \"Warm Up 5 min\", \"Low-intensity cardio 15 min\"\n\nFor Men \"High-Intensity Cardio for men 10 min\", \"Power sculpt for men 10 min - hand weights\"\n\nFor Women \"High-Intensity cardio for women 10 min\", \"power sculpt for women 10 min\"\n\nBoot Camp 15 min \"stability ball,medicine ball, hand weights optional\" \n\nFunctional Flexibility 10 min \"Stability Ball\"\n\nCool-down 5 min\n\n&amp;#x200B;\n\n\"Special Features\"  \n\nCustomize Your Workout\n\nInspirational Story\n\nCooking Segment\n\nMusic Only Option\n\n2.0 Dolby Surround Sound\n\n&amp;#x200B;\n\nHow do I go by organizing and renaming all these files once copied from DVD to PC. \n\n&amp;#x200B;\n\nHow do I go and save these. \n\n&amp;#x200B;\n\nI know that when I use \"MakeMKV\" the videos from a movie are pulled apart. So the main movie is 1 file and the \"Extras\" and \"Trailers\" each have there own files as well. As far as I can tell. So if I copy a DVD and just keep the main movie and its trailer what I do is below.\n\n&amp;#x200B;\n\n(1) Copy the DVD to the PC\n\n(2) Rename the Main movie as the actual title and year Example \"Powder (1995)\" \n\n(3) Place \"Powder (1995)\" inside a \"Movie\" folder and place all other movies I copy inside same folder\n\n(4) Each movie will have a folder called the same name as the movie \"Powder (1995).mkv\" will go inside a folder called \"Powder (1995)\" and then all other movies will have the same process\n\n(5) I will then scan the \"Movie\" folder with \"Media Companion\" to get the info needed\n\n&amp;#x200B;\n\nBut how do I do something like this with a \"Fitness/Exercise\" DVD\n\n&amp;#x200B;\n\nI will not be putting the \"Fitness/Exercise\" DVDs in the same folder as \"Movies\" \n\n(1) Copy 1 fitness DVD to see what happens with the DVD\n\n(2) Try and figure out what each video file is for \n\n&amp;#x200B;\n\nThese are the only (2) things I can come up with for the way to copy the exercise/fitness DVDs. Dose anyone else have any other tips or advice on how to best copy the \"DVDs\" since I will only be keeping a very few things from the full movies. There are multiple things I will need to copy and keep from the fitness DVDs. I will want to be able to rename each file and then put them in the correct folder or folders. And I don't know if media companion can even do fitness/exercise DVDs. If it can't I will need to rename each file myself and decide on what to name each file and folder if there will even need to be different folder. Example will there need to be a \"For Men\" or \"For Women\" folder. Or even \"Special Features\" folder. I have no clue on how to \"Rename\" or \"Organize\" these fitness/exercise DVDs. \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_8gvbu38t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to rename DVDs in sections based on Back Cover?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zbg4w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704473504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay I know this question might seem to be a bit odd but here goes anyways. I have some &amp;quot;Full Movie&amp;quot; DVDs which have &amp;quot;Trailers&amp;quot; and &amp;quot;Extras&amp;quot;. The trailers I already no what I&amp;#39;m going to do with but I need advice on how to store the &amp;quot;Extras&amp;quot; if there are things I wish to keep. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Plus I would like to know what to do with Fitness/Exercise DVDs:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The Biggest Loser (2006)&amp;quot; I wish to copy the full DVD and then just remove the stuff I don&amp;#39;t need. &lt;/p&gt;\n\n&lt;p&gt;On the back cover it shows:&lt;/p&gt;\n\n&lt;p&gt;Mix and match customize! &amp;quot;Warm Up 5 min&amp;quot;, &amp;quot;Low-intensity cardio 15 min&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;For Men &amp;quot;High-Intensity Cardio for men 10 min&amp;quot;, &amp;quot;Power sculpt for men 10 min - hand weights&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;For Women &amp;quot;High-Intensity cardio for women 10 min&amp;quot;, &amp;quot;power sculpt for women 10 min&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Boot Camp 15 min &amp;quot;stability ball,medicine ball, hand weights optional&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Functional Flexibility 10 min &amp;quot;Stability Ball&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Cool-down 5 min&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Special Features&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;Customize Your Workout&lt;/p&gt;\n\n&lt;p&gt;Inspirational Story&lt;/p&gt;\n\n&lt;p&gt;Cooking Segment&lt;/p&gt;\n\n&lt;p&gt;Music Only Option&lt;/p&gt;\n\n&lt;p&gt;2.0 Dolby Surround Sound&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How do I go by organizing and renaming all these files once copied from DVD to PC. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How do I go and save these. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know that when I use &amp;quot;MakeMKV&amp;quot; the videos from a movie are pulled apart. So the main movie is 1 file and the &amp;quot;Extras&amp;quot; and &amp;quot;Trailers&amp;quot; each have there own files as well. As far as I can tell. So if I copy a DVD and just keep the main movie and its trailer what I do is below.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(1) Copy the DVD to the PC&lt;/p&gt;\n\n&lt;p&gt;(2) Rename the Main movie as the actual title and year Example &amp;quot;Powder (1995)&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;(3) Place &amp;quot;Powder (1995)&amp;quot; inside a &amp;quot;Movie&amp;quot; folder and place all other movies I copy inside same folder&lt;/p&gt;\n\n&lt;p&gt;(4) Each movie will have a folder called the same name as the movie &amp;quot;Powder (1995).mkv&amp;quot; will go inside a folder called &amp;quot;Powder (1995)&amp;quot; and then all other movies will have the same process&lt;/p&gt;\n\n&lt;p&gt;(5) I will then scan the &amp;quot;Movie&amp;quot; folder with &amp;quot;Media Companion&amp;quot; to get the info needed&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But how do I do something like this with a &amp;quot;Fitness/Exercise&amp;quot; DVD&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I will not be putting the &amp;quot;Fitness/Exercise&amp;quot; DVDs in the same folder as &amp;quot;Movies&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;(1) Copy 1 fitness DVD to see what happens with the DVD&lt;/p&gt;\n\n&lt;p&gt;(2) Try and figure out what each video file is for &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;These are the only (2) things I can come up with for the way to copy the exercise/fitness DVDs. Dose anyone else have any other tips or advice on how to best copy the &amp;quot;DVDs&amp;quot; since I will only be keeping a very few things from the full movies. There are multiple things I will need to copy and keep from the fitness DVDs. I will want to be able to rename each file and then put them in the correct folder or folders. And I don&amp;#39;t know if media companion can even do fitness/exercise DVDs. If it can&amp;#39;t I will need to rename each file myself and decide on what to name each file and folder if there will even need to be different folder. Example will there need to be a &amp;quot;For Men&amp;quot; or &amp;quot;For Women&amp;quot; folder. Or even &amp;quot;Special Features&amp;quot; folder. I have no clue on how to &amp;quot;Rename&amp;quot; or &amp;quot;Organize&amp;quot; these fitness/exercise DVDs. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zbg4w", "is_robot_indexable": true, "report_reasons": null, "author": "DawnRenee1988", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zbg4w/how_to_rename_dvds_in_sections_based_on_back_cover/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zbg4w/how_to_rename_dvds_in_sections_based_on_back_cover/", "subreddit_subscribers": 723228, "created_utc": 1704473504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello there, I'm quite excited as today I received a Synology DS923+ to replace my Synology DS220j. The older NAS contains two WD40EFRX disks, while I've populated the newer one with four WD40EFPX disks. Besides the cache and some vibration resistance they should be nearly identical. The problem however is that the new ones make a lot more noise! While the sound of the new ones is supposedly normal, I'm just suprised that the old ones were seemingly much more quiet then. Has anyone else experienced something similar?", "author_fullname": "t2_jml0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD40EFPX vs WD40EFRX noise difference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zash0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704471849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there, I&amp;#39;m quite excited as today I received a Synology DS923+ to replace my Synology DS220j. The older NAS contains two WD40EFRX disks, while I&amp;#39;ve populated the newer one with four WD40EFPX disks. Besides the cache and some vibration resistance they should be nearly identical. The problem however is that the new ones make a lot more noise! While the sound of the new ones is supposedly normal, I&amp;#39;m just suprised that the old ones were seemingly much more quiet then. Has anyone else experienced something similar?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18zash0", "is_robot_indexable": true, "report_reasons": null, "author": "Wazaaguy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18zash0/wd40efpx_vs_wd40efrx_noise_difference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18zash0/wd40efpx_vs_wd40efrx_noise_difference/", "subreddit_subscribers": 723228, "created_utc": 1704471849.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}