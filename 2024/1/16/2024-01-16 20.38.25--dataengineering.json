{"kind": "Listing", "data": {"after": "t3_1980zvj", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7rg2eq0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Iceberg: SQL and ACID semantics in the front, scalable object storage in the back", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_197t8fz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 138, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 138, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GwaMM7jM3so5QhzH1p5Lyd6RiCOluALFk2RzuASMbYM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705377172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/731s003m5qcc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/731s003m5qcc1.jpeg?auto=webp&amp;s=7b48899db260ded981a8532c3adc52e05f335590", "width": 500, "height": 560}, "resolutions": [{"url": "https://preview.redd.it/731s003m5qcc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6a32cc11d9e41e3a9399e25b3b708d6de58f8d6e", "width": 108, "height": 120}, {"url": "https://preview.redd.it/731s003m5qcc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4280cf0d36560508431e7c3466e5ca0d7dc5208d", "width": 216, "height": 241}, {"url": "https://preview.redd.it/731s003m5qcc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3b34110f554edd3615190c4606c650cac61713c", "width": 320, "height": 358}], "variants": {}, "id": "wmUXoufzPOhrwMlGUWOoW8zNMs92YkDbZCPOiIcRLOw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "197t8fz", "is_robot_indexable": true, "report_reasons": null, "author": "bitsondatadev", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197t8fz/apache_iceberg_sql_and_acid_semantics_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/731s003m5qcc1.jpeg", "subreddit_subscribers": 153312, "created_utc": 1705377172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-Source Observability for the Semantic Layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_197xr9y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ppnbfojWVnDY-uQPpl-OPS-IwqTmQ_f9UnJLTy6rExM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705392460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/data-drift/data-drift", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NDjSpV0lexBSsnzsa5Ssm0OLJH8Y7uQqDQR2Db2ikzE.jpg?auto=webp&amp;s=30821265908e8b00ae1b1bce3066cb3b6ac3a205", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/NDjSpV0lexBSsnzsa5Ssm0OLJH8Y7uQqDQR2Db2ikzE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1f6f5c8474eded858513a20b420867038029e54f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NDjSpV0lexBSsnzsa5Ssm0OLJH8Y7uQqDQR2Db2ikzE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d809875272a979acf827c7c43fff9794e3ebc8f2", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NDjSpV0lexBSsnzsa5Ssm0OLJH8Y7uQqDQR2Db2ikzE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2bf05bc0e4290bc471544f3bdc55c01f5889a184", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NDjSpV0lexBSsnzsa5Ssm0OLJH8Y7uQqDQR2Db2ikzE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b99e134d159de70cb48f987e34e61c2ea63b3615", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/NDjSpV0lexBSsnzsa5Ssm0OLJH8Y7uQqDQR2Db2ikzE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=52b25aacea01dfb711235c3da151d500df22fea8", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/NDjSpV0lexBSsnzsa5Ssm0OLJH8Y7uQqDQR2Db2ikzE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1400901ae833dd6009e520161b25442bf8c7bb81", "width": 1080, "height": 540}], "variants": {}, "id": "7g8Z3kvEUj9VarbdauuCtwALuuUzFlwBYoquOdTH1u8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "197xr9y", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197xr9y/opensource_observability_for_the_semantic_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/data-drift/data-drift", "subreddit_subscribers": 153312, "created_utc": 1705392460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So someone I know shared company aws credentials in a zip file (many txt files etc) via email to their colleagues. When they were just meant to share the link of the share point/or what ever it was.  It\u2019s now under investigation and classed as a security breach. \n\nIs this normal or are some people just stupid?\n\nHave any of you had similar experiences like this before? Do people share code via email?", "author_fullname": "t2_45tfneon", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Credential Sharing Stories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197lqqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705359320.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705356967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So someone I know shared company aws credentials in a zip file (many txt files etc) via email to their colleagues. When they were just meant to share the link of the share point/or what ever it was.  It\u2019s now under investigation and classed as a security breach. &lt;/p&gt;\n\n&lt;p&gt;Is this normal or are some people just stupid?&lt;/p&gt;\n\n&lt;p&gt;Have any of you had similar experiences like this before? Do people share code via email?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "197lqqx", "is_robot_indexable": true, "report_reasons": null, "author": "Administrative_Ad768", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197lqqx/credential_sharing_stories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197lqqx/credential_sharing_stories/", "subreddit_subscribers": 153312, "created_utc": 1705356967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vbapbjo8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future of Big Data Systems by Spark creator Matei Zaharia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_197ym19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aRk6Lk6L5gA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Future of Big Data Systems by Spark creator Matei Zaharia\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Future of Big Data Systems by Spark creator Matei Zaharia", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aRk6Lk6L5gA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Future of Big Data Systems by Spark creator Matei Zaharia\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/aRk6Lk6L5gA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aRk6Lk6L5gA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Future of Big Data Systems by Spark creator Matei Zaharia\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/197ym19", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/9IDk7XfO1__cGQyCmWI2QjIHiCEVM4sr1ewdeObfVX4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705396045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/aRk6Lk6L5gA?si=9iKT8jej7jKLdy0K", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Vr-eKqVWvTqOk2dSJoNpy5BHuZGe6rMKTPYgDULenqU.jpg?auto=webp&amp;s=3fe7d46d9511238668877cf4e8a6d27ca6e6595d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Vr-eKqVWvTqOk2dSJoNpy5BHuZGe6rMKTPYgDULenqU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d54eb373765389ef33e40cfb02a304d4464c4128", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Vr-eKqVWvTqOk2dSJoNpy5BHuZGe6rMKTPYgDULenqU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=22f86c96c9b941e95f4d6d7bfed16c7d02722ab4", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Vr-eKqVWvTqOk2dSJoNpy5BHuZGe6rMKTPYgDULenqU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b7b74800fc67f19535ab936c0fcaeba2058d8dec", "width": 320, "height": 240}], "variants": {}, "id": "VrUmpf7gHYb0jVrTvpkyd98lRn3v5vdJxtDeGa9WdNc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "197ym19", "is_robot_indexable": true, "report_reasons": null, "author": "dnulcon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197ym19/future_of_big_data_systems_by_spark_creator_matei/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/aRk6Lk6L5gA?si=9iKT8jej7jKLdy0K", "subreddit_subscribers": 153312, "created_utc": 1705396045.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Future of Big Data Systems by Spark creator Matei Zaharia", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aRk6Lk6L5gA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Future of Big Data Systems by Spark creator Matei Zaharia\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/aRk6Lk6L5gA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am considering using Meltano as the EL tool in an application that allows users to configure their data sources so they are replicated to a data lake. For that, it would be necessary to configure Meltano extractors and loaders programatically based on a user request. The application configuring them would not be running on the same server as Meltano.\n\nFor now, this application uses Airbyte under the hood, sending requests to the Airbyte server with their API. I'm getting more and more suspicious and frustrated with Airbyte, so I'm looking for alternatives.\n\nIs there a way to do this with Meltano? Reading the documentation, I've seen that Meltano is configured by a CLI, or directly editing the extractors' and loaders' YAML files. There doesn't seem to be an API or anything like that (except for running jobs, where you have Airflow or Dagster integrations). Should my application edit YAML files on the server, or is there a more consistent and safer way of doing this?\n\n(or is there a third, better alternative to effectively load data from numerous sources to a data lake, while configuring these replications programatically?)", "author_fullname": "t2_c3hoz70b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Programatically configuring Meltano", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197ptmh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705367409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am considering using Meltano as the EL tool in an application that allows users to configure their data sources so they are replicated to a data lake. For that, it would be necessary to configure Meltano extractors and loaders programatically based on a user request. The application configuring them would not be running on the same server as Meltano.&lt;/p&gt;\n\n&lt;p&gt;For now, this application uses Airbyte under the hood, sending requests to the Airbyte server with their API. I&amp;#39;m getting more and more suspicious and frustrated with Airbyte, so I&amp;#39;m looking for alternatives.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this with Meltano? Reading the documentation, I&amp;#39;ve seen that Meltano is configured by a CLI, or directly editing the extractors&amp;#39; and loaders&amp;#39; YAML files. There doesn&amp;#39;t seem to be an API or anything like that (except for running jobs, where you have Airflow or Dagster integrations). Should my application edit YAML files on the server, or is there a more consistent and safer way of doing this?&lt;/p&gt;\n\n&lt;p&gt;(or is there a third, better alternative to effectively load data from numerous sources to a data lake, while configuring these replications programatically?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197ptmh", "is_robot_indexable": true, "report_reasons": null, "author": "henriquemeloo_", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197ptmh/programatically_configuring_meltano/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197ptmh/programatically_configuring_meltano/", "subreddit_subscribers": 153312, "created_utc": 1705367409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub - danielbeach/fine-tune-openLLaMA: This repo shows how to fine-tune openLLaMA (7b) model on a GPU. (Made for Data Engineers)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1985ama", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GpsXNKoSOQDRIr2irjcJ7xFw-BPJpjO1hI8A8XzQz4c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705418388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/danielbeach/fine-tune-openLLaMA", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qt6Fcxy2wJJxMagDknWEgSkIjvfp3aNWTmdGI14USjY.jpg?auto=webp&amp;s=937c252f359ef5edccf2fc46ed45985f9084c9ff", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qt6Fcxy2wJJxMagDknWEgSkIjvfp3aNWTmdGI14USjY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=47e8c68f1131503ad73f4ba855e3ebab451ead03", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qt6Fcxy2wJJxMagDknWEgSkIjvfp3aNWTmdGI14USjY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb0f9663c49277299020049492ef7656310be406", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qt6Fcxy2wJJxMagDknWEgSkIjvfp3aNWTmdGI14USjY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c1a73a1b4aec5105ccbce27299e8f8cef5a4caa", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qt6Fcxy2wJJxMagDknWEgSkIjvfp3aNWTmdGI14USjY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b3a64f4cf634a56fb6ca1e7558ad75ad719cca9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qt6Fcxy2wJJxMagDknWEgSkIjvfp3aNWTmdGI14USjY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b99e4dc4d4af13ba3477497dac450d1057239844", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qt6Fcxy2wJJxMagDknWEgSkIjvfp3aNWTmdGI14USjY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=31c1808058a039ff7d6d8aa62ec94f76892d275c", "width": 1080, "height": 540}], "variants": {}, "id": "b_cOMlzdHKMlrJyYceBFysCEgiK2ma4vc3EwQHqdwo8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1985ama", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1985ama/github_danielbeachfinetuneopenllama_this_repo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/danielbeach/fine-tune-openLLaMA", "subreddit_subscribers": 153312, "created_utc": 1705418388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,  \n\n\nI have a list of PDFs from which I need to extract table data in automated way. I need one specific table or some important data points from that table. PDFs are from different sources, so the table structures are different from one another. I also need to locate the table in PDF because they appear in different pages every year. I was wondering what would be the most robust way of trying to extract the tables in this case?  \n\n\nThings I have experimented:  \n\n\n1. 3rd party Python packages (pdfplumber, tabula): results were not good enough, these packages couldn't extract tables neatly in consistent manner. They were dividing values/labels into chunks and etc.\n2. openAI gpt-4 chat completions endpoint: very much inconsistent. It is difficult both to locate table in the PDF and extract table or specific data points.\n3. openAI gpt-4 vision API endpoint: I take snapshots of PDF pages and try to extract data using vision endpoint, but because the resolution is not high it makes mistakes.  \n\n\nI need as much Automation as possible for this task. That's why I am even trying to locate the table in PDF in automated way. Do any of you have experience with similar task? Does it even make sense to make an effort on this? If so, what would be the most optimal solution?  \n\n\nSample PDF table which I am trying to extract (let's say I need Total revenue &amp; expense for 2023):  \n\n\nhttps://preview.redd.it/iqa9fdmw1tcc1.png?width=1480&amp;format=png&amp;auto=webp&amp;s=6f18977d4c2a77971b4a62970887c4de3971aac7\n\n&amp;#x200B;", "author_fullname": "t2_aek4m4bd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PDF Table Extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "media_metadata": {"iqa9fdmw1tcc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 92, "x": 108, "u": "https://preview.redd.it/iqa9fdmw1tcc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc0daf001a2fed794e5e5945c79d4baf25faffe2"}, {"y": 184, "x": 216, "u": "https://preview.redd.it/iqa9fdmw1tcc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b478b77908997684c7f80cccdf3fa3365cef9419"}, {"y": 272, "x": 320, "u": "https://preview.redd.it/iqa9fdmw1tcc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4dd7613d8b7b51e0971504558e0662ce82f6065"}, {"y": 545, "x": 640, "u": "https://preview.redd.it/iqa9fdmw1tcc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f88240efd330cf4d8b54a0ebd571b87b5643666"}, {"y": 817, "x": 960, "u": "https://preview.redd.it/iqa9fdmw1tcc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f909ef5566822fdcc5452cde6c671e754727317e"}, {"y": 920, "x": 1080, "u": "https://preview.redd.it/iqa9fdmw1tcc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9636c44146861faffcd35c2195da6c982a7413a"}], "s": {"y": 1261, "x": 1480, "u": "https://preview.redd.it/iqa9fdmw1tcc1.png?width=1480&amp;format=png&amp;auto=webp&amp;s=6f18977d4c2a77971b4a62970887c4de3971aac7"}, "id": "iqa9fdmw1tcc1"}}, "name": "t3_19832la", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lusk49_z0e9i-eiPX5y6NMpI6qwXd5V3ZbDhHFBrWVU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705412266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,  &lt;/p&gt;\n\n&lt;p&gt;I have a list of PDFs from which I need to extract table data in automated way. I need one specific table or some important data points from that table. PDFs are from different sources, so the table structures are different from one another. I also need to locate the table in PDF because they appear in different pages every year. I was wondering what would be the most robust way of trying to extract the tables in this case?  &lt;/p&gt;\n\n&lt;p&gt;Things I have experimented:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;3rd party Python packages (pdfplumber, tabula): results were not good enough, these packages couldn&amp;#39;t extract tables neatly in consistent manner. They were dividing values/labels into chunks and etc.&lt;/li&gt;\n&lt;li&gt;openAI gpt-4 chat completions endpoint: very much inconsistent. It is difficult both to locate table in the PDF and extract table or specific data points.&lt;/li&gt;\n&lt;li&gt;openAI gpt-4 vision API endpoint: I take snapshots of PDF pages and try to extract data using vision endpoint, but because the resolution is not high it makes mistakes.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I need as much Automation as possible for this task. That&amp;#39;s why I am even trying to locate the table in PDF in automated way. Do any of you have experience with similar task? Does it even make sense to make an effort on this? If so, what would be the most optimal solution?  &lt;/p&gt;\n\n&lt;p&gt;Sample PDF table which I am trying to extract (let&amp;#39;s say I need Total revenue &amp;amp; expense for 2023):  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/iqa9fdmw1tcc1.png?width=1480&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6f18977d4c2a77971b4a62970887c4de3971aac7\"&gt;https://preview.redd.it/iqa9fdmw1tcc1.png?width=1480&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6f18977d4c2a77971b4a62970887c4de3971aac7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19832la", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Cod_9001", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19832la/pdf_table_extraction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19832la/pdf_table_extraction/", "subreddit_subscribers": 153312, "created_utc": 1705412266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've shared a comprehensive blog on migrating Hive\u2019s UDFs, UDTFs, and UDAFs to BigQuery. It\u2019s a deep dive into the practical strategies and best practices for this crucial migration step.\n\n[www.aliz.ai/en/blog/how-to-migrate-hive-udfs-udtfs-and-udafs-to-bigquery](http://www.aliz.ai/en/blog/how-to-migrate-hive-udfs-udtfs-and-udafs-to-bigquery)\n\nLet's discuss the challenges and solutions. #DataMigration #BigQuery", "author_fullname": "t2_i8mbe4p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring the Transition from Hive to BigQuery: A Detailed Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19810ce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705405420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve shared a comprehensive blog on migrating Hive\u2019s UDFs, UDTFs, and UDAFs to BigQuery. It\u2019s a deep dive into the practical strategies and best practices for this crucial migration step.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.aliz.ai/en/blog/how-to-migrate-hive-udfs-udtfs-and-udafs-to-bigquery\"&gt;www.aliz.ai/en/blog/how-to-migrate-hive-udfs-udtfs-and-udafs-to-bigquery&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s discuss the challenges and solutions. #DataMigration #BigQuery&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XC4tDNNKXNvnyPiftnNbSLL2V5y4CaP2aI-bBRa-I3Y.jpg?auto=webp&amp;s=ee70d5b6efe1f371b6a470cee2ffe421742dbab9", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/XC4tDNNKXNvnyPiftnNbSLL2V5y4CaP2aI-bBRa-I3Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=30336970d98641055f591b03be284091a99b5a3f", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/XC4tDNNKXNvnyPiftnNbSLL2V5y4CaP2aI-bBRa-I3Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35282ec6094788aa9284219f8da9d9657b12992a", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/XC4tDNNKXNvnyPiftnNbSLL2V5y4CaP2aI-bBRa-I3Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0078f97e4629ab1393dd8af05e94654dd32d2838", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/XC4tDNNKXNvnyPiftnNbSLL2V5y4CaP2aI-bBRa-I3Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=65b9cee265fce9311e30b903f1c52acd4629da02", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/XC4tDNNKXNvnyPiftnNbSLL2V5y4CaP2aI-bBRa-I3Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e5b3888799284285083e259d67638b5f1684ee2", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/XC4tDNNKXNvnyPiftnNbSLL2V5y4CaP2aI-bBRa-I3Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=79b7c13eee1e9deb1a2a0942fed80c14c6a2a0a5", "width": 1080, "height": 607}], "variants": {}, "id": "t7qoVmAqnxSF_1Q1M-XdTgVvqZ8z-6Cnn0OiXhaEZII"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19810ce", "is_robot_indexable": true, "report_reasons": null, "author": "Constant-Collar9129", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19810ce/exploring_the_transition_from_hive_to_bigquery_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19810ce/exploring_the_transition_from_hive_to_bigquery_a/", "subreddit_subscribers": 153312, "created_utc": 1705405420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in honey moon with de (maybe some of you been here idk) and also in the final year of my Bachelor's degree in Civil Engineering. Started working as a Data Engineer in a startup, and this experience has sparked a serious interest in computer science for me. I'm thinking about pursuing a degree in Computer Science after I graduate. From what I've looked into, it would take me about two more years to complete, which means I'd have dual degrees in Civil Engineering and Computer Science by 2026.\n\nI seek for advice, will I be wasting my time?", "author_fullname": "t2_6b8brn7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Advice] - Computer Science Degree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197sqkq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705375674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in honey moon with de (maybe some of you been here idk) and also in the final year of my Bachelor&amp;#39;s degree in Civil Engineering. Started working as a Data Engineer in a startup, and this experience has sparked a serious interest in computer science for me. I&amp;#39;m thinking about pursuing a degree in Computer Science after I graduate. From what I&amp;#39;ve looked into, it would take me about two more years to complete, which means I&amp;#39;d have dual degrees in Civil Engineering and Computer Science by 2026.&lt;/p&gt;\n\n&lt;p&gt;I seek for advice, will I be wasting my time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "197sqkq", "is_robot_indexable": true, "report_reasons": null, "author": "gabiru97", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197sqkq/advice_computer_science_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197sqkq/advice_computer_science_degree/", "subreddit_subscribers": 153312, "created_utc": 1705375674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why starting as a DE might be better than DS, considering maybe going to MLE in the future? I like the DE area and I think maybe strong skills like a DE combined with enough DS could be the key and could it be that DE will be more valued in the future as DS is today?", "author_fullname": "t2_g1c5aj9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choicing beetween DE vs DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19892yb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705427590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why starting as a DE might be better than DS, considering maybe going to MLE in the future? I like the DE area and I think maybe strong skills like a DE combined with enough DS could be the key and could it be that DE will be more valued in the future as DS is today?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19892yb", "is_robot_indexable": true, "report_reasons": null, "author": "M4loka", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19892yb/choicing_beetween_de_vs_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19892yb/choicing_beetween_de_vs_ds/", "subreddit_subscribers": 153312, "created_utc": 1705427590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I nedd help!..So i just got a message from an hiring manager on linkedin who told me to prepare for a 1 hr technical interview(intermediate role) in 2 days after sending my resume. This is my first interview ever and i really dont know how to prepare for this, i looked into the company and i figured they are a data consultant agency which makes the preparation difficult since they will be having a lot of different client using different tools. I really don't want to mess this up, i would appreciate any advice on this..Thank you", "author_fullname": "t2_69eunxvf4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1986tw8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705422197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I nedd help!..So i just got a message from an hiring manager on linkedin who told me to prepare for a 1 hr technical interview(intermediate role) in 2 days after sending my resume. This is my first interview ever and i really dont know how to prepare for this, i looked into the company and i figured they are a data consultant agency which makes the preparation difficult since they will be having a lot of different client using different tools. I really don&amp;#39;t want to mess this up, i would appreciate any advice on this..Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1986tw8", "is_robot_indexable": true, "report_reasons": null, "author": "logicdata", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1986tw8/data_engineering_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1986tw8/data_engineering_interview/", "subreddit_subscribers": 153312, "created_utc": 1705422197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Network route visualization using pyvista and osmnx](https://preview.redd.it/q0n4jfveqtcc1.png?width=1357&amp;format=png&amp;auto=webp&amp;s=ba5fa1ca2de8fece3098c795d168d5dd5a9d1343)\n\n[Network route visualization using pyvista and osmnx](https://spatial-dev.guru/2024/01/14/network-route-visualization-using-pyvista-and-osmnx/)", "author_fullname": "t2_avt84u4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Network route visualization using pyvista and osmnx", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "media_metadata": {"q0n4jfveqtcc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/q0n4jfveqtcc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9abbeb4746ef553f1aef68c8c6debc7c972047b5"}, {"y": 95, "x": 216, "u": "https://preview.redd.it/q0n4jfveqtcc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4fee2f9de3d2bf3506a1f1acd797a974539a902c"}, {"y": 141, "x": 320, "u": "https://preview.redd.it/q0n4jfveqtcc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=52512a48fd5d17b5464324dcdd8fe28842081c9b"}, {"y": 282, "x": 640, "u": "https://preview.redd.it/q0n4jfveqtcc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe980a0d3257d5ecaceb8667554af6ce943f7941"}, {"y": 424, "x": 960, "u": "https://preview.redd.it/q0n4jfveqtcc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8d0b400930a5340127b66e0944670d4f5caae820"}, {"y": 477, "x": 1080, "u": "https://preview.redd.it/q0n4jfveqtcc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=efaac704c1849865719df7d44b9bb71d709a2666"}], "s": {"y": 600, "x": 1357, "u": "https://preview.redd.it/q0n4jfveqtcc1.png?width=1357&amp;format=png&amp;auto=webp&amp;s=ba5fa1ca2de8fece3098c795d168d5dd5a9d1343"}, "id": "q0n4jfveqtcc1"}}, "name": "t3_19863jk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Y73gmViO0WJP6xXJ9NSWHmIwnM0qZX4ONqMBp6_YRD4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1705420399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/q0n4jfveqtcc1.png?width=1357&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ba5fa1ca2de8fece3098c795d168d5dd5a9d1343\"&gt;Network route visualization using pyvista and osmnx&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spatial-dev.guru/2024/01/14/network-route-visualization-using-pyvista-and-osmnx/\"&gt;Network route visualization using pyvista and osmnx&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1DeYdjXpDynOJSnSKE2FbMb-scF7xNYcGJESNseGTvQ.jpg?auto=webp&amp;s=f76c672e3729075241c2e408d77f800fcf8b6b8b", "width": 1024, "height": 453}, "resolutions": [{"url": "https://external-preview.redd.it/1DeYdjXpDynOJSnSKE2FbMb-scF7xNYcGJESNseGTvQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d051fa28286a27adc787c0150ae1e637a461f73d", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/1DeYdjXpDynOJSnSKE2FbMb-scF7xNYcGJESNseGTvQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=40376ac06ae921e17d378596528457dd28ec20c0", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/1DeYdjXpDynOJSnSKE2FbMb-scF7xNYcGJESNseGTvQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7642985a92596a4c08573bbf334eebe38fcbed85", "width": 320, "height": 141}, {"url": "https://external-preview.redd.it/1DeYdjXpDynOJSnSKE2FbMb-scF7xNYcGJESNseGTvQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a61849bc98d13f7eb57c77c6c5a66e2330d4d0a4", "width": 640, "height": 283}, {"url": "https://external-preview.redd.it/1DeYdjXpDynOJSnSKE2FbMb-scF7xNYcGJESNseGTvQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=504776bc5e093fa6617177dcd145005d72f2021f", "width": 960, "height": 424}], "variants": {}, "id": "a-ClTSK0hq4XURzgrNMjNTafXZEzBvgRcq4XTj7ZiPM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19863jk", "is_robot_indexable": true, "report_reasons": null, "author": "iamgeoknight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19863jk/network_route_visualization_using_pyvista_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19863jk/network_route_visualization_using_pyvista_and/", "subreddit_subscribers": 153312, "created_utc": 1705420399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a CS undergrad with some exp into ML and LLM applications but i am looking to do more research and projects into the DE side, so thats why i am asking if you guys have any open problems in literature or in general (Problems the ML/AI community as a whole are seeing)   with data structuring, organizing and ingestion for training/fine-tuning or measuring ML models.\n\n&amp;#x200B;\n\nI was thinking about a few problems in this area and would like to hear your feedback on these and suggestions of other topics\n\n1. Orchestrating LLM data for model distilation (i.e LLMs creating data for training smaller models to substitute the larger ones)\n2. general synthetic data generation and filtering for training ML models\n\n&amp;#x200B;\n\nAny more ideas?", "author_fullname": "t2_7xe340s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for interesting data structuring/ acquisition/ ingestion problems in AI/ML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19842tn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705415174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a CS undergrad with some exp into ML and LLM applications but i am looking to do more research and projects into the DE side, so thats why i am asking if you guys have any open problems in literature or in general (Problems the ML/AI community as a whole are seeing)   with data structuring, organizing and ingestion for training/fine-tuning or measuring ML models.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was thinking about a few problems in this area and would like to hear your feedback on these and suggestions of other topics&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Orchestrating LLM data for model distilation (i.e LLMs creating data for training smaller models to substitute the larger ones)&lt;/li&gt;\n&lt;li&gt;general synthetic data generation and filtering for training ML models&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any more ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19842tn", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPineapples7791", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19842tn/suggestions_for_interesting_data_structuring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19842tn/suggestions_for_interesting_data_structuring/", "subreddit_subscribers": 153312, "created_utc": 1705415174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been searching online and there are many different examples. I am looking at one way which is the worker pod template with config in the airflow. However, there are no samples of config variables or files to set up scheduler or workers? I am looking at running the scheduler on OpenShift and run pods there.", "author_fullname": "t2_j39ngtt1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone able to help point me in the right direction with setting Airflow and KubernetesExecutor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1980oqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705404213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been searching online and there are many different examples. I am looking at one way which is the worker pod template with config in the airflow. However, there are no samples of config variables or files to set up scheduler or workers? I am looking at running the scheduler on OpenShift and run pods there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1980oqn", "is_robot_indexable": true, "report_reasons": null, "author": "Unsure-9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1980oqn/anyone_able_to_help_point_me_in_the_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1980oqn/anyone_able_to_help_point_me_in_the_right/", "subreddit_subscribers": 153312, "created_utc": 1705404213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I hope this question is all right for here. I tried to search the sub, but I'm not really sure what to search for to begin with, so here it goes.\n\n&amp;#x200B;\n\nI'll have a database full of posts that have a description, tags, and the body text. I want to create a suggestion functionality where the user clicks a button, select their preferences and receives a number of suggestions based on what they chose or the other posts they liked, etc. \n\nI don't know what can be used for that, what solutions etc, that's why I need your help!\n\nI know elasticsearch have this kind of functionality, as I've seen it being used at my work, but it was for a gigantic pool of items, so maybe it's overkill? Or maybe there's a better solution focused only on suggestions?\n\n&amp;#x200B;\n\nThanks a lot!", "author_fullname": "t2_49azf3fn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie question: What solutions should I use to suggest my users posts based on their preferences?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197zq93", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705400615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this question is all right for here. I tried to search the sub, but I&amp;#39;m not really sure what to search for to begin with, so here it goes.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll have a database full of posts that have a description, tags, and the body text. I want to create a suggestion functionality where the user clicks a button, select their preferences and receives a number of suggestions based on what they chose or the other posts they liked, etc. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know what can be used for that, what solutions etc, that&amp;#39;s why I need your help!&lt;/p&gt;\n\n&lt;p&gt;I know elasticsearch have this kind of functionality, as I&amp;#39;ve seen it being used at my work, but it was for a gigantic pool of items, so maybe it&amp;#39;s overkill? Or maybe there&amp;#39;s a better solution focused only on suggestions?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197zq93", "is_robot_indexable": true, "report_reasons": null, "author": "izotAcario", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197zq93/newbie_question_what_solutions_should_i_use_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197zq93/newbie_question_what_solutions_should_i_use_to/", "subreddit_subscribers": 153312, "created_utc": 1705400615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,   \n\n\none of the dlt contributors wrote up how they created a dlt + dbt pipeline that they run in cloud functions to get some pricing info on real estate data, that is otherwise not available to the general public.  \n\n\nYou can read it on the dbt blog, sharing it [here](https://docs.getdbt.com/blog/serverless-dlt-dbt-stack)", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal project: Free tier serverless GCP dlt + dbt Portugese real estate price analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197zo50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705400402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,   &lt;/p&gt;\n\n&lt;p&gt;one of the dlt contributors wrote up how they created a dlt + dbt pipeline that they run in cloud functions to get some pricing info on real estate data, that is otherwise not available to the general public.  &lt;/p&gt;\n\n&lt;p&gt;You can read it on the dbt blog, sharing it &lt;a href=\"https://docs.getdbt.com/blog/serverless-dlt-dbt-stack\"&gt;here&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?auto=webp&amp;s=2a89f01968bbb7160773570a5739ba364e017ebf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e39c972215449e24ba187a3b3e6d0289aad02d1b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e48b5b0440098be5b7b54dcdd6d78e80f77e948", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c583ec988ffb5d6d8292b88b38a2a7ac9fc2b799", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a97be3626c69aab79c2204db47f040a6a8bb9820", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ba90b674ccf1906f5a13abd09b27db16d203bd0", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=197f95d4689989cecbdb537c3aa18035536b0c50", "width": 1080, "height": 567}], "variants": {}, "id": "s9XQCWayWEjVSYNiK4ez8RIl3EBcstjT4Cv_3rHuPvk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "197zo50", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197zo50/personal_project_free_tier_serverless_gcp_dlt_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197zo50/personal_project_free_tier_serverless_gcp_dlt_dbt/", "subreddit_subscribers": 153312, "created_utc": 1705400402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all I'm currently a Junior Data Engineer at a company based in California. I work remotely from Oregon. I'm currently on track for a promotion to simply Data Engineer. When I first joined the team most of my work consisted of simple database migrations, running/monitioring jobs in Kubernetes and simple Pandas transformations.\n\n&amp;#x200B;\n\nNow I've developed whole repo's worth of ETL for reporting and analytics to our data warehouse. Ensuring almost all our namespaces are running at high performance. I've deployed multiple machine learning models developed from the data science team. Assisted in our transition to utilizing DBT across our entire codebase. My boss' long term goal for me is to implement AirFlow in the future to make our downstream jobs more fault tolerant.\n\n&amp;#x200B;\n\nI currently make $95,000, what is a reasonable salary I can negotiate for?", "author_fullname": "t2_84sfajyq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice on salary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197ydsd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705395087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all I&amp;#39;m currently a Junior Data Engineer at a company based in California. I work remotely from Oregon. I&amp;#39;m currently on track for a promotion to simply Data Engineer. When I first joined the team most of my work consisted of simple database migrations, running/monitioring jobs in Kubernetes and simple Pandas transformations.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;ve developed whole repo&amp;#39;s worth of ETL for reporting and analytics to our data warehouse. Ensuring almost all our namespaces are running at high performance. I&amp;#39;ve deployed multiple machine learning models developed from the data science team. Assisted in our transition to utilizing DBT across our entire codebase. My boss&amp;#39; long term goal for me is to implement AirFlow in the future to make our downstream jobs more fault tolerant.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I currently make $95,000, what is a reasonable salary I can negotiate for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "197ydsd", "is_robot_indexable": true, "report_reasons": null, "author": "thetruthhurts351", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197ydsd/career_advice_on_salary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197ydsd/career_advice_on_salary/", "subreddit_subscribers": 153312, "created_utc": 1705395087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have built a data warehouse in Snowflake for whole department . There are certain key metrics that we want to produce and control the definition to maintain consistency of those numbers across the organization.\nI don\u2019t want to store only aggregated numbers, as it will lose slicing/dicing ability. I want to create a generic framework that we can use for new metrics too.\nWhat kind of framework or approach have you guys used or recommend for such use case?\nTIA", "author_fullname": "t2_cbf6ez4mk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Centralized Metrics in DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197rzuz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705373490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have built a data warehouse in Snowflake for whole department . There are certain key metrics that we want to produce and control the definition to maintain consistency of those numbers across the organization.\nI don\u2019t want to store only aggregated numbers, as it will lose slicing/dicing ability. I want to create a generic framework that we can use for new metrics too.\nWhat kind of framework or approach have you guys used or recommend for such use case?\nTIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "197rzuz", "is_robot_indexable": true, "report_reasons": null, "author": "discoveringlifeat39", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197rzuz/centralized_metrics_in_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197rzuz/centralized_metrics_in_dwh/", "subreddit_subscribers": 153312, "created_utc": 1705373490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\n&amp;#x200B;\n\nI had been part of a data project going on for over 2 years now, however support was somewhat lacking, priorities shifted, and ownership was shrouded, all of this created confusion and unclear goals.\n\nFastforward 2 years we now have\n\n\\- data stored in AWS - S3\n\n\\- ETL transformation happening in Glue, and pushing these cleaned tables into Postgres\n\n\\- Multiple jobs in Postgres, tweaking the tables to make them 'bi ready'\n\n\\- Power BI connecting to Postgres via gateways, which sometimes has instability issues.\n\n\\- Big desktop model (&gt;250 mb) published to the BI service, consumed by users\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nHowever the challenges I currently face are:\n\n\\- multiple transformations make changing / updating the solution challenging, I would very much like to simplify and take full ownership of the solution, offering stakeholders more agility and accountability on the reports\n\n\\- user cannot really query the data outside the reports: due to the sheer size of the model (+400 tables/views) it is unfeasible to have them navigate the tables or build custom views outside BI\n\n\\- Furthermore the 'analyse in excel' feature is not usable, as the olap cube in excel times out due to the sheer size (and lack of best practices I believe) of the data\n\n\\- Although the data warehouse has id and index columns, these are not connected, there is no real ERD between tables, making querying them even more challenging.\n\n&amp;#x200B;\n\nThe intended outcome would be:\n\n&amp;#x200B;\n\n\\- provide senior stakeholder a way to query the data (ideally some sort of excel pivot, would that an OLAP cube?)\n\n\\- Provide power users the ability to create their own reports in the service\n\n\\- Have alignment in definitions, ensuring accurate figures are reported across reports.\n\n\\- Simplify the solution a lot, and I mean A LOT, so that I can fully manage and service it.\n\n&amp;#x200B;\n\nI dabbled with power bi fabric, and although I lack programming skills, I think this could be an alternative, pulling the tables from s3 or postgress, simplifying as much as possible in there, and then creating a curated dataset users could leverage.\n\nAm I correct in saying that creating a cube for senior stakeholders and simplifying the solution for a better bi experience (star schema) are two completely different things, and if so, do you recommend one over the other?\n\n&amp;#x200B;\n\nAny guidance would be very much appreciated, my background is of a business/data analyst not an engineer/scientist, therefore the lack of knowledge could prove challenging, however with 10y of exp in the field, I'm keen to broaden my professional horizons,a nd would take this as an opportunity.", "author_fullname": "t2_3kutilvb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next best steps - disconnected datawarehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197rdxe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705371737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I had been part of a data project going on for over 2 years now, however support was somewhat lacking, priorities shifted, and ownership was shrouded, all of this created confusion and unclear goals.&lt;/p&gt;\n\n&lt;p&gt;Fastforward 2 years we now have&lt;/p&gt;\n\n&lt;p&gt;- data stored in AWS - S3&lt;/p&gt;\n\n&lt;p&gt;- ETL transformation happening in Glue, and pushing these cleaned tables into Postgres&lt;/p&gt;\n\n&lt;p&gt;- Multiple jobs in Postgres, tweaking the tables to make them &amp;#39;bi ready&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;- Power BI connecting to Postgres via gateways, which sometimes has instability issues.&lt;/p&gt;\n\n&lt;p&gt;- Big desktop model (&amp;gt;250 mb) published to the BI service, consumed by users&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However the challenges I currently face are:&lt;/p&gt;\n\n&lt;p&gt;- multiple transformations make changing / updating the solution challenging, I would very much like to simplify and take full ownership of the solution, offering stakeholders more agility and accountability on the reports&lt;/p&gt;\n\n&lt;p&gt;- user cannot really query the data outside the reports: due to the sheer size of the model (+400 tables/views) it is unfeasible to have them navigate the tables or build custom views outside BI&lt;/p&gt;\n\n&lt;p&gt;- Furthermore the &amp;#39;analyse in excel&amp;#39; feature is not usable, as the olap cube in excel times out due to the sheer size (and lack of best practices I believe) of the data&lt;/p&gt;\n\n&lt;p&gt;- Although the data warehouse has id and index columns, these are not connected, there is no real ERD between tables, making querying them even more challenging.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The intended outcome would be:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;- provide senior stakeholder a way to query the data (ideally some sort of excel pivot, would that an OLAP cube?)&lt;/p&gt;\n\n&lt;p&gt;- Provide power users the ability to create their own reports in the service&lt;/p&gt;\n\n&lt;p&gt;- Have alignment in definitions, ensuring accurate figures are reported across reports.&lt;/p&gt;\n\n&lt;p&gt;- Simplify the solution a lot, and I mean A LOT, so that I can fully manage and service it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I dabbled with power bi fabric, and although I lack programming skills, I think this could be an alternative, pulling the tables from s3 or postgress, simplifying as much as possible in there, and then creating a curated dataset users could leverage.&lt;/p&gt;\n\n&lt;p&gt;Am I correct in saying that creating a cube for senior stakeholders and simplifying the solution for a better bi experience (star schema) are two completely different things, and if so, do you recommend one over the other?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any guidance would be very much appreciated, my background is of a business/data analyst not an engineer/scientist, therefore the lack of knowledge could prove challenging, however with 10y of exp in the field, I&amp;#39;m keen to broaden my professional horizons,a nd would take this as an opportunity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197rdxe", "is_robot_indexable": true, "report_reasons": null, "author": "turbo88988", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197rdxe/next_best_steps_disconnected_datawarehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197rdxe/next_best_steps_disconnected_datawarehouse/", "subreddit_subscribers": 153312, "created_utc": 1705371737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm currently undergoing a BI internship at a company where I have to establish a data warehouse and subsequently create dashboards and reports while also implementing automatic data synchronization.\n\nThe company operates within the Microsoft ecosystem. With approximately 400 employees, it falls within the category of a medium-sized enterprise. It uses Microsoft AX ERP database and Excels files as datasources.\n\nI have two questions:\n\n* What are the available tools in microsoft ecosystem for performing ETL processes?\n   * Performing ETL within Power BI.\n   * Employing dedicated ETL software such as Azure Data Factory or SSIS... (Are there additional tools?)\n* How do I determine the most suitable solution among the options mentioned in question 1, what aspects should I analyze and take into consideration?\n\nThanks in advance.", "author_fullname": "t2_glvmoauc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help, How to determine the best option ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197ic1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705349848.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705349041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m currently undergoing a BI internship at a company where I have to establish a data warehouse and subsequently create dashboards and reports while also implementing automatic data synchronization.&lt;/p&gt;\n\n&lt;p&gt;The company operates within the Microsoft ecosystem. With approximately 400 employees, it falls within the category of a medium-sized enterprise. It uses Microsoft AX ERP database and Excels files as datasources.&lt;/p&gt;\n\n&lt;p&gt;I have two questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are the available tools in microsoft ecosystem for performing ETL processes?\n\n&lt;ul&gt;\n&lt;li&gt;Performing ETL within Power BI.&lt;/li&gt;\n&lt;li&gt;Employing dedicated ETL software such as Azure Data Factory or SSIS... (Are there additional tools?)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;How do I determine the most suitable solution among the options mentioned in question 1, what aspects should I analyze and take into consideration?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197ic1z", "is_robot_indexable": true, "report_reasons": null, "author": "CulturalChemical5640", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197ic1z/help_how_to_determine_the_best_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197ic1z/help_how_to_determine_the_best_option/", "subreddit_subscribers": 153312, "created_utc": 1705349041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Transitioning from the Marine Corps soon and getting my MBA. I want to be able to understand what you guys talk about and be able to converse about it for companies like google/amazon. Does any one have any recommendations? Was finance in undergrad and specializing in Data Analytics for my MBA.", "author_fullname": "t2_5f700oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to start learning the technicalities of what this sub discusses as a PM hoping to get into the tech world.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_198ax1v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705431898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Transitioning from the Marine Corps soon and getting my MBA. I want to be able to understand what you guys talk about and be able to converse about it for companies like google/amazon. Does any one have any recommendations? Was finance in undergrad and specializing in Data Analytics for my MBA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "198ax1v", "is_robot_indexable": true, "report_reasons": null, "author": "amdPCbro", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198ax1v/where_to_start_learning_the_technicalities_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198ax1v/where_to_start_learning_the_technicalities_of/", "subreddit_subscribers": 153312, "created_utc": 1705431898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi friends,\n\nI have a spark data frame in Databricks that I want to save to s3 with a specific name. I know its possible and I have done this before but for the life of me, I can't remember how.\n\ntest\\_sdf.write.parquet('/mnt/prod/reporting/actions/', mode=\"overwrite\")\n\nI want to save the file name as \"demo\\_data\"\n\nI am using pyspark/python", "author_fullname": "t2_ayv84cg7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "databricks write parquet file to S3 with custom file name", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1987t8z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705424577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi friends,&lt;/p&gt;\n\n&lt;p&gt;I have a spark data frame in Databricks that I want to save to s3 with a specific name. I know its possible and I have done this before but for the life of me, I can&amp;#39;t remember how.&lt;/p&gt;\n\n&lt;p&gt;test_sdf.write.parquet(&amp;#39;/mnt/prod/reporting/actions/&amp;#39;, mode=&amp;quot;overwrite&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;I want to save the file name as &amp;quot;demo_data&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I am using pyspark/python&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1987t8z", "is_robot_indexable": true, "report_reasons": null, "author": "TeaAdministrative509", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1987t8z/databricks_write_parquet_file_to_s3_with_custom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1987t8z/databricks_write_parquet_file_to_s3_with_custom/", "subreddit_subscribers": 153312, "created_utc": 1705424577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So coming out of a conversation including our Senior Platform Architect (Software Background), he says that IT developers/Engineers who are responsible for developing data integration pipelines and data models in a data warehouse are not allowed to access live/production data and says everything can be built from sample/testing data. Basically build what you need in a development environment with only sample data and deploy to prod, but you have no access to the data in prod. I get that you want to limit access to end users on productive data, but limiting data on the IT data engineering/BI development team??? I don't know...\n\nHow can you monitor data quality or have any type of data observability on top of data you aren't allowed to access? We need to ensure data quality on productive data one way or another. How do you figure out how to conform different customer tables from a CRM and ERP into a single table without having access to the actual data from those systems?\n\nThis idea of only needing test data makes since from a software development point of view where the data scope is relatively small and finite especially when compared to an enterprise data platform. But an enterprise data platform is not some piece of software, data is largely dependent and not finite. \n\nSo, are you guys building things with actual data from your productive systems, or are you using test/sample data for development? Is this at all common practice?\n\n&amp;#x200B;", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Engineering and Development with Non-Productive Data???", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1987mrf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705424169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So coming out of a conversation including our Senior Platform Architect (Software Background), he says that IT developers/Engineers who are responsible for developing data integration pipelines and data models in a data warehouse are not allowed to access live/production data and says everything can be built from sample/testing data. Basically build what you need in a development environment with only sample data and deploy to prod, but you have no access to the data in prod. I get that you want to limit access to end users on productive data, but limiting data on the IT data engineering/BI development team??? I don&amp;#39;t know...&lt;/p&gt;\n\n&lt;p&gt;How can you monitor data quality or have any type of data observability on top of data you aren&amp;#39;t allowed to access? We need to ensure data quality on productive data one way or another. How do you figure out how to conform different customer tables from a CRM and ERP into a single table without having access to the actual data from those systems?&lt;/p&gt;\n\n&lt;p&gt;This idea of only needing test data makes since from a software development point of view where the data scope is relatively small and finite especially when compared to an enterprise data platform. But an enterprise data platform is not some piece of software, data is largely dependent and not finite. &lt;/p&gt;\n\n&lt;p&gt;So, are you guys building things with actual data from your productive systems, or are you using test/sample data for development? Is this at all common practice?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1987mrf", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1987mrf/engineering_and_development_with_nonproductive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1987mrf/engineering_and_development_with_nonproductive/", "subreddit_subscribers": 153312, "created_utc": 1705424169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are working at integrating our CRM &amp; ERP systems. However, is this necessary if both were connected to the data warehouse? Is this an either/or situation, or is it valuable to have ERP &amp; CRM integrated whilst having both integrated into the data warehouse?", "author_fullname": "t2_u2vp7ejv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CRM-ERP and the Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1987ax9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705423370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are working at integrating our CRM &amp;amp; ERP systems. However, is this necessary if both were connected to the data warehouse? Is this an either/or situation, or is it valuable to have ERP &amp;amp; CRM integrated whilst having both integrated into the data warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1987ax9", "is_robot_indexable": true, "report_reasons": null, "author": "-CaptainCapuchin-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1987ax9/crmerp_and_the_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1987ax9/crmerp_and_the_data_warehouse/", "subreddit_subscribers": 153312, "created_utc": 1705423370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have the following use case:\n\nThere are dozen of SQL tables on private server. I would like to pull the data into Azure MI. Sync should be performed daily. \n\nI came up with one idea:\n\n1. Activation of CDC feature for SQL source tables.\n2. Use Azure Data Factory to extract data from cdc tables and load it to Azure MI tables. \n3. At the beggining whole state of tables should be migrated.\n\n&amp;#x200B;\n\nQuestions:\n\n1. How to handle deletions?\n2. Should I first extract data to some Blob Storage and then load it to destination tables?\n3. Maybe you have better proposals?", "author_fullname": "t2_omva4fi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incremental load between private SQL DB and AZURE MI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1980zvj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705405370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have the following use case:&lt;/p&gt;\n\n&lt;p&gt;There are dozen of SQL tables on private server. I would like to pull the data into Azure MI. Sync should be performed daily. &lt;/p&gt;\n\n&lt;p&gt;I came up with one idea:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Activation of CDC feature for SQL source tables.&lt;/li&gt;\n&lt;li&gt;Use Azure Data Factory to extract data from cdc tables and load it to Azure MI tables. &lt;/li&gt;\n&lt;li&gt;At the beggining whole state of tables should be migrated.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How to handle deletions?&lt;/li&gt;\n&lt;li&gt;Should I first extract data to some Blob Storage and then load it to destination tables?&lt;/li&gt;\n&lt;li&gt;Maybe you have better proposals?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1980zvj", "is_robot_indexable": true, "report_reasons": null, "author": "BigDataMax", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1980zvj/incremental_load_between_private_sql_db_and_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1980zvj/incremental_load_between_private_sql_db_and_azure/", "subreddit_subscribers": 153312, "created_utc": 1705405370.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}