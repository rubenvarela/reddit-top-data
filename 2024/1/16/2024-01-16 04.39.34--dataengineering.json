{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I landed an internship as a data engineer in a small software company, I'm not being heavily supervised due to everyone being so busy all the time and the fact that it's a small team, but I'm mainly learning how to use Airbyte (connect and build custom sources using Python). It's a 3 months full-time internship and I may or may not be offered the position (in their words: \"if I excel as an intern\"). I don't feel very hopeful being hired as a data person when there are no senior data engineers in the company... but I really want the position, and I want to prove that I'm capable. I'm trying to explore documentations of tools I'm using and might use (Airbyte, dbt, some API's) when I'm not assigned a specific task, but I don't feel like it's enough, any advice?", "author_fullname": "t2_fkh83nm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would a software company hire junior data engineers while not having a data team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197f0xe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705341353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I landed an internship as a data engineer in a small software company, I&amp;#39;m not being heavily supervised due to everyone being so busy all the time and the fact that it&amp;#39;s a small team, but I&amp;#39;m mainly learning how to use Airbyte (connect and build custom sources using Python). It&amp;#39;s a 3 months full-time internship and I may or may not be offered the position (in their words: &amp;quot;if I excel as an intern&amp;quot;). I don&amp;#39;t feel very hopeful being hired as a data person when there are no senior data engineers in the company... but I really want the position, and I want to prove that I&amp;#39;m capable. I&amp;#39;m trying to explore documentations of tools I&amp;#39;m using and might use (Airbyte, dbt, some API&amp;#39;s) when I&amp;#39;m not assigned a specific task, but I don&amp;#39;t feel like it&amp;#39;s enough, any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "197f0xe", "is_robot_indexable": true, "report_reasons": null, "author": "Whatinthetabuleh", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197f0xe/would_a_software_company_hire_junior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197f0xe/would_a_software_company_hire_junior_data/", "subreddit_subscribers": 153165, "created_utc": 1705341353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started out as a Data Engineer at an organisation that had 0 knowledge about any data driven approaches, they had a data team but all data was being shared with CSV files on teams. I was hired and now I feel like its time I change things. I have just 1 year experience but I feel I have a solid grasp on standard practices on system design and databases. I am alone in this task and I feel doing this will definitely change my impact in the organisation. \n\nRight now I have completed building API's for every data source that was manually collected on CSV files. I need to think about data lakes, warehouses and ETL processes. \n\nThey do not provide any cloud services and just have a server on-prem that runs a VM which I can SSH into. I do not know how scalable this would be but the amount of data they are collecting and processing is not intensive so I guess it would work for an MVP for now.  \n\nI needed some guidance on how can I start working on data modelling, which frameworks to be using for batch processes, some of the best practices on how I need to start planning the system design for such a large project.\n\n&amp;#x200B;", "author_fullname": "t2_ifsnrqa8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a data driven system from ground up for an organisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197621x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705316136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started out as a Data Engineer at an organisation that had 0 knowledge about any data driven approaches, they had a data team but all data was being shared with CSV files on teams. I was hired and now I feel like its time I change things. I have just 1 year experience but I feel I have a solid grasp on standard practices on system design and databases. I am alone in this task and I feel doing this will definitely change my impact in the organisation. &lt;/p&gt;\n\n&lt;p&gt;Right now I have completed building API&amp;#39;s for every data source that was manually collected on CSV files. I need to think about data lakes, warehouses and ETL processes. &lt;/p&gt;\n\n&lt;p&gt;They do not provide any cloud services and just have a server on-prem that runs a VM which I can SSH into. I do not know how scalable this would be but the amount of data they are collecting and processing is not intensive so I guess it would work for an MVP for now.  &lt;/p&gt;\n\n&lt;p&gt;I needed some guidance on how can I start working on data modelling, which frameworks to be using for batch processes, some of the best practices on how I need to start planning the system design for such a large project.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197621x", "is_robot_indexable": true, "report_reasons": null, "author": "IncomeTraditional995", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197621x/building_a_data_driven_system_from_ground_up_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197621x/building_a_data_driven_system_from_ground_up_for/", "subreddit_subscribers": 153165, "created_utc": 1705316136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given the business wants to see a \u2018single customer view\u2019, what would this mean to you? Would your mind be drawn to the technical OBT as a solution, or do you think of it more abstractly as a collection of tables and views which together provide a holistic view of the customer?", "author_fullname": "t2_ojr03vx2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From a Data Warehouse perspective, what does a \u2018single customer view\u2019 mean to you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196zpve", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705292365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given the business wants to see a \u2018single customer view\u2019, what would this mean to you? Would your mind be drawn to the technical OBT as a solution, or do you think of it more abstractly as a collection of tables and views which together provide a holistic view of the customer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "196zpve", "is_robot_indexable": true, "report_reasons": null, "author": "nydasco", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196zpve/from_a_data_warehouse_perspective_what_does_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196zpve/from_a_data_warehouse_perspective_what_does_a/", "subreddit_subscribers": 153165, "created_utc": 1705292365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Netflix Creates Incremental Processing Solution Using Maestro and Apache Iceberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1974haj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0domsVRE3h_tifSIoIcI1Td4z1p5MAFaKfGyX1Rjs_E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705309669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2024/01/netflix-incremental-processing/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M25pZdkao697laUSvEM3aztmzQhcBUyQ5oXoIKn3Yqk.jpg?auto=webp&amp;s=1710815aca35e033fca804ce7c7415b1b404acd4", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/M25pZdkao697laUSvEM3aztmzQhcBUyQ5oXoIKn3Yqk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0214ca957969e677dce820ce6d29c661fd49b8f7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/M25pZdkao697laUSvEM3aztmzQhcBUyQ5oXoIKn3Yqk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d7e8884e22fb97868f24a30e31eb32a47e3b83a9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/M25pZdkao697laUSvEM3aztmzQhcBUyQ5oXoIKn3Yqk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=71d008e6add6e467e01f3d39e5f0bee8f3d77eb1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/M25pZdkao697laUSvEM3aztmzQhcBUyQ5oXoIKn3Yqk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e3afd89ca872a07278725458b26dc241989742fc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/M25pZdkao697laUSvEM3aztmzQhcBUyQ5oXoIKn3Yqk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fa9a05016fbe7cd764ef11d68f94cec32bd7484b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/M25pZdkao697laUSvEM3aztmzQhcBUyQ5oXoIKn3Yqk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3c2337ec010f577645430b2eaeac0afd6928b639", "width": 1080, "height": 567}], "variants": {}, "id": "6xxK7cRteNVzzw1uXp5McZoCyKEyfqZzK3OLRK5k71o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1974haj", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1974haj/netflix_creates_incremental_processing_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2024/01/netflix-incremental-processing/", "subreddit_subscribers": 153165, "created_utc": 1705309669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,  \nAfter browsing through the community posts, it seems like [neetcode.io](https://neetcode.io) is highly recommended for practising Python for Data Engineering (DE) interviews. I work as a Data Engineer at a small startup, and haven't studied for or practised LeetCode or Data Structures and Algorithms (DSA). Hence, I'm reaching out for guidance.  \nIn the [neetcode.io](https://neetcode.io) platform, the practice section allows you group questions by topic. I assume that some of these topics are more geared towards Software Development Engineer (SDE) interviews, and not all may be equally relevant to DE interviews.  \nCould you share your priority list on which topics I should prioritise based on their relevance for DE interviews?  \nA bit more context: My interview prep is not MAANG specific, the goal is to get good at basic problem solving that comes up in Python rounds.\n\n  \nThe topics are:\n\n1. Arrays and Hashing\n2. Two Pointers\n3. Sliding Window\n4. Stack\n5. Binary Search\n6. Linked List\n7. Trees\n8. Tries\n9. Heap / Priority Queue\n10. Backtracking\n11. Graphs\n12. Advanced Graphs\n13. 1-D dynamic programming\n14. 2-D dynamic programming\n15. Greedy\n16. Intervals\n17. Math &amp; Geometry\n18. Bit Manipulation\n\nThank you for the help!!", "author_fullname": "t2_cu6910tv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview prep help - Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1971hmc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705298132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;br/&gt;\nAfter browsing through the community posts, it seems like &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; is highly recommended for practising Python for Data Engineering (DE) interviews. I work as a Data Engineer at a small startup, and haven&amp;#39;t studied for or practised LeetCode or Data Structures and Algorithms (DSA). Hence, I&amp;#39;m reaching out for guidance.&lt;br/&gt;\nIn the &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; platform, the practice section allows you group questions by topic. I assume that some of these topics are more geared towards Software Development Engineer (SDE) interviews, and not all may be equally relevant to DE interviews.&lt;br/&gt;\nCould you share your priority list on which topics I should prioritise based on their relevance for DE interviews?&lt;br/&gt;\nA bit more context: My interview prep is not MAANG specific, the goal is to get good at basic problem solving that comes up in Python rounds.&lt;/p&gt;\n\n&lt;p&gt;The topics are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Arrays and Hashing&lt;/li&gt;\n&lt;li&gt;Two Pointers&lt;/li&gt;\n&lt;li&gt;Sliding Window&lt;/li&gt;\n&lt;li&gt;Stack&lt;/li&gt;\n&lt;li&gt;Binary Search&lt;/li&gt;\n&lt;li&gt;Linked List&lt;/li&gt;\n&lt;li&gt;Trees&lt;/li&gt;\n&lt;li&gt;Tries&lt;/li&gt;\n&lt;li&gt;Heap / Priority Queue&lt;/li&gt;\n&lt;li&gt;Backtracking&lt;/li&gt;\n&lt;li&gt;Graphs&lt;/li&gt;\n&lt;li&gt;Advanced Graphs&lt;/li&gt;\n&lt;li&gt;1-D dynamic programming&lt;/li&gt;\n&lt;li&gt;2-D dynamic programming&lt;/li&gt;\n&lt;li&gt;Greedy&lt;/li&gt;\n&lt;li&gt;Intervals&lt;/li&gt;\n&lt;li&gt;Math &amp;amp; Geometry&lt;/li&gt;\n&lt;li&gt;Bit Manipulation&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you for the help!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1971hmc", "is_robot_indexable": true, "report_reasons": null, "author": "table_data", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1971hmc/interview_prep_help_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1971hmc/interview_prep_help_python/", "subreddit_subscribers": 153165, "created_utc": 1705298132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So someone I know shared company aws credentials in a zip file (many txt files etc) via email to their colleagues. When they were just meant to share the link of the share point/or what ever it was.  It\u2019s now under investigation and classed as a security breach. \n\nIs this normal or are some people just stupid?\n\nHave any of you had similar experiences like this before? Do people share code via email?", "author_fullname": "t2_45tfneon", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Credential Sharing Stories", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197lqqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705359320.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705356967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So someone I know shared company aws credentials in a zip file (many txt files etc) via email to their colleagues. When they were just meant to share the link of the share point/or what ever it was.  It\u2019s now under investigation and classed as a security breach. &lt;/p&gt;\n\n&lt;p&gt;Is this normal or are some people just stupid?&lt;/p&gt;\n\n&lt;p&gt;Have any of you had similar experiences like this before? Do people share code via email?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "197lqqx", "is_robot_indexable": true, "report_reasons": null, "author": "Administrative_Ad768", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197lqqx/credential_sharing_stories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197lqqx/credential_sharing_stories/", "subreddit_subscribers": 153165, "created_utc": 1705356967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nDo you guys know of any DevOps courses on Udemy or Coursera that are suitable for Data Engineers looking to learn how to deploy Data Architectures and set up CI/CD?\n\n&amp;#x200B;", "author_fullname": "t2_34hj7rgv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DevOps course for Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1978bub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705324099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Do you guys know of any DevOps courses on Udemy or Coursera that are suitable for Data Engineers looking to learn how to deploy Data Architectures and set up CI/CD?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1978bub", "is_robot_indexable": true, "report_reasons": null, "author": "katoo2706", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1978bub/devops_course_for_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1978bub/devops_course_for_data_engineer/", "subreddit_subscribers": 153165, "created_utc": 1705324099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ll try to be brief here. \n\nThe current situation: \nIf we have new hires, the HR will share the names with the IT department to create emails for them and give them access to OSS app that we\u2019re using and there will be the basic system they will need. ex; ticketing system - HR system - slack - zoom \n\nThe idea: \nWe want to automate this process. Maybe integrating OSS with our data warehouse and set a trigger that whenever we have a new hire it will create the account automatically. \nAnd based on the possibility level the access permission will be different: Admin - viewr - .. etc\n\nIs it possible? if yes, what are the tools that will help me to achieve my goal?", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automation; new joiners data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197e3p2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705339148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll try to be brief here. &lt;/p&gt;\n\n&lt;p&gt;The current situation: \nIf we have new hires, the HR will share the names with the IT department to create emails for them and give them access to OSS app that we\u2019re using and there will be the basic system they will need. ex; ticketing system - HR system - slack - zoom &lt;/p&gt;\n\n&lt;p&gt;The idea: \nWe want to automate this process. Maybe integrating OSS with our data warehouse and set a trigger that whenever we have a new hire it will create the account automatically. \nAnd based on the possibility level the access permission will be different: Admin - viewr - .. etc&lt;/p&gt;\n\n&lt;p&gt;Is it possible? if yes, what are the tools that will help me to achieve my goal?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "197e3p2", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197e3p2/automation_new_joiners_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197e3p2/automation_new_joiners_data/", "subreddit_subscribers": 153165, "created_utc": 1705339148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nThe title says it all. I am looking for resources to expand my knowledge on dimensional modelling. However, instead of just reading a book, I am actually looking for resources that allow for gaining some hands-on experience.\n\nThank you in advance!", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best resources to get hands-on experience with dimensional modelling and building a data mart?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197cijh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705335361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;The title says it all. I am looking for resources to expand my knowledge on dimensional modelling. However, instead of just reading a book, I am actually looking for resources that allow for gaining some hands-on experience.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197cijh", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197cijh/best_resources_to_get_handson_experience_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197cijh/best_resources_to_get_handson_experience_with/", "subreddit_subscribers": 153165, "created_utc": 1705335361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nAt the moment I am trying to find a solution for working with clickstream data:\n\n* My goal is to collect page views, clicks, form submissions along with technical properties and user properties\n* The volume is at least 20M events per day\n* The final destination is an opensource ClickHouse database (on premise)\n\nJust before the [news](https://snowplow.io/blog/introducing-snowplow-limited-use-license/?utm_campaign=ops.web.OS_license_update&amp;utm_source=linkedin&amp;utm_medium=social) from Snowplow regarding the company \"evolving from a Commercial Open Source Software (hashtag#coss) company into an enterprise software company\", the solution looked like the best option but now I am confused.\n\nHere are my options:\n\n* Buy the Snoplow license. Risk: paying a fortune in future (the way it happens with Mixpanel and Amplitude)\n* Try using Rudderstack opensource solution (don't know much about its issues)\n* Try using Divolte opensource solution (looks outdated)\n* Set up events using GTM and send data from GA4 to BigQuery and then copy it to the ClickHouse. Risk: Google's unpredictable limitations, questionable customer support and possible issues with data transfer to local database\n* Write our own solution. Risk: time consuming and costly\n\nWhat is your set up? Do you know any other alternative? If you see any logical errors in my thoughts, please let me know as well.", "author_fullname": "t2_2kevky5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your set up for frontend event generation/collection/enrichment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197c7bd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705334617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;At the moment I am trying to find a solution for working with clickstream data:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;My goal is to collect page views, clicks, form submissions along with technical properties and user properties&lt;/li&gt;\n&lt;li&gt;The volume is at least 20M events per day&lt;/li&gt;\n&lt;li&gt;The final destination is an opensource ClickHouse database (on premise)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Just before the &lt;a href=\"https://snowplow.io/blog/introducing-snowplow-limited-use-license/?utm_campaign=ops.web.OS_license_update&amp;amp;utm_source=linkedin&amp;amp;utm_medium=social\"&gt;news&lt;/a&gt; from Snowplow regarding the company &amp;quot;evolving from a Commercial Open Source Software (hashtag#coss) company into an enterprise software company&amp;quot;, the solution looked like the best option but now I am confused.&lt;/p&gt;\n\n&lt;p&gt;Here are my options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Buy the Snoplow license. Risk: paying a fortune in future (the way it happens with Mixpanel and Amplitude)&lt;/li&gt;\n&lt;li&gt;Try using Rudderstack opensource solution (don&amp;#39;t know much about its issues)&lt;/li&gt;\n&lt;li&gt;Try using Divolte opensource solution (looks outdated)&lt;/li&gt;\n&lt;li&gt;Set up events using GTM and send data from GA4 to BigQuery and then copy it to the ClickHouse. Risk: Google&amp;#39;s unpredictable limitations, questionable customer support and possible issues with data transfer to local database&lt;/li&gt;\n&lt;li&gt;Write our own solution. Risk: time consuming and costly&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What is your set up? Do you know any other alternative? If you see any logical errors in my thoughts, please let me know as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "197c7bd", "is_robot_indexable": true, "report_reasons": null, "author": "Kooky_Weakness_2629", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197c7bd/what_is_your_set_up_for_frontend_event/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197c7bd/what_is_your_set_up_for_frontend_event/", "subreddit_subscribers": 153165, "created_utc": 1705334617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am planning to switch in 8-12 months. Currently working in telecom based company in gcp services. I want to know interview pattern for data engineers in good product based companies like below.\nAltassian\nPepsiCo\nGojek\nWallmart\nIntuit\nBP\nSame level companies.\n\n1. No of rounds?\n2. Is DSA involved?\n3. Coding round on which language.\n\nPlease share your experience. It will help a lot.", "author_fullname": "t2_pe79l62ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview pattern for data engineers in product based companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1977b3s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705320666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am planning to switch in 8-12 months. Currently working in telecom based company in gcp services. I want to know interview pattern for data engineers in good product based companies like below.\nAltassian\nPepsiCo\nGojek\nWallmart\nIntuit\nBP\nSame level companies.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;No of rounds?&lt;/li&gt;\n&lt;li&gt;Is DSA involved?&lt;/li&gt;\n&lt;li&gt;Coding round on which language.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Please share your experience. It will help a lot.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1977b3s", "is_robot_indexable": true, "report_reasons": null, "author": "TheErenYeager03", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1977b3s/interview_pattern_for_data_engineers_in_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1977b3s/interview_pattern_for_data_engineers_in_product/", "subreddit_subscribers": 153165, "created_utc": 1705320666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm currently undergoing a BI internship at a company where I have to establish a data warehouse and subsequently create dashboards and reports while also implementing automatic data synchronization.\n\nThe company operates within the Microsoft ecosystem. With approximately 400 employees, it falls within the category of a medium-sized enterprise. It uses Microsoft AX ERP database and Excels files as datasources.\n\nI have two questions:\n\n* What are the available tools in microsoft ecosystem for performing ETL processes?\n   * Performing ETL within Power BI.\n   * Employing dedicated ETL software such as Azure Data Factory or SSIS... (Are there additional tools?)\n* How do I determine the most suitable solution among the options mentioned in question 1, what aspects should I analyze and take into consideration?\n\nThanks in advance.", "author_fullname": "t2_glvmoauc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help, How to determine the best option ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197ic1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705349848.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705349041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m currently undergoing a BI internship at a company where I have to establish a data warehouse and subsequently create dashboards and reports while also implementing automatic data synchronization.&lt;/p&gt;\n\n&lt;p&gt;The company operates within the Microsoft ecosystem. With approximately 400 employees, it falls within the category of a medium-sized enterprise. It uses Microsoft AX ERP database and Excels files as datasources.&lt;/p&gt;\n\n&lt;p&gt;I have two questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are the available tools in microsoft ecosystem for performing ETL processes?\n\n&lt;ul&gt;\n&lt;li&gt;Performing ETL within Power BI.&lt;/li&gt;\n&lt;li&gt;Employing dedicated ETL software such as Azure Data Factory or SSIS... (Are there additional tools?)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;How do I determine the most suitable solution among the options mentioned in question 1, what aspects should I analyze and take into consideration?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197ic1z", "is_robot_indexable": true, "report_reasons": null, "author": "CulturalChemical5640", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197ic1z/help_how_to_determine_the_best_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197ic1z/help_how_to_determine_the_best_option/", "subreddit_subscribers": 153165, "created_utc": 1705349041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have a sharepoint site with thousands of documents in nested folders. I need to find a way to search in those directories and get only the documents that start with \"aaa\\_\" (ideally also with some sort of lastModified filter but that's not mandatory).\n\nThese files need to be copied to an azure storage container, keeping the folder structure it has in Sharepoint. \n\nI've tried connecting ADF to sharepoint through an app registration but that gives an error, presumably due to permission. But even if I could connect I think it's only possible to copy the files using a direct path (while I need to find them dynamically).\n\nDoes anyone have an idea on how I could best do this using Azure and/or Python?\n\n&amp;#x200B;\n\nThanks for reading.", "author_fullname": "t2_16t847", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to copy specific Sharepoint files using Azure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19744b2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705308179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have a sharepoint site with thousands of documents in nested folders. I need to find a way to search in those directories and get only the documents that start with &amp;quot;aaa_&amp;quot; (ideally also with some sort of lastModified filter but that&amp;#39;s not mandatory).&lt;/p&gt;\n\n&lt;p&gt;These files need to be copied to an azure storage container, keeping the folder structure it has in Sharepoint. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried connecting ADF to sharepoint through an app registration but that gives an error, presumably due to permission. But even if I could connect I think it&amp;#39;s only possible to copy the files using a direct path (while I need to find them dynamically).&lt;/p&gt;\n\n&lt;p&gt;Does anyone have an idea on how I could best do this using Azure and/or Python?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19744b2", "is_robot_indexable": true, "report_reasons": null, "author": "drollerfoot7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19744b2/best_way_to_copy_specific_sharepoint_files_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19744b2/best_way_to_copy_specific_sharepoint_files_using/", "subreddit_subscribers": 153165, "created_utc": 1705308179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in honey moon with de (maybe some of you been here idk) and also in the final year of my Bachelor's degree in Civil Engineering. Started working as a Data Engineer in a startup, and this experience has sparked a serious interest in computer science for me. I'm thinking about pursuing a degree in Computer Science after I graduate. From what I've looked into, it would take me about two more years to complete, which means I'd have dual degrees in Civil Engineering and Computer Science by 2026.\n\nI seek for advice, will I be wasting my time?", "author_fullname": "t2_6b8brn7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Advice] - Computer Science Degree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_197sqkq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705375674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in honey moon with de (maybe some of you been here idk) and also in the final year of my Bachelor&amp;#39;s degree in Civil Engineering. Started working as a Data Engineer in a startup, and this experience has sparked a serious interest in computer science for me. I&amp;#39;m thinking about pursuing a degree in Computer Science after I graduate. From what I&amp;#39;ve looked into, it would take me about two more years to complete, which means I&amp;#39;d have dual degrees in Civil Engineering and Computer Science by 2026.&lt;/p&gt;\n\n&lt;p&gt;I seek for advice, will I be wasting my time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "197sqkq", "is_robot_indexable": true, "report_reasons": null, "author": "gabiru97", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197sqkq/advice_computer_science_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197sqkq/advice_computer_science_degree/", "subreddit_subscribers": 153165, "created_utc": 1705375674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am considering using Meltano as the EL tool in an application that allows users to configure their data sources so they are replicated to a data lake. For that, it would be necessary to configure Meltano extractors and loaders programatically based on a user request. The application configuring them would not be running on the same server as Meltano.\n\nFor now, this application uses Airbyte under the hood, sending requests to the Airbyte server with their API. I'm getting more and more suspicious and frustrated with Airbyte, so I'm looking for alternatives.\n\nIs there a way to do this with Meltano? Reading the documentation, I've seen that Meltano is configured by a CLI, or directly editing the extractors' and loaders' YAML files. There doesn't seem to be an API or anything like that (except for running jobs, where you have Airflow or Dagster integrations). Should my application edit YAML files on the server, or is there a more consistent and safer way of doing this?\n\n(or is there a third, better alternative to effectively load data from numerous sources to a data lake, while configuring these replications programatically?)", "author_fullname": "t2_c3hoz70b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Programatically configuring Meltano", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197ptmh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705367409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am considering using Meltano as the EL tool in an application that allows users to configure their data sources so they are replicated to a data lake. For that, it would be necessary to configure Meltano extractors and loaders programatically based on a user request. The application configuring them would not be running on the same server as Meltano.&lt;/p&gt;\n\n&lt;p&gt;For now, this application uses Airbyte under the hood, sending requests to the Airbyte server with their API. I&amp;#39;m getting more and more suspicious and frustrated with Airbyte, so I&amp;#39;m looking for alternatives.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this with Meltano? Reading the documentation, I&amp;#39;ve seen that Meltano is configured by a CLI, or directly editing the extractors&amp;#39; and loaders&amp;#39; YAML files. There doesn&amp;#39;t seem to be an API or anything like that (except for running jobs, where you have Airflow or Dagster integrations). Should my application edit YAML files on the server, or is there a more consistent and safer way of doing this?&lt;/p&gt;\n\n&lt;p&gt;(or is there a third, better alternative to effectively load data from numerous sources to a data lake, while configuring these replications programatically?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197ptmh", "is_robot_indexable": true, "report_reasons": null, "author": "henriquemeloo_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197ptmh/programatically_configuring_meltano/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197ptmh/programatically_configuring_meltano/", "subreddit_subscribers": 153165, "created_utc": 1705367409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty much the title. However, here is some background. \nI am a senior level Data Engineer skilled in pyspark, sql and azure cloud. Know in and out of Databricks too. I can write complex etl code in both functional and OOP style and create end-to-end orchestrated ETL with minimal supervision. I also work well with business teams and strive to create the utility that they are looking for. My past experiences have taught me to he humble no matter what. \nHowever, I recently i have been failing at behavioral rounds even though I exceed expectations at tech rounds. \nSo, for all the Data Engineering Hiring Managers out there, what is it that you look for in a candidate beyond their technical competency. \nYour inputs here would benefit me immensely in improving myself.", "author_fullname": "t2_qea0d89b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Hiring Manager here that could shed some light what do you check for culture fit in a candidate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197i22i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705348402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title. However, here is some background. \nI am a senior level Data Engineer skilled in pyspark, sql and azure cloud. Know in and out of Databricks too. I can write complex etl code in both functional and OOP style and create end-to-end orchestrated ETL with minimal supervision. I also work well with business teams and strive to create the utility that they are looking for. My past experiences have taught me to he humble no matter what. \nHowever, I recently i have been failing at behavioral rounds even though I exceed expectations at tech rounds. \nSo, for all the Data Engineering Hiring Managers out there, what is it that you look for in a candidate beyond their technical competency. \nYour inputs here would benefit me immensely in improving myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197i22i", "is_robot_indexable": true, "report_reasons": null, "author": "chrgrz", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197i22i/any_hiring_manager_here_that_could_shed_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197i22i/any_hiring_manager_here_that_could_shed_some/", "subreddit_subscribers": 153165, "created_utc": 1705348402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am curious about the ways of deploying Dagster which requires the least amount of knowledge and hassle to manage (load monitoring, version updating, etc.) the underlying infrastructure, i.e. focus on writing pipelines in Dagster. Setting up a managed K8s cluster and deploying Dagster there seems error-prone for a small unexperienced team.\n\nLogically, Dagster Cloud can be used to get a managed version of Dagster. However, for us, its pricing model is too expensive.", "author_fullname": "t2_trs7vyx7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managed Dagster Hosting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1974l0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705310105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am curious about the ways of deploying Dagster which requires the least amount of knowledge and hassle to manage (load monitoring, version updating, etc.) the underlying infrastructure, i.e. focus on writing pipelines in Dagster. Setting up a managed K8s cluster and deploying Dagster there seems error-prone for a small unexperienced team.&lt;/p&gt;\n\n&lt;p&gt;Logically, Dagster Cloud can be used to get a managed version of Dagster. However, for us, its pricing model is too expensive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1974l0z", "is_robot_indexable": true, "report_reasons": null, "author": "WeddingIndependent30", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1974l0z/managed_dagster_hosting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1974l0z/managed_dagster_hosting/", "subreddit_subscribers": 153165, "created_utc": 1705310105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, wanted to ask senior practitioners' POV on how to implement Data Quality and Data Observability using modern data engineering approaches.\n\n**Context**\n\n* I work an \"old-school\" enterprise that uses source systems like SAP ECC, SAP Concur, Anaplan, Yardi\n* Our current state approach is to use ELT to land the raw data into ALDS Gen2, then do the subsequent transformations and data quality checks on Databricks and dbt Cloud \n* Our CIO (non-technical person) thinks this is \"inefficient\", believing that we should perform data quality checks on the source system itself and remediate any issues identified from the source \n* The challenge is I do not know of any tool that would allow us to connect to an SAP FICO table for instance, run the DQ rule, then trigger a workflow to write back to SAP to correct a DQ issue \n\nWould love to get the community's POV on what the best approach here would be ", "author_fullname": "t2_6b1hqs16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality &amp; Observability Best Practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19743jl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705308094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, wanted to ask senior practitioners&amp;#39; POV on how to implement Data Quality and Data Observability using modern data engineering approaches.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I work an &amp;quot;old-school&amp;quot; enterprise that uses source systems like SAP ECC, SAP Concur, Anaplan, Yardi&lt;/li&gt;\n&lt;li&gt;Our current state approach is to use ELT to land the raw data into ALDS Gen2, then do the subsequent transformations and data quality checks on Databricks and dbt Cloud &lt;/li&gt;\n&lt;li&gt;Our CIO (non-technical person) thinks this is &amp;quot;inefficient&amp;quot;, believing that we should perform data quality checks on the source system itself and remediate any issues identified from the source &lt;/li&gt;\n&lt;li&gt;The challenge is I do not know of any tool that would allow us to connect to an SAP FICO table for instance, run the DQ rule, then trigger a workflow to write back to SAP to correct a DQ issue &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would love to get the community&amp;#39;s POV on what the best approach here would be &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19743jl", "is_robot_indexable": true, "report_reasons": null, "author": "Background-Proof5402", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19743jl/data_quality_observability_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19743jl/data_quality_observability_best_practice/", "subreddit_subscribers": 153165, "created_utc": 1705308094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am working as a data engineer since past 4 years in the same company. My expertise is very limited currently; one etl tool and SQL.   \nThis year I want to leave this job but before that I want to delve into freelancing. Which skills can I learn in the realm of data that are somewhat in high demand? Should I focus on data cleaning or visualization? Or should I learn cloud?\n\n&amp;#x200B;", "author_fullname": "t2_jbhzqmif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Freelancing advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19730nu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705303782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am working as a data engineer since past 4 years in the same company. My expertise is very limited currently; one etl tool and SQL.&lt;br/&gt;\nThis year I want to leave this job but before that I want to delve into freelancing. Which skills can I learn in the realm of data that are somewhat in high demand? Should I focus on data cleaning or visualization? Or should I learn cloud?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19730nu", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Joke5208", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19730nu/freelancing_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19730nu/freelancing_advice/", "subreddit_subscribers": 153165, "created_utc": 1705303782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7rg2eq0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Iceberg: SQL and ACID semantics in the front, scalable object storage in the back", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_197t8fz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GwaMM7jM3so5QhzH1p5Lyd6RiCOluALFk2RzuASMbYM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705377172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/731s003m5qcc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/731s003m5qcc1.jpeg?auto=webp&amp;s=7b48899db260ded981a8532c3adc52e05f335590", "width": 500, "height": 560}, "resolutions": [{"url": "https://preview.redd.it/731s003m5qcc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6a32cc11d9e41e3a9399e25b3b708d6de58f8d6e", "width": 108, "height": 120}, {"url": "https://preview.redd.it/731s003m5qcc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4280cf0d36560508431e7c3466e5ca0d7dc5208d", "width": 216, "height": 241}, {"url": "https://preview.redd.it/731s003m5qcc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3b34110f554edd3615190c4606c650cac61713c", "width": 320, "height": 358}], "variants": {}, "id": "wmUXoufzPOhrwMlGUWOoW8zNMs92YkDbZCPOiIcRLOw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "197t8fz", "is_robot_indexable": true, "report_reasons": null, "author": "bitsondatadev", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197t8fz/apache_iceberg_sql_and_acid_semantics_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/731s003m5qcc1.jpeg", "subreddit_subscribers": 153165, "created_utc": 1705377172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have built a data warehouse in Snowflake for whole department . There are certain key metrics that we want to produce and control the definition to maintain consistency of those numbers across the organization.\nI don\u2019t want to store only aggregated numbers, as it will lose slicing/dicing ability. I want to create a generic framework that we can use for new metrics too.\nWhat kind of framework or approach have you guys used or recommend for such use case?\nTIA", "author_fullname": "t2_cbf6ez4mk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Centralized Metrics in DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_197rzuz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705373490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have built a data warehouse in Snowflake for whole department . There are certain key metrics that we want to produce and control the definition to maintain consistency of those numbers across the organization.\nI don\u2019t want to store only aggregated numbers, as it will lose slicing/dicing ability. I want to create a generic framework that we can use for new metrics too.\nWhat kind of framework or approach have you guys used or recommend for such use case?\nTIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "197rzuz", "is_robot_indexable": true, "report_reasons": null, "author": "discoveringlifeat39", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197rzuz/centralized_metrics_in_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197rzuz/centralized_metrics_in_dwh/", "subreddit_subscribers": 153165, "created_utc": 1705373490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\n&amp;#x200B;\n\nI had been part of a data project going on for over 2 years now, however support was somewhat lacking, priorities shifted, and ownership was shrouded, all of this created confusion and unclear goals.\n\nFastforward 2 years we now have\n\n\\- data stored in AWS - S3\n\n\\- ETL transformation happening in Glue, and pushing these cleaned tables into Postgres\n\n\\- Multiple jobs in Postgres, tweaking the tables to make them 'bi ready'\n\n\\- Power BI connecting to Postgres via gateways, which sometimes has instability issues.\n\n\\- Big desktop model (&gt;250 mb) published to the BI service, consumed by users\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nHowever the challenges I currently face are:\n\n\\- multiple transformations make changing / updating the solution challenging, I would very much like to simplify and take full ownership of the solution, offering stakeholders more agility and accountability on the reports\n\n\\- user cannot really query the data outside the reports: due to the sheer size of the model (+400 tables/views) it is unfeasible to have them navigate the tables or build custom views outside BI\n\n\\- Furthermore the 'analyse in excel' feature is not usable, as the olap cube in excel times out due to the sheer size (and lack of best practices I believe) of the data\n\n\\- Although the data warehouse has id and index columns, these are not connected, there is no real ERD between tables, making querying them even more challenging.\n\n&amp;#x200B;\n\nThe intended outcome would be:\n\n&amp;#x200B;\n\n\\- provide senior stakeholder a way to query the data (ideally some sort of excel pivot, would that an OLAP cube?)\n\n\\- Provide power users the ability to create their own reports in the service\n\n\\- Have alignment in definitions, ensuring accurate figures are reported across reports.\n\n\\- Simplify the solution a lot, and I mean A LOT, so that I can fully manage and service it.\n\n&amp;#x200B;\n\nI dabbled with power bi fabric, and although I lack programming skills, I think this could be an alternative, pulling the tables from s3 or postgress, simplifying as much as possible in there, and then creating a curated dataset users could leverage.\n\nAm I correct in saying that creating a cube for senior stakeholders and simplifying the solution for a better bi experience (star schema) are two completely different things, and if so, do you recommend one over the other?\n\n&amp;#x200B;\n\nAny guidance would be very much appreciated, my background is of a business/data analyst not an engineer/scientist, therefore the lack of knowledge could prove challenging, however with 10y of exp in the field, I'm keen to broaden my professional horizons,a nd would take this as an opportunity.", "author_fullname": "t2_3kutilvb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next best steps - disconnected datawarehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_197rdxe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705371737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I had been part of a data project going on for over 2 years now, however support was somewhat lacking, priorities shifted, and ownership was shrouded, all of this created confusion and unclear goals.&lt;/p&gt;\n\n&lt;p&gt;Fastforward 2 years we now have&lt;/p&gt;\n\n&lt;p&gt;- data stored in AWS - S3&lt;/p&gt;\n\n&lt;p&gt;- ETL transformation happening in Glue, and pushing these cleaned tables into Postgres&lt;/p&gt;\n\n&lt;p&gt;- Multiple jobs in Postgres, tweaking the tables to make them &amp;#39;bi ready&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;- Power BI connecting to Postgres via gateways, which sometimes has instability issues.&lt;/p&gt;\n\n&lt;p&gt;- Big desktop model (&amp;gt;250 mb) published to the BI service, consumed by users&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However the challenges I currently face are:&lt;/p&gt;\n\n&lt;p&gt;- multiple transformations make changing / updating the solution challenging, I would very much like to simplify and take full ownership of the solution, offering stakeholders more agility and accountability on the reports&lt;/p&gt;\n\n&lt;p&gt;- user cannot really query the data outside the reports: due to the sheer size of the model (+400 tables/views) it is unfeasible to have them navigate the tables or build custom views outside BI&lt;/p&gt;\n\n&lt;p&gt;- Furthermore the &amp;#39;analyse in excel&amp;#39; feature is not usable, as the olap cube in excel times out due to the sheer size (and lack of best practices I believe) of the data&lt;/p&gt;\n\n&lt;p&gt;- Although the data warehouse has id and index columns, these are not connected, there is no real ERD between tables, making querying them even more challenging.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The intended outcome would be:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;- provide senior stakeholder a way to query the data (ideally some sort of excel pivot, would that an OLAP cube?)&lt;/p&gt;\n\n&lt;p&gt;- Provide power users the ability to create their own reports in the service&lt;/p&gt;\n\n&lt;p&gt;- Have alignment in definitions, ensuring accurate figures are reported across reports.&lt;/p&gt;\n\n&lt;p&gt;- Simplify the solution a lot, and I mean A LOT, so that I can fully manage and service it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I dabbled with power bi fabric, and although I lack programming skills, I think this could be an alternative, pulling the tables from s3 or postgress, simplifying as much as possible in there, and then creating a curated dataset users could leverage.&lt;/p&gt;\n\n&lt;p&gt;Am I correct in saying that creating a cube for senior stakeholders and simplifying the solution for a better bi experience (star schema) are two completely different things, and if so, do you recommend one over the other?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any guidance would be very much appreciated, my background is of a business/data analyst not an engineer/scientist, therefore the lack of knowledge could prove challenging, however with 10y of exp in the field, I&amp;#39;m keen to broaden my professional horizons,a nd would take this as an opportunity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "197rdxe", "is_robot_indexable": true, "report_reasons": null, "author": "turbo88988", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/197rdxe/next_best_steps_disconnected_datawarehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/197rdxe/next_best_steps_disconnected_datawarehouse/", "subreddit_subscribers": 153165, "created_utc": 1705371737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nIf some teams are well versed with the Oracle database architecture and its optimizers working and designed application on top of this. Now moving same team to work on aurora postgresql/mysql databases design/development [projects. Is](https://projects.Is) any key design/architectural changes should the app development team or the database design team, should really aware about, so as to take right decision on any new development project in AWS aurora postgresql database?\n\nOr\n\nIs there any list of differences(as compared to Oracle database) in key concepts like for example basic design concepts, Normalization, Partitioning, clustering, backup and recovery, Indexing strategy, isolation level, performance which one should definitely be aware of? ", "author_fullname": "t2_awgfwfxot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Changing database technology", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196zhaf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705291637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;If some teams are well versed with the Oracle database architecture and its optimizers working and designed application on top of this. Now moving same team to work on aurora postgresql/mysql databases design/development &lt;a href=\"https://projects.Is\"&gt;projects. Is&lt;/a&gt; any key design/architectural changes should the app development team or the database design team, should really aware about, so as to take right decision on any new development project in AWS aurora postgresql database?&lt;/p&gt;\n\n&lt;p&gt;Or&lt;/p&gt;\n\n&lt;p&gt;Is there any list of differences(as compared to Oracle database) in key concepts like for example basic design concepts, Normalization, Partitioning, clustering, backup and recovery, Indexing strategy, isolation level, performance which one should definitely be aware of? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Dg1o0AJbvvVMQwZg2i-NvyEKVAX5yGx9ref44kXYj1s.jpg?auto=webp&amp;s=af5de3acedaddd416b8b24ddc5cb1933cd06ac6c", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/Dg1o0AJbvvVMQwZg2i-NvyEKVAX5yGx9ref44kXYj1s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a6c35bd2a0d24a13926015700885dd99237c50fe", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Dg1o0AJbvvVMQwZg2i-NvyEKVAX5yGx9ref44kXYj1s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4b3501d56ddedf1dce715e68629c59d84db61ed", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Dg1o0AJbvvVMQwZg2i-NvyEKVAX5yGx9ref44kXYj1s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bbf04438abb85783e52d503124fabc94466440cf", "width": 320, "height": 320}], "variants": {}, "id": "LOQqOuoAMEPrL6Vf8Q-o5Hy7dVfc1KRQghfUPiDRtXQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "196zhaf", "is_robot_indexable": true, "report_reasons": null, "author": "Big_Length9755", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196zhaf/changing_database_technology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196zhaf/changing_database_technology/", "subreddit_subscribers": 153165, "created_utc": 1705291637.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}