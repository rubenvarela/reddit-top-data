{"kind": "Listing", "data": {"after": "t3_1aehll2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "in general", "author_fullname": "t2_lno6576f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is programming in data engineering as complex as in software engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1advvbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706536559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;in general&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1advvbm", "is_robot_indexable": true, "report_reasons": null, "author": "ryanwolfh", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1advvbm/is_programming_in_data_engineering_as_complex_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1advvbm/is_programming_in_data_engineering_as_complex_as/", "subreddit_subscribers": 156924, "created_utc": 1706536559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked as a BI Developer/SQL DBA/ SQL Developer for like 5 years.For the last 2 years I have been working as a Big data analyst working on Databricks, Python,Pyspark and some AWS services.\nAlso been working on Looker.\n\nI have been trying to switch to a pure DE role where I get to create pipelines and work on more advanced AWS services etc.But most do the DE roles out there requires lots of skills set and I don\u2019t even see many entry level DE roles.\n\nAny one in similar situation?", "author_fullname": "t2_slia7yw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is it so hard to land a DE role.?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae4wnv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706559133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked as a BI Developer/SQL DBA/ SQL Developer for like 5 years.For the last 2 years I have been working as a Big data analyst working on Databricks, Python,Pyspark and some AWS services.\nAlso been working on Looker.&lt;/p&gt;\n\n&lt;p&gt;I have been trying to switch to a pure DE role where I get to create pipelines and work on more advanced AWS services etc.But most do the DE roles out there requires lots of skills set and I don\u2019t even see many entry level DE roles.&lt;/p&gt;\n\n&lt;p&gt;Any one in similar situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ae4wnv", "is_robot_indexable": true, "report_reasons": null, "author": "cruze_8907", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ae4wnv/why_is_it_so_hard_to_land_a_de_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ae4wnv/why_is_it_so_hard_to_land_a_de_role/", "subreddit_subscribers": 156924, "created_utc": 1706559133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\nWhich one is better to choose in your opinion? I am a self-taught data engineer, but I would like to get certified so that future employers stop questioning my Bachelor's degree in Economics.\n\ni know that the main diffrence is in the cloud platforms but i would like to know which one offers a greater and better depth into the field of data engineer? \n\nthank you in advance for ur help :D\n\n[https://aws.amazon.com/certification/certified-data-engineer-associate/](https://aws.amazon.com/certification/certified-data-engineer-associate/)\n\n[https://learn.microsoft.com/en-us/credentials/certifications/azure-data-engineer/](https://learn.microsoft.com/en-us/credentials/certifications/azure-data-engineer/)", "author_fullname": "t2_qmhxkds80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Certified Data Engineer - Associate VS Azure Data Engineer Associate (DP 203 exam)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae6h40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706563015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;Which one is better to choose in your opinion? I am a self-taught data engineer, but I would like to get certified so that future employers stop questioning my Bachelor&amp;#39;s degree in Economics.&lt;/p&gt;\n\n&lt;p&gt;i know that the main diffrence is in the cloud platforms but i would like to know which one offers a greater and better depth into the field of data engineer? &lt;/p&gt;\n\n&lt;p&gt;thank you in advance for ur help :D&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://aws.amazon.com/certification/certified-data-engineer-associate/\"&gt;https://aws.amazon.com/certification/certified-data-engineer-associate/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/credentials/certifications/azure-data-engineer/\"&gt;https://learn.microsoft.com/en-us/credentials/certifications/azure-data-engineer/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?auto=webp&amp;s=8afacfc14dfed09cec0415cac7d36db9c3374c61", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=64a1b1322ed94c559cb213e6a08f3eb426a3fb0b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9edddfdb28bb0e92ceb041859aacef81ab9ed42e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=de73cdc9da2d0b04938bb7d051ab1a3ceb783323", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60037829d2ce04de0705a2b45123d8ab7c12d41c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5a8f0da08b9281c578a8ab6f49a5b3f577ec9b8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a9a9c1c38bd543a7ea6b718e139a9c1e6b62d18", "width": 1080, "height": 567}], "variants": {}, "id": "RUqh18uQTwuGJocqdUcC-6UfvfWS63SRDdr8AQqU3uM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ae6h40", "is_robot_indexable": true, "report_reasons": null, "author": "Comment_Error", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ae6h40/aws_certified_data_engineer_associate_vs_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ae6h40/aws_certified_data_engineer_associate_vs_azure/", "subreddit_subscribers": 156924, "created_utc": 1706563015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was testing out a nosql solution using cosmosDB on azure. I know this is not conventional. But is it wrong to go with this approach, where the database can be considered as a broker and the tables(or collection) considered as topics? \n\nThe producers add the data to the required  topics(table) and consumers can consume directly from the table. Assuming that there is auto scaling and that these can be upscaled based on the number of incoming messages, is this a viable alternative? And would this be cost effective in comparison to Kafka(Or event hubs)?\n\nAssume that my usecase is adding messages and consuming the data for different purposes. (Processing, dumping to data lake, visualizing data)\n\nAlternatively, is this how Kafka is designed in the backend or is there any other system?\n\nAny answers would be greatly appreciated! Thank you!", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why use Kafka when you can use a database with multiple tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1adzfya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706545955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was testing out a nosql solution using cosmosDB on azure. I know this is not conventional. But is it wrong to go with this approach, where the database can be considered as a broker and the tables(or collection) considered as topics? &lt;/p&gt;\n\n&lt;p&gt;The producers add the data to the required  topics(table) and consumers can consume directly from the table. Assuming that there is auto scaling and that these can be upscaled based on the number of incoming messages, is this a viable alternative? And would this be cost effective in comparison to Kafka(Or event hubs)?&lt;/p&gt;\n\n&lt;p&gt;Assume that my usecase is adding messages and consuming the data for different purposes. (Processing, dumping to data lake, visualizing data)&lt;/p&gt;\n\n&lt;p&gt;Alternatively, is this how Kafka is designed in the backend or is there any other system?&lt;/p&gt;\n\n&lt;p&gt;Any answers would be greatly appreciated! Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1adzfya", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adzfya/why_use_kafka_when_you_can_use_a_database_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adzfya/why_use_kafka_when_you_can_use_a_database_with/", "subreddit_subscribers": 156924, "created_utc": 1706545955.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently a mid-ish level analytics engineer that went from being a data analyst at a previous job to being hired almost exclusively to make data models in dbt at my current job (data stack is airflow, dbt, snowflake). There's been some internal restructuring in my organization on top of my manager leaving (2.5 months after hiring me too) so now there's an expectation that my work is going to include a lot more stuff outside my niche skillset, specifically leaning more towards DE stuff. \n\n&amp;#x200B;\n\nMost of my skills lie in data modeling and the front end aspect of data analytics like dashboarding, data exploration, creating reports etc. When I listen in on conversations involving our data architect and senior DE, it gets overwhelming for me as I'm trying to keep up. On top of this, I already have ideas I want to change/implement with how we go about using dbt and overall just have better ownership of it. For example, my current org doesn't have a separate develop environment to develop models, like I'll create a new branch in git but if I want to test the results and use the dbt run command, it literally will materialize the model straight to production. I want to change that but all of that back end stuff seems daunting and I don't want to break anything.\n\n&amp;#x200B;\n\nBasically, I'm getting anxious about not knowing what I don't know regarding most things DE and I want to sack up and try to get better at it but I'm not quite sure where to start.", "author_fullname": "t2_4xc90hk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you do to elevate your skills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aeefxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706584492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a mid-ish level analytics engineer that went from being a data analyst at a previous job to being hired almost exclusively to make data models in dbt at my current job (data stack is airflow, dbt, snowflake). There&amp;#39;s been some internal restructuring in my organization on top of my manager leaving (2.5 months after hiring me too) so now there&amp;#39;s an expectation that my work is going to include a lot more stuff outside my niche skillset, specifically leaning more towards DE stuff. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Most of my skills lie in data modeling and the front end aspect of data analytics like dashboarding, data exploration, creating reports etc. When I listen in on conversations involving our data architect and senior DE, it gets overwhelming for me as I&amp;#39;m trying to keep up. On top of this, I already have ideas I want to change/implement with how we go about using dbt and overall just have better ownership of it. For example, my current org doesn&amp;#39;t have a separate develop environment to develop models, like I&amp;#39;ll create a new branch in git but if I want to test the results and use the dbt run command, it literally will materialize the model straight to production. I want to change that but all of that back end stuff seems daunting and I don&amp;#39;t want to break anything.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basically, I&amp;#39;m getting anxious about not knowing what I don&amp;#39;t know regarding most things DE and I want to sack up and try to get better at it but I&amp;#39;m not quite sure where to start.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aeefxr", "is_robot_indexable": true, "report_reasons": null, "author": "thisisformeworking", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aeefxr/what_would_you_do_to_elevate_your_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aeefxr/what_would_you_do_to_elevate_your_skills/", "subreddit_subscribers": 156924, "created_utc": 1706584492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Shouldn't be a huge amount of data, &lt;200 GB currently in the DB.  \n\nI titled this as 'replicate', but it's really just ELT without the T.  This replication wouldn't have to be realtime, by the way.\n\nWe're hoping to roll our own as much as possible in order to save money, but maybe that is unrealistic/unadvisable?\n\nEdit: edited for clarity.", "author_fullname": "t2_j15uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to replicate from AWS Sql Server db to Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae7u5p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706566863.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706566365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Shouldn&amp;#39;t be a huge amount of data, &amp;lt;200 GB currently in the DB.  &lt;/p&gt;\n\n&lt;p&gt;I titled this as &amp;#39;replicate&amp;#39;, but it&amp;#39;s really just ELT without the T.  This replication wouldn&amp;#39;t have to be realtime, by the way.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re hoping to roll our own as much as possible in order to save money, but maybe that is unrealistic/unadvisable?&lt;/p&gt;\n\n&lt;p&gt;Edit: edited for clarity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ae7u5p", "is_robot_indexable": true, "report_reasons": null, "author": "jbrune", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ae7u5p/whats_the_best_way_to_replicate_from_aws_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ae7u5p/whats_the_best_way_to_replicate_from_aws_sql/", "subreddit_subscribers": 156924, "created_utc": 1706566365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to work on a table with 50mil rows, but I'm not able to load the table into pandas on my local system. Will it work if I use sagemaker or google colab? Does anyone have experience working with such big data?", "author_fullname": "t2_8mn3m0sl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with a sql table of 50mil records in pandas? Will sagemaker work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aeawka", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706574401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to work on a table with 50mil rows, but I&amp;#39;m not able to load the table into pandas on my local system. Will it work if I use sagemaker or google colab? Does anyone have experience working with such big data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aeawka", "is_robot_indexable": true, "report_reasons": null, "author": "PurpVan", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aeawka/working_with_a_sql_table_of_50mil_records_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aeawka/working_with_a_sql_table_of_50mil_records_in/", "subreddit_subscribers": 156924, "created_utc": 1706574401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Fellow architects, what\u2019s your favorite architect you\u2019ve built and why?", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions Architect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aegsqh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706592086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fellow architects, what\u2019s your favorite architect you\u2019ve built and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "CEO of Data Engineer Academy", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aegsqh", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1aegsqh/solutions_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aegsqh/solutions_architect/", "subreddit_subscribers": 156924, "created_utc": 1706592086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am curios to know that what ideas and innovations you introduced in your data engineering project?", "author_fullname": "t2_uok38vei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas and innovations in data engineering project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae3glr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706555617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am curios to know that what ideas and innovations you introduced in your data engineering project?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ae3glr", "is_robot_indexable": true, "report_reasons": null, "author": "loosernew7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ae3glr/ideas_and_innovations_in_data_engineering_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ae3glr/ideas_and_innovations_in_data_engineering_project/", "subreddit_subscribers": 156924, "created_utc": 1706555617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nCompany is currently in the process of designing a custom architecture for a data warehouse. Due to data residency requirements, our data is split across 7 different azure regions in seven different databases. In addition, the databases are semi multi-tenant \u2014 some clients have their own specialized schema, though the tables are constant in each schema. In short, there are \"50\" targets where data could be stored.\n\nAnyways, we rely on Presto to query this data, which is inefficient and expensive. We're looking into centralizing everything, which will be done in Databricks for the creation of the Silver/Bronze layers and Unity for ACL. However, to prevent vendor lock-in, we're looking to engineer a custom solution to get all the data from our databases, incrementally update via CDC it in a bronze layer stored in Azure S3, so we could move vendors and not re-invent the wheel if business priorities change.\n\nHere's the architecture I'm currently considering, based on a couple days of research.\n\nMariaDB Databases -&gt; CDC read through Debezium Server -&gt; Dumped to common FastAPI/Axum HTTP Server via Json/Avro (between all 7 databases) -&gt; Instructions for recreating data inserted into Delta Table -&gt; Reconstruct entire dataset based on Instructions (Delta or Iceberg, open question) -&gt; Create Silver/Gold layers through Databricks ([process here](https://docs.databricks.com/en/delta/clone-parquet.html))\n\nSome open questions I have\n\n\\- Is Iceberg or Delta the preferred solution here? I was mocking the HTTP server with Iceberg because it supports schema evolution. I was looking at delta-rs for this, but doesn't support schema evolution yet, which I would like to be intention since Iceberg supports this natively. I would like to avoid using Spark if possible.\n\n\\- I would be processing the CDC as they come in, which means I would constantly be inserting one row. I'd imagine these parquet-based solutions are not particularly good at inserts of one row. I could theoretically implement native batching. Is there any alternate solution, that is ideally file-based like Delta/Iceberg and open-source?\n\n\\- Am I overthinking it by storing the instructions for how to recreate the data rather than just translating the Debezium instructions directly into the relevant data?\n\nAny thoughts would be appreciated here. Thank you!", "author_fullname": "t2_v12atn7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Debezium-based Multimodal Datastore - critiques needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae36c3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "287cf772-ac9d-11eb-aa84-0ead36cb44af", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706554911.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;Company is currently in the process of designing a custom architecture for a data warehouse. Due to data residency requirements, our data is split across 7 different azure regions in seven different databases. In addition, the databases are semi multi-tenant \u2014 some clients have their own specialized schema, though the tables are constant in each schema. In short, there are &amp;quot;50&amp;quot; targets where data could be stored.&lt;/p&gt;\n\n&lt;p&gt;Anyways, we rely on Presto to query this data, which is inefficient and expensive. We&amp;#39;re looking into centralizing everything, which will be done in Databricks for the creation of the Silver/Bronze layers and Unity for ACL. However, to prevent vendor lock-in, we&amp;#39;re looking to engineer a custom solution to get all the data from our databases, incrementally update via CDC it in a bronze layer stored in Azure S3, so we could move vendors and not re-invent the wheel if business priorities change.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the architecture I&amp;#39;m currently considering, based on a couple days of research.&lt;/p&gt;\n\n&lt;p&gt;MariaDB Databases -&amp;gt; CDC read through Debezium Server -&amp;gt; Dumped to common FastAPI/Axum HTTP Server via Json/Avro (between all 7 databases) -&amp;gt; Instructions for recreating data inserted into Delta Table -&amp;gt; Reconstruct entire dataset based on Instructions (Delta or Iceberg, open question) -&amp;gt; Create Silver/Gold layers through Databricks (&lt;a href=\"https://docs.databricks.com/en/delta/clone-parquet.html\"&gt;process here&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Some open questions I have&lt;/p&gt;\n\n&lt;p&gt;- Is Iceberg or Delta the preferred solution here? I was mocking the HTTP server with Iceberg because it supports schema evolution. I was looking at delta-rs for this, but doesn&amp;#39;t support schema evolution yet, which I would like to be intention since Iceberg supports this natively. I would like to avoid using Spark if possible.&lt;/p&gt;\n\n&lt;p&gt;- I would be processing the CDC as they come in, which means I would constantly be inserting one row. I&amp;#39;d imagine these parquet-based solutions are not particularly good at inserts of one row. I could theoretically implement native batching. Is there any alternate solution, that is ideally file-based like Delta/Iceberg and open-source?&lt;/p&gt;\n\n&lt;p&gt;- Am I overthinking it by storing the instructions for how to recreate the data rather than just translating the Debezium instructions directly into the relevant data?&lt;/p&gt;\n\n&lt;p&gt;Any thoughts would be appreciated here. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?auto=webp&amp;s=9dd59568b8579947f05ce66ee028655ef14e64d6", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99613d282007d0bcc41947bc7f0846da94adca04", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=400ef45c57444e53fb95c1358e9a0b6419c3112e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ed83d9a6c1afb35b8be4de3f85b722298d1c3d6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=768e111879e31b88e5a61b81d8d367edaa5e5351", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2a359111feb6e4d3ffa529f6614614a63914c4e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6e5d40f18830851f93eb2158f465da573a5df80", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data/Software Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ae36c3", "is_robot_indexable": true, "report_reasons": null, "author": "Dazzling-Reason-5140", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1ae36c3/building_a_debeziumbased_multimodal_datastore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ae36c3/building_a_debeziumbased_multimodal_datastore/", "subreddit_subscribers": 156924, "created_utc": 1706554911.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you use data virtualization (using a tool to connect different data sources and wrangle them together without the need to physically move the data).\n\nWhat tools do you use? What do like or dislike about it? What do you wish existed?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Virtualization, do you use it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1adzkjs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706546281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you use data virtualization (using a tool to connect different data sources and wrangle them together without the need to physically move the data).&lt;/p&gt;\n\n&lt;p&gt;What tools do you use? What do like or dislike about it? What do you wish existed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1adzkjs", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adzkjs/data_virtualization_do_you_use_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adzkjs/data_virtualization_do_you_use_it/", "subreddit_subscribers": 156924, "created_utc": 1706546281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,   \n\n\nAt the moment, I am in the process of setting up a new data architecture with a focus on making it more scalable. My data is mostly text coming in from different sources (mostly internal, some external). Each piece of text has associated metadata fields directly stored with the text in a field and some metadata in additional tables (e.g. topics). There is quite a lot data coming in each week and the most recent data is always the most relevant.  \n\n\nFor each text, we also want to compute the embeddings to filter and find the most relevant texts within a topic (mostly a focus area within our enterprise) and make it available to the user. The relevant texts are then summarized and tagged with additional keywords to make the search easier. I could get around storing only the most recent relevant data (e.g. past month or quarter).   \n\n\nI want to build it scalable and have the time to test a few different architectures and systems, but I would love to hear what other people think first.   \n\n\nAt the moment, I am thinking of something like this:  \n1. NoSQL, where I parse in the entire data and all new incoming data (something like MongoDB).   \n2. Something faster and more structured to store the \"relevant texts\" (e.g. Cassandra, Postgres, Elastic). This should also be able to capture feedback data, so I can connect it to the specific texts directly.    \n3. Purge the structured storage after 1 month or so and put it into a S3 for future reference (we collect feedback data on which things were clicked to improve the system over time).  \n\n\nThe amount of daily data varies but its at least 50MB can go up to 500MB.   \n\n\nWhat are your thoughts on how you would set it up and what different components would you use? If you need any additional information feel free to reach out. ", "author_fullname": "t2_as93aiie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding the right data architecture for mostly text-based data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aeku01", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706608316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,   &lt;/p&gt;\n\n&lt;p&gt;At the moment, I am in the process of setting up a new data architecture with a focus on making it more scalable. My data is mostly text coming in from different sources (mostly internal, some external). Each piece of text has associated metadata fields directly stored with the text in a field and some metadata in additional tables (e.g. topics). There is quite a lot data coming in each week and the most recent data is always the most relevant.  &lt;/p&gt;\n\n&lt;p&gt;For each text, we also want to compute the embeddings to filter and find the most relevant texts within a topic (mostly a focus area within our enterprise) and make it available to the user. The relevant texts are then summarized and tagged with additional keywords to make the search easier. I could get around storing only the most recent relevant data (e.g. past month or quarter).   &lt;/p&gt;\n\n&lt;p&gt;I want to build it scalable and have the time to test a few different architectures and systems, but I would love to hear what other people think first.   &lt;/p&gt;\n\n&lt;p&gt;At the moment, I am thinking of something like this:&lt;br/&gt;\n1. NoSQL, where I parse in the entire data and all new incoming data (something like MongoDB).&lt;br/&gt;\n2. Something faster and more structured to store the &amp;quot;relevant texts&amp;quot; (e.g. Cassandra, Postgres, Elastic). This should also be able to capture feedback data, so I can connect it to the specific texts directly.&lt;br/&gt;\n3. Purge the structured storage after 1 month or so and put it into a S3 for future reference (we collect feedback data on which things were clicked to improve the system over time).  &lt;/p&gt;\n\n&lt;p&gt;The amount of daily data varies but its at least 50MB can go up to 500MB.   &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on how you would set it up and what different components would you use? If you need any additional information feel free to reach out. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aeku01", "is_robot_indexable": true, "report_reasons": null, "author": "SpiritedAd895", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aeku01/finding_the_right_data_architecture_for_mostly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aeku01/finding_the_right_data_architecture_for_mostly/", "subreddit_subscribers": 156924, "created_utc": 1706608316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nSorry for the long post, but I am not sure how to sum this up into a tl;dr.\n\nI am fairly early in my career, and I have been tasked with setting up a monitoring system that is able to provide visibility at the row level.\n\nFor clarification, the lead of my team wants to be able to pick an arbitrary row in a table and know exactly how long it took to get from the source to destination and the details at each step in between.\n\nThe concept is simple at a high level. It's just subtracting timestamps. However, we use a lot of no-code solutions that don't provide APIs or access to what's actually going on behind the scenes, and the source system metrics are closed to external use. Getting a creation time and visibility into each step is extremely difficult as I see it.\n\nI feel like time would be better spent fixing the architecture that is unstable instead of chasing a level of monitoring that I am not sure is even possible to create reliably due to manual exports of data and hacky code due to closed systems.\n\nHowever, maybe I am missing something obvious due to a lack of knowledge. I am the only data engineer and my boss isn't technical, so I am mostly on my own here.\n\nAny advice?\n\nThe current pipeline is SAP -&gt; Qlik Replicate -&gt; Databricks DLT -&gt; Synapse serverless.", "author_fullname": "t2_96mteoc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wasting Resources Chasing Dreams?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae2x5u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706554292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Sorry for the long post, but I am not sure how to sum this up into a tl;dr.&lt;/p&gt;\n\n&lt;p&gt;I am fairly early in my career, and I have been tasked with setting up a monitoring system that is able to provide visibility at the row level.&lt;/p&gt;\n\n&lt;p&gt;For clarification, the lead of my team wants to be able to pick an arbitrary row in a table and know exactly how long it took to get from the source to destination and the details at each step in between.&lt;/p&gt;\n\n&lt;p&gt;The concept is simple at a high level. It&amp;#39;s just subtracting timestamps. However, we use a lot of no-code solutions that don&amp;#39;t provide APIs or access to what&amp;#39;s actually going on behind the scenes, and the source system metrics are closed to external use. Getting a creation time and visibility into each step is extremely difficult as I see it.&lt;/p&gt;\n\n&lt;p&gt;I feel like time would be better spent fixing the architecture that is unstable instead of chasing a level of monitoring that I am not sure is even possible to create reliably due to manual exports of data and hacky code due to closed systems.&lt;/p&gt;\n\n&lt;p&gt;However, maybe I am missing something obvious due to a lack of knowledge. I am the only data engineer and my boss isn&amp;#39;t technical, so I am mostly on my own here.&lt;/p&gt;\n\n&lt;p&gt;Any advice?&lt;/p&gt;\n\n&lt;p&gt;The current pipeline is SAP -&amp;gt; Qlik Replicate -&amp;gt; Databricks DLT -&amp;gt; Synapse serverless.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ae2x5u", "is_robot_indexable": true, "report_reasons": null, "author": "kevrinth", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ae2x5u/wasting_resources_chasing_dreams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ae2x5u/wasting_resources_chasing_dreams/", "subreddit_subscribers": 156924, "created_utc": 1706554292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI've been in DE/DA field for 2 years now, and I'd like to start working with AWS. I'd like to get the \"AWS Certified Data Engineer\" certification to improve my resume and to find a good job easily. I've done few simple pipelines at my previous job, but nothing big, mainly using Appflow, S3, Athena, Redshift and Quicksight. So no Spark, no Kafka, no Glue. \n\nMy maine issue actually is : what path should I follow and what ressources should I use to prepare this exam ?\n\nThe AWS SkillBuilder recommands to get 2 certifications before this one : Foundational Cloud Practitioner and Associate Solutions Architect. Do I really have to get these 2 certifications first (especially the Associate one which is probably harder and more expensive) ? Or it won't bring me any value for the DE one and I can skip them, saving time and money ?\n\nFor these 3 certifications, there are a bunch of courses provided by AWS SkillBuilder for 29$/mo, is it good and worth buying/following ? And is it enough ?", "author_fullname": "t2_1cdu2cz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to prepare \"AWS Certified Data Engineer - Associate\" ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae2r8k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706553894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been in DE/DA field for 2 years now, and I&amp;#39;d like to start working with AWS. I&amp;#39;d like to get the &amp;quot;AWS Certified Data Engineer&amp;quot; certification to improve my resume and to find a good job easily. I&amp;#39;ve done few simple pipelines at my previous job, but nothing big, mainly using Appflow, S3, Athena, Redshift and Quicksight. So no Spark, no Kafka, no Glue. &lt;/p&gt;\n\n&lt;p&gt;My maine issue actually is : what path should I follow and what ressources should I use to prepare this exam ?&lt;/p&gt;\n\n&lt;p&gt;The AWS SkillBuilder recommands to get 2 certifications before this one : Foundational Cloud Practitioner and Associate Solutions Architect. Do I really have to get these 2 certifications first (especially the Associate one which is probably harder and more expensive) ? Or it won&amp;#39;t bring me any value for the DE one and I can skip them, saving time and money ?&lt;/p&gt;\n\n&lt;p&gt;For these 3 certifications, there are a bunch of courses provided by AWS SkillBuilder for 29$/mo, is it good and worth buying/following ? And is it enough ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ae2r8k", "is_robot_indexable": true, "report_reasons": null, "author": "imKrypex", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ae2r8k/how_to_prepare_aws_certified_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ae2r8k/how_to_prepare_aws_certified_data_engineer/", "subreddit_subscribers": 156924, "created_utc": 1706553894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently working in a project to start doing analytics and reporting of our company data, the data is in a cockroach DB instance and I plan on making a pipeline to incrementally move the data to Snowflake. But I don't know what should be a good approach to making this pipeline, I took a look at snowpipe and snowpark to move the data, but all the documentation I found relies on the use of a staging area, such as S3. My main concerns are:\n\n\\- How to incrementally move the CockroachDB data to a staging area\n\n\\- How to make transformations to alter the table schemas and relationships? Right now the CockroachDB is used as a OLTP database, I want to implement a star schema on Snowflake.\n\n&amp;#x200B;", "author_fullname": "t2_625bbvhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving data to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1adwv6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706539269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working in a project to start doing analytics and reporting of our company data, the data is in a cockroach DB instance and I plan on making a pipeline to incrementally move the data to Snowflake. But I don&amp;#39;t know what should be a good approach to making this pipeline, I took a look at snowpipe and snowpark to move the data, but all the documentation I found relies on the use of a staging area, such as S3. My main concerns are:&lt;/p&gt;\n\n&lt;p&gt;- How to incrementally move the CockroachDB data to a staging area&lt;/p&gt;\n\n&lt;p&gt;- How to make transformations to alter the table schemas and relationships? Right now the CockroachDB is used as a OLTP database, I want to implement a star schema on Snowflake.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1adwv6q", "is_robot_indexable": true, "report_reasons": null, "author": "Bira-of-louders", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adwv6q/moving_data_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adwv6q/moving_data_to_snowflake/", "subreddit_subscribers": 156924, "created_utc": 1706539269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Guys, does somebody know about any Databricks vouchers in 2024.\nI don\u2019t see so far that Databricks events on databricks.com/events offer it this year. Maybe there are other resources where you can get it?!", "author_fullname": "t2_p4w5948ch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks voucher certificate in 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ael37k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706609390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys, does somebody know about any Databricks vouchers in 2024.\nI don\u2019t see so far that Databricks events on databricks.com/events offer it this year. Maybe there are other resources where you can get it?!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ael37k", "is_robot_indexable": true, "report_reasons": null, "author": "fearlessevy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ael37k/databricks_voucher_certificate_in_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ael37k/databricks_voucher_certificate_in_2024/", "subreddit_subscribers": 156924, "created_utc": 1706609390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uwe2fsd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Maps Web Scraping: 3 Practical Use Cases and How to Make the Most of Them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1aedw84", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/f8g_U5jBsJM2NEpGIUDWiYZcTFPXGTuOLB2SlNkfK3k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706582904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://plainenglish.io/community/google-maps-web-scraping-3-practical-use-cases-and-how-to-make-the-most-of-them-marcoacavaco-rodrigues-gmail-com-1700744574311", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ngNy0twZ9PucNZE5BSURJzeMDm0NyXIJbY9y18tB90I.jpg?auto=webp&amp;s=46d33550cc81f9decd30fc91d60f6d2eeb67d612", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ngNy0twZ9PucNZE5BSURJzeMDm0NyXIJbY9y18tB90I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cac97fdd038cc2a317548d28ca7e8c67e25d359", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ngNy0twZ9PucNZE5BSURJzeMDm0NyXIJbY9y18tB90I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17bd1c7742d995fe6de3bdf8b35eeaf0fb7bbd5d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ngNy0twZ9PucNZE5BSURJzeMDm0NyXIJbY9y18tB90I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=67aace18bb950eb12834c9d34e6c62d5ea85fec2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ngNy0twZ9PucNZE5BSURJzeMDm0NyXIJbY9y18tB90I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7bcb8328a6c4d241ae19d9f1c42540e44059486e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ngNy0twZ9PucNZE5BSURJzeMDm0NyXIJbY9y18tB90I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=95819aa2b0595c6080f137c4b7c50287242c2787", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ngNy0twZ9PucNZE5BSURJzeMDm0NyXIJbY9y18tB90I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9ec8499ad5ccce921e23e6417b7f23f5ba77d7c4", "width": 1080, "height": 567}], "variants": {}, "id": "XyWQAoZBD9EGqALl6yef2IcN-kJAsS4GMso9KUxnV-M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aedw84", "is_robot_indexable": true, "report_reasons": null, "author": "TheLostWanderer47", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aedw84/google_maps_web_scraping_3_practical_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://plainenglish.io/community/google-maps-web-scraping-3-practical-use-cases-and-how-to-make-the-most-of-them-marcoacavaco-rodrigues-gmail-com-1700744574311", "subreddit_subscribers": 156924, "created_utc": 1706582904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am not sure what to expect, if any of you have gone through mid/senior interviews, what do you suggest I prepare for?  (e.g. DS&amp;Algo Leetcode style then Medium/Hard questions? etc)", "author_fullname": "t2_3tzpeuhd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do data engineer interviews (mid/senior) look like at hedge funds?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae5l9n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706560835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not sure what to expect, if any of you have gone through mid/senior interviews, what do you suggest I prepare for?  (e.g. DS&amp;amp;Algo Leetcode style then Medium/Hard questions? etc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ae5l9n", "is_robot_indexable": true, "report_reasons": null, "author": "randomusicjunkie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ae5l9n/what_do_data_engineer_interviews_midsenior_look/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ae5l9n/what_do_data_engineer_interviews_midsenior_look/", "subreddit_subscribers": 156924, "created_utc": 1706560835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For over 8 years, I've been using Laravel daily. One of the gaps I currently feel in the Geoglify stack is the ease of organizing initial data and automatically populating the database, as I do with Laravel Seed. Therefore, I created a small example for MongoDB. This example allows for a straightforward addition of static data related to ships, ports, zones, and more to MongoDB.", "author_fullname": "t2_7svy5qp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Initializing MongoDB with JSON Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1ae37fb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/1d_bJ-kMqLDpO6iJ3U2REgS6a30wsr3yupAaSsutzD0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706554983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "geoglify.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For over 8 years, I&amp;#39;ve been using Laravel daily. One of the gaps I currently feel in the Geoglify stack is the ease of organizing initial data and automatically populating the database, as I do with Laravel Seed. Therefore, I created a small example for MongoDB. This example allows for a straightforward addition of static data related to ships, ports, zones, and more to MongoDB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.geoglify.com/blog/initial-seed-mongodb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eu2M4QjAnh9nLNf_PELZn0_FDJ8R4yN1XSoXHUjJVOQ.jpg?auto=webp&amp;s=3cc2c6acaae95b98a6c8f39545bd7e504d78f55a", "width": 1479, "height": 827}, "resolutions": [{"url": "https://external-preview.redd.it/eu2M4QjAnh9nLNf_PELZn0_FDJ8R4yN1XSoXHUjJVOQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b837534f089c8820261cfcb889dc11563e14a1ef", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/eu2M4QjAnh9nLNf_PELZn0_FDJ8R4yN1XSoXHUjJVOQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c7d18d2b443100a6f929670b845f1fe883035b0", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/eu2M4QjAnh9nLNf_PELZn0_FDJ8R4yN1XSoXHUjJVOQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a468b2ac0110bf2609f4c73260f416432055526", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/eu2M4QjAnh9nLNf_PELZn0_FDJ8R4yN1XSoXHUjJVOQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4559439083657794f464663ef64746dbdbd4b90b", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/eu2M4QjAnh9nLNf_PELZn0_FDJ8R4yN1XSoXHUjJVOQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d0d605e28f3189116727cc02990acd2efc3a3c8a", "width": 960, "height": 536}, {"url": "https://external-preview.redd.it/eu2M4QjAnh9nLNf_PELZn0_FDJ8R4yN1XSoXHUjJVOQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b351ac9b40ab82a3ab6e0790369310db29a4da8", "width": 1080, "height": 603}], "variants": {}, "id": "avzTdEtIlyrGjuhStoUYXVeh_K8zC4M5WXCGDLZ_9L8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1ae37fb", "is_robot_indexable": true, "report_reasons": null, "author": "leoneljdias", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ae37fb/initializing_mongodb_with_json_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.geoglify.com/blog/initial-seed-mongodb", "subreddit_subscribers": 156924, "created_utc": 1706554983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!  \n\n\nWhat recommendations do you have for automatic exposures &amp; lineage for dbt &gt; bigquery &gt; looker studio (not looker).\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_gdhnbh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lineage Options/Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aenokc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706619057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!  &lt;/p&gt;\n\n&lt;p&gt;What recommendations do you have for automatic exposures &amp;amp; lineage for dbt &amp;gt; bigquery &amp;gt; looker studio (not looker).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aenokc", "is_robot_indexable": true, "report_reasons": null, "author": "Major-Car342", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aenokc/data_lineage_optionstools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aenokc/data_lineage_optionstools/", "subreddit_subscribers": 156924, "created_utc": 1706619057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a semi technical PM working on a new solution for our BI, analytics, and data science capabilities.\n\nRecommended tools and technologies? \n\nImportant questions to ask?\n\nPitfalls to avoid?\n\n\nContext:\n\n\u2022 Mix of on prem home brewed applications and modern cloud SaaS apps\n\n\u2022 Need to report data blended between HRIS, ERP, Etc. \n\n\u2022 99% structured data with a few images files etc. \n\n\u2022 Limited need for real-time, batch should be sufficient for most use cases\n\n\u2022 Previous investment in Microsoft: Azure, Power BI, Office 365, AAD, etc. \n\n\u2022 Org is very risk averse and conservative with data privacy and innovation", "author_fullname": "t2_22omtog9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solution design recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1aemmsy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706615452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a semi technical PM working on a new solution for our BI, analytics, and data science capabilities.&lt;/p&gt;\n\n&lt;p&gt;Recommended tools and technologies? &lt;/p&gt;\n\n&lt;p&gt;Important questions to ask?&lt;/p&gt;\n\n&lt;p&gt;Pitfalls to avoid?&lt;/p&gt;\n\n&lt;p&gt;Context:&lt;/p&gt;\n\n&lt;p&gt;\u2022 Mix of on prem home brewed applications and modern cloud SaaS apps&lt;/p&gt;\n\n&lt;p&gt;\u2022 Need to report data blended between HRIS, ERP, Etc. &lt;/p&gt;\n\n&lt;p&gt;\u2022 99% structured data with a few images files etc. &lt;/p&gt;\n\n&lt;p&gt;\u2022 Limited need for real-time, batch should be sufficient for most use cases&lt;/p&gt;\n\n&lt;p&gt;\u2022 Previous investment in Microsoft: Azure, Power BI, Office 365, AAD, etc. &lt;/p&gt;\n\n&lt;p&gt;\u2022 Org is very risk averse and conservative with data privacy and innovation&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aemmsy", "is_robot_indexable": true, "report_reasons": null, "author": "Heroic_Self", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aemmsy/solution_design_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aemmsy/solution_design_recommendations/", "subreddit_subscribers": 156924, "created_utc": 1706615452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, we\u2019re relatively a young team. So we have loads of json data, csv data related to vehicles how all devices work in the vehicle. The manufacturer of the devices, their power rating etc. \n\nWe have information from the basic till the vehicle is fully assembled and given to a customer. The variants of the vehicle etc. So basically we have loads of data spread across json, csv and confluence pages. \n\nData tracking is getting hard and when customers come to us with some problems, it\u2019s hard to track which vehicle has what stuff in it to get to the root cause of the problem. \n\nNow we are planning to move towards a cloud solution? Maybe have a database and then a dashboard of how many vehicles are being assembled, already assembled, how many have what devices? Something like that, basically so we know that everything is documented and can be tracked. Also need to link Jira tickets to this system.\n\nWhat solution would you guys suggest for this? I\u2019m thinking of services from AWS/ Azure? Sorry I am new to this and not sure how to find solutions for this. \n\nThanks in advance for the help!", "author_fullname": "t2_gdjxkf2v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions for database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aeknta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706607564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, we\u2019re relatively a young team. So we have loads of json data, csv data related to vehicles how all devices work in the vehicle. The manufacturer of the devices, their power rating etc. &lt;/p&gt;\n\n&lt;p&gt;We have information from the basic till the vehicle is fully assembled and given to a customer. The variants of the vehicle etc. So basically we have loads of data spread across json, csv and confluence pages. &lt;/p&gt;\n\n&lt;p&gt;Data tracking is getting hard and when customers come to us with some problems, it\u2019s hard to track which vehicle has what stuff in it to get to the root cause of the problem. &lt;/p&gt;\n\n&lt;p&gt;Now we are planning to move towards a cloud solution? Maybe have a database and then a dashboard of how many vehicles are being assembled, already assembled, how many have what devices? Something like that, basically so we know that everything is documented and can be tracked. Also need to link Jira tickets to this system.&lt;/p&gt;\n\n&lt;p&gt;What solution would you guys suggest for this? I\u2019m thinking of services from AWS/ Azure? Sorry I am new to this and not sure how to find solutions for this. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aeknta", "is_robot_indexable": true, "report_reasons": null, "author": "Informal_Poem_4394", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aeknta/solutions_for_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aeknta/solutions_for_database/", "subreddit_subscribers": 156924, "created_utc": 1706607564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nTL;DR For building a profiling platform similar to LinkedIn (but on a smaller scale) for customers and vehicles of a car rental company, do we need a dimensional model? Also, should we go for a columnar or row-oriented database?\n\n\\------------------------------------------------------------------------------------\n\nI'm a data analyst and I found myself in a position where I'm leading the data engineering part in a project. I can quite well handle the ELT tasks. However, I'm facing some difficulties in data architecture and choosing the most suitable database tool. I spent the last week googling and researching but couldn't find a clear answer.\n\nI'm working on a project where the client wants to build a profile system for a car rental company (something like LinkedIn but in a smaller scale) for their customers and vehicles. The database will feed a platform where the user can search for a customer or a vehicle based on some parameters (customer number, customer name, age, vehicle plate, license expiry date etc). The webpage will show a profile with more than 12 sections (e.g. demographic, educational, economic etc depends on whether the user is searching for a customer or a vehicle profile) and each section displays tens or sometimes hundreds of attributes for that single profile. The data has around 30-50 million customers and 2-3 million vehicles.\n\nAll this data is stored in more than source 120 tables. The tables are divided into customers tables and vehicles tables. All customer tables contain customer\\_ids and all vehicle tables contain vehicle\\_ids. The main vehicle table contains also the customer\\_id as a foreign key. So linking the tables is easy here.\n\nNow, I'm facing two questions. The first is how should I model the schema for this system. My co-worker thinks that a dimensional model will optimize the query performance. However, I think that a relational model or maybe 2 OBTs (one for customers and another for vehicles) might be sufficient. I see no benefit of using a dimensional model here since the platform won't display any aggregations or analytical query results.\n\nThe second question is whether we should go for a columnar database or just a normal row-oriented database. What I know is that columnar database can significantly speed the query performance but that is for analytical queries, not queries like what we need for this system. Is that right?  \n\n\nI tried to add all the details that I have. If you have any more questions please feel free to ask. I'd really appreciate every feedback. ", "author_fullname": "t2_91yem840g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dimensional or Relational AND Columnar or Row-oriented Database for Profiling System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aejqzh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706603660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR For building a profiling platform similar to LinkedIn (but on a smaller scale) for customers and vehicles of a car rental company, do we need a dimensional model? Also, should we go for a columnar or row-oriented database?&lt;/p&gt;\n\n&lt;p&gt;------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data analyst and I found myself in a position where I&amp;#39;m leading the data engineering part in a project. I can quite well handle the ELT tasks. However, I&amp;#39;m facing some difficulties in data architecture and choosing the most suitable database tool. I spent the last week googling and researching but couldn&amp;#39;t find a clear answer.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a project where the client wants to build a profile system for a car rental company (something like LinkedIn but in a smaller scale) for their customers and vehicles. The database will feed a platform where the user can search for a customer or a vehicle based on some parameters (customer number, customer name, age, vehicle plate, license expiry date etc). The webpage will show a profile with more than 12 sections (e.g. demographic, educational, economic etc depends on whether the user is searching for a customer or a vehicle profile) and each section displays tens or sometimes hundreds of attributes for that single profile. The data has around 30-50 million customers and 2-3 million vehicles.&lt;/p&gt;\n\n&lt;p&gt;All this data is stored in more than source 120 tables. The tables are divided into customers tables and vehicles tables. All customer tables contain customer_ids and all vehicle tables contain vehicle_ids. The main vehicle table contains also the customer_id as a foreign key. So linking the tables is easy here.&lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;m facing two questions. The first is how should I model the schema for this system. My co-worker thinks that a dimensional model will optimize the query performance. However, I think that a relational model or maybe 2 OBTs (one for customers and another for vehicles) might be sufficient. I see no benefit of using a dimensional model here since the platform won&amp;#39;t display any aggregations or analytical query results.&lt;/p&gt;\n\n&lt;p&gt;The second question is whether we should go for a columnar database or just a normal row-oriented database. What I know is that columnar database can significantly speed the query performance but that is for analytical queries, not queries like what we need for this system. Is that right?  &lt;/p&gt;\n\n&lt;p&gt;I tried to add all the details that I have. If you have any more questions please feel free to ask. I&amp;#39;d really appreciate every feedback. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aejqzh", "is_robot_indexable": true, "report_reasons": null, "author": "Historical-Hyena4643", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aejqzh/dimensional_or_relational_and_columnar_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aejqzh/dimensional_or_relational_and_columnar_or/", "subreddit_subscribers": 156924, "created_utc": 1706603660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working in the data analytics field for about 2-3 yrs now (ETL process using python, PowerBI, and other BI tools) and I want to expand my skillset that involves DE processes. What tools or sites do you recommend where I can learn and practice the above? \n\n(I work in consulting so I have a choice in the types of projects that I want to take on and that\u2019s obviously granted I have some experience and capability to do those said projects)", "author_fullname": "t2_6gfchy9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online DE projects or sites that can help me gain more DEing skills than only data analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aejj5l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706602731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working in the data analytics field for about 2-3 yrs now (ETL process using python, PowerBI, and other BI tools) and I want to expand my skillset that involves DE processes. What tools or sites do you recommend where I can learn and practice the above? &lt;/p&gt;\n\n&lt;p&gt;(I work in consulting so I have a choice in the types of projects that I want to take on and that\u2019s obviously granted I have some experience and capability to do those said projects)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aejj5l", "is_robot_indexable": true, "report_reasons": null, "author": "earlyiteration", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aejj5l/online_de_projects_or_sites_that_can_help_me_gain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aejj5l/online_de_projects_or_sites_that_can_help_me_gain/", "subreddit_subscribers": 156924, "created_utc": 1706602731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I am a SWE at a B2B SaaS company and my PM asked me to classify our customer feedback into Feature Requests, Bugs, and Reviews. I built a model but it does not work. Are there any models I can use? Any suggestions? I am on a time clock.\n\nThanks!", "author_fullname": "t2_nvnticro", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Classify our customer feedback into Feature Requests, Bugs, and Reviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aehll2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706594942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I am a SWE at a B2B SaaS company and my PM asked me to classify our customer feedback into Feature Requests, Bugs, and Reviews. I built a model but it does not work. Are there any models I can use? Any suggestions? I am on a time clock.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aehll2", "is_robot_indexable": true, "report_reasons": null, "author": "Scary-Swing2852", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aehll2/classify_our_customer_feedback_into_feature/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aehll2/classify_our_customer_feedback_into_feature/", "subreddit_subscribers": 156924, "created_utc": 1706594942.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}