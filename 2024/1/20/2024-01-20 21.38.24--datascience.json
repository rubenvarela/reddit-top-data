{"kind": "Listing", "data": {"after": null, "dist": 4, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking to get into anything and all things related to supply chain data, but don\u2019t know where to best look for data, even to buy. I\u2019m interested in vendors and suppliers, B2B , international trade, investor relationships. Really any data I can get my hands on that can allow me to map international supply chain.", "author_fullname": "t2_q87mqvk0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know where to get ahold of supply chain related datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b78z1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705739549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to get into anything and all things related to supply chain data, but don\u2019t know where to best look for data, even to buy. I\u2019m interested in vendors and suppliers, B2B , international trade, investor relationships. Really any data I can get my hands on that can allow me to map international supply chain.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "19b78z1", "is_robot_indexable": true, "report_reasons": null, "author": "drrednirgskizif", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/19b78z1/anyone_know_where_to_get_ahold_of_supply_chain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/19b78z1/anyone_know_where_to_get_ahold_of_supply_chain/", "subreddit_subscribers": 1261592, "created_utc": 1705739549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I graduated from stats/maths with double major and have data science master's degree from a prestigious uni. Working in Fortune 500 companies for the last 8 years as data analyst, data product owner and data scientist positions. \n\nIn the last 3 years, I lost my job (as a data scientist) twice. The first one decided to change the structure, instead of a team of 10 data scientists, they formed a new team of 1 ml engineer, 1 data engineer, 1 mlops engineer, and 5 data analysts to save cost. The second one reduced the team of 10 data scientists to 3 and hired the rest 7 from India. \n\nAfter having 2 lay-off in the last 3 years I decided to pivot to a more human-based role. I feel like jobs in tech positions are always changing and it's hard for me to keep up. I want to move to a business/system analyst job, or project manager role prbably in finance or audit department. These roles are hard to automate by ai they don't fall out of trend like data science. Any suggestions? ", "author_fullname": "t2_tg4tyljh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "thinking of pivoting from Data Scientist to a Business/System Analyst - Project Manager role. What do you think? [EUROPE]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19biv8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705776847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated from stats/maths with double major and have data science master&amp;#39;s degree from a prestigious uni. Working in Fortune 500 companies for the last 8 years as data analyst, data product owner and data scientist positions. &lt;/p&gt;\n\n&lt;p&gt;In the last 3 years, I lost my job (as a data scientist) twice. The first one decided to change the structure, instead of a team of 10 data scientists, they formed a new team of 1 ml engineer, 1 data engineer, 1 mlops engineer, and 5 data analysts to save cost. The second one reduced the team of 10 data scientists to 3 and hired the rest 7 from India. &lt;/p&gt;\n\n&lt;p&gt;After having 2 lay-off in the last 3 years I decided to pivot to a more human-based role. I feel like jobs in tech positions are always changing and it&amp;#39;s hard for me to keep up. I want to move to a business/system analyst job, or project manager role prbably in finance or audit department. These roles are hard to automate by ai they don&amp;#39;t fall out of trend like data science. Any suggestions? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19biv8v", "is_robot_indexable": true, "report_reasons": null, "author": "Good_Old_Days_92", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/19biv8v/thinking_of_pivoting_from_data_scientist_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/19biv8v/thinking_of_pivoting_from_data_scientist_to_a/", "subreddit_subscribers": 1261592, "created_utc": 1705776847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to predict the conversion rate of company defined groups of customers for various product offers. The company clusters customers into Q groups (these groups overlap) and want to know if we can predict conversion rate (using regression) when offering product Y. I can also potentially model the problem as binary classification  at the customer level and aggregate up later but at the moment I\u2019m modeling @ the customer clustering level (predict conversion rate based on features of each of the Q customer groups)\n\nI have access to historical purchase behaviors of customers and purchase volumes and what not for each product.\n\nEach row of my training set looks like this:\nDesign matrix:\n- Features describing last N days purchase volumes for the cluster of customers (historical purchases before time of marketing offer being made)\n- Features describing what proportion of customers bought similar products before the current product offer (similar products defined by nearest K neighbors of product description embedding)\n\nLabels:\n- the conversion rate of that customer clustering which can be interpreted as a probability\n\nMy question is should I split the training data to be product offers before CUTOFF date and test examples to be after CUTOFF date?\n\nI think that that is potentially the most realistic and anti leakage proof split but I only have 3 years of purchase data and 1 year was covid + 1 year was recession + inflation. Im afraid that doing time splits I will make the test set have substantial seasonal differences and also macroeconomic differences than train set\n\nConceptually speaking i see no issue with doing a true random train test split of all product offers in 2023. Since each training / testing data row only has features calculated from historical (before the label was ever calculated) purchases. But I am worried that I am missing something and may have leakage. I am not experienced in running and leading projects myself so I want to ensure I am being rigorous and thoughtful\n\nTo make things a little more interesting, i need to model both new products and existing products. So i might even make a separate dataset for new product campaigns vs existing campaigns but I am not sure what\u2019s the best approach here\n\nWould love tips and guidance here!!\n\nSide note: yes i could model this as a recommender system problem and build a complicated solution but my company is not a tech company and i am working with a single laptop no cloud. Id rather see if i can make progress in supervised learning framework first", "author_fullname": "t2_z1sj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make a proper train test split", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19au18t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705699051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to predict the conversion rate of company defined groups of customers for various product offers. The company clusters customers into Q groups (these groups overlap) and want to know if we can predict conversion rate (using regression) when offering product Y. I can also potentially model the problem as binary classification  at the customer level and aggregate up later but at the moment I\u2019m modeling @ the customer clustering level (predict conversion rate based on features of each of the Q customer groups)&lt;/p&gt;\n\n&lt;p&gt;I have access to historical purchase behaviors of customers and purchase volumes and what not for each product.&lt;/p&gt;\n\n&lt;p&gt;Each row of my training set looks like this:\nDesign matrix:\n- Features describing last N days purchase volumes for the cluster of customers (historical purchases before time of marketing offer being made)\n- Features describing what proportion of customers bought similar products before the current product offer (similar products defined by nearest K neighbors of product description embedding)&lt;/p&gt;\n\n&lt;p&gt;Labels:\n- the conversion rate of that customer clustering which can be interpreted as a probability&lt;/p&gt;\n\n&lt;p&gt;My question is should I split the training data to be product offers before CUTOFF date and test examples to be after CUTOFF date?&lt;/p&gt;\n\n&lt;p&gt;I think that that is potentially the most realistic and anti leakage proof split but I only have 3 years of purchase data and 1 year was covid + 1 year was recession + inflation. Im afraid that doing time splits I will make the test set have substantial seasonal differences and also macroeconomic differences than train set&lt;/p&gt;\n\n&lt;p&gt;Conceptually speaking i see no issue with doing a true random train test split of all product offers in 2023. Since each training / testing data row only has features calculated from historical (before the label was ever calculated) purchases. But I am worried that I am missing something and may have leakage. I am not experienced in running and leading projects myself so I want to ensure I am being rigorous and thoughtful&lt;/p&gt;\n\n&lt;p&gt;To make things a little more interesting, i need to model both new products and existing products. So i might even make a separate dataset for new product campaigns vs existing campaigns but I am not sure what\u2019s the best approach here&lt;/p&gt;\n\n&lt;p&gt;Would love tips and guidance here!!&lt;/p&gt;\n\n&lt;p&gt;Side note: yes i could model this as a recommender system problem and build a complicated solution but my company is not a tech company and i am working with a single laptop no cloud. Id rather see if i can make progress in supervised learning framework first&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "19au18t", "is_robot_indexable": true, "report_reasons": null, "author": "slimsippin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/19au18t/how_to_make_a_proper_train_test_split/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/19au18t/how_to_make_a_proper_train_test_split/", "subreddit_subscribers": 1261592, "created_utc": 1705699051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There's an AI right now that has been trending in its ability to solve data science problems, it is called Julius AI, it allows for a free 10 questions per month to an account. \n\nI've personally used it and its ability to solve problems is incredible, but it is powered by GPT4. \n\nI've never used GPT4 to test the difference, so my question is for those who have used GPT4 or tried both AIs, is Julius worth it more than GPT4, does GPT4 has an advantage on Julius in data science or data analysis? \n\nAlso note that the proper plan of Julius is about 40$ per month for unlimited messages which is double of that for GPT4.\n\nSo what would you recommend? Should I go for it? \n\nThanks for your reply in advance\u270c\ufe0f", "author_fullname": "t2_l8jdxq43u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Julius AI worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19awedm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705705027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s an AI right now that has been trending in its ability to solve data science problems, it is called Julius AI, it allows for a free 10 questions per month to an account. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve personally used it and its ability to solve problems is incredible, but it is powered by GPT4. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve never used GPT4 to test the difference, so my question is for those who have used GPT4 or tried both AIs, is Julius worth it more than GPT4, does GPT4 has an advantage on Julius in data science or data analysis? &lt;/p&gt;\n\n&lt;p&gt;Also note that the proper plan of Julius is about 40$ per month for unlimited messages which is double of that for GPT4.&lt;/p&gt;\n\n&lt;p&gt;So what would you recommend? Should I go for it? &lt;/p&gt;\n\n&lt;p&gt;Thanks for your reply in advance\u270c\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "19awedm", "is_robot_indexable": true, "report_reasons": null, "author": "Darktrader21", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/19awedm/is_julius_ai_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/19awedm/is_julius_ai_worth_it/", "subreddit_subscribers": 1261592, "created_utc": 1705705027.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}