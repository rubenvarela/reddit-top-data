{"kind": "Listing", "data": {"after": null, "dist": 7, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a background in medical research. I'm getting confused with data science terminology. Is causal inference the same in medical research and data science? So you do eg an RCT to determine treatment effect then Treatment effect = (Outcome under E) minus (Outcome under C)?\n\nOr in data science I guess it's A/B testing and measuring the effect when people are randomised to A or B. How do you use it?\n\nWhen I first heard of it I thought it was a way of determining a causative relationship when looking at correlation and teasing out confounders but I think you'd still need to do an RCT to prove the relationship, otherwise there's still the risk of reverse causality or confounders.", "author_fullname": "t2_d51zenrcx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What exactly is causal inference? How do you use it in your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xtii1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Statistics", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704314563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a background in medical research. I&amp;#39;m getting confused with data science terminology. Is causal inference the same in medical research and data science? So you do eg an RCT to determine treatment effect then Treatment effect = (Outcome under E) minus (Outcome under C)?&lt;/p&gt;\n\n&lt;p&gt;Or in data science I guess it&amp;#39;s A/B testing and measuring the effect when people are randomised to A or B. How do you use it?&lt;/p&gt;\n\n&lt;p&gt;When I first heard of it I thought it was a way of determining a causative relationship when looking at correlation and teasing out confounders but I think you&amp;#39;d still need to do an RCT to prove the relationship, otherwise there&amp;#39;s still the risk of reverse causality or confounders.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "370e8fc0-70eb-11ee-b58a-86a96bfd3389", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#94e044", "id": "18xtii1", "is_robot_indexable": true, "report_reasons": null, "author": "InsightSeeker99", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18xtii1/what_exactly_is_causal_inference_how_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18xtii1/what_exactly_is_causal_inference_how_do_you_use/", "subreddit_subscribers": 1224830, "created_utc": 1704314563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Over the last 10 months, the [Tidier.jl](https://github.com/TidierOrg) team has implemented nearly all of the the tidyverse\u2019s critical infrastructure/features.\n\nOut of curiosity, I did some benchmarking on 6 million rows and [TidierData.jl](https://tidierorg.github.io/TidierData.jl/latest/) it was as fast as DataFrames.jl (the backend for TidierData.jl)  for everything except  summarize.. that would put it in the top 5 on duckdb [benchmarks](https://duckdb.org/2023/11/03/db-benchmark-update.html#results) for 5 and 50gb.\n\nAlso, [chaining](https://github.com/TidierOrg/TidierCourse/blob/main/what-is-tidier-jl/what-is-tidier-jl.ipynb) plots directly into data manipulation like ggplot2 is supported with [TidierPlots.jl](https://github.com/TidierOrg/TidierPlots.jl).  and TidierPlots.jl is literally 1 character different from ggplot2\n\nPlus, they also have a tidytext equivalent for text - [TidierText.jl](https://github.com/TidierOrg/TidierText.jl), all in addition to support packages for dates, categorical variables, strings, and web scraping!\n\nThe lead dev makes an interesting point in the [readme](https://tidierorg.github.io/Tidier.jl/dev/) about why use Julia and its potential to be a fast glue language. It looks like he\u2019s also building a course?\n\nI\u2019m curious what you all think? Could Julia be fast glue language? Could you ever find ways to work Julia into your workflows? Also what do you all think of this metapackage?", "author_fullname": "t2_bb216nh2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tidier.jl, Julia\u2019s tidyverse is fast and extensive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xnvg4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704303098.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704300722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the last 10 months, the &lt;a href=\"https://github.com/TidierOrg\"&gt;Tidier.jl&lt;/a&gt; team has implemented nearly all of the the tidyverse\u2019s critical infrastructure/features.&lt;/p&gt;\n\n&lt;p&gt;Out of curiosity, I did some benchmarking on 6 million rows and &lt;a href=\"https://tidierorg.github.io/TidierData.jl/latest/\"&gt;TidierData.jl&lt;/a&gt; it was as fast as DataFrames.jl (the backend for TidierData.jl)  for everything except  summarize.. that would put it in the top 5 on duckdb &lt;a href=\"https://duckdb.org/2023/11/03/db-benchmark-update.html#results\"&gt;benchmarks&lt;/a&gt; for 5 and 50gb.&lt;/p&gt;\n\n&lt;p&gt;Also, &lt;a href=\"https://github.com/TidierOrg/TidierCourse/blob/main/what-is-tidier-jl/what-is-tidier-jl.ipynb\"&gt;chaining&lt;/a&gt; plots directly into data manipulation like ggplot2 is supported with &lt;a href=\"https://github.com/TidierOrg/TidierPlots.jl\"&gt;TidierPlots.jl&lt;/a&gt;.  and TidierPlots.jl is literally 1 character different from ggplot2&lt;/p&gt;\n\n&lt;p&gt;Plus, they also have a tidytext equivalent for text - &lt;a href=\"https://github.com/TidierOrg/TidierText.jl\"&gt;TidierText.jl&lt;/a&gt;, all in addition to support packages for dates, categorical variables, strings, and web scraping!&lt;/p&gt;\n\n&lt;p&gt;The lead dev makes an interesting point in the &lt;a href=\"https://tidierorg.github.io/Tidier.jl/dev/\"&gt;readme&lt;/a&gt; about why use Julia and its potential to be a fast glue language. It looks like he\u2019s also building a course?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what you all think? Could Julia be fast glue language? Could you ever find ways to work Julia into your workflows? Also what do you all think of this metapackage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-eZ_6WE8_cJnoXg4ArVRvygUCZpGyShgswp3J0lqa6w.jpg?auto=webp&amp;s=b1ce39dec021814d2bb819ac460a213bcd346618", "width": 280, "height": 280}, "resolutions": [{"url": "https://external-preview.redd.it/-eZ_6WE8_cJnoXg4ArVRvygUCZpGyShgswp3J0lqa6w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e354063d9f0c9173e405b72ee3fc2b01d3a0900b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-eZ_6WE8_cJnoXg4ArVRvygUCZpGyShgswp3J0lqa6w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9907c4ef81183cdde4ab2f9fb427225f3837dc4f", "width": 216, "height": 216}], "variants": {}, "id": "bG1-1JNmjbQX5lLHqr-NJFM22-YuqxBHUPkt5nifS-A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "18xnvg4", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious-Oil6672", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18xnvg4/tidierjl_julias_tidyverse_is_fast_and_extensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18xnvg4/tidierjl_julias_tidyverse_is_fast_and_extensive/", "subreddit_subscribers": 1224830, "created_utc": 1704300722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Have a client churn model that seems to be constantly drifting over the past year because what would previously be perfectly healthy clients are canceling randomly, which has meant less consistent patterns for training and more frequent model drift.\n\nYet another reason why it would be nice for things to stabilize.", "author_fullname": "t2_53o3zuz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else B2B finding the tech recession is messing w their models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y1zqa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704335951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a client churn model that seems to be constantly drifting over the past year because what would previously be perfectly healthy clients are canceling randomly, which has meant less consistent patterns for training and more frequent model drift.&lt;/p&gt;\n\n&lt;p&gt;Yet another reason why it would be nice for things to stabilize.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "18y1zqa", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Tooth_501", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18y1zqa/anyone_else_b2b_finding_the_tech_recession_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18y1zqa/anyone_else_b2b_finding_the_tech_recession_is/", "subreddit_subscribers": 1224830, "created_utc": 1704335951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, \n\nI\u2019m trying to really get in to the nuts and bolts of pymc but I feel like my python is lacking. Somehow there\u2019s a bunch of syntax I don\u2019t ever see day to day. One example is learning about the different number of \u201c_\u201d before methods has a meaning. Or even something more simple on how the package is structured so that it can call method from different files within the package.\n\nThe whole thing makes me really feel like I probably suck at programming but hey at least I have something to work on, thanks in advance", "author_fullname": "t2_3kdgnq0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning more python to understand modules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xmapb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704296495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to really get in to the nuts and bolts of pymc but I feel like my python is lacking. Somehow there\u2019s a bunch of syntax I don\u2019t ever see day to day. One example is learning about the different number of \u201c_\u201d before methods has a meaning. Or even something more simple on how the package is structured so that it can call method from different files within the package.&lt;/p&gt;\n\n&lt;p&gt;The whole thing makes me really feel like I probably suck at programming but hey at least I have something to work on, thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "18xmapb", "is_robot_indexable": true, "report_reasons": null, "author": "Jbor941197", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18xmapb/learning_more_python_to_understand_modules/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18xmapb/learning_more_python_to_understand_modules/", "subreddit_subscribers": 1224830, "created_utc": 1704296495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Some teams in my organization have empowered data scientists to explore and develop AI/ML use cases, which is a positive initiative. However, we have noticed that this freedom has led to an experimentation spree, resulting in unnecessary expenses and resource allocation. The new data scientists are insisting on expensive software and cloud technologies that are straining our annual budget. \n\nThis has caused some concern among the more experienced cross-functional data science teams, who believe that the leadership's generosity towards the new data scientists is misplaced. They feel that these inexperienced data scientists are pursuing impractical ideas that do not contribute to the business effectively. \n\nAdditionally, the new data scientists seem uninterested to take-up any other analytical work apart from coding in Jupyter NBs. While it is important for data scientists to experiment, there needs to be a balance and clarity on when to focus and when to halt. We also need guidelines in place to prevent inexperienced data scientists from pursuing use cases that do not provide value to the business.\n\nAny suggestions?", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you detect when a data scientist is chasing a wild goose? And how do you prevent them from consuming company resouces unnecessarily?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y9xbd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704363731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some teams in my organization have empowered data scientists to explore and develop AI/ML use cases, which is a positive initiative. However, we have noticed that this freedom has led to an experimentation spree, resulting in unnecessary expenses and resource allocation. The new data scientists are insisting on expensive software and cloud technologies that are straining our annual budget. &lt;/p&gt;\n\n&lt;p&gt;This has caused some concern among the more experienced cross-functional data science teams, who believe that the leadership&amp;#39;s generosity towards the new data scientists is misplaced. They feel that these inexperienced data scientists are pursuing impractical ideas that do not contribute to the business effectively. &lt;/p&gt;\n\n&lt;p&gt;Additionally, the new data scientists seem uninterested to take-up any other analytical work apart from coding in Jupyter NBs. While it is important for data scientists to experiment, there needs to be a balance and clarity on when to focus and when to halt. We also need guidelines in place to prevent inexperienced data scientists from pursuing use cases that do not provide value to the business.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18y9xbd", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18y9xbd/how_do_you_detect_when_a_data_scientist_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18y9xbd/how_do_you_detect_when_a_data_scientist_is/", "subreddit_subscribers": 1224830, "created_utc": 1704363731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a project where I need to quantify the similarity between two data series. Essentially, I'm looking for an automated way to do this without relying on visual chart comparisons.\n\nThe core of my question revolves around defining\n'similarity' in this context. For my purposes, if I were to plot these two series on the same graph, their trajectories should appear closely aligned. This means minimal distance between corresponding points, similar fluctuation patterns, etc. Ideally, perfectly overlapping series would score a similarity of 1.0, while completely uncorrelated series would score lower, though I suspect a score of 0 might not be feasible. \n\nAn important note for my use case: a t-test isn't feasible since the series I'm comparing have similar mean values. This adds a layer of complexity to finding a suitable method.\n\nI'm eager to hear your thoughts or suggestions on how to approach this. Any advice or experiences shared would be incredibly helpful!", "author_fullname": "t2_agbj58l8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strategies for quantifying similarity between two data series?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y6ndy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704350647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project where I need to quantify the similarity between two data series. Essentially, I&amp;#39;m looking for an automated way to do this without relying on visual chart comparisons.&lt;/p&gt;\n\n&lt;p&gt;The core of my question revolves around defining\n&amp;#39;similarity&amp;#39; in this context. For my purposes, if I were to plot these two series on the same graph, their trajectories should appear closely aligned. This means minimal distance between corresponding points, similar fluctuation patterns, etc. Ideally, perfectly overlapping series would score a similarity of 1.0, while completely uncorrelated series would score lower, though I suspect a score of 0 might not be feasible. &lt;/p&gt;\n\n&lt;p&gt;An important note for my use case: a t-test isn&amp;#39;t feasible since the series I&amp;#39;m comparing have similar mean values. This adds a layer of complexity to finding a suitable method.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m eager to hear your thoughts or suggestions on how to approach this. Any advice or experiences shared would be incredibly helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "18y6ndy", "is_robot_indexable": true, "report_reasons": null, "author": "jujuman1313", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18y6ndy/strategies_for_quantifying_similarity_between_two/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18y6ndy/strategies_for_quantifying_similarity_between_two/", "subreddit_subscribers": 1224830, "created_utc": 1704350647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Folks, I've been pondering a question and I've found it to be more complicated than I initially thought.\n\nAssume we have two very large tables (large enough that discussing efficiency is worthwhile). Let's say one table is named 'course' and the other 'registration', recording the instances of students registering for courses. The goal is simply to filter out the courses that have been registered for by at least one student this year.\n\nIt is simple, we can do:\n\n    SELECT course.*\n    FROM course \n    WHERE course.id in (\n    SELECT DISTINCT course_id \n    FROM registration\n    WHERE YEAR(date) = CURRENT_YEAR\n    )\n\nI believe the time complexity should be O(n\\_course) + O(n\\_registration), since the average complexity for evaluating 'IN' is O(1) using hash.\n\nHowever, I saw a lot of people adopting, and even suggesting, the use of JOIN to perform the filtering.\n\n    SELECT course.*\n    FROM course\n    JOIN registration ON course.id = registration.course_id\n    WHERE YEAR(date) = CURRENT_YEAR\n\nI understand this would also work, but I think this is a O(n\\^2) algorithm that wastes a lot of resources. Am I correct? I'm open to any criticism. I've searched on stackoverflow and found only arbitrary SQL queries.", "author_fullname": "t2_q7zheewy2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Efficiency Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y2ojf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704338625.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704337924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Folks, I&amp;#39;ve been pondering a question and I&amp;#39;ve found it to be more complicated than I initially thought.&lt;/p&gt;\n\n&lt;p&gt;Assume we have two very large tables (large enough that discussing efficiency is worthwhile). Let&amp;#39;s say one table is named &amp;#39;course&amp;#39; and the other &amp;#39;registration&amp;#39;, recording the instances of students registering for courses. The goal is simply to filter out the courses that have been registered for by at least one student this year.&lt;/p&gt;\n\n&lt;p&gt;It is simple, we can do:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT course.*\nFROM course \nWHERE course.id in (\nSELECT DISTINCT course_id \nFROM registration\nWHERE YEAR(date) = CURRENT_YEAR\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I believe the time complexity should be O(n_course) + O(n_registration), since the average complexity for evaluating &amp;#39;IN&amp;#39; is O(1) using hash.&lt;/p&gt;\n\n&lt;p&gt;However, I saw a lot of people adopting, and even suggesting, the use of JOIN to perform the filtering.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT course.*\nFROM course\nJOIN registration ON course.id = registration.course_id\nWHERE YEAR(date) = CURRENT_YEAR\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I understand this would also work, but I think this is a O(n^2) algorithm that wastes a lot of resources. Am I correct? I&amp;#39;m open to any criticism. I&amp;#39;ve searched on stackoverflow and found only arbitrary SQL queries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "18y2ojf", "is_robot_indexable": true, "report_reasons": null, "author": "Cyraxess", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18y2ojf/sql_efficiency_discussion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18y2ojf/sql_efficiency_discussion/", "subreddit_subscribers": 1224830, "created_utc": 1704337924.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}