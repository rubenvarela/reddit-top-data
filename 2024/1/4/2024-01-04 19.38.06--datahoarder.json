{"kind": "Listing", "data": {"after": "t3_18xtcff", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a ton of physically media, and know that if the power goes out, or electrical grid fails I\u2019m fucked, but I still go and keep downloading knowing that I may \u201cin the event of a serious disaster\u201d may not be able to watch anything ever again.", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did your hoarding originally start as an \u201cend of day\u201d scenario?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y7q9v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704354836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a ton of physically media, and know that if the power goes out, or electrical grid fails I\u2019m fucked, but I still go and keep downloading knowing that I may \u201cin the event of a serious disaster\u201d may not be able to watch anything ever again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y7q9v", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y7q9v/did_your_hoarding_originally_start_as_an_end_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y7q9v/did_your_hoarding_originally_start_as_an_end_of/", "subreddit_subscribers": 723036, "created_utc": 1704354836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "And in particular, is there somewhere else I should be buying music (which isn't available on physical media) that does not leave me vulnerable to being lost?", "author_fullname": "t2_vx1zhii3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I worry about music I've purchased on iTunes disappearing on me someday? What should I do about it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xz98a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704328630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And in particular, is there somewhere else I should be buying music (which isn&amp;#39;t available on physical media) that does not leave me vulnerable to being lost?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xz98a", "is_robot_indexable": true, "report_reasons": null, "author": "grey_crawfish", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xz98a/should_i_worry_about_music_ive_purchased_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xz98a/should_i_worry_about_music_ive_purchased_on/", "subreddit_subscribers": 723036, "created_utc": 1704328630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My grandfather left behind a computer when he passed in 2003. He was doing research on our family's genealogy and likely left behind notes. Unfortunately, he passed before be could properly share all of his findings. I would like to inspect the data on this PCs hard drive to see if there are any notes or otherwise sentimentally valuable data. However, I'm concerned about causing damage while trying to access the data (i.e. malfunction of the hard drive that results in data loss etc).\n\nAm I being too worrisome? Ideally, I would use something like clonezilla to copy the data off the HDD, but I worry that even this procedure may carry some risk for data corruption. If I'm not being too worrisome is there a safer way?", "author_fullname": "t2_512xtibc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard drive from 2003. How to read data without causing damage to data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xxllj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704325277.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704324470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My grandfather left behind a computer when he passed in 2003. He was doing research on our family&amp;#39;s genealogy and likely left behind notes. Unfortunately, he passed before be could properly share all of his findings. I would like to inspect the data on this PCs hard drive to see if there are any notes or otherwise sentimentally valuable data. However, I&amp;#39;m concerned about causing damage while trying to access the data (i.e. malfunction of the hard drive that results in data loss etc).&lt;/p&gt;\n\n&lt;p&gt;Am I being too worrisome? Ideally, I would use something like clonezilla to copy the data off the HDD, but I worry that even this procedure may carry some risk for data corruption. If I&amp;#39;m not being too worrisome is there a safer way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xxllj", "is_robot_indexable": true, "report_reasons": null, "author": "nodeselector", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xxllj/hard_drive_from_2003_how_to_read_data_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xxllj/hard_drive_from_2003_how_to_read_data_without/", "subreddit_subscribers": 723036, "created_utc": 1704324470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "In [this post](https://www.reddit.com/r/DataHoarder/comments/7aw4kf/how_long_do_harddrives_last_in_hours/), people are saying that hard drives usually fail at around 50k hours. So then how does goharddrive sell used/renewed hard drives that still will last another 5 years even though they've been used for over 40k hours?Here's one example, just look at the second pic: [https://www.ebay.com/itm/175753891245?hash=item28ebbf8dad:g:1B0AAOSwfUlkox3x](https://www.ebay.com/itm/175753891245?hash=item28ebbf8dad:g:1B0AAOSwfUlkox3x)\n\n1786 days \\* 24 hours = 42.9k hours\n\nAnother, almost 40k: [https://www.ebay.com/itm/166458859343?hash=item26c1b89f4f:g:2kwAAOSwxNRkp1Cb](https://www.ebay.com/itm/166458859343?hash=item26c1b89f4f:g:2kwAAOSwxNRkp1Cb)", "author_fullname": "t2_u5ch0ltp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "5 year warranty despite being used for 40k hours?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yfbs3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704380938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/7aw4kf/how_long_do_harddrives_last_in_hours/\"&gt;this post&lt;/a&gt;, people are saying that hard drives usually fail at around 50k hours. So then how does goharddrive sell used/renewed hard drives that still will last another 5 years even though they&amp;#39;ve been used for over 40k hours?Here&amp;#39;s one example, just look at the second pic: &lt;a href=\"https://www.ebay.com/itm/175753891245?hash=item28ebbf8dad:g:1B0AAOSwfUlkox3x\"&gt;https://www.ebay.com/itm/175753891245?hash=item28ebbf8dad:g:1B0AAOSwfUlkox3x&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;1786 days * 24 hours = 42.9k hours&lt;/p&gt;\n\n&lt;p&gt;Another, almost 40k: &lt;a href=\"https://www.ebay.com/itm/166458859343?hash=item26c1b89f4f:g:2kwAAOSwxNRkp1Cb\"&gt;https://www.ebay.com/itm/166458859343?hash=item26c1b89f4f:g:2kwAAOSwxNRkp1Cb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oP24DOmUCfs7-Yx9DCHM8eBtFQL4DDz1aia6tWM0paU.jpg?auto=webp&amp;s=ee90708e76b6e98e4102017e1778acc5bf7e17a6", "width": 400, "height": 304}, "resolutions": [{"url": "https://external-preview.redd.it/oP24DOmUCfs7-Yx9DCHM8eBtFQL4DDz1aia6tWM0paU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0aea7e08ffac8a5812369815fe14002a88c568a", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/oP24DOmUCfs7-Yx9DCHM8eBtFQL4DDz1aia6tWM0paU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1914f9888017f8c5f82ab10568d856e1565a0f40", "width": 216, "height": 164}, {"url": "https://external-preview.redd.it/oP24DOmUCfs7-Yx9DCHM8eBtFQL4DDz1aia6tWM0paU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3aa9ea8894b8551b38194528083d4efe1eafb53", "width": 320, "height": 243}], "variants": {}, "id": "dEGw3Czr3hhzOPCER3bnGA7wq4gtTYn7HucUOcHwbAM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yfbs3", "is_robot_indexable": true, "report_reasons": null, "author": "CompetitiveSal", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yfbs3/5_year_warranty_despite_being_used_for_40k_hours/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yfbs3/5_year_warranty_despite_being_used_for_40k_hours/", "subreddit_subscribers": 723036, "created_utc": 1704380938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\nI have a problem that took me into an infinite loop of searching through dead links or 'no search results' in Google or other web search engines, tried Bing, Yandex and Rambler.\nI try to preserve as maximum as possible of original World of Tanks updates files (.patch or .wgpkg, if they were released after 0.9.14.x), complete client EXE/ZIP installers/archives, EXE-patch installers, as well as their *original* torrents, if they were available. When it comes to complete installers, it's mostly possible to find them and save, but updates that were released between major versions (we call them 'micropatches') become a real pest. My searched areas, as of today, are:\n- DC++ hubs\n- torrents\n- WoT community websites that hadn't seen any treatment for a decade\n- normal web search\n- Wayback Machine (sadly, absolutely useless for file exchange services, as search bots are either blocked from there or download links are behind nine circles of Hell, making the capture impossible)\n- 'Chomikuj' (Polish file exchange service, but 50 MB weekly limit is suitable only for very small files)\n\nWhat else could be used to widen my search possibilities, given that I know files' names I search and their size in bytes? The checksum is likely to be unknown, neither MD5, nor TTH.", "author_fullname": "t2_452npj84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions on how to extend lost/rare files search range?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y0uxu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704332854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!\nI have a problem that took me into an infinite loop of searching through dead links or &amp;#39;no search results&amp;#39; in Google or other web search engines, tried Bing, Yandex and Rambler.\nI try to preserve as maximum as possible of original World of Tanks updates files (.patch or .wgpkg, if they were released after 0.9.14.x), complete client EXE/ZIP installers/archives, EXE-patch installers, as well as their &lt;em&gt;original&lt;/em&gt; torrents, if they were available. When it comes to complete installers, it&amp;#39;s mostly possible to find them and save, but updates that were released between major versions (we call them &amp;#39;micropatches&amp;#39;) become a real pest. My searched areas, as of today, are:\n- DC++ hubs\n- torrents\n- WoT community websites that hadn&amp;#39;t seen any treatment for a decade\n- normal web search\n- Wayback Machine (sadly, absolutely useless for file exchange services, as search bots are either blocked from there or download links are behind nine circles of Hell, making the capture impossible)\n- &amp;#39;Chomikuj&amp;#39; (Polish file exchange service, but 50 MB weekly limit is suitable only for very small files)&lt;/p&gt;\n\n&lt;p&gt;What else could be used to widen my search possibilities, given that I know files&amp;#39; names I search and their size in bytes? The checksum is likely to be unknown, neither MD5, nor TTH.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y0uxu", "is_robot_indexable": true, "report_reasons": null, "author": "SigmaTel71", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y0uxu/suggestions_on_how_to_extend_lostrare_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y0uxu/suggestions_on_how_to_extend_lostrare_files/", "subreddit_subscribers": 723036, "created_utc": 1704332854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "According to their [bot traffic TOS](https://www.sports-reference.com/bot-traffic.html) they will block anyone when exceeding their rate limit of 20 requests per minute. My bot I'm writing to scrape every NBA players gamelogs for the season is getting banned after around 30 requests in the span of 50 seconds even though I am assigning my bot a new random user-agent each request and a new [public proxy](https://www.sslproxies.org/) after every 19 requests.\n\nDoes anyone know if they are detecting users by fingerprints or if there are other ways to get around the rate limit?", "author_fullname": "t2_bt3yvb06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here have experience bypassing the sports-reference websites rate limits when web scraping?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yce4l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704372513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;According to their &lt;a href=\"https://www.sports-reference.com/bot-traffic.html\"&gt;bot traffic TOS&lt;/a&gt; they will block anyone when exceeding their rate limit of 20 requests per minute. My bot I&amp;#39;m writing to scrape every NBA players gamelogs for the season is getting banned after around 30 requests in the span of 50 seconds even though I am assigning my bot a new random user-agent each request and a new &lt;a href=\"https://www.sslproxies.org/\"&gt;public proxy&lt;/a&gt; after every 19 requests.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know if they are detecting users by fingerprints or if there are other ways to get around the rate limit?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yce4l", "is_robot_indexable": true, "report_reasons": null, "author": "EnaGrimm", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yce4l/does_anyone_here_have_experience_bypassing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yce4l/does_anyone_here_have_experience_bypassing_the/", "subreddit_subscribers": 723036, "created_utc": 1704372513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been collecting for years, you name it I have it, and during my Christmas New Year break, I have been trying to sort out my tv shows, specifically into current or ongoing and cancelled, but ones I am potentially going to watch again , and those I never will.\n\nIt isn\u2019t a matter of executive disfunction, I know that no one else will do it, I have to, it will get done, but every time I do start, the sheer size of what I have still astounds me.", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who here is constantly astounded by exactly what they have?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y7p0z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704354701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been collecting for years, you name it I have it, and during my Christmas New Year break, I have been trying to sort out my tv shows, specifically into current or ongoing and cancelled, but ones I am potentially going to watch again , and those I never will.&lt;/p&gt;\n\n&lt;p&gt;It isn\u2019t a matter of executive disfunction, I know that no one else will do it, I have to, it will get done, but every time I do start, the sheer size of what I have still astounds me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y7p0z", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y7p0z/who_here_is_constantly_astounded_by_exactly_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y7p0z/who_here_is_constantly_astounded_by_exactly_what/", "subreddit_subscribers": 723036, "created_utc": 1704354701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My company is trying to transfer nearly 20tb of video and audio files to several external 8tb LaCie drives to give to an editor. We are currently using a program called hedge data transfer. When we move the data and unmount the drives, they won\u2019t mount back up again. When we plug them into a different machine, they mount but we then notice large amounts of data loss. What\u2019s the most efficient and secure way to move this much data around?", "author_fullname": "t2_7wssb0kt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to transfer several terabytes of data locally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xvkpj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704319558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is trying to transfer nearly 20tb of video and audio files to several external 8tb LaCie drives to give to an editor. We are currently using a program called hedge data transfer. When we move the data and unmount the drives, they won\u2019t mount back up again. When we plug them into a different machine, they mount but we then notice large amounts of data loss. What\u2019s the most efficient and secure way to move this much data around?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xvkpj", "is_robot_indexable": true, "report_reasons": null, "author": "Basic-Cauliflower-71", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xvkpj/best_way_to_transfer_several_terabytes_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xvkpj/best_way_to_transfer_several_terabytes_of_data/", "subreddit_subscribers": 723036, "created_utc": 1704319558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When im doing hardware upgrades/maintenance/network changes to my central file server i end up shutting down all the clients servers that have mounted SMB Shares to prevent problems. Is there a better way to take the file server offline without it screwing up all the Ubuntu/windows clients with hosted Containers mapped running?", "author_fullname": "t2_2czxzxq1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File Server Maintenance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xtoyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704315003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When im doing hardware upgrades/maintenance/network changes to my central file server i end up shutting down all the clients servers that have mounted SMB Shares to prevent problems. Is there a better way to take the file server offline without it screwing up all the Ubuntu/windows clients with hosted Containers mapped running?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xtoyw", "is_robot_indexable": true, "report_reasons": null, "author": "nickichi84", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xtoyw/file_server_maintenance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xtoyw/file_server_maintenance/", "subreddit_subscribers": 723036, "created_utc": 1704315003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, i found this mini pc in ali expres, it has usb3, i wanna use it mainly as a nas/ plex server for 4k remuxes, it won't do any transocoding, will it be enough? \n\nPrice is 130$", "author_fullname": "t2_d1qginax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mini pc as a plex server for 4k", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18yibp7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yUB9MDbPgK3LLVfXK6JnL61LCTGb3vswBaxsqNBGNdg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704388613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i found this mini pc in ali expres, it has usb3, i wanna use it mainly as a nas/ plex server for 4k remuxes, it won&amp;#39;t do any transocoding, will it be enough? &lt;/p&gt;\n\n&lt;p&gt;Price is 130$&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/k7mu84leigac1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/k7mu84leigac1.png?auto=webp&amp;s=645e588a3c605a3e602c2e1c64774e3c1984f332", "width": 1080, "height": 1835}, "resolutions": [{"url": "https://preview.redd.it/k7mu84leigac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f821592f20d129556a14b12f3ed47aef9a986751", "width": 108, "height": 183}, {"url": "https://preview.redd.it/k7mu84leigac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=390713cb8aed74f7b1e1e81a119cf68d68049ed1", "width": 216, "height": 367}, {"url": "https://preview.redd.it/k7mu84leigac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=62b432c06395698dd789d303c0d41fbb69248cc4", "width": 320, "height": 543}, {"url": "https://preview.redd.it/k7mu84leigac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e4ac983eb3683ed9806dd3201d38baed078af980", "width": 640, "height": 1087}, {"url": "https://preview.redd.it/k7mu84leigac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=556a61702d397a1f345a235c4d2f98151e957ca1", "width": 960, "height": 1631}, {"url": "https://preview.redd.it/k7mu84leigac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c485ccab32ee3d34e834dc54fbae8d2bb199fc31", "width": 1080, "height": 1835}], "variants": {}, "id": "vupNHuSliT4U1vdLrF8rCoqTFyIpmpTgUnqEoTgBo9c"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yibp7", "is_robot_indexable": true, "report_reasons": null, "author": "kretsstdr", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yibp7/mini_pc_as_a_plex_server_for_4k/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/k7mu84leigac1.png", "subreddit_subscribers": 723036, "created_utc": 1704388613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A year ago I have bought a new big external hard disk and copied all the content of 3 different external hard disks to that new hard disk (which is my backup of these 3 different disks).  \n\n\nAs I have put some new data on these 3 disks the last few months, I would like to see which data on those 3 hard disks is not present on the 1 big disk.   \n\n\nI use Beyond Compare which does a great job, but according to mee I can only compare 2 disks.   \n\n\nSo if my 'old disks' are named A1, A2 and A3,...and the new big disk is called B1, than I can compare A1 to B1 and see the differences. After that I can compare A2 with B1 and then A3 with B1. But that way I don't see if everything on A1,A2 and A3 is on B1.   \n\n\nSo I'm looking for something with which I can compare A1+A2+A3 with B1.   \n\n\nAnybody can help me?  \n\n\nPlease don't posts any post with RAID and that kind of stuff, because I don't have that and am not planning to use that.", "author_fullname": "t2_997i4gw1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Compare content multiple external hard-disks with content 1 external hard-disk", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yd9f5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704375135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A year ago I have bought a new big external hard disk and copied all the content of 3 different external hard disks to that new hard disk (which is my backup of these 3 different disks).  &lt;/p&gt;\n\n&lt;p&gt;As I have put some new data on these 3 disks the last few months, I would like to see which data on those 3 hard disks is not present on the 1 big disk.   &lt;/p&gt;\n\n&lt;p&gt;I use Beyond Compare which does a great job, but according to mee I can only compare 2 disks.   &lt;/p&gt;\n\n&lt;p&gt;So if my &amp;#39;old disks&amp;#39; are named A1, A2 and A3,...and the new big disk is called B1, than I can compare A1 to B1 and see the differences. After that I can compare A2 with B1 and then A3 with B1. But that way I don&amp;#39;t see if everything on A1,A2 and A3 is on B1.   &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for something with which I can compare A1+A2+A3 with B1.   &lt;/p&gt;\n\n&lt;p&gt;Anybody can help me?  &lt;/p&gt;\n\n&lt;p&gt;Please don&amp;#39;t posts any post with RAID and that kind of stuff, because I don&amp;#39;t have that and am not planning to use that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yd9f5", "is_robot_indexable": true, "report_reasons": null, "author": "EmvanZee", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yd9f5/compare_content_multiple_external_harddisks_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yd9f5/compare_content_multiple_external_harddisks_with/", "subreddit_subscribers": 723036, "created_utc": 1704375135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As of now, I have a 1GB stock SSD that has C: drive (OS/applications) and D: drive and repositories/applications/files).\n\nI want to essentially clone everything on D to the new SSD, without breaking shortcuts.\n\nIf I use disk management to create a new simple volume, it automatically assigns the drive the label E.. I'm not sure what the consequences/implications of not assigning a letter would entail  (Aspirationally, I would also like to backup said D: drive and test that my programs on D: work before cloning and deleting anything on the original SSD) \n\nI am planning on using Macrium Free to complete this process, don't want to delay too long beyond its EOL. Has anyone done this or something similar, provide input? Thank you in advance.", "author_fullname": "t2_1361mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recently purchased a new SSD and want to clone my current D: drive onto it. How to do this elegantly without breaking shortcuts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ybtoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704370896.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704370675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now, I have a 1GB stock SSD that has C: drive (OS/applications) and D: drive and repositories/applications/files).&lt;/p&gt;\n\n&lt;p&gt;I want to essentially clone everything on D to the new SSD, without breaking shortcuts.&lt;/p&gt;\n\n&lt;p&gt;If I use disk management to create a new simple volume, it automatically assigns the drive the label E.. I&amp;#39;m not sure what the consequences/implications of not assigning a letter would entail  (Aspirationally, I would also like to backup said D: drive and test that my programs on D: work before cloning and deleting anything on the original SSD) &lt;/p&gt;\n\n&lt;p&gt;I am planning on using Macrium Free to complete this process, don&amp;#39;t want to delay too long beyond its EOL. Has anyone done this or something similar, provide input? Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ybtoc", "is_robot_indexable": true, "report_reasons": null, "author": "MildlyVandalized", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ybtoc/i_recently_purchased_a_new_ssd_and_want_to_clone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ybtoc/i_recently_purchased_a_new_ssd_and_want_to_clone/", "subreddit_subscribers": 723036, "created_utc": 1704370675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, Im looking to add some more drives in the coming months to my setup. However i have a problem which is my sata port shortage. After reading around on this sub i figured i should get a sas hba which is flashed in IT mode and those 1 sas -&gt; 4 sata cables. I have 4 questions regarding this:\n\n1: Is this indeed the recommended way to add sata hard drives to your setup?\n\n2: Where can i find these cards flashed correctly with atleast 4 sas ports? ill need to connect upto 16 drives. All i can find on amazon are some irrelevant results. (links would be really helpful)\n\n3: Do these cards have linux support? I believe most of them have drivers you need to install but how would i go about doing this on linux?\n\n4: My friend says that sata is a dead standard and i should rather buy sas hard drives and connect those instead. What do you guys think?\n\nThanks in advance for any advice!", "author_fullname": "t2_ioer2jm0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a SAS HBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18yjdr7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704391237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, Im looking to add some more drives in the coming months to my setup. However i have a problem which is my sata port shortage. After reading around on this sub i figured i should get a sas hba which is flashed in IT mode and those 1 sas -&amp;gt; 4 sata cables. I have 4 questions regarding this:&lt;/p&gt;\n\n&lt;p&gt;1: Is this indeed the recommended way to add sata hard drives to your setup?&lt;/p&gt;\n\n&lt;p&gt;2: Where can i find these cards flashed correctly with atleast 4 sas ports? ill need to connect upto 16 drives. All i can find on amazon are some irrelevant results. (links would be really helpful)&lt;/p&gt;\n\n&lt;p&gt;3: Do these cards have linux support? I believe most of them have drivers you need to install but how would i go about doing this on linux?&lt;/p&gt;\n\n&lt;p&gt;4: My friend says that sata is a dead standard and i should rather buy sas hard drives and connect those instead. What do you guys think?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yjdr7", "is_robot_indexable": true, "report_reasons": null, "author": "No-Explanation2174", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yjdr7/looking_for_a_sas_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yjdr7/looking_for_a_sas_hba/", "subreddit_subscribers": 723036, "created_utc": 1704391237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i recorded a lot of tv shows through dvr and now have entire seasons of animated shows. however, none of these have subtitles on them. If im going to be streaming through plex, how do pre burn in subtitles for all of these shows without doing them one by one ?? is there a mass subtitle burner of sorts ??", "author_fullname": "t2_o50q94l4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "subtitles for an entire series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yikbf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704389205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i recorded a lot of tv shows through dvr and now have entire seasons of animated shows. however, none of these have subtitles on them. If im going to be streaming through plex, how do pre burn in subtitles for all of these shows without doing them one by one ?? is there a mass subtitle burner of sorts ??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yikbf", "is_robot_indexable": true, "report_reasons": null, "author": "illbollocksyou", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yikbf/subtitles_for_an_entire_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yikbf/subtitles_for_an_entire_series/", "subreddit_subscribers": 723036, "created_utc": 1704389205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a video editing friend who really likes the Pegasus Raid Drives, but I don't want to pay full price.  Do any of you have experience recommendations for if I buy an older Thunderbolt 2 vs 3 enclosure like this one:  **Promise Technology Pegasus2 R4 Raid Storage Array**  vs a newer one and just use a TB2 to TB3 adapter? Any feedback, appreciated. Thanks!", "author_fullname": "t2_574ayjt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pegasus Raid Drives Thunderbolt 2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yhpg1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704387072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a video editing friend who really likes the Pegasus Raid Drives, but I don&amp;#39;t want to pay full price.  Do any of you have experience recommendations for if I buy an older Thunderbolt 2 vs 3 enclosure like this one:  &lt;strong&gt;Promise Technology Pegasus2 R4 Raid Storage Array&lt;/strong&gt;  vs a newer one and just use a TB2 to TB3 adapter? Any feedback, appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yhpg1", "is_robot_indexable": true, "report_reasons": null, "author": "here_and_there_too", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yhpg1/pegasus_raid_drives_thunderbolt_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yhpg1/pegasus_raid_drives_thunderbolt_2/", "subreddit_subscribers": 723036, "created_utc": 1704387072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nI  am new to NAS systems and planning to configure a NAS for professional  4K video editing. The main goal is to use the NAS as an extended  workspace for projects during editing and then transfer them to another  storage solution upon completion.\n\nI would appreciate advice on the following points:\n\n1. **Budget:**  Being inexperienced in this field, I am unsure about the costs. What  budget should I plan for such a setup? Is there a recommended price  range?\n2. **Model Recommendations:**  Which NAS models would you recommend for my project, especially  considering a limited budget? Are out-of-the-box solutions or open  systems like FreeNAS more suitable?\n3. **Storage:**  I am considering using Samsung PM893 SSDs for storage and possibly  Intel NVMe SSD DC P4511 as a cache. Are these components suitable, or  are there better alternatives? I will determine the size of the storage  space based on how much budget I need to allocate for the core system.\n4. **CPU Performance:**  What processor power is required to efficiently perform 4K video  editing on the NAS? Should I consider additional features like  transcoding?\n\nI am open  to all kinds of advice, tips, and resources to expand my understanding  of NAS systems. Thank you in advance for your help!", "author_fullname": "t2_s3q9nn0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help: Configuring a NAS for 4K Video Editing with 10GbE Connectivity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ygytz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704385228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I  am new to NAS systems and planning to configure a NAS for professional  4K video editing. The main goal is to use the NAS as an extended  workspace for projects during editing and then transfer them to another  storage solution upon completion.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate advice on the following points:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Budget:&lt;/strong&gt;  Being inexperienced in this field, I am unsure about the costs. What  budget should I plan for such a setup? Is there a recommended price  range?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Model Recommendations:&lt;/strong&gt;  Which NAS models would you recommend for my project, especially  considering a limited budget? Are out-of-the-box solutions or open  systems like FreeNAS more suitable?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Storage:&lt;/strong&gt;  I am considering using Samsung PM893 SSDs for storage and possibly  Intel NVMe SSD DC P4511 as a cache. Are these components suitable, or  are there better alternatives? I will determine the size of the storage  space based on how much budget I need to allocate for the core system.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;CPU Performance:&lt;/strong&gt;  What processor power is required to efficiently perform 4K video  editing on the NAS? Should I consider additional features like  transcoding?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am open  to all kinds of advice, tips, and resources to expand my understanding  of NAS systems. Thank you in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ygytz", "is_robot_indexable": true, "report_reasons": null, "author": "Lyranel_origin", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ygytz/need_help_configuring_a_nas_for_4k_video_editing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ygytz/need_help_configuring_a_nas_for_4k_video_editing/", "subreddit_subscribers": 723036, "created_utc": 1704385228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone.\n\nSome time ago I wanted to use my Canopus ADVC-1394 card, which had been gathering dust for years (as previously I used MBP from 2012 for such scenarios), to re-digitize VHS archives I have atm.\n\nOn Windows 7 I got no output of it whatsoever (mb just forgor to install legacy FireWire drivers), so I installed Windows XP. There I could capture DV streams from my JVC SR-VS30 VCR, though I also wanted to take some advantages (none?) of using composite inputs. And, sure enough, it didn't work.\n\nAmong the utilities I've tested yet were WinDV, VirtualDub, Edius and Ulead MediaStudio.\n\nAny advices?", "author_fullname": "t2_e89jxe2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADVC-1394 for Advanced", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yahlj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704365941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone.&lt;/p&gt;\n\n&lt;p&gt;Some time ago I wanted to use my Canopus ADVC-1394 card, which had been gathering dust for years (as previously I used MBP from 2012 for such scenarios), to re-digitize VHS archives I have atm.&lt;/p&gt;\n\n&lt;p&gt;On Windows 7 I got no output of it whatsoever (mb just forgor to install legacy FireWire drivers), so I installed Windows XP. There I could capture DV streams from my JVC SR-VS30 VCR, though I also wanted to take some advantages (none?) of using composite inputs. And, sure enough, it didn&amp;#39;t work.&lt;/p&gt;\n\n&lt;p&gt;Among the utilities I&amp;#39;ve tested yet were WinDV, VirtualDub, Edius and Ulead MediaStudio.&lt;/p&gt;\n\n&lt;p&gt;Any advices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yahlj", "is_robot_indexable": true, "report_reasons": null, "author": "prizmech", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yahlj/advc1394_for_advanced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yahlj/advc1394_for_advanced/", "subreddit_subscribers": 723036, "created_utc": 1704365941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi !  \nI'm looking for a program in which I could save all the friendships I have (IRL). It would save them in a graph with information like name, birthdate, picture, phone number, etc. The graph structure would allow to add links in between friends, and not only with me.  \nAlso, it would be great to save the friendship strength as well to see how close each person is to each other, as well as for how long the people have been knowing each other.  \nI have no idea if a specialized program for this exists, or if there are only generic graph programs that need customization.", "author_fullname": "t2_h6pb6ppc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Friendships graph organizer program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ya4wv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704364556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi !&lt;br/&gt;\nI&amp;#39;m looking for a program in which I could save all the friendships I have (IRL). It would save them in a graph with information like name, birthdate, picture, phone number, etc. The graph structure would allow to add links in between friends, and not only with me.&lt;br/&gt;\nAlso, it would be great to save the friendship strength as well to see how close each person is to each other, as well as for how long the people have been knowing each other.&lt;br/&gt;\nI have no idea if a specialized program for this exists, or if there are only generic graph programs that need customization.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ya4wv", "is_robot_indexable": true, "report_reasons": null, "author": "AntonioKarot", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ya4wv/friendships_graph_organizer_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ya4wv/friendships_graph_organizer_program/", "subreddit_subscribers": 723036, "created_utc": 1704364556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few old IDE drives from old iterations of my PC, which range in size from 4.3gb up to 500gb I think. I have a USB 2.0 adapter from 'Bipra', bought from Amazon recently. I find one drive, the oldest 4.3gb one, mounts OK, but the others do not mount and show no effect when plugged in. I am using Ubuntu Linux, and Windows 10 on a laptop.\n\nIs it possible the drives' electronics have degraded? \nI would like to retrieve the contents but its not worth spending money on data recovery. \n\nIs there something else I should check before disposing of them? I tried checking the master/slave jumpers.\n\nThanks!", "author_fullname": "t2_a66p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old IDE drives which won't mount. (I am using a USB 2.0 adapter)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y8tmy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704359844.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704359311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few old IDE drives from old iterations of my PC, which range in size from 4.3gb up to 500gb I think. I have a USB 2.0 adapter from &amp;#39;Bipra&amp;#39;, bought from Amazon recently. I find one drive, the oldest 4.3gb one, mounts OK, but the others do not mount and show no effect when plugged in. I am using Ubuntu Linux, and Windows 10 on a laptop.&lt;/p&gt;\n\n&lt;p&gt;Is it possible the drives&amp;#39; electronics have degraded? \nI would like to retrieve the contents but its not worth spending money on data recovery. &lt;/p&gt;\n\n&lt;p&gt;Is there something else I should check before disposing of them? I tried checking the master/slave jumpers.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y8tmy", "is_robot_indexable": true, "report_reasons": null, "author": "brainburger", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y8tmy/old_ide_drives_which_wont_mount_i_am_using_a_usb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y8tmy/old_ide_drives_which_wont_mount_i_am_using_a_usb/", "subreddit_subscribers": 723036, "created_utc": 1704359311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nfirst of all, I'm sorry for my bad English; it's not my native language.\n\nNow to my problem, maybe some can help me.\n\nI found my old shucked HDD, which I left because I thought at the time it was defective.\n\nNow, after some years, I'm trying it again.\n\nhttps://preview.redd.it/ta7s1kjejdac1.jpg?width=1005&amp;format=pjpg&amp;auto=webp&amp;s=ea8a0725b90d63c49c1b91a4c7ae809f118cca27\n\n**HDD Model: WDC WD 10 0EZAZ-11TDBA0 (Western Digital White Label)**\n\n&amp;#x200B;\n\nI shucked the HDD, but it cannot be initialized on Windows.\n\nWhat I tried:\n\n1. Covering the three pins for the 3.3 Volt (maybe I didn't do it correctly, I ordered Kapton tapes)\n2. Using a USB HDD Adapter\n3. I tried with a MOLEX Cable\n4. Using different programs like (Partition Master &amp; AOMEI)\n5. In program tests, it's written that every sector is defective.\n\nThe HDD is spinning, but nothing more.\n\nCan it be that the HDD is encrypted with the WD Western Digital USB Bridge and is locked now? I don't have the  USB Bridge Module anymore, but I know the old password.\n\nShould I try with LINUX UBUNTU to unlock it? I never used UBUNTU, but there are some YouTube tutorials on how to do it.\n\nOr is the HDD just defective?\n\nI will add some pictures of the Data on the HDD.\n\nhttps://preview.redd.it/wax9q3i3idac1.jpg?width=1459&amp;format=pjpg&amp;auto=webp&amp;s=3a7dc5e0d02cbb67921a9200d4997f2b87a678b9\n\nhttps://preview.redd.it/ib3047i3idac1.jpg?width=2587&amp;format=pjpg&amp;auto=webp&amp;s=2c8faf84b8233dc81cfc55bce089fb33266e2253\n\nhttps://preview.redd.it/gv9bnai3idac1.jpg?width=1216&amp;format=pjpg&amp;auto=webp&amp;s=c6a59de5ca50443416c4acdd2512e15f285a3943\n\nhttps://preview.redd.it/4kcqvci3idac1.jpg?width=1217&amp;format=pjpg&amp;auto=webp&amp;s=580c5f922e58993125a8e625b17876bd07b1aea7\n\nhttps://preview.redd.it/bj2ujgi3idac1.jpg?width=1761&amp;format=pjpg&amp;auto=webp&amp;s=02a54497626c01ed5b0512af6e7a6dfec6347db3\n\nhttps://preview.redd.it/6amehji3idac1.jpg?width=1232&amp;format=pjpg&amp;auto=webp&amp;s=4a5cd91fa5845ac5905734e2bcc0e0b9b53597f9\n\nhttps://preview.redd.it/xjmjymi3idac1.jpg?width=1112&amp;format=pjpg&amp;auto=webp&amp;s=2db266bda590c5aa7a2f5ff0e292fb7fdc260ecc\n\nhttps://preview.redd.it/oiuueqi3idac1.jpg?width=2065&amp;format=pjpg&amp;auto=webp&amp;s=f4ff5c57cd7e114d4ec90c06feea634659921946", "author_fullname": "t2_26233p68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shucked HDD - White Label not working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ib3047i3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae9c8f396c172127f80ca70589ac030a583c6dcd"}, {"y": 87, "x": 216, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5189d68a2f607db90781595989aca9f757559b5"}, {"y": 129, "x": 320, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c144bef2435c9c54731abcbe3dbfeb2e0cc459ef"}, {"y": 259, "x": 640, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a381e26bbb0e94f6229e98e30d7d12401697f93f"}, {"y": 389, "x": 960, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7eca801dc686e26b7448727c4f3380a09a400ae2"}, {"y": 437, "x": 1080, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=10374a3110ac0d5c1a8f60fbee4a18e1390809c5"}], "s": {"y": 1049, "x": 2587, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=2587&amp;format=pjpg&amp;auto=webp&amp;s=2c8faf84b8233dc81cfc55bce089fb33266e2253"}, "id": "ib3047i3idac1"}, "wax9q3i3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de51e64b5457af77aa5fdb710a0d08cc20b8e980"}, {"y": 145, "x": 216, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3fc4367b968f317ca0d50cfd8bf82f38898c3bb8"}, {"y": 215, "x": 320, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=57e92b8ea8067250637fa475dfffbb060efef8a0"}, {"y": 431, "x": 640, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=83896053a2b19f4ff6a13362a2bc0bec3680e4d3"}, {"y": 646, "x": 960, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=04277e0d1606dc46e0d8793cc9fdb4218ee0ca71"}, {"y": 727, "x": 1080, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=447d325f754f87d8d97602ad1ed50966767225e4"}], "s": {"y": 983, "x": 1459, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=1459&amp;format=pjpg&amp;auto=webp&amp;s=3a7dc5e0d02cbb67921a9200d4997f2b87a678b9"}, "id": "wax9q3i3idac1"}, "oiuueqi3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 21, "x": 108, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b24638faead3a63a6eab58a948cbb6f0b4d1348"}, {"y": 43, "x": 216, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2cbd8182503a3982683054817a0e73893360ba0a"}, {"y": 64, "x": 320, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3133a4fc8a729d64fa88eb26d2d3da0f6928cedd"}, {"y": 129, "x": 640, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=48fe51132f72beca5003d2852bc64b2605b9408e"}, {"y": 194, "x": 960, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=89c6f757bfcd80ffc58b17f88736b31714f8c799"}, {"y": 219, "x": 1080, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=863f17bccf205324b47735be8464179bdbaf718f"}], "s": {"y": 419, "x": 2065, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=2065&amp;format=pjpg&amp;auto=webp&amp;s=f4ff5c57cd7e114d4ec90c06feea634659921946"}, "id": "oiuueqi3idac1"}, "bj2ujgi3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0174ab0409ce0b1c1db0a563f49cd9fdd8e0029"}, {"y": 134, "x": 216, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=125d9f92fe007930ede46ce2b1af4dd3f671433f"}, {"y": 199, "x": 320, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3114abc6b685b6aaae59061b80fd50413ba27f5a"}, {"y": 398, "x": 640, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1a3715f5f2abe5dbfd14e067f86735a96f58d469"}, {"y": 598, "x": 960, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a36ad72de2e450a96dc1fd9c6d87b706b7c39eb1"}, {"y": 672, "x": 1080, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3e632a3cfd13480e42fa095b8fe8a625dafa7c03"}], "s": {"y": 1097, "x": 1761, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=1761&amp;format=pjpg&amp;auto=webp&amp;s=02a54497626c01ed5b0512af6e7a6dfec6347db3"}, "id": "bj2ujgi3idac1"}, "ta7s1kjejdac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 137, "x": 108, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca73cc918c882058efcdffe31b88987475595907"}, {"y": 275, "x": 216, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e79c2d00e8bb94aacbd065c1a582a7c59c8f1c59"}, {"y": 408, "x": 320, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e8d1078b7ead90c7da196e11b2bb1f8bc3398900"}, {"y": 817, "x": 640, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bae532f49f303e7595f172487a5a2b040db6803b"}, {"y": 1225, "x": 960, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=988cd46b0ed0c851a3b2406c0db746fa721c9582"}], "s": {"y": 1283, "x": 1005, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=1005&amp;format=pjpg&amp;auto=webp&amp;s=ea8a0725b90d63c49c1b91a4c7ae809f118cca27"}, "id": "ta7s1kjejdac1"}, "gv9bnai3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 73, "x": 108, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de186add8f589731387747781dfc43f2f79bb5ad"}, {"y": 146, "x": 216, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=81ee204ea8acc287de19357607cdc9bc71e91c35"}, {"y": 216, "x": 320, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ea978b0be2cd750fa9a4f5236cf7c0755b598d8"}, {"y": 433, "x": 640, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e686e3402e5b14deadc44a1ec473d43893024ce1"}, {"y": 650, "x": 960, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=340c591a86b166e6c13153e12d98b6498710743f"}, {"y": 731, "x": 1080, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f2463c87b35ad6c5eb769e526c788171da9a3e8"}], "s": {"y": 824, "x": 1216, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=1216&amp;format=pjpg&amp;auto=webp&amp;s=c6a59de5ca50443416c4acdd2512e15f285a3943"}, "id": "gv9bnai3idac1"}, "6amehji3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 41, "x": 108, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=126e2e83320cbd8082f166885a725f5807dfb0b0"}, {"y": 82, "x": 216, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4343354b6e7dc911251729fc5333c83eb9f6f807"}, {"y": 122, "x": 320, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1db9acafa7a8ad661cad9b93689c6599e2ac18a"}, {"y": 244, "x": 640, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3bf53c2a43b4c5b2d3a5262fd42f04166a5efd07"}, {"y": 367, "x": 960, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ffc9a780db010ec7be8d6c2d6faa0b2392bf762e"}, {"y": 412, "x": 1080, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=22b96a3b83f6e2d669596ebac6d78e7c956f85ed"}], "s": {"y": 471, "x": 1232, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=1232&amp;format=pjpg&amp;auto=webp&amp;s=4a5cd91fa5845ac5905734e2bcc0e0b9b53597f9"}, "id": "6amehji3idac1"}, "4kcqvci3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=514a34d5f4251809ce8e4e627db84dafe89f1003"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9314b632edb771992357b2e362fa947c81f5db08"}, {"y": 225, "x": 320, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ebca0cf04b5ad19b0de351592c79f5e6118df60"}, {"y": 451, "x": 640, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=26c063e99705b29790edafa27a8f24d42f7c8c83"}, {"y": 677, "x": 960, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d266decd4922168ca47941f4bb99793cda8e753"}, {"y": 762, "x": 1080, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=12f61a7ed1d902b1a5acf4e2426d56465c6561e1"}], "s": {"y": 859, "x": 1217, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=1217&amp;format=pjpg&amp;auto=webp&amp;s=580c5f922e58993125a8e625b17876bd07b1aea7"}, "id": "4kcqvci3idac1"}, "xjmjymi3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b311ab7d6bfdcc8dfcbd73639b6455d0863cf56c"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e53dbe40af9a58fda3bdd41d327d9c69594a86c"}, {"y": 85, "x": 320, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9bb3c0bec847ff67407839eb7d113b6a19bcf66a"}, {"y": 171, "x": 640, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e969ac929d8ab0807a96093e066daae999ddbd83"}, {"y": 257, "x": 960, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=68bcc8db251151d5588f674d34f67820cfed1be4"}, {"y": 289, "x": 1080, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f5f043251a2eabb30a43628c41f3fb945bd3a3a0"}], "s": {"y": 298, "x": 1112, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=1112&amp;format=pjpg&amp;auto=webp&amp;s=2db266bda590c5aa7a2f5ff0e292fb7fdc260ecc"}, "id": "xjmjymi3idac1"}}, "name": "t3_18y71el", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ek0WWwoYmLOq9QQci9ZmaQH724z1ItU7b_Ii6dvTjBE.jpg", "edited": 1704352633.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704352121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;first of all, I&amp;#39;m sorry for my bad English; it&amp;#39;s not my native language.&lt;/p&gt;\n\n&lt;p&gt;Now to my problem, maybe some can help me.&lt;/p&gt;\n\n&lt;p&gt;I found my old shucked HDD, which I left because I thought at the time it was defective.&lt;/p&gt;\n\n&lt;p&gt;Now, after some years, I&amp;#39;m trying it again.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ta7s1kjejdac1.jpg?width=1005&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ea8a0725b90d63c49c1b91a4c7ae809f118cca27\"&gt;https://preview.redd.it/ta7s1kjejdac1.jpg?width=1005&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ea8a0725b90d63c49c1b91a4c7ae809f118cca27&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;HDD Model: WDC WD 10 0EZAZ-11TDBA0 (Western Digital White Label)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I shucked the HDD, but it cannot be initialized on Windows.&lt;/p&gt;\n\n&lt;p&gt;What I tried:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Covering the three pins for the 3.3 Volt (maybe I didn&amp;#39;t do it correctly, I ordered Kapton tapes)&lt;/li&gt;\n&lt;li&gt;Using a USB HDD Adapter&lt;/li&gt;\n&lt;li&gt;I tried with a MOLEX Cable&lt;/li&gt;\n&lt;li&gt;Using different programs like (Partition Master &amp;amp; AOMEI)&lt;/li&gt;\n&lt;li&gt;In program tests, it&amp;#39;s written that every sector is defective.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The HDD is spinning, but nothing more.&lt;/p&gt;\n\n&lt;p&gt;Can it be that the HDD is encrypted with the WD Western Digital USB Bridge and is locked now? I don&amp;#39;t have the  USB Bridge Module anymore, but I know the old password.&lt;/p&gt;\n\n&lt;p&gt;Should I try with LINUX UBUNTU to unlock it? I never used UBUNTU, but there are some YouTube tutorials on how to do it.&lt;/p&gt;\n\n&lt;p&gt;Or is the HDD just defective?&lt;/p&gt;\n\n&lt;p&gt;I will add some pictures of the Data on the HDD.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wax9q3i3idac1.jpg?width=1459&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=3a7dc5e0d02cbb67921a9200d4997f2b87a678b9\"&gt;https://preview.redd.it/wax9q3i3idac1.jpg?width=1459&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=3a7dc5e0d02cbb67921a9200d4997f2b87a678b9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ib3047i3idac1.jpg?width=2587&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2c8faf84b8233dc81cfc55bce089fb33266e2253\"&gt;https://preview.redd.it/ib3047i3idac1.jpg?width=2587&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2c8faf84b8233dc81cfc55bce089fb33266e2253&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gv9bnai3idac1.jpg?width=1216&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c6a59de5ca50443416c4acdd2512e15f285a3943\"&gt;https://preview.redd.it/gv9bnai3idac1.jpg?width=1216&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c6a59de5ca50443416c4acdd2512e15f285a3943&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4kcqvci3idac1.jpg?width=1217&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=580c5f922e58993125a8e625b17876bd07b1aea7\"&gt;https://preview.redd.it/4kcqvci3idac1.jpg?width=1217&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=580c5f922e58993125a8e625b17876bd07b1aea7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bj2ujgi3idac1.jpg?width=1761&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=02a54497626c01ed5b0512af6e7a6dfec6347db3\"&gt;https://preview.redd.it/bj2ujgi3idac1.jpg?width=1761&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=02a54497626c01ed5b0512af6e7a6dfec6347db3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6amehji3idac1.jpg?width=1232&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4a5cd91fa5845ac5905734e2bcc0e0b9b53597f9\"&gt;https://preview.redd.it/6amehji3idac1.jpg?width=1232&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4a5cd91fa5845ac5905734e2bcc0e0b9b53597f9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xjmjymi3idac1.jpg?width=1112&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2db266bda590c5aa7a2f5ff0e292fb7fdc260ecc\"&gt;https://preview.redd.it/xjmjymi3idac1.jpg?width=1112&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2db266bda590c5aa7a2f5ff0e292fb7fdc260ecc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oiuueqi3idac1.jpg?width=2065&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f4ff5c57cd7e114d4ec90c06feea634659921946\"&gt;https://preview.redd.it/oiuueqi3idac1.jpg?width=2065&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f4ff5c57cd7e114d4ec90c06feea634659921946&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y71el", "is_robot_indexable": true, "report_reasons": null, "author": "neso___", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y71el/shucked_hdd_white_label_not_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y71el/shucked_hdd_white_label_not_working/", "subreddit_subscribers": 723036, "created_utc": 1704352121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently doing a project where a client stored 800TB of data on Dropbox Unlimited.\n\nNow since Dropbox Unlimited has stopped offering its unlimited option, I am left with a task to offload the data from Dropbox to an onsite NAS.\n\nMy idea is to get two Synology DS2422+ and the expansion unit DS1222 which should give me a total of 48 drive bays.\n\nNow the plan is to purchase 48 x 20TB drives then configured on a RAID 5 which should give me enough to cover the 800TB. It'll be 4 storage pools as well with each pool getting 1 volume.\n\nMy ask to anyone is, is there a better way that is more cost effective? If anyone has done it, any gotchas or things to note? Any feedback or input is appreciated. Thanks!", "author_fullname": "t2_1ey2oziy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropbox to NAS - 800TB Offload", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y5u87", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704347735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently doing a project where a client stored 800TB of data on Dropbox Unlimited.&lt;/p&gt;\n\n&lt;p&gt;Now since Dropbox Unlimited has stopped offering its unlimited option, I am left with a task to offload the data from Dropbox to an onsite NAS.&lt;/p&gt;\n\n&lt;p&gt;My idea is to get two Synology DS2422+ and the expansion unit DS1222 which should give me a total of 48 drive bays.&lt;/p&gt;\n\n&lt;p&gt;Now the plan is to purchase 48 x 20TB drives then configured on a RAID 5 which should give me enough to cover the 800TB. It&amp;#39;ll be 4 storage pools as well with each pool getting 1 volume.&lt;/p&gt;\n\n&lt;p&gt;My ask to anyone is, is there a better way that is more cost effective? If anyone has done it, any gotchas or things to note? Any feedback or input is appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y5u87", "is_robot_indexable": true, "report_reasons": null, "author": "Plakiii", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y5u87/dropbox_to_nas_800tb_offload/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y5u87/dropbox_to_nas_800tb_offload/", "subreddit_subscribers": 723036, "created_utc": 1704347735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've had multiple instances of data integrity issues with Kopia and gave up on it a while back. It seems like those issues haven't been resolved which is very offputting.\n\nI've been using syncthing + ZFS snapshots as a placeholder in the meantime, but it hasn't been working as well as I had hoped. So I'm looking for an alternative that has some basic-ish features.\n\n1. I'd prefer cross platform; Windows and Debian. But I'm fine with having 2 separate programs for each OS if that's required\n\n2. Webgui is preferred so I can manage it remotely. Docker images or wrappers with webguis also work\n\n3. File level backups (not system images). I'm just backing up photos and documents, so I don't need to be able to boot off a backup image or anything.\n\n4. Scheduling the backup directly from the UI (hourly, daily, monthly etc) as well as setting up snapshot retention.\n\n5. Incremental, compression, deduplication. \n\n6. Natively being able to back up to / from sources like S3, dropbox etc are nice but not required since I can mount them with rclone.\n\n7. FOSS is strongly preferred, I don't like having backups held hostage.\n\nI've done some research and testing, but I'd like to hear some opinions\n\n1. Kopia : Data corruption + doesn't actually verify integrity half the time\n\n2. Duplicati : Data + database corruption = irrecoverable backups\n\n3. Urbackup : The server didn't work when I tested it on windows. Haven't looked into the issue yet\n\n4. Veeam NFR / community backup  : Seems to be extremely bloated, unsure if it does file level all that well.\n\n5. Veeam agent : Haven't tested it recently. Had issues with shared folders before, unsure if that's still an issue\n\n6. Borg : Untested but borgwarehouse seems to offer a nice GUI\n\n7. Restic : Restic-GX is a pretty good UI. Unfortunately you can't mount the snapshots in windows, but you can still browse them.\n\nSo far I'm thinking either Borg or restic on the linux machines and Veeam for windows. I'm assuming 2 separate programs is probably safer than relying on 1, even if it's more of a headache to manage.", "author_fullname": "t2_upalof7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a replacement for Kopia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y402n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704341837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had multiple instances of data integrity issues with Kopia and gave up on it a while back. It seems like those issues haven&amp;#39;t been resolved which is very offputting.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using syncthing + ZFS snapshots as a placeholder in the meantime, but it hasn&amp;#39;t been working as well as I had hoped. So I&amp;#39;m looking for an alternative that has some basic-ish features.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;d prefer cross platform; Windows and Debian. But I&amp;#39;m fine with having 2 separate programs for each OS if that&amp;#39;s required&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Webgui is preferred so I can manage it remotely. Docker images or wrappers with webguis also work&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;File level backups (not system images). I&amp;#39;m just backing up photos and documents, so I don&amp;#39;t need to be able to boot off a backup image or anything.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Scheduling the backup directly from the UI (hourly, daily, monthly etc) as well as setting up snapshot retention.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Incremental, compression, deduplication. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Natively being able to back up to / from sources like S3, dropbox etc are nice but not required since I can mount them with rclone.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;FOSS is strongly preferred, I don&amp;#39;t like having backups held hostage.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve done some research and testing, but I&amp;#39;d like to hear some opinions&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Kopia : Data corruption + doesn&amp;#39;t actually verify integrity half the time&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Duplicati : Data + database corruption = irrecoverable backups&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Urbackup : The server didn&amp;#39;t work when I tested it on windows. Haven&amp;#39;t looked into the issue yet&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Veeam NFR / community backup  : Seems to be extremely bloated, unsure if it does file level all that well.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Veeam agent : Haven&amp;#39;t tested it recently. Had issues with shared folders before, unsure if that&amp;#39;s still an issue&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Borg : Untested but borgwarehouse seems to offer a nice GUI&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Restic : Restic-GX is a pretty good UI. Unfortunately you can&amp;#39;t mount the snapshots in windows, but you can still browse them.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So far I&amp;#39;m thinking either Borg or restic on the linux machines and Veeam for windows. I&amp;#39;m assuming 2 separate programs is probably safer than relying on 1, even if it&amp;#39;s more of a headache to manage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "vTrueNAS 72TB / Hyper-V", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y402n", "is_robot_indexable": true, "report_reasons": null, "author": "Party_9001", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/18y402n/looking_for_a_replacement_for_kopia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y402n/looking_for_a_replacement_for_kopia/", "subreddit_subscribers": 723036, "created_utc": 1704341837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a couple used enterprise HGST Ultrastar sata drives and I am wondering what the best way to test them is on my MacOS??\n\nIs it worth using F3? Is there a good SMART tool to download for Mac that you recommend like smartmontools? ", "author_fullname": "t2_attol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to test HDD on MacOS??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xvj1z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704319447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a couple used enterprise HGST Ultrastar sata drives and I am wondering what the best way to test them is on my MacOS??&lt;/p&gt;\n\n&lt;p&gt;Is it worth using F3? Is there a good SMART tool to download for Mac that you recommend like smartmontools? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xvj1z", "is_robot_indexable": true, "report_reasons": null, "author": "d-cent", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xvj1z/software_to_test_hdd_on_macos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xvj1z/software_to_test_hdd_on_macos/", "subreddit_subscribers": 723036, "created_utc": 1704319447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Hoarders,\n\nAny know of a **minimalistic** tool (utility, script, etc.) that bulk creates creates empty folders named based on provided patterns (be it regex or anything else)?  Not looking for a file mover/sorter/re-name tool. Just trying to generate empty folders with ever changing patterns.\n\nHaving to structure text and excel files every time a new directory structure is needed for use with a batch script is tedious as hell.\n\nExample:   \n**Each line representing a new folder.** \n\nMAIN   \n\\-0001-0099   \n\\-0100-0199   \n\\-0200-0299   \n\\-up to 9900-9999.\n\n&amp;#x200B;\n\n2. Any know of a **minimalistic** tool (utility, script, etc.) that bulk sorts images &amp; video based on geolocation metadata? Not looking for a bloated full-fledged media manager/viewer/player app. Just looking to bulk sort.\n\n&amp;#x200B;\n\nExample:   \n**Each line representing a new folder.** \n\nBarbados  \n\\-13\u00b005'50.0N 59\u00b036'41.7W  \n\\-13\u00b002'43.8N 59\u00b031'36.3W\n\nAll  help is appreciated.  \n", "author_fullname": "t2_c0tub3mw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software Inquiry: Bulk Directory Creation Based on Pattern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xulg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704317184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Hoarders,&lt;/p&gt;\n\n&lt;p&gt;Any know of a &lt;strong&gt;minimalistic&lt;/strong&gt; tool (utility, script, etc.) that bulk creates creates empty folders named based on provided patterns (be it regex or anything else)?  Not looking for a file mover/sorter/re-name tool. Just trying to generate empty folders with ever changing patterns.&lt;/p&gt;\n\n&lt;p&gt;Having to structure text and excel files every time a new directory structure is needed for use with a batch script is tedious as hell.&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;br/&gt;\n&lt;strong&gt;Each line representing a new folder.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;MAIN&lt;br/&gt;\n-0001-0099&lt;br/&gt;\n-0100-0199&lt;br/&gt;\n-0200-0299&lt;br/&gt;\n-up to 9900-9999.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Any know of a &lt;strong&gt;minimalistic&lt;/strong&gt; tool (utility, script, etc.) that bulk sorts images &amp;amp; video based on geolocation metadata? Not looking for a bloated full-fledged media manager/viewer/player app. Just looking to bulk sort.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;br/&gt;\n&lt;strong&gt;Each line representing a new folder.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Barbados&lt;br/&gt;\n-13\u00b005&amp;#39;50.0N 59\u00b036&amp;#39;41.7W&lt;br/&gt;\n-13\u00b002&amp;#39;43.8N 59\u00b031&amp;#39;36.3W&lt;/p&gt;\n\n&lt;p&gt;All  help is appreciated.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xulg6", "is_robot_indexable": true, "report_reasons": null, "author": "DominusImundi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xulg6/software_inquiry_bulk_directory_creation_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xulg6/software_inquiry_bulk_directory_creation_based_on/", "subreddit_subscribers": 723036, "created_utc": 1704317184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've had a 3TB Seagate drive for.... not sure how long. Never dropped or damaged, still spins up and registers on my computer. The only problem is that it says there is 1.22TB of used space but the files that show in file explorer only account for 206GB of that. Tried to look if they were hidden files but no luck.\n\nContacted Seagate and they gave me their data recovery suite software. I ran that, and (20 hours later) I transfered 1.22TB of recovered files to a newer drive. Went back through the files and there are a whole lot of CSV, PDF, and DOC files that just won't open, plus all of the files have been renamed so I can't figure out which files exactly broke. There were also JPEG files that caused a message about the file format not being supported even though it was. I was told this meant the drive could have been corrupted?\n\nI found a local data recovery company who can look at the drive, but is there any chance of actually getting the original file names, folders and the non-working files back?", "author_fullname": "t2_rh851", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Corrupted external HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xtcff", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704314158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had a 3TB Seagate drive for.... not sure how long. Never dropped or damaged, still spins up and registers on my computer. The only problem is that it says there is 1.22TB of used space but the files that show in file explorer only account for 206GB of that. Tried to look if they were hidden files but no luck.&lt;/p&gt;\n\n&lt;p&gt;Contacted Seagate and they gave me their data recovery suite software. I ran that, and (20 hours later) I transfered 1.22TB of recovered files to a newer drive. Went back through the files and there are a whole lot of CSV, PDF, and DOC files that just won&amp;#39;t open, plus all of the files have been renamed so I can&amp;#39;t figure out which files exactly broke. There were also JPEG files that caused a message about the file format not being supported even though it was. I was told this meant the drive could have been corrupted?&lt;/p&gt;\n\n&lt;p&gt;I found a local data recovery company who can look at the drive, but is there any chance of actually getting the original file names, folders and the non-working files back?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xtcff", "is_robot_indexable": true, "report_reasons": null, "author": "SciFiGirl42", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xtcff/corrupted_external_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xtcff/corrupted_external_hdd/", "subreddit_subscribers": 723036, "created_utc": 1704314158.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}