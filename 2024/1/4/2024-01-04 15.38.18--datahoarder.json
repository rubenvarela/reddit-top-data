{"kind": "Listing", "data": {"after": "t3_18y1vx8", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a ton of physically media, and know that if the power goes out, or electrical grid fails I\u2019m fucked, but I still go and keep downloading knowing that I may \u201cin the event of a serious disaster\u201d may not be able to watch anything ever again.", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did your hoarding originally start as an \u201cend of day\u201d scenario?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y7q9v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704354836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a ton of physically media, and know that if the power goes out, or electrical grid fails I\u2019m fucked, but I still go and keep downloading knowing that I may \u201cin the event of a serious disaster\u201d may not be able to watch anything ever again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y7q9v", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y7q9v/did_your_hoarding_originally_start_as_an_end_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y7q9v/did_your_hoarding_originally_start_as_an_end_of/", "subreddit_subscribers": 723065, "created_utc": 1704354836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My grandfather left behind a computer when he passed in 2003. He was doing research on our family's genealogy and likely left behind notes. Unfortunately, he passed before be could properly share all of his findings. I would like to inspect the data on this PCs hard drive to see if there are any notes or otherwise sentimentally valuable data. However, I'm concerned about causing damage while trying to access the data (i.e. malfunction of the hard drive that results in data loss etc).\n\nAm I being too worrisome? Ideally, I would use something like clonezilla to copy the data off the HDD, but I worry that even this procedure may carry some risk for data corruption. If I'm not being too worrisome is there a safer way?", "author_fullname": "t2_512xtibc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard drive from 2003. How to read data without causing damage to data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xxllj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704325277.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704324470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My grandfather left behind a computer when he passed in 2003. He was doing research on our family&amp;#39;s genealogy and likely left behind notes. Unfortunately, he passed before be could properly share all of his findings. I would like to inspect the data on this PCs hard drive to see if there are any notes or otherwise sentimentally valuable data. However, I&amp;#39;m concerned about causing damage while trying to access the data (i.e. malfunction of the hard drive that results in data loss etc).&lt;/p&gt;\n\n&lt;p&gt;Am I being too worrisome? Ideally, I would use something like clonezilla to copy the data off the HDD, but I worry that even this procedure may carry some risk for data corruption. If I&amp;#39;m not being too worrisome is there a safer way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xxllj", "is_robot_indexable": true, "report_reasons": null, "author": "nodeselector", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xxllj/hard_drive_from_2003_how_to_read_data_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xxllj/hard_drive_from_2003_how_to_read_data_without/", "subreddit_subscribers": 723065, "created_utc": 1704324470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey folks,\nI was recently given a rather large tote of old family VHSs and asked if I could make copies on DVDs for other family members. While I'm a nerd, this is a process that's new to me and I'd like to follow whatever sort of best practices exist.\n\nI've already got a setup to copy the VHS to my server using OBS. From there, I'm not sure the best way to go. I'd like to store them digitally in such a way that they'll be good for years to come - future-proofed if you will. What sort of encoding should I prioritize? If I burn them to DVDs as well, what's the suggested encoding &amp; tools for that? Am I missing anything here?\n\nI do plan on a 3-2-1 backup as I know that's near and dear to this sub's heart.", "author_fullname": "t2_3pe8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving old family VHSs - Best practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xligi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704294433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,\nI was recently given a rather large tote of old family VHSs and asked if I could make copies on DVDs for other family members. While I&amp;#39;m a nerd, this is a process that&amp;#39;s new to me and I&amp;#39;d like to follow whatever sort of best practices exist.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve already got a setup to copy the VHS to my server using OBS. From there, I&amp;#39;m not sure the best way to go. I&amp;#39;d like to store them digitally in such a way that they&amp;#39;ll be good for years to come - future-proofed if you will. What sort of encoding should I prioritize? If I burn them to DVDs as well, what&amp;#39;s the suggested encoding &amp;amp; tools for that? Am I missing anything here?&lt;/p&gt;\n\n&lt;p&gt;I do plan on a 3-2-1 backup as I know that&amp;#39;s near and dear to this sub&amp;#39;s heart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xligi", "is_robot_indexable": true, "report_reasons": null, "author": "dprimedx", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xligi/archiving_old_family_vhss_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xligi/archiving_old_family_vhss_best_practices/", "subreddit_subscribers": 723065, "created_utc": 1704294433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "And in particular, is there somewhere else I should be buying music (which isn't available on physical media) that does not leave me vulnerable to being lost?", "author_fullname": "t2_vx1zhii3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I worry about music I've purchased on iTunes disappearing on me someday? What should I do about it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xz98a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704328630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And in particular, is there somewhere else I should be buying music (which isn&amp;#39;t available on physical media) that does not leave me vulnerable to being lost?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xz98a", "is_robot_indexable": true, "report_reasons": null, "author": "grey_crawfish", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xz98a/should_i_worry_about_music_ive_purchased_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xz98a/should_i_worry_about_music_ive_purchased_on/", "subreddit_subscribers": 723065, "created_utc": 1704328630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\nI have a problem that took me into an infinite loop of searching through dead links or 'no search results' in Google or other web search engines, tried Bing, Yandex and Rambler.\nI try to preserve as maximum as possible of original World of Tanks updates files (.patch or .wgpkg, if they were released after 0.9.14.x), complete client EXE/ZIP installers/archives, EXE-patch installers, as well as their *original* torrents, if they were available. When it comes to complete installers, it's mostly possible to find them and save, but updates that were released between major versions (we call them 'micropatches') become a real pest. My searched areas, as of today, are:\n- DC++ hubs\n- torrents\n- WoT community websites that hadn't seen any treatment for a decade\n- normal web search\n- Wayback Machine (sadly, absolutely useless for file exchange services, as search bots are either blocked from there or download links are behind nine circles of Hell, making the capture impossible)\n- 'Chomikuj' (Polish file exchange service, but 50 MB weekly limit is suitable only for very small files)\n\nWhat else could be used to widen my search possibilities, given that I know files' names I search and their size in bytes? The checksum is likely to be unknown, neither MD5, nor TTH.", "author_fullname": "t2_452npj84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions on how to extend lost/rare files search range?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y0uxu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704332854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!\nI have a problem that took me into an infinite loop of searching through dead links or &amp;#39;no search results&amp;#39; in Google or other web search engines, tried Bing, Yandex and Rambler.\nI try to preserve as maximum as possible of original World of Tanks updates files (.patch or .wgpkg, if they were released after 0.9.14.x), complete client EXE/ZIP installers/archives, EXE-patch installers, as well as their &lt;em&gt;original&lt;/em&gt; torrents, if they were available. When it comes to complete installers, it&amp;#39;s mostly possible to find them and save, but updates that were released between major versions (we call them &amp;#39;micropatches&amp;#39;) become a real pest. My searched areas, as of today, are:\n- DC++ hubs\n- torrents\n- WoT community websites that hadn&amp;#39;t seen any treatment for a decade\n- normal web search\n- Wayback Machine (sadly, absolutely useless for file exchange services, as search bots are either blocked from there or download links are behind nine circles of Hell, making the capture impossible)\n- &amp;#39;Chomikuj&amp;#39; (Polish file exchange service, but 50 MB weekly limit is suitable only for very small files)&lt;/p&gt;\n\n&lt;p&gt;What else could be used to widen my search possibilities, given that I know files&amp;#39; names I search and their size in bytes? The checksum is likely to be unknown, neither MD5, nor TTH.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y0uxu", "is_robot_indexable": true, "report_reasons": null, "author": "SigmaTel71", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y0uxu/suggestions_on_how_to_extend_lostrare_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y0uxu/suggestions_on_how_to_extend_lostrare_files/", "subreddit_subscribers": 723065, "created_utc": 1704332854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My company is trying to transfer nearly 20tb of video and audio files to several external 8tb LaCie drives to give to an editor. We are currently using a program called hedge data transfer. When we move the data and unmount the drives, they won\u2019t mount back up again. When we plug them into a different machine, they mount but we then notice large amounts of data loss. What\u2019s the most efficient and secure way to move this much data around?", "author_fullname": "t2_7wssb0kt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to transfer several terabytes of data locally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xvkpj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704319558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is trying to transfer nearly 20tb of video and audio files to several external 8tb LaCie drives to give to an editor. We are currently using a program called hedge data transfer. When we move the data and unmount the drives, they won\u2019t mount back up again. When we plug them into a different machine, they mount but we then notice large amounts of data loss. What\u2019s the most efficient and secure way to move this much data around?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xvkpj", "is_robot_indexable": true, "report_reasons": null, "author": "Basic-Cauliflower-71", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xvkpj/best_way_to_transfer_several_terabytes_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xvkpj/best_way_to_transfer_several_terabytes_of_data/", "subreddit_subscribers": 723065, "created_utc": 1704319558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When im doing hardware upgrades/maintenance/network changes to my central file server i end up shutting down all the clients servers that have mounted SMB Shares to prevent problems. Is there a better way to take the file server offline without it screwing up all the Ubuntu/windows clients with hosted Containers mapped running?", "author_fullname": "t2_2czxzxq1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File Server Maintenance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xtoyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704315003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When im doing hardware upgrades/maintenance/network changes to my central file server i end up shutting down all the clients servers that have mounted SMB Shares to prevent problems. Is there a better way to take the file server offline without it screwing up all the Ubuntu/windows clients with hosted Containers mapped running?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xtoyw", "is_robot_indexable": true, "report_reasons": null, "author": "nickichi84", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xtoyw/file_server_maintenance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xtoyw/file_server_maintenance/", "subreddit_subscribers": 723065, "created_utc": 1704315003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "According to their [bot traffic TOS](https://www.sports-reference.com/bot-traffic.html) they will block anyone when exceeding their rate limit of 20 requests per minute. My bot I'm writing to scrape every NBA players gamelogs for the season is getting banned after around 30 requests in the span of 50 seconds even though I am assigning my bot a new random user-agent each request and a new [public proxy](https://www.sslproxies.org/) after every 19 requests.\n\nDoes anyone know if they are detecting users by fingerprints or if there are other ways to get around the rate limit?", "author_fullname": "t2_bt3yvb06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here have experience bypassing the sports-reference websites rate limits when web scraping?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yce4l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704372513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;According to their &lt;a href=\"https://www.sports-reference.com/bot-traffic.html\"&gt;bot traffic TOS&lt;/a&gt; they will block anyone when exceeding their rate limit of 20 requests per minute. My bot I&amp;#39;m writing to scrape every NBA players gamelogs for the season is getting banned after around 30 requests in the span of 50 seconds even though I am assigning my bot a new random user-agent each request and a new &lt;a href=\"https://www.sslproxies.org/\"&gt;public proxy&lt;/a&gt; after every 19 requests.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know if they are detecting users by fingerprints or if there are other ways to get around the rate limit?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yce4l", "is_robot_indexable": true, "report_reasons": null, "author": "EnaGrimm", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yce4l/does_anyone_here_have_experience_bypassing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yce4l/does_anyone_here_have_experience_bypassing_the/", "subreddit_subscribers": 723065, "created_utc": 1704372513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As of now, I have a 1GB stock SSD that has C: drive (OS/applications) and D: drive and repositories/applications/files).\n\nI want to essentially clone everything on D to the new SSD, without breaking shortcuts.\n\nIf I use disk management to create a new simple volume, it automatically assigns the drive the label E.. I'm not sure what the consequences/implications of not assigning a letter would entail  (Aspirationally, I would also like to backup said D: drive and test that my programs on D: work before cloning and deleting anything on the original SSD) \n\nI am planning on using Macrium Free to complete this process, don't want to delay too long beyond its EOL. Has anyone done this or something similar, provide input? Thank you in advance.", "author_fullname": "t2_1361mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recently purchased a new SSD and want to clone my current D: drive onto it. How to do this elegantly without breaking shortcuts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ybtoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704370896.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704370675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now, I have a 1GB stock SSD that has C: drive (OS/applications) and D: drive and repositories/applications/files).&lt;/p&gt;\n\n&lt;p&gt;I want to essentially clone everything on D to the new SSD, without breaking shortcuts.&lt;/p&gt;\n\n&lt;p&gt;If I use disk management to create a new simple volume, it automatically assigns the drive the label E.. I&amp;#39;m not sure what the consequences/implications of not assigning a letter would entail  (Aspirationally, I would also like to backup said D: drive and test that my programs on D: work before cloning and deleting anything on the original SSD) &lt;/p&gt;\n\n&lt;p&gt;I am planning on using Macrium Free to complete this process, don&amp;#39;t want to delay too long beyond its EOL. Has anyone done this or something similar, provide input? Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ybtoc", "is_robot_indexable": true, "report_reasons": null, "author": "MildlyVandalized", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ybtoc/i_recently_purchased_a_new_ssd_and_want_to_clone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ybtoc/i_recently_purchased_a_new_ssd_and_want_to_clone/", "subreddit_subscribers": 723065, "created_utc": 1704370675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hoping to get an enclosure for a spare drive for making backups. I found this one which looks nice, with USB3: https://www.microcenter.com/product/486116/inland-35-usb-30-hard-drive-enclosure\n\nBut it says it's limited to 4TB. Why would that be? What is it missing that would allow for using an 8TB or larger drive?", "author_fullname": "t2_c1oyp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are these hard drive enclosures limited to 4TB drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xppt5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704305471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping to get an enclosure for a spare drive for making backups. I found this one which looks nice, with USB3: &lt;a href=\"https://www.microcenter.com/product/486116/inland-35-usb-30-hard-drive-enclosure\"&gt;https://www.microcenter.com/product/486116/inland-35-usb-30-hard-drive-enclosure&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But it says it&amp;#39;s limited to 4TB. Why would that be? What is it missing that would allow for using an 8TB or larger drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xppt5", "is_robot_indexable": true, "report_reasons": null, "author": "WaitForItTheMongols", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xppt5/why_are_these_hard_drive_enclosures_limited_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xppt5/why_are_these_hard_drive_enclosures_limited_to/", "subreddit_subscribers": 723065, "created_utc": 1704305471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm subscribed to a bunch of Patreon podcasts and I wish to archive all old posts. \n\nA quick look at the HTML shows that the posts are just HTML `&lt;audio&gt;`  tags with with an `src` to the MP3 file which i can download. \n\nBut I have +100 posts that I would like to download and doing so by hand would take too long. \n\nAre there any tools around there for the job?", "author_fullname": "t2_vulo6oa0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download Patreon audio posts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18yen9y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704379077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m subscribed to a bunch of Patreon podcasts and I wish to archive all old posts. &lt;/p&gt;\n\n&lt;p&gt;A quick look at the HTML shows that the posts are just HTML &lt;code&gt;&amp;lt;audio&amp;gt;&lt;/code&gt;  tags with with an &lt;code&gt;src&lt;/code&gt; to the MP3 file which i can download. &lt;/p&gt;\n\n&lt;p&gt;But I have +100 posts that I would like to download and doing so by hand would take too long. &lt;/p&gt;\n\n&lt;p&gt;Are there any tools around there for the job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yen9y", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Tomato_1733", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yen9y/how_to_download_patreon_audio_posts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yen9y/how_to_download_patreon_audio_posts/", "subreddit_subscribers": 723065, "created_utc": 1704379077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A year ago I have bought a new big external hard disk and copied all the content of 3 different external hard disks to that new hard disk (which is my backup of these 3 different disks).  \n\n\nAs I have put some new data on these 3 disks the last few months, I would like to see which data on those 3 hard disks is not present on the 1 big disk.   \n\n\nI use Beyond Compare which does a great job, but according to mee I can only compare 2 disks.   \n\n\nSo if my 'old disks' are named A1, A2 and A3,...and the new big disk is called B1, than I can compare A1 to B1 and see the differences. After that I can compare A2 with B1 and then A3 with B1. But that way I don't see if everything on A1,A2 and A3 is on B1.   \n\n\nSo I'm looking for something with which I can compare A1+A2+A3 with B1.   \n\n\nAnybody can help me?  \n\n\nPlease don't posts any post with RAID and that kind of stuff, because I don't have that and am not planning to use that.", "author_fullname": "t2_997i4gw1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Compare content multiple external hard-disks with content 1 external hard-disk", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yd9f5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704375135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A year ago I have bought a new big external hard disk and copied all the content of 3 different external hard disks to that new hard disk (which is my backup of these 3 different disks).  &lt;/p&gt;\n\n&lt;p&gt;As I have put some new data on these 3 disks the last few months, I would like to see which data on those 3 hard disks is not present on the 1 big disk.   &lt;/p&gt;\n\n&lt;p&gt;I use Beyond Compare which does a great job, but according to mee I can only compare 2 disks.   &lt;/p&gt;\n\n&lt;p&gt;So if my &amp;#39;old disks&amp;#39; are named A1, A2 and A3,...and the new big disk is called B1, than I can compare A1 to B1 and see the differences. After that I can compare A2 with B1 and then A3 with B1. But that way I don&amp;#39;t see if everything on A1,A2 and A3 is on B1.   &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for something with which I can compare A1+A2+A3 with B1.   &lt;/p&gt;\n\n&lt;p&gt;Anybody can help me?  &lt;/p&gt;\n\n&lt;p&gt;Please don&amp;#39;t posts any post with RAID and that kind of stuff, because I don&amp;#39;t have that and am not planning to use that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yd9f5", "is_robot_indexable": true, "report_reasons": null, "author": "EmvanZee", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yd9f5/compare_content_multiple_external_harddisks_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yd9f5/compare_content_multiple_external_harddisks_with/", "subreddit_subscribers": 723065, "created_utc": 1704375135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi !  \nI'm looking for a program in which I could save all the friendships I have (IRL). It would save them in a graph with information like name, birthdate, picture, phone number, etc. The graph structure would allow to add links in between friends, and not only with me.  \nAlso, it would be great to save the friendship strength as well to see how close each person is to each other, as well as for how long the people have been knowing each other.  \nI have no idea if a specialized program for this exists, or if there are only generic graph programs that need customization.", "author_fullname": "t2_h6pb6ppc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Friendships graph organizer program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ya4wv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704364556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi !&lt;br/&gt;\nI&amp;#39;m looking for a program in which I could save all the friendships I have (IRL). It would save them in a graph with information like name, birthdate, picture, phone number, etc. The graph structure would allow to add links in between friends, and not only with me.&lt;br/&gt;\nAlso, it would be great to save the friendship strength as well to see how close each person is to each other, as well as for how long the people have been knowing each other.&lt;br/&gt;\nI have no idea if a specialized program for this exists, or if there are only generic graph programs that need customization.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ya4wv", "is_robot_indexable": true, "report_reasons": null, "author": "AntonioKarot", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ya4wv/friendships_graph_organizer_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ya4wv/friendships_graph_organizer_program/", "subreddit_subscribers": 723065, "created_utc": 1704364556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few old IDE drives from old iterations of my PC, which range in size from 4.3gb up to 500gb I think. I have a USB 2.0 adapter from 'Bipra', bought from Amazon recently. I find one drive, the oldest 4.3gb one, mounts OK, but the others do not mount and show no effect when plugged in. I am using Ubuntu Linux, and Windows 10 on a laptop.\n\nIs it possible the drives' electronics have degraded? \nI would like to retrieve the contents but its not worth spending money on data recovery. \n\nIs there something else I should check before disposing of them? I tried checking the master/slave jumpers.\n\nThanks!", "author_fullname": "t2_a66p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old IDE drives which won't mount. (I am using a USB 2.0 adapter)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y8tmy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704359844.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704359311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few old IDE drives from old iterations of my PC, which range in size from 4.3gb up to 500gb I think. I have a USB 2.0 adapter from &amp;#39;Bipra&amp;#39;, bought from Amazon recently. I find one drive, the oldest 4.3gb one, mounts OK, but the others do not mount and show no effect when plugged in. I am using Ubuntu Linux, and Windows 10 on a laptop.&lt;/p&gt;\n\n&lt;p&gt;Is it possible the drives&amp;#39; electronics have degraded? \nI would like to retrieve the contents but its not worth spending money on data recovery. &lt;/p&gt;\n\n&lt;p&gt;Is there something else I should check before disposing of them? I tried checking the master/slave jumpers.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y8tmy", "is_robot_indexable": true, "report_reasons": null, "author": "brainburger", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y8tmy/old_ide_drives_which_wont_mount_i_am_using_a_usb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y8tmy/old_ide_drives_which_wont_mount_i_am_using_a_usb/", "subreddit_subscribers": 723065, "created_utc": 1704359311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been collecting for years, you name it I have it, and during my Christmas New Year break, I have been trying to sort out my tv shows, specifically into current or ongoing and cancelled, but ones I am potentially going to watch again , and those I never will.\n\nIt isn\u2019t a matter of executive disfunction, I know that no one else will do it, I have to, it will get done, but every time I do start, the sheer size of what I have still astounds me.", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who here is constantly astounded by exactly what they have?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y7p0z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704354701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been collecting for years, you name it I have it, and during my Christmas New Year break, I have been trying to sort out my tv shows, specifically into current or ongoing and cancelled, but ones I am potentially going to watch again , and those I never will.&lt;/p&gt;\n\n&lt;p&gt;It isn\u2019t a matter of executive disfunction, I know that no one else will do it, I have to, it will get done, but every time I do start, the sheer size of what I have still astounds me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y7p0z", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y7p0z/who_here_is_constantly_astounded_by_exactly_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y7p0z/who_here_is_constantly_astounded_by_exactly_what/", "subreddit_subscribers": 723065, "created_utc": 1704354701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nfirst of all, I'm sorry for my bad English; it's not my native language.\n\nNow to my problem, maybe some can help me.\n\nI found my old shucked HDD, which I left because I thought at the time it was defective.\n\nNow, after some years, I'm trying it again.\n\nhttps://preview.redd.it/ta7s1kjejdac1.jpg?width=1005&amp;format=pjpg&amp;auto=webp&amp;s=ea8a0725b90d63c49c1b91a4c7ae809f118cca27\n\n**HDD Model: WDC WD 10 0EZAZ-11TDBA0 (Western Digital White Label)**\n\n&amp;#x200B;\n\nI shucked the HDD, but it cannot be initialized on Windows.\n\nWhat I tried:\n\n1. Covering the three pins for the 3.3 Volt (maybe I didn't do it correctly, I ordered Kapton tapes)\n2. Using a USB HDD Adapter\n3. I tried with a MOLEX Cable\n4. Using different programs like (Partition Master &amp; AOMEI)\n5. In program tests, it's written that every sector is defective.\n\nThe HDD is spinning, but nothing more.\n\nCan it be that the HDD is encrypted with the WD Western Digital USB Bridge and is locked now? I don't have the  USB Bridge Module anymore, but I know the old password.\n\nShould I try with LINUX UBUNTU to unlock it? I never used UBUNTU, but there are some YouTube tutorials on how to do it.\n\nOr is the HDD just defective?\n\nI will add some pictures of the Data on the HDD.\n\nhttps://preview.redd.it/wax9q3i3idac1.jpg?width=1459&amp;format=pjpg&amp;auto=webp&amp;s=3a7dc5e0d02cbb67921a9200d4997f2b87a678b9\n\nhttps://preview.redd.it/ib3047i3idac1.jpg?width=2587&amp;format=pjpg&amp;auto=webp&amp;s=2c8faf84b8233dc81cfc55bce089fb33266e2253\n\nhttps://preview.redd.it/gv9bnai3idac1.jpg?width=1216&amp;format=pjpg&amp;auto=webp&amp;s=c6a59de5ca50443416c4acdd2512e15f285a3943\n\nhttps://preview.redd.it/4kcqvci3idac1.jpg?width=1217&amp;format=pjpg&amp;auto=webp&amp;s=580c5f922e58993125a8e625b17876bd07b1aea7\n\nhttps://preview.redd.it/bj2ujgi3idac1.jpg?width=1761&amp;format=pjpg&amp;auto=webp&amp;s=02a54497626c01ed5b0512af6e7a6dfec6347db3\n\nhttps://preview.redd.it/6amehji3idac1.jpg?width=1232&amp;format=pjpg&amp;auto=webp&amp;s=4a5cd91fa5845ac5905734e2bcc0e0b9b53597f9\n\nhttps://preview.redd.it/xjmjymi3idac1.jpg?width=1112&amp;format=pjpg&amp;auto=webp&amp;s=2db266bda590c5aa7a2f5ff0e292fb7fdc260ecc\n\nhttps://preview.redd.it/oiuueqi3idac1.jpg?width=2065&amp;format=pjpg&amp;auto=webp&amp;s=f4ff5c57cd7e114d4ec90c06feea634659921946", "author_fullname": "t2_26233p68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shucked HDD - White Label not working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ib3047i3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae9c8f396c172127f80ca70589ac030a583c6dcd"}, {"y": 87, "x": 216, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5189d68a2f607db90781595989aca9f757559b5"}, {"y": 129, "x": 320, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c144bef2435c9c54731abcbe3dbfeb2e0cc459ef"}, {"y": 259, "x": 640, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a381e26bbb0e94f6229e98e30d7d12401697f93f"}, {"y": 389, "x": 960, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7eca801dc686e26b7448727c4f3380a09a400ae2"}, {"y": 437, "x": 1080, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=10374a3110ac0d5c1a8f60fbee4a18e1390809c5"}], "s": {"y": 1049, "x": 2587, "u": "https://preview.redd.it/ib3047i3idac1.jpg?width=2587&amp;format=pjpg&amp;auto=webp&amp;s=2c8faf84b8233dc81cfc55bce089fb33266e2253"}, "id": "ib3047i3idac1"}, "wax9q3i3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de51e64b5457af77aa5fdb710a0d08cc20b8e980"}, {"y": 145, "x": 216, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3fc4367b968f317ca0d50cfd8bf82f38898c3bb8"}, {"y": 215, "x": 320, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=57e92b8ea8067250637fa475dfffbb060efef8a0"}, {"y": 431, "x": 640, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=83896053a2b19f4ff6a13362a2bc0bec3680e4d3"}, {"y": 646, "x": 960, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=04277e0d1606dc46e0d8793cc9fdb4218ee0ca71"}, {"y": 727, "x": 1080, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=447d325f754f87d8d97602ad1ed50966767225e4"}], "s": {"y": 983, "x": 1459, "u": "https://preview.redd.it/wax9q3i3idac1.jpg?width=1459&amp;format=pjpg&amp;auto=webp&amp;s=3a7dc5e0d02cbb67921a9200d4997f2b87a678b9"}, "id": "wax9q3i3idac1"}, "oiuueqi3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 21, "x": 108, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b24638faead3a63a6eab58a948cbb6f0b4d1348"}, {"y": 43, "x": 216, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2cbd8182503a3982683054817a0e73893360ba0a"}, {"y": 64, "x": 320, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3133a4fc8a729d64fa88eb26d2d3da0f6928cedd"}, {"y": 129, "x": 640, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=48fe51132f72beca5003d2852bc64b2605b9408e"}, {"y": 194, "x": 960, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=89c6f757bfcd80ffc58b17f88736b31714f8c799"}, {"y": 219, "x": 1080, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=863f17bccf205324b47735be8464179bdbaf718f"}], "s": {"y": 419, "x": 2065, "u": "https://preview.redd.it/oiuueqi3idac1.jpg?width=2065&amp;format=pjpg&amp;auto=webp&amp;s=f4ff5c57cd7e114d4ec90c06feea634659921946"}, "id": "oiuueqi3idac1"}, "bj2ujgi3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0174ab0409ce0b1c1db0a563f49cd9fdd8e0029"}, {"y": 134, "x": 216, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=125d9f92fe007930ede46ce2b1af4dd3f671433f"}, {"y": 199, "x": 320, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3114abc6b685b6aaae59061b80fd50413ba27f5a"}, {"y": 398, "x": 640, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1a3715f5f2abe5dbfd14e067f86735a96f58d469"}, {"y": 598, "x": 960, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a36ad72de2e450a96dc1fd9c6d87b706b7c39eb1"}, {"y": 672, "x": 1080, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3e632a3cfd13480e42fa095b8fe8a625dafa7c03"}], "s": {"y": 1097, "x": 1761, "u": "https://preview.redd.it/bj2ujgi3idac1.jpg?width=1761&amp;format=pjpg&amp;auto=webp&amp;s=02a54497626c01ed5b0512af6e7a6dfec6347db3"}, "id": "bj2ujgi3idac1"}, "ta7s1kjejdac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 137, "x": 108, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca73cc918c882058efcdffe31b88987475595907"}, {"y": 275, "x": 216, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e79c2d00e8bb94aacbd065c1a582a7c59c8f1c59"}, {"y": 408, "x": 320, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e8d1078b7ead90c7da196e11b2bb1f8bc3398900"}, {"y": 817, "x": 640, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bae532f49f303e7595f172487a5a2b040db6803b"}, {"y": 1225, "x": 960, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=988cd46b0ed0c851a3b2406c0db746fa721c9582"}], "s": {"y": 1283, "x": 1005, "u": "https://preview.redd.it/ta7s1kjejdac1.jpg?width=1005&amp;format=pjpg&amp;auto=webp&amp;s=ea8a0725b90d63c49c1b91a4c7ae809f118cca27"}, "id": "ta7s1kjejdac1"}, "gv9bnai3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 73, "x": 108, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de186add8f589731387747781dfc43f2f79bb5ad"}, {"y": 146, "x": 216, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=81ee204ea8acc287de19357607cdc9bc71e91c35"}, {"y": 216, "x": 320, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ea978b0be2cd750fa9a4f5236cf7c0755b598d8"}, {"y": 433, "x": 640, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e686e3402e5b14deadc44a1ec473d43893024ce1"}, {"y": 650, "x": 960, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=340c591a86b166e6c13153e12d98b6498710743f"}, {"y": 731, "x": 1080, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f2463c87b35ad6c5eb769e526c788171da9a3e8"}], "s": {"y": 824, "x": 1216, "u": "https://preview.redd.it/gv9bnai3idac1.jpg?width=1216&amp;format=pjpg&amp;auto=webp&amp;s=c6a59de5ca50443416c4acdd2512e15f285a3943"}, "id": "gv9bnai3idac1"}, "6amehji3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 41, "x": 108, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=126e2e83320cbd8082f166885a725f5807dfb0b0"}, {"y": 82, "x": 216, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4343354b6e7dc911251729fc5333c83eb9f6f807"}, {"y": 122, "x": 320, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1db9acafa7a8ad661cad9b93689c6599e2ac18a"}, {"y": 244, "x": 640, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3bf53c2a43b4c5b2d3a5262fd42f04166a5efd07"}, {"y": 367, "x": 960, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ffc9a780db010ec7be8d6c2d6faa0b2392bf762e"}, {"y": 412, "x": 1080, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=22b96a3b83f6e2d669596ebac6d78e7c956f85ed"}], "s": {"y": 471, "x": 1232, "u": "https://preview.redd.it/6amehji3idac1.jpg?width=1232&amp;format=pjpg&amp;auto=webp&amp;s=4a5cd91fa5845ac5905734e2bcc0e0b9b53597f9"}, "id": "6amehji3idac1"}, "4kcqvci3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=514a34d5f4251809ce8e4e627db84dafe89f1003"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9314b632edb771992357b2e362fa947c81f5db08"}, {"y": 225, "x": 320, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ebca0cf04b5ad19b0de351592c79f5e6118df60"}, {"y": 451, "x": 640, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=26c063e99705b29790edafa27a8f24d42f7c8c83"}, {"y": 677, "x": 960, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d266decd4922168ca47941f4bb99793cda8e753"}, {"y": 762, "x": 1080, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=12f61a7ed1d902b1a5acf4e2426d56465c6561e1"}], "s": {"y": 859, "x": 1217, "u": "https://preview.redd.it/4kcqvci3idac1.jpg?width=1217&amp;format=pjpg&amp;auto=webp&amp;s=580c5f922e58993125a8e625b17876bd07b1aea7"}, "id": "4kcqvci3idac1"}, "xjmjymi3idac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b311ab7d6bfdcc8dfcbd73639b6455d0863cf56c"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e53dbe40af9a58fda3bdd41d327d9c69594a86c"}, {"y": 85, "x": 320, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9bb3c0bec847ff67407839eb7d113b6a19bcf66a"}, {"y": 171, "x": 640, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e969ac929d8ab0807a96093e066daae999ddbd83"}, {"y": 257, "x": 960, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=68bcc8db251151d5588f674d34f67820cfed1be4"}, {"y": 289, "x": 1080, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f5f043251a2eabb30a43628c41f3fb945bd3a3a0"}], "s": {"y": 298, "x": 1112, "u": "https://preview.redd.it/xjmjymi3idac1.jpg?width=1112&amp;format=pjpg&amp;auto=webp&amp;s=2db266bda590c5aa7a2f5ff0e292fb7fdc260ecc"}, "id": "xjmjymi3idac1"}}, "name": "t3_18y71el", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ek0WWwoYmLOq9QQci9ZmaQH724z1ItU7b_Ii6dvTjBE.jpg", "edited": 1704352633.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704352121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;first of all, I&amp;#39;m sorry for my bad English; it&amp;#39;s not my native language.&lt;/p&gt;\n\n&lt;p&gt;Now to my problem, maybe some can help me.&lt;/p&gt;\n\n&lt;p&gt;I found my old shucked HDD, which I left because I thought at the time it was defective.&lt;/p&gt;\n\n&lt;p&gt;Now, after some years, I&amp;#39;m trying it again.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ta7s1kjejdac1.jpg?width=1005&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ea8a0725b90d63c49c1b91a4c7ae809f118cca27\"&gt;https://preview.redd.it/ta7s1kjejdac1.jpg?width=1005&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ea8a0725b90d63c49c1b91a4c7ae809f118cca27&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;HDD Model: WDC WD 10 0EZAZ-11TDBA0 (Western Digital White Label)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I shucked the HDD, but it cannot be initialized on Windows.&lt;/p&gt;\n\n&lt;p&gt;What I tried:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Covering the three pins for the 3.3 Volt (maybe I didn&amp;#39;t do it correctly, I ordered Kapton tapes)&lt;/li&gt;\n&lt;li&gt;Using a USB HDD Adapter&lt;/li&gt;\n&lt;li&gt;I tried with a MOLEX Cable&lt;/li&gt;\n&lt;li&gt;Using different programs like (Partition Master &amp;amp; AOMEI)&lt;/li&gt;\n&lt;li&gt;In program tests, it&amp;#39;s written that every sector is defective.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The HDD is spinning, but nothing more.&lt;/p&gt;\n\n&lt;p&gt;Can it be that the HDD is encrypted with the WD Western Digital USB Bridge and is locked now? I don&amp;#39;t have the  USB Bridge Module anymore, but I know the old password.&lt;/p&gt;\n\n&lt;p&gt;Should I try with LINUX UBUNTU to unlock it? I never used UBUNTU, but there are some YouTube tutorials on how to do it.&lt;/p&gt;\n\n&lt;p&gt;Or is the HDD just defective?&lt;/p&gt;\n\n&lt;p&gt;I will add some pictures of the Data on the HDD.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wax9q3i3idac1.jpg?width=1459&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=3a7dc5e0d02cbb67921a9200d4997f2b87a678b9\"&gt;https://preview.redd.it/wax9q3i3idac1.jpg?width=1459&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=3a7dc5e0d02cbb67921a9200d4997f2b87a678b9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ib3047i3idac1.jpg?width=2587&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2c8faf84b8233dc81cfc55bce089fb33266e2253\"&gt;https://preview.redd.it/ib3047i3idac1.jpg?width=2587&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2c8faf84b8233dc81cfc55bce089fb33266e2253&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gv9bnai3idac1.jpg?width=1216&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c6a59de5ca50443416c4acdd2512e15f285a3943\"&gt;https://preview.redd.it/gv9bnai3idac1.jpg?width=1216&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c6a59de5ca50443416c4acdd2512e15f285a3943&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4kcqvci3idac1.jpg?width=1217&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=580c5f922e58993125a8e625b17876bd07b1aea7\"&gt;https://preview.redd.it/4kcqvci3idac1.jpg?width=1217&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=580c5f922e58993125a8e625b17876bd07b1aea7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bj2ujgi3idac1.jpg?width=1761&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=02a54497626c01ed5b0512af6e7a6dfec6347db3\"&gt;https://preview.redd.it/bj2ujgi3idac1.jpg?width=1761&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=02a54497626c01ed5b0512af6e7a6dfec6347db3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6amehji3idac1.jpg?width=1232&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4a5cd91fa5845ac5905734e2bcc0e0b9b53597f9\"&gt;https://preview.redd.it/6amehji3idac1.jpg?width=1232&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4a5cd91fa5845ac5905734e2bcc0e0b9b53597f9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xjmjymi3idac1.jpg?width=1112&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2db266bda590c5aa7a2f5ff0e292fb7fdc260ecc\"&gt;https://preview.redd.it/xjmjymi3idac1.jpg?width=1112&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2db266bda590c5aa7a2f5ff0e292fb7fdc260ecc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oiuueqi3idac1.jpg?width=2065&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f4ff5c57cd7e114d4ec90c06feea634659921946\"&gt;https://preview.redd.it/oiuueqi3idac1.jpg?width=2065&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f4ff5c57cd7e114d4ec90c06feea634659921946&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y71el", "is_robot_indexable": true, "report_reasons": null, "author": "neso___", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y71el/shucked_hdd_white_label_not_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y71el/shucked_hdd_white_label_not_working/", "subreddit_subscribers": 723065, "created_utc": 1704352121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a couple used enterprise HGST Ultrastar sata drives and I am wondering what the best way to test them is on my MacOS??\n\nIs it worth using F3? Is there a good SMART tool to download for Mac that you recommend like smartmontools? ", "author_fullname": "t2_attol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to test HDD on MacOS??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xvj1z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704319447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a couple used enterprise HGST Ultrastar sata drives and I am wondering what the best way to test them is on my MacOS??&lt;/p&gt;\n\n&lt;p&gt;Is it worth using F3? Is there a good SMART tool to download for Mac that you recommend like smartmontools? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xvj1z", "is_robot_indexable": true, "report_reasons": null, "author": "d-cent", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xvj1z/software_to_test_hdd_on_macos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xvj1z/software_to_test_hdd_on_macos/", "subreddit_subscribers": 723065, "created_utc": 1704319447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Hoarders,\n\nAny know of a **minimalistic** tool (utility, script, etc.) that bulk creates creates empty folders named based on provided patterns (be it regex or anything else)?  Not looking for a file mover/sorter/re-name tool. Just trying to generate empty folders with ever changing patterns.\n\nHaving to structure text and excel files every time a new directory structure is needed for use with a batch script is tedious as hell.\n\nExample:   \n**Each line representing a new folder.** \n\nMAIN   \n\\-0001-0099   \n\\-0100-0199   \n\\-0200-0299   \n\\-up to 9900-9999.\n\n&amp;#x200B;\n\n2. Any know of a **minimalistic** tool (utility, script, etc.) that bulk sorts images &amp; video based on geolocation metadata? Not looking for a bloated full-fledged media manager/viewer/player app. Just looking to bulk sort.\n\n&amp;#x200B;\n\nExample:   \n**Each line representing a new folder.** \n\nBarbados  \n\\-13\u00b005'50.0N 59\u00b036'41.7W  \n\\-13\u00b002'43.8N 59\u00b031'36.3W\n\nAll  help is appreciated.  \n", "author_fullname": "t2_c0tub3mw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software Inquiry: Bulk Directory Creation Based on Pattern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xulg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704317184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Hoarders,&lt;/p&gt;\n\n&lt;p&gt;Any know of a &lt;strong&gt;minimalistic&lt;/strong&gt; tool (utility, script, etc.) that bulk creates creates empty folders named based on provided patterns (be it regex or anything else)?  Not looking for a file mover/sorter/re-name tool. Just trying to generate empty folders with ever changing patterns.&lt;/p&gt;\n\n&lt;p&gt;Having to structure text and excel files every time a new directory structure is needed for use with a batch script is tedious as hell.&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;br/&gt;\n&lt;strong&gt;Each line representing a new folder.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;MAIN&lt;br/&gt;\n-0001-0099&lt;br/&gt;\n-0100-0199&lt;br/&gt;\n-0200-0299&lt;br/&gt;\n-up to 9900-9999.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Any know of a &lt;strong&gt;minimalistic&lt;/strong&gt; tool (utility, script, etc.) that bulk sorts images &amp;amp; video based on geolocation metadata? Not looking for a bloated full-fledged media manager/viewer/player app. Just looking to bulk sort.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;br/&gt;\n&lt;strong&gt;Each line representing a new folder.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Barbados&lt;br/&gt;\n-13\u00b005&amp;#39;50.0N 59\u00b036&amp;#39;41.7W&lt;br/&gt;\n-13\u00b002&amp;#39;43.8N 59\u00b031&amp;#39;36.3W&lt;/p&gt;\n\n&lt;p&gt;All  help is appreciated.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xulg6", "is_robot_indexable": true, "report_reasons": null, "author": "DominusImundi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xulg6/software_inquiry_bulk_directory_creation_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xulg6/software_inquiry_bulk_directory_creation_based_on/", "subreddit_subscribers": 723065, "created_utc": 1704317184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've had a 3TB Seagate drive for.... not sure how long. Never dropped or damaged, still spins up and registers on my computer. The only problem is that it says there is 1.22TB of used space but the files that show in file explorer only account for 206GB of that. Tried to look if they were hidden files but no luck.\n\nContacted Seagate and they gave me their data recovery suite software. I ran that, and (20 hours later) I transfered 1.22TB of recovered files to a newer drive. Went back through the files and there are a whole lot of CSV, PDF, and DOC files that just won't open, plus all of the files have been renamed so I can't figure out which files exactly broke. There were also JPEG files that caused a message about the file format not being supported even though it was. I was told this meant the drive could have been corrupted?\n\nI found a local data recovery company who can look at the drive, but is there any chance of actually getting the original file names, folders and the non-working files back?", "author_fullname": "t2_rh851", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Corrupted external HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xtcff", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704314158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had a 3TB Seagate drive for.... not sure how long. Never dropped or damaged, still spins up and registers on my computer. The only problem is that it says there is 1.22TB of used space but the files that show in file explorer only account for 206GB of that. Tried to look if they were hidden files but no luck.&lt;/p&gt;\n\n&lt;p&gt;Contacted Seagate and they gave me their data recovery suite software. I ran that, and (20 hours later) I transfered 1.22TB of recovered files to a newer drive. Went back through the files and there are a whole lot of CSV, PDF, and DOC files that just won&amp;#39;t open, plus all of the files have been renamed so I can&amp;#39;t figure out which files exactly broke. There were also JPEG files that caused a message about the file format not being supported even though it was. I was told this meant the drive could have been corrupted?&lt;/p&gt;\n\n&lt;p&gt;I found a local data recovery company who can look at the drive, but is there any chance of actually getting the original file names, folders and the non-working files back?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xtcff", "is_robot_indexable": true, "report_reasons": null, "author": "SciFiGirl42", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xtcff/corrupted_external_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xtcff/corrupted_external_hdd/", "subreddit_subscribers": 723065, "created_utc": 1704314158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nIn 2020 I bought a QNAP 4 bay NAS with 4 Seagate Ironwolf Pro 4TB hard drives for my studio (I'm a filmmaker). I wanted to use it as a second back up for both my projects and video files. After three years I realized the NAS was useless, cause I lost my studio and it's too noisy to keep it as a home server.  \nSo I purchased a Yottamaster 4 Bay Raid Array to use the 4 Disks in RAID 5 Mode, cause I didn't want to throw away the money I spent on those 4 Seagate Ironwolf Pro drives.  \n\n\nIs it safe to use those drives on this RAID Array? I plan to use this only when I need to back up my projects (once every two or three months). Or should I just switch to external SSDs?  \n\n\nThanks", "author_fullname": "t2_mzi0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "from NAS to DAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xqfud", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704307229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;In 2020 I bought a QNAP 4 bay NAS with 4 Seagate Ironwolf Pro 4TB hard drives for my studio (I&amp;#39;m a filmmaker). I wanted to use it as a second back up for both my projects and video files. After three years I realized the NAS was useless, cause I lost my studio and it&amp;#39;s too noisy to keep it as a home server.&lt;br/&gt;\nSo I purchased a Yottamaster 4 Bay Raid Array to use the 4 Disks in RAID 5 Mode, cause I didn&amp;#39;t want to throw away the money I spent on those 4 Seagate Ironwolf Pro drives.  &lt;/p&gt;\n\n&lt;p&gt;Is it safe to use those drives on this RAID Array? I plan to use this only when I need to back up my projects (once every two or three months). Or should I just switch to external SSDs?  &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xqfud", "is_robot_indexable": true, "report_reasons": null, "author": "jokergio", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xqfud/from_nas_to_das/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xqfud/from_nas_to_das/", "subreddit_subscribers": 723065, "created_utc": 1704307229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm not that familiar with NAS so that's why I'm asking this,...which NAS server can I use to setup on my phone without having a PC?", "author_fullname": "t2_cmt2rl73", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using phone to setup NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xorrk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704303214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m not that familiar with NAS so that&amp;#39;s why I&amp;#39;m asking this,...which NAS server can I use to setup on my phone without having a PC?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xorrk", "is_robot_indexable": true, "report_reasons": null, "author": "WebSuccessful1987", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xorrk/using_phone_to_setup_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xorrk/using_phone_to_setup_nas/", "subreddit_subscribers": 723065, "created_utc": 1704303214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I have a RAIDZ1 array of 4 HDDs: 2x  Seagate Exos 7E8 (ST4000NM003A), 1x Toshiba MG08SDA400E and 1 WD  HUS726060ALS640. I use Grafana+Prometheus+Node Exporter for monitoring.\n\nhttps://preview.redd.it/zy8baap519ac1.png?width=912&amp;format=png&amp;auto=webp&amp;s=f7b7ec3d0764d807e13860590fbf13bc32683a48\n\nI  use 2 different recordsizes for datasets: 512K and 128K, the behavior  when writing to both datasets on hard drives is identical. But on the  left side of the graph you can see that Toshiba loads at 100% when  writing linearly to a dataset with a record size of 128k, and on the  right side there is a random recording to a dataset with a record size  of 512K.\n\nAll four drives are  Enterprise-class SAS HDD 7200RPM with CMR recording technology. I watch  their utilization during recording, and I see that the Toshiba  MG08SDA400E has a utilization about 3-4 times higher than other disks in  the array, and this HDD slows down the operation of the entire array as  a whole. I would like to figure out what this might be related to?\n\nI  tried changing the WCE parameter to 0 and 1 for different disks - it  doesn't affect anything. I suspected that Toshiba has SMR technology,  but I couldn't find the information in the official documentation.  In  online stores selling this disc, it is indicated that it is CMR and it  seems to be true given that it is expensive enterprise SAS-drive.\n\nThe screenshot shows that:\n\n* /sde and /sdd are Seagate Exos 7E8\n* /sdf is Toshiba\n* /sdg is WDC\n\nThe main load is recording (both linear and random).\n\nAnother  strange moment is that all 4 disks are in the same cage, and Toshiba's  temperature is noticeably 6-7 degrees lower than the rest. Maybe it's  running at 5400 RPM? Is this even possible if 7200 RPM is specified in  the datasheet?\n\nCan you tell me where to start troubleshooting?\n\nP.S. OS is Proxmox VE 7.4-17", "author_fullname": "t2_a1x30h51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is disk utilization in an array so much different?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zy8baap519ac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/zy8baap519ac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1e7780c636ae7e8e40d82e0988fd79ded9e14e0"}, {"y": 103, "x": 216, "u": "https://preview.redd.it/zy8baap519ac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=17963727792f50b0604c7b99fa856662837f37c1"}, {"y": 153, "x": 320, "u": "https://preview.redd.it/zy8baap519ac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=33108ba58b1e30368b7a4b4a2579989bcea35da8"}, {"y": 306, "x": 640, "u": "https://preview.redd.it/zy8baap519ac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9925f35cfbd095c27ed5f6fe9300b3ca18ad29f"}], "s": {"y": 437, "x": 912, "u": "https://preview.redd.it/zy8baap519ac1.png?width=912&amp;format=png&amp;auto=webp&amp;s=f7b7ec3d0764d807e13860590fbf13bc32683a48"}, "id": "zy8baap519ac1"}}, "name": "t3_18xmwuj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GEeQVGAlHHy54chMDA36RZ-y7QHt3SWotIW8yYbUyNw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704298078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a RAIDZ1 array of 4 HDDs: 2x  Seagate Exos 7E8 (ST4000NM003A), 1x Toshiba MG08SDA400E and 1 WD  HUS726060ALS640. I use Grafana+Prometheus+Node Exporter for monitoring.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zy8baap519ac1.png?width=912&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f7b7ec3d0764d807e13860590fbf13bc32683a48\"&gt;https://preview.redd.it/zy8baap519ac1.png?width=912&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f7b7ec3d0764d807e13860590fbf13bc32683a48&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I  use 2 different recordsizes for datasets: 512K and 128K, the behavior  when writing to both datasets on hard drives is identical. But on the  left side of the graph you can see that Toshiba loads at 100% when  writing linearly to a dataset with a record size of 128k, and on the  right side there is a random recording to a dataset with a record size  of 512K.&lt;/p&gt;\n\n&lt;p&gt;All four drives are  Enterprise-class SAS HDD 7200RPM with CMR recording technology. I watch  their utilization during recording, and I see that the Toshiba  MG08SDA400E has a utilization about 3-4 times higher than other disks in  the array, and this HDD slows down the operation of the entire array as  a whole. I would like to figure out what this might be related to?&lt;/p&gt;\n\n&lt;p&gt;I  tried changing the WCE parameter to 0 and 1 for different disks - it  doesn&amp;#39;t affect anything. I suspected that Toshiba has SMR technology,  but I couldn&amp;#39;t find the information in the official documentation.  In  online stores selling this disc, it is indicated that it is CMR and it  seems to be true given that it is expensive enterprise SAS-drive.&lt;/p&gt;\n\n&lt;p&gt;The screenshot shows that:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;/sde and /sdd are Seagate Exos 7E8&lt;/li&gt;\n&lt;li&gt;/sdf is Toshiba&lt;/li&gt;\n&lt;li&gt;/sdg is WDC&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The main load is recording (both linear and random).&lt;/p&gt;\n\n&lt;p&gt;Another  strange moment is that all 4 disks are in the same cage, and Toshiba&amp;#39;s  temperature is noticeably 6-7 degrees lower than the rest. Maybe it&amp;#39;s  running at 5400 RPM? Is this even possible if 7200 RPM is specified in  the datasheet?&lt;/p&gt;\n\n&lt;p&gt;Can you tell me where to start troubleshooting?&lt;/p&gt;\n\n&lt;p&gt;P.S. OS is Proxmox VE 7.4-17&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xmwuj", "is_robot_indexable": true, "report_reasons": null, "author": "Hatred_grows", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xmwuj/why_is_disk_utilization_in_an_array_so_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xmwuj/why_is_disk_utilization_in_an_array_so_much/", "subreddit_subscribers": 723065, "created_utc": 1704298078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone.\n\nSome time ago I wanted to use my Canopus ADVC-1394 card, which had been gathering dust for years (as previously I used MBP from 2012 for such scenarios), to re-digitize VHS archives I have atm.\n\nOn Windows 7 I got no output of it whatsoever (mb just forgor to install legacy FireWire drivers), so I installed Windows XP. There I could capture DV streams from my JVC SR-VS30 VCR, though I also wanted to take some advantages (none?) of using composite inputs. And, sure enough, it didn't work.\n\nAmong the utilities I've tested yet were WinDV, VirtualDub, Edius and Ulead MediaStudio.\n\nAny advices?", "author_fullname": "t2_e89jxe2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADVC-1394 for Advanced", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yahlj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704365941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone.&lt;/p&gt;\n\n&lt;p&gt;Some time ago I wanted to use my Canopus ADVC-1394 card, which had been gathering dust for years (as previously I used MBP from 2012 for such scenarios), to re-digitize VHS archives I have atm.&lt;/p&gt;\n\n&lt;p&gt;On Windows 7 I got no output of it whatsoever (mb just forgor to install legacy FireWire drivers), so I installed Windows XP. There I could capture DV streams from my JVC SR-VS30 VCR, though I also wanted to take some advantages (none?) of using composite inputs. And, sure enough, it didn&amp;#39;t work.&lt;/p&gt;\n\n&lt;p&gt;Among the utilities I&amp;#39;ve tested yet were WinDV, VirtualDub, Edius and Ulead MediaStudio.&lt;/p&gt;\n\n&lt;p&gt;Any advices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18yahlj", "is_robot_indexable": true, "report_reasons": null, "author": "prizmech", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18yahlj/advc1394_for_advanced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18yahlj/advc1394_for_advanced/", "subreddit_subscribers": 723065, "created_utc": 1704365941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, first time poster here and new into storage solutions.\n\nJust purchased a 2 bay DAS to set up in RAID 1 as I want a complete mirror of an 8TB drive. I'm using it for archival purposes offloading completed projects as I finish them.\n\nI couldn't find a good answer, and though I think the answer is no, my question is:\n\nDoes a DAS need to be constantly connected to your computer? I am going to leave it plugged into power and on, but in regards to the connection to the computer, does it always have to be connected? I envision myself connecting to computer, offloading whatever I need to offload, and then disconnecting, like an external drive. \n\nWould this present any issues/concerns? \n\nThank you!", "author_fullname": "t2_tfexy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does DAS always have to be connected to computer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y2xhd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704338632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, first time poster here and new into storage solutions.&lt;/p&gt;\n\n&lt;p&gt;Just purchased a 2 bay DAS to set up in RAID 1 as I want a complete mirror of an 8TB drive. I&amp;#39;m using it for archival purposes offloading completed projects as I finish them.&lt;/p&gt;\n\n&lt;p&gt;I couldn&amp;#39;t find a good answer, and though I think the answer is no, my question is:&lt;/p&gt;\n\n&lt;p&gt;Does a DAS need to be constantly connected to your computer? I am going to leave it plugged into power and on, but in regards to the connection to the computer, does it always have to be connected? I envision myself connecting to computer, offloading whatever I need to offload, and then disconnecting, like an external drive. &lt;/p&gt;\n\n&lt;p&gt;Would this present any issues/concerns? &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y2xhd", "is_robot_indexable": true, "report_reasons": null, "author": "frankymas", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y2xhd/does_das_always_have_to_be_connected_to_computer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y2xhd/does_das_always_have_to_be_connected_to_computer/", "subreddit_subscribers": 723065, "created_utc": 1704338632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI\u2019m struggling to find the differences between those two western digital purple pro models.\n\nI understand that the last letter doesn\u2019t matter, it seems to be related to the region?\n\nWhat about 101 vs 102? I can\u2019t find the difference anywhere online.\n\nThank you.", "author_fullname": "t2_ntaon", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD101PURP vs WD102PURX HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18y1vx8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704335656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m struggling to find the differences between those two western digital purple pro models.&lt;/p&gt;\n\n&lt;p&gt;I understand that the last letter doesn\u2019t matter, it seems to be related to the region?&lt;/p&gt;\n\n&lt;p&gt;What about 101 vs 102? I can\u2019t find the difference anywhere online.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18y1vx8", "is_robot_indexable": true, "report_reasons": null, "author": "jpbourdeau", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18y1vx8/wd101purp_vs_wd102purx_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18y1vx8/wd101purp_vs_wd102purx_hdd/", "subreddit_subscribers": 723065, "created_utc": 1704335656.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}