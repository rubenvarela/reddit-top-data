{"kind": "Listing", "data": {"after": "t3_192o9cg", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My wife isn't a fan of me hoarding lots of drives, and I completely understand her perspective. Also lately, I been swapping out drives in my NAS, which houses a total of 10 drives, mostly 2TB and 3TB WD Red NAS drives. I been destroying a few drives, including SSDs, resulting in around 13 or 15 casualties so far.\n\nBut, the process is starting to feel a bit sad, and I still have a few outdated drives remaining, two of which have accumulated nearly 90,000 hours of runtime. Any creative ideas on how I can have some fun repurposing or disposing of these old drives?", "author_fullname": "t2_5tsmwe62", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The destruction of hard drives in my home has begun, but seriously, what alternative options do I have instead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192hzyp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704816049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My wife isn&amp;#39;t a fan of me hoarding lots of drives, and I completely understand her perspective. Also lately, I been swapping out drives in my NAS, which houses a total of 10 drives, mostly 2TB and 3TB WD Red NAS drives. I been destroying a few drives, including SSDs, resulting in around 13 or 15 casualties so far.&lt;/p&gt;\n\n&lt;p&gt;But, the process is starting to feel a bit sad, and I still have a few outdated drives remaining, two of which have accumulated nearly 90,000 hours of runtime. Any creative ideas on how I can have some fun repurposing or disposing of these old drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192hzyp", "is_robot_indexable": true, "report_reasons": null, "author": "bilstream", "discussion_type": null, "num_comments": 109, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192hzyp/the_destruction_of_hard_drives_in_my_home_has/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192hzyp/the_destruction_of_hard_drives_in_my_home_has/", "subreddit_subscribers": 724294, "created_utc": 1704816049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello DataHoarders, I see people hoarding TBs of content. What do you do with it. I myswlf have a couple of TBs (mostly digitized family pics and some series and movies). Combined doesn't cross 6TB. I am curious as to what you would do with the data?\n\nThanks in advance for your responses.", "author_fullname": "t2_68f29j4b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do with your content?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19221x3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704763129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DataHoarders, I see people hoarding TBs of content. What do you do with it. I myswlf have a couple of TBs (mostly digitized family pics and some series and movies). Combined doesn&amp;#39;t cross 6TB. I am curious as to what you would do with the data?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19221x3", "is_robot_indexable": true, "report_reasons": null, "author": "lordjinesh", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19221x3/what_do_you_do_with_your_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19221x3/what_do_you_do_with_your_content/", "subreddit_subscribers": 724294, "created_utc": 1704763129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_76d1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Its not THAT bad is it?? /s", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "name": "t3_1923uho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zOYgRmcqBa5hdmyURL5lNQIB5-COxDqJTOJDjqxTTWE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704768151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/nYFvpAo.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/woQz-lO8mh-edHU2TR_tH4S6jULXDjDGS-nyMfnI_Qg.png?auto=webp&amp;s=cb6cc5ddd3b8eb28a12d3c01c835b1f4599d78b7", "width": 637, "height": 288}, "resolutions": [{"url": "https://external-preview.redd.it/woQz-lO8mh-edHU2TR_tH4S6jULXDjDGS-nyMfnI_Qg.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ae594a9150baa857dc56c4a26d2c2ae923dfdbb", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/woQz-lO8mh-edHU2TR_tH4S6jULXDjDGS-nyMfnI_Qg.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=294e5728a82adc9758031e804e21dc1dc72e5693", "width": 216, "height": 97}, {"url": "https://external-preview.redd.it/woQz-lO8mh-edHU2TR_tH4S6jULXDjDGS-nyMfnI_Qg.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9bebb0ae0aba1b99ed6d70332419cb9aca17ac84", "width": 320, "height": 144}], "variants": {}, "id": "Vn2a7OOo5xLN_O4p-VXEJOiGy7Lme8kxQteApzfhB2I"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1923uho", "is_robot_indexable": true, "report_reasons": null, "author": "LynchMob_Lerry", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1923uho/its_not_that_bad_is_it_s/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/nYFvpAo.png", "subreddit_subscribers": 724294, "created_utc": 1704768151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a hoard that's about 30 years in the making. I have backups on CD-R/DVD-R/HDD of:\n\n- personal garbage\n- movies\n- CDs\n- rare music (FLAC/Ogg/MP3/MPA)\n- software development\n- software install packages\n- Video game saves and play throughs\n- Old game ISOs to mount and install and run\n- Table top game PDFs\n- Family Pictures / Video\n- Machine backups\n\nI'm looking to discard my current backup solution (an older Windows Server Dell P4 blade server with 3.5\" 6 drive bays) for something newer. Features I want to have are parity and striping, though potentially using platter drives that vary in size and that I can add to my new solution when I get spare cash or a sale comes up or if I want to upgrade 1 or 2 drives. UNRAID OS seems to be the area that I'm honing in on.\n\nFurthermore, I have several Smart TVs, Roku and Android in my home, as well as several Alexas. I have 2 or 3 personal laptops (one for professional-ish development, one for gaming, wife has one, kids will have one soon enough). We have several Amazon Kindle Fire Kids tablets. My home is wired with CAT 6, so bandwidth isn't an issue.\n\nAll this is to fish for suggestions for my next setup. I like the idea of Plex, but I have a large number of backups that are ISO -- back in the day I ran PS3 Media Server which allowed me to navigate _into_ an ISO and play back specific titles on my PS3/laptop. I'd love to connect Alexa to some of my rarer music at times that's not in service catalogs. I'm a dev and would also like to be able to run things on this NAS-y server (such as Plex or alternatives) by installing things on containers to spin up, run off the machine and spin down if I find it's not useful.\n\nWhat kind of practical uses do fellow hoarders connect to in their homes?", "author_fullname": "t2_116xv2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Putting my hoard to use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1927sqb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704780364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a hoard that&amp;#39;s about 30 years in the making. I have backups on CD-R/DVD-R/HDD of:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;personal garbage&lt;/li&gt;\n&lt;li&gt;movies&lt;/li&gt;\n&lt;li&gt;CDs&lt;/li&gt;\n&lt;li&gt;rare music (FLAC/Ogg/MP3/MPA)&lt;/li&gt;\n&lt;li&gt;software development&lt;/li&gt;\n&lt;li&gt;software install packages&lt;/li&gt;\n&lt;li&gt;Video game saves and play throughs&lt;/li&gt;\n&lt;li&gt;Old game ISOs to mount and install and run&lt;/li&gt;\n&lt;li&gt;Table top game PDFs&lt;/li&gt;\n&lt;li&gt;Family Pictures / Video&lt;/li&gt;\n&lt;li&gt;Machine backups&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m looking to discard my current backup solution (an older Windows Server Dell P4 blade server with 3.5&amp;quot; 6 drive bays) for something newer. Features I want to have are parity and striping, though potentially using platter drives that vary in size and that I can add to my new solution when I get spare cash or a sale comes up or if I want to upgrade 1 or 2 drives. UNRAID OS seems to be the area that I&amp;#39;m honing in on.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, I have several Smart TVs, Roku and Android in my home, as well as several Alexas. I have 2 or 3 personal laptops (one for professional-ish development, one for gaming, wife has one, kids will have one soon enough). We have several Amazon Kindle Fire Kids tablets. My home is wired with CAT 6, so bandwidth isn&amp;#39;t an issue.&lt;/p&gt;\n\n&lt;p&gt;All this is to fish for suggestions for my next setup. I like the idea of Plex, but I have a large number of backups that are ISO -- back in the day I ran PS3 Media Server which allowed me to navigate &lt;em&gt;into&lt;/em&gt; an ISO and play back specific titles on my PS3/laptop. I&amp;#39;d love to connect Alexa to some of my rarer music at times that&amp;#39;s not in service catalogs. I&amp;#39;m a dev and would also like to be able to run things on this NAS-y server (such as Plex or alternatives) by installing things on containers to spin up, run off the machine and spin down if I find it&amp;#39;s not useful.&lt;/p&gt;\n\n&lt;p&gt;What kind of practical uses do fellow hoarders connect to in their homes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1927sqb", "is_robot_indexable": true, "report_reasons": null, "author": "Bardez", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1927sqb/putting_my_hoard_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1927sqb/putting_my_hoard_to_use/", "subreddit_subscribers": 724294, "created_utc": 1704780364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Although I personally have barely used OS/2, this does seem like a shame to lose. If you're interested in archiving it, it's at [https://hobbes.nmsu.edu](https://hobbes.nmsu.edu). I'm personally planning to create an archive at some point.\n\nThis originally showed up on [Hacker News](https://news.ycombinator.com/item?id=38929369).", "author_fullname": "t2_5yh3j5m3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Hobbes OS/2 archive will disappear on April 15", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192p8jc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704833450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Although I personally have barely used OS/2, this does seem like a shame to lose. If you&amp;#39;re interested in archiving it, it&amp;#39;s at &lt;a href=\"https://hobbes.nmsu.edu\"&gt;https://hobbes.nmsu.edu&lt;/a&gt;. I&amp;#39;m personally planning to create an archive at some point.&lt;/p&gt;\n\n&lt;p&gt;This originally showed up on &lt;a href=\"https://news.ycombinator.com/item?id=38929369\"&gt;Hacker News&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192p8jc", "is_robot_indexable": true, "report_reasons": null, "author": "Loren-DB", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192p8jc/the_hobbes_os2_archive_will_disappear_on_april_15/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192p8jc/the_hobbes_os2_archive_will_disappear_on_april_15/", "subreddit_subscribers": 724294, "created_utc": 1704833450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I am not sure if this is common thing to do or even a sensible thing to do but for my media files I use torrents as the checksum. In some cases, I already have the torrent file that I downloaded from the tracker and when I don't have one I create a torrent file and load it to the torrent client. Whenever I need to check checksum, I just use force recheck option on the torrent client.\n\nIs there anything wrong with this setup? I realize it might be odd and there are probably better solutions but it just works for me and I don't want to switch it if possible.", "author_fullname": "t2_r687it3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any reason why I shouldn't be using torrent files as checksum?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192mnwo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704827311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am not sure if this is common thing to do or even a sensible thing to do but for my media files I use torrents as the checksum. In some cases, I already have the torrent file that I downloaded from the tracker and when I don&amp;#39;t have one I create a torrent file and load it to the torrent client. Whenever I need to check checksum, I just use force recheck option on the torrent client.&lt;/p&gt;\n\n&lt;p&gt;Is there anything wrong with this setup? I realize it might be odd and there are probably better solutions but it just works for me and I don&amp;#39;t want to switch it if possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Unraid |  35TB usable", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192mnwo", "is_robot_indexable": true, "report_reasons": null, "author": "lemmeanon", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/192mnwo/any_reason_why_i_shouldnt_be_using_torrent_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192mnwo/any_reason_why_i_shouldnt_be_using_torrent_files/", "subreddit_subscribers": 724294, "created_utc": 1704827311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wondering if there is a way to save money before buying it at full price.", "author_fullname": "t2_169yso", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has StableBits DrivePool ever been on sale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192gqcd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704812702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if there is a way to save money before buying it at full price.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192gqcd", "is_robot_indexable": true, "report_reasons": null, "author": "0key0key", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192gqcd/has_stablebits_drivepool_ever_been_on_sale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192gqcd/has_stablebits_drivepool_ever_been_on_sale/", "subreddit_subscribers": 724294, "created_utc": 1704812702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " The Community Forum of a Minecraft server is set to close after 8 years.  My goal is to archive as much content as possible from the forum.  Access to the content is restricted to logged-in accounts, and the forum  operates using WoltLab Suite software. What steps should I take to  archive as much content as possible? ", "author_fullname": "t2_6z55xcb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I archive an entire Forum?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192lfgx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704824351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The Community Forum of a Minecraft server is set to close after 8 years.  My goal is to archive as much content as possible from the forum.  Access to the content is restricted to logged-in accounts, and the forum  operates using WoltLab Suite software. What steps should I take to  archive as much content as possible? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192lfgx", "is_robot_indexable": true, "report_reasons": null, "author": "TheOneFromEarth", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192lfgx/how_would_i_archive_an_entire_forum/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192lfgx/how_would_i_archive_an_entire_forum/", "subreddit_subscribers": 724294, "created_utc": 1704824351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I think it's obvious, but just to make sure before buying, I want to use an HDD as external cold storage, I will make a system image backup OR I could back up some files without doing a complete system image, it depends on what I will settle on.\n\n\nI will backup the files (or the system image) and the drive won't be accessed or used for a long time. So, is using video HDD for this purpose a good thing? like this below one? or I need PC/laptop HDD?:\n\n\nSeagate Video 2.5 HDD 500GB - ST500VT000  \nhttps://www.seagate.com/em/en/support/internal-hard-drives/consumer-electronics/video-2-5-hdd/", "author_fullname": "t2_zdphv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does using video HDD as cold external storage drive is a bad thing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192j0bw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704818523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think it&amp;#39;s obvious, but just to make sure before buying, I want to use an HDD as external cold storage, I will make a system image backup OR I could back up some files without doing a complete system image, it depends on what I will settle on.&lt;/p&gt;\n\n&lt;p&gt;I will backup the files (or the system image) and the drive won&amp;#39;t be accessed or used for a long time. So, is using video HDD for this purpose a good thing? like this below one? or I need PC/laptop HDD?:&lt;/p&gt;\n\n&lt;p&gt;Seagate Video 2.5 HDD 500GB - ST500VT000&lt;br/&gt;\n&lt;a href=\"https://www.seagate.com/em/en/support/internal-hard-drives/consumer-electronics/video-2-5-hdd/\"&gt;https://www.seagate.com/em/en/support/internal-hard-drives/consumer-electronics/video-2-5-hdd/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?auto=webp&amp;s=b98f58f088fdf8fbeb225a485466816520892a66", "width": 1440, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=800aeac928e4d6917cdf3db161d37c173da92af5", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a9549b2c27b55813f6941439e0246cac408ff1d", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=708b52a8cc3161e776c554b1f4a488231d8bfce6", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=93eb129bea186541cdd32a88a0cb2d619f9a954c", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ad5e3bcc25ba7cdf8dd591fb8e247b839fe5aa7", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b52b8bf108499e8a6d3bd58f428c8f644af3085", "width": 1080, "height": 675}], "variants": {}, "id": "GJ9K1o7VNo6J4JXg3IrZBPizWfgWXRc6b6FmSaP5cNc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192j0bw", "is_robot_indexable": true, "report_reasons": null, "author": "abdo_shahba", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192j0bw/does_using_video_hdd_as_cold_external_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192j0bw/does_using_video_hdd_as_cold_external_storage/", "subreddit_subscribers": 724294, "created_utc": 1704818523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys,\n\nI'm planning to upgrade my homeserver and I'd like some advice.\n\nI am currently running a JBOD setup with 3x12TB (linux isos) and 2x4TB (media) on OMV 6.xx. However I want to upgrade and make sure my data isn't lost in case of drive failure.\n\nI'm contemplating switching to Unraid because it allows me to add disks in the future and it accepts disks of different sizes.\n\nThe idea would be to run my old i5 8600k + 32GB ram with:\n\n3x 12TB (that I currently own)\n\n3-5x 18-20 TB (replacing the current 2x4TB)\n\nI mainly run the following dockers: \n\n&amp;#x200B;\n\n1. Stashapp\n2. Wordpress (test enviroment), not high traffic website\n3. Radarr\n4. Sonarr\n5. Jellyfin\n6. Qbittorrent (actively seeding 6k+ torrents)\n7. Watchtower\n8. Wireguard VPN\n9. Discord bot\n10. Homarr organizer\n11. Freqtrade (2-3 strats)\n12. Pihole\n\n&amp;#x200B;\n\nIf you guys were to start fresh, how would you go about things regarding OS, RAID and ZFS?\n\n&amp;#x200B;", "author_fullname": "t2_jcfky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading my homeserver", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192gzb1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704814504.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704813389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to upgrade my homeserver and I&amp;#39;d like some advice.&lt;/p&gt;\n\n&lt;p&gt;I am currently running a JBOD setup with 3x12TB (linux isos) and 2x4TB (media) on OMV 6.xx. However I want to upgrade and make sure my data isn&amp;#39;t lost in case of drive failure.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m contemplating switching to Unraid because it allows me to add disks in the future and it accepts disks of different sizes.&lt;/p&gt;\n\n&lt;p&gt;The idea would be to run my old i5 8600k + 32GB ram with:&lt;/p&gt;\n\n&lt;p&gt;3x 12TB (that I currently own)&lt;/p&gt;\n\n&lt;p&gt;3-5x 18-20 TB (replacing the current 2x4TB)&lt;/p&gt;\n\n&lt;p&gt;I mainly run the following dockers: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Stashapp&lt;/li&gt;\n&lt;li&gt;Wordpress (test enviroment), not high traffic website&lt;/li&gt;\n&lt;li&gt;Radarr&lt;/li&gt;\n&lt;li&gt;Sonarr&lt;/li&gt;\n&lt;li&gt;Jellyfin&lt;/li&gt;\n&lt;li&gt;Qbittorrent (actively seeding 6k+ torrents)&lt;/li&gt;\n&lt;li&gt;Watchtower&lt;/li&gt;\n&lt;li&gt;Wireguard VPN&lt;/li&gt;\n&lt;li&gt;Discord bot&lt;/li&gt;\n&lt;li&gt;Homarr organizer&lt;/li&gt;\n&lt;li&gt;Freqtrade (2-3 strats)&lt;/li&gt;\n&lt;li&gt;Pihole&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you guys were to start fresh, how would you go about things regarding OS, RAID and ZFS?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192gzb1", "is_robot_indexable": true, "report_reasons": null, "author": "roogie15", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192gzb1/upgrading_my_homeserver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192gzb1/upgrading_my_homeserver/", "subreddit_subscribers": 724294, "created_utc": 1704813389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Things are getting serious.\n\nhttps://preview.redd.it/7277w95j4ebc1.png?width=1708&amp;format=png&amp;auto=webp&amp;s=312e8bc5adba545c5fc1f32ebd5aab9ac37425a6", "author_fullname": "t2_2gbfxsdx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New year, new drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 51, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7277w95j4ebc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/7277w95j4ebc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6463e5f15b7f61fb4e41454e1973ee4c0dd790ea"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/7277w95j4ebc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=523efe8243501a32c2230d192f184b5940b47b57"}, {"y": 116, "x": 320, "u": "https://preview.redd.it/7277w95j4ebc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=de866f09ca97b6a95eb9ffb10eec0631a508a0e7"}, {"y": 233, "x": 640, "u": "https://preview.redd.it/7277w95j4ebc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0720582bafe238d07c0bc4ba86d7b5f569c194b1"}, {"y": 350, "x": 960, "u": "https://preview.redd.it/7277w95j4ebc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=192c72b3a1e1ee22105acf9c26706d57121de673"}, {"y": 393, "x": 1080, "u": "https://preview.redd.it/7277w95j4ebc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9ef85919bbe2e4e6c50eb50598b8a7ee9ef1fbb8"}], "s": {"y": 623, "x": 1708, "u": "https://preview.redd.it/7277w95j4ebc1.png?width=1708&amp;format=png&amp;auto=webp&amp;s=312e8bc5adba545c5fc1f32ebd5aab9ac37425a6"}, "id": "7277w95j4ebc1"}}, "name": "t3_192bktx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4wApcgs0ejrj-4yiEuMlK7KtYdCvYq2P3abbckEZxrA.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704795608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Things are getting serious.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7277w95j4ebc1.png?width=1708&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=312e8bc5adba545c5fc1f32ebd5aab9ac37425a6\"&gt;https://preview.redd.it/7277w95j4ebc1.png?width=1708&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=312e8bc5adba545c5fc1f32ebd5aab9ac37425a6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "182TB unRAID", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192bktx", "is_robot_indexable": true, "report_reasons": null, "author": "SpuddyUK", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/192bktx/new_year_new_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192bktx/new_year_new_drives/", "subreddit_subscribers": 724294, "created_utc": 1704795608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sometimes I download music to my PC and sometimes to my SD cards through other means. I\u2019d like to sync my various SD cards with folders on the PC. Is there anything out there that I should consider as an alternative to Goodsync?", "author_fullname": "t2_x7z9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Goodsync alternative?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192ai4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704791094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sometimes I download music to my PC and sometimes to my SD cards through other means. I\u2019d like to sync my various SD cards with folders on the PC. Is there anything out there that I should consider as an alternative to Goodsync?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192ai4u", "is_robot_indexable": true, "report_reasons": null, "author": "thanrl", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192ai4u/goodsync_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192ai4u/goodsync_alternative/", "subreddit_subscribers": 724294, "created_utc": 1704791094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m not 100% sure if this is the correct sub for my questions, but if not let me know and I\u2019ll take it elsewhere. It\u2019s just such a specific scenario I have no idea what the hell to google. \n\nI have a lot of cookbooks. Somewhere from 250-300 at an estimate. But when you have that many, you tend to find yourself going back to the same couple for recipes, since the sheer volume is so overwhelming, and you can\u2019t find a recipe when you need to, etc etc. \n\nA few years ago I started a paper index system using note cards. There were several general categories, such as meat, salads, desserts, etc, and then those would be further divided into subcategories such as savoury salads, sweet salads, morning tea, puddings, cakes, biscuits, chicken cuts, chicken mince, whole chicken, beef cuts, beef mince, pork cuts, pork mince, offal, etc, you get the idea. \nThe idea is that you have an ingredient you want to cook with, say chicken breast, go to the \u201cmeat\u201d tab, then the \u201cchicken cuts\u201d tab, and then look at the cards in there. I\u2019d just lump all the different types of chicken cuts together to save the exhaustion of having too many sub-cards to be so specific. On those cards I would have the recipe, then the book it comes from, and the page number. Then I could go find the right book and see if I like it. I\u2019ll attach a piccy. \n\nObviously, this takes a long time to record, especially by hand. I started back in about 2020, and have been doing it on and off since then. I\u2019ve probably tackled about 100 books. Shit is draining, especially when writing by hand. I haven\u2019t been terribly dedicated to it, but I am motivated to see if there\u2019s a digital way I can do things.\n\nMy archiving and statistics experience doesn\u2019t extend past organising pirated iTunes music, and using an excel spreadsheet. I may be Gen Z, but I possess the technical know-how and spirit of a ninety year old woman. I\u2019m hoping someone might have ideas to execute my vision in a way that doesn\u2019t involve excel. \n\nHere\u2019s what I\u2019m thinking: \n\nI type in a recipe name. I can then label it with the book it comes from, and what page. Then I can tag it with relevant info. Say it\u2019s a spaghetti bolognese. I could tag it with \u201cpasta\u201d AND \u201cbeef mince\u201d, instead of just putting it under pasta like I would in my paper system. Borscht I could tag with \u201csoup\u201d, \u201cbeef\u201d, \u201cbeetroot\u201d, and \u201croot vegetables\u201d instead of just \u201csoup\u201d. \nThat way I could tag recipes with lots of different things relevant to the ingredients and the setting, instead of just taking a wild guess at what the rest of the ingredients might be. \nThen, I could search for a specific tag when wanting ideas. I could tag with the type of cuisine, where it comes from, as well as the ingredients. Just be able to supply a lot more information than what I can cram onto the index cards. \n\nAny ideas?", "author_fullname": "t2_to3n8k84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recipe Archiving Advice - Moving to Digital", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1929n4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0_AfWNZhlJ_7bXy8BF5YZMIknzHg1uURX5AJUDKYARY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704787387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m not 100% sure if this is the correct sub for my questions, but if not let me know and I\u2019ll take it elsewhere. It\u2019s just such a specific scenario I have no idea what the hell to google. &lt;/p&gt;\n\n&lt;p&gt;I have a lot of cookbooks. Somewhere from 250-300 at an estimate. But when you have that many, you tend to find yourself going back to the same couple for recipes, since the sheer volume is so overwhelming, and you can\u2019t find a recipe when you need to, etc etc. &lt;/p&gt;\n\n&lt;p&gt;A few years ago I started a paper index system using note cards. There were several general categories, such as meat, salads, desserts, etc, and then those would be further divided into subcategories such as savoury salads, sweet salads, morning tea, puddings, cakes, biscuits, chicken cuts, chicken mince, whole chicken, beef cuts, beef mince, pork cuts, pork mince, offal, etc, you get the idea. \nThe idea is that you have an ingredient you want to cook with, say chicken breast, go to the \u201cmeat\u201d tab, then the \u201cchicken cuts\u201d tab, and then look at the cards in there. I\u2019d just lump all the different types of chicken cuts together to save the exhaustion of having too many sub-cards to be so specific. On those cards I would have the recipe, then the book it comes from, and the page number. Then I could go find the right book and see if I like it. I\u2019ll attach a piccy. &lt;/p&gt;\n\n&lt;p&gt;Obviously, this takes a long time to record, especially by hand. I started back in about 2020, and have been doing it on and off since then. I\u2019ve probably tackled about 100 books. Shit is draining, especially when writing by hand. I haven\u2019t been terribly dedicated to it, but I am motivated to see if there\u2019s a digital way I can do things.&lt;/p&gt;\n\n&lt;p&gt;My archiving and statistics experience doesn\u2019t extend past organising pirated iTunes music, and using an excel spreadsheet. I may be Gen Z, but I possess the technical know-how and spirit of a ninety year old woman. I\u2019m hoping someone might have ideas to execute my vision in a way that doesn\u2019t involve excel. &lt;/p&gt;\n\n&lt;p&gt;Here\u2019s what I\u2019m thinking: &lt;/p&gt;\n\n&lt;p&gt;I type in a recipe name. I can then label it with the book it comes from, and what page. Then I can tag it with relevant info. Say it\u2019s a spaghetti bolognese. I could tag it with \u201cpasta\u201d AND \u201cbeef mince\u201d, instead of just putting it under pasta like I would in my paper system. Borscht I could tag with \u201csoup\u201d, \u201cbeef\u201d, \u201cbeetroot\u201d, and \u201croot vegetables\u201d instead of just \u201csoup\u201d. \nThat way I could tag recipes with lots of different things relevant to the ingredients and the setting, instead of just taking a wild guess at what the rest of the ingredients might be. \nThen, I could search for a specific tag when wanting ideas. I could tag with the type of cuisine, where it comes from, as well as the ingredients. Just be able to supply a lot more information than what I can cram onto the index cards. &lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9m3wjxi5gdbc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9m3wjxi5gdbc1.jpeg?auto=webp&amp;s=cd381a4aa9d8318e94a66bd1c6be6948a368346a", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/9m3wjxi5gdbc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0b9499e9ec8a339896ae11f3353aa51226d8994", "width": 108, "height": 144}, {"url": "https://preview.redd.it/9m3wjxi5gdbc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6c597d22af7a22ebceea7730c59c089475a1032", "width": 216, "height": 288}, {"url": "https://preview.redd.it/9m3wjxi5gdbc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2eb6d0c9a72586234a42f7267695177724ccc2b8", "width": 320, "height": 426}, {"url": "https://preview.redd.it/9m3wjxi5gdbc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a3dc7196c27f49d93a700bff37f3336e440661a0", "width": 640, "height": 853}, {"url": "https://preview.redd.it/9m3wjxi5gdbc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5166ccc787e80473b8af6e7615017f5324dd6347", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/9m3wjxi5gdbc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3d74284de96c579e134ac7ed01c58a209ff3a7b", "width": 1080, "height": 1440}], "variants": {}, "id": "RsHS5knAHDKkOOgR5AuQikr00HJ3QBrOFuMZlnw7aeI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1929n4p", "is_robot_indexable": true, "report_reasons": null, "author": "candlebox1976", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1929n4p/recipe_archiving_advice_moving_to_digital/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9m3wjxi5gdbc1.jpeg", "subreddit_subscribers": 724294, "created_utc": 1704787387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2018m looking for a Software that can copy files to optical media and with wich you can tell which disk contains what.\nIs something like this a thing?", "author_fullname": "t2_ogqsk2i6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Software to create Backups to Optical Media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192gmpn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704812432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2018m looking for a Software that can copy files to optical media and with wich you can tell which disk contains what.\nIs something like this a thing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192gmpn", "is_robot_indexable": true, "report_reasons": null, "author": "Basic_Macintosher", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192gmpn/best_software_to_create_backups_to_optical_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192gmpn/best_software_to_create_backups_to_optical_media/", "subreddit_subscribers": 724294, "created_utc": 1704812432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to shuck my 16tb wd elements external drive and put it inside my desktop tower, Ive never shucked an external drive before. I only use the 16tb drive for mirroring backup from my work drive which I carry around with me. Currently the 16tb drive takes ages to spin up so whenever I open my computer folder folder for example it hangs for awhile. Also it's very loud drive I can hear spinning and clicking. \n\nWill spin up speed improve when I move it on SATA data and power cables in my PC ? When I shuck the drive all I need to do is mount it and connect it to the SATA cables and it should just work ?", "author_fullname": "t2_bbrqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving 16tb we elements into a desktop PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192dm2b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704803294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to shuck my 16tb wd elements external drive and put it inside my desktop tower, Ive never shucked an external drive before. I only use the 16tb drive for mirroring backup from my work drive which I carry around with me. Currently the 16tb drive takes ages to spin up so whenever I open my computer folder folder for example it hangs for awhile. Also it&amp;#39;s very loud drive I can hear spinning and clicking. &lt;/p&gt;\n\n&lt;p&gt;Will spin up speed improve when I move it on SATA data and power cables in my PC ? When I shuck the drive all I need to do is mount it and connect it to the SATA cables and it should just work ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192dm2b", "is_robot_indexable": true, "report_reasons": null, "author": "Stormxlr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192dm2b/moving_16tb_we_elements_into_a_desktop_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192dm2b/moving_16tb_we_elements_into_a_desktop_pc/", "subreddit_subscribers": 724294, "created_utc": 1704803294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On the lookout for software, paid or open source, that can be installed on TrueNAS or Windows to help me sort out the mess of photos and videos I've dumped onto my NAS. It's the go-to place for our monthly phone and camera media dump, and now I'm thinking about getting it all organized by dates and locations. If you've got any honest recommendations and opinions, I'd really appreciate it! Just trying to simplify my life however I can!", "author_fullname": "t2_8uk8cotor", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which photo grouping/organization software do you recommend for managing a stash of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192aqgj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704792089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On the lookout for software, paid or open source, that can be installed on TrueNAS or Windows to help me sort out the mess of photos and videos I&amp;#39;ve dumped onto my NAS. It&amp;#39;s the go-to place for our monthly phone and camera media dump, and now I&amp;#39;m thinking about getting it all organized by dates and locations. If you&amp;#39;ve got any honest recommendations and opinions, I&amp;#39;d really appreciate it! Just trying to simplify my life however I can!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "192aqgj", "is_robot_indexable": true, "report_reasons": null, "author": "Reid0nly", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192aqgj/which_photo_groupingorganization_software_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192aqgj/which_photo_groupingorganization_software_do_you/", "subreddit_subscribers": 724294, "created_utc": 1704792089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am getting a new computer and was backing up the hard drives onto portable hard drives.  The first drive (which just had games and videos) worked perfectly.  When I use the same command to try to copy C: drive (which has windows and my documents) it only copies the C:\\\\users\\\\smili folder, nothing else.  I expected that there would be files that I wouldn't be allow to copy, such as system files, but this is baffling me.  \n\n\nHere is the command I am using.\n\nrobocopy \"C:\" \"F:\\\\C Drive Backup\" /W:1 /R:3 /E /V /XJD /TEE /ETA /DCOPY:T /FP /A-:SHRA\n\nAny help solving this mystery would be appreciated!\n\n  \n", "author_fullname": "t2_a2o6r0ms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Robocopy only copying current user folder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1929fcl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704786495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am getting a new computer and was backing up the hard drives onto portable hard drives.  The first drive (which just had games and videos) worked perfectly.  When I use the same command to try to copy C: drive (which has windows and my documents) it only copies the C:\\users\\smili folder, nothing else.  I expected that there would be files that I wouldn&amp;#39;t be allow to copy, such as system files, but this is baffling me.  &lt;/p&gt;\n\n&lt;p&gt;Here is the command I am using.&lt;/p&gt;\n\n&lt;p&gt;robocopy &amp;quot;C:&amp;quot; &amp;quot;F:\\C Drive Backup&amp;quot; /W:1 /R:3 /E /V /XJD /TEE /ETA /DCOPY:T /FP /A-:SHRA&lt;/p&gt;\n\n&lt;p&gt;Any help solving this mystery would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1929fcl", "is_robot_indexable": true, "report_reasons": null, "author": "Smiling_Sparrow", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1929fcl/robocopy_only_copying_current_user_folder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1929fcl/robocopy_only_copying_current_user_folder/", "subreddit_subscribers": 724294, "created_utc": 1704786495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ran a search for duplicate files, only 100% most strict match, have to be same file kind and got 60+GB of dupes found. I figure I should be able delete all dupes that have the same file name, 100% match, 0 size diff, and 0.0 seconds diff on modify time. So to get those, I have dupes only and delta values checked, and I've sorted my list by size, and marked all the dupes that are 0 size from the reference. Then I sorted my list by modified, with all the 0's in the middle, and all + and - time deltas are above and below. So I have my list with intermittently marked rows, and I want to select all the files from 0.1 second to the max on modified delta and of all those rows selected, I want to unmark them if they're marked. Then I'd go and select all rows from -0.1 second to the min, and again, unmark those selected, theoretically that'd leave me with having only marked files with 0 size and 0 modified time, 100% match, and identical file names that I could delete.\n\nI can't find an option for unmarking selected. Mark none unmarks EVERYTHING, and invert does EVERYTHING, not ONLY the rows I've got selected.\n\nAny ideas how I'd go about doing this or another way to adjust filters?\n\n&amp;#x200B;\n\nEDIT: Finally figured it out... so simple! Select all the rows that are a mix of marked/unmarked, then hit space to mark them all, space again and now they're all unmarked. Maybe this will help someone else dense like me. Or future me.", "author_fullname": "t2_1139u1g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dupeGuru Help Filtering Results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1926pg2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Solved", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704841671.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704776674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran a search for duplicate files, only 100% most strict match, have to be same file kind and got 60+GB of dupes found. I figure I should be able delete all dupes that have the same file name, 100% match, 0 size diff, and 0.0 seconds diff on modify time. So to get those, I have dupes only and delta values checked, and I&amp;#39;ve sorted my list by size, and marked all the dupes that are 0 size from the reference. Then I sorted my list by modified, with all the 0&amp;#39;s in the middle, and all + and - time deltas are above and below. So I have my list with intermittently marked rows, and I want to select all the files from 0.1 second to the max on modified delta and of all those rows selected, I want to unmark them if they&amp;#39;re marked. Then I&amp;#39;d go and select all rows from -0.1 second to the min, and again, unmark those selected, theoretically that&amp;#39;d leave me with having only marked files with 0 size and 0 modified time, 100% match, and identical file names that I could delete.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t find an option for unmarking selected. Mark none unmarks EVERYTHING, and invert does EVERYTHING, not ONLY the rows I&amp;#39;ve got selected.&lt;/p&gt;\n\n&lt;p&gt;Any ideas how I&amp;#39;d go about doing this or another way to adjust filters?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: Finally figured it out... so simple! Select all the rows that are a mix of marked/unmarked, then hit space to mark them all, space again and now they&amp;#39;re all unmarked. Maybe this will help someone else dense like me. Or future me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1926pg2", "is_robot_indexable": true, "report_reasons": null, "author": "Mike714321", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1926pg2/dupeguru_help_filtering_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1926pg2/dupeguru_help_filtering_results/", "subreddit_subscribers": 724294, "created_utc": 1704776674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I noticed that if I upload a bunch of photos to a folder in Mega, they seem to be out of order in which I selected them to be in. \n\nIt is very frustrating since I would like them to be in order since some photos should go right after the other so if you\u2019re looking at them and pressing the arrow keys or clicking \u201cnext\u201d, you\u2019ll go to the next photo that comes right after the previous one like a slideshow or  powerpoint slide. \n\nSorry if that\u2019s a dumb analogy but I hope you get what I mean. \n\nSo how do I upload them in order if I want to upload multiple files? \n\nI really don\u2019t want to upload them one by one!", "author_fullname": "t2_x1c78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to upload files (mostly photos and videos) to Mega where they\u2019re in order?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1926ms6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704776449.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I noticed that if I upload a bunch of photos to a folder in Mega, they seem to be out of order in which I selected them to be in. &lt;/p&gt;\n\n&lt;p&gt;It is very frustrating since I would like them to be in order since some photos should go right after the other so if you\u2019re looking at them and pressing the arrow keys or clicking \u201cnext\u201d, you\u2019ll go to the next photo that comes right after the previous one like a slideshow or  powerpoint slide. &lt;/p&gt;\n\n&lt;p&gt;Sorry if that\u2019s a dumb analogy but I hope you get what I mean. &lt;/p&gt;\n\n&lt;p&gt;So how do I upload them in order if I want to upload multiple files? &lt;/p&gt;\n\n&lt;p&gt;I really don\u2019t want to upload them one by one!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1926ms6", "is_robot_indexable": true, "report_reasons": null, "author": "taylormarie213", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1926ms6/how_to_upload_files_mostly_photos_and_videos_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1926ms6/how_to_upload_files_mostly_photos_and_videos_to/", "subreddit_subscribers": 724294, "created_utc": 1704776449.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "here in korea. our company is film archive and treat about 20TBs for annual. mostly HQ MOVs.  \nwe are seriously consider LTO Solution. specifically m-Logics Portable Machine.\n\nin here Korea the m-Logic Machine cost around $ 9,200.\n\nwe worried about Maintenance(A/S). because here is not much of information about LTO. they used by only few giant company such as Broadcast or Netflix. so if occur error or malfunction in LTO Drive, i can not sure handle that. i know everything in google... but... we got daily works and i can not sure got time to learn about that machine.\n\n\\- do i better use familiar tools like RAID Server or adventure to LTO ?\n\n\\- is it m Logic famous archive system for use LTO in western ?\n\n\\- is there many error in LTO Drive or Software ?\n\n&amp;#x200B;", "author_fullname": "t2_12gvic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is it m Logic solution good?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1923hth", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704767155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;here in korea. our company is film archive and treat about 20TBs for annual. mostly HQ MOVs.&lt;br/&gt;\nwe are seriously consider LTO Solution. specifically m-Logics Portable Machine.&lt;/p&gt;\n\n&lt;p&gt;in here Korea the m-Logic Machine cost around $ 9,200.&lt;/p&gt;\n\n&lt;p&gt;we worried about Maintenance(A/S). because here is not much of information about LTO. they used by only few giant company such as Broadcast or Netflix. so if occur error or malfunction in LTO Drive, i can not sure handle that. i know everything in google... but... we got daily works and i can not sure got time to learn about that machine.&lt;/p&gt;\n\n&lt;p&gt;- do i better use familiar tools like RAID Server or adventure to LTO ?&lt;/p&gt;\n\n&lt;p&gt;- is it m Logic famous archive system for use LTO in western ?&lt;/p&gt;\n\n&lt;p&gt;- is there many error in LTO Drive or Software ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1923hth", "is_robot_indexable": true, "report_reasons": null, "author": "ddd102", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1923hth/is_it_m_logic_solution_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1923hth/is_it_m_logic_solution_good/", "subreddit_subscribers": 724294, "created_utc": 1704767155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello there... I believe goharddrive is reputable from all that I read, but I have a few questions about the drives I received from them.\n\nThe auction is for:**Grade A HGST Ultrastar HUH728080ALE601 8TB 7200RPM SATA 6Gb/s 3.5\" Hard Drive**\n\nThey specifically say in the auction:\n**\"Tested with Zero Bad Sectors, Excellent Condition &amp; 5 Years Warranty from Reseller\nNOTE: These HDD is used by Datacenter Servers for about 3.5~4 Years period.\"**\n\n\n\nI ran a smartctl -t short test on each drive\n\n**One of the drives is over 7 years old, and the other is  5 years old** according to smart info. \n\nHe specifically says in the auction \"NOTE: These HDD is used by Datacenter Servers for about 3.5~4 Years period.\"\n\nSo both drives are pretty far out of that range if the hours is accurate.\n\nI'm not good at interpreting smart data. Can you please help me determine how good these drives are based on short smart tests?\n\nAre these still good drives for grade A...and considering in the auction they claim no more than 4 years old?\n\nI should mention **the price was $75.50 each drive**\n\n**drive 1**: /dev/sda smartctl -a output log\nhttps://pastebin.com/CDwyZ7Aa\n\n**drive 2**: /dev/sdb smartctl -a output log\nhttps://pastebin.com/9CiVt6wC\n\nI really appreciate it! Thank you!", "author_fullname": "t2_147crh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Purchased 2 grade A 8tb drives from goharddrive on ebay...questions about drive condition, smartctl hours, and data logs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1922793", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704764046.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704763549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there... I believe goharddrive is reputable from all that I read, but I have a few questions about the drives I received from them.&lt;/p&gt;\n\n&lt;p&gt;The auction is for:&lt;strong&gt;Grade A HGST Ultrastar HUH728080ALE601 8TB 7200RPM SATA 6Gb/s 3.5&amp;quot; Hard Drive&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;They specifically say in the auction:\n&lt;strong&gt;&amp;quot;Tested with Zero Bad Sectors, Excellent Condition &amp;amp; 5 Years Warranty from Reseller\nNOTE: These HDD is used by Datacenter Servers for about 3.5~4 Years period.&amp;quot;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I ran a smartctl -t short test on each drive&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;One of the drives is over 7 years old, and the other is  5 years old&lt;/strong&gt; according to smart info. &lt;/p&gt;\n\n&lt;p&gt;He specifically says in the auction &amp;quot;NOTE: These HDD is used by Datacenter Servers for about 3.5~4 Years period.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So both drives are pretty far out of that range if the hours is accurate.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not good at interpreting smart data. Can you please help me determine how good these drives are based on short smart tests?&lt;/p&gt;\n\n&lt;p&gt;Are these still good drives for grade A...and considering in the auction they claim no more than 4 years old?&lt;/p&gt;\n\n&lt;p&gt;I should mention &lt;strong&gt;the price was $75.50 each drive&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;drive 1&lt;/strong&gt;: /dev/sda smartctl -a output log\n&lt;a href=\"https://pastebin.com/CDwyZ7Aa\"&gt;https://pastebin.com/CDwyZ7Aa&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;drive 2&lt;/strong&gt;: /dev/sdb smartctl -a output log\n&lt;a href=\"https://pastebin.com/9CiVt6wC\"&gt;https://pastebin.com/9CiVt6wC&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I really appreciate it! Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/P8lS0kk6BFe2IEo6TxCZd1LVwksc34IkzGTVx_SCc8w.jpg?auto=webp&amp;s=b9f5c4e4867fbffb2c1ff45dd70aa338d1e3f40c", "width": 150, "height": 150}, "resolutions": [{"url": "https://external-preview.redd.it/P8lS0kk6BFe2IEo6TxCZd1LVwksc34IkzGTVx_SCc8w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3d74dbe4f1d67cc8b587db9aa01762f26e269bcf", "width": 108, "height": 108}], "variants": {}, "id": "OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1922793", "is_robot_indexable": true, "report_reasons": null, "author": "kenwho", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1922793/purchased_2_grade_a_8tb_drives_from_goharddrive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1922793/purchased_2_grade_a_8tb_drives_from_goharddrive/", "subreddit_subscribers": 724294, "created_utc": 1704763549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't need high speed or biggest space out there, I just need something that will outlive me. I know hard drives die quicker than flies and even SSDs don't last if they aren't used for over a year or something. I'd like it to be 16GB or more. Thanks in advance.", "author_fullname": "t2_dg0k8xij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best storage media for long term storage.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_192vdfb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704848603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t need high speed or biggest space out there, I just need something that will outlive me. I know hard drives die quicker than flies and even SSDs don&amp;#39;t last if they aren&amp;#39;t used for over a year or something. I&amp;#39;d like it to be 16GB or more. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "error: not enough disk space", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192vdfb", "is_robot_indexable": true, "report_reasons": null, "author": "BricksBear", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/192vdfb/what_is_the_best_storage_media_for_long_term/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192vdfb/what_is_the_best_storage_media_for_long_term/", "subreddit_subscribers": 724294, "created_utc": 1704848603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have over 200TB running of a customer server and a custom NAS using an $80 LSI Logic LSI00333 MegaRAID SAS 9286CV-8e card.  I get about 300MB/s off my RAID 6 arrays on my 10G nic.  This card only has 1GB of cache.  But my CPU and memory are free to run Plex and other apps.  All RAID functions use up the processor on the LSI card only.\n\nI've been reading up on TrueNAS and see that everyone is using it.  \n\nI can build up a new system with TrueNAS and get a couple 12G controller cards to drive all my drives.  I would love to have 1-2TB of cache running off of NVME drives.  \n\nBut I also see that these TrueNAS systems eat up CPU and memory, the larger the array.  This is something I don't have to deal with using a RAID card.  \n\nIs there something I am missing? Besides the large cache, what else are the benefits of going with TrueNAS over a cheap LSI/Broadcom RAID card with MegaRAID?\n\n&amp;#x200B;", "author_fullname": "t2_50kz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MegaRAID vs TrueNAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_192uddm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704845970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have over 200TB running of a customer server and a custom NAS using an $80 LSI Logic LSI00333 MegaRAID SAS 9286CV-8e card.  I get about 300MB/s off my RAID 6 arrays on my 10G nic.  This card only has 1GB of cache.  But my CPU and memory are free to run Plex and other apps.  All RAID functions use up the processor on the LSI card only.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been reading up on TrueNAS and see that everyone is using it.  &lt;/p&gt;\n\n&lt;p&gt;I can build up a new system with TrueNAS and get a couple 12G controller cards to drive all my drives.  I would love to have 1-2TB of cache running off of NVME drives.  &lt;/p&gt;\n\n&lt;p&gt;But I also see that these TrueNAS systems eat up CPU and memory, the larger the array.  This is something I don&amp;#39;t have to deal with using a RAID card.  &lt;/p&gt;\n\n&lt;p&gt;Is there something I am missing? Besides the large cache, what else are the benefits of going with TrueNAS over a cheap LSI/Broadcom RAID card with MegaRAID?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "200TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192uddm", "is_robot_indexable": true, "report_reasons": null, "author": "EvanWasHere", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/192uddm/megaraid_vs_truenas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192uddm/megaraid_vs_truenas/", "subreddit_subscribers": 724294, "created_utc": 1704845970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Idk if this is the right forum (if anyone could direct me to a better one as well lmk), but I am interested in archiving videos on a platform like youtube. I have a collection of videos like: interviews with artists, musicians, directors; performances such as opera, concert footage, ballet; old films such as Battleship Potemkin, other movies from pre 1940s; collection of short films including amateur animation, experimental short films, very old like pre 1950s animated foreign films; audiovisual and experimental animation clips from youtube creators etc. who no longer have a channel; etc.\n\n&amp;#x200B;\n\nI would love to be able to archive these on an online website like youtube, vimeo, or daily motion, either archive privately so I can share with my friends, or archive publicly to share obscure and rare art, peformances, etc. with people. I am wondering if anyone has any recommendation or advice for a platform. I tried uploading some to youtube (set to private for now), but it limits 15 minute uploads to verified accounts (which I guess maybe I could go thru that process). I also have no idea as to whether these videos are copyright, many of them are very old, obscure, or not widely released, and I doubt that most of them would have copyright holders interested in trying to take down random interviews or super old films or performances. I also have no interest in profiting off of any of this content, this is purely for archival purposes. So if anyone has any info on how youtube or other platforms treats things like this, like if something did get flagged for copyright would it just be demonetized, would it be taken down, would my channel be at risk for being taken down, etc.\n\n&amp;#x200B;\n\nThanks for any help and if you know of a different sub that would be good for this sort of discussion lmk!", "author_fullname": "t2_svlkyjzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Websites for archiving videos online, like youtube, daily motion, vimeo?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192s0nf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704840120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Idk if this is the right forum (if anyone could direct me to a better one as well lmk), but I am interested in archiving videos on a platform like youtube. I have a collection of videos like: interviews with artists, musicians, directors; performances such as opera, concert footage, ballet; old films such as Battleship Potemkin, other movies from pre 1940s; collection of short films including amateur animation, experimental short films, very old like pre 1950s animated foreign films; audiovisual and experimental animation clips from youtube creators etc. who no longer have a channel; etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would love to be able to archive these on an online website like youtube, vimeo, or daily motion, either archive privately so I can share with my friends, or archive publicly to share obscure and rare art, peformances, etc. with people. I am wondering if anyone has any recommendation or advice for a platform. I tried uploading some to youtube (set to private for now), but it limits 15 minute uploads to verified accounts (which I guess maybe I could go thru that process). I also have no idea as to whether these videos are copyright, many of them are very old, obscure, or not widely released, and I doubt that most of them would have copyright holders interested in trying to take down random interviews or super old films or performances. I also have no interest in profiting off of any of this content, this is purely for archival purposes. So if anyone has any info on how youtube or other platforms treats things like this, like if something did get flagged for copyright would it just be demonetized, would it be taken down, would my channel be at risk for being taken down, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help and if you know of a different sub that would be good for this sort of discussion lmk!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192s0nf", "is_robot_indexable": true, "report_reasons": null, "author": "rainrainrainr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/192s0nf/websites_for_archiving_videos_online_like_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192s0nf/websites_for_archiving_videos_online_like_youtube/", "subreddit_subscribers": 724294, "created_utc": 1704840120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I work for a university and was approached by a faculty member working on a grant with regards to helping to enable easier access to research data. For example one dataset is years worth of camera data from over a dozen cameras in a large city. This was used for tracking tides/sea levels over time using computer vision. Another set is a few years worth of atmospherics data for a different city as well as quite a few larger GIS datasets.\n\nThe intention behind their project would be to make these datasets more easily accessible to students and the pubic.\n\nDuring the meeting my mind went to P2P and the Data Hoarding community. Do any of you currently hold and seed research data? Is there an interested in the community to do more of that?", "author_fullname": "t2_n0xfw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interest in seeding research data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192o9cg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704831119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a university and was approached by a faculty member working on a grant with regards to helping to enable easier access to research data. For example one dataset is years worth of camera data from over a dozen cameras in a large city. This was used for tracking tides/sea levels over time using computer vision. Another set is a few years worth of atmospherics data for a different city as well as quite a few larger GIS datasets.&lt;/p&gt;\n\n&lt;p&gt;The intention behind their project would be to make these datasets more easily accessible to students and the pubic.&lt;/p&gt;\n\n&lt;p&gt;During the meeting my mind went to P2P and the Data Hoarding community. Do any of you currently hold and seed research data? Is there an interested in the community to do more of that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB - Unraid", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "192o9cg", "is_robot_indexable": true, "report_reasons": null, "author": "mr-octo_squid", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/192o9cg/interest_in_seeding_research_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/192o9cg/interest_in_seeding_research_data/", "subreddit_subscribers": 724294, "created_utc": 1704831119.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}