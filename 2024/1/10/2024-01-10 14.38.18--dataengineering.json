{"kind": "Listing", "data": {"after": "t3_19384vx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently observed this trend where people are getting curious about rust for data engineering especially after the whole polars, duckdb and apache arrow revolution. Apache arrow and parquet are amazing technologies but I am confused by craze of rust.\n\nWe all agree python has issues and major of them are\n1. Its slow as hell\n2. Packaging problem : I am sure we can agree than dyanmic languages have a bad packaging ecosystem for eg python and js. Go and rust has a much better ecosystem \n3. Two language problem : there are way more python users than contributors in libraries and a lot of libraries have expressed this concern\n\nBecause users have to learn an entire new language and learn to do memory management efficiently in c++ to become contributors \n\nI agree rust is better than c/c++ but still we are creating the same two language problem and writing libraries in rust doesn\u2019t solve the packaging problem of python\n\nWhy don\u2019t we just use one general purpose language with a good type system and almost as fast as C and users can become contributors", "author_fullname": "t2_q27tep12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why we are ignoring Julia for data engineering and going for rust??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192fhgg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704809199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently observed this trend where people are getting curious about rust for data engineering especially after the whole polars, duckdb and apache arrow revolution. Apache arrow and parquet are amazing technologies but I am confused by craze of rust.&lt;/p&gt;\n\n&lt;p&gt;We all agree python has issues and major of them are\n1. Its slow as hell\n2. Packaging problem : I am sure we can agree than dyanmic languages have a bad packaging ecosystem for eg python and js. Go and rust has a much better ecosystem \n3. Two language problem : there are way more python users than contributors in libraries and a lot of libraries have expressed this concern&lt;/p&gt;\n\n&lt;p&gt;Because users have to learn an entire new language and learn to do memory management efficiently in c++ to become contributors &lt;/p&gt;\n\n&lt;p&gt;I agree rust is better than c/c++ but still we are creating the same two language problem and writing libraries in rust doesn\u2019t solve the packaging problem of python&lt;/p&gt;\n\n&lt;p&gt;Why don\u2019t we just use one general purpose language with a good type system and almost as fast as C and users can become contributors&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "192fhgg", "is_robot_indexable": true, "report_reasons": null, "author": "__albatross", "discussion_type": null, "num_comments": 90, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192fhgg/why_we_are_ignoring_julia_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192fhgg/why_we_are_ignoring_julia_for_data_engineering/", "subreddit_subscribers": 151671, "created_utc": 1704809199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After seeing the same basic question again, I was like \u201cI think it\u2019s enough. It\u2019s time to create a new subreddit\u201d and when I tried to create r/learndataengineering, it said community already exists. Voila!\n\n\nMy nominations for questions that should go there:\n- What makes a good Data Engineer?\n- Do you need &lt;tool/skill&gt; to be a Data Engineer?\n- What do you all think about &lt;tool/skill&gt;?\n- What &lt;project/skills&gt; should I work on if I want to be a Data Engineer?\n- Is Data Engineering a good role for me to transition to from &lt;current role&gt;?\n- Read my blog post about DuckDB/Polars/\u2026\n\n\nSince I had to choose a flair, I went with discussion. What questions/topics do folks think belong in that subreddit?\n\n\nEdit: I guess it\u2019s an old subreddit (3+ years). Regardless, since it exists, I think we should utilize it", "author_fullname": "t2_16b1dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Someone finally did it! r/learndataengineering is live!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1933ach", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704874234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After seeing the same basic question again, I was like \u201cI think it\u2019s enough. It\u2019s time to create a new subreddit\u201d and when I tried to create &lt;a href=\"/r/learndataengineering\"&gt;r/learndataengineering&lt;/a&gt;, it said community already exists. Voila!&lt;/p&gt;\n\n&lt;p&gt;My nominations for questions that should go there:\n- What makes a good Data Engineer?\n- Do you need &amp;lt;tool/skill&amp;gt; to be a Data Engineer?\n- What do you all think about &amp;lt;tool/skill&amp;gt;?\n- What &amp;lt;project/skills&amp;gt; should I work on if I want to be a Data Engineer?\n- Is Data Engineering a good role for me to transition to from &amp;lt;current role&amp;gt;?\n- Read my blog post about DuckDB/Polars/\u2026&lt;/p&gt;\n\n&lt;p&gt;Since I had to choose a flair, I went with discussion. What questions/topics do folks think belong in that subreddit?&lt;/p&gt;\n\n&lt;p&gt;Edit: I guess it\u2019s an old subreddit (3+ years). Regardless, since it exists, I think we should utilize it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1933ach", "is_robot_indexable": true, "report_reasons": null, "author": "jawabdey", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1933ach/someone_finally_did_it_rlearndataengineering_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1933ach/someone_finally_did_it_rlearndataengineering_is/", "subreddit_subscribers": 151671, "created_utc": 1704874234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "All of us **want to move fast**, and while tests and documentation may feel like they slow you down, we firmly believe that the confidence they provide far outweighs their cost in the long term. Yet lots of people we speak to using dbt don't use them.\n\nWe built a quick tool that infers tests/documents for you. \n\nWhat are people's **thoughts on a tool that infers tests and docs and helps you add them to your schema definition**? \n\n&amp;#x200B;\n\n[Schema inference](https://reddit.com/link/192he2z/video/mv0k6icgofbc1/player)", "author_fullname": "t2_q5jcx79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT test and documentation generation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"mv0k6icgofbc1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/192he2z/asset/mv0k6icgofbc1/DASHPlaylist.mpd?a=1707489498%2CYjMwODg1MzRhOWQwMTY0NThmNzEzNDQwZWQ4MGQ2NDRlOTk3NDIzMGNiZTQwMWIxZjc2MDYyNjA2YjU1OGY0OQ%3D%3D&amp;v=1&amp;f=sd", "x": 1730, "y": 1080, "hlsUrl": "https://v.redd.it/link/192he2z/asset/mv0k6icgofbc1/HLSPlaylist.m3u8?a=1707489498%2CZTk1YmU2NWM4OTczYjU5MzliZjhiYjM5OGIzMTI5ZGQzZjkwNDM1MTk5NTQ1NDFkOWNiNGNhNDk3NWQ0OWJiMQ%3D%3D&amp;v=1&amp;f=sd", "id": "mv0k6icgofbc1", "isGif": false}}, "name": "t3_192he2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704814481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All of us &lt;strong&gt;want to move fast&lt;/strong&gt;, and while tests and documentation may feel like they slow you down, we firmly believe that the confidence they provide far outweighs their cost in the long term. Yet lots of people we speak to using dbt don&amp;#39;t use them.&lt;/p&gt;\n\n&lt;p&gt;We built a quick tool that infers tests/documents for you. &lt;/p&gt;\n\n&lt;p&gt;What are people&amp;#39;s &lt;strong&gt;thoughts on a tool that infers tests and docs and helps you add them to your schema definition&lt;/strong&gt;? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/192he2z/video/mv0k6icgofbc1/player\"&gt;Schema inference&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "192he2z", "is_robot_indexable": true, "report_reasons": null, "author": "bk1007", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192he2z/dbt_test_and_documentation_generation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192he2z/dbt_test_and_documentation_generation/", "subreddit_subscribers": 151671, "created_utc": 1704814481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So let's start by saying this is by no means a post to complain but just to get a reality check and understand what you guys mean when you name a technology in your tech stack. I was navigating the sub and found the posts like the salary discussion or newbies asking for help, and you've got the usual comments throwing around a bunch of technologies like it's fresh water. Oh sure just learn aws, sql, python, powerbi, airflow, terraform and docker and you're good to go, took me a year. Obviously started questioning if I'm dumb since I've been at this job 4 years and I'm currently mastering SQL after spending 3 years on PowerBI only\n\nSo I want to understand when you name these tools and put them in your tech stack, how good are you actually at this and how much is it just \"I understand the basics and I can Google/ChatGPT the rest\" ?\n\nLet's take SQL for example. There's a huge difference between \"Udemy course\" level of knowledge (you got the basic idea, can use SQL up to subqueries and Window Functions) and that one colleague that can write 1000+ lines of stored procedure from scratch and model JSON into tables level of knowledge. Or PowerBI: again there's a difference between \"I can drag and drop objects on the canvas and create a visualization, yaay let me add it to the CV\" and having read The definitive guide to DAX 700+ pages on PowerBI's programming language, understanding how Vertipaq engine works internally and so on. You might say it is overkill to invest that much time in one single tech but that's another topic I don't want to tackle now.\n\nFor example, I don't use Python daily at my job, but I can do some stuff with it with the help of Google and Chatgpt. I know the basics of programming, I've done a couple Udemy courses out of curiosity, I know what sets and dictionaries are, I can query an API, do some stuff with the common libraries for data manipulation and return the data. If I have to touch a Python script written by another DEV to modify something specific, I can do that. But I don't have profound knowledge of the internals, I wouldn't know how to optimize code, I probably couldn't do heavy tasks on Python-built infrastructure unless the task was very clear or build something enterprise-level from scratch myself. Do you think I should name Python in my tech stack? Is this an acceptable level of knowledge for you to name in the tech stack? \n\nSo yeah I just need to know what's the idea of this sub on this topic because there's one of two possible outcomes:\n\n1. I'm studying in the wrong way, and it's taking me a lot more than a normal person to really understand these tools\n2. I am underselling myself and suffering from imposter syndrome or something like that\n\nCheers ", "author_fullname": "t2_ehpb7yoc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reality check: How good are you at the skills in your tech stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1935ykj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704885325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So let&amp;#39;s start by saying this is by no means a post to complain but just to get a reality check and understand what you guys mean when you name a technology in your tech stack. I was navigating the sub and found the posts like the salary discussion or newbies asking for help, and you&amp;#39;ve got the usual comments throwing around a bunch of technologies like it&amp;#39;s fresh water. Oh sure just learn aws, sql, python, powerbi, airflow, terraform and docker and you&amp;#39;re good to go, took me a year. Obviously started questioning if I&amp;#39;m dumb since I&amp;#39;ve been at this job 4 years and I&amp;#39;m currently mastering SQL after spending 3 years on PowerBI only&lt;/p&gt;\n\n&lt;p&gt;So I want to understand when you name these tools and put them in your tech stack, how good are you actually at this and how much is it just &amp;quot;I understand the basics and I can Google/ChatGPT the rest&amp;quot; ?&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s take SQL for example. There&amp;#39;s a huge difference between &amp;quot;Udemy course&amp;quot; level of knowledge (you got the basic idea, can use SQL up to subqueries and Window Functions) and that one colleague that can write 1000+ lines of stored procedure from scratch and model JSON into tables level of knowledge. Or PowerBI: again there&amp;#39;s a difference between &amp;quot;I can drag and drop objects on the canvas and create a visualization, yaay let me add it to the CV&amp;quot; and having read The definitive guide to DAX 700+ pages on PowerBI&amp;#39;s programming language, understanding how Vertipaq engine works internally and so on. You might say it is overkill to invest that much time in one single tech but that&amp;#39;s another topic I don&amp;#39;t want to tackle now.&lt;/p&gt;\n\n&lt;p&gt;For example, I don&amp;#39;t use Python daily at my job, but I can do some stuff with it with the help of Google and Chatgpt. I know the basics of programming, I&amp;#39;ve done a couple Udemy courses out of curiosity, I know what sets and dictionaries are, I can query an API, do some stuff with the common libraries for data manipulation and return the data. If I have to touch a Python script written by another DEV to modify something specific, I can do that. But I don&amp;#39;t have profound knowledge of the internals, I wouldn&amp;#39;t know how to optimize code, I probably couldn&amp;#39;t do heavy tasks on Python-built infrastructure unless the task was very clear or build something enterprise-level from scratch myself. Do you think I should name Python in my tech stack? Is this an acceptable level of knowledge for you to name in the tech stack? &lt;/p&gt;\n\n&lt;p&gt;So yeah I just need to know what&amp;#39;s the idea of this sub on this topic because there&amp;#39;s one of two possible outcomes:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;m studying in the wrong way, and it&amp;#39;s taking me a lot more than a normal person to really understand these tools&lt;/li&gt;\n&lt;li&gt;I am underselling myself and suffering from imposter syndrome or something like that&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Cheers &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1935ykj", "is_robot_indexable": true, "report_reasons": null, "author": "schizo_coder", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1935ykj/reality_check_how_good_are_you_at_the_skills_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1935ykj/reality_check_how_good_are_you_at_the_skills_in/", "subreddit_subscribers": 151671, "created_utc": 1704885325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is probably a stupid question to anyone with a deeper background in data engineering, but I'm new and learned dbt first using dbt cloud which makes orchestrating transformation pretty easy. \n\nIf I have a data warehouse and I can't use dbt, how do I go about orchestrating transformation of data after landing it in raw form in the data warehouse? BigQuery seems to have Dataform and I'm guessing the other cloud providers have something similar, but what if I'm just using an on-prem database? Do I just have a bunch of scheduled stored procedures?", "author_fullname": "t2_550fb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are people orchestrating the T in ELT for their data warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192ou1k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704832493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is probably a stupid question to anyone with a deeper background in data engineering, but I&amp;#39;m new and learned dbt first using dbt cloud which makes orchestrating transformation pretty easy. &lt;/p&gt;\n\n&lt;p&gt;If I have a data warehouse and I can&amp;#39;t use dbt, how do I go about orchestrating transformation of data after landing it in raw form in the data warehouse? BigQuery seems to have Dataform and I&amp;#39;m guessing the other cloud providers have something similar, but what if I&amp;#39;m just using an on-prem database? Do I just have a bunch of scheduled stored procedures?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "192ou1k", "is_robot_indexable": true, "report_reasons": null, "author": "PureOhms", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192ou1k/how_are_people_orchestrating_the_t_in_elt_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192ou1k/how_are_people_orchestrating_the_t_in_elt_for/", "subreddit_subscribers": 151671, "created_utc": 1704832493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!\n\nI'm currently working in a new open source project called DataFlint .([https://github.com/dataflint/spark](https://github.com/dataflint/spark)) to do performance monitoring better in Apache Spark.\n\nI'm working on creating a new feature for monitoring resource allocation ( i.e. how many executors do you need, and how many CPU/Memory each executor needs), so it would be easier to tune your Apache Spark resource allocation.\n\n&amp;#x200B;\n\nSo while making this feature I was wondering - how do you usually decide how many resources to give a job? on what metrics do you look? which configs do you play with?\n\n&amp;#x200B;\n\nI released an initial version of this feature and looks like this:\n\nhttps://preview.redd.it/41qbfiv6qgbc1.png?width=2936&amp;format=png&amp;auto=webp&amp;s=e5e34bf888ecfa9cc7ddd8c8680729a3d3c58f45\n\nit contains a graph of the number of executors, the min/max executors (if using dynamic allocation), which query ran, and some relevant configs.\n\nWDYT?", "author_fullname": "t2_i2b8380mi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you decide how many resources to give an Apache Spark job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"41qbfiv6qgbc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 64, "x": 108, "u": "https://preview.redd.it/41qbfiv6qgbc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=63e154617bee6f9d91a697c94a56112a9c355c78"}, {"y": 129, "x": 216, "u": "https://preview.redd.it/41qbfiv6qgbc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7133befe2d3f988c7d01619b33ee57255e467ea6"}, {"y": 191, "x": 320, "u": "https://preview.redd.it/41qbfiv6qgbc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ea4dd00f02057a058d7229e44aef26a8b171944"}, {"y": 383, "x": 640, "u": "https://preview.redd.it/41qbfiv6qgbc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca309ecc3ce66dddcb2b7377076ba46d0a5e53dd"}, {"y": 575, "x": 960, "u": "https://preview.redd.it/41qbfiv6qgbc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a58fd54e378fb9fb6e4899cbb22854c87288ef99"}, {"y": 647, "x": 1080, "u": "https://preview.redd.it/41qbfiv6qgbc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a82815521f8704e06249340feeb5f035020dcdd"}], "s": {"y": 1760, "x": 2936, "u": "https://preview.redd.it/41qbfiv6qgbc1.png?width=2936&amp;format=png&amp;auto=webp&amp;s=e5e34bf888ecfa9cc7ddd8c8680729a3d3c58f45"}, "id": "41qbfiv6qgbc1"}}, "name": "t3_192muug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AezvY7fMP8doLXTsi_G8Z8F4Tn4-jS7gnbLgMIJwhBA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1704827778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working in a new open source project called DataFlint .(&lt;a href=\"https://github.com/dataflint/spark\"&gt;https://github.com/dataflint/spark&lt;/a&gt;) to do performance monitoring better in Apache Spark.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on creating a new feature for monitoring resource allocation ( i.e. how many executors do you need, and how many CPU/Memory each executor needs), so it would be easier to tune your Apache Spark resource allocation.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So while making this feature I was wondering - how do you usually decide how many resources to give a job? on what metrics do you look? which configs do you play with?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I released an initial version of this feature and looks like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/41qbfiv6qgbc1.png?width=2936&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e5e34bf888ecfa9cc7ddd8c8680729a3d3c58f45\"&gt;https://preview.redd.it/41qbfiv6qgbc1.png?width=2936&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e5e34bf888ecfa9cc7ddd8c8680729a3d3c58f45&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;it contains a graph of the number of executors, the min/max executors (if using dynamic allocation), which query ran, and some relevant configs.&lt;/p&gt;\n\n&lt;p&gt;WDYT?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Sv50pQCTIQ0Rf8MO8FwWxzhAHyj4iVOKP09PBXUlicU.jpg?auto=webp&amp;s=a1663328cfda62d121dd3c35d545c7154f598f94", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Sv50pQCTIQ0Rf8MO8FwWxzhAHyj4iVOKP09PBXUlicU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d4e8132c91b474e33b64e9468995d4cc1462f092", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Sv50pQCTIQ0Rf8MO8FwWxzhAHyj4iVOKP09PBXUlicU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7010b91ae5f970f49e95f0f17ab12305a316fa41", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Sv50pQCTIQ0Rf8MO8FwWxzhAHyj4iVOKP09PBXUlicU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ea61b0ba3918f27a1e06a272145364b2a29116b2", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Sv50pQCTIQ0Rf8MO8FwWxzhAHyj4iVOKP09PBXUlicU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=674e0a743cab1aebdda9c72a1ca77e724b8445d9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Sv50pQCTIQ0Rf8MO8FwWxzhAHyj4iVOKP09PBXUlicU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c5e24b2de2c1f04042e397985e6b67f560bb6091", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Sv50pQCTIQ0Rf8MO8FwWxzhAHyj4iVOKP09PBXUlicU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d77199ece2473fe34677bac5cdf8dfb606a4037f", "width": 1080, "height": 540}], "variants": {}, "id": "fo-5dKHfVMLxEc3zQneZtZO1K1S_XEWh5A5Sl5GzQDY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "192muug", "is_robot_indexable": true, "report_reasons": null, "author": "menishmueli", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192muug/how_do_you_decide_how_many_resources_to_give_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192muug/how_do_you_decide_how_many_resources_to_give_an/", "subreddit_subscribers": 151671, "created_utc": 1704827778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI'm a data storage guy (22 years in IT. age 48). I've done some bash and Python scripting. Started playing with Pandas for some data analysis. How easy/tough would it be to get into data engineering? How's the ageism in data engineering? Are they ok with senior folks?", "author_fullname": "t2_2lbw4pfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How's data engineering for a senior storage guy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1932tvf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704872319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI&amp;#39;m a data storage guy (22 years in IT. age 48). I&amp;#39;ve done some bash and Python scripting. Started playing with Pandas for some data analysis. How easy/tough would it be to get into data engineering? How&amp;#39;s the ageism in data engineering? Are they ok with senior folks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1932tvf", "is_robot_indexable": true, "report_reasons": null, "author": "pritesh_ugrankar", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1932tvf/hows_data_engineering_for_a_senior_storage_guy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1932tvf/hows_data_engineering_for_a_senior_storage_guy/", "subreddit_subscribers": 151671, "created_utc": 1704872319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One of the products my company offers requires customers to submit export files from various platforms to us. From there, our current process is to transform the data in excel and import into a MySQL database. Yuck.\n\nEach system exports similar data in the same shape, but of course, headers differ, customers use different values to mean the same thing, etc. Super simple transformations. However, it doesn\u2019t make any sense to make an ETL for each one because these files are used only once.\n\nWhat I am looking for is a tool that would allow someone who isn\u2019t super technical to upload one of these files, select a preset target, select what each header means, make any necessary transformations, and check for errors/missing values.\n\nI haven\u2019t been able to find anything that does this short of building it myself. If it doesn\u2019t, I\u2019m thinking about building it on my own.\n\nWe have a long term solution planned for this whole process so it doesn\u2019t make sense to build it out for the company.", "author_fullname": "t2_m0ki4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this tool exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192sv8t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704842154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of the products my company offers requires customers to submit export files from various platforms to us. From there, our current process is to transform the data in excel and import into a MySQL database. Yuck.&lt;/p&gt;\n\n&lt;p&gt;Each system exports similar data in the same shape, but of course, headers differ, customers use different values to mean the same thing, etc. Super simple transformations. However, it doesn\u2019t make any sense to make an ETL for each one because these files are used only once.&lt;/p&gt;\n\n&lt;p&gt;What I am looking for is a tool that would allow someone who isn\u2019t super technical to upload one of these files, select a preset target, select what each header means, make any necessary transformations, and check for errors/missing values.&lt;/p&gt;\n\n&lt;p&gt;I haven\u2019t been able to find anything that does this short of building it myself. If it doesn\u2019t, I\u2019m thinking about building it on my own.&lt;/p&gt;\n\n&lt;p&gt;We have a long term solution planned for this whole process so it doesn\u2019t make sense to build it out for the company.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "192sv8t", "is_robot_indexable": true, "report_reasons": null, "author": "phonyfakeorreal", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192sv8t/does_this_tool_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192sv8t/does_this_tool_exist/", "subreddit_subscribers": 151671, "created_utc": 1704842154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, I have some experience with dbt and just wanted to know if anyone knows of any use cases for integrating the two tools together for an ELT.  In my last organization dbt was used to treat our transformation pipeline like software development to make sure it had good documentation, testing, snapshotting etc.  Would it ever make sense to use dbt and clickhouse together?", "author_fullname": "t2_maega", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt + ClickHouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1933kce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704875400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, I have some experience with dbt and just wanted to know if anyone knows of any use cases for integrating the two tools together for an ELT.  In my last organization dbt was used to treat our transformation pipeline like software development to make sure it had good documentation, testing, snapshotting etc.  Would it ever make sense to use dbt and clickhouse together?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1933kce", "is_robot_indexable": true, "report_reasons": null, "author": "TheAnglerfish1616", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1933kce/dbt_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1933kce/dbt_clickhouse/", "subreddit_subscribers": 151671, "created_utc": 1704875400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently helped launch the Airflow 2023 User Survey, and thought some of you may find the results interesting, especially those that use Airflow :)\n\nI even had a cool infographic made. Included a sneak peek below, but for the full thing- [check it out here](https://airflow.apache.org/survey/)\n\nHope this is useful!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/hciz2m67whbc1.png?width=3168&amp;format=png&amp;auto=webp&amp;s=9a7db044ca109cd37398102034f0e54d39ae365a\n\n&amp;#x200B;", "author_fullname": "t2_l5gu8nhgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow User Survey Infographic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 107, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hciz2m67whbc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/hciz2m67whbc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c3e09454778390c7ce578aab35d0fcaea35f497a"}, {"y": 166, "x": 216, "u": "https://preview.redd.it/hciz2m67whbc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a94f97ab4f80708fef7d14b983d4cbf92154e040"}, {"y": 246, "x": 320, "u": "https://preview.redd.it/hciz2m67whbc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6e9c42dd627f9fe78177c9ac6a9dbf52f0919481"}, {"y": 493, "x": 640, "u": "https://preview.redd.it/hciz2m67whbc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=94f3180b991467baad0827a1845c6e243a6dc2d5"}, {"y": 740, "x": 960, "u": "https://preview.redd.it/hciz2m67whbc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=775fd2b4c9c52e4fb41dda044b67843649186407"}, {"y": 832, "x": 1080, "u": "https://preview.redd.it/hciz2m67whbc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bebaaa3731d90e613fce69e064e975d399b67118"}], "s": {"y": 2442, "x": 3168, "u": "https://preview.redd.it/hciz2m67whbc1.png?width=3168&amp;format=png&amp;auto=webp&amp;s=9a7db044ca109cd37398102034f0e54d39ae365a"}, "id": "hciz2m67whbc1"}}, "name": "t3_192sgnv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/S6G9CqW9lzwaTz1q98tNVJY5QdgfeIMzDv_T0jxdeOQ.jpg", "edited": 1704841382.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704841179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently helped launch the Airflow 2023 User Survey, and thought some of you may find the results interesting, especially those that use Airflow :)&lt;/p&gt;\n\n&lt;p&gt;I even had a cool infographic made. Included a sneak peek below, but for the full thing- &lt;a href=\"https://airflow.apache.org/survey/\"&gt;check it out here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hope this is useful!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hciz2m67whbc1.png?width=3168&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9a7db044ca109cd37398102034f0e54d39ae365a\"&gt;https://preview.redd.it/hciz2m67whbc1.png?width=3168&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9a7db044ca109cd37398102034f0e54d39ae365a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "192sgnv", "is_robot_indexable": true, "report_reasons": null, "author": "BrianaGraceOkyere", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192sgnv/airflow_user_survey_infographic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192sgnv/airflow_user_survey_infographic/", "subreddit_subscribers": 151671, "created_utc": 1704841179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "let's use a simple use case of no windowing or anything like that. Kafka/Flink transformations are done and then data flows into a DB (such as Snowflake) to be queried. \n\nSuppose that you find out at some point that there is a bug with the streaming data transformation, and that it needs to be changed and past data needs to be re-processed. How is that handled?", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do your teams handle backfill with streaming data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192r24x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704837803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;let&amp;#39;s use a simple use case of no windowing or anything like that. Kafka/Flink transformations are done and then data flows into a DB (such as Snowflake) to be queried. &lt;/p&gt;\n\n&lt;p&gt;Suppose that you find out at some point that there is a bug with the streaming data transformation, and that it needs to be changed and past data needs to be re-processed. How is that handled?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "192r24x", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192r24x/how_do_your_teams_handle_backfill_with_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192r24x/how_do_your_teams_handle_backfill_with_streaming/", "subreddit_subscribers": 151671, "created_utc": 1704837803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am transitioning from data analyst to data engineer career. Usually in the technical interview process, we are asked to perform a technical assessment(live or offline) to evaluate our tech skills. \n\nWhen I was interviewing for data analyst roles, I was usually given a dataset and the following pattern-\n1. a data set and few questions to find out certain patterns or trends. \n2. A dashboard in power bi/tableau to find how I am thinking of the kpis and metrics \n3. Few questions to be done in sql from the dataset. \n4. If live coding, some basic python and sql questions \n5. A PowerPoint deck with key points and to be presented to the interview online. \n\nSimilarly, what\u2019s the pattern of technical assessments for a data engineer? I am mostly applying for roles which focus on ETL/ELT processes, big data processing like spark and Databricks, data warehousing etc. \n\nCan anyone shed any light from their previous interview experience?", "author_fullname": "t2_o51po378", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the common pattern for technical assessment for data engineer interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1934jw1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704879596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am transitioning from data analyst to data engineer career. Usually in the technical interview process, we are asked to perform a technical assessment(live or offline) to evaluate our tech skills. &lt;/p&gt;\n\n&lt;p&gt;When I was interviewing for data analyst roles, I was usually given a dataset and the following pattern-\n1. a data set and few questions to find out certain patterns or trends. \n2. A dashboard in power bi/tableau to find how I am thinking of the kpis and metrics \n3. Few questions to be done in sql from the dataset. \n4. If live coding, some basic python and sql questions \n5. A PowerPoint deck with key points and to be presented to the interview online. &lt;/p&gt;\n\n&lt;p&gt;Similarly, what\u2019s the pattern of technical assessments for a data engineer? I am mostly applying for roles which focus on ETL/ELT processes, big data processing like spark and Databricks, data warehousing etc. &lt;/p&gt;\n\n&lt;p&gt;Can anyone shed any light from their previous interview experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1934jw1", "is_robot_indexable": true, "report_reasons": null, "author": "NeighborhoodCold5339", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1934jw1/what_is_the_common_pattern_for_technical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1934jw1/what_is_the_common_pattern_for_technical/", "subreddit_subscribers": 151671, "created_utc": 1704879596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tables vs int in dbt\n\nWhat are the differences between a regular table and intermediate table in dbt? \n\nI\u2019m learning by doing and while creating my tables I realised that I don\u2019t need to have all tables to be either DIMs or FCTs. \n\nThen I started searching in the internet and I felt overwhelmed tbh, specially after I came across int page and they said its not meant to be used in dashboards or exposed to end user. \n\nthen, what about the tables that I need them to study my data, build analytics around it and generate ad hoc reports?", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Types of tables in dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192z6bh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704859757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tables vs int in dbt&lt;/p&gt;\n\n&lt;p&gt;What are the differences between a regular table and intermediate table in dbt? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m learning by doing and while creating my tables I realised that I don\u2019t need to have all tables to be either DIMs or FCTs. &lt;/p&gt;\n\n&lt;p&gt;Then I started searching in the internet and I felt overwhelmed tbh, specially after I came across int page and they said its not meant to be used in dashboards or exposed to end user. &lt;/p&gt;\n\n&lt;p&gt;then, what about the tables that I need them to study my data, build analytics around it and generate ad hoc reports?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "192z6bh", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192z6bh/types_of_tables_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192z6bh/types_of_tables_in_dbt/", "subreddit_subscribers": 151671, "created_utc": 1704859757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I am looking for some help or suggestions.\n\nI have ssis script that do some calculations, while and for loops etc for each row of table and need to make the same thing in snowflake.\n\nI managed to create a bunch of procedures and function that together do the thing(as a result it inserts into temp table so i can join to it later) but only for predefined values and I need it to be executed for each row in the table.\n\n\nI also tried using dbt jinja for this purpose, but because jinja doesn't have while loop(i still have to use procedure for one part) i didn't manage to make script work with columns because it didn't render values, only column names.\n\nDo you have any ideas? I am out of them.\nThanks in advance.", "author_fullname": "t2_v3orytfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Make ssis script variant in snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192q0bi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704835282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I am looking for some help or suggestions.&lt;/p&gt;\n\n&lt;p&gt;I have ssis script that do some calculations, while and for loops etc for each row of table and need to make the same thing in snowflake.&lt;/p&gt;\n\n&lt;p&gt;I managed to create a bunch of procedures and function that together do the thing(as a result it inserts into temp table so i can join to it later) but only for predefined values and I need it to be executed for each row in the table.&lt;/p&gt;\n\n&lt;p&gt;I also tried using dbt jinja for this purpose, but because jinja doesn&amp;#39;t have while loop(i still have to use procedure for one part) i didn&amp;#39;t manage to make script work with columns because it didn&amp;#39;t render values, only column names.&lt;/p&gt;\n\n&lt;p&gt;Do you have any ideas? I am out of them.\nThanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "192q0bi", "is_robot_indexable": true, "report_reasons": null, "author": "awkward_period", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192q0bi/make_ssis_script_variant_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192q0bi/make_ssis_script_variant_in_snowflake/", "subreddit_subscribers": 151671, "created_utc": 1704835282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been looking at using Iceberg with Trino, but I see you need a metastore/Iceberg catalog to work with Iceberg tables. I have data in Dell ECS (can't move it to something like Amazon S3).\n\nCan anyone with Iceberg or Trino experience walk me through their thought process on choosing their Iceberg catalog? Why shouldn't I just use Hive Metastore?\n\nAny comparison on experiences with Hive Metastore or another Iceberg catalog like JDBC Catalog would be great. Thank you", "author_fullname": "t2_rl9jnw10q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg catalog for Trino?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192l2hm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704823480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking at using Iceberg with Trino, but I see you need a metastore/Iceberg catalog to work with Iceberg tables. I have data in Dell ECS (can&amp;#39;t move it to something like Amazon S3).&lt;/p&gt;\n\n&lt;p&gt;Can anyone with Iceberg or Trino experience walk me through their thought process on choosing their Iceberg catalog? Why shouldn&amp;#39;t I just use Hive Metastore?&lt;/p&gt;\n\n&lt;p&gt;Any comparison on experiences with Hive Metastore or another Iceberg catalog like JDBC Catalog would be great. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "192l2hm", "is_robot_indexable": true, "report_reasons": null, "author": "Relative_Unit_7640", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192l2hm/iceberg_catalog_for_trino/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192l2hm/iceberg_catalog_for_trino/", "subreddit_subscribers": 151671, "created_utc": 1704823480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have a question wrt Meltano, as I'm considering using it. How well does it work wrt batch jobs? Especially extractions from ftp servers, databases and api's on a daily basis with full overwrites to the target. Based on what I'm reading, it seems to be geared very much towards streaming with the batch related developments being rather new. Is it correct that streaming was always the focus of Meltano?", "author_fullname": "t2_9knk666s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch with Meltano", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192gc7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704811623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a question wrt Meltano, as I&amp;#39;m considering using it. How well does it work wrt batch jobs? Especially extractions from ftp servers, databases and api&amp;#39;s on a daily basis with full overwrites to the target. Based on what I&amp;#39;m reading, it seems to be geared very much towards streaming with the batch related developments being rather new. Is it correct that streaming was always the focus of Meltano?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "192gc7y", "is_robot_indexable": true, "report_reasons": null, "author": "limartje", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192gc7y/batch_with_meltano/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192gc7y/batch_with_meltano/", "subreddit_subscribers": 151671, "created_utc": 1704811623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi pals \n\nSo, last month I started a position as a data engineer at this big company and it's something really new to me. \n\nFor context, I have about 1 year of experience and at my last job I mostly worked in azure data factory, mantaining an ETL fmk with that + sql server + databricks (a lot of sql, a bit of pyspark). I also did some monitoring reports in powerbi. \n\nThe company is transitioning a lot of erp data into the cloud, and there's a big project involving different countries but at the same time it still relies on outsourcing for developing features for this other platform so there's some silos there and I feel so overwhelmed cause I was given the task to develop a feature but I feel like i have't even grasped the whole architecture and really wasn't aware of the dimension of it all... I'm also working on a language I haven't worked in a while so that's also affecting my impostor syndrome.\n\nIt's been a month and I feel like I have made very small progress, any advice on how to deal with this? Any of you been in a similar situation before?", "author_fullname": "t2_6bkvjznd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overwhelmed + Impostor Syndrome in DE position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19371i1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704889258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi pals &lt;/p&gt;\n\n&lt;p&gt;So, last month I started a position as a data engineer at this big company and it&amp;#39;s something really new to me. &lt;/p&gt;\n\n&lt;p&gt;For context, I have about 1 year of experience and at my last job I mostly worked in azure data factory, mantaining an ETL fmk with that + sql server + databricks (a lot of sql, a bit of pyspark). I also did some monitoring reports in powerbi. &lt;/p&gt;\n\n&lt;p&gt;The company is transitioning a lot of erp data into the cloud, and there&amp;#39;s a big project involving different countries but at the same time it still relies on outsourcing for developing features for this other platform so there&amp;#39;s some silos there and I feel so overwhelmed cause I was given the task to develop a feature but I feel like i have&amp;#39;t even grasped the whole architecture and really wasn&amp;#39;t aware of the dimension of it all... I&amp;#39;m also working on a language I haven&amp;#39;t worked in a while so that&amp;#39;s also affecting my impostor syndrome.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s been a month and I feel like I have made very small progress, any advice on how to deal with this? Any of you been in a similar situation before?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19371i1", "is_robot_indexable": true, "report_reasons": null, "author": "taromoo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19371i1/overwhelmed_impostor_syndrome_in_de_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19371i1/overwhelmed_impostor_syndrome_in_de_position/", "subreddit_subscribers": 151671, "created_utc": 1704889258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, \n\nI recently passed the exam for **Databricks Data Engineer Pro certification** \n\n[https://www.databricks.com/learn/certification/data-engineer-professional](https://www.databricks.com/learn/certification/data-engineer-professional)\n\nand I would like to expand it with the **Databricks Associate Developer for Apache Spark 3.0.**\n\n[https://www.databricks.com/learn/certification/apache-spark-developer-associate](https://www.databricks.com/learn/certification/apache-spark-developer-associate)\n\nI have reviewed the event list in [https://www.databricks.com/events](https://www.databricks.com/events) but it seems there are no upcoming events where one would get a voucher code for the exam. \n\nDo you guys know where to get one?. Are the events the only possible way for that?. \n\nThanks!", "author_fullname": "t2_oonyiqxt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just Got Certified as Databricks Data Engineer Pro - Aiming now for the spark badge. Any available voucher codes?.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1935ppc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704884392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, &lt;/p&gt;\n\n&lt;p&gt;I recently passed the exam for &lt;strong&gt;Databricks Data Engineer Pro certification&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/learn/certification/data-engineer-professional\"&gt;https://www.databricks.com/learn/certification/data-engineer-professional&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;and I would like to expand it with the &lt;strong&gt;Databricks Associate Developer for Apache Spark 3.0.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/learn/certification/apache-spark-developer-associate\"&gt;https://www.databricks.com/learn/certification/apache-spark-developer-associate&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have reviewed the event list in &lt;a href=\"https://www.databricks.com/events\"&gt;https://www.databricks.com/events&lt;/a&gt; but it seems there are no upcoming events where one would get a voucher code for the exam. &lt;/p&gt;\n\n&lt;p&gt;Do you guys know where to get one?. Are the events the only possible way for that?. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q3J_5tNQxoVKYB7KkTYPB72RKx1ZM5aY7do8m8eyJrY.jpg?auto=webp&amp;s=757df626a63f83d9b1b9f06f8d8ba2d8237cc58f", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/Q3J_5tNQxoVKYB7KkTYPB72RKx1ZM5aY7do8m8eyJrY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a16398fc492032970830de9a00c08df10b34b4f6", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Q3J_5tNQxoVKYB7KkTYPB72RKx1ZM5aY7do8m8eyJrY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a41a848b62534920ef03a38d809533173e246992", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Q3J_5tNQxoVKYB7KkTYPB72RKx1ZM5aY7do8m8eyJrY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=40a54960ac2c4744e4b273083930feb825efabd6", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/Q3J_5tNQxoVKYB7KkTYPB72RKx1ZM5aY7do8m8eyJrY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=014f43b3314169ca926f88efd3b0ee45aa5e04c5", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/Q3J_5tNQxoVKYB7KkTYPB72RKx1ZM5aY7do8m8eyJrY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=35758df6b7e49498041bec685a142e08302fa089", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/Q3J_5tNQxoVKYB7KkTYPB72RKx1ZM5aY7do8m8eyJrY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6db5a3a3031ae960d05d7a0590693b1808444daf", "width": 1080, "height": 565}], "variants": {}, "id": "HwfMz-OF8GV89jc_qQVRVxc8W8oTe2mVUnnrYLKLhX8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1935ppc", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Percentage447", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1935ppc/just_got_certified_as_databricks_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1935ppc/just_got_certified_as_databricks_data_engineer/", "subreddit_subscribers": 151671, "created_utc": 1704884392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need some help with dbt\n\nHi everyone I have started my learning journey in dbt. I have understood the basic concepts plus how to work with a standard dataset. But I m really confused when it comes to higher level when I m dealing with lots of table and huge data. \n\nHow can I make my models generic? \nDo I need to purely use macros for this? \nHow does a dbt project structure look like? \n\nWould be grateful if someone could guide me through this.", "author_fullname": "t2_sa16pkrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some help with dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19317lt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704866275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need some help with dbt&lt;/p&gt;\n\n&lt;p&gt;Hi everyone I have started my learning journey in dbt. I have understood the basic concepts plus how to work with a standard dataset. But I m really confused when it comes to higher level when I m dealing with lots of table and huge data. &lt;/p&gt;\n\n&lt;p&gt;How can I make my models generic? \nDo I need to purely use macros for this? \nHow does a dbt project structure look like? &lt;/p&gt;\n\n&lt;p&gt;Would be grateful if someone could guide me through this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19317lt", "is_robot_indexable": true, "report_reasons": null, "author": "misaaaa18", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19317lt/need_some_help_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19317lt/need_some_help_with_dbt/", "subreddit_subscribers": 151671, "created_utc": 1704866275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I originally posted this in /r/dataanalysis, but in hindsight it likely makes more sense for this audience, so asking it here as well.\n\nI work in higher education as a senior data analyst. As we have been adopting more and more external data sources (APIs, cloud-based databases, SFTP dumps), it has become clear that we need a formal ETL solution. We already have an on-premise data warehouse and staff to support it. As we start to look into whether we should buy a tool or train staff on writing custom python scripts for everything, I was hoping others at organizations might share what they do.", "author_fullname": "t2_gcxbn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your company handle ETL/ELT processes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192yp9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704858240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I originally posted this in &lt;a href=\"/r/dataanalysis\"&gt;/r/dataanalysis&lt;/a&gt;, but in hindsight it likely makes more sense for this audience, so asking it here as well.&lt;/p&gt;\n\n&lt;p&gt;I work in higher education as a senior data analyst. As we have been adopting more and more external data sources (APIs, cloud-based databases, SFTP dumps), it has become clear that we need a formal ETL solution. We already have an on-premise data warehouse and staff to support it. As we start to look into whether we should buy a tool or train staff on writing custom python scripts for everything, I was hoping others at organizations might share what they do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "192yp9u", "is_robot_indexable": true, "report_reasons": null, "author": "farm3rb0b", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192yp9u/how_does_your_company_handle_etlelt_processes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192yp9u/how_does_your_company_handle_etlelt_processes/", "subreddit_subscribers": 151671, "created_utc": 1704858240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI am currently a 3rd year College Student with a keen interest in pursuing a career in data engineering. I've been researching about the field and its prospects in India, especially for someone entering as a fresher.\n\nI would greatly appreciate insights and advice from the **experienced members** of this community. a few questions:\n\n1. **Current Scenario in India:** What is the current state of the data engineering job market in India? Are there ample opportunities for entry-level positions?\n2. **In-Demand Skills:** As a fresher, what specific skills or technologies should I focus on to make myself more marketable in the field?\n3. **Industry Preferences:** Are there specific industries or sectors in India that have a higher demand for data engineers? Any emerging trends worth noting?\n4. **Certifications:** Are there any certifications that are highly regarded in the Indian job market for data engineering roles?\n5. **Advice for Freshers:** What advice would you give to someone like me who is just starting out in their data engineering journey in India?\n6. **Networking Opportunities:** Are there any local or online communities, meetups, or events in India that you recommend for networking and staying updated on industry trends?", "author_fullname": "t2_qf3p8az34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring the Scope of Data Engineering in India as a Fresher: Seeking Advice and Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192wo0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704852236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a 3rd year College Student with a keen interest in pursuing a career in data engineering. I&amp;#39;ve been researching about the field and its prospects in India, especially for someone entering as a fresher.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate insights and advice from the &lt;strong&gt;experienced members&lt;/strong&gt; of this community. a few questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Current Scenario in India:&lt;/strong&gt; What is the current state of the data engineering job market in India? Are there ample opportunities for entry-level positions?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;In-Demand Skills:&lt;/strong&gt; As a fresher, what specific skills or technologies should I focus on to make myself more marketable in the field?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Industry Preferences:&lt;/strong&gt; Are there specific industries or sectors in India that have a higher demand for data engineers? Any emerging trends worth noting?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Certifications:&lt;/strong&gt; Are there any certifications that are highly regarded in the Indian job market for data engineering roles?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Advice for Freshers:&lt;/strong&gt; What advice would you give to someone like me who is just starting out in their data engineering journey in India?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Networking Opportunities:&lt;/strong&gt; Are there any local or online communities, meetups, or events in India that you recommend for networking and staying updated on industry trends?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "192wo0c", "is_robot_indexable": true, "report_reasons": null, "author": "Aj412803", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192wo0c/exploring_the_scope_of_data_engineering_in_india/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192wo0c/exploring_the_scope_of_data_engineering_in_india/", "subreddit_subscribers": 151671, "created_utc": 1704852236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering! \n\nWe figured out how to scale GitHub repos to handle large files. One of the side effects of this is that you can use GitHub actions to run data ETL pipelines and store the results in the same repo as your ETL code. No need to manage S3 credentials or setup a bunch of extra tools (e.g. logging / observability).\n\nI wrote a short tutorial here: [https://about.xethub.com/blog/simple-etl-pipelines-git-xet-github-actions](https://about.xethub.com/blog/simple-etl-pipelines-git-xet-github-actions)\n\nThis is our starter repo if you want to try this yourself:\n\n[https://github.com/xetdata/easy-etl-template](https://github.com/xetdata/easy-etl-template)", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Run ETL Pipelines &amp; Store Data in your GitHub Repos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_192mvcy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704827812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;! &lt;/p&gt;\n\n&lt;p&gt;We figured out how to scale GitHub repos to handle large files. One of the side effects of this is that you can use GitHub actions to run data ETL pipelines and store the results in the same repo as your ETL code. No need to manage S3 credentials or setup a bunch of extra tools (e.g. logging / observability).&lt;/p&gt;\n\n&lt;p&gt;I wrote a short tutorial here: &lt;a href=\"https://about.xethub.com/blog/simple-etl-pipelines-git-xet-github-actions\"&gt;https://about.xethub.com/blog/simple-etl-pipelines-git-xet-github-actions&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is our starter repo if you want to try this yourself:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/xetdata/easy-etl-template\"&gt;https://github.com/xetdata/easy-etl-template&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sdYV6ZkEi_gzGQ-MXB_vGnBrF8i34Rt_s57g3ZAxNbA.jpg?auto=webp&amp;s=ce2361d4419eab5a684702b36320b36c751b0021", "width": 999, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/sdYV6ZkEi_gzGQ-MXB_vGnBrF8i34Rt_s57g3ZAxNbA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1938fefade0e4a0fc98d7373c5455998e6223552", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/sdYV6ZkEi_gzGQ-MXB_vGnBrF8i34Rt_s57g3ZAxNbA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=647cf0aa213c535606e7a48d14a2fe5a7c0709fc", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/sdYV6ZkEi_gzGQ-MXB_vGnBrF8i34Rt_s57g3ZAxNbA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=21d2e3f28492f9d75297b14dd36d9ab3cc6f9c60", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/sdYV6ZkEi_gzGQ-MXB_vGnBrF8i34Rt_s57g3ZAxNbA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a2f4bd8dee603b2d9d3db569fff287d5846397e1", "width": 640, "height": 384}, {"url": "https://external-preview.redd.it/sdYV6ZkEi_gzGQ-MXB_vGnBrF8i34Rt_s57g3ZAxNbA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=787d94858e6e76f04ebb1524aa3562627ddb87f7", "width": 960, "height": 576}], "variants": {}, "id": "MZUbycikHgdIhqG0Jr7OWKJ4DUAVKQTfRwDuWOGvtow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "192mvcy", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/192mvcy/run_etl_pipelines_store_data_in_your_github_repos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/192mvcy/run_etl_pipelines_store_data_in_your_github_repos/", "subreddit_subscribers": 151671, "created_utc": 1704827812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a Jr Data engineer, and  I always thought the most frustrating part in the DE world is setting up a local environment for your side projects, especially all tutorial starts with the coding with little or no information on that first initial step which is setting the environment what are you thoughts on this ? And do you have any tips on how to build a stable local environment  ( feel free to propose the stack you're using and OS  )", "author_fullname": "t2_clvfd8b8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting a stable environment for data pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1938z3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704895397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a Jr Data engineer, and  I always thought the most frustrating part in the DE world is setting up a local environment for your side projects, especially all tutorial starts with the coding with little or no information on that first initial step which is setting the environment what are you thoughts on this ? And do you have any tips on how to build a stable local environment  ( feel free to propose the stack you&amp;#39;re using and OS  )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1938z3i", "is_robot_indexable": true, "report_reasons": null, "author": "mechniwegeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1938z3i/setting_a_stable_environment_for_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1938z3i/setting_a_stable_environment_for_data_pipeline/", "subreddit_subscribers": 151671, "created_utc": 1704895397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a small startup that has implemented some very basic pyspark scripts orchestrated by step functions.\nI want to get an understanding of best practices of pyspark processes (how to structure files, optimise pipelines etc) and I'm not sure where to look.", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn ETL best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1938bix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704893445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a small startup that has implemented some very basic pyspark scripts orchestrated by step functions.\nI want to get an understanding of best practices of pyspark processes (how to structure files, optimise pipelines etc) and I&amp;#39;m not sure where to look.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1938bix", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1938bix/how_to_learn_etl_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1938bix/how_to_learn_etl_best_practices/", "subreddit_subscribers": 151671, "created_utc": 1704893445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Community,\n\nAdding Kafka to my organization. What would you build on top to make your developers' lives easier? in a sense of self-serve, APIs, boilerplates, out-of-the-box services, etc.\n\nThank you!\n\n&amp;#x200B;", "author_fullname": "t2_hhdac8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding Kafka to my organization. What should be built on top?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19384vx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704892872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Community,&lt;/p&gt;\n\n&lt;p&gt;Adding Kafka to my organization. What would you build on top to make your developers&amp;#39; lives easier? in a sense of self-serve, APIs, boilerplates, out-of-the-box services, etc.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19384vx", "is_robot_indexable": true, "report_reasons": null, "author": "yanivbh1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19384vx/adding_kafka_to_my_organization_what_should_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19384vx/adding_kafka_to_my_organization_what_should_be/", "subreddit_subscribers": 151671, "created_utc": 1704892872.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}