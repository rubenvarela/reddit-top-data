{"kind": "Listing", "data": {"after": "t3_18x4lva", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Happy new year! Here is a write-up of how I cancelled my Spotify subscription and RETVRNed to tradition (an MP3 player). This task felt incredibly daunting to me for a long time and I couldn't find a ton of good resources on how to ease the pain of migration. So here's how I managed it.\n\n---\n\n**THE REASONING**\n\nIn the 8 years I've been a Spotify subscriber, I've paid the company almost $1000. With that money I could have bought one new digital album every month; instead it went to a streaming company that I despise so their CEO could rub his nipples atop a pile of macarons for the rest of his life. \n\nI shouldn't go into the reasons I hate Spotify in depth, but it's cathartic to complain, so here are my basic gripes:\n\n* Poor and worsening interface design that doesn't yet have feature parity with a 2005 iPod\n* Taking forever to load albums that I have downloaded\n* Repeatedly deleting music that I have downloaded when I'm in the backcountry without internet\n* Not paying artists and generally being toxic for the industry. As a musician this is especially painful.\n* All the algorithms, metrics, \"engagement\" shit, etc. make me want to &lt;redacted&gt;.\n\nMost importantly, I was no longer enjoying music like I used to. Maybe I'm just a boomer millennial, but having everything immediately accessible cheapens the experience for me. Music starts to feel less valuable, it all gets shoveled into the endless-scrolling slop trough and my dopamine-addled neurons can barely fire in response.\n\n---\n\n**THE TOOLS**\n\n* [Tunemymusic](https://tunemymusic.com/) -- used to export all of my albums from Spotify to a CSV. After connecting and selecting your albums, use the \"Export to file\" option at the bottom. This does not require a tunemymusic account or whatever.\n* [Beets](https://beets.readthedocs.io/en/stable/index.html) -- used to organize and tag MP3s\n* Astell &amp; Kern AK70 MP3 player, used from ebay (I just needed something with aux and bluetooth and good sound quality and a decent interface; there are a million other mp3 players to choose from)\n* [Tagger](https://flathub.org/apps/org.nickvision.tagger) -- used to correct tags when Beets couldn't find them, especially for classical music\n* [This dumb Python script I wrote](https://gist.github.com/sayoder/a942faa075466b0c3fecf5d4de8934c5) -- Used to easily see what albums I still have to download. Requires beets and termcolor libraries to run.\n* [This even dumber Bash script](https://gist.github.com/sayoder/5c2187002498966db53571ca51e9e170) -- WARNING: running this will convert and delete ALL flac files under your current working directory. \n\n---\n\n**THE PROCESS**\n\n1. I bought an MP3 player. Important step. \n2. I exported all of my albums from Spotify into a CSV using the Tunemymusic tool.\n3. Using a text editor, I removed the CSV header and all columns except for the Artist and Album columns. Why? Because I didn't feel like counting all the columns to find the right indices for my dumbass python script.\n4. I wrote a python script (linked above) to compare the CSV with the albums I have in my Beets library. The output looks like [this](https://i.imgur.com/CPFceFK.png). \n5. Over the course of a few weeks, I obtained most of my music, repeatedly using the Python script to track albums I had vs. albums I still needed. For small or local artists, I purchase digital album downloads directly from their websites or bandcamp pages. Admittedly, this is a large initial investment. For larger artists, I usually found the music through other means: Perhaps cosmic rays flipped a billion bits on my hard drive in precisely the correct orientations, stuff like that. We'll never know how it got there.\n6. After downloading a few albums into a \"staging\" folder on my computer, I use the `flac2mp3.sh` script (linked above) to convert all FLACs to equivalent MP3s because I'm not a lossless audio freak.\n7. Then, I use `beet import` to scan and import music to my Beets library. Beets almost always finds the correct tags using metadata from musicbrainz.org. For cases where it doesn't find the correct tags, I cancel the import and re-tag the MP3s using the Tagger software.\n8. I still have some albums left to get, but most of my music is perfectly tagged, sitting in a folder on my hard drive, organized in directories like `Artist/Album/Track.mp3`. I plug in my MP3 player and use `rsync` to sync my music.\n9. Rejoice. Exhale.\n\n---\n\nSo that was my process. I know a lot of people are at the end of their rope with the [enshittification](https://www.wired.com/story/tiktok-platforms-cory-doctorow/) of streaming services, but are too locked in to see a way out. So I hope this is helpful for someone else out there! If there's anything I can clarify, please let me know, and I am available for help with any of the command-line tools mentioned here.", "author_fullname": "t2_15jtp4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I migrated my music from Spotify", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18wuyj5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 311, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 311, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704221141.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704216744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happy new year! Here is a write-up of how I cancelled my Spotify subscription and RETVRNed to tradition (an MP3 player). This task felt incredibly daunting to me for a long time and I couldn&amp;#39;t find a ton of good resources on how to ease the pain of migration. So here&amp;#39;s how I managed it.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;strong&gt;THE REASONING&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In the 8 years I&amp;#39;ve been a Spotify subscriber, I&amp;#39;ve paid the company almost $1000. With that money I could have bought one new digital album every month; instead it went to a streaming company that I despise so their CEO could rub his nipples atop a pile of macarons for the rest of his life. &lt;/p&gt;\n\n&lt;p&gt;I shouldn&amp;#39;t go into the reasons I hate Spotify in depth, but it&amp;#39;s cathartic to complain, so here are my basic gripes:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Poor and worsening interface design that doesn&amp;#39;t yet have feature parity with a 2005 iPod&lt;/li&gt;\n&lt;li&gt;Taking forever to load albums that I have downloaded&lt;/li&gt;\n&lt;li&gt;Repeatedly deleting music that I have downloaded when I&amp;#39;m in the backcountry without internet&lt;/li&gt;\n&lt;li&gt;Not paying artists and generally being toxic for the industry. As a musician this is especially painful.&lt;/li&gt;\n&lt;li&gt;All the algorithms, metrics, &amp;quot;engagement&amp;quot; shit, etc. make me want to &amp;lt;redacted&amp;gt;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Most importantly, I was no longer enjoying music like I used to. Maybe I&amp;#39;m just a boomer millennial, but having everything immediately accessible cheapens the experience for me. Music starts to feel less valuable, it all gets shoveled into the endless-scrolling slop trough and my dopamine-addled neurons can barely fire in response.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;strong&gt;THE TOOLS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://tunemymusic.com/\"&gt;Tunemymusic&lt;/a&gt; -- used to export all of my albums from Spotify to a CSV. After connecting and selecting your albums, use the &amp;quot;Export to file&amp;quot; option at the bottom. This does not require a tunemymusic account or whatever.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://beets.readthedocs.io/en/stable/index.html\"&gt;Beets&lt;/a&gt; -- used to organize and tag MP3s&lt;/li&gt;\n&lt;li&gt;Astell &amp;amp; Kern AK70 MP3 player, used from ebay (I just needed something with aux and bluetooth and good sound quality and a decent interface; there are a million other mp3 players to choose from)&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://flathub.org/apps/org.nickvision.tagger\"&gt;Tagger&lt;/a&gt; -- used to correct tags when Beets couldn&amp;#39;t find them, especially for classical music&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://gist.github.com/sayoder/a942faa075466b0c3fecf5d4de8934c5\"&gt;This dumb Python script I wrote&lt;/a&gt; -- Used to easily see what albums I still have to download. Requires beets and termcolor libraries to run.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://gist.github.com/sayoder/5c2187002498966db53571ca51e9e170\"&gt;This even dumber Bash script&lt;/a&gt; -- WARNING: running this will convert and delete ALL flac files under your current working directory. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;strong&gt;THE PROCESS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I bought an MP3 player. Important step. &lt;/li&gt;\n&lt;li&gt;I exported all of my albums from Spotify into a CSV using the Tunemymusic tool.&lt;/li&gt;\n&lt;li&gt;Using a text editor, I removed the CSV header and all columns except for the Artist and Album columns. Why? Because I didn&amp;#39;t feel like counting all the columns to find the right indices for my dumbass python script.&lt;/li&gt;\n&lt;li&gt;I wrote a python script (linked above) to compare the CSV with the albums I have in my Beets library. The output looks like &lt;a href=\"https://i.imgur.com/CPFceFK.png\"&gt;this&lt;/a&gt;. &lt;/li&gt;\n&lt;li&gt;Over the course of a few weeks, I obtained most of my music, repeatedly using the Python script to track albums I had vs. albums I still needed. For small or local artists, I purchase digital album downloads directly from their websites or bandcamp pages. Admittedly, this is a large initial investment. For larger artists, I usually found the music through other means: Perhaps cosmic rays flipped a billion bits on my hard drive in precisely the correct orientations, stuff like that. We&amp;#39;ll never know how it got there.&lt;/li&gt;\n&lt;li&gt;After downloading a few albums into a &amp;quot;staging&amp;quot; folder on my computer, I use the &lt;code&gt;flac2mp3.sh&lt;/code&gt; script (linked above) to convert all FLACs to equivalent MP3s because I&amp;#39;m not a lossless audio freak.&lt;/li&gt;\n&lt;li&gt;Then, I use &lt;code&gt;beet import&lt;/code&gt; to scan and import music to my Beets library. Beets almost always finds the correct tags using metadata from musicbrainz.org. For cases where it doesn&amp;#39;t find the correct tags, I cancel the import and re-tag the MP3s using the Tagger software.&lt;/li&gt;\n&lt;li&gt;I still have some albums left to get, but most of my music is perfectly tagged, sitting in a folder on my hard drive, organized in directories like &lt;code&gt;Artist/Album/Track.mp3&lt;/code&gt;. I plug in my MP3 player and use &lt;code&gt;rsync&lt;/code&gt; to sync my music.&lt;/li&gt;\n&lt;li&gt;Rejoice. Exhale.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;So that was my process. I know a lot of people are at the end of their rope with the &lt;a href=\"https://www.wired.com/story/tiktok-platforms-cory-doctorow/\"&gt;enshittification&lt;/a&gt; of streaming services, but are too locked in to see a way out. So I hope this is helpful for someone else out there! If there&amp;#39;s anything I can clarify, please let me know, and I am available for help with any of the command-line tools mentioned here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fQuNUTQGXqIeg6ZLF6mEifO55yU_Y7j7Xv5nKKwto-s.png?auto=webp&amp;s=7e038f1bf09fbb31af409df152fbd66da1b456a5", "width": 743, "height": 995}, "resolutions": [{"url": "https://external-preview.redd.it/fQuNUTQGXqIeg6ZLF6mEifO55yU_Y7j7Xv5nKKwto-s.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d50efe9c937f57fdc7db09614d0af247d7c4afee", "width": 108, "height": 144}, {"url": "https://external-preview.redd.it/fQuNUTQGXqIeg6ZLF6mEifO55yU_Y7j7Xv5nKKwto-s.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=674a9fa17853890bbf7ce5e9ac253f0befc5b01d", "width": 216, "height": 289}, {"url": "https://external-preview.redd.it/fQuNUTQGXqIeg6ZLF6mEifO55yU_Y7j7Xv5nKKwto-s.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7d8ecfbc0f06b8890bd59253bd55c7e20ce898f", "width": 320, "height": 428}, {"url": "https://external-preview.redd.it/fQuNUTQGXqIeg6ZLF6mEifO55yU_Y7j7Xv5nKKwto-s.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7cd9e693ff7f7a3ed4680c6eaa0bde44510f69a7", "width": 640, "height": 857}], "variants": {}, "id": "Fbna8hA7kSMoskvvHphOLKEZ585kI6_qD8-6xg57988"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18wuyj5", "is_robot_indexable": true, "report_reasons": null, "author": "MortimerMcMire315", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18wuyj5/how_i_migrated_my_music_from_spotify/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18wuyj5/how_i_migrated_my_music_from_spotify/", "subreddit_subscribers": 722981, "created_utc": 1704216744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys,\n\nI would like to introduce you all to a piece of software that my friend and I have been developing for almost around one and a half year i think: [GameVault](https://gamevau.lt)\n\nIf you don't hoard any video games, you can stop reading right here. :)\n\nGameVault is a self-hostable platform that you can deploy directly on your file server/NAS where your games are stored. It allows you to browse, download, launch, track, and share all video games you have on there using a [Steam-like Windows app](https://www.microsoft.com/store/apps/9PCKDV76GL75) ([also usable via Linux via Wine](https://gamevau.lt/docs/advanced-usage/linux-client)).\n\nIt automatically enriches the games with metadata and is completely free to use. Think plex/jellyfin, but for videogames (and without streaming). Currently, it's mostly optimized for PC video gaming, but it already supports browsing and downloading ROMs. We plan to integrate emulator support to allow you to track and launch video games as well soon!\n\nIf you like what you've heard, you can come and check it out further [here](https://gamevau.lt), or join our [Discord](https://discord.gg/NEdNen2dSu) if you have any further questions.\n\nThank you all for your attention and have a nice day!\n\n\nWebsite: [gamevau.lt](https://gamevau.lt)  \nGithub: [Frontend](https://github.com/Phalcode/gamevault-app) / [Backend](https://github.com/Phalcode/gamevault-backend)", "author_fullname": "t2_xqgrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GameVault: browse and play your hoarded games using a self-hosted steam-like gaming Platform.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ww1q4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 78, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 78, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704219704.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704219308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I would like to introduce you all to a piece of software that my friend and I have been developing for almost around one and a half year i think: &lt;a href=\"https://gamevau.lt\"&gt;GameVault&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you don&amp;#39;t hoard any video games, you can stop reading right here. :)&lt;/p&gt;\n\n&lt;p&gt;GameVault is a self-hostable platform that you can deploy directly on your file server/NAS where your games are stored. It allows you to browse, download, launch, track, and share all video games you have on there using a &lt;a href=\"https://www.microsoft.com/store/apps/9PCKDV76GL75\"&gt;Steam-like Windows app&lt;/a&gt; (&lt;a href=\"https://gamevau.lt/docs/advanced-usage/linux-client\"&gt;also usable via Linux via Wine&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;It automatically enriches the games with metadata and is completely free to use. Think plex/jellyfin, but for videogames (and without streaming). Currently, it&amp;#39;s mostly optimized for PC video gaming, but it already supports browsing and downloading ROMs. We plan to integrate emulator support to allow you to track and launch video games as well soon!&lt;/p&gt;\n\n&lt;p&gt;If you like what you&amp;#39;ve heard, you can come and check it out further &lt;a href=\"https://gamevau.lt\"&gt;here&lt;/a&gt;, or join our &lt;a href=\"https://discord.gg/NEdNen2dSu\"&gt;Discord&lt;/a&gt; if you have any further questions.&lt;/p&gt;\n\n&lt;p&gt;Thank you all for your attention and have a nice day!&lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://gamevau.lt\"&gt;gamevau.lt&lt;/a&gt;&lt;br/&gt;\nGithub: &lt;a href=\"https://github.com/Phalcode/gamevault-app\"&gt;Frontend&lt;/a&gt; / &lt;a href=\"https://github.com/Phalcode/gamevault-backend\"&gt;Backend&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18ww1q4", "is_robot_indexable": true, "report_reasons": null, "author": "Alfagun74", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18ww1q4/gamevault_browse_and_play_your_hoarded_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18ww1q4/gamevault_browse_and_play_your_hoarded_games/", "subreddit_subscribers": 722981, "created_utc": 1704219308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_mks58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ytvip: a local YouTube archive/library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_18wtfjb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/10tkec5wv1ac1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/10tkec5wv1ac1/DASH_96.mp4", "dash_url": "https://v.redd.it/10tkec5wv1ac1/DASHPlaylist.mpd?a=1706892028%2CYzQzMGMwNDgyNTQ4YjIxMGRmMGIyZDYzYmEyNjgwZjlkODY5N2FlMmI3MTc3MzgyMjE0NWZiM2E4M2I0ZWEyMA%3D%3D&amp;v=1&amp;f=sd", "duration": 10, "hls_url": "https://v.redd.it/10tkec5wv1ac1/HLSPlaylist.m3u8?a=1706892028%2CYTM5OWExZTdmYjFiMjc4MzRjMTNiM2NhNDg2Mzk3N2Q0NTc3ODY2NjQzMWZlNWNmMjg2NDdhZThhMmViZmZkYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=d56df38d7b2a8638ebdaf5329e007e056c7ee6f5", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704212990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/10tkec5wv1ac1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg.png?format=pjpg&amp;auto=webp&amp;s=11a60f36ad9d73faff09128108b0ca93460c1ebf", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c4e648360f15f8d82c62ca7e266a08b344e7539d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b7bf80703f74ddbeda251fb14e4be57df9887cc3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=161165f721f60608b461115b2689414be5577d02", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0b97e7e0de96aa705756db8c450a16315ba3c18e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=bae0312f01db30c67077b349d4a515011e35c92b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c9ecf667e3ab5f123d8d0114389a2c34a5cd4740", "width": 1080, "height": 607}], "variants": {}, "id": "Z2VmbTRsdzQwMmFjMY5P5mn_dutiHeWU7N5LywuB4opIIePV-cPOEG53ypZg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18wtfjb", "is_robot_indexable": true, "report_reasons": null, "author": "kwirled", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18wtfjb/ytvip_a_local_youtube_archivelibrary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/10tkec5wv1ac1", "subreddit_subscribers": 722981, "created_utc": 1704212990.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/10tkec5wv1ac1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/10tkec5wv1ac1/DASH_96.mp4", "dash_url": "https://v.redd.it/10tkec5wv1ac1/DASHPlaylist.mpd?a=1706892028%2CYzQzMGMwNDgyNTQ4YjIxMGRmMGIyZDYzYmEyNjgwZjlkODY5N2FlMmI3MTc3MzgyMjE0NWZiM2E4M2I0ZWEyMA%3D%3D&amp;v=1&amp;f=sd", "duration": 10, "hls_url": "https://v.redd.it/10tkec5wv1ac1/HLSPlaylist.m3u8?a=1706892028%2CYTM5OWExZTdmYjFiMjc4MzRjMTNiM2NhNDg2Mzk3N2Q0NTc3ODY2NjQzMWZlNWNmMjg2NDdhZThhMmViZmZkYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_cqim23k3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "New year = new NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4v13sb3bc3ac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/4v13sb3bc3ac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=089373c108a278cd9b1605298bed4107eadcafd5"}, {"y": 161, "x": 216, "u": "https://preview.redd.it/4v13sb3bc3ac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=53880a9b570f6aca900751c1bcd7434d47aa3feb"}, {"y": 238, "x": 320, "u": "https://preview.redd.it/4v13sb3bc3ac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c041170eed2ccf4aa3e62df5391af65b89f7be3b"}, {"y": 477, "x": 640, "u": "https://preview.redd.it/4v13sb3bc3ac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca00048d3b14cc5191b7adb0bc655fe18ca20c07"}, {"y": 716, "x": 960, "u": "https://preview.redd.it/4v13sb3bc3ac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=43a66b0656a4b2b037fe2ee2d2bb63d083d5b781"}, {"y": 806, "x": 1080, "u": "https://preview.redd.it/4v13sb3bc3ac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0f148c055f38ae7bba772e8b211c3c29ac23a0ca"}], "s": {"y": 1876, "x": 2512, "u": "https://preview.redd.it/4v13sb3bc3ac1.png?width=2512&amp;format=png&amp;auto=webp&amp;s=2b31bd70f4549215e6e34edb7ab75ee8055b2545"}, "id": "4v13sb3bc3ac1"}, "ax5m6ohob3ac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/ax5m6ohob3ac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e478683fc1e2d83cc7ea434affb428e2196b9485"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/ax5m6ohob3ac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0929a480899e38901174baa0694c3299a9b2ba33"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/ax5m6ohob3ac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d82a14c19ca40aa2fb2102119551612b413055b7"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/ax5m6ohob3ac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9f11163bf56ba1583ebc77df0669cdc56769a26c"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/ax5m6ohob3ac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=85771ad82db762e886cfb1cc10f28fbb0ee1135d"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/ax5m6ohob3ac1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f40ff8d0ba1a0c747ee112fa32d7d3eb6b6835a3"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/ax5m6ohob3ac1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=4600c7a3f3db9805997e44af8b029e769210ffe8"}, "id": "ax5m6ohob3ac1"}}, "name": "t3_18x0t6k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 50, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Build from spare parts", "media_id": "ax5m6ohob3ac1", "id": 383125256}, {"caption": "Utilization while 1 Gbit transfer from Backup-HDD", "media_id": "4v13sb3bc3ac1", "id": 383125257}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3XxRTvP1MW_xHVP2xmOvHhdc0IOwx-Vw1lgCEeROC5M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704230696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18x0t6k", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18x0t6k", "is_robot_indexable": true, "report_reasons": null, "author": "Simsalabimson", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18x0t6k/new_year_new_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18x0t6k", "subreddit_subscribers": 722981, "created_utc": 1704230696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a consensus on the best storage pooling (software raid) technology in this sub?   I know it gets a lot of hate, but I'm currently running a Windows Storage Space with 6 drives totaling 76tb and it's worked really well for me.  I have even moved it between computers with no issues.  I'm approaching 80% space used and so I want to take the time and analyze the best path forward.  \n\nI'm aware of freenas and stablebit drivepool.  I think another option could be to upgrade to Windows server and use storage pools there.   What does this sub prefer?  I'd like something that could run on top of windows as this computer also hosts my plex server.  \n\nOn the hardware side I have 18,14,14,10,10,10 TB drives and a 2tb NVME.  I have maxed out my SATA ports on my motherboard so I either need larger drives or I'll have to start using splitters which I'm a bit nervous about.  Any suggestions are appreciated.", "author_fullname": "t2_fcr46", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best storage pooling technology for datahoarders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18wu3om", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704214676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a consensus on the best storage pooling (software raid) technology in this sub?   I know it gets a lot of hate, but I&amp;#39;m currently running a Windows Storage Space with 6 drives totaling 76tb and it&amp;#39;s worked really well for me.  I have even moved it between computers with no issues.  I&amp;#39;m approaching 80% space used and so I want to take the time and analyze the best path forward.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware of freenas and stablebit drivepool.  I think another option could be to upgrade to Windows server and use storage pools there.   What does this sub prefer?  I&amp;#39;d like something that could run on top of windows as this computer also hosts my plex server.  &lt;/p&gt;\n\n&lt;p&gt;On the hardware side I have 18,14,14,10,10,10 TB drives and a 2tb NVME.  I have maxed out my SATA ports on my motherboard so I either need larger drives or I&amp;#39;ll have to start using splitters which I&amp;#39;m a bit nervous about.  Any suggestions are appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18wu3om", "is_robot_indexable": true, "report_reasons": null, "author": "watchoutfor2nd", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18wu3om/best_storage_pooling_technology_for_datahoarders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18wu3om/best_storage_pooling_technology_for_datahoarders/", "subreddit_subscribers": 722981, "created_utc": 1704214676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5ijcn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just formatted (not quick), is the drive useless?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18x3gd3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oA-sdI0jhzYEWMqoNsmsFmWJM65gYcx_xuW-CJ9T5vk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704237057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/l4usq3anz3ac1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/l4usq3anz3ac1.jpeg?auto=webp&amp;s=8b8d1d5ba0ec48995f67076b16c7d1e18d7d46bf", "width": 672, "height": 685}, "resolutions": [{"url": "https://preview.redd.it/l4usq3anz3ac1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=177c3aa60790265ceef20651e5cfa7a0f6f4bac7", "width": 108, "height": 110}, {"url": "https://preview.redd.it/l4usq3anz3ac1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bcfb303d646f34cf55cc30545ac4eafe05b51a76", "width": 216, "height": 220}, {"url": "https://preview.redd.it/l4usq3anz3ac1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=19fbbb9d12fdfd7ba652b0af19e588d0fcc67e0a", "width": 320, "height": 326}, {"url": "https://preview.redd.it/l4usq3anz3ac1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=44961b92b08f24aeddbd3deb248f1e3df3844884", "width": 640, "height": 652}], "variants": {}, "id": "jpgObdNVpcJuLubMjQVm3vhYX3eIz45mXDi24bOd1m8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18x3gd3", "is_robot_indexable": true, "report_reasons": null, "author": "zkinny", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18x3gd3/just_formatted_not_quick_is_the_drive_useless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/l4usq3anz3ac1.jpeg", "subreddit_subscribers": 722981, "created_utc": 1704237057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just transferred all my JBOD drives to a 4 mirrored vdev ZFS configuration, and was worried scrubbing 50TB of data is going to take a very long time if I went with ZFS. I was pleasantly surprised when I saw the scrub speed reach 800 MB/s and that it will only take 17 hours for 50TB of data!\n\nI'm sure many of you are ZFS connoisseurs and this comes as no surprise, but I was happy to learn that ZFS scrub speed is proportional to how many mirrored vdevs you have in this configuration, so I'm getting 4x the individual drive speed. What a benefit over my previous non-RAID setup!\n\nI should've moved to ZFS sooner. ZFS' RAID configuration has increased the read speed of my files tremendously. Thanks r/datahoarder for showing me the path to lightning HDD speeds!", "author_fullname": "t2_qfbo9cm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZFS scrub speed is much faster than I anticipated!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 111, "top_awarded_type": null, "hide_score": false, "name": "t3_18x0ujv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GisqGGJ8-AXxl9NdWl04VVYgnkiDBbMAPjePiyhcBLA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704230786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just transferred all my JBOD drives to a 4 mirrored vdev ZFS configuration, and was worried scrubbing 50TB of data is going to take a very long time if I went with ZFS. I was pleasantly surprised when I saw the scrub speed reach 800 MB/s and that it will only take 17 hours for 50TB of data!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure many of you are ZFS connoisseurs and this comes as no surprise, but I was happy to learn that ZFS scrub speed is proportional to how many mirrored vdevs you have in this configuration, so I&amp;#39;m getting 4x the individual drive speed. What a benefit over my previous non-RAID setup!&lt;/p&gt;\n\n&lt;p&gt;I should&amp;#39;ve moved to ZFS sooner. ZFS&amp;#39; RAID configuration has increased the read speed of my files tremendously. Thanks &lt;a href=\"/r/datahoarder\"&gt;r/datahoarder&lt;/a&gt; for showing me the path to lightning HDD speeds!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/75g6t4x3h3ac1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/75g6t4x3h3ac1.png?auto=webp&amp;s=e4f6d99836112eb891d71413911c66262a8c80af", "width": 1440, "height": 1145}, "resolutions": [{"url": "https://preview.redd.it/75g6t4x3h3ac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9be9cc9e6a885fcc01a1427051a055b3113941f8", "width": 108, "height": 85}, {"url": "https://preview.redd.it/75g6t4x3h3ac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2106cabbfd356a4e128ab69ad4f43ca7903b6e7d", "width": 216, "height": 171}, {"url": "https://preview.redd.it/75g6t4x3h3ac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8fdd0734884e55dac856c7c098ebfe72f22e94d", "width": 320, "height": 254}, {"url": "https://preview.redd.it/75g6t4x3h3ac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f12ecc6a3c47869557356adec123b788a1750ac4", "width": 640, "height": 508}, {"url": "https://preview.redd.it/75g6t4x3h3ac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f536229f891abf29c166d00d002d6d5f46433da3", "width": 960, "height": 763}, {"url": "https://preview.redd.it/75g6t4x3h3ac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=81cfb1cf7fe90424e463d324f4077600903fc874", "width": 1080, "height": 858}], "variants": {}, "id": "Avw3ItXuRM_rUIefqKgRNpdrDXaBvqkhuU5Itext74Y"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18x0ujv", "is_robot_indexable": true, "report_reasons": null, "author": "peacey8", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18x0ujv/zfs_scrub_speed_is_much_faster_than_i_anticipated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/75g6t4x3h3ac1.png", "subreddit_subscribers": 722981, "created_utc": 1704230786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey folks,\nI was recently given a rather large tote of old family VHSs and asked if I could make copies on DVDs for other family members. While I'm a nerd, this is a process that's new to me and I'd like to follow whatever sort of best practices exist.\n\nI've already got a setup to copy the VHS to my server using OBS. From there, I'm not sure the best way to go. I'd like to store them digitally in such a way that they'll be good for years to come - future-proofed if you will. What sort of encoding should I prioritize? If I burn them to DVDs as well, what's the suggested encoding &amp; tools for that? Am I missing anything here?\n\nI do plan on a 3-2-1 backup as I know that's near and dear to this sub's heart.", "author_fullname": "t2_3pe8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving old family VHSs - Best practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18xligi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704294433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,\nI was recently given a rather large tote of old family VHSs and asked if I could make copies on DVDs for other family members. While I&amp;#39;m a nerd, this is a process that&amp;#39;s new to me and I&amp;#39;d like to follow whatever sort of best practices exist.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve already got a setup to copy the VHS to my server using OBS. From there, I&amp;#39;m not sure the best way to go. I&amp;#39;d like to store them digitally in such a way that they&amp;#39;ll be good for years to come - future-proofed if you will. What sort of encoding should I prioritize? If I burn them to DVDs as well, what&amp;#39;s the suggested encoding &amp;amp; tools for that? Am I missing anything here?&lt;/p&gt;\n\n&lt;p&gt;I do plan on a 3-2-1 backup as I know that&amp;#39;s near and dear to this sub&amp;#39;s heart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xligi", "is_robot_indexable": true, "report_reasons": null, "author": "dprimedx", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xligi/archiving_old_family_vhss_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xligi/archiving_old_family_vhss_best_practices/", "subreddit_subscribers": 722981, "created_utc": 1704294433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello r/datahoarder. I'm an amateur archivist, only just now getting the hang of how to navigate the command prompt. One of my favorite fan websites is dying, what is the easiest way to automate archiving all of the content on the website? I'd like to be able to access the images easily in the future. Websites like way back require manual entry for every link, a lot of image and video data gets lost. \nIs there an idiot proof way to automatically archive everything visible on the webpages?\nFor reference the website is tvxqdrip.com", "author_fullname": "t2_mek1y4er", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to idiotproof automate website archival", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xbsj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704260517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/datahoarder\"&gt;r/datahoarder&lt;/a&gt;. I&amp;#39;m an amateur archivist, only just now getting the hang of how to navigate the command prompt. One of my favorite fan websites is dying, what is the easiest way to automate archiving all of the content on the website? I&amp;#39;d like to be able to access the images easily in the future. Websites like way back require manual entry for every link, a lot of image and video data gets lost. \nIs there an idiot proof way to automatically archive everything visible on the webpages?\nFor reference the website is tvxqdrip.com&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xbsj2", "is_robot_indexable": true, "report_reasons": null, "author": "neo_theproletariat", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xbsj2/how_to_idiotproof_automate_website_archival/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xbsj2/how_to_idiotproof_automate_website_archival/", "subreddit_subscribers": 722981, "created_utc": 1704260517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nI perused before posting but didn't anticipate finding any other instances of something with so many moving parts. I have two 10 TB external HDDs (WD Elements @ 5400RPM) which I had planned to shuck and put to use in a RAID1 array but for reasons I don't exactly recall, probably just laziness, that never happened and I simply put one of them to work and left the other sealed in its packaging which is where it remains to this day. This was about 5-6 years ago but now the drive that I *did* put to use is nearly at capacity. It has around 700 GB of free space remaining (and if I'm not mistaken it's not advisable to tap them out entirely).\n\nSo, I endeavored to do what I had set out to initially 5-6 years ago with the 10TB drives but since one of them is already full, and tech being as quick to progress as it is, I purchased a couple of refurb'd 20TB 3.5\" HDDs (@7200rpm) from Server Part Deals via eBay in hopes of future proofing to some extent (The item has since sold out but this is the exact model https://www.ebay.com/itm/305178476535).\n\nNow that I've laid out the details, my question is;\n\nshould I purchase a 4-bay enclosure capable of running two simultaneous RAID1 arrays with two pairs of discs that are the same as each other but different from the other pair and which differ in size, speed, make and model? ChatGPT and Bard Tell me that this is doable as long as I get the correct model of enclosure, but didn't speak to whether it's advisable. Are there any other considerations that maybe the Chatbots didn't consider or share?\n\nOr.. \n\nShould I simply leave the external WD Elements drives enclosed as is and go with a simpler 2 bay enclosure for the two 20TB discs?\n\nThe latter option wouldn't provide data redundancy on the 10TB of data I've already accumulated, which doesn't sit well, but since that's nearly at capacity already, I was thinking (or hoping) that I could simply copy the contents of the one disc to the other without the need of a secondary RAID1 array running simultaneously, which would likely also save me a fair amount of scratch since the 4 bay enclosures capable of multiple arrays are quite a bit costlier than a more straightforward 2 bay enclosure. Not to mention I wouldn't have to shuck anything, as the 20TB HDDs are already free of any enclosures.\n\nAlso, in case it's not readily apparent, I am an utter n00b when it comes to data duplication and redundancy etc. and I fully admit as much, so I defer to your judgment. Are there any other options that I'm not considering here? Any input you're able to share is very much appreciated!\n\nEdited to add - despite its age and relatively slow speed, the WD Elements drive I've been using has been an absolute workhorse. SMART reporting tells me that it's still performing optimally with no bad sectors etc. But It has accumulated a not insignificant number of hours (years) under its belt. It's probably irrelevant but it's formatted BTRFS and is LUKS2 encrypted.", "author_fullname": "t2_16inwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4 Bay multiple RAID1 Array enclosure or nah?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xblzo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704260600.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704259928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I perused before posting but didn&amp;#39;t anticipate finding any other instances of something with so many moving parts. I have two 10 TB external HDDs (WD Elements @ 5400RPM) which I had planned to shuck and put to use in a RAID1 array but for reasons I don&amp;#39;t exactly recall, probably just laziness, that never happened and I simply put one of them to work and left the other sealed in its packaging which is where it remains to this day. This was about 5-6 years ago but now the drive that I &lt;em&gt;did&lt;/em&gt; put to use is nearly at capacity. It has around 700 GB of free space remaining (and if I&amp;#39;m not mistaken it&amp;#39;s not advisable to tap them out entirely).&lt;/p&gt;\n\n&lt;p&gt;So, I endeavored to do what I had set out to initially 5-6 years ago with the 10TB drives but since one of them is already full, and tech being as quick to progress as it is, I purchased a couple of refurb&amp;#39;d 20TB 3.5&amp;quot; HDDs (@7200rpm) from Server Part Deals via eBay in hopes of future proofing to some extent (The item has since sold out but this is the exact model &lt;a href=\"https://www.ebay.com/itm/305178476535\"&gt;https://www.ebay.com/itm/305178476535&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;Now that I&amp;#39;ve laid out the details, my question is;&lt;/p&gt;\n\n&lt;p&gt;should I purchase a 4-bay enclosure capable of running two simultaneous RAID1 arrays with two pairs of discs that are the same as each other but different from the other pair and which differ in size, speed, make and model? ChatGPT and Bard Tell me that this is doable as long as I get the correct model of enclosure, but didn&amp;#39;t speak to whether it&amp;#39;s advisable. Are there any other considerations that maybe the Chatbots didn&amp;#39;t consider or share?&lt;/p&gt;\n\n&lt;p&gt;Or.. &lt;/p&gt;\n\n&lt;p&gt;Should I simply leave the external WD Elements drives enclosed as is and go with a simpler 2 bay enclosure for the two 20TB discs?&lt;/p&gt;\n\n&lt;p&gt;The latter option wouldn&amp;#39;t provide data redundancy on the 10TB of data I&amp;#39;ve already accumulated, which doesn&amp;#39;t sit well, but since that&amp;#39;s nearly at capacity already, I was thinking (or hoping) that I could simply copy the contents of the one disc to the other without the need of a secondary RAID1 array running simultaneously, which would likely also save me a fair amount of scratch since the 4 bay enclosures capable of multiple arrays are quite a bit costlier than a more straightforward 2 bay enclosure. Not to mention I wouldn&amp;#39;t have to shuck anything, as the 20TB HDDs are already free of any enclosures.&lt;/p&gt;\n\n&lt;p&gt;Also, in case it&amp;#39;s not readily apparent, I am an utter n00b when it comes to data duplication and redundancy etc. and I fully admit as much, so I defer to your judgment. Are there any other options that I&amp;#39;m not considering here? Any input you&amp;#39;re able to share is very much appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edited to add - despite its age and relatively slow speed, the WD Elements drive I&amp;#39;ve been using has been an absolute workhorse. SMART reporting tells me that it&amp;#39;s still performing optimally with no bad sectors etc. But It has accumulated a not insignificant number of hours (years) under its belt. It&amp;#39;s probably irrelevant but it&amp;#39;s formatted BTRFS and is LUKS2 encrypted.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lygmnjm702AdNem5VZNnDB27O--7vGMpJtAoXd92y0M.jpg?auto=webp&amp;s=fb6850728c002168b34a947b6c24eaf7b5574cef", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/lygmnjm702AdNem5VZNnDB27O--7vGMpJtAoXd92y0M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=35afeab7929decf9ba2084052d1d420626268124", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/lygmnjm702AdNem5VZNnDB27O--7vGMpJtAoXd92y0M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6bb26a6f2ebb2ea50e248a86f7a097905477e467", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/lygmnjm702AdNem5VZNnDB27O--7vGMpJtAoXd92y0M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=80484bf92e28cb001078bce15623eb4e1676748a", "width": 320, "height": 320}], "variants": {}, "id": "Cf3pgH9F0LfT_MMBYPC_5FkLmKLaKyGfen4YB_o2FDo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xblzo", "is_robot_indexable": true, "report_reasons": null, "author": "QneEyedJack", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xblzo/4_bay_multiple_raid1_array_enclosure_or_nah/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xblzo/4_bay_multiple_raid1_array_enclosure_or_nah/", "subreddit_subscribers": 722981, "created_utc": 1704259928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am on a Mac. I need to transfer all of my 2023 collected images from one external drive to my main wallpaper folder. The images are in various subfolders, I can find them all using Find Any File, but from there whenever I copy all of them or try to transfer my mac shuts down, it can't handle it.\n\nIs there an app or a terminal command/shortcut that will allow me to select by file name and kind, all images with 2023 in the title, and copy them to another location?", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions to efficiently transfer 100,000 images.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x643s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704243844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am on a Mac. I need to transfer all of my 2023 collected images from one external drive to my main wallpaper folder. The images are in various subfolders, I can find them all using Find Any File, but from there whenever I copy all of them or try to transfer my mac shuts down, it can&amp;#39;t handle it.&lt;/p&gt;\n\n&lt;p&gt;Is there an app or a terminal command/shortcut that will allow me to select by file name and kind, all images with 2023 in the title, and copy them to another location?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18x643s", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18x643s/suggestions_to_efficiently_transfer_100000_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18x643s/suggestions_to_efficiently_transfer_100000_images/", "subreddit_subscribers": 722981, "created_utc": 1704243844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "even supplied me with spindles of DVD-r and DVD+r with cases and disc labels\u270a\ud83c\udffb", "author_fullname": "t2_a1iyfrdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "update on digitizing moms tapes: went to my electronic hoarding grandpa\u2019s for supplies\u2026this\u2019ll do!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": true, "name": "t3_18xl5hi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/m5I2s4ETN5tfZYC3F9V4e6RMcwdvb7ei294p10Wxuvk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704293458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;even supplied me with spindles of DVD-r and DVD+r with cases and disc labels\u270a\ud83c\udffb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/5l1f9yogn8ac1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/5l1f9yogn8ac1.jpeg?auto=webp&amp;s=b8d94c927e590dedd391bf11573bdf5e7b8ccb6d", "width": 1440, "height": 926}, "resolutions": [{"url": "https://preview.redd.it/5l1f9yogn8ac1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=87707a794fee54b4d83cd135dcee01d6678c1b71", "width": 108, "height": 69}, {"url": "https://preview.redd.it/5l1f9yogn8ac1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bf9fcdb6e31dca5679d0bf548fdba4a8cb09077e", "width": 216, "height": 138}, {"url": "https://preview.redd.it/5l1f9yogn8ac1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=35c2a5b4fac6c0dc64c3f06b206bf5f0e5f80a11", "width": 320, "height": 205}, {"url": "https://preview.redd.it/5l1f9yogn8ac1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60cbdf99ed56775880f5fd5ba6819a22fcf5d303", "width": 640, "height": 411}, {"url": "https://preview.redd.it/5l1f9yogn8ac1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61d408e7a29166004b417b7a87ec94c5746c099d", "width": 960, "height": 617}, {"url": "https://preview.redd.it/5l1f9yogn8ac1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88240e1b125c3f0d21af13b26ba54ab2fab4d6e5", "width": 1080, "height": 694}], "variants": {}, "id": "ffdsKugLTtNIGCQnzWPMMljCneVwhA8N5AtcIpcoECI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xl5hi", "is_robot_indexable": true, "report_reasons": null, "author": "KingCandy0103", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xl5hi/update_on_digitizing_moms_tapes_went_to_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/5l1f9yogn8ac1.jpeg", "subreddit_subscribers": 722981, "created_utc": 1704293458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it not viable to store video files in flash drives? It was a 64 GB cheap drive and I used up practically all the space. I was thinking of making a habit of this as I have a decent collection and people always ask me for suggestions. ", "author_fullname": "t2_146cxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I tried gifting my friend a flash drive with films, and apparently a couple of them freeze", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xjfc8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704288572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it not viable to store video files in flash drives? It was a 64 GB cheap drive and I used up practically all the space. I was thinking of making a habit of this as I have a decent collection and people always ask me for suggestions. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xjfc8", "is_robot_indexable": true, "report_reasons": null, "author": "Tiny_Tim1956", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xjfc8/i_tried_gifting_my_friend_a_flash_drive_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xjfc8/i_tried_gifting_my_friend_a_flash_drive_with/", "subreddit_subscribers": 722981, "created_utc": 1704288572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't particularly like SAP, and that's not a particularly active community\n\nAnd there's probably many anti-scraping counter measures in place to frustrate archivers\n\nBut, January 16, it's probably going to be gone.", "author_fullname": "t2_msvx0qnz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looks like community.sap.com is getting nuked", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xdcfv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704265844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t particularly like SAP, and that&amp;#39;s not a particularly active community&lt;/p&gt;\n\n&lt;p&gt;And there&amp;#39;s probably many anti-scraping counter measures in place to frustrate archivers&lt;/p&gt;\n\n&lt;p&gt;But, January 16, it&amp;#39;s probably going to be gone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "18xdcfv", "is_robot_indexable": true, "report_reasons": null, "author": "transdimensionalmeme", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xdcfv/looks_like_communitysapcom_is_getting_nuked/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xdcfv/looks_like_communitysapcom_is_getting_nuked/", "subreddit_subscribers": 722981, "created_utc": 1704265844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I normally hoard my data on my NAS with 20+ TB capacity, but for less tech-savvy family members I need an external drive for basic hoarding. Since the WD Elements 4TB external drive died (and had reports of these drives failing from other users as well) I am thinking about a regular drive in an external enclosure. \n\nA 4 TB 870 QVO seems to be a better choice than a Seagate Barracute compute SMR (likely) drive. \n\nHowever, how this disk will act as an external drive? Considering scenarios where data is copied over and the drive is immediately disconnected? My understanding is, that these drives work in a way that they fill up the SLC cache and then copy over the data to the actual QLC NAND chips. What will happen if the drive is disconnected during this procedure? ", "author_fullname": "t2_gww3b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung 870 QVO - good choice for an external backup drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x2v3x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704235583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I normally hoard my data on my NAS with 20+ TB capacity, but for less tech-savvy family members I need an external drive for basic hoarding. Since the WD Elements 4TB external drive died (and had reports of these drives failing from other users as well) I am thinking about a regular drive in an external enclosure. &lt;/p&gt;\n\n&lt;p&gt;A 4 TB 870 QVO seems to be a better choice than a Seagate Barracute compute SMR (likely) drive. &lt;/p&gt;\n\n&lt;p&gt;However, how this disk will act as an external drive? Considering scenarios where data is copied over and the drive is immediately disconnected? My understanding is, that these drives work in a way that they fill up the SLC cache and then copy over the data to the actual QLC NAND chips. What will happen if the drive is disconnected during this procedure? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18x2v3x", "is_robot_indexable": true, "report_reasons": null, "author": "rudeer_poke", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18x2v3x/samsung_870_qvo_good_choice_for_an_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18x2v3x/samsung_870_qvo_good_choice_for_an_external/", "subreddit_subscribers": 722981, "created_utc": 1704235583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://era.org.uk/\n\nTried some browser extension and fudding around in inspect element but nothing seems to work.\n\nCheers.", "author_fullname": "t2_7kp1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know how to download videos from the Educational Recording Facility?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18wxj0l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704222856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://era.org.uk/\"&gt;https://era.org.uk/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Tried some browser extension and fudding around in inspect element but nothing seems to work.&lt;/p&gt;\n\n&lt;p&gt;Cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZHrJf_S_A_feCjEadXZ2NV6rHPCyYWC4ni26RATuOcM.jpg?auto=webp&amp;s=e66154edaad2d1df244449defdf1265f56474392", "width": 712, "height": 505}, "resolutions": [{"url": "https://external-preview.redd.it/ZHrJf_S_A_feCjEadXZ2NV6rHPCyYWC4ni26RATuOcM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=303b04b58277eb225678e244b71b6a5fa73263b1", "width": 108, "height": 76}, {"url": "https://external-preview.redd.it/ZHrJf_S_A_feCjEadXZ2NV6rHPCyYWC4ni26RATuOcM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e053485290dd2f939eefbdf2ccf57bb1cbc54bab", "width": 216, "height": 153}, {"url": "https://external-preview.redd.it/ZHrJf_S_A_feCjEadXZ2NV6rHPCyYWC4ni26RATuOcM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26b932d6e42c6a6b9366b48769d04a77b4e67066", "width": 320, "height": 226}, {"url": "https://external-preview.redd.it/ZHrJf_S_A_feCjEadXZ2NV6rHPCyYWC4ni26RATuOcM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e450fc539f40237113e1c123be6d907389ce8c72", "width": 640, "height": 453}], "variants": {}, "id": "nfzwl7zb01G_Xt51OiZ589JqDwrsO0pvIGhNfmulTdA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18wxj0l", "is_robot_indexable": true, "report_reasons": null, "author": "MisterBreeze", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18wxj0l/does_anyone_know_how_to_download_videos_from_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18wxj0l/does_anyone_know_how_to_download_videos_from_the/", "subreddit_subscribers": 722981, "created_utc": 1704222856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to back up/clone an 18tb drive that I use as my media archive. Apart from being good practice, the drive threw up some errors after being shut down incorrectly a couple months ago. The windows repair tool run at the time and did some stuff (looks like it moved some files into some new folders?) But I didn't let it repair the drive in case I lost any data.\n\nWith some free time on my hands now, I wanted to back it up/clone it in its current state so I can let windows do it's thing and repair the drive.\n\nIt's a WD 18tb so I tried using the WD Acronis tool to clone it onto a second WD 18tb but it doesn't work because it thinks I need an additional 111mb of free space on the second drive.\n\nSo my plan was to reformat the new drive to be the same as the source drive and manually copy the data (as slow as that may be). It does actually seem to be the same currently but I don't think the allocation size is the same and I can't work out what it should be to match the source drive. Can anybody help?\n\nAdditional info:\n\nThe source drive works fine still, the only difference between now and before it had an error is that it doesn't shut down (blinking light) when the device it's connected to shuts down. So I have to button before I unplug it it after I've shut down the PC or turned off the TV it's connected to.\n\nI use it across a few devices which are an LG TV and a couple of Windows 10 PCs. Sometimes on a Mac.\n\nI believe I used diskpart in command prompt to format it initially using a guide online. I may have used the Windows Disk Management to format it after.\n\nI am a bit of a layman, I use step by step guides to use features in command prompt. I have no idea about Linux or anything like that (I've looked into clonezilla and I believe I won't be able to use it for this reason).\n\nI also may not understand instructions provided for command prompt so I may need a bit of extra hand holding it anybody provides help in this way. The reason I'm creating a new post for this is because I find it really difficult to understand random bits of information I've found in this Reddit and online.\n\nI've run an fsutil fsinfi ntfsinfo driveletter: command on both drives to see the allocation size but to be honest, I don't know how to read the information its given me. Some fields are different for each drive.\n\n----\n\nShould I let Windows repair the drive without doing a back up first?\n\nIf not, how can I clone the drive?\n\nIf I just need to manually back up all the files, how do I read the allocation size of the source drive so I can format the new one in exactly the same way?\n\nWhat other information do you need from me to help?\n\nThanks in advance for any help that can be provided.", "author_fullname": "t2_2i5j0omu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help for a Layman", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18xl15q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704293122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to back up/clone an 18tb drive that I use as my media archive. Apart from being good practice, the drive threw up some errors after being shut down incorrectly a couple months ago. The windows repair tool run at the time and did some stuff (looks like it moved some files into some new folders?) But I didn&amp;#39;t let it repair the drive in case I lost any data.&lt;/p&gt;\n\n&lt;p&gt;With some free time on my hands now, I wanted to back it up/clone it in its current state so I can let windows do it&amp;#39;s thing and repair the drive.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a WD 18tb so I tried using the WD Acronis tool to clone it onto a second WD 18tb but it doesn&amp;#39;t work because it thinks I need an additional 111mb of free space on the second drive.&lt;/p&gt;\n\n&lt;p&gt;So my plan was to reformat the new drive to be the same as the source drive and manually copy the data (as slow as that may be). It does actually seem to be the same currently but I don&amp;#39;t think the allocation size is the same and I can&amp;#39;t work out what it should be to match the source drive. Can anybody help?&lt;/p&gt;\n\n&lt;p&gt;Additional info:&lt;/p&gt;\n\n&lt;p&gt;The source drive works fine still, the only difference between now and before it had an error is that it doesn&amp;#39;t shut down (blinking light) when the device it&amp;#39;s connected to shuts down. So I have to button before I unplug it it after I&amp;#39;ve shut down the PC or turned off the TV it&amp;#39;s connected to.&lt;/p&gt;\n\n&lt;p&gt;I use it across a few devices which are an LG TV and a couple of Windows 10 PCs. Sometimes on a Mac.&lt;/p&gt;\n\n&lt;p&gt;I believe I used diskpart in command prompt to format it initially using a guide online. I may have used the Windows Disk Management to format it after.&lt;/p&gt;\n\n&lt;p&gt;I am a bit of a layman, I use step by step guides to use features in command prompt. I have no idea about Linux or anything like that (I&amp;#39;ve looked into clonezilla and I believe I won&amp;#39;t be able to use it for this reason).&lt;/p&gt;\n\n&lt;p&gt;I also may not understand instructions provided for command prompt so I may need a bit of extra hand holding it anybody provides help in this way. The reason I&amp;#39;m creating a new post for this is because I find it really difficult to understand random bits of information I&amp;#39;ve found in this Reddit and online.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve run an fsutil fsinfi ntfsinfo driveletter: command on both drives to see the allocation size but to be honest, I don&amp;#39;t know how to read the information its given me. Some fields are different for each drive.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Should I let Windows repair the drive without doing a back up first?&lt;/p&gt;\n\n&lt;p&gt;If not, how can I clone the drive?&lt;/p&gt;\n\n&lt;p&gt;If I just need to manually back up all the files, how do I read the allocation size of the source drive so I can format the new one in exactly the same way?&lt;/p&gt;\n\n&lt;p&gt;What other information do you need from me to help?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help that can be provided.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xl15q", "is_robot_indexable": true, "report_reasons": null, "author": "totalmcgotals", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xl15q/help_for_a_layman/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xl15q/help_for_a_layman/", "subreddit_subscribers": 722981, "created_utc": 1704293122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Data: \\~200G music and \\~200G videos. Daily upload, rarely download\n\nCurrently I'm using Digital Ocean Spaces (\\~$5/m) and a s3cmd script, but wondering if there's better option.\n\nRequirements:\n\n* upload procedure can be scripted\n* cheap\n\nNice to have:\n\n* web ui for file list, media file viewer even better", "author_fullname": "t2_x3s0wiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best options for remote backup media files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xja84", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704288739.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704288133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data: ~200G music and ~200G videos. Daily upload, rarely download&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m using Digital Ocean Spaces (~$5/m) and a s3cmd script, but wondering if there&amp;#39;s better option.&lt;/p&gt;\n\n&lt;p&gt;Requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;upload procedure can be scripted&lt;/li&gt;\n&lt;li&gt;cheap&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Nice to have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;web ui for file list, media file viewer even better&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xja84", "is_robot_indexable": true, "report_reasons": null, "author": "slmjkdbtl", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xja84/best_options_for_remote_backup_media_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xja84/best_options_for_remote_backup_media_files/", "subreddit_subscribers": 722981, "created_utc": 1704288133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Primarily looking for  a HDD for internal I'm open for an external harddrive. \n\nGoing to be doing a lot of reading and writing of files photos 80-120MB in size. Videos over 1GB. Looking for at leadt 8TB per drive. A lot of the high-usage rated HDDs are reported as failing with low useage on most reviews. ( today's age I trust negative over postive reviews)\n\nLooking for some options. I was thinking of a NAS but deciding against that for now.", "author_fullname": "t2_49phl308", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a reliable internal drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xj79e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704287882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Primarily looking for  a HDD for internal I&amp;#39;m open for an external harddrive. &lt;/p&gt;\n\n&lt;p&gt;Going to be doing a lot of reading and writing of files photos 80-120MB in size. Videos over 1GB. Looking for at leadt 8TB per drive. A lot of the high-usage rated HDDs are reported as failing with low useage on most reviews. ( today&amp;#39;s age I trust negative over postive reviews)&lt;/p&gt;\n\n&lt;p&gt;Looking for some options. I was thinking of a NAS but deciding against that for now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xj79e", "is_robot_indexable": true, "report_reasons": null, "author": "Andtheman4444", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xj79e/looking_for_a_reliable_internal_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xj79e/looking_for_a_reliable_internal_drive/", "subreddit_subscribers": 722981, "created_utc": 1704287882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a backup solution that takes a directory on my NAS and creates \"archives\" on local disk drives that I can take to an offsite location (and just leave them there, without touching them, hopefully ever). I'm looking for the following ideal workflow:\n\n* I initialize a local \"database\" of the backup status, stored in a local directory on the NAS. (may be multiple ones for multiple offsite/cloud destinations).\n* I attach a disk say 512 GB (or 2TB, whatever is lying around), and the backup tool will copy/encrypt data to that disk until it is mostly full, and also updates the local \"database\". It is important to assume that my NAS is much larger than the disks being used.\n* I can ship my disk to the offsite location without worrying that the data is exposed. The files on the disks would have a checksum on them to verify bit rot. I could move them physically or upload to cloud, doesn't really matter.\n* The tool can give me a % and teardown on how much and which data is not in the archive yet. (for incremental updates too). It should also track deletions, and maybe even renames.\n* I would also backup the local \"database\" of the archive to a different place. I would re-start the archive every 2-3 years, to rotate the disks and make sure it doesn't accumulate much unused bits.\n* The local \"database\" + the disks could be used to restore the backup partially or in full if needed.\n\nAny tool that exists for this use case or should I start writing it for myself?", "author_fullname": "t2_165hqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incremental backup (encrypted archive) to JBOD for offsite storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xho3c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704282831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a backup solution that takes a directory on my NAS and creates &amp;quot;archives&amp;quot; on local disk drives that I can take to an offsite location (and just leave them there, without touching them, hopefully ever). I&amp;#39;m looking for the following ideal workflow:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I initialize a local &amp;quot;database&amp;quot; of the backup status, stored in a local directory on the NAS. (may be multiple ones for multiple offsite/cloud destinations).&lt;/li&gt;\n&lt;li&gt;I attach a disk say 512 GB (or 2TB, whatever is lying around), and the backup tool will copy/encrypt data to that disk until it is mostly full, and also updates the local &amp;quot;database&amp;quot;. It is important to assume that my NAS is much larger than the disks being used.&lt;/li&gt;\n&lt;li&gt;I can ship my disk to the offsite location without worrying that the data is exposed. The files on the disks would have a checksum on them to verify bit rot. I could move them physically or upload to cloud, doesn&amp;#39;t really matter.&lt;/li&gt;\n&lt;li&gt;The tool can give me a % and teardown on how much and which data is not in the archive yet. (for incremental updates too). It should also track deletions, and maybe even renames.&lt;/li&gt;\n&lt;li&gt;I would also backup the local &amp;quot;database&amp;quot; of the archive to a different place. I would re-start the archive every 2-3 years, to rotate the disks and make sure it doesn&amp;#39;t accumulate much unused bits.&lt;/li&gt;\n&lt;li&gt;The local &amp;quot;database&amp;quot; + the disks could be used to restore the backup partially or in full if needed.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any tool that exists for this use case or should I start writing it for myself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xho3c", "is_robot_indexable": true, "report_reasons": null, "author": "isoos", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xho3c/incremental_backup_encrypted_archive_to_jbod_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xho3c/incremental_backup_encrypted_archive_to_jbod_for/", "subreddit_subscribers": 722981, "created_utc": 1704282831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everybody, I have 4 SSDs (two Samsung, two Toshiba) from old and dead CF-19 toughbooks. They had an hdd password set in bios. \nThis results in the drives being unusable and not formatable. The security level is set to maximum. The screenshot shows the hdparm output of the drive.\n\nI don\u2019t know the user or master password of these disks. How can in format these disks? I don\u2019t need any data from these disks, just want to make them usable again. \n\nThanks for your help!", "author_fullname": "t2_8yw4q3wz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Formatting an ata security maximum ssd", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_18xgp8x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w7Ms0NDZHMouLikM0JqevbRyohsxS30c8FQrrXYjFZY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704279297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody, I have 4 SSDs (two Samsung, two Toshiba) from old and dead CF-19 toughbooks. They had an hdd password set in bios. \nThis results in the drives being unusable and not formatable. The security level is set to maximum. The screenshot shows the hdparm output of the drive.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know the user or master password of these disks. How can in format these disks? I don\u2019t need any data from these disks, just want to make them usable again. &lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4us377nch7ac1.jpeg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4us377nch7ac1.jpeg?auto=webp&amp;s=d16535f99ec7cfa78c486064b925aa3984ec1611", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/4us377nch7ac1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d849a1a10a4dd70353ba2418464484031eefffd4", "width": 108, "height": 81}, {"url": "https://preview.redd.it/4us377nch7ac1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aea12b37539be9cbe348ac25684098c3a80e9c68", "width": 216, "height": 162}, {"url": "https://preview.redd.it/4us377nch7ac1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dce1586ca518ff215449647f6d7b93c5374d89f", "width": 320, "height": 240}, {"url": "https://preview.redd.it/4us377nch7ac1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=927562e5b5a991660f5c4298abfaf367263e145d", "width": 640, "height": 480}, {"url": "https://preview.redd.it/4us377nch7ac1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=70b6ae393fa57491c4ea4f4d3ca78ef86d1f3587", "width": 960, "height": 720}, {"url": "https://preview.redd.it/4us377nch7ac1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba13308791598d696e6c91efae95cc7351b7f7d7", "width": 1080, "height": 810}], "variants": {}, "id": "VPt9uw-_7WRXRbE0RsfJ7CGotea2zXaT5r-mIkM95Ho"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xgp8x", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Buy1907", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xgp8x/formatting_an_ata_security_maximum_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4us377nch7ac1.jpeg", "subreddit_subscribers": 722981, "created_utc": 1704279297.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am looking for a way to make a backup of my drive to another drive connected to my PC. However it should be able to sync both the drives so if I make changes in the original , it updates changes to the other drive only. I am fine if has to be updated manually. Can anyone suggest something", "author_fullname": "t2_8cpg4ih7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need a software to backup information from one drive to another and also have the data sync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xfbyc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704273809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am looking for a way to make a backup of my drive to another drive connected to my PC. However it should be able to sync both the drives so if I make changes in the original , it updates changes to the other drive only. I am fine if has to be updated manually. Can anyone suggest something&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xfbyc", "is_robot_indexable": true, "report_reasons": null, "author": "AwarenessNo4986", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xfbyc/need_a_software_to_backup_information_from_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xfbyc/need_a_software_to_backup_information_from_one/", "subreddit_subscribers": 722981, "created_utc": 1704273809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "like the title says. i suspect i will eventually get into nas as well as internet backup but for now, im not really looking to do that. what i do have right now is two 8 tb HDDs in my PC. i was previously using then as a mirrored storage pool on but have learned storage pools suck and decided to just offload some of my data and format the drives instead\n\nI was going to just mirror the drives to protect against failures but i was wondering if there's another alternative that's as simple to execute and wouldn't require too much manual work on my end. fwiw i have like 4 tb of data im working with atm", "author_fullname": "t2_91tx0vd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is there a middle ground between \"true\" backup that requires me to get a NAS/external and some sort of daily/weekly system vs me just mirroring data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xbipo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704259655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;like the title says. i suspect i will eventually get into nas as well as internet backup but for now, im not really looking to do that. what i do have right now is two 8 tb HDDs in my PC. i was previously using then as a mirrored storage pool on but have learned storage pools suck and decided to just offload some of my data and format the drives instead&lt;/p&gt;\n\n&lt;p&gt;I was going to just mirror the drives to protect against failures but i was wondering if there&amp;#39;s another alternative that&amp;#39;s as simple to execute and wouldn&amp;#39;t require too much manual work on my end. fwiw i have like 4 tb of data im working with atm&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18xbipo", "is_robot_indexable": true, "report_reasons": null, "author": "throwsomecode", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18xbipo/is_there_a_middle_ground_between_true_backup_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18xbipo/is_there_a_middle_ground_between_true_backup_that/", "subreddit_subscribers": 722981, "created_utc": 1704259655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As title states.  It was free software from MidAtlantic. Seems to have disappeared off the internet and internet archive doesn\u2019t have a copy. \n\nNot sure where else to look either.", "author_fullname": "t2_ar4yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone happen to have archive of RackTools 3.5?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x76v2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704246805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title states.  It was free software from MidAtlantic. Seems to have disappeared off the internet and internet archive doesn\u2019t have a copy. &lt;/p&gt;\n\n&lt;p&gt;Not sure where else to look either.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18x76v2", "is_robot_indexable": true, "report_reasons": null, "author": "Plainzwalker", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18x76v2/anyone_happen_to_have_archive_of_racktools_35/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18x76v2/anyone_happen_to_have_archive_of_racktools_35/", "subreddit_subscribers": 722981, "created_utc": 1704246805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Initially I just wanted to print pdfs, but noticed that the formatting goes way off / aka not preserved.\nSoftware like httrack are hard to use and give me a bunch of files, instead of a single file which is easier for me to keep. \n\nWhat can I do?", "author_fullname": "t2_addo5jzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create an offline interactive website archive in a single file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x4lva", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704239970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Initially I just wanted to print pdfs, but noticed that the formatting goes way off / aka not preserved.\nSoftware like httrack are hard to use and give me a bunch of files, instead of a single file which is easier for me to keep. &lt;/p&gt;\n\n&lt;p&gt;What can I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18x4lva", "is_robot_indexable": true, "report_reasons": null, "author": "milkygirl21", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18x4lva/how_to_create_an_offline_interactive_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18x4lva/how_to_create_an_offline_interactive_website/", "subreddit_subscribers": 722981, "created_utc": 1704239970.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}