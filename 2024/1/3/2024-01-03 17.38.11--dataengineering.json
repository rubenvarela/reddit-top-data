{"kind": "Listing", "data": {"after": "t3_18xmqus", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I posted this on /rust and I thought /dataengineering might find it interesting! \n\nI saw this [Blog Post](https://www.morling.dev/blog/one-billion-row-challenge/) on a Billion Row challenge for Java so naturally I tried implementing a solution in Rust using mainly polars.[Code/Gist here](https://gist.github.com/Butch78/702944427d78da6727a277e1f54d65c8)\n\nRunning the code on my laptop, which is equipped with an i7-1185G7 @ 3.00GHz and 32GB of RAM, but it is limited to 16GB of RAM because I developed in a Dev Container.  Using Polars I was able to get a solution that only takes around 39 seconds.\n\n\n|Implementation|Time|Code/Gist Link|\n|:-|:-|:-|\n|Rust + Polars|39s|[https://gist.github.com/Butch78/702944427d78da6727a277e1f54d65c8](https://gist.github.com/Butch78/702944427d78da6727a277e1f54d65c8)|\n|Rust STD Libray|19s|[Coriolinus Solution](https://github.com/coriolinus/1brc)|\n|Python + Polars|61.41 sec|[https://github.com/Butch78/1BillionRowChallenge/blob/main/python\\_1brc/main.py](https://github.com/Butch78/1BillionRowChallenge/blob/main/python_1brc/main.py)|\n|Java [royvanrijn](https://github.com/gunnarmorling/1brc/blob/main/calculate_average_royvanrijn.sh)'s Solution | 23.366sec on the (8 core, 32 GB RAM) |[https://github.com/gunnarmorling/1brc/blob/main/calculate\\_average\\_royvanrijn.sh](https://github.com/gunnarmorling/1brc/blob/main/calculate_average_royvanrijn.sh)|\n\nThanks to @[coriolinus](https://www.reddit.com/user/coriolinus/) and his code, I was able to get a better implementation with the Rust STD library implementation.  Also thanks to @[ritchie46](https://www.reddit.com/user/ritchie46/) for the Polars recommendations and the great library!", "author_fullname": "t2_98aju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing a One Billion Row Challenge in with Rust and Python with Polars", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x2214", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704244329.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704233622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I posted this on /rust and I thought /dataengineering might find it interesting! &lt;/p&gt;\n\n&lt;p&gt;I saw this &lt;a href=\"https://www.morling.dev/blog/one-billion-row-challenge/\"&gt;Blog Post&lt;/a&gt; on a Billion Row challenge for Java so naturally I tried implementing a solution in Rust using mainly polars.&lt;a href=\"https://gist.github.com/Butch78/702944427d78da6727a277e1f54d65c8\"&gt;Code/Gist here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Running the code on my laptop, which is equipped with an i7-1185G7 @ 3.00GHz and 32GB of RAM, but it is limited to 16GB of RAM because I developed in a Dev Container.  Using Polars I was able to get a solution that only takes around 39 seconds.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Implementation&lt;/th&gt;\n&lt;th align=\"left\"&gt;Time&lt;/th&gt;\n&lt;th align=\"left\"&gt;Code/Gist Link&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Rust + Polars&lt;/td&gt;\n&lt;td align=\"left\"&gt;39s&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://gist.github.com/Butch78/702944427d78da6727a277e1f54d65c8\"&gt;https://gist.github.com/Butch78/702944427d78da6727a277e1f54d65c8&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Rust STD Libray&lt;/td&gt;\n&lt;td align=\"left\"&gt;19s&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://github.com/coriolinus/1brc\"&gt;Coriolinus Solution&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Python + Polars&lt;/td&gt;\n&lt;td align=\"left\"&gt;61.41 sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://github.com/Butch78/1BillionRowChallenge/blob/main/python_1brc/main.py\"&gt;https://github.com/Butch78/1BillionRowChallenge/blob/main/python_1brc/main.py&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Java &lt;a href=\"https://github.com/gunnarmorling/1brc/blob/main/calculate_average_royvanrijn.sh\"&gt;royvanrijn&lt;/a&gt;&amp;#39;s Solution&lt;/td&gt;\n&lt;td align=\"left\"&gt;23.366sec on the (8 core, 32 GB RAM)&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://github.com/gunnarmorling/1brc/blob/main/calculate_average_royvanrijn.sh\"&gt;https://github.com/gunnarmorling/1brc/blob/main/calculate_average_royvanrijn.sh&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Thanks to @&lt;a href=\"https://www.reddit.com/user/coriolinus/\"&gt;coriolinus&lt;/a&gt; and his code, I was able to get a better implementation with the Rust STD library implementation.  Also thanks to @&lt;a href=\"https://www.reddit.com/user/ritchie46/\"&gt;ritchie46&lt;/a&gt; for the Polars recommendations and the great library!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18x2214", "is_robot_indexable": true, "report_reasons": null, "author": "matt78whoop", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18x2214/optimizing_a_one_billion_row_challenge_in_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18x2214/optimizing_a_one_billion_row_challenge_in_with/", "subreddit_subscribers": 150260, "created_utc": 1704233622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dashboards, views, tables, pipelines, entire data marts. Why does 90% of the work I do never get used?   \n\nI used to be one of the best BA's in my entire company so I am very good at requirements gathering and understanding what the business is trying to accomplish. Most of the work that I get comes from the CEO/VP level (global corporation not startup so real CEO and real VP 's) so a lot of people seem like they are very invested in solving these problems and my work always gets rave reviews.....but once things go into prod they basically never get touched.  \n\nSix months ago I just.... stopped doing QA.. I have been relying on the \"scream test\", I mark tickets resolved and immediately move to prod and only do QA if someone screams that something is wrong. I have yet to hear back on anything.", "author_fullname": "t2_o1c691xd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why does nothing ever get used?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xj97r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704288050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dashboards, views, tables, pipelines, entire data marts. Why does 90% of the work I do never get used?   &lt;/p&gt;\n\n&lt;p&gt;I used to be one of the best BA&amp;#39;s in my entire company so I am very good at requirements gathering and understanding what the business is trying to accomplish. Most of the work that I get comes from the CEO/VP level (global corporation not startup so real CEO and real VP &amp;#39;s) so a lot of people seem like they are very invested in solving these problems and my work always gets rave reviews.....but once things go into prod they basically never get touched.  &lt;/p&gt;\n\n&lt;p&gt;Six months ago I just.... stopped doing QA.. I have been relying on the &amp;quot;scream test&amp;quot;, I mark tickets resolved and immediately move to prod and only do QA if someone screams that something is wrong. I have yet to hear back on anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18xj97r", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive-One6226", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xj97r/why_does_nothing_ever_get_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xj97r/why_does_nothing_ever_get_used/", "subreddit_subscribers": 150260, "created_utc": 1704288050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, here's an example job requirements I just found (shortened it), which has the same feel as the last 50 job adverts I've seen recently.\n\n\"Proficiency in Bash, Python, and SQL. Experience with Linux and Docker. Knowledge in Databases, Data Modeling, ETL, dbt, and Snowflake. Expertise in Spark, Databricks, EMR, Streaming, and Kafka. Familiarity with AWS services such as EC2, S3, Lambda, EMR, Glue, and Athena.\"\n\nSo.. I'm about to graduate from a Master's in Data Science, where I took mostly Data Engineering stuff for my optional units. Literally all I have had is some exposure to Bash, Python and SQL, and data types. The only reason why I know Linux and Docker is because I started writing something on a Raspberry Pi to open my garage door when I was 16, with a few other small projects.\n\nYes the master's teaches lots of stats, modelling concepts, ML, DL, and some Data Warehousing etc.. but not a single job, not even entry position that I have found, require skills I learned in my Master's. Every student in my class is now great at R but useless in Python, literally never see job adverts with R on it. Feels like the Master's was a Bachelor's or an \"Intro to Data Literacy\" course.\n\nWhere do you even learn these skills? I doubt that you guys just bullshit-apply to jobs and watch YouTube before the interview.. Should I take a full year OFF after my Master's to just learn everything about Azure, Google Cloud, Microsoft Analytics, bloody software development practices even and empty all the Udemy/Coursera courses out there? Then maybe I can get a job?\n\nGee. I feel like uni has absolutely not made me job ready in any way.", "author_fullname": "t2_3wfadcr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "None of what I learned is a job requirement. I am essentially skill-less.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xb4ug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704258392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, here&amp;#39;s an example job requirements I just found (shortened it), which has the same feel as the last 50 job adverts I&amp;#39;ve seen recently.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Proficiency in Bash, Python, and SQL. Experience with Linux and Docker. Knowledge in Databases, Data Modeling, ETL, dbt, and Snowflake. Expertise in Spark, Databricks, EMR, Streaming, and Kafka. Familiarity with AWS services such as EC2, S3, Lambda, EMR, Glue, and Athena.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So.. I&amp;#39;m about to graduate from a Master&amp;#39;s in Data Science, where I took mostly Data Engineering stuff for my optional units. Literally all I have had is some exposure to Bash, Python and SQL, and data types. The only reason why I know Linux and Docker is because I started writing something on a Raspberry Pi to open my garage door when I was 16, with a few other small projects.&lt;/p&gt;\n\n&lt;p&gt;Yes the master&amp;#39;s teaches lots of stats, modelling concepts, ML, DL, and some Data Warehousing etc.. but not a single job, not even entry position that I have found, require skills I learned in my Master&amp;#39;s. Every student in my class is now great at R but useless in Python, literally never see job adverts with R on it. Feels like the Master&amp;#39;s was a Bachelor&amp;#39;s or an &amp;quot;Intro to Data Literacy&amp;quot; course.&lt;/p&gt;\n\n&lt;p&gt;Where do you even learn these skills? I doubt that you guys just bullshit-apply to jobs and watch YouTube before the interview.. Should I take a full year OFF after my Master&amp;#39;s to just learn everything about Azure, Google Cloud, Microsoft Analytics, bloody software development practices even and empty all the Udemy/Coursera courses out there? Then maybe I can get a job?&lt;/p&gt;\n\n&lt;p&gt;Gee. I feel like uni has absolutely not made me job ready in any way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18xb4ug", "is_robot_indexable": true, "report_reasons": null, "author": "Zomdou", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xb4ug/none_of_what_i_learned_is_a_job_requirement_i_am/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xb4ug/none_of_what_i_learned_is_a_job_requirement_i_am/", "subreddit_subscribers": 150260, "created_utc": 1704258392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We often discuss about ETL, rarely about its reverse counterpart (i.e getting data from your warehouse into various destinations). What is your tool of choice for the job, if you do rely on this mechanism?", "author_fullname": "t2_3wbyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your reverse ETL tool of choice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x6y0i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704246120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We often discuss about ETL, rarely about its reverse counterpart (i.e getting data from your warehouse into various destinations). What is your tool of choice for the job, if you do rely on this mechanism?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18x6y0i", "is_robot_indexable": true, "report_reasons": null, "author": "axlee", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18x6y0i/what_is_your_reverse_etl_tool_of_choice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18x6y0i/what_is_your_reverse_etl_tool_of_choice/", "subreddit_subscribers": 150260, "created_utc": 1704246120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I`m used to work with SP whenever I am etl`ing from database to database. I only use python when I need to work with csv, an pai, Json.\n\nBut I think I rear about using python and learning python (for begginers mainly) too much.\n\nDoes It makes Sense to work with python instead of PS on a database to database ETL? We are talking about stg to dw workloads for example. Is ir fazer? Secure? Or anything that advocates pro python?", "author_fullname": "t2_8lo1pjes", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python over Stored Procedure in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x3ygn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704238335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&lt;code&gt;m used to work with SP whenever I am etl&lt;/code&gt;ing from database to database. I only use python when I need to work with csv, an pai, Json.&lt;/p&gt;\n\n&lt;p&gt;But I think I rear about using python and learning python (for begginers mainly) too much.&lt;/p&gt;\n\n&lt;p&gt;Does It makes Sense to work with python instead of PS on a database to database ETL? We are talking about stg to dw workloads for example. Is ir fazer? Secure? Or anything that advocates pro python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18x3ygn", "is_robot_indexable": true, "report_reasons": null, "author": "DesperateBus362", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18x3ygn/python_over_stored_procedure_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18x3ygn/python_over_stored_procedure_in_de/", "subreddit_subscribers": 150260, "created_utc": 1704238335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "u/gunnarmorling [launched a fun challenge](https://www.morling.dev/blog/one-billion-row-challenge/) this week: how fast can you aggregate and summarise a billion rows of data?\n\nI'm not a Java coder (which is what the challenge is set in) but thought it'd be fun to do it in SQL with DuckDB nonetheless.\n\nLoading the CSV in is simple enough:\n\n    CREATE OR REPLACE TABLE measurements AS\n            SELECT * FROM READ_CSV('measurements.txt', header=false, columns= {'station_name':'VARCHAR','measurement':'double'}, delim=';') LIMIT 2048;\n\nas are the calculations:\n\n    SELECT station_name, \n               MIN(measurement),\n               AVG(measurement),\n               MAX(measurement)\n        FROM measurements \n        GROUP BY station_name\n\nThe funky bit comes in trying to reproduce the specified output format:\n\n    SELECT '{' || \n                ARRAY_TO_STRING(LIST_SORT(LIST(station_name || '=' || CONCAT_WS('/',min_measurement, mean_measurement, max_measurement))),', ') ||\n                '}' AS \"1BRC\"\n        FROM src;\n\nThe final script looks like this, and takes about 26 seconds to run:\n\n    \u276f /usr/bin/time -p duckdb -no-stdin -init 1brc.opt2.sql\n    -- Loading resources from 1brc.opt2.sql\n    \n    WITH src AS (SELECT station_name,\n                        MIN(measurement) AS min_measurement,\n                        CAST(AVG(measurement) AS DECIMAL(8,1)) AS mean_measurement,\n                        MAX(measurement) AS max_measurement\n                FROM READ_CSV('measurements.txt', header=false, columns= {'station_name':'VARCHAR','measurement':'double'}, delim=';')\n                GROUP BY station_name)\n        SELECT '{' ||\n                ARRAY_TO_STRING(LIST_SORT(LIST(station_name || '=' || CONCAT_WS('/',min_measurement, mean_measurement, max_measurement))),', ') ||\n                '}' AS \"1BRC\"\n        FROM src;\n    100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f\n    1BRC{Abha=-33.0/18.0/69.2, Abidjan=-24.4/26.0/75.4, Ab\u00e9ch\u00e9=-21.1/29.4/77.1, Accra=-25.1/26.4/79.0, [\u2026]Zanzibar City=-23.9/26.0/77.2, Z\u00fcrich=-39.0/9.3/56.0, \u00dcr\u00fcmqi=-39.6/7.4/58.1, \u0130zmir=-32.8/17.9/67.9}Run Time (s): real 25.539 user 203.968621 sys 2.572107\n    \n    .quit\n    real 25.58\n    user 203.98\n    sys 2.57\n\n**\ud83d\udc49 Full writeup:** [**1\ufe0f\u20e3\ud83d\udc1d\ud83c\udfce\ufe0f\ud83e\udd86 (1BRC in SQL with DuckDB)**](https://rmoff.net/2024/01/03/1%EF%B8%8F%E2%83%A3%EF%B8%8F-1brc-in-sql-with-duckdb/)", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One Billion Row Challenge\u2014using SQL and DuckDB 1\ufe0f\u20e3\ud83d\udc1d\ud83c\udfce\ufe0f\ud83e\udd86", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xldbk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704294064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"/u/gunnarmorling\"&gt;u/gunnarmorling&lt;/a&gt; &lt;a href=\"https://www.morling.dev/blog/one-billion-row-challenge/\"&gt;launched a fun challenge&lt;/a&gt; this week: how fast can you aggregate and summarise a billion rows of data?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not a Java coder (which is what the challenge is set in) but thought it&amp;#39;d be fun to do it in SQL with DuckDB nonetheless.&lt;/p&gt;\n\n&lt;p&gt;Loading the CSV in is simple enough:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE OR REPLACE TABLE measurements AS\n        SELECT * FROM READ_CSV(&amp;#39;measurements.txt&amp;#39;, header=false, columns= {&amp;#39;station_name&amp;#39;:&amp;#39;VARCHAR&amp;#39;,&amp;#39;measurement&amp;#39;:&amp;#39;double&amp;#39;}, delim=&amp;#39;;&amp;#39;) LIMIT 2048;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;as are the calculations:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT station_name, \n           MIN(measurement),\n           AVG(measurement),\n           MAX(measurement)\n    FROM measurements \n    GROUP BY station_name\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The funky bit comes in trying to reproduce the specified output format:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT &amp;#39;{&amp;#39; || \n            ARRAY_TO_STRING(LIST_SORT(LIST(station_name || &amp;#39;=&amp;#39; || CONCAT_WS(&amp;#39;/&amp;#39;,min_measurement, mean_measurement, max_measurement))),&amp;#39;, &amp;#39;) ||\n            &amp;#39;}&amp;#39; AS &amp;quot;1BRC&amp;quot;\n    FROM src;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The final script looks like this, and takes about 26 seconds to run:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u276f /usr/bin/time -p duckdb -no-stdin -init 1brc.opt2.sql\n-- Loading resources from 1brc.opt2.sql\n\nWITH src AS (SELECT station_name,\n                    MIN(measurement) AS min_measurement,\n                    CAST(AVG(measurement) AS DECIMAL(8,1)) AS mean_measurement,\n                    MAX(measurement) AS max_measurement\n            FROM READ_CSV(&amp;#39;measurements.txt&amp;#39;, header=false, columns= {&amp;#39;station_name&amp;#39;:&amp;#39;VARCHAR&amp;#39;,&amp;#39;measurement&amp;#39;:&amp;#39;double&amp;#39;}, delim=&amp;#39;;&amp;#39;)\n            GROUP BY station_name)\n    SELECT &amp;#39;{&amp;#39; ||\n            ARRAY_TO_STRING(LIST_SORT(LIST(station_name || &amp;#39;=&amp;#39; || CONCAT_WS(&amp;#39;/&amp;#39;,min_measurement, mean_measurement, max_measurement))),&amp;#39;, &amp;#39;) ||\n            &amp;#39;}&amp;#39; AS &amp;quot;1BRC&amp;quot;\n    FROM src;\n100% \u2595\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f\n1BRC{Abha=-33.0/18.0/69.2, Abidjan=-24.4/26.0/75.4, Ab\u00e9ch\u00e9=-21.1/29.4/77.1, Accra=-25.1/26.4/79.0, [\u2026]Zanzibar City=-23.9/26.0/77.2, Z\u00fcrich=-39.0/9.3/56.0, \u00dcr\u00fcmqi=-39.6/7.4/58.1, \u0130zmir=-32.8/17.9/67.9}Run Time (s): real 25.539 user 203.968621 sys 2.572107\n\n.quit\nreal 25.58\nuser 203.98\nsys 2.57\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udc49 Full writeup:&lt;/strong&gt; &lt;a href=\"https://rmoff.net/2024/01/03/1%EF%B8%8F%E2%83%A3%EF%B8%8F-1brc-in-sql-with-duckdb/\"&gt;&lt;strong&gt;1\ufe0f\u20e3\ud83d\udc1d\ud83c\udfce\ufe0f\ud83e\udd86 (1BRC in SQL with DuckDB)&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18xldbk", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xldbk/one_billion_row_challengeusing_sql_and_duckdb_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xldbk/one_billion_row_challengeusing_sql_and_duckdb_1/", "subreddit_subscribers": 150260, "created_utc": 1704294064.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jayt2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fastest Way to Read Excel in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 108, "top_awarded_type": null, "hide_score": false, "name": "t3_18xiu4l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8cMcPCXb08vMLYWq7uJMHWwdunpUaTJeef8XeBBPZWo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704286755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hakibenita.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://hakibenita.com/fast-excel-python", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jo5Vlc6pD3jMr_Xsd_mbM-Z3lkixwcIFaKHnHff-JSw.jpg?auto=webp&amp;s=5e9cbf64a9c1de5b880abad10a0c8bf86005df0c", "width": 515, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/jo5Vlc6pD3jMr_Xsd_mbM-Z3lkixwcIFaKHnHff-JSw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db947785956ab738a898a135b5b851c3b72aa735", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/jo5Vlc6pD3jMr_Xsd_mbM-Z3lkixwcIFaKHnHff-JSw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f89fc2b250aa711a063abfd0f4280774cc9765c8", "width": 216, "height": 167}, {"url": "https://external-preview.redd.it/jo5Vlc6pD3jMr_Xsd_mbM-Z3lkixwcIFaKHnHff-JSw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a515eadbaa4eb634f51d3b992e10cbde7c510058", "width": 320, "height": 248}], "variants": {}, "id": "pJyQaK84V_TZQ12VFWSnepvOTiE1dmH9Jz8B6l7kRbI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18xiu4l", "is_robot_indexable": true, "report_reasons": null, "author": "be_haki", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xiu4l/fastest_way_to_read_excel_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://hakibenita.com/fast-excel-python", "subreddit_subscribers": 150260, "created_utc": 1704286755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a table of aggregated data in Redshift which has +7 billion rows. I can\u2019t aggregate it any further. \n\nThey want me to run it through some python time series library and then through a data science model (which the data scientist will create) but pandas can only handle 5GB of data from my understanding. \n\nWhat are my options? The company is on a tight budget so Spark is not something they\u2019re willing to pay for.", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to work with Billions of rows of Time Series Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x908p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704251928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a table of aggregated data in Redshift which has +7 billion rows. I can\u2019t aggregate it any further. &lt;/p&gt;\n\n&lt;p&gt;They want me to run it through some python time series library and then through a data science model (which the data scientist will create) but pandas can only handle 5GB of data from my understanding. &lt;/p&gt;\n\n&lt;p&gt;What are my options? The company is on a tight budget so Spark is not something they\u2019re willing to pay for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18x908p", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18x908p/how_to_work_with_billions_of_rows_of_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18x908p/how_to_work_with_billions_of_rows_of_time_series/", "subreddit_subscribers": 150260, "created_utc": 1704251928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I'm working in a product business, and we have about 200 members in our customer community. Most of them are Data Engineers. The main reason for having this community is to have a place for questions, ideas, and feedback about the product. Currently, I'm not satisfied with how active our community is.\n\nSo, I'm asking, what kind of things should I publish/create/do to activate our community?   \nHave you ended up in some good communities that I can benchmark? ", "author_fullname": "t2_lm2q4av4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to maintain an active Data Engineer Community?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xblnf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704259898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m working in a product business, and we have about 200 members in our customer community. Most of them are Data Engineers. The main reason for having this community is to have a place for questions, ideas, and feedback about the product. Currently, I&amp;#39;m not satisfied with how active our community is.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m asking, what kind of things should I publish/create/do to activate our community?&lt;br/&gt;\nHave you ended up in some good communities that I can benchmark? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18xblnf", "is_robot_indexable": true, "report_reasons": null, "author": "Nikke47", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xblnf/how_to_maintain_an_active_data_engineer_community/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xblnf/how_to_maintain_an_active_data_engineer_community/", "subreddit_subscribers": 150260, "created_utc": 1704259898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some of the high level meeting discussed these buzz words.\n\nSpark\nAzure\nIceberg\nStarrocks\n\nIn understand infrastructure is Azure and computational is done by Spark.\n\nWhat does StarRocks and Iceberg do in this setup. Can some one please explain how all these concepts fit in architecture or pipeline", "author_fullname": "t2_m6gnxiuj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to DE concepts. My company analytics team was working on setting up DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18wyvdt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704226049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some of the high level meeting discussed these buzz words.&lt;/p&gt;\n\n&lt;p&gt;Spark\nAzure\nIceberg\nStarrocks&lt;/p&gt;\n\n&lt;p&gt;In understand infrastructure is Azure and computational is done by Spark.&lt;/p&gt;\n\n&lt;p&gt;What does StarRocks and Iceberg do in this setup. Can some one please explain how all these concepts fit in architecture or pipeline&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18wyvdt", "is_robot_indexable": true, "report_reasons": null, "author": "rajekum512", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18wyvdt/new_to_de_concepts_my_company_analytics_team_was/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18wyvdt/new_to_de_concepts_my_company_analytics_team_was/", "subreddit_subscribers": 150260, "created_utc": 1704226049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently working as a data engineer. At my current company the projects are mostly Ops type so there isn't much to learn. I am trying to switch from a year now but cant find any company in my country sometimes because there aren't much opportunities and sometimes because my knowledge and skills are not up to par and I fail the interviews.\n\nNow I want to dedicate a year and make myself at least a better data engineer so that after a year I can call myself a data engineer. My experience currently is 2-3 years. So to make myself justify that experience what skills, projects, topics, tools should I focus on. \n\nPlease help me. ", "author_fullname": "t2_r509bej6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn on my own along with a job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18xmcm7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704296632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working as a data engineer. At my current company the projects are mostly Ops type so there isn&amp;#39;t much to learn. I am trying to switch from a year now but cant find any company in my country sometimes because there aren&amp;#39;t much opportunities and sometimes because my knowledge and skills are not up to par and I fail the interviews.&lt;/p&gt;\n\n&lt;p&gt;Now I want to dedicate a year and make myself at least a better data engineer so that after a year I can call myself a data engineer. My experience currently is 2-3 years. So to make myself justify that experience what skills, projects, topics, tools should I focus on. &lt;/p&gt;\n\n&lt;p&gt;Please help me. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18xmcm7", "is_robot_indexable": true, "report_reasons": null, "author": "mediocrX", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xmcm7/how_to_learn_on_my_own_along_with_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xmcm7/how_to_learn_on_my_own_along_with_a_job/", "subreddit_subscribers": 150260, "created_utc": 1704296632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, a Fractional Head of Growth here.  \nHas anyone implemented **Customer Level Unit economics**? (B2B or B2C)\n\nBasically have an event-driven data architecture that allows you to assign cost or revenue to every action a customer might take. The goal is to identify the most profitable customers and the actions that drive profitability.\n\nIt helps answer questions like:\n\n1. Bottom 10% of loss-making customers\n2. Profitability of customers in 20s vs 30s vs 40s\n3. Profitability of customers who signed up through Google vs Meta\n\nIf yes, how? Is there any resource I can refer to? I am looking to implement this at 2 companies (B2B and B2C)\n\nThanks!", "author_fullname": "t2_nvnticro", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Customer Level Unit economics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xemop", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704270891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, a Fractional Head of Growth here.&lt;br/&gt;\nHas anyone implemented &lt;strong&gt;Customer Level Unit economics&lt;/strong&gt;? (B2B or B2C)&lt;/p&gt;\n\n&lt;p&gt;Basically have an event-driven data architecture that allows you to assign cost or revenue to every action a customer might take. The goal is to identify the most profitable customers and the actions that drive profitability.&lt;/p&gt;\n\n&lt;p&gt;It helps answer questions like:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Bottom 10% of loss-making customers&lt;/li&gt;\n&lt;li&gt;Profitability of customers in 20s vs 30s vs 40s&lt;/li&gt;\n&lt;li&gt;Profitability of customers who signed up through Google vs Meta&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If yes, how? Is there any resource I can refer to? I am looking to implement this at 2 companies (B2B and B2C)&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18xemop", "is_robot_indexable": true, "report_reasons": null, "author": "Scary-Swing2852", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xemop/customer_level_unit_economics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xemop/customer_level_unit_economics/", "subreddit_subscribers": 150260, "created_utc": 1704270891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm currently brainstorming ideas for my MSc Data Science/Comp Eng research project and I'm leaning towards a topic in Data Engineering. I'm particularly interested in areas involving pipelines, ETL, efficiency, cloud computing, and the use of Python, Spark, and SQL.\n\nHas anyone come across any recent research or projects in these areas that could inspire a solid project idea? I'm looking for something technically challenging and innovative.\n\nAppreciate any suggestions or pointers to recent papers, projects, or trends in this field!\n\nThanks!", "author_fullname": "t2_ukaxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Suggestions for a MSc Research Project in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18wxzco", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704223945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently brainstorming ideas for my MSc Data Science/Comp Eng research project and I&amp;#39;m leaning towards a topic in Data Engineering. I&amp;#39;m particularly interested in areas involving pipelines, ETL, efficiency, cloud computing, and the use of Python, Spark, and SQL.&lt;/p&gt;\n\n&lt;p&gt;Has anyone come across any recent research or projects in these areas that could inspire a solid project idea? I&amp;#39;m looking for something technically challenging and innovative.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any suggestions or pointers to recent papers, projects, or trends in this field!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18wxzco", "is_robot_indexable": true, "report_reasons": null, "author": "dildan101", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18wxzco/need_suggestions_for_a_msc_research_project_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18wxzco/need_suggestions_for_a_msc_research_project_in/", "subreddit_subscribers": 150260, "created_utc": 1704223945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my case it always happens to be \"scrum bi/weekly\" but I never felt it as perfect match due to continuous fire fighting, last minute unpredictable decision changes etc. However I never had the chance to test alternatives. What about you?", "author_fullname": "t2_utk7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which management framework (scrum, lean, kanban, etc) does your company/team use for Data Engineering and more generally which framework do you think is the best for Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xlejx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704294146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my case it always happens to be &amp;quot;scrum bi/weekly&amp;quot; but I never felt it as perfect match due to continuous fire fighting, last minute unpredictable decision changes etc. However I never had the chance to test alternatives. What about you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18xlejx", "is_robot_indexable": true, "report_reasons": null, "author": "df016", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xlejx/which_management_framework_scrum_lean_kanban_etc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xlejx/which_management_framework_scrum_lean_kanban_etc/", "subreddit_subscribers": 150260, "created_utc": 1704294146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Over the past few months, I have written about a number of different technologies ([Ray Data](https://blog.min.io/distributed-data-processing-with-ray-data-and-minio/), [Ray Train](https://blog.min.io/distributed-training-with-ray-train-and-minio/), and [MLflow](https://blog.min.io/mlflow-tracking-and-minio/)). I thought it would make sense to pull them all together and deliver an easy-to-understand recipe for distributed data preprocessing and distributed training using a production-ready MLOPs tool for tracking and model serving. This post integrates the code I presented in my [Ray Train post](https://blog.min.io/distributed-training-with-ray-train-and-minio/) that distributes training across a cluster of workers with a deployment of MLFlow that uses MinIO under the hood for artifact storage and model checkpoints. While my code trains a model on the MNIST dataset, the code is mostly boilerplate - replace the MNIST model with your model and replace the MNIST data access and preprocessing with your data access and preprocessing, and you are ready to start training your model. A fully functioning sample containing all the code presented in this post can be found [here](https://github.com/minio/blog-assets/tree/main/ray_mlflow?ref=blog.min.io).\n\n[https://blog.min.io/distributed-training-and-experiment-tracking-with-ray-train-mlflow-and-minio/?utm\\_source=reddit&amp;utm\\_medium=organic-social+&amp;utm\\_campaign=distributed\\_training\\_experiment\\_tracking\\_ray\\_train\\_mlflow+](https://blog.min.io/distributed-training-and-experiment-tracking-with-ray-train-mlflow-and-minio/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=distributed_training_experiment_tracking_ray_train_mlflow+)", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributed Training and Experiment Tracking with Ray Train, MLflow, and MinIO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x0tav", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704230704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the past few months, I have written about a number of different technologies (&lt;a href=\"https://blog.min.io/distributed-data-processing-with-ray-data-and-minio/\"&gt;Ray Data&lt;/a&gt;, &lt;a href=\"https://blog.min.io/distributed-training-with-ray-train-and-minio/\"&gt;Ray Train&lt;/a&gt;, and &lt;a href=\"https://blog.min.io/mlflow-tracking-and-minio/\"&gt;MLflow&lt;/a&gt;). I thought it would make sense to pull them all together and deliver an easy-to-understand recipe for distributed data preprocessing and distributed training using a production-ready MLOPs tool for tracking and model serving. This post integrates the code I presented in my &lt;a href=\"https://blog.min.io/distributed-training-with-ray-train-and-minio/\"&gt;Ray Train post&lt;/a&gt; that distributes training across a cluster of workers with a deployment of MLFlow that uses MinIO under the hood for artifact storage and model checkpoints. While my code trains a model on the MNIST dataset, the code is mostly boilerplate - replace the MNIST model with your model and replace the MNIST data access and preprocessing with your data access and preprocessing, and you are ready to start training your model. A fully functioning sample containing all the code presented in this post can be found &lt;a href=\"https://github.com/minio/blog-assets/tree/main/ray_mlflow?ref=blog.min.io\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.min.io/distributed-training-and-experiment-tracking-with-ray-train-mlflow-and-minio/?utm_source=reddit&amp;amp;utm_medium=organic-social+&amp;amp;utm_campaign=distributed_training_experiment_tracking_ray_train_mlflow+\"&gt;https://blog.min.io/distributed-training-and-experiment-tracking-with-ray-train-mlflow-and-minio/?utm_source=reddit&amp;amp;utm_medium=organic-social+&amp;amp;utm_campaign=distributed_training_experiment_tracking_ray_train_mlflow+&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?auto=webp&amp;s=60a9a5bb13ad52dc6f983d22a24a53b3b835a119", "width": 1200, "height": 359}, "resolutions": [{"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db2aa38b11de95fa42f9dbf716d73c3b2a64e4f3", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c18b4e8bc4062930b8490b5721bf20e5d91b96a", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e065467bf6807e1f7014eb05a7e8aef79c5b4e88", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=74d1b5b114a455946e7c372fa0cc71907ebdd6dd", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d0ea6ae4d3f00a6c97c690b38471318183ee2c8", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/elFSPAdTCUARL5snaD1gQznx3b133pDeGEBCTuTl2Po.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=011a2c8ca8070e4782e8cf151170e64f2db7fd85", "width": 1080, "height": 323}], "variants": {}, "id": "ycJVbgf3bDDq06hpn_WuGtC2gZGgwo5DkVBTrJOe5j8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18x0tav", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18x0tav/distributed_training_and_experiment_tracking_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18x0tav/distributed_training_and_experiment_tracking_with/", "subreddit_subscribers": 150260, "created_utc": 1704230704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently came across a design decision while implementing EDA using celery canvas workflows to distribute celery tasks and workers across multiple containers or keep them at one place. Need y'all to share an opinion on my piece and appreciate any tips or help on this.", "author_fullname": "t2_5fi8z4gf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Container management for EDA workflow on kubernetes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 57, "top_awarded_type": null, "hide_score": true, "name": "t3_18xnwp2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1kDN64llQdqAOCGY3MkMi26T8im2VCRWJtASASEKb0g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704300835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently came across a design decision while implementing EDA using celery canvas workflows to distribute celery tasks and workers across multiple containers or keep them at one place. Need y&amp;#39;all to share an opinion on my piece and appreciate any tips or help on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@rajani.param1/ce-238793394b0d", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LGhMLQs_y8OLcGbqy5Kd8ddZCUmmYTKEI3nno7anEJ8.jpg?auto=webp&amp;s=89aee81a30a73490b614d4a0a64fef4a6f3b495e", "width": 1133, "height": 464}, "resolutions": [{"url": "https://external-preview.redd.it/LGhMLQs_y8OLcGbqy5Kd8ddZCUmmYTKEI3nno7anEJ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e7940bbd6ca11719bc5b4bb0d24288c7396bbd9c", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/LGhMLQs_y8OLcGbqy5Kd8ddZCUmmYTKEI3nno7anEJ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a34e42a26eb73aae91420b0902b39059ec58b1cf", "width": 216, "height": 88}, {"url": "https://external-preview.redd.it/LGhMLQs_y8OLcGbqy5Kd8ddZCUmmYTKEI3nno7anEJ8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=11b275425a021b16a541eefad98c6625c208b13b", "width": 320, "height": 131}, {"url": "https://external-preview.redd.it/LGhMLQs_y8OLcGbqy5Kd8ddZCUmmYTKEI3nno7anEJ8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=552510444955fe1f572da2f4a31dff937e31cd28", "width": 640, "height": 262}, {"url": "https://external-preview.redd.it/LGhMLQs_y8OLcGbqy5Kd8ddZCUmmYTKEI3nno7anEJ8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fd5d969554639dff6a89fd0a475e7e672aa523f2", "width": 960, "height": 393}, {"url": "https://external-preview.redd.it/LGhMLQs_y8OLcGbqy5Kd8ddZCUmmYTKEI3nno7anEJ8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0fddd5aa1400cf0b0656b397113582ba8b7e2f2d", "width": 1080, "height": 442}], "variants": {}, "id": "56y15oXXflHMI-5GNnjGmpCuezGqtSFtKpDjSBIPnFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18xnwp2", "is_robot_indexable": true, "report_reasons": null, "author": "Drphysics5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xnwp2/container_management_for_eda_workflow_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@rajani.param1/ce-238793394b0d", "subreddit_subscribers": 150260, "created_utc": 1704300835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I\u2019m thinking of going back to school as my employer will pay for part of it, and I want to do some structured learning. My bachelors degree is non-CS engineering. I\u2019m currently on a DE team (8 months of experience). \nIs an MS in Data Analytics or IT degree useful for data engineers? I\u2019d aim for something like OMSA from Georgia Tech. If the analytics degree has a decent amount of ML, databases, pipeline development on the curriculum, is it useful? \nI\u2019m also considering MS CS programs but I believe those would be harder for me to get into.", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MS in Analytics for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18xng3n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704299419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I\u2019m thinking of going back to school as my employer will pay for part of it, and I want to do some structured learning. My bachelors degree is non-CS engineering. I\u2019m currently on a DE team (8 months of experience). \nIs an MS in Data Analytics or IT degree useful for data engineers? I\u2019d aim for something like OMSA from Georgia Tech. If the analytics degree has a decent amount of ML, databases, pipeline development on the curriculum, is it useful? \nI\u2019m also considering MS CS programs but I believe those would be harder for me to get into.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18xng3n", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xng3n/ms_in_analytics_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xng3n/ms_in_analytics_for_de/", "subreddit_subscribers": 150260, "created_utc": 1704299419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "They are different roles iam aware and i know that data ops are more close of being data engineer but just curious about my question to increase my skills", "author_fullname": "t2_hxue1umo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What projects can demonstrate both of data engineering skills and devops skills ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18xnd6m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704299220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They are different roles iam aware and i know that data ops are more close of being data engineer but just curious about my question to increase my skills&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18xnd6m", "is_robot_indexable": true, "report_reasons": null, "author": "Single-Sound-1865", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xnd6m/what_projects_can_demonstrate_both_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xnd6m/what_projects_can_demonstrate_both_of_data/", "subreddit_subscribers": 150260, "created_utc": 1704299220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have job offer for data engineer at fintech Smbc NYC location base 135k and one more offer from Walmart Dallas location 110k, which one is better regarding the company and location", "author_fullname": "t2_ck2k6nuk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer job offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18xnan6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704299044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have job offer for data engineer at fintech Smbc NYC location base 135k and one more offer from Walmart Dallas location 110k, which one is better regarding the company and location&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18xnan6", "is_robot_indexable": true, "report_reasons": null, "author": "No_Stand_3145", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xnan6/data_engineer_job_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xnan6/data_engineer_job_offer/", "subreddit_subscribers": 150260, "created_utc": 1704299044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How does this sound as a dwh / orchestration setup for an IoT startup with &lt;100 tables and pipelines to manage?\n\nI have a dbt / dagster project in a monorepo, containing all our db models, pipeline code and a Dockerfile. \n\nFor local development, the Dockerfile is used to setup a dev container running dagster daemon + webserver. For staging / production, changes are pulled into staging / production branches and a GitHub action is triggered to run CI tests + build an image which is pushed to Artifact Registry, and then onto a cloud hosted VM (also running dagster daemon + webserver).\n\nI would be using BigQuery as a dwh, and I was thinking each branch of the repo would have its own dataset in BigQuery. I think I could get this to work using environment variables in the dbt config files.\n\nI'm aware that it probably makes more sense to deploy staging / production on kubernetes, but I don't want to overcomplicate things as this is already breaking a lot of new ground for me\n\nIs there anything I've overlooked?", "author_fullname": "t2_i7dbhuu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT + Dagster setup for an IoT startup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18xmwva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704298080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does this sound as a dwh / orchestration setup for an IoT startup with &amp;lt;100 tables and pipelines to manage?&lt;/p&gt;\n\n&lt;p&gt;I have a dbt / dagster project in a monorepo, containing all our db models, pipeline code and a Dockerfile. &lt;/p&gt;\n\n&lt;p&gt;For local development, the Dockerfile is used to setup a dev container running dagster daemon + webserver. For staging / production, changes are pulled into staging / production branches and a GitHub action is triggered to run CI tests + build an image which is pushed to Artifact Registry, and then onto a cloud hosted VM (also running dagster daemon + webserver).&lt;/p&gt;\n\n&lt;p&gt;I would be using BigQuery as a dwh, and I was thinking each branch of the repo would have its own dataset in BigQuery. I think I could get this to work using environment variables in the dbt config files.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that it probably makes more sense to deploy staging / production on kubernetes, but I don&amp;#39;t want to overcomplicate things as this is already breaking a lot of new ground for me&lt;/p&gt;\n\n&lt;p&gt;Is there anything I&amp;#39;ve overlooked?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18xmwva", "is_robot_indexable": true, "report_reasons": null, "author": "hennyblub", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xmwva/dbt_dagster_setup_for_an_iot_startup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xmwva/dbt_dagster_setup_for_an_iot_startup/", "subreddit_subscribers": 150260, "created_utc": 1704298080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a basic question , within Data bricks we have  Create SQL . .  \nMy question considering data bricks being clould portable   \nIf we are creating a SQL warehouse in databricks . is it fully managed . .if not how it will be portable across. . i am missing something .   \nIs it like sql storage is underlying cloud infrastructure. . where exactly sql warehouse is stored and manged is it be databricks or underlying cloud infra ", "author_fullname": "t2_hwqrk3yk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Bricks SQL warehouse where it is stored .", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xhl15", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704282522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a basic question , within Data bricks we have  Create SQL . .&lt;br/&gt;\nMy question considering data bricks being clould portable&lt;br/&gt;\nIf we are creating a SQL warehouse in databricks . is it fully managed . .if not how it will be portable across. . i am missing something .&lt;br/&gt;\nIs it like sql storage is underlying cloud infrastructure. . where exactly sql warehouse is stored and manged is it be databricks or underlying cloud infra &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18xhl15", "is_robot_indexable": true, "report_reasons": null, "author": "Data5kull", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xhl15/data_bricks_sql_warehouse_where_it_is_stored/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xhl15/data_bricks_sql_warehouse_where_it_is_stored/", "subreddit_subscribers": 150260, "created_utc": 1704282522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,   \nI am currently researching low-code tools topic to integrate our company's SaaS solutions with business client systems (ERP, CRM, DW, or data lakes mostly). We are looking for something with capabilities to integrate with the most popular systems (aka SAP or Microsoft software, both cloud and on-premises) with predefined connectors, but also with options to connect to other less popular systems (it can be either API or direct db connection).   \nFor now, I am trying Azure Data Factory for this purpose, but still not sure if it will be suitable for us, do you have any other suggestions?  It might be both cloud or non-cloud tools. Thank you for your answers in advance and hope you have a great day :)", "author_fullname": "t2_hfmqvbux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most suitable low-code data integration tools for SaaS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18xfota", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704275301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;br/&gt;\nI am currently researching low-code tools topic to integrate our company&amp;#39;s SaaS solutions with business client systems (ERP, CRM, DW, or data lakes mostly). We are looking for something with capabilities to integrate with the most popular systems (aka SAP or Microsoft software, both cloud and on-premises) with predefined connectors, but also with options to connect to other less popular systems (it can be either API or direct db connection).&lt;br/&gt;\nFor now, I am trying Azure Data Factory for this purpose, but still not sure if it will be suitable for us, do you have any other suggestions?  It might be both cloud or non-cloud tools. Thank you for your answers in advance and hope you have a great day :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18xfota", "is_robot_indexable": true, "report_reasons": null, "author": "Myhasik", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xfota/most_suitable_lowcode_data_integration_tools_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xfota/most_suitable_lowcode_data_integration_tools_for/", "subreddit_subscribers": 150260, "created_utc": 1704275301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello all, first post here on reddit. Below I\u2019ve outlined a potential data architecture for a general sports betting analytics framework and would like to solicit feedback as well as any potential off the shelf alternatives that could accomplish the same goals. The data architecture needs to primarily support the following:\n\n1. entity definitions. Things like players, teams, games, etc.\n2. entity features. Some quantifiable piece of information about an entity. Usually associated with a given day. I.e. features are often time series for a given entity. Things like player ratings prior to a game, weather impacts on game day, etc. Can be arbitrarily complex - more than simple aggregations.\n3. point-in-timeliness. To support proper backtesting, all entities and metrics should be queryable as they existed at some point in time. \n4. ability to iterate quickly on feature research. Should be able to define a complex feature and run on the entire dataset. Entities \\* features \\* number of days \\* number of revisions could be in the millions. Queries here will often be vertical in nature. E.g. you might ask a question like \u201cgive me these 3 features across all entities on all days for all revisions\u201d.\n5. quick real time feature calculation. Will be used for real time predictions. These queries will often be horizontal in nature e.g. you might ask \u201cgive me these 100 features for these 5 entities on this day\u201d. Can also be vertical if a given feature requires history of itself or others.\n\nGiven the requirements for both 4/5, I\u2019m leaning towards a polyglot data model, utilizing multiple data architectures to support the different query patterns. Off the top of my head, I\u2019m thinking something like postgres for entity management and point-in-timeliness, MongoDB as the feature store for horizontal queries, and some type of columnar store like parquet files on s3 for fast querying of entire feature history.\n\nObvious complications are synchronization and consistency across data stores. My intuition says this could be managed crudely with triggers on the entity tables and/or tracking update timestamps across all 3 stores, but I\u2019m well aware that this could snowball into a fragile and extremely complex system. Happy to provide more details if necessary, but I\u2019m hoping there\u2019s enough here to know that I\u2019m either potentially headed down the right path or completely misguided. I\u2019d also be interested in any off the shelf, open source or relatively cheap solutions that exist to fulfill these requirements, as I haven\u2019t found any that satisfy all of them. While I'm committed to spending a decent amount of $ on this, I'm a solo dev who has a day job, so cost does play a major role. Thanks in advance!", "author_fullname": "t2_h3jdyzqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data architecture for analytics framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18x6piq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704245469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, first post here on reddit. Below I\u2019ve outlined a potential data architecture for a general sports betting analytics framework and would like to solicit feedback as well as any potential off the shelf alternatives that could accomplish the same goals. The data architecture needs to primarily support the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;entity definitions. Things like players, teams, games, etc.&lt;/li&gt;\n&lt;li&gt;entity features. Some quantifiable piece of information about an entity. Usually associated with a given day. I.e. features are often time series for a given entity. Things like player ratings prior to a game, weather impacts on game day, etc. Can be arbitrarily complex - more than simple aggregations.&lt;/li&gt;\n&lt;li&gt;point-in-timeliness. To support proper backtesting, all entities and metrics should be queryable as they existed at some point in time. &lt;/li&gt;\n&lt;li&gt;ability to iterate quickly on feature research. Should be able to define a complex feature and run on the entire dataset. Entities * features * number of days * number of revisions could be in the millions. Queries here will often be vertical in nature. E.g. you might ask a question like \u201cgive me these 3 features across all entities on all days for all revisions\u201d.&lt;/li&gt;\n&lt;li&gt;quick real time feature calculation. Will be used for real time predictions. These queries will often be horizontal in nature e.g. you might ask \u201cgive me these 100 features for these 5 entities on this day\u201d. Can also be vertical if a given feature requires history of itself or others.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Given the requirements for both 4/5, I\u2019m leaning towards a polyglot data model, utilizing multiple data architectures to support the different query patterns. Off the top of my head, I\u2019m thinking something like postgres for entity management and point-in-timeliness, MongoDB as the feature store for horizontal queries, and some type of columnar store like parquet files on s3 for fast querying of entire feature history.&lt;/p&gt;\n\n&lt;p&gt;Obvious complications are synchronization and consistency across data stores. My intuition says this could be managed crudely with triggers on the entity tables and/or tracking update timestamps across all 3 stores, but I\u2019m well aware that this could snowball into a fragile and extremely complex system. Happy to provide more details if necessary, but I\u2019m hoping there\u2019s enough here to know that I\u2019m either potentially headed down the right path or completely misguided. I\u2019d also be interested in any off the shelf, open source or relatively cheap solutions that exist to fulfill these requirements, as I haven\u2019t found any that satisfy all of them. While I&amp;#39;m committed to spending a decent amount of $ on this, I&amp;#39;m a solo dev who has a day job, so cost does play a major role. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18x6piq", "is_robot_indexable": true, "report_reasons": null, "author": "Ashamed-Diamond-4859", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18x6piq/data_architecture_for_analytics_framework/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18x6piq/data_architecture_for_analytics_framework/", "subreddit_subscribers": 150260, "created_utc": 1704245469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a requirement to read mainframe ebcdic files using spark. Has anyone had any luck with this?\n\nUpon research I came across \"cobrix\". Has anyone used this package before? . Unfortunately that's the only one we have come across.\n\nPlease suggest if there are any other options that are avaliable to read these files on spark.", "author_fullname": "t2_6kmo2ecy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EBCIDIC in spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18wxfo5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704223101.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704222635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a requirement to read mainframe ebcdic files using spark. Has anyone had any luck with this?&lt;/p&gt;\n\n&lt;p&gt;Upon research I came across &amp;quot;cobrix&amp;quot;. Has anyone used this package before? . Unfortunately that&amp;#39;s the only one we have come across.&lt;/p&gt;\n\n&lt;p&gt;Please suggest if there are any other options that are avaliable to read these files on spark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18wxfo5", "is_robot_indexable": true, "report_reasons": null, "author": "soujoshi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18wxfo5/ebcidic_in_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18wxfo5/ebcidic_in_spark/", "subreddit_subscribers": 150260, "created_utc": 1704222635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What Udemy courses would you recommend   \nPossible topics:   \n\\- ETL/ELT\n\n\\- Python for data engineering\n\n\\- Designing data warehouses and datamodeling\n\n\\- Use of cloud tech (AWS, Azure)\n\n\\- Optimize data models and structures for maximum - performance and scalability.\n\n\\- integrating new database technologies.\n\n\\- Optimizing query performance and data access for users.  \n\n\nI am currently pursuing a degree in Big Data, but it lacks hands-on projects in data engineering technologies. ", "author_fullname": "t2_3agaai2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good UDEMY courses for data engineering skills ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18xmqus", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704297668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What Udemy courses would you recommend&lt;br/&gt;\nPossible topics:&lt;br/&gt;\n- ETL/ELT&lt;/p&gt;\n\n&lt;p&gt;- Python for data engineering&lt;/p&gt;\n\n&lt;p&gt;- Designing data warehouses and datamodeling&lt;/p&gt;\n\n&lt;p&gt;- Use of cloud tech (AWS, Azure)&lt;/p&gt;\n\n&lt;p&gt;- Optimize data models and structures for maximum - performance and scalability.&lt;/p&gt;\n\n&lt;p&gt;- integrating new database technologies.&lt;/p&gt;\n\n&lt;p&gt;- Optimizing query performance and data access for users.  &lt;/p&gt;\n\n&lt;p&gt;I am currently pursuing a degree in Big Data, but it lacks hands-on projects in data engineering technologies. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18xmqus", "is_robot_indexable": true, "report_reasons": null, "author": "SteffooM", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18xmqus/what_are_some_good_udemy_courses_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18xmqus/what_are_some_good_udemy_courses_for_data/", "subreddit_subscribers": 150260, "created_utc": 1704297668.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}