{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was hired as a consultant and started to work as a Data Engineer on a startup. A lot of work but I really enjoyed working on it. However, they decided to fire a entire team and put me instead as the developer of that project. When I opened the files, it is just a mess. Spaghetti codes, multiple logics that just gets overwritten and no documentation at all. I discovered that the logic didn't work at all and I have been mostly finding issues with the code.\n\nI asked the business analyst to help me understand all the logic and he doesn't know either. There is no proper documentation of the reqs of the project (the original business analyst was fired for this too), they changed the project owner since the original moved to another company and this new guy doesn't know either what to do.\n\nWell, I suggested to spend time to try to understand the project itself but got called off by everyone since they need this done by February. It just happens that I am in a trial period in this job and it also ends in February. They are expecting me to finish this one but honestly I feel lost since there is no one to contact about the full scope of the project, I am working blinding and doing some \"screaming\" qa.\n\nBy the way, the original stack was Python Pandas, DBT, Airflow, AWS, Postgresql and they were planning to move to Snowflake, and now in this project is just plain SQL for MariaDB. The fricking test to enter the company were hard, I studied a lot of these data engineer tools to enter, even Kubernetes, Docker, Terraform and now I am just a SQL developer. Honestly, I don't mind working with SQL but because the incompetence of other people, they switched me over since they are out of people and they are no plans to hire a new team for this. I just hope that I can recover back my original role.", "author_fullname": "t2_gdhxcn2h6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After finally getting my dream job, I was switched to other role against my will.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195tn9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705168405.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705168197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was hired as a consultant and started to work as a Data Engineer on a startup. A lot of work but I really enjoyed working on it. However, they decided to fire a entire team and put me instead as the developer of that project. When I opened the files, it is just a mess. Spaghetti codes, multiple logics that just gets overwritten and no documentation at all. I discovered that the logic didn&amp;#39;t work at all and I have been mostly finding issues with the code.&lt;/p&gt;\n\n&lt;p&gt;I asked the business analyst to help me understand all the logic and he doesn&amp;#39;t know either. There is no proper documentation of the reqs of the project (the original business analyst was fired for this too), they changed the project owner since the original moved to another company and this new guy doesn&amp;#39;t know either what to do.&lt;/p&gt;\n\n&lt;p&gt;Well, I suggested to spend time to try to understand the project itself but got called off by everyone since they need this done by February. It just happens that I am in a trial period in this job and it also ends in February. They are expecting me to finish this one but honestly I feel lost since there is no one to contact about the full scope of the project, I am working blinding and doing some &amp;quot;screaming&amp;quot; qa.&lt;/p&gt;\n\n&lt;p&gt;By the way, the original stack was Python Pandas, DBT, Airflow, AWS, Postgresql and they were planning to move to Snowflake, and now in this project is just plain SQL for MariaDB. The fricking test to enter the company were hard, I studied a lot of these data engineer tools to enter, even Kubernetes, Docker, Terraform and now I am just a SQL developer. Honestly, I don&amp;#39;t mind working with SQL but because the incompetence of other people, they switched me over since they are out of people and they are no plans to hire a new team for this. I just hope that I can recover back my original role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "195tn9u", "is_robot_indexable": true, "report_reasons": null, "author": "DataSenpai", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195tn9u/after_finally_getting_my_dream_job_i_was_switched/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195tn9u/after_finally_getting_my_dream_job_i_was_switched/", "subreddit_subscribers": 152742, "created_utc": 1705168197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a smallish company but we don\u2019t spend a lot on data team resourcing. So by default I\u2019m the all inclusive data engineer, architect, analyst and requests come from all departments. \n\nAnyone here find it really challenging to source, ingest,  model, shape AND then do analysis?\n\nI used to be analyst but had a much smaller slice of the pie and did no engineering, I was good at doing the analysis and making recommendations.  But now I get to the end of the whole process and I really struggle to analyse the data, anyone else been here or have any tips?", "author_fullname": "t2_uqyn3qdq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Fatigue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195k5tz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705137632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a smallish company but we don\u2019t spend a lot on data team resourcing. So by default I\u2019m the all inclusive data engineer, architect, analyst and requests come from all departments. &lt;/p&gt;\n\n&lt;p&gt;Anyone here find it really challenging to source, ingest,  model, shape AND then do analysis?&lt;/p&gt;\n\n&lt;p&gt;I used to be analyst but had a much smaller slice of the pie and did no engineering, I was good at doing the analysis and making recommendations.  But now I get to the end of the whole process and I really struggle to analyse the data, anyone else been here or have any tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195k5tz", "is_robot_indexable": true, "report_reasons": null, "author": "variance-explained", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195k5tz/data_fatigue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195k5tz/data_fatigue/", "subreddit_subscribers": 152742, "created_utc": 1705137632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've noticed people say on some old Reddit posts that certain companies use Databricks for their Bronze and Silver data layers, and then transfer this data into Snowflake for the Gold layer.\n\nIn such scenarios, as Data Engineers, we often need to reconnect to Snowflake from Databricks to retrieve data\u2014sometimes a significant amount, depending on the table sizes and number of tables. This step is crucial when we have substantial data from sources not integrated into the data warehouse, as it allows us to enrich this data with warehouse data to create specialized datasets for data scientists' ML models.\n\nConsidering the use of both platforms, wouldn't it be more logical to fully establish the data warehouse in Snowflake and only transfer data into Databricks when necessary for creating these specialized, enriched datasets for data science and ML models?\n\nI\u2019m not familiar with the cost implications of these options, but I assume the latter approach might be more practical and efficient, especially for companies whose data warehouse teams have limited proficiency in Python.", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Databricks for Data Science/ML and Snowflake for Data Warehousing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195txyv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705168968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed people say on some old Reddit posts that certain companies use Databricks for their Bronze and Silver data layers, and then transfer this data into Snowflake for the Gold layer.&lt;/p&gt;\n\n&lt;p&gt;In such scenarios, as Data Engineers, we often need to reconnect to Snowflake from Databricks to retrieve data\u2014sometimes a significant amount, depending on the table sizes and number of tables. This step is crucial when we have substantial data from sources not integrated into the data warehouse, as it allows us to enrich this data with warehouse data to create specialized datasets for data scientists&amp;#39; ML models.&lt;/p&gt;\n\n&lt;p&gt;Considering the use of both platforms, wouldn&amp;#39;t it be more logical to fully establish the data warehouse in Snowflake and only transfer data into Databricks when necessary for creating these specialized, enriched datasets for data science and ML models?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not familiar with the cost implications of these options, but I assume the latter approach might be more practical and efficient, especially for companies whose data warehouse teams have limited proficiency in Python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195txyv", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195txyv/using_databricks_for_data_scienceml_and_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195txyv/using_databricks_for_data_scienceml_and_snowflake/", "subreddit_subscribers": 152742, "created_utc": 1705168968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am the sole data analyst/engineer for a smallish manufacturing company where I have practically built the whole thing from scratch: ETL from ERP/other sources using SSIS and Python, into a SQL data warehouse, and then into Power BI and SSRS for end users. \n\nI am starting to look at roles outside the company (for both my professional development as well as some red flags popping up at the office) but I am starting to feel that I am a bit of a cul-de-sac with my experience and don't have the hottest tools and software on my resume. \n\nI don't have \"formal\" data architecture/engineering knowledge (if that is a thing) so I have been trying to cobble together my knowledge from articles, youtube videos, etc, and have noticed there were several mistakes I made early on that I would have caught with best practices re: data warehouse design.\n\nFurthermore, I have not learned any of the newer \"cutting edge\" cloud tools as I don't think I can justify the cost and the time it would require to rebuild the whole thing in the cloud, nor do we need a lot of the high performance big data tools, even though I feel it would be personally beneficial for my career to get some experience with them.\n\nCan anyone recommend some books or something that would help me brush up on current best practices and also some suggestions how I might be able to get some experience with some of the newer tools? We are mostly Microsoft so I am taking some Udemy courses that cover the DP203 Azure Data Engineer Cert but if there are cheaper open source versions that I might be able to stick into my process somewhere that would be helpful as well.\n\nThanks for your help!", "author_fullname": "t2_466z52hl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shoring up resume with best practices/gaining cloud experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195trbo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705168494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the sole data analyst/engineer for a smallish manufacturing company where I have practically built the whole thing from scratch: ETL from ERP/other sources using SSIS and Python, into a SQL data warehouse, and then into Power BI and SSRS for end users. &lt;/p&gt;\n\n&lt;p&gt;I am starting to look at roles outside the company (for both my professional development as well as some red flags popping up at the office) but I am starting to feel that I am a bit of a cul-de-sac with my experience and don&amp;#39;t have the hottest tools and software on my resume. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have &amp;quot;formal&amp;quot; data architecture/engineering knowledge (if that is a thing) so I have been trying to cobble together my knowledge from articles, youtube videos, etc, and have noticed there were several mistakes I made early on that I would have caught with best practices re: data warehouse design.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, I have not learned any of the newer &amp;quot;cutting edge&amp;quot; cloud tools as I don&amp;#39;t think I can justify the cost and the time it would require to rebuild the whole thing in the cloud, nor do we need a lot of the high performance big data tools, even though I feel it would be personally beneficial for my career to get some experience with them.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend some books or something that would help me brush up on current best practices and also some suggestions how I might be able to get some experience with some of the newer tools? We are mostly Microsoft so I am taking some Udemy courses that cover the DP203 Azure Data Engineer Cert but if there are cheaper open source versions that I might be able to stick into my process somewhere that would be helpful as well.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "195trbo", "is_robot_indexable": true, "report_reasons": null, "author": "Midnight_Old", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195trbo/shoring_up_resume_with_best_practicesgaining/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195trbo/shoring_up_resume_with_best_practicesgaining/", "subreddit_subscribers": 152742, "created_utc": 1705168494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At work we have dozens of use cases where scientists will track experiments and metadata in Excel files and share them through email or Microsoft Teams messages. I don't think that it will be easy to completely 180 their current processes, and because they still feel comfortable interacting with their data in editable tables, I thought that I could systemically upgrade their workflows to simple Streamlit apps with editable dataframes ([https://blog.streamlit.io/editable-dataframes-are-here/](https://blog.streamlit.io/editable-dataframes-are-here/)); with the hopes of:\n\n1. Validating data at the source\n2. Creating single source of truth for data\n3. Enabling downstream automation and data sharing\n\nSpecifically with #3, a goal would be to facilitate downstream automation and data sharing in the companies data lake. But technically I'm not sure how this could/should be structured? My initial idea was to have the backend data source be an Iceberg table and have the application make inserts, updates, and deletes directly to the Iceberg table. This would in theory update the data lake in real-time and prevent the need for any extra complexity with databases, orchestration, etc.\n\nBut I've never used Iceberg before so I may be making a lot of assumptions that might not actually work... Would this be a valid use case and are there any technical/data issues with this architecture?\n\n&amp;#x200B;", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reading/writing directly to Iceberg table from web app?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195vi3m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705172994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At work we have dozens of use cases where scientists will track experiments and metadata in Excel files and share them through email or Microsoft Teams messages. I don&amp;#39;t think that it will be easy to completely 180 their current processes, and because they still feel comfortable interacting with their data in editable tables, I thought that I could systemically upgrade their workflows to simple Streamlit apps with editable dataframes (&lt;a href=\"https://blog.streamlit.io/editable-dataframes-are-here/\"&gt;https://blog.streamlit.io/editable-dataframes-are-here/&lt;/a&gt;); with the hopes of:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Validating data at the source&lt;/li&gt;\n&lt;li&gt;Creating single source of truth for data&lt;/li&gt;\n&lt;li&gt;Enabling downstream automation and data sharing&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Specifically with #3, a goal would be to facilitate downstream automation and data sharing in the companies data lake. But technically I&amp;#39;m not sure how this could/should be structured? My initial idea was to have the backend data source be an Iceberg table and have the application make inserts, updates, and deletes directly to the Iceberg table. This would in theory update the data lake in real-time and prevent the need for any extra complexity with databases, orchestration, etc.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;ve never used Iceberg before so I may be making a lot of assumptions that might not actually work... Would this be a valid use case and are there any technical/data issues with this architecture?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195vi3m", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195vi3m/readingwriting_directly_to_iceberg_table_from_web/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195vi3m/readingwriting_directly_to_iceberg_table_from_web/", "subreddit_subscribers": 152742, "created_utc": 1705172994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI\u2019m currently involved in migrating data from a legacy system to a cloud platform. What are the key considerations when initiating such operations? In other words, how do I plan for such a project from scratch?\n\nI\u2019m keen to learn from your experiences. How have you successfully managed projects like these? Your insights and thoughts are incredibly valuable to me.\n\nThank you!", "author_fullname": "t2_azqk02tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the things that we should consider when migrating data from legacy systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195oj1a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705154125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently involved in migrating data from a legacy system to a cloud platform. What are the key considerations when initiating such operations? In other words, how do I plan for such a project from scratch?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m keen to learn from your experiences. How have you successfully managed projects like these? Your insights and thoughts are incredibly valuable to me.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195oj1a", "is_robot_indexable": true, "report_reasons": null, "author": "adatascientistSl", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195oj1a/what_are_the_things_that_we_should_consider_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195oj1a/what_are_the_things_that_we_should_consider_when/", "subreddit_subscribers": 152742, "created_utc": 1705154125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have completed a few projects on data engineering (real world projects and not demo projects). I know how and where to use the common tools. I have mostly been doing this on Azure. So I am familiar with services like synapse analytics, data factory, databricks (pyspark) , SQL databases. And PowerBI for visualization purposes. I had done the basics of ML(classification, clustering, some simple Deep learning, etc...) a few years ago. But that's not enough. How much time would it take to get decent at ML and and probably be amongst the top 15% in this industry globally?", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard is it for a Data Engineer to move into ML/Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195l6dn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705141912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have completed a few projects on data engineering (real world projects and not demo projects). I know how and where to use the common tools. I have mostly been doing this on Azure. So I am familiar with services like synapse analytics, data factory, databricks (pyspark) , SQL databases. And PowerBI for visualization purposes. I had done the basics of ML(classification, clustering, some simple Deep learning, etc...) a few years ago. But that&amp;#39;s not enough. How much time would it take to get decent at ML and and probably be amongst the top 15% in this industry globally?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195l6dn", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195l6dn/how_hard_is_it_for_a_data_engineer_to_move_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195l6dn/how_hard_is_it_for_a_data_engineer_to_move_into/", "subreddit_subscribers": 152742, "created_utc": 1705141912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm a data scientist at a very small startup, trying to grasp some DE concepts. I have a python script that downloads data from a database, does some processing in pandas and then uploads it to another service via their SDK. I want this script to run automatically once a day.\n\n&amp;#x200B;\n\nWe work with Azure and unlikely to move to AWS currently, but are open to using any other tools. Could I get some direction on how to set this up? I see Airflow could be relevant but I don't understand where the computation in Airflow actually run. Do I need to connect it to Azure somehow to give it access to computing power?", "author_fullname": "t2_dqzrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to set up a data processing script automatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195jn3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705135376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m a data scientist at a very small startup, trying to grasp some DE concepts. I have a python script that downloads data from a database, does some processing in pandas and then uploads it to another service via their SDK. I want this script to run automatically once a day.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We work with Azure and unlikely to move to AWS currently, but are open to using any other tools. Could I get some direction on how to set this up? I see Airflow could be relevant but I don&amp;#39;t understand where the computation in Airflow actually run. Do I need to connect it to Azure somehow to give it access to computing power?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195jn3v", "is_robot_indexable": true, "report_reasons": null, "author": "PixelPixell", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195jn3v/how_to_set_up_a_data_processing_script/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195jn3v/how_to_set_up_a_data_processing_script/", "subreddit_subscribers": 152742, "created_utc": 1705135376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have anyone tried to automate the workflow deployment process using Jenkins. I want to migrate a workflow from QA to production environment, provided I should be able to modify the workflow variables.\nIs there a way to do this?", "author_fullname": "t2_7iy7e20h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Collibra workflow deployment via Jenkins", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195vooq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705173459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have anyone tried to automate the workflow deployment process using Jenkins. I want to migrate a workflow from QA to production environment, provided I should be able to modify the workflow variables.\nIs there a way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195vooq", "is_robot_indexable": true, "report_reasons": null, "author": "rags1230", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195vooq/collibra_workflow_deployment_via_jenkins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195vooq/collibra_workflow_deployment_via_jenkins/", "subreddit_subscribers": 152742, "created_utc": 1705173459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow redditors!\n\nSo I\u2019m beginning to get interested in building streaming pipelines. Things like a near real-time data ingestion (a bronze table, for instance), silver tables or even building near real-time specialized datasets (gold datasets).\n\nI know from some researches that in service oriented architectures companies use apache kafka as a integration layer/hub for consumers and producers.\n\nAs far as I\u2019m aware a producer generates some event and sends it for the kafka broker and the consumer can process it right after, and depending on the architecture the consumer even deletes (?) the event that already has been processed to avoid duplication.\n\nIf I\u2019m a data engineer interested in the data that this producer pushed to kafka, how would I reliably get access to this data, without intruding into the integration between the microservices? \n\nI\u2019m looking into kafka connect as something that tries to solve this issue, but I\u2019m quite unsure.\n\nCan someone with more experience in these streaming context bring some light to the subject?", "author_fullname": "t2_5fmit0v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming Pipelines Architecture with Kafka and Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195z6b2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705182606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow redditors!&lt;/p&gt;\n\n&lt;p&gt;So I\u2019m beginning to get interested in building streaming pipelines. Things like a near real-time data ingestion (a bronze table, for instance), silver tables or even building near real-time specialized datasets (gold datasets).&lt;/p&gt;\n\n&lt;p&gt;I know from some researches that in service oriented architectures companies use apache kafka as a integration layer/hub for consumers and producers.&lt;/p&gt;\n\n&lt;p&gt;As far as I\u2019m aware a producer generates some event and sends it for the kafka broker and the consumer can process it right after, and depending on the architecture the consumer even deletes (?) the event that already has been processed to avoid duplication.&lt;/p&gt;\n\n&lt;p&gt;If I\u2019m a data engineer interested in the data that this producer pushed to kafka, how would I reliably get access to this data, without intruding into the integration between the microservices? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking into kafka connect as something that tries to solve this issue, but I\u2019m quite unsure.&lt;/p&gt;\n\n&lt;p&gt;Can someone with more experience in these streaming context bring some light to the subject?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195z6b2", "is_robot_indexable": true, "report_reasons": null, "author": "gabbom_XCII", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195z6b2/streaming_pipelines_architecture_with_kafka_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195z6b2/streaming_pipelines_architecture_with_kafka_and/", "subreddit_subscribers": 152742, "created_utc": 1705182606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familar with reasources for beginning in Python, but am wondering if there are any specific to Synapse Serverless PySpark.\n\nGenerally it works best for me, to start with things I can immediately apply.  Not always, but with Python being a general purpose language, I'm thinking it might be best to try starting with that.", "author_fullname": "t2_3bc49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 Python Beginner Resources, that focus on Synapse Serverless PySpark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195t3cn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705166748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familar with reasources for beginning in Python, but am wondering if there are any specific to Synapse Serverless PySpark.&lt;/p&gt;\n\n&lt;p&gt;Generally it works best for me, to start with things I can immediately apply.  Not always, but with Python being a general purpose language, I&amp;#39;m thinking it might be best to try starting with that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195t3cn", "is_robot_indexable": true, "report_reasons": null, "author": "cdigioia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195t3cn/1_python_beginner_resources_that_focus_on_synapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195t3cn/1_python_beginner_resources_that_focus_on_synapse/", "subreddit_subscribers": 152742, "created_utc": 1705166748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nI'm creating a staging model that feeds on many source tables.  Initially i had a staging model for mails and one for sms that i'd join to create a consolidated staging model.\n\nBut it dawned on my i could just create one model that union sms and email avoiding to create two additional tables. however, i'm afraid there's a quota of UNION within a With clause in BigQuery.\n\nWhat is your point of view?\n\nHere's the query\n\n    WITH source1__data AS (\n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table2\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table2\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table3\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table4\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table5\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table6\n    ),\n        source2__data as (\n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table7\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table8\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table9\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table10\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table11\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table12\n    \n     )\n      \n    SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n    FROM  source1__data\n    UNION ALL\n    SELECT     \n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n    FROM  source2__data\n\nBest!  \n\n\nEdit: renamed the tables to prevent misunderstanding.", "author_fullname": "t2_m0fkuha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery and joins!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195nntp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705180683.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705151369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m creating a staging model that feeds on many source tables.  Initially i had a staging model for mails and one for sms that i&amp;#39;d join to create a consolidated staging model.&lt;/p&gt;\n\n&lt;p&gt;But it dawned on my i could just create one model that union sms and email avoiding to create two additional tables. however, i&amp;#39;m afraid there&amp;#39;s a quota of UNION within a With clause in BigQuery.&lt;/p&gt;\n\n&lt;p&gt;What is your point of view?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the query&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;WITH source1__data AS (\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table2\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table2\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table3\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table4\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table5\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table6\n),\n    source2__data as (\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table7\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table8\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table9\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table10\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table11\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table12\n\n )\n\nSELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\nFROM  source1__data\nUNION ALL\nSELECT     \n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\nFROM  source2__data\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Best!  &lt;/p&gt;\n\n&lt;p&gt;Edit: renamed the tables to prevent misunderstanding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195nntp", "is_robot_indexable": true, "report_reasons": null, "author": "anfawave", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195nntp/bigquery_and_joins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195nntp/bigquery_and_joins/", "subreddit_subscribers": 152742, "created_utc": 1705151369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "can i work with it through the vscode extension tho? i'd like to know cause thats what we are studying in uni for now , but if thats not the case then i would be okay with a close equivalent  ", "author_fullname": "t2_6elmofyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "oracle equivalent for mac?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195ketb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705138691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;can i work with it through the vscode extension tho? i&amp;#39;d like to know cause thats what we are studying in uni for now , but if thats not the case then i would be okay with a close equivalent  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195ketb", "is_robot_indexable": true, "report_reasons": null, "author": "Getsuga_H", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195ketb/oracle_equivalent_for_mac/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195ketb/oracle_equivalent_for_mac/", "subreddit_subscribers": 152742, "created_utc": 1705138691.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}