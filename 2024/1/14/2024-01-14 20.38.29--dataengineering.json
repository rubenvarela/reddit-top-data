{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_i6ulm8ug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Guide to Data Lake Interview Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_196erg9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bo78L9h3mP3c8ZqpOxqRXHUuylpR-bghme4LCs1jXZs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705235073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "itcertificate.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://itcertificate.org/blog/data-lake-interview-questions", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cHkwD7ukAvg_vQGvsjs8wjDt5_sEjsIl-0ndpPgdz60.jpg?auto=webp&amp;s=25e6c249242342b7465f7dde367031c7dba962b4", "width": 612, "height": 412}, "resolutions": [{"url": "https://external-preview.redd.it/cHkwD7ukAvg_vQGvsjs8wjDt5_sEjsIl-0ndpPgdz60.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=feebdea14eb4a8ff904b50bc6bc91ec4f6b08a05", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/cHkwD7ukAvg_vQGvsjs8wjDt5_sEjsIl-0ndpPgdz60.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=31e8f1434a143f7b488df42f359572d314b8b32c", "width": 216, "height": 145}, {"url": "https://external-preview.redd.it/cHkwD7ukAvg_vQGvsjs8wjDt5_sEjsIl-0ndpPgdz60.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89bd9dc6a08ccef63465a60a082f473445836cba", "width": 320, "height": 215}], "variants": {}, "id": "Yqass0Jy5N-IMcQo6kIJhHlHiqg68ZoeZSEXF7fnvro"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "196erg9", "is_robot_indexable": true, "report_reasons": null, "author": "Intelligent_Tune_392", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196erg9/a_guide_to_data_lake_interview_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://itcertificate.org/blog/data-lake-interview-questions", "subreddit_subscribers": 152875, "created_utc": 1705235073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just started my academic course where i would be learning how to perform ETL from multiple postgresql OLTP's to a postgresql OLAP using talend and AWS cloudstack for data engineering where im expected to do a individual project as my finals. My prof has told us that the coursework would be hectic with a lot of in class lab sessions. Would really appreciate any tips or suggestions that can help me through my academic course and to build a professional career as a data engineer.\n\nCurrently I know python as a programming language and intermediate mysql.", "author_fullname": "t2_7bo4ark1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips: Started to learn Data Engineering!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196bfau", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705221609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just started my academic course where i would be learning how to perform ETL from multiple postgresql OLTP&amp;#39;s to a postgresql OLAP using talend and AWS cloudstack for data engineering where im expected to do a individual project as my finals. My prof has told us that the coursework would be hectic with a lot of in class lab sessions. Would really appreciate any tips or suggestions that can help me through my academic course and to build a professional career as a data engineer.&lt;/p&gt;\n\n&lt;p&gt;Currently I know python as a programming language and intermediate mysql.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "196bfau", "is_robot_indexable": true, "report_reasons": null, "author": "iT0X1Ni", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196bfau/tips_started_to_learn_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196bfau/tips_started_to_learn_data_engineering/", "subreddit_subscribers": 152875, "created_utc": 1705221609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi to all Seniors and experienced one in the industry. \nI have a question how does you face a business problem and convert it into technical design. Like for various software Engineering post they follow norms of system design like scalability, load balancing, reliability. \nWhat's the norm or basic protocol followed while designing a data warehouse. \n\nI m ETL developer, fresh into industry. And I want to make it norm, to approach a problem with big picture in subconscious mind. Currently I had to faced a lot of rework due to modification in DWH architecture. But are various approach you follow. Do you have any great blogs!? Right now I m trying to learn from \"Design data intensive applications\" But its more like solving software issues.\n\nLike what common do you face and how you solved it. I'm great into blogs, books more than video. video is very tiring for me. Also I am looking forward enter real time processing market. So from that perspective I want to aware of scenarios normally faced in those situations\n\nAny suggestions will be appreciated by heart.", "author_fullname": "t2_1ubfs6x4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does a Data Warehouse Architect approach a business problem and convert it into technical design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196hliq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705244070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi to all Seniors and experienced one in the industry. \nI have a question how does you face a business problem and convert it into technical design. Like for various software Engineering post they follow norms of system design like scalability, load balancing, reliability. \nWhat&amp;#39;s the norm or basic protocol followed while designing a data warehouse. &lt;/p&gt;\n\n&lt;p&gt;I m ETL developer, fresh into industry. And I want to make it norm, to approach a problem with big picture in subconscious mind. Currently I had to faced a lot of rework due to modification in DWH architecture. But are various approach you follow. Do you have any great blogs!? Right now I m trying to learn from &amp;quot;Design data intensive applications&amp;quot; But its more like solving software issues.&lt;/p&gt;\n\n&lt;p&gt;Like what common do you face and how you solved it. I&amp;#39;m great into blogs, books more than video. video is very tiring for me. Also I am looking forward enter real time processing market. So from that perspective I want to aware of scenarios normally faced in those situations&lt;/p&gt;\n\n&lt;p&gt;Any suggestions will be appreciated by heart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "196hliq", "is_robot_indexable": true, "report_reasons": null, "author": "asud_w_asud", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196hliq/how_does_a_data_warehouse_architect_approach_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196hliq/how_does_a_data_warehouse_architect_approach_a/", "subreddit_subscribers": 152875, "created_utc": 1705244070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a graduate student in data science with a 4.0 GPA but I feel lost. Imposter syndrome has really gotten to me and I try my best to upskill especially as I have great interest in data engineering. \n\nAside my data science course work, I have enrolled in DataCamp's data engineering track to learn skills there but I somehow feel inadequate. I have completed about 47% of the track spanning \n- SQL Joins\n- Introduction to Relational Databases \n- Database Design\n- Intermediate Python \n\nI have reached out to many potential mentors but no one has responded. I need someone to guide me on this path. I am willing to join or work for free on your projects, I need exposure and direction on what to actually learn and practice. Help please.", "author_fullname": "t2_v01madky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In dire need of guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1968ntq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705211078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a graduate student in data science with a 4.0 GPA but I feel lost. Imposter syndrome has really gotten to me and I try my best to upskill especially as I have great interest in data engineering. &lt;/p&gt;\n\n&lt;p&gt;Aside my data science course work, I have enrolled in DataCamp&amp;#39;s data engineering track to learn skills there but I somehow feel inadequate. I have completed about 47% of the track spanning \n- SQL Joins\n- Introduction to Relational Databases \n- Database Design\n- Intermediate Python &lt;/p&gt;\n\n&lt;p&gt;I have reached out to many potential mentors but no one has responded. I need someone to guide me on this path. I am willing to join or work for free on your projects, I need exposure and direction on what to actually learn and practice. Help please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1968ntq", "is_robot_indexable": true, "report_reasons": null, "author": "ETKojo", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1968ntq/in_dire_need_of_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1968ntq/in_dire_need_of_guidance/", "subreddit_subscribers": 152875, "created_utc": 1705211078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI need help with Spark streaming in Databricks. I'm reading data from EventHub and writing it to a Delta Lake using the medallion architecture in two steps:\n\n* EventHub to Bronze Delta table.\n* Bronze to Silver Delta table (the final table).\n\nThe EventHub to Bronze part is working fine. However, when reading from Bronze to Silver (Delta to Delta), I'm facing issues. I'm using 1-second intervals to process batches, and sometimes I get a massive number of records in one batch (100,000 to 200,000), causing out-of-memory errors and delays.\n\nI've tried adjusting parameters like maxRecordsPerTrigger, maxFilesPerTrigger, maxbytespertrigger  \n, and Spark configurations like spark.databricks.delta.autoOptimize.optimizeWrite  \n, spark.databricks.delta.properties.defaults.autoOptimize.autoCompact  \n, and spark.sql.optimizer.dynamicPartitionPruning  \n, along with enabling backpressure in streaming, but nothing seems to be working.\n\nIf I can limit the incoming records to around 15,000-20,000, it should solve the problem. Here are my questions:\n\n1. Is there any other solution to this issue?\n2. Is the approach of going from EventHub to Bronze and then Bronze to Silver the right one?\n3. If I were to replace this flow with stream analytics, would it support complex transformations?  \n\n\nattaching screeshots of code of reading from eventhub and writing the data to delta lake, also adding screenshot of  capturing the unexpected  data spike while transferring from Bronze to Silver, especially when there was no corresponding spike in EventHub data at that time \n\nplease note: trigger\\_time is 1 second\n\nhttps://preview.redd.it/2ltlqx6hagcc1.png?width=868&amp;format=png&amp;auto=webp&amp;s=0da2f9b413f7fa0689714e21d80fde30d5b39258\n\nhttps://preview.redd.it/xiow507hagcc1.png?width=1113&amp;format=png&amp;auto=webp&amp;s=a154da0f2546d2030e936eece7ca690f9f281cfc\n\nhttps://preview.redd.it/yv0yg27hagcc1.png?width=1204&amp;format=png&amp;auto=webp&amp;s=c475dd3ad360e569488b85d204f5d93865dedc9a", "author_fullname": "t2_ptil4bof4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in Spark streaming to address to delays when processing large batches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": true, "media_metadata": {"yv0yg27hagcc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/yv0yg27hagcc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7937a6ec269c6f17eeea13e5f58f970299bb3533"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/yv0yg27hagcc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9ffc0f50a884be4aeb08bc4b829cd850fd46e03"}, {"y": 150, "x": 320, "u": "https://preview.redd.it/yv0yg27hagcc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e23713b9eb78f02ca06b9731d48b19b7e331d7a"}, {"y": 301, "x": 640, "u": "https://preview.redd.it/yv0yg27hagcc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=46eee918ede1c185a119d558c0eb875655c7f6dc"}, {"y": 452, "x": 960, "u": "https://preview.redd.it/yv0yg27hagcc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=405b6394e98a391d8617c4bf78a3b4f96430bd82"}, {"y": 509, "x": 1080, "u": "https://preview.redd.it/yv0yg27hagcc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=258565fb8b4be7a149fd5fe89519bb1a209b1c04"}], "s": {"y": 568, "x": 1204, "u": "https://preview.redd.it/yv0yg27hagcc1.png?width=1204&amp;format=png&amp;auto=webp&amp;s=c475dd3ad360e569488b85d204f5d93865dedc9a"}, "id": "yv0yg27hagcc1"}, "xiow507hagcc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/xiow507hagcc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=01791a368bb3a934f55b6eb687179ce8f1637def"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/xiow507hagcc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=37d97aa769f85feb032862d89c6fa5cd6697deb6"}, {"y": 154, "x": 320, "u": "https://preview.redd.it/xiow507hagcc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=30dbf2d9c5311ce3062a1e5d56522f9d081baf70"}, {"y": 308, "x": 640, "u": "https://preview.redd.it/xiow507hagcc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d8a588ab7e97c5c62d66ad9e13d66d7055740aa6"}, {"y": 463, "x": 960, "u": "https://preview.redd.it/xiow507hagcc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=220b7ed5d84c9a6341e56ab833c6e0a3e0ee5383"}, {"y": 521, "x": 1080, "u": "https://preview.redd.it/xiow507hagcc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e54a60fd6629c7ac871ece491cce406c9245ada5"}], "s": {"y": 537, "x": 1113, "u": "https://preview.redd.it/xiow507hagcc1.png?width=1113&amp;format=png&amp;auto=webp&amp;s=a154da0f2546d2030e936eece7ca690f9f281cfc"}, "id": "xiow507hagcc1"}, "2ltlqx6hagcc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/2ltlqx6hagcc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=20bccf257aa2fe1f65853e83e63c7b387807cf60"}, {"y": 99, "x": 216, "u": "https://preview.redd.it/2ltlqx6hagcc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=92d0d6791f71c21b3e0c3d955c64ddd1e9bf1dc4"}, {"y": 147, "x": 320, "u": "https://preview.redd.it/2ltlqx6hagcc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c9f09255229f41a8dc843f4e73278e108300d84"}, {"y": 294, "x": 640, "u": "https://preview.redd.it/2ltlqx6hagcc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=86d4c494cbaa8136c743611c5bf5e78a86634a27"}], "s": {"y": 400, "x": 868, "u": "https://preview.redd.it/2ltlqx6hagcc1.png?width=868&amp;format=png&amp;auto=webp&amp;s=0da2f9b413f7fa0689714e21d80fde30d5b39258"}, "id": "2ltlqx6hagcc1"}}, "name": "t3_196ms9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vEiRua_RmbPacMB3rAJ7qu0yHwNytLt50u4FWsLVKFk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705257652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I need help with Spark streaming in Databricks. I&amp;#39;m reading data from EventHub and writing it to a Delta Lake using the medallion architecture in two steps:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;EventHub to Bronze Delta table.&lt;/li&gt;\n&lt;li&gt;Bronze to Silver Delta table (the final table).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The EventHub to Bronze part is working fine. However, when reading from Bronze to Silver (Delta to Delta), I&amp;#39;m facing issues. I&amp;#39;m using 1-second intervals to process batches, and sometimes I get a massive number of records in one batch (100,000 to 200,000), causing out-of-memory errors and delays.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried adjusting parameters like maxRecordsPerTrigger, maxFilesPerTrigger, maxbytespertrigger&lt;br/&gt;\n, and Spark configurations like spark.databricks.delta.autoOptimize.optimizeWrite&lt;br/&gt;\n, spark.databricks.delta.properties.defaults.autoOptimize.autoCompact&lt;br/&gt;\n, and spark.sql.optimizer.dynamicPartitionPruning&lt;br/&gt;\n, along with enabling backpressure in streaming, but nothing seems to be working.&lt;/p&gt;\n\n&lt;p&gt;If I can limit the incoming records to around 15,000-20,000, it should solve the problem. Here are my questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is there any other solution to this issue?&lt;/li&gt;\n&lt;li&gt;Is the approach of going from EventHub to Bronze and then Bronze to Silver the right one?&lt;/li&gt;\n&lt;li&gt;If I were to replace this flow with stream analytics, would it support complex transformations?&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;attaching screeshots of code of reading from eventhub and writing the data to delta lake, also adding screenshot of  capturing the unexpected  data spike while transferring from Bronze to Silver, especially when there was no corresponding spike in EventHub data at that time &lt;/p&gt;\n\n&lt;p&gt;please note: trigger_time is 1 second&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2ltlqx6hagcc1.png?width=868&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0da2f9b413f7fa0689714e21d80fde30d5b39258\"&gt;https://preview.redd.it/2ltlqx6hagcc1.png?width=868&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0da2f9b413f7fa0689714e21d80fde30d5b39258&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xiow507hagcc1.png?width=1113&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a154da0f2546d2030e936eece7ca690f9f281cfc\"&gt;https://preview.redd.it/xiow507hagcc1.png?width=1113&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a154da0f2546d2030e936eece7ca690f9f281cfc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yv0yg27hagcc1.png?width=1204&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c475dd3ad360e569488b85d204f5d93865dedc9a\"&gt;https://preview.redd.it/yv0yg27hagcc1.png?width=1204&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c475dd3ad360e569488b85d204f5d93865dedc9a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "196ms9c", "is_robot_indexable": true, "report_reasons": null, "author": "HousingStriking3770", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196ms9c/need_help_in_spark_streaming_to_address_to_delays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196ms9c/need_help_in_spark_streaming_to_address_to_delays/", "subreddit_subscribers": 152875, "created_utc": 1705257652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I recently started a new job that is not related to data engineering, but there are a lot of things where I can apply ETL things to automate my tasks. I don't have experience as a data engineer but is my goal to switch careers and get a data engineering job eventually.\n\nAnyways, my problem is as follows: Everyday I get a new CSV that is the same table as the day before but with new info. Every day I need to rearrange that table and 1- create a new CSV file with the daily info and 2-  \"append\" it into the monthly cleaned table. \n\nThose things that take a lot of time manually I can use python to automate the task, and I am in the process of achieving it. But the thing is that I get to a point in which I don't know if I should use stuff like SQLalchemy, psycopg2 or if I should just stick to pandas. I want to understand the thought process of when I should use what. Let me develop. \n\nFor example, once I get the CSV as a DF, I filter it with pandas. But then, I need to modify the values of column F according to the values of column G. In column G I have description and each description corresponds to a group. In column F I need to specify the group. I know I can keep using pandas to also achieve this, but at the same time, this is a clear and plain simple JOIN function. \n\nI am reluctant to create a, let's say, PostgreSQL Database because I want to eventually be able to share my python scripts as an exe and someone like my teammate can simply execute it and don't need another program like PostgreSQL to successfully run the file. But maybe I should just do it. I don't really know. \n\nAlso I don't understand why should I use sql at all if pandas can cover for the things that I want to achieve. \n\nThanks in advance for your advice and if you can point me into maybe some useful learning books I would really appreciate it.", "author_fullname": "t2_9yaiy40i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie here trying to learn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196hvq8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705244826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I recently started a new job that is not related to data engineering, but there are a lot of things where I can apply ETL things to automate my tasks. I don&amp;#39;t have experience as a data engineer but is my goal to switch careers and get a data engineering job eventually.&lt;/p&gt;\n\n&lt;p&gt;Anyways, my problem is as follows: Everyday I get a new CSV that is the same table as the day before but with new info. Every day I need to rearrange that table and 1- create a new CSV file with the daily info and 2-  &amp;quot;append&amp;quot; it into the monthly cleaned table. &lt;/p&gt;\n\n&lt;p&gt;Those things that take a lot of time manually I can use python to automate the task, and I am in the process of achieving it. But the thing is that I get to a point in which I don&amp;#39;t know if I should use stuff like SQLalchemy, psycopg2 or if I should just stick to pandas. I want to understand the thought process of when I should use what. Let me develop. &lt;/p&gt;\n\n&lt;p&gt;For example, once I get the CSV as a DF, I filter it with pandas. But then, I need to modify the values of column F according to the values of column G. In column G I have description and each description corresponds to a group. In column F I need to specify the group. I know I can keep using pandas to also achieve this, but at the same time, this is a clear and plain simple JOIN function. &lt;/p&gt;\n\n&lt;p&gt;I am reluctant to create a, let&amp;#39;s say, PostgreSQL Database because I want to eventually be able to share my python scripts as an exe and someone like my teammate can simply execute it and don&amp;#39;t need another program like PostgreSQL to successfully run the file. But maybe I should just do it. I don&amp;#39;t really know. &lt;/p&gt;\n\n&lt;p&gt;Also I don&amp;#39;t understand why should I use sql at all if pandas can cover for the things that I want to achieve. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your advice and if you can point me into maybe some useful learning books I would really appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "196hvq8", "is_robot_indexable": true, "report_reasons": null, "author": "GFM41", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196hvq8/newbie_here_trying_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196hvq8/newbie_here_trying_to_learn/", "subreddit_subscribers": 152875, "created_utc": 1705244826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to build up some DE personal projects in my spare time. Mostly just in the interest of learning and upskilling with no plans to profit off of anything.\n\nI'd like to orchestrate some DAGs through Airflow, and would like to host in on AWS. At work we use MWAA which would be way overkill, and I'm curious what the cheapest hosting strategy would be for hobbyists? I'm planning to play around with the idea of running all tasks as ECS/EKS tasks, so the core infra doesn't need to support anything too intensive.", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the cheapest way to host Airflow for personal projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_196mzxv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705258198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to build up some DE personal projects in my spare time. Mostly just in the interest of learning and upskilling with no plans to profit off of anything.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to orchestrate some DAGs through Airflow, and would like to host in on AWS. At work we use MWAA which would be way overkill, and I&amp;#39;m curious what the cheapest hosting strategy would be for hobbyists? I&amp;#39;m planning to play around with the idea of running all tasks as ECS/EKS tasks, so the core infra doesn&amp;#39;t need to support anything too intensive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "196mzxv", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196mzxv/whats_the_cheapest_way_to_host_airflow_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196mzxv/whats_the_cheapest_way_to_host_airflow_for/", "subreddit_subscribers": 152875, "created_utc": 1705258198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "About me: 25M, &lt; 2y experience, graduated May 2022 with degree in Mathematical Economics. Currently working in a business analytics role for a non-tech firm It's pretty simple, fairly low pay and atp quite stagnant in terms of learning/progressing, but it's a good experience\n\nI just got offered a new job as a Power BI developer, that pays about 15k+ more. On one hand, it seems like an obvious accept, however the two main issues I have are:\n\n* I want to learn more technical stuff beyond building dashboards. I mean, yes dashboards and visualizations are important, but I really enjoy doing actual large-scale computational science work. I find it much more intellectually stimulating and interesting.\n* I don't want to stay in my current city, which the new job is in. I don't really like it here tbh, it's small and boring. Ideally, I want to go to a bigger city (nyc or SF).\n* Little-to-no DE focus, apart from \"ocassional SQL queries\" they threw into the job description.\n\nAm I being naive to turn this offer down? Any input is greatly appreciated.", "author_fullname": "t2_16cclgpl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take this job offer as a PowerBI Developer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_196ntm5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705260290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About me: 25M, &amp;lt; 2y experience, graduated May 2022 with degree in Mathematical Economics. Currently working in a business analytics role for a non-tech firm It&amp;#39;s pretty simple, fairly low pay and atp quite stagnant in terms of learning/progressing, but it&amp;#39;s a good experience&lt;/p&gt;\n\n&lt;p&gt;I just got offered a new job as a Power BI developer, that pays about 15k+ more. On one hand, it seems like an obvious accept, however the two main issues I have are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I want to learn more technical stuff beyond building dashboards. I mean, yes dashboards and visualizations are important, but I really enjoy doing actual large-scale computational science work. I find it much more intellectually stimulating and interesting.&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t want to stay in my current city, which the new job is in. I don&amp;#39;t really like it here tbh, it&amp;#39;s small and boring. Ideally, I want to go to a bigger city (nyc or SF).&lt;/li&gt;\n&lt;li&gt;Little-to-no DE focus, apart from &amp;quot;ocassional SQL queries&amp;quot; they threw into the job description.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Am I being naive to turn this offer down? Any input is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "196ntm5", "is_robot_indexable": true, "report_reasons": null, "author": "OutrageousPressure6", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196ntm5/should_i_take_this_job_offer_as_a_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196ntm5/should_i_take_this_job_offer_as_a_powerbi/", "subreddit_subscribers": 152875, "created_utc": 1705260290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any favorite resources for developing a rigorous approach to data modeling? I have a couple years of real-world experience developing data models in my work- identifying business needs, thinking about how data is collected and accessed and mapping that to a model that balances the business's priorities- but I'm looking to develop a more rigorous or formal framework or methodology for data modeling now that I think I'm primed for it.  \n\n\nDoes anyone have any favorite books, videos, or other resources they really like for learning data modeling?", "author_fullname": "t2_7cbbasaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196ml6j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705257143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any favorite resources for developing a rigorous approach to data modeling? I have a couple years of real-world experience developing data models in my work- identifying business needs, thinking about how data is collected and accessed and mapping that to a model that balances the business&amp;#39;s priorities- but I&amp;#39;m looking to develop a more rigorous or formal framework or methodology for data modeling now that I think I&amp;#39;m primed for it.  &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any favorite books, videos, or other resources they really like for learning data modeling?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "196ml6j", "is_robot_indexable": true, "report_reasons": null, "author": "Cheetah-Infinite", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196ml6j/data_modeling_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196ml6j/data_modeling_resources/", "subreddit_subscribers": 152875, "created_utc": 1705257143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "By way of introduction - I\u2019m primarily an econometrician by trade and focus on building smaller scale econometric/ML models for clients. I typically work with a range of datasets, but importantly it\u2019s collectively small enough to fit in to local memory and work with using R or Python.\n\nAs the lines between data science and econometrics continue to blur, I find myself working more and more with much larger datasets. Too large to fit in to local memory.\n\nAs an organisation we use Snowflake to store data that we don\u2019t want on our network drives (100gb+). As of now, I use Python's Snowpark library to aggregate large datasets on snowflake in to a level where I can transfer locally and then deploy an ML model locally. I'm also comfortable writing the SQL directly. \n\nHowever using cloud or online data platforms hasn't really been my bread and butter and wondered if anybody could offer any advice around the following:\n\n1. I'm unsure if its best practice to aggregate on the cloud and then analyse locally. Supposing its not - is it possible to deploy a ML model within a snowflake environment instead? In other words \u2013 all data wrangling and model execution is done on the snowflake engine.\n2. I hear a lot about databricks as an alternative to snowflake, but struggling to understand what it offers, and what it can do that\u2019s different? Could anybody help to explain this to me like you would to a small dog?\n\nThanks a lot! ", "author_fullname": "t2_uqor47tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for some guidance around online data platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196lma9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705254663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;By way of introduction - I\u2019m primarily an econometrician by trade and focus on building smaller scale econometric/ML models for clients. I typically work with a range of datasets, but importantly it\u2019s collectively small enough to fit in to local memory and work with using R or Python.&lt;/p&gt;\n\n&lt;p&gt;As the lines between data science and econometrics continue to blur, I find myself working more and more with much larger datasets. Too large to fit in to local memory.&lt;/p&gt;\n\n&lt;p&gt;As an organisation we use Snowflake to store data that we don\u2019t want on our network drives (100gb+). As of now, I use Python&amp;#39;s Snowpark library to aggregate large datasets on snowflake in to a level where I can transfer locally and then deploy an ML model locally. I&amp;#39;m also comfortable writing the SQL directly. &lt;/p&gt;\n\n&lt;p&gt;However using cloud or online data platforms hasn&amp;#39;t really been my bread and butter and wondered if anybody could offer any advice around the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;m unsure if its best practice to aggregate on the cloud and then analyse locally. Supposing its not - is it possible to deploy a ML model within a snowflake environment instead? In other words \u2013 all data wrangling and model execution is done on the snowflake engine.&lt;/li&gt;\n&lt;li&gt;I hear a lot about databricks as an alternative to snowflake, but struggling to understand what it offers, and what it can do that\u2019s different? Could anybody help to explain this to me like you would to a small dog?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks a lot! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "196lma9", "is_robot_indexable": true, "report_reasons": null, "author": "LDM-88", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196lma9/looking_for_some_guidance_around_online_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196lma9/looking_for_some_guidance_around_online_data/", "subreddit_subscribers": 152875, "created_utc": 1705254663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company requires reporting on information within salesforce.\n\nThey want something like # open leads, # closed leads and # converted leads on a monthly basis. My issue is that often this data is not immutable: a lead (or an opportunity for example) might be closed, but then later on reopens since the lead/opp is now interested in the product.  \n\n\nThis would generally change data retrospectively.  \nIs the only way to do a complex query using lead and opportunity history tables and creating an events based data model?", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing Salesforce Reporting (in DBT)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196funh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705238784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company requires reporting on information within salesforce.&lt;/p&gt;\n\n&lt;p&gt;They want something like # open leads, # closed leads and # converted leads on a monthly basis. My issue is that often this data is not immutable: a lead (or an opportunity for example) might be closed, but then later on reopens since the lead/opp is now interested in the product.  &lt;/p&gt;\n\n&lt;p&gt;This would generally change data retrospectively.&lt;br/&gt;\nIs the only way to do a complex query using lead and opportunity history tables and creating an events based data model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "196funh", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196funh/managing_salesforce_reporting_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196funh/managing_salesforce_reporting_in_dbt/", "subreddit_subscribers": 152875, "created_utc": 1705238784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have upgraded Databricks Community Edition to Databricks' free trial on AWS free tier. Since NAT Gateway was not part of the free tier and I am being charged, I deleted it. This results in me not being able to create clusters.\n\nI've seen suggestions about replacing it with VPC endpoint, but I have zero knowledge about networking so I don't know how to do it myself and I can't make sense of the tutorials I see on the internet how to customise it for Databricks use. Does anyone know any resource that I can follow so I can setup the needed VPC endpoints and for Databricks to work?\n\nOr if there are better options than VPC endpoints which a compete networking noob can easily follow, that would be great too.", "author_fullname": "t2_tomg3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to replace AWS NAT Gateway being used by Databricks with VPC endpoints?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196beob", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705221537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have upgraded Databricks Community Edition to Databricks&amp;#39; free trial on AWS free tier. Since NAT Gateway was not part of the free tier and I am being charged, I deleted it. This results in me not being able to create clusters.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen suggestions about replacing it with VPC endpoint, but I have zero knowledge about networking so I don&amp;#39;t know how to do it myself and I can&amp;#39;t make sense of the tutorials I see on the internet how to customise it for Databricks use. Does anyone know any resource that I can follow so I can setup the needed VPC endpoints and for Databricks to work?&lt;/p&gt;\n\n&lt;p&gt;Or if there are better options than VPC endpoints which a compete networking noob can easily follow, that would be great too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "196beob", "is_robot_indexable": true, "report_reasons": null, "author": "AxenZh", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196beob/how_to_replace_aws_nat_gateway_being_used_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196beob/how_to_replace_aws_nat_gateway_being_used_by/", "subreddit_subscribers": 152875, "created_utc": 1705221537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in insurnace in London and this is my first job out of uni. Currently earning 38k.\n\nSalary review is in April which I will have a little over 1 year experience. What would be a realistic salary increase in my current role?\n\nI know by looking on LinkedIn I should be on average 45-50k with 1 year experience but would like to know from you guys what I could expect. Last year my company gave a 5% increase to my team but the company performed about 3 times worse last year compared to this year.\n\nMany thanks looking forward to reading your responses", "author_fullname": "t2_9wz5l9vg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary progression?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_196ogxq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705261965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in insurnace in London and this is my first job out of uni. Currently earning 38k.&lt;/p&gt;\n\n&lt;p&gt;Salary review is in April which I will have a little over 1 year experience. What would be a realistic salary increase in my current role?&lt;/p&gt;\n\n&lt;p&gt;I know by looking on LinkedIn I should be on average 45-50k with 1 year experience but would like to know from you guys what I could expect. Last year my company gave a 5% increase to my team but the company performed about 3 times worse last year compared to this year.&lt;/p&gt;\n\n&lt;p&gt;Many thanks looking forward to reading your responses&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "196ogxq", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Statistician2604", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196ogxq/salary_progression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196ogxq/salary_progression/", "subreddit_subscribers": 152875, "created_utc": 1705261965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey hey all, data/analytics engineer here,\n\nI got a lenghty topic, hopefully worthy of a lenghty discussion. I'm looking into LLM-s and how they could be used for assisting in understanding reports.\n\nI would like your opinion on the following idea I am exploring.\n\n**Business Problem**\n\nOur company got loads of reports generated, more than humanely possible to read (that's another discussion to have, but many of these are legally required, etc.). It would be really cool that for a given report, there would be a few sentences highlighting things. \n\nA Report's (Reader's) Digest if you will. Things like \n\n* \"It seems that compared to 2023 Q1, in 2023 Q2 our sales in department x has increased by 6.4% percent which is unusually high.\"\n* \"Our social network reach has been constantly falling on Facebook since 2023 February.\"\n* \"The average customer rating has been dropping for 5 consecutive days.\"\n\n**Understanding limits**\n\nI get that LLM-s work with string data, so i'm guessing this isn't a straightforward thing to do. I'm also thinking that currently LLM-s won't figure out insights on their own without guidance, thus questions should be agreed upon with business. (Altough self-propelled insight finding would be a holy grail.) So with this in mind:\n\n* probably business questions should be agreed upon\n* probably business shouldn't ask their questions directly from an LLM agent\n* LLMs are not great at understanding tabular data so this is not an obvious path ahead\n\n**Brainstorming ideas**\n\nArchitecture-wise, I would be using Databricks (something we actively work with), loading a report in as a delta table, then use a [LLM serving endpoint](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/llm-optimized-model-serving). This is fairly new stuff coming from them, it's still in public preview, but it can leverage LLama-2, keeps the data on databricks side so it seems secure. (GDPR says hello.)\n\nI found of course Pandas AI, that could be useful in combination with databricks somehow? I also found this [fairly recent paper](https://arxiv.org/pdf/2401.04398v1.pdf), which talks about \"Evolving chain for table reasoning\" on L[LamaIndex linkedin page](https://www.linkedin.com/posts/llamaindex_chain-of-table-use-llms-to-understand-activity-7151983658596229120-fOo3?utm_source=share&amp;utm_medium=member_desktop) that proposes a chain-of-table querying that looks interesting. It seems something closer to what LangChain is doing. Some [medium.com](https://medium.com) articles i found: [1](https://medium.com/@murtuza753/using-llama-2-0-faiss-and-langchain-for-question-answering-on-your-own-data-682241488476) (this is about documents), [2](https://ameer-hakme.medium.com/unlocking-context-aware-insights-in-tabular-data-with-llms-and-langchain-fac1d33b5c6d) (this is about tabular data)\n\n**A maybe functioning idea**\n\nOkay so let's see if the following makes sense, it is very highlever and very brainstormy:\n\n1. Agree on with business what are the core questions they want to know from a report.\n2. A LLama-2 model is setup in Databricks with serving endpoint\n3. A job runs daily:\n   1. A report is ingested some magical data engineering-y way (my fellow data engineers know the pain)\n   2. Prompt engineering: do some setup with the LLM agent (no clue yet what could be needed, but it's a good guess that this is required - to prevent hallucations, etc).\n   3. Prompts from business are loaded from some config file\n   4. Results are stored in a separate delta table with following schema:\n      1. Some primary key\n      2. Some report identifier\n      3. Business unit or stakeholder identifier\n      4. Prompt\n      5. Answer\n      6. Timestamp\n   5. A SQL Warehouse endpoint is available and can be queried (by PowerBI for example that gets the latest answers.)\n\n**Problems and limitations**\n\nHow do we check if the answers are correct? Monitoring results is very blackbox-y at best. Ideally endusers needs to be trained on the purpose of the Report's Digest is to highlight stuff, but they have to verify it themselves. Getting feedback from endusers can be also complicated\n\n**Conclusion in an ideal world**\n\nBusiness managers like to look at PowerBI reports, and with this new feature they get an immediate highlight of the day, the top 3 questions they always wanna know about comes with immedaite answers. \"We have an increased count of customer service tickets compared to previous week\". The manager looks at the graph and it seems to verify this statement.\n\nEngineer team walks into the sunset with cool music in background\n\n&amp;#x200B;", "author_fullname": "t2_hp7r8vez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using LLMs to draw simple insight from tabular data: a discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_196nl41", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705259690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey hey all, data/analytics engineer here,&lt;/p&gt;\n\n&lt;p&gt;I got a lenghty topic, hopefully worthy of a lenghty discussion. I&amp;#39;m looking into LLM-s and how they could be used for assisting in understanding reports.&lt;/p&gt;\n\n&lt;p&gt;I would like your opinion on the following idea I am exploring.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Business Problem&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Our company got loads of reports generated, more than humanely possible to read (that&amp;#39;s another discussion to have, but many of these are legally required, etc.). It would be really cool that for a given report, there would be a few sentences highlighting things. &lt;/p&gt;\n\n&lt;p&gt;A Report&amp;#39;s (Reader&amp;#39;s) Digest if you will. Things like &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;It seems that compared to 2023 Q1, in 2023 Q2 our sales in department x has increased by 6.4% percent which is unusually high.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;Our social network reach has been constantly falling on Facebook since 2023 February.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;The average customer rating has been dropping for 5 consecutive days.&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Understanding limits&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I get that LLM-s work with string data, so i&amp;#39;m guessing this isn&amp;#39;t a straightforward thing to do. I&amp;#39;m also thinking that currently LLM-s won&amp;#39;t figure out insights on their own without guidance, thus questions should be agreed upon with business. (Altough self-propelled insight finding would be a holy grail.) So with this in mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;probably business questions should be agreed upon&lt;/li&gt;\n&lt;li&gt;probably business shouldn&amp;#39;t ask their questions directly from an LLM agent&lt;/li&gt;\n&lt;li&gt;LLMs are not great at understanding tabular data so this is not an obvious path ahead&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Brainstorming ideas&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Architecture-wise, I would be using Databricks (something we actively work with), loading a report in as a delta table, then use a &lt;a href=\"https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/llm-optimized-model-serving\"&gt;LLM serving endpoint&lt;/a&gt;. This is fairly new stuff coming from them, it&amp;#39;s still in public preview, but it can leverage LLama-2, keeps the data on databricks side so it seems secure. (GDPR says hello.)&lt;/p&gt;\n\n&lt;p&gt;I found of course Pandas AI, that could be useful in combination with databricks somehow? I also found this &lt;a href=\"https://arxiv.org/pdf/2401.04398v1.pdf\"&gt;fairly recent paper&lt;/a&gt;, which talks about &amp;quot;Evolving chain for table reasoning&amp;quot; on L&lt;a href=\"https://www.linkedin.com/posts/llamaindex_chain-of-table-use-llms-to-understand-activity-7151983658596229120-fOo3?utm_source=share&amp;amp;utm_medium=member_desktop\"&gt;LamaIndex linkedin page&lt;/a&gt; that proposes a chain-of-table querying that looks interesting. It seems something closer to what LangChain is doing. Some &lt;a href=\"https://medium.com\"&gt;medium.com&lt;/a&gt; articles i found: &lt;a href=\"https://medium.com/@murtuza753/using-llama-2-0-faiss-and-langchain-for-question-answering-on-your-own-data-682241488476\"&gt;1&lt;/a&gt; (this is about documents), &lt;a href=\"https://ameer-hakme.medium.com/unlocking-context-aware-insights-in-tabular-data-with-llms-and-langchain-fac1d33b5c6d\"&gt;2&lt;/a&gt; (this is about tabular data)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;A maybe functioning idea&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Okay so let&amp;#39;s see if the following makes sense, it is very highlever and very brainstormy:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Agree on with business what are the core questions they want to know from a report.&lt;/li&gt;\n&lt;li&gt;A LLama-2 model is setup in Databricks with serving endpoint&lt;/li&gt;\n&lt;li&gt;A job runs daily:\n\n&lt;ol&gt;\n&lt;li&gt;A report is ingested some magical data engineering-y way (my fellow data engineers know the pain)&lt;/li&gt;\n&lt;li&gt;Prompt engineering: do some setup with the LLM agent (no clue yet what could be needed, but it&amp;#39;s a good guess that this is required - to prevent hallucations, etc).&lt;/li&gt;\n&lt;li&gt;Prompts from business are loaded from some config file&lt;/li&gt;\n&lt;li&gt;Results are stored in a separate delta table with following schema:\n\n&lt;ol&gt;\n&lt;li&gt;Some primary key&lt;/li&gt;\n&lt;li&gt;Some report identifier&lt;/li&gt;\n&lt;li&gt;Business unit or stakeholder identifier&lt;/li&gt;\n&lt;li&gt;Prompt&lt;/li&gt;\n&lt;li&gt;Answer&lt;/li&gt;\n&lt;li&gt;Timestamp&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;A SQL Warehouse endpoint is available and can be queried (by PowerBI for example that gets the latest answers.)&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Problems and limitations&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How do we check if the answers are correct? Monitoring results is very blackbox-y at best. Ideally endusers needs to be trained on the purpose of the Report&amp;#39;s Digest is to highlight stuff, but they have to verify it themselves. Getting feedback from endusers can be also complicated&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Conclusion in an ideal world&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Business managers like to look at PowerBI reports, and with this new feature they get an immediate highlight of the day, the top 3 questions they always wanna know about comes with immedaite answers. &amp;quot;We have an increased count of customer service tickets compared to previous week&amp;quot;. The manager looks at the graph and it seems to verify this statement.&lt;/p&gt;\n\n&lt;p&gt;Engineer team walks into the sunset with cool music in background&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?auto=webp&amp;s=41fa146938cd97da5abfeff0d092a2cc151e65fa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3881e36da92b82c6947f6ca4ff3804ca47f2aea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17b5b01e50a969ac9e2353bebb062cd52a99d108", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=acadaf004e8aeb6919eabdb0d93065a34f7e89df", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=883009d39175a2f03b76275ed0f7c6011d94a3a7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc62aef83f192d102fa78c83c8f4fcfa85057e3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/CcTKId6ti1J-bMqj-jlWVD1tyE1LbM9FagmfDfaIVmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ca6913f202be9a9f83b266dd459edc90adbf9dd", "width": 1080, "height": 567}], "variants": {}, "id": "RCFh0Kid3SAqWEkALMGNW1e9Vu6ayZpftekoayP00hY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "196nl41", "is_robot_indexable": true, "report_reasons": null, "author": "Labanc_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/196nl41/using_llms_to_draw_simple_insight_from_tabular/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196nl41/using_llms_to_draw_simple_insight_from_tabular/", "subreddit_subscribers": 152875, "created_utc": 1705259690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi ,\n\nI have been working as bi/etl , data engineer for 15 years . Recently i took up business system analyst role. Will it be beneficial for my career in case I want to pivot back to data engineer or will it hurt my profile. The thing is Iam not sure I would be good at being business system analyst and was thinking to go back to data engineering in cloud in case things don\u2019t work out.", "author_fullname": "t2_rcdiz5r9c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I move back to data engineering from a business system analyst role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_196ngi6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705259359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi ,&lt;/p&gt;\n\n&lt;p&gt;I have been working as bi/etl , data engineer for 15 years . Recently i took up business system analyst role. Will it be beneficial for my career in case I want to pivot back to data engineer or will it hurt my profile. The thing is Iam not sure I would be good at being business system analyst and was thinking to go back to data engineering in cloud in case things don\u2019t work out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "196ngi6", "is_robot_indexable": true, "report_reasons": null, "author": "InstanceSea05", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196ngi6/how_can_i_move_back_to_data_engineering_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196ngi6/how_can_i_move_back_to_data_engineering_from_a/", "subreddit_subscribers": 152875, "created_utc": 1705259359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Posting here as I'm not big into the DE world, but figure yall probably know where noobs like me could find data sets to brush up with.  \n\nDoes anyone know if there are any downloadable data sets for downloads of open source packages? NPM / Maven / Composer / etc \u2013 any statistics like that would be helpful!\n\n&amp;#x200B;\n\nP.s. I know I could try harvesting from APIs, but there's a LOT of stats to download, and I can't help but imagine someone's done this.", "author_fullname": "t2_n1kbf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data sets for Open Source package downloads (Maven / NPM / etc)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196kexn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705251589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Posting here as I&amp;#39;m not big into the DE world, but figure yall probably know where noobs like me could find data sets to brush up with.  &lt;/p&gt;\n\n&lt;p&gt;Does anyone know if there are any downloadable data sets for downloads of open source packages? NPM / Maven / Composer / etc \u2013 any statistics like that would be helpful!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;P.s. I know I could try harvesting from APIs, but there&amp;#39;s a LOT of stats to download, and I can&amp;#39;t help but imagine someone&amp;#39;s done this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "196kexn", "is_robot_indexable": true, "report_reasons": null, "author": "dwelch2344", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196kexn/data_sets_for_open_source_package_downloads_maven/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196kexn/data_sets_for_open_source_package_downloads_maven/", "subreddit_subscribers": 152875, "created_utc": 1705251589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Kedro is often overlooked in Data Science projects despite offering structure, caching and tracking datasets, MLOps features as well as powerfull intergrations with other Data tools", "author_fullname": "t2_vbapbjo8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kedro Intro and Hello World example", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_196gjd0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/r-oQ701wgDQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Kedro Intro and Hello World example\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Kedro Intro and Hello World example", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/r-oQ701wgDQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Kedro Intro and Hello World example\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/r-oQ701wgDQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/r-oQ701wgDQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Kedro Intro and Hello World example\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/196gjd0", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lEaH4fdOaFUim4MSa1dMXoEXZnisdrqh46i-mO9dpwE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705240892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kedro is often overlooked in Data Science projects despite offering structure, caching and tracking datasets, MLOps features as well as powerfull intergrations with other Data tools&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/r-oQ701wgDQ?si=roh4zqGCb7pithUY", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6Fr1bqghrzjNeHGjCmNPl2IwtpoJ68OtMVimm8CYA7U.jpg?auto=webp&amp;s=c8a24bf13665b37f042154cdde85fb28c250c98d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/6Fr1bqghrzjNeHGjCmNPl2IwtpoJ68OtMVimm8CYA7U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7fdd1cc5a2ddc5ae95e23b021f4eb4cf621f962b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/6Fr1bqghrzjNeHGjCmNPl2IwtpoJ68OtMVimm8CYA7U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=711d0a99e36cba6734cf4ab86a80970eb3e789d2", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/6Fr1bqghrzjNeHGjCmNPl2IwtpoJ68OtMVimm8CYA7U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=29f32d1da2077405987e79acb96813efac6719d2", "width": 320, "height": 240}], "variants": {}, "id": "v_XpU9SkWBZnhYuzYwDmOvhQLE6L9_ed2E4WBP_NL1Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "196gjd0", "is_robot_indexable": true, "report_reasons": null, "author": "dnulcon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196gjd0/kedro_intro_and_hello_world_example/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/r-oQ701wgDQ?si=roh4zqGCb7pithUY", "subreddit_subscribers": 152875, "created_utc": 1705240892.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Kedro Intro and Hello World example", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/r-oQ701wgDQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Kedro Intro and Hello World example\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/r-oQ701wgDQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI'm following a Microsoft Tutorial on MS Fabric. I'm working on an ETL process using Azure Blob Storage and Apache Spark, and I've come across a step in the process that I'm trying to understand better. The workflow involves reading a large dataset from Azure Blob Storage, processing it, and then writing the first 1000 rows of this dataset back to Blob Storage. After this, the script reads this subset again, performs further transformations, and finally loads it into a Delta table.\n\nMy question is: What could be the rationale for writing a subset of the data (1000 rows) back to Azure Blob Storage, only to read it again for further processing and loading into a Delta table? Are there specific benefits or use cases for this approach, such as performance optimization, data segmentation, or testing purposes that I might be overlooking?. Here is the link to the tutorial:  \n\n\n[https://microsoftlearning.github.io/mslearn-fabric/Instructions/Labs/10-ingest-notebooks.html](https://microsoftlearning.github.io/mslearn-fabric/Instructions/Labs/10-ingest-notebooks.html)\n\nAny insights or experiences you can share regarding this method would be greatly appreciated, especially if there are more direct or efficient ways to handle such a workflow.\n\nThanks in advance.", "author_fullname": "t2_7r901d2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding the Rationale Behind Writing Subset of Data Back to Azure Blob in ETL Process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_196eln8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705234509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m following a Microsoft Tutorial on MS Fabric. I&amp;#39;m working on an ETL process using Azure Blob Storage and Apache Spark, and I&amp;#39;ve come across a step in the process that I&amp;#39;m trying to understand better. The workflow involves reading a large dataset from Azure Blob Storage, processing it, and then writing the first 1000 rows of this dataset back to Blob Storage. After this, the script reads this subset again, performs further transformations, and finally loads it into a Delta table.&lt;/p&gt;\n\n&lt;p&gt;My question is: What could be the rationale for writing a subset of the data (1000 rows) back to Azure Blob Storage, only to read it again for further processing and loading into a Delta table? Are there specific benefits or use cases for this approach, such as performance optimization, data segmentation, or testing purposes that I might be overlooking?. Here is the link to the tutorial:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://microsoftlearning.github.io/mslearn-fabric/Instructions/Labs/10-ingest-notebooks.html\"&gt;https://microsoftlearning.github.io/mslearn-fabric/Instructions/Labs/10-ingest-notebooks.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any insights or experiences you can share regarding this method would be greatly appreciated, especially if there are more direct or efficient ways to handle such a workflow.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "196eln8", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Necessary-6455", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/196eln8/understanding_the_rationale_behind_writing_subset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/196eln8/understanding_the_rationale_behind_writing_subset/", "subreddit_subscribers": 152875, "created_utc": 1705234509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow redditors!\n\nSo I\u2019m beginning to get interested in building streaming pipelines. Things like a near real-time data ingestion (a bronze table, for instance), silver tables or even building near real-time specialized datasets (gold datasets).\n\nI know from some researches that in service oriented architectures companies use apache kafka as a integration layer/hub for consumers and producers.\n\nAs far as I\u2019m aware a producer generates some event and sends it for the kafka broker and the consumer can process it right after, and depending on the architecture the consumer even deletes (?) the event that already has been processed to avoid duplication.\n\nIf I\u2019m a data engineer interested in the data that this producer pushed to kafka, how would I reliably get access to this data, without intruding into the integration between the microservices? \n\nI\u2019m looking into kafka connect as something that tries to solve this issue, but I\u2019m quite unsure.\n\nCan someone with more experience in these streaming context bring some light to the subject?", "author_fullname": "t2_5fmit0v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming Pipelines Architecture with Kafka and Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195z6b2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705182606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow redditors!&lt;/p&gt;\n\n&lt;p&gt;So I\u2019m beginning to get interested in building streaming pipelines. Things like a near real-time data ingestion (a bronze table, for instance), silver tables or even building near real-time specialized datasets (gold datasets).&lt;/p&gt;\n\n&lt;p&gt;I know from some researches that in service oriented architectures companies use apache kafka as a integration layer/hub for consumers and producers.&lt;/p&gt;\n\n&lt;p&gt;As far as I\u2019m aware a producer generates some event and sends it for the kafka broker and the consumer can process it right after, and depending on the architecture the consumer even deletes (?) the event that already has been processed to avoid duplication.&lt;/p&gt;\n\n&lt;p&gt;If I\u2019m a data engineer interested in the data that this producer pushed to kafka, how would I reliably get access to this data, without intruding into the integration between the microservices? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking into kafka connect as something that tries to solve this issue, but I\u2019m quite unsure.&lt;/p&gt;\n\n&lt;p&gt;Can someone with more experience in these streaming context bring some light to the subject?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195z6b2", "is_robot_indexable": true, "report_reasons": null, "author": "gabbom_XCII", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195z6b2/streaming_pipelines_architecture_with_kafka_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195z6b2/streaming_pipelines_architecture_with_kafka_and/", "subreddit_subscribers": 152875, "created_utc": 1705182606.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}