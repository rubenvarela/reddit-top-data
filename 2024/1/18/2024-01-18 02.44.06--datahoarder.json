{"kind": "Listing", "data": {"after": "t3_198nlx9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://secure.runescape.com/m=news/an-update-regarding-our-forums\n\nhttps://secure.runescape.com/m=forum/forums\n\nIs it possible to download all of the contents somewhere before they close for good?", "author_fullname": "t2_ybwlb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The official runescape forums are closing down for good. Decades worth of information is being deleted. Is there any way to back everything up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198m42v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 340, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 340, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705460352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://secure.runescape.com/m=news/an-update-regarding-our-forums\"&gt;https://secure.runescape.com/m=news/an-update-regarding-our-forums&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://secure.runescape.com/m=forum/forums\"&gt;https://secure.runescape.com/m=forum/forums&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is it possible to download all of the contents somewhere before they close for good?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XKBZnPyy41iV1uAc9X4Mm7bh9AXwsAPQXwubsaFH3t0.jpg?auto=webp&amp;s=3b765e552549c446512e41d81118d15d5c9b107e", "width": 629, "height": 255}, "resolutions": [{"url": "https://external-preview.redd.it/XKBZnPyy41iV1uAc9X4Mm7bh9AXwsAPQXwubsaFH3t0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e87a2f9eaf743b213056c36b5cf3fc770e2fa6d", "width": 108, "height": 43}, {"url": "https://external-preview.redd.it/XKBZnPyy41iV1uAc9X4Mm7bh9AXwsAPQXwubsaFH3t0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef4ee870b9aaca4632bcaeb99125d166ed6bac1f", "width": 216, "height": 87}, {"url": "https://external-preview.redd.it/XKBZnPyy41iV1uAc9X4Mm7bh9AXwsAPQXwubsaFH3t0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31f0b4edaaa91cc8181045e79367a6cc926d567f", "width": 320, "height": 129}], "variants": {}, "id": "NztJJyCjHFYvUc5xyb38IeKVCGJQui-6yQ2sVMUhk2M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198m42v", "is_robot_indexable": true, "report_reasons": null, "author": "Monterey-Jack", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198m42v/the_official_runescape_forums_are_closing_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198m42v/the_official_runescape_forums_are_closing_down/", "subreddit_subscribers": 725947, "created_utc": 1705460352.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_624hy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "1 month ago I got the itch and decided to become one of you - Built my own NAS + Unraid and 32TB later I have my little beast!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"l945rs657ycc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/l945rs657ycc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6c326fcfa34831781429b1bb4780b90a00cf32f0"}, {"y": 142, "x": 216, "u": "https://preview.redd.it/l945rs657ycc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f30c0f3a2b0a331713717266ee7acd0a3582740"}, {"y": 211, "x": 320, "u": "https://preview.redd.it/l945rs657ycc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f84a15500777af3a5299f9dd120a798a501b495"}, {"y": 423, "x": 640, "u": "https://preview.redd.it/l945rs657ycc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=144ab00d4fb33dbb3999f72f139157d7c21bf11c"}, {"y": 635, "x": 960, "u": "https://preview.redd.it/l945rs657ycc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bfaf1225f340600a967b56a611278727aeef9ecb"}, {"y": 714, "x": 1080, "u": "https://preview.redd.it/l945rs657ycc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5bbc7b0a038252cd1a9d1137562038ddefad9a96"}], "s": {"y": 1037, "x": 1567, "u": "https://preview.redd.it/l945rs657ycc1.png?width=1567&amp;format=png&amp;auto=webp&amp;s=e88e590063961433d907f4eb2a3c79879e38e539"}, "id": "l945rs657ycc1"}, "b6cjfr657ycc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/b6cjfr657ycc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab10aea3330e493e12cbe6585cc879e768df8bac"}, {"y": 232, "x": 216, "u": "https://preview.redd.it/b6cjfr657ycc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7612b5c98f71f11e739743317193be332b6dc934"}, {"y": 343, "x": 320, "u": "https://preview.redd.it/b6cjfr657ycc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ffde7f6c56f756b17d742bbfa40dd345a38fc9c4"}, {"y": 687, "x": 640, "u": "https://preview.redd.it/b6cjfr657ycc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=abb308e244f50139783780e6359348d8af32e12d"}], "s": {"y": 996, "x": 927, "u": "https://preview.redd.it/b6cjfr657ycc1.png?width=927&amp;format=png&amp;auto=webp&amp;s=6ad1ce24f17ea7e3f2a2469aa4e6857302327a13"}, "id": "b6cjfr657ycc1"}, "rybipp657ycc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/rybipp657ycc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc75f363abb469937686cb03549486a8a0f50adf"}, {"y": 76, "x": 216, "u": "https://preview.redd.it/rybipp657ycc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f238d22a8f1ae8dbd954ee0c3a81f3ee76b07a4"}, {"y": 113, "x": 320, "u": "https://preview.redd.it/rybipp657ycc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f472c687d774cbaa09621f8c07ab9d909297424"}, {"y": 226, "x": 640, "u": "https://preview.redd.it/rybipp657ycc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bac42c983db40eb5e43a0b9e7211ff78c0a1fa6b"}, {"y": 339, "x": 960, "u": "https://preview.redd.it/rybipp657ycc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bf661b646c329e085b7d0faa90679beebed3def1"}, {"y": 382, "x": 1080, "u": "https://preview.redd.it/rybipp657ycc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6d22caa18c700b16a6912f0edb566357b127972d"}], "s": {"y": 687, "x": 1941, "u": "https://preview.redd.it/rybipp657ycc1.png?width=1941&amp;format=png&amp;auto=webp&amp;s=3515933c02a5bfe9ec63115817e05adf82ac839b"}, "id": "rybipp657ycc1"}}, "name": "t3_198qfoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 122, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "b6cjfr657ycc1", "id": 390706213}, {"media_id": "l945rs657ycc1", "id": 390706214}, {"media_id": "rybipp657ycc1", "id": 390706215}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 122, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-XbbB9f0uzga0ysuMbG8L-2z-nZZ4FhTOExW2k66y9k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705474481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/198qfoc", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198qfoc", "is_robot_indexable": true, "report_reasons": null, "author": "strich", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198qfoc/1_month_ago_i_got_the_itch_and_decided_to_become/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/198qfoc", "subreddit_subscribers": 725947, "created_utc": 1705474481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_afj5b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit must share IP addresses of piracy-discussing users, film studios say (Reddit Refuses)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_199ah69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 147, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 147, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UberXAJ3MkHEHzZm4RHZudlvQ5tA_JO85MzfwPUwUZc.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705532282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arstechnica.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arstechnica.com/tech-policy/2024/01/film-studios-demand-ip-addresses-of-people-who-discussed-piracy-on-reddit/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?auto=webp&amp;s=283e75c3e435a26092b20456e0e6f04e45f033e1", "width": 760, "height": 380}, "resolutions": [{"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c203afa0163b8be5a52fc05b552bf0a140fa975d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8994b7291c4eb722a7220d0633fb429ce8918f65", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34bc9278c53cd476ff4c14855746243d73e2046a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5213d11b79df959651527e87463c565156e924e", "width": 640, "height": 320}], "variants": {}, "id": "Unj7h3l6SCdChsZkFY4Xe_7dlOcCiz9mmZd2X6YpmPQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "2075+TB ZFS", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199ah69", "is_robot_indexable": true, "report_reasons": null, "author": "EchoGecko795", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/199ah69/reddit_must_share_ip_addresses_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arstechnica.com/tech-policy/2024/01/film-studios-demand-ip-addresses-of-people-who-discussed-piracy-on-reddit/", "subreddit_subscribers": 725947, "created_utc": 1705532282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looks like 30 TB CMR drives will be available to end users soon, initial estimates are at a cost of $450 ($15/TB)", "author_fullname": "t2_gdylz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Unveils Mozaic 3+ HDD Platform as HAMR Readies for Volume Ramp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1991f8h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yQIqrXtkh8I_eVpCxR76kkBW_E0kWnmvLNPL-O6vn6M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705510725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "anandtech.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looks like 30 TB CMR drives will be available to end users soon, initial estimates are at a cost of $450 ($15/TB)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.anandtech.com/show/21235/seagate-unveils-mozaic-3-hdd-platform-as-hamr-readies-for-volume-ramp", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NIk0koIKrqMl8MMsoQwuFM1CuVxjVvZpyptZ_XFPbQc.jpg?auto=webp&amp;s=62ad888e9582935239d5995ce13bc49554e84f8e", "width": 678, "height": 454}, "resolutions": [{"url": "https://external-preview.redd.it/NIk0koIKrqMl8MMsoQwuFM1CuVxjVvZpyptZ_XFPbQc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=539b551cd7e001391733b06321faca42a764d289", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/NIk0koIKrqMl8MMsoQwuFM1CuVxjVvZpyptZ_XFPbQc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=210e413c1dfd9e6fac0a3ce066a4b1fa76aec7b5", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/NIk0koIKrqMl8MMsoQwuFM1CuVxjVvZpyptZ_XFPbQc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26ec095d38679f2f4f292ab95971cab9e6431a4f", "width": 320, "height": 214}, {"url": "https://external-preview.redd.it/NIk0koIKrqMl8MMsoQwuFM1CuVxjVvZpyptZ_XFPbQc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=326cd7292d9dce93469d911ad517962f0cfebd1c", "width": 640, "height": 428}], "variants": {}, "id": "NBsCzkYjW9BeOLzrNst8GXyGl5iuPqtIDVB0wm_Jki0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1991f8h", "is_robot_indexable": true, "report_reasons": null, "author": "Robotater", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1991f8h/seagate_unveils_mozaic_3_hdd_platform_as_hamr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.anandtech.com/show/21235/seagate-unveils-mozaic-3-hdd-platform-as-hamr-readies-for-volume-ramp", "subreddit_subscribers": 725947, "created_utc": 1705510725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is the H.264 vs 265 something that is already on the source disc?  In other words, you don't need to control the type of compression on a rip, it's just going to get whatever it's already got?\n\nAnd if you want to do a 1:1 rip with no compression, what option is what in something like MakeMKV or DVDFab?  Watching some videos, I think that \"MKV Passthrough\" is what is needed for a 1:1 rip?", "author_fullname": "t2_16fj1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ripping BD and UHD to MKV - Compression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1999bob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705530717.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705529401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is the H.264 vs 265 something that is already on the source disc?  In other words, you don&amp;#39;t need to control the type of compression on a rip, it&amp;#39;s just going to get whatever it&amp;#39;s already got?&lt;/p&gt;\n\n&lt;p&gt;And if you want to do a 1:1 rip with no compression, what option is what in something like MakeMKV or DVDFab?  Watching some videos, I think that &amp;quot;MKV Passthrough&amp;quot; is what is needed for a 1:1 rip?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1999bob", "is_robot_indexable": true, "report_reasons": null, "author": "_Nismo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1999bob/ripping_bd_and_uhd_to_mkv_compression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1999bob/ripping_bd_and_uhd_to_mkv_compression/", "subreddit_subscribers": 725947, "created_utc": 1705529401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "TL:DR, I\u2019ve binged too much YouTube (and this forum) and am in decision paralysis for my first NAS. \n\nBackground:\nI\u2019m downsizing and have digitized a reasonable DVD library, along with many disparate hard drives of photos over the years. Looking for a basic NAS setup with reasonable RAM and M.2 capability for data pools for file sharing and a Plex library for both at-home and away access. \nAdditionally, I\u2019m looking to keep to exclusively SSD drives (so likely 4tb 2.5 in drives) for noise and heat limitations. \nI have 9tb now (across a bunch of drives) so thinking a 4-5 bay enclosure. Not super driven toward high-speed access or write speeds as there won\u2019t be a ton of traffic, but a fair amount of streaming. \n\nWas considering the Synology DS923+ but am fearful of using non-Synology drives in the unit (since their \u201capproved\u201d drives are only Synology\u2026 I think)\n\nAny direction would be super appreciated. Thank you!", "author_fullname": "t2_mj5dqg8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drowning in Information, suggestions for my first NAS setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198nzgn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705466021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL:DR, I\u2019ve binged too much YouTube (and this forum) and am in decision paralysis for my first NAS. &lt;/p&gt;\n\n&lt;p&gt;Background:\nI\u2019m downsizing and have digitized a reasonable DVD library, along with many disparate hard drives of photos over the years. Looking for a basic NAS setup with reasonable RAM and M.2 capability for data pools for file sharing and a Plex library for both at-home and away access. \nAdditionally, I\u2019m looking to keep to exclusively SSD drives (so likely 4tb 2.5 in drives) for noise and heat limitations. \nI have 9tb now (across a bunch of drives) so thinking a 4-5 bay enclosure. Not super driven toward high-speed access or write speeds as there won\u2019t be a ton of traffic, but a fair amount of streaming. &lt;/p&gt;\n\n&lt;p&gt;Was considering the Synology DS923+ but am fearful of using non-Synology drives in the unit (since their \u201capproved\u201d drives are only Synology\u2026 I think)&lt;/p&gt;\n\n&lt;p&gt;Any direction would be super appreciated. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198nzgn", "is_robot_indexable": true, "report_reasons": null, "author": "HistoricalReturn6468", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198nzgn/drowning_in_information_suggestions_for_my_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198nzgn/drowning_in_information_suggestions_for_my_first/", "subreddit_subscribers": 725947, "created_utc": 1705466021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've seen some users recommend Macrium Reflect to clone an OS drive, but from my understanding this would rewrite the entire HDD when copying the OS drive over. If this doesn't happen and I'm wrong that would be great! Otherwise, if I want to copy my boot drive with the OS, along with other non-boot drives all onto one HDD roughly once a week for backups, what is my best option?", "author_fullname": "t2_9l9ghq60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to regularly copy Boot drive and multiple drives to One HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199ak3x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705532809.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705532478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen some users recommend Macrium Reflect to clone an OS drive, but from my understanding this would rewrite the entire HDD when copying the OS drive over. If this doesn&amp;#39;t happen and I&amp;#39;m wrong that would be great! Otherwise, if I want to copy my boot drive with the OS, along with other non-boot drives all onto one HDD roughly once a week for backups, what is my best option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199ak3x", "is_robot_indexable": true, "report_reasons": null, "author": "jordanisplaying", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199ak3x/how_to_regularly_copy_boot_drive_and_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199ak3x/how_to_regularly_copy_boot_drive_and_multiple/", "subreddit_subscribers": 725947, "created_utc": 1705532478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a couple of these drives still in their original enclosure and I would like to shuck them to use with my ugreen enclosure. I'm not a big fan of the WD enclosure so was just wondering if anyone else shucks them to use in another enclosure and whether their would be any risk shucking and using in another enclosure?", "author_fullname": "t2_5dkgegkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shucking WD 18tb Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1995w5c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705521165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a couple of these drives still in their original enclosure and I would like to shuck them to use with my ugreen enclosure. I&amp;#39;m not a big fan of the WD enclosure so was just wondering if anyone else shucks them to use in another enclosure and whether their would be any risk shucking and using in another enclosure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1995w5c", "is_robot_indexable": true, "report_reasons": null, "author": "craftywizard1983", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1995w5c/shucking_wd_18tb_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1995w5c/shucking_wd_18tb_drive/", "subreddit_subscribers": 725947, "created_utc": 1705521165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone,\n\nI just got a Synology that I've put **four 18 TB HDDs** into. I'm trying to decide whether to go with **SHR-1 or SHR-2** (Synology's equivalent of RAID5 and RAID6).\n\nI have read previously on this sub about the probability of a failure during array rebuild after a disk goes down for parity raid, and I believe I'm at the drive capacity where it begins to matter. **I'm wondering what the math is behind the probability of failure during RAID rebuild**, perhaps as a function of both drive capacity and URE.\n\nI've noticed in recent articles about this issue that a URE of 1e14 is often cited, but I'm running Seagate Exos which have a URE of 1e15 which I think might put a rebuild failure in a sufficiently unlikely scenario to just opt for the RAID5 verison.\n\nAnyway, any insight into failure probabilities is very much appreciated!\n\n&amp;#x200B;\n\nP.S. For additional context, I'm planning on backing up essential files to the cloud as well as nightly syncs to a TrueNAS server once I get that up and running, as well as monthly cold backups.", "author_fullname": "t2_kqraiwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID5/6 failure during rebuild math", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198lleq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705458885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I just got a Synology that I&amp;#39;ve put &lt;strong&gt;four 18 TB HDDs&lt;/strong&gt; into. I&amp;#39;m trying to decide whether to go with &lt;strong&gt;SHR-1 or SHR-2&lt;/strong&gt; (Synology&amp;#39;s equivalent of RAID5 and RAID6).&lt;/p&gt;\n\n&lt;p&gt;I have read previously on this sub about the probability of a failure during array rebuild after a disk goes down for parity raid, and I believe I&amp;#39;m at the drive capacity where it begins to matter. &lt;strong&gt;I&amp;#39;m wondering what the math is behind the probability of failure during RAID rebuild&lt;/strong&gt;, perhaps as a function of both drive capacity and URE.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve noticed in recent articles about this issue that a URE of 1e14 is often cited, but I&amp;#39;m running Seagate Exos which have a URE of 1e15 which I think might put a rebuild failure in a sufficiently unlikely scenario to just opt for the RAID5 verison.&lt;/p&gt;\n\n&lt;p&gt;Anyway, any insight into failure probabilities is very much appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;P.S. For additional context, I&amp;#39;m planning on backing up essential files to the cloud as well as nightly syncs to a TrueNAS server once I get that up and running, as well as monthly cold backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198lleq", "is_robot_indexable": true, "report_reasons": null, "author": "FiziksMayMays", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198lleq/raid56_failure_during_rebuild_math/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198lleq/raid56_failure_during_rebuild_math/", "subreddit_subscribers": 725947, "created_utc": 1705458885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all I am new to hoarding and have run into the worst thing to happen; file corruption.\n\nOn an external 3 TB exFAT SSD, there is a single directory with around 10k images/videos (totaling to something like 3 gigs) which has been corrupted. The rest of the drive works fine (and I have backed it all up already), but when trying to access that specific directory, I get \"The file or directory is corrupted and unreadable.\"  \n\n\nI have tried running chkdsk for about 3 days straight, as well as tools like Stellar, but it keeps on running and I assume the huge driver size isn't doing me any favors.\n\nIs there a way or tool that can attempt recovery inside specific folders only? Any insights and tips would be greatly appreciated", "author_fullname": "t2_2amfgvyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to isolate folders for corruption recovery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1995fd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705520065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all I am new to hoarding and have run into the worst thing to happen; file corruption.&lt;/p&gt;\n\n&lt;p&gt;On an external 3 TB exFAT SSD, there is a single directory with around 10k images/videos (totaling to something like 3 gigs) which has been corrupted. The rest of the drive works fine (and I have backed it all up already), but when trying to access that specific directory, I get &amp;quot;The file or directory is corrupted and unreadable.&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;I have tried running chkdsk for about 3 days straight, as well as tools like Stellar, but it keeps on running and I assume the huge driver size isn&amp;#39;t doing me any favors.&lt;/p&gt;\n\n&lt;p&gt;Is there a way or tool that can attempt recovery inside specific folders only? Any insights and tips would be greatly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1995fd5", "is_robot_indexable": true, "report_reasons": null, "author": "IlliquidFabricator", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1995fd5/is_there_a_way_to_isolate_folders_for_corruption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1995fd5/is_there_a_way_to_isolate_folders_for_corruption/", "subreddit_subscribers": 725947, "created_utc": 1705520065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm looking for the best quality Windows 11-compatible VHS capture device. Can anyone suggest one to go with? Elgato and Dazzle do not function with it.", "author_fullname": "t2_dtf8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows 11 compatible VHS capture devices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1993w9k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705516416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking for the best quality Windows 11-compatible VHS capture device. Can anyone suggest one to go with? Elgato and Dazzle do not function with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1993w9k", "is_robot_indexable": true, "report_reasons": null, "author": "Half_Aborted", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1993w9k/windows_11_compatible_vhs_capture_devices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1993w9k/windows_11_compatible_vhs_capture_devices/", "subreddit_subscribers": 725947, "created_utc": 1705516416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two seperate kodi machines in two different locations, both play movies from external hdd's. One of them is on a TV that doesn't do UHD. Is there anything out there that can split my library up into HD and UHD folders so that I'm not accidentally sending UHD files to the TV that can't play them?", "author_fullname": "t2_5sobum3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to automatically seperate the UHD (h.265) from the HD (h.264) files in my media library on a windows based pc?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19917kz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705510228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two seperate kodi machines in two different locations, both play movies from external hdd&amp;#39;s. One of them is on a TV that doesn&amp;#39;t do UHD. Is there anything out there that can split my library up into HD and UHD folders so that I&amp;#39;m not accidentally sending UHD files to the TV that can&amp;#39;t play them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19917kz", "is_robot_indexable": true, "report_reasons": null, "author": "ForagerGrikk", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19917kz/is_there_a_way_to_automatically_seperate_the_uhd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19917kz/is_there_a_way_to_automatically_seperate_the_uhd/", "subreddit_subscribers": 725947, "created_utc": 1705510228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently running a RaidZ1 pool with two 1tb HDDs and one 2tb HDD, it's working fine even with the data loss from the 2tb. But I'm wondering what you would do in expanding the storage. Is there a way to make the 3 HDDs into a 4tb block and then expand with new 4tb drives or would you keep expanding with 1tb drives? I got these drives for free, but I'd hate for them to go to waste. Is there a configuration where I could expand with these drives or am I out of luck and better off just getting a pair of the size I'm looking for?", "author_fullname": "t2_s8c96a698", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you do with this set up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198nvks", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705465674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently running a RaidZ1 pool with two 1tb HDDs and one 2tb HDD, it&amp;#39;s working fine even with the data loss from the 2tb. But I&amp;#39;m wondering what you would do in expanding the storage. Is there a way to make the 3 HDDs into a 4tb block and then expand with new 4tb drives or would you keep expanding with 1tb drives? I got these drives for free, but I&amp;#39;d hate for them to go to waste. Is there a configuration where I could expand with these drives or am I out of luck and better off just getting a pair of the size I&amp;#39;m looking for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198nvks", "is_robot_indexable": true, "report_reasons": null, "author": "confuseddatanovice", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198nvks/what_would_you_do_with_this_set_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198nvks/what_would_you_do_with_this_set_up/", "subreddit_subscribers": 725947, "created_utc": 1705465674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am having issues getting a brand new WD Gold 12TB drive to work in my Windows 10 Pro computer which has a decently recent motherboard (MSI X570 Gaming Plus, flashed latest BIOS). The disk is recognized no problem in the BIOS and in Windows, including with the WD Dashboard tool.  Correct capacity and everything.  However, when I go to Disk Management, it already was showing a 2TB partition and a 9TB partition.  Besides initializing with GPT, I could then not do anything else in Disk Management, everything was greyed out.  So I tried a couple of different partitioning softwares and they would always either fail or complete, but not actually do anything.  I tried diskpart and had similar results, but it would say i/o error.  I ran SMART and it was fine.  In looking around, I read about the new issue with \"Power Disable\" on the SATA power connectors, but this doesn't seem to apply because my disk was powering on no problem and recognized (I tried the molex adapter trick, and there was no change).\n\nI decided to take it to work and pop it in our \"enterprise grade\" server running Windows Server 2022 and using diskpart, I was able to set GPT, clean it, and create a 12TB NTFS partition right away.  I set if offline, removed it, and brought it home, but Disk Mangement immediately was showing the 2TB/9TB thing, and the partitioning software was able to read the drive label I had added, but it would not let me set a drive letter (however, it was showing the 12TB partition properly in the partition software).  Tried a few more things, but clearly there is some incompatibility here, or I'm hitting a limit in Win 10 Pro?\n\nAny suggestions would be greatly appreciated, thanks!", "author_fullname": "t2_qzir1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weird WD Gold problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199bic6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705534939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am having issues getting a brand new WD Gold 12TB drive to work in my Windows 10 Pro computer which has a decently recent motherboard (MSI X570 Gaming Plus, flashed latest BIOS). The disk is recognized no problem in the BIOS and in Windows, including with the WD Dashboard tool.  Correct capacity and everything.  However, when I go to Disk Management, it already was showing a 2TB partition and a 9TB partition.  Besides initializing with GPT, I could then not do anything else in Disk Management, everything was greyed out.  So I tried a couple of different partitioning softwares and they would always either fail or complete, but not actually do anything.  I tried diskpart and had similar results, but it would say i/o error.  I ran SMART and it was fine.  In looking around, I read about the new issue with &amp;quot;Power Disable&amp;quot; on the SATA power connectors, but this doesn&amp;#39;t seem to apply because my disk was powering on no problem and recognized (I tried the molex adapter trick, and there was no change).&lt;/p&gt;\n\n&lt;p&gt;I decided to take it to work and pop it in our &amp;quot;enterprise grade&amp;quot; server running Windows Server 2022 and using diskpart, I was able to set GPT, clean it, and create a 12TB NTFS partition right away.  I set if offline, removed it, and brought it home, but Disk Mangement immediately was showing the 2TB/9TB thing, and the partitioning software was able to read the drive label I had added, but it would not let me set a drive letter (however, it was showing the 12TB partition properly in the partition software).  Tried a few more things, but clearly there is some incompatibility here, or I&amp;#39;m hitting a limit in Win 10 Pro?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199bic6", "is_robot_indexable": true, "report_reasons": null, "author": "eyecannon", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199bic6/weird_wd_gold_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199bic6/weird_wd_gold_problem/", "subreddit_subscribers": 725947, "created_utc": 1705534939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The closure of Beyond3D.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1996b48", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_jonsu", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jUae2zOxQoc-o4MB_DNAKeoV0P3ZYlEGLMAOT3HE1Ig.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "hardware", "selftext": "", "author_fullname": "t2_81y6hxs0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The closure of Beyond3D.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/hardware", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_198w32c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 101, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 101, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jUae2zOxQoc-o4MB_DNAKeoV0P3ZYlEGLMAOT3HE1Ig.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705496660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "forum.beyond3d.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://forum.beyond3d.com/threads/the-closure-of-beyond3d.63478/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?auto=webp&amp;s=a32c2466f76ce4dc1a039bfd2e56da6e261ef0de", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9da9dc020670dcf7c36e78ab0f6ab33926fde84", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5b6f49b2f1051f5a4511b3c8ca58d694bd005f62", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad0d12c26920c77116fc15b766ae2c10249495f7", "width": 320, "height": 320}], "variants": {}, "id": "4zTA237Us5pzFc1DQ4fB7gMVMwjsFpHHrSWjv5g_plY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e763e51e-c141-11e3-b9ac-12313d31e5b1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2qh18", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "198w32c", "is_robot_indexable": true, "report_reasons": null, "author": "ResponsibleJudge3172", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/hardware/comments/198w32c/the_closure_of_beyond3d/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://forum.beyond3d.com/threads/the-closure-of-beyond3d.63478/", "subreddit_subscribers": 3553104, "created_utc": 1705496660.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1705522132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "forum.beyond3d.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://forum.beyond3d.com/threads/the-closure-of-beyond3d.63478/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?auto=webp&amp;s=a32c2466f76ce4dc1a039bfd2e56da6e261ef0de", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9da9dc020670dcf7c36e78ab0f6ab33926fde84", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5b6f49b2f1051f5a4511b3c8ca58d694bd005f62", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad0d12c26920c77116fc15b766ae2c10249495f7", "width": 320, "height": 320}], "variants": {}, "id": "4zTA237Us5pzFc1DQ4fB7gMVMwjsFpHHrSWjv5g_plY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1996b48", "is_robot_indexable": true, "report_reasons": null, "author": "capn_hector", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_198w32c", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1996b48/the_closure_of_beyond3d/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://forum.beyond3d.com/threads/the-closure-of-beyond3d.63478/", "subreddit_subscribers": 725947, "created_utc": 1705522132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'll try and get to the point. My wife passed and I am looking to create a archive of all her files for long term storage. I have  cloned to SSD drives but want to also create a backup onto spinning disk. Her files all live on two Macs , one iPhone, one iPad, Google Drive, and USB drives/sticks.\n\nWhat would you recommend as a file system for long term storage and archive? I am thinking ext4 for the stand alone drives. I  plan on organizing and archiving to the cloud, and building a ZFS server. I am mainly a Mac user but I also run a couple Linux boxes.\n\nThanks for any suggestions.", "author_fullname": "t2_d4svi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File System for Archive on HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1994j97", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705517948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll try and get to the point. My wife passed and I am looking to create a archive of all her files for long term storage. I have  cloned to SSD drives but want to also create a backup onto spinning disk. Her files all live on two Macs , one iPhone, one iPad, Google Drive, and USB drives/sticks.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend as a file system for long term storage and archive? I am thinking ext4 for the stand alone drives. I  plan on organizing and archiving to the cloud, and building a ZFS server. I am mainly a Mac user but I also run a couple Linux boxes.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1994j97", "is_robot_indexable": true, "report_reasons": null, "author": "120r", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1994j97/file_system_for_archive_on_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1994j97/file_system_for_archive_on_hdd/", "subreddit_subscribers": 725947, "created_utc": 1705517948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have around 26 TB of storage capacity in a pool and planning to add another 8TB drive. However, I get the error: the physical disk sector size is not supported by the storage pool. Is due to the cluster size? I am currently using 8 KB for the pool. Do I need to increase to 16 KB? Is there a way to do it without migrating/formatting? \n\nAny help would be appreciated!\nThank you!", "author_fullname": "t2_128aay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows storage spaces error", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1994b6u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705517401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 26 TB of storage capacity in a pool and planning to add another 8TB drive. However, I get the error: the physical disk sector size is not supported by the storage pool. Is due to the cluster size? I am currently using 8 KB for the pool. Do I need to increase to 16 KB? Is there a way to do it without migrating/formatting? &lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated!\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1994b6u", "is_robot_indexable": true, "report_reasons": null, "author": "avii22", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1994b6u/windows_storage_spaces_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1994b6u/windows_storage_spaces_error/", "subreddit_subscribers": 725947, "created_utc": 1705517401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Thanks, EU! \n\nHere's the bit just announced, emphasis mine:\n\n&gt;**Data portability:** For over a decade we have offered users the  ability to download or transfer a copy of their data from more than 80  Google products. We continue to make investments in Google Takeout, the [Data Transfer Initiative](https://dtinit.org/)  and data portability more broadly. To meet new requirements around  moving your data to a third-party app or service, ***we will soon be testing a Data Portability API for developers*****.**\n\nsource: [https://blog.google/around-the-globe/google-europe/an-update-on-our-preparations-for-the-dma/](https://blog.google/around-the-globe/google-europe/an-update-on-our-preparations-for-the-dma/)", "author_fullname": "t2_gabfs0cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Takeout is getting an official API \u203d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199411o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705516733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks, EU! &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the bit just announced, emphasis mine:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;Data portability:&lt;/strong&gt; For over a decade we have offered users the  ability to download or transfer a copy of their data from more than 80  Google products. We continue to make investments in Google Takeout, the &lt;a href=\"https://dtinit.org/\"&gt;Data Transfer Initiative&lt;/a&gt;  and data portability more broadly. To meet new requirements around  moving your data to a third-party app or service, &lt;strong&gt;&lt;em&gt;we will soon be testing a Data Portability API for developers&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;source: &lt;a href=\"https://blog.google/around-the-globe/google-europe/an-update-on-our-preparations-for-the-dma/\"&gt;https://blog.google/around-the-globe/google-europe/an-update-on-our-preparations-for-the-dma/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199411o", "is_robot_indexable": true, "report_reasons": null, "author": "BestExtraLibrarian", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199411o/google_takeout_is_getting_an_official_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199411o/google_takeout_is_getting_an_official_api/", "subreddit_subscribers": 725947, "created_utc": 1705516733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone else been having issues with Yoyotta lately? Every time I do a spanning backup it ends up using significantly more tape storage than it should. I had a 7tb back to LTO 7 that should use up all 5.5tb on one tape then a part of a second one. Instead on the first tape it left 1.5tb unused which means it\u2019s going to need to use a much larger amount of storage on the second tape.\n\nThis same issue has been happening to me since October and customer support\u2019s answer was \u201ctry backing up smaller sizes.\u201d Then they stopped responding to my emails \ud83d\ude29\n\nFor context:\nMac OS Ventura 13.6\nYoyotta Version 3 (240)\nM-Logic M-Rack\n\nThanks for any help you guys have!", "author_fullname": "t2_rapfkoz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Yoyotta Spanning Backups Failing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1991oj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vFMZS8ieEH_0y3zJXxrDq8Dgim4KxEL5Ho9gKoDsUXI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705511270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone else been having issues with Yoyotta lately? Every time I do a spanning backup it ends up using significantly more tape storage than it should. I had a 7tb back to LTO 7 that should use up all 5.5tb on one tape then a part of a second one. Instead on the first tape it left 1.5tb unused which means it\u2019s going to need to use a much larger amount of storage on the second tape.&lt;/p&gt;\n\n&lt;p&gt;This same issue has been happening to me since October and customer support\u2019s answer was \u201ctry backing up smaller sizes.\u201d Then they stopped responding to my emails \ud83d\ude29&lt;/p&gt;\n\n&lt;p&gt;For context:\nMac OS Ventura 13.6\nYoyotta Version 3 (240)\nM-Logic M-Rack&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help you guys have!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gxvn0k9n81dc1.jpeg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?auto=webp&amp;s=190e9ed2b5a8fc71476b6c540954adf4e63cb362", "width": 1280, "height": 1280}, "resolutions": [{"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=18f87d7451fd39d5a9b10d840fccca3f92b7cdff", "width": 108, "height": 108}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bbee8379fe9da3b1e06f852240d3c64b3f077b6b", "width": 216, "height": 216}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8eac8a0b1cf7c7bfe473b79f3d9645ac20917688", "width": 320, "height": 320}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6846c2b32a21f6deb122147430e5a0bcc1fe874e", "width": 640, "height": 640}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=567a77ac0d88cbba675174f7e45ee36b70489696", "width": 960, "height": 960}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d9002890f55a01a006d675ba83bfda39c22f9c8d", "width": 1080, "height": 1080}], "variants": {}, "id": "k4pd9dRByGzZ_BJfOdgf8Js79m37pTcx8EgcyGWR9oA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1991oj7", "is_robot_indexable": true, "report_reasons": null, "author": "zapugh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1991oj7/yoyotta_spanning_backups_failing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gxvn0k9n81dc1.jpeg", "subreddit_subscribers": 725947, "created_utc": 1705511270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently tried to get all my data from Google, especially Youtube comments. Now I noticed that it's just reaching back to about 07/2022, but in a takeout I did in 2021 I got all comments from then until 2015.\n\nAnyone got any experience with Takeout and knows what's up?", "author_fullname": "t2_16yscp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any luck using Google Takeout?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199076p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705507875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently tried to get all my data from Google, especially Youtube comments. Now I noticed that it&amp;#39;s just reaching back to about 07/2022, but in a takeout I did in 2021 I got all comments from then until 2015.&lt;/p&gt;\n\n&lt;p&gt;Anyone got any experience with Takeout and knows what&amp;#39;s up?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199076p", "is_robot_indexable": true, "report_reasons": null, "author": "hoppla1232", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199076p/any_luck_using_google_takeout/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199076p/any_luck_using_google_takeout/", "subreddit_subscribers": 725947, "created_utc": 1705507875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nHi, I have recently got an internal SSD for my laptop. Same size as my external one. I've tried to use Acronis but it will not copy it to the new internal drive, due to the different in file system.\n\nIt's just games, some applications, some videos. I don't want a boot file, or the OS or anything.\n\nDo I just copy it, and convert my internal SSD from a NTFS file system to a exFAT, so the data will transfer. Maybe find a way to convert it back to NTFS?\n\nWill normal Windows Explorer CTRL C + V work?\n\nAnything else I can do, or will I just have to reinstall everything.", "author_fullname": "t2_74po0kp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External exFAT USB SSD to internal NTFS Internal M.2 NVME SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198ydz6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705503338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have recently got an internal SSD for my laptop. Same size as my external one. I&amp;#39;ve tried to use Acronis but it will not copy it to the new internal drive, due to the different in file system.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s just games, some applications, some videos. I don&amp;#39;t want a boot file, or the OS or anything.&lt;/p&gt;\n\n&lt;p&gt;Do I just copy it, and convert my internal SSD from a NTFS file system to a exFAT, so the data will transfer. Maybe find a way to convert it back to NTFS?&lt;/p&gt;\n\n&lt;p&gt;Will normal Windows Explorer CTRL C + V work?&lt;/p&gt;\n\n&lt;p&gt;Anything else I can do, or will I just have to reinstall everything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198ydz6", "is_robot_indexable": true, "report_reasons": null, "author": "Renoir_V", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198ydz6/external_exfat_usb_ssd_to_internal_ntfs_internal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198ydz6/external_exfat_usb_ssd_to_internal_ntfs_internal/", "subreddit_subscribers": 725947, "created_utc": 1705503338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I can find NAS type storage, but is there just an inherent limit on the smaller (physical) size SSDs at 8TB? \n\nI was looking to replace an 8TB HDD used for backup. It\u2019s almost full", "author_fullname": "t2_mogji8q5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I can\u2019t seem to find any external SSD drives over 8TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198ws9r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705498839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can find NAS type storage, but is there just an inherent limit on the smaller (physical) size SSDs at 8TB? &lt;/p&gt;\n\n&lt;p&gt;I was looking to replace an 8TB HDD used for backup. It\u2019s almost full&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198ws9r", "is_robot_indexable": true, "report_reasons": null, "author": "ButterscotchLucky798", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198ws9r/i_cant_seem_to_find_any_external_ssd_drives_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198ws9r/i_cant_seem_to_find_any_external_ssd_drives_over/", "subreddit_subscribers": 725947, "created_utc": 1705498839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a collection of folders which have several files inside, mostly zip files and unity related stuff, which I want to be able to search using custom metadata: in order to accomplish that, I would ideally like to create a metadata.json file inside a folder (json, ldjson, yaml, etc.) which can have some arbitrary attributes such as: resource\\_id, title, description, source\\_url, model\\_type, thumbnail\\_image\\_path...\n\nI would like to find a software that would let me perform searches against those metadata files, ideally being able to display the result items in a grid with thumbnails and the custom attributes I would like to display. It would be nice as well if it would manage the part of creating those metadata files from a GUI, be compatible with network based storage such as google drive and ideally (but not mandatory) to be multi-platform.\n\nIs there any software that you find suitable / can recommend to me? I have tried to find a software but seems like all of them are oriented towards automatic metadata recognition from images, videos, audios, etc. but that's not what I really want since I am going to add that metadata manually.", "author_fullname": "t2_heqg6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Searching for a software that lets me search folders based on custom metadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198tgdk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705487066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a collection of folders which have several files inside, mostly zip files and unity related stuff, which I want to be able to search using custom metadata: in order to accomplish that, I would ideally like to create a metadata.json file inside a folder (json, ldjson, yaml, etc.) which can have some arbitrary attributes such as: resource_id, title, description, source_url, model_type, thumbnail_image_path...&lt;/p&gt;\n\n&lt;p&gt;I would like to find a software that would let me perform searches against those metadata files, ideally being able to display the result items in a grid with thumbnails and the custom attributes I would like to display. It would be nice as well if it would manage the part of creating those metadata files from a GUI, be compatible with network based storage such as google drive and ideally (but not mandatory) to be multi-platform.&lt;/p&gt;\n\n&lt;p&gt;Is there any software that you find suitable / can recommend to me? I have tried to find a software but seems like all of them are oriented towards automatic metadata recognition from images, videos, audios, etc. but that&amp;#39;s not what I really want since I am going to add that metadata manually.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198tgdk", "is_robot_indexable": true, "report_reasons": null, "author": "Welcius", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198tgdk/searching_for_a_software_that_lets_me_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198tgdk/searching_for_a_software_that_lets_me_search/", "subreddit_subscribers": 725947, "created_utc": 1705487066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a NetApp DS something. 24 bay DAS - with 16 slots filled of mostly 6TB drives. I think 4 are actually 3Tb.\n\nAnyways I have them in a Raid-Z2 running on a TrueNAS VM with the HBA Passed through in a R720.\n\nI have something like 54TB of pool with 80% full.\n\nAs I start future planning for my next steps, I would like to migrate from a DAS to a dedicated NAS instead and possibly trying to consolidate some power costs.", "author_fullname": "t2_12kxb0qd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most cost effective option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198p5vk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705469925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a NetApp DS something. 24 bay DAS - with 16 slots filled of mostly 6TB drives. I think 4 are actually 3Tb.&lt;/p&gt;\n\n&lt;p&gt;Anyways I have them in a Raid-Z2 running on a TrueNAS VM with the HBA Passed through in a R720.&lt;/p&gt;\n\n&lt;p&gt;I have something like 54TB of pool with 80% full.&lt;/p&gt;\n\n&lt;p&gt;As I start future planning for my next steps, I would like to migrate from a DAS to a dedicated NAS instead and possibly trying to consolidate some power costs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198p5vk", "is_robot_indexable": true, "report_reasons": null, "author": "Ironfox2151", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198p5vk/most_cost_effective_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198p5vk/most_cost_effective_option/", "subreddit_subscribers": 725947, "created_utc": 1705469925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was trying to rm -r a mount point without realizing the removable ext4 HDD was still mounted. I panicked and unplugged the drive after a few seconds. \n\n\nI can tell some of the files has been deleted, but unfortunately I don't have a backup (I was going to make a backup I swear). \n\n\ntestdisk doesn't list any recently deleted files, but it does list files deleted long time ago. extundelete and ext4magic recovered 0 files too. \n\n\nNo new data was written to the HDD since the incident, however it was mounted 1 or 2 times when I checked for losses. What could have gone so wrong such that extundelete and testdisk couldn't find the recently deleted files?", "author_fullname": "t2_bov3ioom", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "extundelete, ext4magic found 0 recoverable files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198nlx9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705464824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to rm -r a mount point without realizing the removable ext4 HDD was still mounted. I panicked and unplugged the drive after a few seconds. &lt;/p&gt;\n\n&lt;p&gt;I can tell some of the files has been deleted, but unfortunately I don&amp;#39;t have a backup (I was going to make a backup I swear). &lt;/p&gt;\n\n&lt;p&gt;testdisk doesn&amp;#39;t list any recently deleted files, but it does list files deleted long time ago. extundelete and ext4magic recovered 0 files too. &lt;/p&gt;\n\n&lt;p&gt;No new data was written to the HDD since the incident, however it was mounted 1 or 2 times when I checked for losses. What could have gone so wrong such that extundelete and testdisk couldn&amp;#39;t find the recently deleted files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "198nlx9", "is_robot_indexable": true, "report_reasons": null, "author": "tough_leek", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/198nlx9/extundelete_ext4magic_found_0_recoverable_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/198nlx9/extundelete_ext4magic_found_0_recoverable_files/", "subreddit_subscribers": 725947, "created_utc": 1705464824.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}