{"kind": "Listing", "data": {"after": "t3_199tgu9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_afj5b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit must share IP addresses of piracy-discussing users, film studios say (Reddit Refuses)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_199ah69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 638, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 638, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UberXAJ3MkHEHzZm4RHZudlvQ5tA_JO85MzfwPUwUZc.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705532282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arstechnica.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arstechnica.com/tech-policy/2024/01/film-studios-demand-ip-addresses-of-people-who-discussed-piracy-on-reddit/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?auto=webp&amp;s=283e75c3e435a26092b20456e0e6f04e45f033e1", "width": 760, "height": 380}, "resolutions": [{"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c203afa0163b8be5a52fc05b552bf0a140fa975d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8994b7291c4eb722a7220d0633fb429ce8918f65", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34bc9278c53cd476ff4c14855746243d73e2046a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/nwWHObWV5OeQDfHAelLCkU9UwypyiO0V-_ELFThwQb8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5213d11b79df959651527e87463c565156e924e", "width": 640, "height": 320}], "variants": {}, "id": "Unj7h3l6SCdChsZkFY4Xe_7dlOcCiz9mmZd2X6YpmPQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "2075+TB ZFS", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199ah69", "is_robot_indexable": true, "report_reasons": null, "author": "EchoGecko795", "discussion_type": null, "num_comments": 197, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/199ah69/reddit_must_share_ip_addresses_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arstechnica.com/tech-policy/2024/01/film-studios-demand-ip-addresses-of-people-who-discussed-piracy-on-reddit/", "subreddit_subscribers": 726104, "created_utc": 1705532282.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_u4kys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The largest consumer SSD that has been available each year at Newegg (2007-2023)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_199mbt0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 102, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 102, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bdEo1FXusaqbyWA8um5jFbJwop_0h4_Jco96XuUHp3A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705570410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tzvk1x9246dc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tzvk1x9246dc1.png?auto=webp&amp;s=332dfa58c1fe6e8d42f617205d33e49abbd87356", "width": 1002, "height": 1066}, "resolutions": [{"url": "https://preview.redd.it/tzvk1x9246dc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a2eec603735045ed189ee1a82d4f24eba1eb9578", "width": 108, "height": 114}, {"url": "https://preview.redd.it/tzvk1x9246dc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5fcfb018027210434095522baaad5fd306a494b5", "width": 216, "height": 229}, {"url": "https://preview.redd.it/tzvk1x9246dc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=19e3ee5b7dac45a41bcea5b871eaa2a9aa6a66e4", "width": 320, "height": 340}, {"url": "https://preview.redd.it/tzvk1x9246dc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=def49b9cd189ef89eb6d2a907ef7c99020143e71", "width": 640, "height": 680}, {"url": "https://preview.redd.it/tzvk1x9246dc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dbcf35100291a1c1c3c1c119439ff6ee82d42f8b", "width": 960, "height": 1021}], "variants": {}, "id": "nfi-AeHMTNKCskH-YfPNi_riFWFQCr6lA4vH8AXxgiA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199mbt0", "is_robot_indexable": true, "report_reasons": null, "author": "CokeZoro", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199mbt0/the_largest_consumer_ssd_that_has_been_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tzvk1x9246dc1.png", "subreddit_subscribers": 726104, "created_utc": 1705570410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys! I've been keeping an eye out on my local market places for old office PCs and I came across someone selling this home server for 300 CAD so about 220ish USD it's going to be used for data storage (audio books music  my roms  flash game collection ) a plex and Minecraft server as well as personal cloud storage", "author_fullname": "t2_1c3xlq4p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_199aztn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3CMSn67pN1d2zpwxLLehl9xjugN-ub24gYDEX-3nYMA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705533582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys! I&amp;#39;ve been keeping an eye out on my local market places for old office PCs and I came across someone selling this home server for 300 CAD so about 220ish USD it&amp;#39;s going to be used for data storage (audio books music  my roms  flash game collection ) a plex and Minecraft server as well as personal cloud storage&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gwjkhwjz23dc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gwjkhwjz23dc1.png?auto=webp&amp;s=cb3ff714a5ed7d8b4b2f23ef1c36ceb28c0e5aa7", "width": 1080, "height": 1623}, "resolutions": [{"url": "https://preview.redd.it/gwjkhwjz23dc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0eb5f784c25d4a0f53b7bd1284011d1bf21da69d", "width": 108, "height": 162}, {"url": "https://preview.redd.it/gwjkhwjz23dc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b42187cc6ec9fb3a7157eb0f1ffcc2a5bb5a0ec", "width": 216, "height": 324}, {"url": "https://preview.redd.it/gwjkhwjz23dc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7fd2b573ee290cad5494d857358664831fa2843b", "width": 320, "height": 480}, {"url": "https://preview.redd.it/gwjkhwjz23dc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=02e7c7a3f62d3c218b96a9922fbd610fa65331e7", "width": 640, "height": 961}, {"url": "https://preview.redd.it/gwjkhwjz23dc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e68a4bb763d3e6c7ffc29ecacacb4196f36e8c97", "width": 960, "height": 1442}, {"url": "https://preview.redd.it/gwjkhwjz23dc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=44bd49f474dcae40321a88a4b3b5f81f72e8e87c", "width": 1080, "height": 1623}], "variants": {}, "id": "6FOEs_YBRWzQEzsugfVXSTxwyZ7P60s0zNRHLNSlUHU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199aztn", "is_robot_indexable": true, "report_reasons": null, "author": "wokecycles", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199aztn/thoughts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gwjkhwjz23dc1.png", "subreddit_subscribers": 726104, "created_utc": 1705533582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is the H.264 vs 265 something that is already on the source disc?  In other words, you don't need to control the type of compression on a rip, it's just going to get whatever it's already got?\n\nAnd if you want to do a 1:1 rip with no compression, what option is what in something like MakeMKV or DVDFab?  Watching some videos, I think that \"MKV Passthrough\" is what is needed for a 1:1 rip?", "author_fullname": "t2_16fj1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ripping BD and UHD to MKV - Compression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1999bob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705530717.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705529401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is the H.264 vs 265 something that is already on the source disc?  In other words, you don&amp;#39;t need to control the type of compression on a rip, it&amp;#39;s just going to get whatever it&amp;#39;s already got?&lt;/p&gt;\n\n&lt;p&gt;And if you want to do a 1:1 rip with no compression, what option is what in something like MakeMKV or DVDFab?  Watching some videos, I think that &amp;quot;MKV Passthrough&amp;quot; is what is needed for a 1:1 rip?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1999bob", "is_robot_indexable": true, "report_reasons": null, "author": "_Nismo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1999bob/ripping_bd_and_uhd_to_mkv_compression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1999bob/ripping_bd_and_uhd_to_mkv_compression/", "subreddit_subscribers": 726104, "created_utc": 1705529401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Thanks, EU! \n\nHere's the bit just announced, emphasis mine:\n\n&gt;**Data portability:** For over a decade we have offered users the  ability to download or transfer a copy of their data from more than 80  Google products. We continue to make investments in Google Takeout, the [Data Transfer Initiative](https://dtinit.org/)  and data portability more broadly. To meet new requirements around  moving your data to a third-party app or service, ***we will soon be testing a Data Portability API for developers*****.**\n\nsource: [https://blog.google/around-the-globe/google-europe/an-update-on-our-preparations-for-the-dma/](https://blog.google/around-the-globe/google-europe/an-update-on-our-preparations-for-the-dma/)", "author_fullname": "t2_gabfs0cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Takeout is getting an official API \u203d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199411o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705516733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks, EU! &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the bit just announced, emphasis mine:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;Data portability:&lt;/strong&gt; For over a decade we have offered users the  ability to download or transfer a copy of their data from more than 80  Google products. We continue to make investments in Google Takeout, the &lt;a href=\"https://dtinit.org/\"&gt;Data Transfer Initiative&lt;/a&gt;  and data portability more broadly. To meet new requirements around  moving your data to a third-party app or service, &lt;strong&gt;&lt;em&gt;we will soon be testing a Data Portability API for developers&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;source: &lt;a href=\"https://blog.google/around-the-globe/google-europe/an-update-on-our-preparations-for-the-dma/\"&gt;https://blog.google/around-the-globe/google-europe/an-update-on-our-preparations-for-the-dma/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199411o", "is_robot_indexable": true, "report_reasons": null, "author": "BestExtraLibrarian", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199411o/google_takeout_is_getting_an_official_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199411o/google_takeout_is_getting_an_official_api/", "subreddit_subscribers": 726104, "created_utc": 1705516733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've seen some users recommend Macrium Reflect to clone an OS drive, but from my understanding this would rewrite the entire HDD when copying the OS drive over. If this doesn't happen and I'm wrong that would be great! Otherwise, if I want to copy my boot drive with the OS, along with other non-boot drives all onto one HDD roughly once a week for backups, what is my best option?", "author_fullname": "t2_9l9ghq60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to regularly copy Boot drive and multiple drives to One HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199ak3x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705532809.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705532478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen some users recommend Macrium Reflect to clone an OS drive, but from my understanding this would rewrite the entire HDD when copying the OS drive over. If this doesn&amp;#39;t happen and I&amp;#39;m wrong that would be great! Otherwise, if I want to copy my boot drive with the OS, along with other non-boot drives all onto one HDD roughly once a week for backups, what is my best option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199ak3x", "is_robot_indexable": true, "report_reasons": null, "author": "jordanisplaying", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199ak3x/how_to_regularly_copy_boot_drive_and_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199ak3x/how_to_regularly_copy_boot_drive_and_multiple/", "subreddit_subscribers": 726104, "created_utc": 1705532478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am having issues getting a brand new WD Gold 12TB drive to work in my Windows 10 Pro computer which has a decently recent motherboard (MSI X570 Gaming Plus, flashed latest BIOS). The disk is recognized no problem in the BIOS and in Windows, including with the WD Dashboard tool.  Correct capacity and everything.  However, when I go to Disk Management, it already was showing a 2TB partition and a 9TB partition.  Besides initializing with GPT, I could then not do anything else in Disk Management, everything was greyed out.  So I tried a couple of different partitioning softwares and they would always either fail or complete, but not actually do anything.  I tried diskpart and had similar results, but it would say i/o error.  I ran SMART and it was fine.  In looking around, I read about the new issue with \"Power Disable\" on the SATA power connectors, but this doesn't seem to apply because my disk was powering on no problem and recognized (I tried the molex adapter trick, and there was no change).\n\nI decided to take it to work and pop it in our \"enterprise grade\" server running Windows Server 2022 and using diskpart, I was able to set GPT, clean it, and create a 12TB NTFS partition right away.  I set if offline, removed it, and brought it home, but Disk Mangement immediately was showing the 2TB/9TB thing, and the partitioning software was able to read the drive label I had added, but it would not let me set a drive letter (however, it was showing the 12TB partition properly in the partition software).  Tried a few more things, but clearly there is some incompatibility here, or I'm hitting a limit in Win 10 Pro?\n\nAny suggestions would be greatly appreciated, thanks!", "author_fullname": "t2_qzir1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weird WD Gold problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199bic6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705534939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am having issues getting a brand new WD Gold 12TB drive to work in my Windows 10 Pro computer which has a decently recent motherboard (MSI X570 Gaming Plus, flashed latest BIOS). The disk is recognized no problem in the BIOS and in Windows, including with the WD Dashboard tool.  Correct capacity and everything.  However, when I go to Disk Management, it already was showing a 2TB partition and a 9TB partition.  Besides initializing with GPT, I could then not do anything else in Disk Management, everything was greyed out.  So I tried a couple of different partitioning softwares and they would always either fail or complete, but not actually do anything.  I tried diskpart and had similar results, but it would say i/o error.  I ran SMART and it was fine.  In looking around, I read about the new issue with &amp;quot;Power Disable&amp;quot; on the SATA power connectors, but this doesn&amp;#39;t seem to apply because my disk was powering on no problem and recognized (I tried the molex adapter trick, and there was no change).&lt;/p&gt;\n\n&lt;p&gt;I decided to take it to work and pop it in our &amp;quot;enterprise grade&amp;quot; server running Windows Server 2022 and using diskpart, I was able to set GPT, clean it, and create a 12TB NTFS partition right away.  I set if offline, removed it, and brought it home, but Disk Mangement immediately was showing the 2TB/9TB thing, and the partitioning software was able to read the drive label I had added, but it would not let me set a drive letter (however, it was showing the 12TB partition properly in the partition software).  Tried a few more things, but clearly there is some incompatibility here, or I&amp;#39;m hitting a limit in Win 10 Pro?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199bic6", "is_robot_indexable": true, "report_reasons": null, "author": "eyecannon", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199bic6/weird_wd_gold_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199bic6/weird_wd_gold_problem/", "subreddit_subscribers": 726104, "created_utc": 1705534939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hypothetically", "author_fullname": "t2_ilpgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "would it be possible to manufacture a bluray the size of a vinyl to store more data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_199t7ad", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": "", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705593078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hypothetically&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "96TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199t7ad", "is_robot_indexable": true, "report_reasons": null, "author": "myc123", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/199t7ad/would_it_be_possible_to_manufacture_a_bluray_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199t7ad/would_it_be_possible_to_manufacture_a_bluray_the/", "subreddit_subscribers": 726104, "created_utc": 1705593078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The closure of Beyond3D.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1996b48", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_jonsu", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jUae2zOxQoc-o4MB_DNAKeoV0P3ZYlEGLMAOT3HE1Ig.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "hardware", "selftext": "", "author_fullname": "t2_81y6hxs0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The closure of Beyond3D.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/hardware", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_198w32c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 121, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 121, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jUae2zOxQoc-o4MB_DNAKeoV0P3ZYlEGLMAOT3HE1Ig.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705496660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "forum.beyond3d.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://forum.beyond3d.com/threads/the-closure-of-beyond3d.63478/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?auto=webp&amp;s=a32c2466f76ce4dc1a039bfd2e56da6e261ef0de", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9da9dc020670dcf7c36e78ab0f6ab33926fde84", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5b6f49b2f1051f5a4511b3c8ca58d694bd005f62", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad0d12c26920c77116fc15b766ae2c10249495f7", "width": 320, "height": 320}], "variants": {}, "id": "4zTA237Us5pzFc1DQ4fB7gMVMwjsFpHHrSWjv5g_plY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e763e51e-c141-11e3-b9ac-12313d31e5b1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2qh18", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "198w32c", "is_robot_indexable": true, "report_reasons": null, "author": "ResponsibleJudge3172", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/hardware/comments/198w32c/the_closure_of_beyond3d/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://forum.beyond3d.com/threads/the-closure-of-beyond3d.63478/", "subreddit_subscribers": 3554128, "created_utc": 1705496660.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1705522132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "forum.beyond3d.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://forum.beyond3d.com/threads/the-closure-of-beyond3d.63478/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?auto=webp&amp;s=a32c2466f76ce4dc1a039bfd2e56da6e261ef0de", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9da9dc020670dcf7c36e78ab0f6ab33926fde84", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5b6f49b2f1051f5a4511b3c8ca58d694bd005f62", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/CIgDIgD13NIkl60XD2UysZOKJIoiyPqzS8hmWFbjLOU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad0d12c26920c77116fc15b766ae2c10249495f7", "width": 320, "height": 320}], "variants": {}, "id": "4zTA237Us5pzFc1DQ4fB7gMVMwjsFpHHrSWjv5g_plY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1996b48", "is_robot_indexable": true, "report_reasons": null, "author": "capn_hector", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_198w32c", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1996b48/the_closure_of_beyond3d/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://forum.beyond3d.com/threads/the-closure-of-beyond3d.63478/", "subreddit_subscribers": 726104, "created_utc": 1705522132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a couple of these drives still in their original enclosure and I would like to shuck them to use with my ugreen enclosure. I'm not a big fan of the WD enclosure so was just wondering if anyone else shucks them to use in another enclosure and whether their would be any risk shucking and using in another enclosure?", "author_fullname": "t2_5dkgegkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shucking WD 18tb Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1995w5c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705521165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a couple of these drives still in their original enclosure and I would like to shuck them to use with my ugreen enclosure. I&amp;#39;m not a big fan of the WD enclosure so was just wondering if anyone else shucks them to use in another enclosure and whether their would be any risk shucking and using in another enclosure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1995w5c", "is_robot_indexable": true, "report_reasons": null, "author": "craftywizard1983", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1995w5c/shucking_wd_18tb_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1995w5c/shucking_wd_18tb_drive/", "subreddit_subscribers": 726104, "created_utc": 1705521165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7bhbks0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just bought this 20TB hard used which has only 5000 hours of use on it. I had to cover the 3.3V pins so it would work in my computer.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_199lzh5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/XFM46zEONrHws3ZRPTjYOWviJPEYdEnTXQ1yicB8ip4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705568915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vc8ujksyz5dc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vc8ujksyz5dc1.jpeg?auto=webp&amp;s=0fe9f1ced4fb4a23fc5cff335e7d33c7ec420326", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/vc8ujksyz5dc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1b125504976a35621d8b17ec53f552d290a10be8", "width": 108, "height": 144}, {"url": "https://preview.redd.it/vc8ujksyz5dc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=44d3f9c0ee911b28953cbd4e31514781cf393802", "width": 216, "height": 288}, {"url": "https://preview.redd.it/vc8ujksyz5dc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ffb936ce7263fa361fb7c29d1dfcc7457eebaac5", "width": 320, "height": 426}, {"url": "https://preview.redd.it/vc8ujksyz5dc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dbe7f1c9b0a235bde49c48947699299740ca28d1", "width": 640, "height": 853}, {"url": "https://preview.redd.it/vc8ujksyz5dc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=35a62f9fc858658d41cb62ad012ca392fde38332", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/vc8ujksyz5dc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ea212e01ce13c5fe7ae978625cc576114e0e5a2c", "width": 1080, "height": 1440}], "variants": {}, "id": "Menvk_rnPRBBbIvcM6rgKLonQXCAzitqrEXJE3r2JaM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199lzh5", "is_robot_indexable": true, "report_reasons": null, "author": "2001_F350_7point3", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199lzh5/i_just_bought_this_20tb_hard_used_which_has_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vc8ujksyz5dc1.jpeg", "subreddit_subscribers": 726104, "created_utc": 1705568915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I purchased a brand new 2TB Samsung T7 shield from an expensive and reputable high street retailer chain rather than Amazon to (hopefully) make sure it's legit. I've decided to transfer the main SSD c drive of a laptop onto an external SSD before giving the laptop away.\n\nI'm doing a 680 GB transfer using TeraCopy which was going well with an estimated total \\~ 2 hour transfer time. However when it reached around \"95% done\" with about 30GB left the transfer says it will take 6 days at around 50 kb/s.\n\nAnyone know whats happening or what I can do to get the final 5% of the transfercompleted? I really don't want to stop this transfer and restart it all over again as it's 96% done and worried the issue will happen again the second time", "author_fullname": "t2_ey91h2hh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung T7 has suddenly gone from minutes to days for a transfer to complete", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1997cl3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705524623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I purchased a brand new 2TB Samsung T7 shield from an expensive and reputable high street retailer chain rather than Amazon to (hopefully) make sure it&amp;#39;s legit. I&amp;#39;ve decided to transfer the main SSD c drive of a laptop onto an external SSD before giving the laptop away.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing a 680 GB transfer using TeraCopy which was going well with an estimated total ~ 2 hour transfer time. However when it reached around &amp;quot;95% done&amp;quot; with about 30GB left the transfer says it will take 6 days at around 50 kb/s.&lt;/p&gt;\n\n&lt;p&gt;Anyone know whats happening or what I can do to get the final 5% of the transfercompleted? I really don&amp;#39;t want to stop this transfer and restart it all over again as it&amp;#39;s 96% done and worried the issue will happen again the second time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1997cl3", "is_robot_indexable": true, "report_reasons": null, "author": "Royal_Difficulty_678", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1997cl3/samsung_t7_has_suddenly_gone_from_minutes_to_days/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1997cl3/samsung_t7_has_suddenly_gone_from_minutes_to_days/", "subreddit_subscribers": 726104, "created_utc": 1705524623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all I am new to hoarding and have run into the worst thing to happen; file corruption.\n\nOn an external 3 TB exFAT SSD, there is a single directory with around 10k images/videos (totaling to something like 3 gigs) which has been corrupted. The rest of the drive works fine (and I have backed it all up already), but when trying to access that specific directory, I get \"The file or directory is corrupted and unreadable.\"  \n\n\nI have tried running chkdsk for about 3 days straight, as well as tools like Stellar, but it keeps on running and I assume the huge driver size isn't doing me any favors.\n\nIs there a way or tool that can attempt recovery inside specific folders only? Any insights and tips would be greatly appreciated", "author_fullname": "t2_2amfgvyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to isolate folders for corruption recovery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1995fd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705520065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all I am new to hoarding and have run into the worst thing to happen; file corruption.&lt;/p&gt;\n\n&lt;p&gt;On an external 3 TB exFAT SSD, there is a single directory with around 10k images/videos (totaling to something like 3 gigs) which has been corrupted. The rest of the drive works fine (and I have backed it all up already), but when trying to access that specific directory, I get &amp;quot;The file or directory is corrupted and unreadable.&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;I have tried running chkdsk for about 3 days straight, as well as tools like Stellar, but it keeps on running and I assume the huge driver size isn&amp;#39;t doing me any favors.&lt;/p&gt;\n\n&lt;p&gt;Is there a way or tool that can attempt recovery inside specific folders only? Any insights and tips would be greatly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1995fd5", "is_robot_indexable": true, "report_reasons": null, "author": "IlliquidFabricator", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1995fd5/is_there_a_way_to_isolate_folders_for_corruption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1995fd5/is_there_a_way_to_isolate_folders_for_corruption/", "subreddit_subscribers": 726104, "created_utc": 1705520065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have around 26 TB of storage capacity in a pool and planning to add another 8TB drive. However, I get the error: the physical disk sector size is not supported by the storage pool. Is due to the cluster size? I am currently using 8 KB for the pool. Do I need to increase to 16 KB? Is there a way to do it without migrating/formatting? \n\nAny help would be appreciated!\nThank you!", "author_fullname": "t2_128aay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows storage spaces error", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1994b6u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705517401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 26 TB of storage capacity in a pool and planning to add another 8TB drive. However, I get the error: the physical disk sector size is not supported by the storage pool. Is due to the cluster size? I am currently using 8 KB for the pool. Do I need to increase to 16 KB? Is there a way to do it without migrating/formatting? &lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated!\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1994b6u", "is_robot_indexable": true, "report_reasons": null, "author": "avii22", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1994b6u/windows_storage_spaces_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1994b6u/windows_storage_spaces_error/", "subreddit_subscribers": 726104, "created_utc": 1705517401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm looking for the best quality Windows 11-compatible VHS capture device. Can anyone suggest one to go with? Elgato and Dazzle do not function with it.", "author_fullname": "t2_dtf8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows 11 compatible VHS capture devices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1993w9k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705516416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking for the best quality Windows 11-compatible VHS capture device. Can anyone suggest one to go with? Elgato and Dazzle do not function with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1993w9k", "is_robot_indexable": true, "report_reasons": null, "author": "Half_Aborted", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1993w9k/windows_11_compatible_vhs_capture_devices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1993w9k/windows_11_compatible_vhs_capture_devices/", "subreddit_subscribers": 726104, "created_utc": 1705516416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Unlike the 3.5\" drives I've shucked, this doesn't have a standard SATA connection. I'm thinking internal USB 3.0 port from a PCIE slot but I've never seen such a device.", "author_fullname": "t2_qp7ix", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to mount WD My Passport internally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199nwlx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705576789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Unlike the 3.5&amp;quot; drives I&amp;#39;ve shucked, this doesn&amp;#39;t have a standard SATA connection. I&amp;#39;m thinking internal USB 3.0 port from a PCIE slot but I&amp;#39;ve never seen such a device.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "230TB Drivepool", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199nwlx", "is_robot_indexable": true, "report_reasons": null, "author": "Smior", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/199nwlx/any_way_to_mount_wd_my_passport_internally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199nwlx/any_way_to_mount_wd_my_passport_internally/", "subreddit_subscribers": 726104, "created_utc": 1705576789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'll try and get to the point. My wife passed and I am looking to create a archive of all her files for long term storage. I have  cloned to SSD drives but want to also create a backup onto spinning disk. Her files all live on two Macs , one iPhone, one iPad, Google Drive, and USB drives/sticks.\n\nWhat would you recommend as a file system for long term storage and archive? I am thinking ext4 for the stand alone drives. I  plan on organizing and archiving to the cloud, and building a ZFS server. I am mainly a Mac user but I also run a couple Linux boxes.\n\nThanks for any suggestions.", "author_fullname": "t2_d4svi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File System for Archive on HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1994j97", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705517948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll try and get to the point. My wife passed and I am looking to create a archive of all her files for long term storage. I have  cloned to SSD drives but want to also create a backup onto spinning disk. Her files all live on two Macs , one iPhone, one iPad, Google Drive, and USB drives/sticks.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend as a file system for long term storage and archive? I am thinking ext4 for the stand alone drives. I  plan on organizing and archiving to the cloud, and building a ZFS server. I am mainly a Mac user but I also run a couple Linux boxes.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1994j97", "is_robot_indexable": true, "report_reasons": null, "author": "120r", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1994j97/file_system_for_archive_on_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1994j97/file_system_for_archive_on_hdd/", "subreddit_subscribers": 726104, "created_utc": 1705517948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone else been having issues with Yoyotta lately? Every time I do a spanning backup it ends up using significantly more tape storage than it should. I had a 7tb back to LTO 7 that should use up all 5.5tb on one tape then a part of a second one. Instead on the first tape it left 1.5tb unused which means it\u2019s going to need to use a much larger amount of storage on the second tape.\n\nThis same issue has been happening to me since October and customer support\u2019s answer was \u201ctry backing up smaller sizes.\u201d Then they stopped responding to my emails \ud83d\ude29\n\nFor context:\nMac OS Ventura 13.6\nYoyotta Version 3 (240)\nM-Logic M-Rack\n\nThanks for any help you guys have!", "author_fullname": "t2_rapfkoz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Yoyotta Spanning Backups Failing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1991oj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vFMZS8ieEH_0y3zJXxrDq8Dgim4KxEL5Ho9gKoDsUXI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705511270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone else been having issues with Yoyotta lately? Every time I do a spanning backup it ends up using significantly more tape storage than it should. I had a 7tb back to LTO 7 that should use up all 5.5tb on one tape then a part of a second one. Instead on the first tape it left 1.5tb unused which means it\u2019s going to need to use a much larger amount of storage on the second tape.&lt;/p&gt;\n\n&lt;p&gt;This same issue has been happening to me since October and customer support\u2019s answer was \u201ctry backing up smaller sizes.\u201d Then they stopped responding to my emails \ud83d\ude29&lt;/p&gt;\n\n&lt;p&gt;For context:\nMac OS Ventura 13.6\nYoyotta Version 3 (240)\nM-Logic M-Rack&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help you guys have!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gxvn0k9n81dc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?auto=webp&amp;s=190e9ed2b5a8fc71476b6c540954adf4e63cb362", "width": 1280, "height": 1280}, "resolutions": [{"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=18f87d7451fd39d5a9b10d840fccca3f92b7cdff", "width": 108, "height": 108}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bbee8379fe9da3b1e06f852240d3c64b3f077b6b", "width": 216, "height": 216}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8eac8a0b1cf7c7bfe473b79f3d9645ac20917688", "width": 320, "height": 320}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6846c2b32a21f6deb122147430e5a0bcc1fe874e", "width": 640, "height": 640}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=567a77ac0d88cbba675174f7e45ee36b70489696", "width": 960, "height": 960}, {"url": "https://preview.redd.it/gxvn0k9n81dc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d9002890f55a01a006d675ba83bfda39c22f9c8d", "width": 1080, "height": 1080}], "variants": {}, "id": "k4pd9dRByGzZ_BJfOdgf8Js79m37pTcx8EgcyGWR9oA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1991oj7", "is_robot_indexable": true, "report_reasons": null, "author": "zapugh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1991oj7/yoyotta_spanning_backups_failing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gxvn0k9n81dc1.jpeg", "subreddit_subscribers": 726104, "created_utc": 1705511270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Seagate drive (Seagate Exos) that has increasing bad sectors. Seagate approved a warranty replacement online with free shipping.\n\nThey emailed a prepaid shipping label and the packing instructions state the following:\n\n&gt;*Place the drive in a bubble wrap envelope or a box lined with bubble wrap. Do not use packing pellets, peanuts, air bags or newspaper*\n\nAll I have are the standard HDD \"air bag\" that Newegg uses to send out the hard drive. But the instructions explicitly say do not use air bags!\n\nAll of my other HDDs have the exact same form fitted airbag.\n\nTBH any drives I have bought that didn't have one of these airbags, arrived damaged the last thing I want is the drive to arrive to Seagate with physical damage.\n\nWhat would you do in this scenario? I don't want to mess up the RMA process and end up with a delayed return or return to sender situation.\n\nAnyone have experience returning to Seagate? What did you use for the packaging?\n\n&amp;#x200B;", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos RMA &amp; packaging opinions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_199t8z3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705593201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Seagate drive (Seagate Exos) that has increasing bad sectors. Seagate approved a warranty replacement online with free shipping.&lt;/p&gt;\n\n&lt;p&gt;They emailed a prepaid shipping label and the packing instructions state the following:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;em&gt;Place the drive in a bubble wrap envelope or a box lined with bubble wrap. Do not use packing pellets, peanuts, air bags or newspaper&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;All I have are the standard HDD &amp;quot;air bag&amp;quot; that Newegg uses to send out the hard drive. But the instructions explicitly say do not use air bags!&lt;/p&gt;\n\n&lt;p&gt;All of my other HDDs have the exact same form fitted airbag.&lt;/p&gt;\n\n&lt;p&gt;TBH any drives I have bought that didn&amp;#39;t have one of these airbags, arrived damaged the last thing I want is the drive to arrive to Seagate with physical damage.&lt;/p&gt;\n\n&lt;p&gt;What would you do in this scenario? I don&amp;#39;t want to mess up the RMA process and end up with a delayed return or return to sender situation.&lt;/p&gt;\n\n&lt;p&gt;Anyone have experience returning to Seagate? What did you use for the packaging?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "199t8z3", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/199t8z3/seagate_exos_rma_packaging_opinions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199t8z3/seagate_exos_rma_packaging_opinions/", "subreddit_subscribers": 726104, "created_utc": 1705593201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently on my build I have a cheap Teamgroup 256GB M.2 NVME SSD and a old Toshiba 3TB 7200RPM HDD.\n\nThe SSD is at 65% health and is being used mainly for OS, programs a few games so I don't care if it suddenly dies. It's not the fastest but it works fine. \n\nHowever all my personal data and games are on the old HDD which I keep since my first gaming build. It's almost 9 years old and hast 32569 hours (3,75 years) of active usage. It still works pretty fine even for gaming. The only game than ended up having some reading speed problems was Cyberpunk but this only happened in the endgame. This made me worry a bit because I thought the HDD was dying.\n\nAthough SMART values say everything is fine. I ran a long surface test with Victoria and passed without problems. I'm still a bit concerned since I don't have a backup or anything.\n\nUnfortunately my motherboard only has one M.2 slot so if I wanted to make a only SSD build I'd have to replace the current one.\n\nI'm considering buying a 4TB HDD to make backups or maybe replace the older one. I have seen many good options with 256MB cache. I guess the higher the cache the better(?)\n\nAlso I thought about buying something like Intel Optane or an Hybrid HDD...\n\nWhat would you choose?\n\n&amp;#x200B;", "author_fullname": "t2_gmtguze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacement suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199pewq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705582117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently on my build I have a cheap Teamgroup 256GB M.2 NVME SSD and a old Toshiba 3TB 7200RPM HDD.&lt;/p&gt;\n\n&lt;p&gt;The SSD is at 65% health and is being used mainly for OS, programs a few games so I don&amp;#39;t care if it suddenly dies. It&amp;#39;s not the fastest but it works fine. &lt;/p&gt;\n\n&lt;p&gt;However all my personal data and games are on the old HDD which I keep since my first gaming build. It&amp;#39;s almost 9 years old and hast 32569 hours (3,75 years) of active usage. It still works pretty fine even for gaming. The only game than ended up having some reading speed problems was Cyberpunk but this only happened in the endgame. This made me worry a bit because I thought the HDD was dying.&lt;/p&gt;\n\n&lt;p&gt;Athough SMART values say everything is fine. I ran a long surface test with Victoria and passed without problems. I&amp;#39;m still a bit concerned since I don&amp;#39;t have a backup or anything.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately my motherboard only has one M.2 slot so if I wanted to make a only SSD build I&amp;#39;d have to replace the current one.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering buying a 4TB HDD to make backups or maybe replace the older one. I have seen many good options with 256MB cache. I guess the higher the cache the better(?)&lt;/p&gt;\n\n&lt;p&gt;Also I thought about buying something like Intel Optane or an Hybrid HDD...&lt;/p&gt;\n\n&lt;p&gt;What would you choose?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199pewq", "is_robot_indexable": true, "report_reasons": null, "author": "chemhha", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199pewq/replacement_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199pewq/replacement_suggestions/", "subreddit_subscribers": 726104, "created_utc": 1705582117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, community.\n\nDoes anyone has experience with [this product](https://www.delock.com/produkt/42622/merkmale.html?setLanguage=en)  or similar (on basis of chipset  JMicron JMS561) ? If yes, when you connect it in linux with two hdd in it, do you see them separately in /dev or just as one disk?", "author_fullname": "t2_3rrevo74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DeLOCK 2x hdd usb enclosure - is it JBOD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199m3wo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705569471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, community.&lt;/p&gt;\n\n&lt;p&gt;Does anyone has experience with &lt;a href=\"https://www.delock.com/produkt/42622/merkmale.html?setLanguage=en\"&gt;this product&lt;/a&gt;  or similar (on basis of chipset  JMicron JMS561) ? If yes, when you connect it in linux with two hdd in it, do you see them separately in /dev or just as one disk?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199m3wo", "is_robot_indexable": true, "report_reasons": null, "author": "JeNeSaisPasWarum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/199m3wo/delock_2x_hdd_usb_enclosure_is_it_jbod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199m3wo/delock_2x_hdd_usb_enclosure_is_it_jbod/", "subreddit_subscribers": 726104, "created_utc": 1705569471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a portable Samsung T-series drive. I want to store most of my important and frequently-accessed files/media. I\u2019d carry the drive on me when I\u2019m out for extended periods of time, sometimes with long stretches of no Internet access.\n\nWhen plugged into a trusted computer with Internet again, I\u2019d like to configure only the contents of the portable drive to get backed up automaticallly to B2 or a Minio instance. Most backup clients seem to support the reverse: on mount, backup computer files to the drive. I haven\u2019t found any explicit mentions of this feature among most common tools mentioned in this sub.\n\nAny and all ideas are appreciated!", "author_fullname": "t2_a64l1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strategy for automatic backups of potable SSD on mount?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1994mst", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705518168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a portable Samsung T-series drive. I want to store most of my important and frequently-accessed files/media. I\u2019d carry the drive on me when I\u2019m out for extended periods of time, sometimes with long stretches of no Internet access.&lt;/p&gt;\n\n&lt;p&gt;When plugged into a trusted computer with Internet again, I\u2019d like to configure only the contents of the portable drive to get backed up automaticallly to B2 or a Minio instance. Most backup clients seem to support the reverse: on mount, backup computer files to the drive. I haven\u2019t found any explicit mentions of this feature among most common tools mentioned in this sub.&lt;/p&gt;\n\n&lt;p&gt;Any and all ideas are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1994mst", "is_robot_indexable": true, "report_reasons": null, "author": "Nezteb", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1994mst/strategy_for_automatic_backups_of_potable_ssd_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1994mst/strategy_for_automatic_backups_of_potable_ssd_on/", "subreddit_subscribers": 726104, "created_utc": 1705518168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 18tb Seagate Exos data drive that failed today. Seagate setup a RMA but it could take a month to get the replacment drive.\n\nI currently have two levels of parity in Snapraid and have come up with a couple options to recover the bad drive.\n\n* Option A:  Remove the bad hard drive from my Snapraid.conf and when the replacment drive arrives, add it back to my Snapraid.conf then run \"Snapraid fix\" to recover the data. (not sure if this would trigger a full-resync which I would like to avoid if possible (as this array is 70TB)\n* Option B: Use my second parity drive (which is the same capacity as failed HDD) to replace the failed data drive, then when the replacment arrives assign the new drive to become Parity-2.\n\nWhich option makes most sense? I would like to keep my array up and running while waiting for the replacement HDD to arrive.\n\n&amp;#x200B;", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD failed (Repurpose Parity-2 as data drive?) &lt;Snapraid&gt;", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_199u94o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705595770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 18tb Seagate Exos data drive that failed today. Seagate setup a RMA but it could take a month to get the replacment drive.&lt;/p&gt;\n\n&lt;p&gt;I currently have two levels of parity in Snapraid and have come up with a couple options to recover the bad drive.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Option A:  Remove the bad hard drive from my Snapraid.conf and when the replacment drive arrives, add it back to my Snapraid.conf then run &amp;quot;Snapraid fix&amp;quot; to recover the data. (not sure if this would trigger a full-resync which I would like to avoid if possible (as this array is 70TB)&lt;/li&gt;\n&lt;li&gt;Option B: Use my second parity drive (which is the same capacity as failed HDD) to replace the failed data drive, then when the replacment arrives assign the new drive to become Parity-2.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Which option makes most sense? I would like to keep my array up and running while waiting for the replacement HDD to arrive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199u94o", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/199u94o/hdd_failed_repurpose_parity2_as_data_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199u94o/hdd_failed_repurpose_parity2_as_data_drive/", "subreddit_subscribers": 726104, "created_utc": 1705595770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So i have been looking replacement for Marcium Reflect and there seems to be none (free ones).  \nI'm filling to give acronis a chance (cause i can get it cheaper), but my need is:  \nI backup my main pc as an imgage to my NAS. In Marcium i can open the Image and browse the content. Then choose what i want to \"rescue\".\n\nI really do not need the clone-clone feature, even if my drive fails i wont be moving everything to the replacement drive. Just few hand picked files.\n\nQ: Can the Acronis Protect Home support this?", "author_fullname": "t2_1djtee8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Acronis as replacement for Marcium Reflect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_199tp8c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705594369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i have been looking replacement for Marcium Reflect and there seems to be none (free ones).&lt;br/&gt;\nI&amp;#39;m filling to give acronis a chance (cause i can get it cheaper), but my need is:&lt;br/&gt;\nI backup my main pc as an imgage to my NAS. In Marcium i can open the Image and browse the content. Then choose what i want to &amp;quot;rescue&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I really do not need the clone-clone feature, even if my drive fails i wont be moving everything to the replacement drive. Just few hand picked files.&lt;/p&gt;\n\n&lt;p&gt;Q: Can the Acronis Protect Home support this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "24TB + 4TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199tp8c", "is_robot_indexable": true, "report_reasons": null, "author": "YesThisIsi", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/199tp8c/acronis_as_replacement_for_marcium_reflect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199tp8c/acronis_as_replacement_for_marcium_reflect/", "subreddit_subscribers": 726104, "created_utc": 1705594369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have (or, had,) three NAS drives: one WD MyCloud, one WD MyCloud Home, and one WD MyCloud EX2 Ultra. I got the WD MyCloud in 2017 and now, after being online 24/7 since then, it has died on me. I plan on taking it to Geek Squad to liberate the drive from the dead enclosure.   \n  \nBut my question is: how long do NAS drives last? And does it being user-servicable or user-nonservicable matter? I was hoping to get at least a decade out of it.", "author_fullname": "t2_8swd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long do NAS drives typically last?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_199tgu9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705593760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have (or, had,) three NAS drives: one WD MyCloud, one WD MyCloud Home, and one WD MyCloud EX2 Ultra. I got the WD MyCloud in 2017 and now, after being online 24/7 since then, it has died on me. I plan on taking it to Geek Squad to liberate the drive from the dead enclosure.   &lt;/p&gt;\n\n&lt;p&gt;But my question is: how long do NAS drives last? And does it being user-servicable or user-nonservicable matter? I was hoping to get at least a decade out of it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "39TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "199tgu9", "is_robot_indexable": true, "report_reasons": null, "author": "tachibanakanade", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/199tgu9/how_long_do_nas_drives_typically_last/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/199tgu9/how_long_do_nas_drives_typically_last/", "subreddit_subscribers": 726104, "created_utc": 1705593760.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}