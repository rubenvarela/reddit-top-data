{"kind": "Listing", "data": {"after": "t3_199fdad", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm coming up on 1.5 YoE at my job where my title is \"data analyst\". This is my first real job and I got it out of college. Up until today, I assumed that I was a data analyst doing data analysty things and building a career in data analytics. However, since finding out that data engineering is a separate thing, I've started to suspect that I may actually be working in an entry-level data engineering role.\n\nThe job description asked for mastery of Tableau and proficiency in Python. Since starting, I've used Python for scripting a fair amount, but have used Tableau EDA a grand total of zero times. They trained me up in Alteryx, an ETL tool, and now my work mainly consists of Alteryx, SQL, and Python.\n\n90% of my work is building automated data pipelines for other teams; they come to us with some process that they're doing manually in Excel and we make it automatic for them. We follow an Agile framework, gather requirements, build and test, deploy and support. Our typical end product is an app that another team uses, not a dashboard.\n\nAm I actually a trainee data engineer? ", "author_fullname": "t2_dkj7fy8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did I get bamboozled into a data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199fg7g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 91, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 91, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705545828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m coming up on 1.5 YoE at my job where my title is &amp;quot;data analyst&amp;quot;. This is my first real job and I got it out of college. Up until today, I assumed that I was a data analyst doing data analysty things and building a career in data analytics. However, since finding out that data engineering is a separate thing, I&amp;#39;ve started to suspect that I may actually be working in an entry-level data engineering role.&lt;/p&gt;\n\n&lt;p&gt;The job description asked for mastery of Tableau and proficiency in Python. Since starting, I&amp;#39;ve used Python for scripting a fair amount, but have used Tableau EDA a grand total of zero times. They trained me up in Alteryx, an ETL tool, and now my work mainly consists of Alteryx, SQL, and Python.&lt;/p&gt;\n\n&lt;p&gt;90% of my work is building automated data pipelines for other teams; they come to us with some process that they&amp;#39;re doing manually in Excel and we make it automatic for them. We follow an Agile framework, gather requirements, build and test, deploy and support. Our typical end product is an app that another team uses, not a dashboard.&lt;/p&gt;\n\n&lt;p&gt;Am I actually a trainee data engineer? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "199fg7g", "is_robot_indexable": true, "report_reasons": null, "author": "WarCrimeWizard", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199fg7g/did_i_get_bamboozled_into_a_data_engineering_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199fg7g/did_i_get_bamboozled_into_a_data_engineering_job/", "subreddit_subscribers": 153735, "created_utc": 1705545828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1c6f704", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Ultimate Guide to Unit Testing With dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_198w13u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": "transparent", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kn_7noFCcJ0D3GC3fMXCYuMoZKNZe0YzGczP5o_Lm9E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705496494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datagibberish.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datagibberish.com/p/unit-testing-with-dbt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dMVSnzYeOz4m-v9_lFGHhqBVERA9g-3W0dnAdpsBiQs.jpg?auto=webp&amp;s=64087a3f1c05693b324e04792b5fe96ff216a457", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/dMVSnzYeOz4m-v9_lFGHhqBVERA9g-3W0dnAdpsBiQs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9174980cce3f2892735c33b75d4870bcd8ee80f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/dMVSnzYeOz4m-v9_lFGHhqBVERA9g-3W0dnAdpsBiQs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1c099adcd7a125bb2db8ac947f05ddbe3f0d6cb4", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/dMVSnzYeOz4m-v9_lFGHhqBVERA9g-3W0dnAdpsBiQs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f357a9fdd3ad5f6d9af7cad962d97242a563e81", "width": 320, "height": 320}], "variants": {}, "id": "OawLUvz2FSM3rDsbu-rhVg-PnA7GkLGIR6DvBSR00eE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "198w13u", "is_robot_indexable": true, "report_reasons": null, "author": "ivanovyordan", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/198w13u/the_ultimate_guide_to_unit_testing_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datagibberish.com/p/unit-testing-with-dbt", "subreddit_subscribers": 153735, "created_utc": 1705496494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I\u2019m a mechanical engineer working currently as a mechanical designer. I do HVAC/plumbing system design and analysis. My company is a consulting firm and everyone here has architectural engineering degrees, so I feel out of place. It\u2019s also a really small office and I don\u2019t like it nor do I feel comfortable here. I\u2019ve been working there for 7 months. It is my first job out of college and I\u2019ve realized I want to do something more concentrated in data/analysis. My favorite classes as an engineering student were linear algebra, differential equations, statistics etc. Are there online certifications/programs out there that will help expand my skills and are worth the money and time so I can get a new job? I\u2019d like to avoid going back to school because I don\u2019t want more debt.", "author_fullname": "t2_rcat5shey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I get into data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199dfy5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705540087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I\u2019m a mechanical engineer working currently as a mechanical designer. I do HVAC/plumbing system design and analysis. My company is a consulting firm and everyone here has architectural engineering degrees, so I feel out of place. It\u2019s also a really small office and I don\u2019t like it nor do I feel comfortable here. I\u2019ve been working there for 7 months. It is my first job out of college and I\u2019ve realized I want to do something more concentrated in data/analysis. My favorite classes as an engineering student were linear algebra, differential equations, statistics etc. Are there online certifications/programs out there that will help expand my skills and are worth the money and time so I can get a new job? I\u2019d like to avoid going back to school because I don\u2019t want more debt.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "199dfy5", "is_robot_indexable": true, "report_reasons": null, "author": "Serious-Look1597", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199dfy5/how_can_i_get_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199dfy5/how_can_i_get_into_data_engineering/", "subreddit_subscribers": 153735, "created_utc": 1705540087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sometimes when I run a pipeline or a query, while waiting for it to finish I find myself getting distracted on my phone (e.g. right now writing this post). What are some things y'all do while waiting for something to run?", "author_fullname": "t2_a2lh9x7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you spend your time waiting for things to run?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199lx3r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705568611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sometimes when I run a pipeline or a query, while waiting for it to finish I find myself getting distracted on my phone (e.g. right now writing this post). What are some things y&amp;#39;all do while waiting for something to run?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "199lx3r", "is_robot_indexable": true, "report_reasons": null, "author": "an27725", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199lx3r/how_do_you_spend_your_time_waiting_for_things_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199lx3r/how_do_you_spend_your_time_waiting_for_things_to/", "subreddit_subscribers": 153735, "created_utc": 1705568611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "   \nI've read a lot about data pipelines, I'd like to learn how to build them but I'm not sure what tools I should use. What do I need to know/learn in order to complete this task successfully?    \nAll I find is mostly generalized information nothing concrete and specific, could someone with experience help?   \nThanks.", "author_fullname": "t2_jrkpwx27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipeline for begunners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1994mwj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705518174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve read a lot about data pipelines, I&amp;#39;d like to learn how to build them but I&amp;#39;m not sure what tools I should use. What do I need to know/learn in order to complete this task successfully?&lt;br/&gt;\nAll I find is mostly generalized information nothing concrete and specific, could someone with experience help?&lt;br/&gt;\nThanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1994mwj", "is_robot_indexable": true, "report_reasons": null, "author": "Mundane-Research9306", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1994mwj/data_pipeline_for_begunners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1994mwj/data_pipeline_for_begunners/", "subreddit_subscribers": 153735, "created_utc": 1705518174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I'm building a data-focused software app, so while I don't require the same scale that traditional data engineering requires (due to lack of actual users so far lol), I'd still like some DE input.\n\nThe app is surrounding League of Legends, and the part of the software I'm concerned with right now is getting the data from the Riot API into our database.\n\nI have to process one player at a time, because the API call is on a per-player/per-match basis\n\nThe steps are essentially:\n\n1. Get the match IDs that a player has played\n2. Loop through these match IDs to make an API call, that returns the actual in-game data for that particular match\n3. Append all this data into a pandas dataframe\n   1. I know pandas is looked down upon as a transformation tool, but the total matches for each player is (at max) 1000 rows and \\~200 columns, which always fits within memory\n4. CAVEAT - due to the game itself changing over time, they are continually adding new columns/stats that are tracked in matches, so there are a changing # of columns returned by the API\n5. Because of the caveat, I take the intersection of the columns we have in the database already, and those returned by the API. I \"manually\" add the columns we don't have in the database `ALTER TABLE ADD COLUMN`\n6. I then just run a `df.to_sql()` to get all the matches into the database\n\nI realize that this isn't the best approach, because to have a table that is continually changing can lead to troubles.\n\nI would ideally like to store ALL data, but I really only need a subset of the data for the actual product that I'm trying to create.\n\n# The main question I have is, how should I handle extra fields being added to the API response?", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database design for my software app - how to handle changing fields from API response?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1995ho8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705520216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I&amp;#39;m building a data-focused software app, so while I don&amp;#39;t require the same scale that traditional data engineering requires (due to lack of actual users so far lol), I&amp;#39;d still like some DE input.&lt;/p&gt;\n\n&lt;p&gt;The app is surrounding League of Legends, and the part of the software I&amp;#39;m concerned with right now is getting the data from the Riot API into our database.&lt;/p&gt;\n\n&lt;p&gt;I have to process one player at a time, because the API call is on a per-player/per-match basis&lt;/p&gt;\n\n&lt;p&gt;The steps are essentially:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get the match IDs that a player has played&lt;/li&gt;\n&lt;li&gt;Loop through these match IDs to make an API call, that returns the actual in-game data for that particular match&lt;/li&gt;\n&lt;li&gt;Append all this data into a pandas dataframe\n\n&lt;ol&gt;\n&lt;li&gt;I know pandas is looked down upon as a transformation tool, but the total matches for each player is (at max) 1000 rows and ~200 columns, which always fits within memory&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;CAVEAT - due to the game itself changing over time, they are continually adding new columns/stats that are tracked in matches, so there are a changing # of columns returned by the API&lt;/li&gt;\n&lt;li&gt;Because of the caveat, I take the intersection of the columns we have in the database already, and those returned by the API. I &amp;quot;manually&amp;quot; add the columns we don&amp;#39;t have in the database &lt;code&gt;ALTER TABLE ADD COLUMN&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;I then just run a &lt;code&gt;df.to_sql()&lt;/code&gt; to get all the matches into the database&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I realize that this isn&amp;#39;t the best approach, because to have a table that is continually changing can lead to troubles.&lt;/p&gt;\n\n&lt;p&gt;I would ideally like to store ALL data, but I really only need a subset of the data for the actual product that I&amp;#39;m trying to create.&lt;/p&gt;\n\n&lt;h1&gt;The main question I have is, how should I handle extra fields being added to the API response?&lt;/h1&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1995ho8", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1995ho8/database_design_for_my_software_app_how_to_handle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1995ho8/database_design_for_my_software_app_how_to_handle/", "subreddit_subscribers": 153735, "created_utc": 1705520216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you have good strategies around keeping metabase organized?  \n\nWhat seems to happen is we get a lot of similar questions by different business units and then it\u2019s hard to find anything.\n\nOr the data changes- like google analytics not being supported has made a lot of charts go dead.\n\nHow do you all keep a handle on things?", "author_fullname": "t2_5gzu4ur4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organising metabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199e5tw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705542118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have good strategies around keeping metabase organized?  &lt;/p&gt;\n\n&lt;p&gt;What seems to happen is we get a lot of similar questions by different business units and then it\u2019s hard to find anything.&lt;/p&gt;\n\n&lt;p&gt;Or the data changes- like google analytics not being supported has made a lot of charts go dead.&lt;/p&gt;\n\n&lt;p&gt;How do you all keep a handle on things?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "199e5tw", "is_robot_indexable": true, "report_reasons": null, "author": "bluezebra42", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199e5tw/organising_metabase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199e5tw/organising_metabase/", "subreddit_subscribers": 153735, "created_utc": 1705542118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At [PeerDB](https://peerdb.io/), we recently added this new feature of SSH Tunneling to securely connect and replicate data from your Postgres Database to Data Warehouses. Sharing the blog that talks more about this feature - [https://blog.peerdb.io/ssh-tunneling-for-secure-postgres-replication](https://blog.peerdb.io/ssh-tunneling-for-secure-postgres-replication) We would love to hear your feedback!  \n\n\nhttps://i.redd.it/988cru7ik2dc1.gif", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSH Tunneling for Secure Postgres Replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"988cru7ik2dc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/988cru7ik2dc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=8247debf48bd7b30dc2b632d6df292a3f242e6a4"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/988cru7ik2dc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=b26a2dfc073a19318bce6c68203cae8a7b2ce71d"}, {"y": 212, "x": 320, "u": "https://preview.redd.it/988cru7ik2dc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=2cf9ebcf84f11e7b7fffaba87c2fd7f00a7229d5"}, {"y": 425, "x": 640, "u": "https://preview.redd.it/988cru7ik2dc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=9039157ad202ff353ef0d52e5985df4ba94d2205"}, {"y": 638, "x": 960, "u": "https://preview.redd.it/988cru7ik2dc1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=d503096068733ff38cb22debd3ead41083662dcc"}, {"y": 718, "x": 1080, "u": "https://preview.redd.it/988cru7ik2dc1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=edce4061c35e5baa5510ff80a57261aff55ded14"}], "s": {"y": 798, "gif": "https://i.redd.it/988cru7ik2dc1.gif", "mp4": "https://preview.redd.it/988cru7ik2dc1.gif?format=mp4&amp;s=8a19ea20ac78d0b5828f20c03272c1f0c63809c7", "x": 1200}, "id": "988cru7ik2dc1"}}, "name": "t3_1998e1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fyRlB0dqf4-D6iRV6cBPix78JLmW_cQB-0mLJhDnDIQ.jpg", "edited": 1705527371.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705527099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At &lt;a href=\"https://peerdb.io/\"&gt;PeerDB&lt;/a&gt;, we recently added this new feature of SSH Tunneling to securely connect and replicate data from your Postgres Database to Data Warehouses. Sharing the blog that talks more about this feature - &lt;a href=\"https://blog.peerdb.io/ssh-tunneling-for-secure-postgres-replication\"&gt;https://blog.peerdb.io/ssh-tunneling-for-secure-postgres-replication&lt;/a&gt; We would love to hear your feedback!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/988cru7ik2dc1.gif\"&gt;https://i.redd.it/988cru7ik2dc1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1998e1x", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1998e1x/ssh_tunneling_for_secure_postgres_replication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1998e1x/ssh_tunneling_for_secure_postgres_replication/", "subreddit_subscribers": 153735, "created_utc": 1705527099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I applied for a DE position at a major financial services company, and after the initial interview, they chose another candidate. Two months later, the job was reposted, and somewhat impulsively, I reapplied. Now, I've been contacted for another interview. I'm uncertain about proceeding because I fear the initial panel's opinion might not have changed. Would it be advisable to call and cancel the interview?", "author_fullname": "t2_i4gjp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reconsidering an Interview Opportunity After Initial Rejection: Seeking Advice on Whether to Proceed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1994v41", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705518720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I applied for a DE position at a major financial services company, and after the initial interview, they chose another candidate. Two months later, the job was reposted, and somewhat impulsively, I reapplied. Now, I&amp;#39;ve been contacted for another interview. I&amp;#39;m uncertain about proceeding because I fear the initial panel&amp;#39;s opinion might not have changed. Would it be advisable to call and cancel the interview?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1994v41", "is_robot_indexable": true, "report_reasons": null, "author": "Greckol", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1994v41/reconsidering_an_interview_opportunity_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1994v41/reconsidering_an_interview_opportunity_after/", "subreddit_subscribers": 153735, "created_utc": 1705518720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intro to SQL Indexes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_1991uni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2DRFBEjOvA1bk39vxVMwPZ3SCS2QfqVEESm-rljHqYQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705511648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/intro-to-sql-indexes", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?auto=webp&amp;s=db0dd46d348e43b93993efd89a3ab3188a2f750b", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb2ea7d2253e0b13f31c2b3a501bdb079c99f02a", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=774a9c7b5b1e9f2a6f0c3ad95da0fc6d8a27e60d", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59a28b06415dd585266957e277e86b821c702bb2", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe6f8284bd45732fa8e0bf3c2c0a5161ba9cfde4", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fadc5fdf695a74ba6f949375c70332ad149ab17d", "width": 960, "height": 562}], "variants": {}, "id": "Xv37p1IZSW1jS6YQK2dPjfcAGpVMaRZFFbZVqXsuRIE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1991uni", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1991uni/intro_to_sql_indexes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/intro-to-sql-indexes", "subreddit_subscribers": 153735, "created_utc": 1705511648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHi everyone\nI am a software engineer with 2 yrs of experience my company recently laid me off because of cost cutting and I have no job now I am actively looking for jobs but no luck and since then I have been upskilling my self in data engineering domain and during these 2 months I have learnt python ,snowflake, and currently learning spark and azure databricks\n\nSo can anyone here help me out with getting a job especially in data domain I don't mind working as an intern ( bcz I have no exp in this field I want to switch to this ) any help is appreciated thanks. \ud83d\ude4f", "author_fullname": "t2_ochcknol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_199nj7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705575348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone\nI am a software engineer with 2 yrs of experience my company recently laid me off because of cost cutting and I have no job now I am actively looking for jobs but no luck and since then I have been upskilling my self in data engineering domain and during these 2 months I have learnt python ,snowflake, and currently learning spark and azure databricks&lt;/p&gt;\n\n&lt;p&gt;So can anyone here help me out with getting a job especially in data domain I don&amp;#39;t mind working as an intern ( bcz I have no exp in this field I want to switch to this ) any help is appreciated thanks. \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "199nj7c", "is_robot_indexable": true, "report_reasons": null, "author": "LemonFluffy1488", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199nj7c/looking_for_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199nj7c/looking_for_jobs/", "subreddit_subscribers": 153735, "created_utc": 1705575348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are doing another iteration on our dataplatform. This time we will overhaul our ingestion framework from full-loads only to incremental. The deltas are stored as received in a data lake (ADLS Gen2).\n\nWe are using dbt as transformation tool and Azure SQL database as compute / storage.\n\nMy question is how would you get the incrementals staged ready to be referenced by the dbt models?\nHow to set the desired column data types?\nWhere would you perform schema checking?\n\nAny advice is welcome \ud83e\udd17", "author_fullname": "t2_5zyyjiwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ODS with dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199n6gu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705573940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are doing another iteration on our dataplatform. This time we will overhaul our ingestion framework from full-loads only to incremental. The deltas are stored as received in a data lake (ADLS Gen2).&lt;/p&gt;\n\n&lt;p&gt;We are using dbt as transformation tool and Azure SQL database as compute / storage.&lt;/p&gt;\n\n&lt;p&gt;My question is how would you get the incrementals staged ready to be referenced by the dbt models?\nHow to set the desired column data types?\nWhere would you perform schema checking?&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome \ud83e\udd17&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "199n6gu", "is_robot_indexable": true, "report_reasons": null, "author": "Ashamed_Cantaloupe_9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199n6gu/ods_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199n6gu/ods_with_dbt/", "subreddit_subscribers": 153735, "created_utc": 1705573940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I feel in the next few years solutions will come out to do analysis on more unstructured data (no not just log files), I mean video, audio, text and doing sentiment analysis on it to extract data and do data quality check to train a LLM\n\nAnyone doing this in their current data engineering job? Any tech stacks to do this that you recommend?", "author_fullname": "t2_5q1b2lj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unstructured data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199hke6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705552263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel in the next few years solutions will come out to do analysis on more unstructured data (no not just log files), I mean video, audio, text and doing sentiment analysis on it to extract data and do data quality check to train a LLM&lt;/p&gt;\n\n&lt;p&gt;Anyone doing this in their current data engineering job? Any tech stacks to do this that you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "199hke6", "is_robot_indexable": true, "report_reasons": null, "author": "Guilty-Commission435", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199hke6/unstructured_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199hke6/unstructured_data/", "subreddit_subscribers": 153735, "created_utc": 1705552263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you tried to programmatically export access details (name, role etc.) from SQL server (cloud or on-Prem) or oracle DBs? \n\nI am hoping to build a report on access and data rights across various data stores, primarily Azure SQL and others. \n\nAppreciate your perspective if you have tried something similar.", "author_fullname": "t2_dswp11x7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quick question on the database access management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1993m10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705515737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried to programmatically export access details (name, role etc.) from SQL server (cloud or on-Prem) or oracle DBs? &lt;/p&gt;\n\n&lt;p&gt;I am hoping to build a report on access and data rights across various data stores, primarily Azure SQL and others. &lt;/p&gt;\n\n&lt;p&gt;Appreciate your perspective if you have tried something similar.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1993m10", "is_robot_indexable": true, "report_reasons": null, "author": "abskiing403", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1993m10/quick_question_on_the_database_access_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1993m10/quick_question_on_the_database_access_management/", "subreddit_subscribers": 153735, "created_utc": 1705515737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was inspired by the [unofficial Python submission to the 1BRC](https://github.com/gunnarmorling/1brc/discussions/62) and wanted to share an implementation for Dask and PySpark: [https://github.com/gunnarmorling/1brc/discussions/450](https://github.com/gunnarmorling/1brc/discussions/450)  \nDask took \\~32 seconds, while Spark took \\~2 minutes.\n\nAmongst the other 1BRC Python submissions, Dask is pretty squarely in the middle. It\u2019s faster than Python\u2019s multiprocessing (except for the PyPy3 implementation) and slower than DuckDB and Polars. This is not too surprising given Polars and DuckDB tend to be faster than Dask on a smaller scale, especially on a single machine. I was actually pleasantly surprised to see this level of performance for Dask on a single machine for only a 13 GB dataset. This is largely due to a number of recent improvements in Dask like:  \n\\- Arrow strings  \n\\- New shuffling algorithms  \n\\- Query optimization  \n\n\nThough many of these improvements are still under active development in the dask-expr project, Dask users can expect to see these changes in core Dask DataFrame soon.  \n\n\nMore details in this blog post: [https://blog.coiled.io/blog/1brc.html](https://blog.coiled.io/blog/1brc.html)", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One billion row challenge - Dask vs. Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1992yx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705514242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was inspired by the &lt;a href=\"https://github.com/gunnarmorling/1brc/discussions/62\"&gt;unofficial Python submission to the 1BRC&lt;/a&gt; and wanted to share an implementation for Dask and PySpark: &lt;a href=\"https://github.com/gunnarmorling/1brc/discussions/450\"&gt;https://github.com/gunnarmorling/1brc/discussions/450&lt;/a&gt;&lt;br/&gt;\nDask took ~32 seconds, while Spark took ~2 minutes.&lt;/p&gt;\n\n&lt;p&gt;Amongst the other 1BRC Python submissions, Dask is pretty squarely in the middle. It\u2019s faster than Python\u2019s multiprocessing (except for the PyPy3 implementation) and slower than DuckDB and Polars. This is not too surprising given Polars and DuckDB tend to be faster than Dask on a smaller scale, especially on a single machine. I was actually pleasantly surprised to see this level of performance for Dask on a single machine for only a 13 GB dataset. This is largely due to a number of recent improvements in Dask like:&lt;br/&gt;\n- Arrow strings&lt;br/&gt;\n- New shuffling algorithms&lt;br/&gt;\n- Query optimization  &lt;/p&gt;\n\n&lt;p&gt;Though many of these improvements are still under active development in the dask-expr project, Dask users can expect to see these changes in core Dask DataFrame soon.  &lt;/p&gt;\n\n&lt;p&gt;More details in this blog post: &lt;a href=\"https://blog.coiled.io/blog/1brc.html\"&gt;https://blog.coiled.io/blog/1brc.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8YLTJORZcvmRbhmo__AN3FponNxyUFe5iX_7CPWV-Ds.jpg?auto=webp&amp;s=f9870422301fda8da802ca7aedf0b91b9a04a0c1", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/8YLTJORZcvmRbhmo__AN3FponNxyUFe5iX_7CPWV-Ds.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0e73b3946c993da59de05d21b3a12404282c3992", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8YLTJORZcvmRbhmo__AN3FponNxyUFe5iX_7CPWV-Ds.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d5ed51e011fcf63e510de41119007081bb008f5f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8YLTJORZcvmRbhmo__AN3FponNxyUFe5iX_7CPWV-Ds.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=854c5c277985af2914f5dea4655f9fd1d43900f9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8YLTJORZcvmRbhmo__AN3FponNxyUFe5iX_7CPWV-Ds.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=976f2c6eac5ecd200bffac409312ac5d983f6a63", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/8YLTJORZcvmRbhmo__AN3FponNxyUFe5iX_7CPWV-Ds.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=37d855a33c5c112cadc15c254621dd8014f9abe5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/8YLTJORZcvmRbhmo__AN3FponNxyUFe5iX_7CPWV-Ds.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2fc3acfdcb972dc2115035367fa753bc6d9fb9b4", "width": 1080, "height": 540}], "variants": {}, "id": "FOD8kSXmvpIvMnYCzs25YbyWTjYZjt9ymZFa-nV8Zds"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1992yx6", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1992yx6/one_billion_row_challenge_dask_vs_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1992yx6/one_billion_row_challenge_dask_vs_spark/", "subreddit_subscribers": 153735, "created_utc": 1705514242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All!\n\nToday, I'm launching [a project that I have been working on](https://www.linkedin.com/posts/briana-okyere_introducing-the-astronomer-champions-program-activity-7153422011896074240-qimp?utm_source=share&amp;utm_medium=member_desktop) for the last 6 months, and I want to share it with all of you.\n\nThe Astronomer Champions Program for Apache Airflow aims to **recognize outstanding data practitioners worldwide** who have **demonstrated excellence in leveraging the full capabilities of Apache Airflow in diverse capacities**. Today, I'm celebrating our Inaugural Cohort, and if you are passionate about Airflow, please [apply](https://docs.google.com/forms/d/e/1FAIpQLScSKVzfRf3wppjUbzx0dUzFLwoP66ZfQ6rYLjk9ZASzpKA2Dw/viewform) to our next cohort.\n\n[**Learn more about the program here**](https://www.astronomer.io/blog/introducing-the-astronomer-champions-program-for-apache-airflow/)**, and feel free to respond with any questions!**", "author_fullname": "t2_l5gu8nhgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Champions Program for Apache Airflow- Invite to Apply", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1991so2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705511520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All!&lt;/p&gt;\n\n&lt;p&gt;Today, I&amp;#39;m launching &lt;a href=\"https://www.linkedin.com/posts/briana-okyere_introducing-the-astronomer-champions-program-activity-7153422011896074240-qimp?utm_source=share&amp;amp;utm_medium=member_desktop\"&gt;a project that I have been working on&lt;/a&gt; for the last 6 months, and I want to share it with all of you.&lt;/p&gt;\n\n&lt;p&gt;The Astronomer Champions Program for Apache Airflow aims to &lt;strong&gt;recognize outstanding data practitioners worldwide&lt;/strong&gt; who have &lt;strong&gt;demonstrated excellence in leveraging the full capabilities of Apache Airflow in diverse capacities&lt;/strong&gt;. Today, I&amp;#39;m celebrating our Inaugural Cohort, and if you are passionate about Airflow, please &lt;a href=\"https://docs.google.com/forms/d/e/1FAIpQLScSKVzfRf3wppjUbzx0dUzFLwoP66ZfQ6rYLjk9ZASzpKA2Dw/viewform\"&gt;apply&lt;/a&gt; to our next cohort.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.astronomer.io/blog/introducing-the-astronomer-champions-program-for-apache-airflow/\"&gt;&lt;strong&gt;Learn more about the program here&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;, and feel free to respond with any questions!&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?auto=webp&amp;s=2d909d5a7d65908ef8fcfd7949a9b73664913bbe", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e0e68f887e066789358abba6b4426e3b4fe124a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f61ce6fc49f2b1d4585439a5738a62f4939e4a8e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d116fced6575e8124b63ea2f80a67d1954f3ee92", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac1df5a47081fff76bdfe8de826b9f1b9b741c3a", "width": 640, "height": 360}], "variants": {}, "id": "yH5v3ow6vBGicYhsqdR2lMV56YgJD_KEIWRCxL-rZac"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1991so2", "is_robot_indexable": true, "report_reasons": null, "author": "BrianaGraceOkyere", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1991so2/champions_program_for_apache_airflow_invite_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1991so2/champions_program_for_apache_airflow_invite_to/", "subreddit_subscribers": 153735, "created_utc": 1705511520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello experienced devs,\nI am a noob DE working in ADF, SSMS, data modelling and data warehousing with the government as a contractor. \n\nI am posting this as I recently switched from Manufacturing to IT and want to maintain a network with people that have exp in DE so I can learn and grow to become a completely capable software engineer; occasional chats/call is the most I\u2019m going to ask for. Since I\u2019m a contractor, I cannot connect/ask for guidance in my workplace\n\nCouple of years back I was an IE working on process improvements. I slowly learnt to write sql queries, get data from different internal systems, analyze the data and find opportunities for improvement. \n\nOne day I found out that what I was doing was not very different from our in-house data analyst\u2019s role. \n\nThen, I learned Azure services and got a job as a contractor. Now I\u2019m struggling to move up and would need your mentorship. I am in NYC area, so I can meetup at your convineance.\n\ntl;dr: a noob DE want a mentor to help navigate through the data carrier.", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got some time to mentor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1991m63", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705511140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello experienced devs,\nI am a noob DE working in ADF, SSMS, data modelling and data warehousing with the government as a contractor. &lt;/p&gt;\n\n&lt;p&gt;I am posting this as I recently switched from Manufacturing to IT and want to maintain a network with people that have exp in DE so I can learn and grow to become a completely capable software engineer; occasional chats/call is the most I\u2019m going to ask for. Since I\u2019m a contractor, I cannot connect/ask for guidance in my workplace&lt;/p&gt;\n\n&lt;p&gt;Couple of years back I was an IE working on process improvements. I slowly learnt to write sql queries, get data from different internal systems, analyze the data and find opportunities for improvement. &lt;/p&gt;\n\n&lt;p&gt;One day I found out that what I was doing was not very different from our in-house data analyst\u2019s role. &lt;/p&gt;\n\n&lt;p&gt;Then, I learned Azure services and got a job as a contractor. Now I\u2019m struggling to move up and would need your mentorship. I am in NYC area, so I can meetup at your convineance.&lt;/p&gt;\n\n&lt;p&gt;tl;dr: a noob DE want a mentor to help navigate through the data carrier.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1991m63", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1991m63/got_some_time_to_mentor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1991m63/got_some_time_to_mentor/", "subreddit_subscribers": 153735, "created_utc": 1705511140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Reddit, i turn to you once again for a DE issue. TIA.\n\n&amp;#x200B;\n\n**Currently:**\n\n\"RDS MySQL &gt; DMS &gt; Redshift\"\n\nDMS is configured for a \\`full load, ongoing replication\\` (lags around 6-12 hours everyday ig)\n\n&amp;#x200B;\n\n**Problem:**\n\nExpense (unutilized instance after initial full load) and want to move away CDC to a different tool, as a POC\n\n&amp;#x200B;\n\n**POC** **TODO**: (*no choice here*)\n\nMySQL &gt; Kafka &gt; *Redshift sync connector (necessarily)*\n\n&amp;#x200B;\n\nAssuming the POC *has* to be done..\n\n*Questions:*\n\n1. **Duplicates**: There's mention of \"atleast once delivery\" into sync'd table, and a dummy topic set up on confluent cloud confirmed presence of \\~10k dupes per 1mil rows. Support could not answer pattern on when/why it occurs. How should one tackle this? Not sure if ksqdDB/single message transform can help here.\n2. **CDC:** There is a latest\\_updated\\_ts to help determine updates, how can the sync connector handle upserting? [docs](https://docs.confluent.io/kafka-connectors/aws-redshift/current/sink_config_options.html#redshift-sink-config-options) mention insert OR update (\"*this will only apply when modifying a record; you can\u2019t use this mode to insert a new record if the record doesn\u2019t already exist*\"). Solution to run two parallel ones?\n3. What other tests should one do? I've done basic data sanity checks so far, and plan to set up a kafka local to stream to redshift to test a dummy run.\n\nApologies if there's basic issues in my writings. TIA, once again!", "author_fullname": "t2_vvcegq1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift sync connector to replace DMS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199105x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705511098.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705509739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Reddit, i turn to you once again for a DE issue. TIA.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Currently:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;RDS MySQL &amp;gt; DMS &amp;gt; Redshift&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;DMS is configured for a `full load, ongoing replication` (lags around 6-12 hours everyday ig)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Expense (unutilized instance after initial full load) and want to move away CDC to a different tool, as a POC&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;POC&lt;/strong&gt; &lt;strong&gt;TODO&lt;/strong&gt;: (&lt;em&gt;no choice here&lt;/em&gt;)&lt;/p&gt;\n\n&lt;p&gt;MySQL &amp;gt; Kafka &amp;gt; &lt;em&gt;Redshift sync connector (necessarily)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Assuming the POC &lt;em&gt;has&lt;/em&gt; to be done..&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Questions:&lt;/em&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Duplicates&lt;/strong&gt;: There&amp;#39;s mention of &amp;quot;atleast once delivery&amp;quot; into sync&amp;#39;d table, and a dummy topic set up on confluent cloud confirmed presence of ~10k dupes per 1mil rows. Support could not answer pattern on when/why it occurs. How should one tackle this? Not sure if ksqdDB/single message transform can help here.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;CDC:&lt;/strong&gt; There is a latest_updated_ts to help determine updates, how can the sync connector handle upserting? &lt;a href=\"https://docs.confluent.io/kafka-connectors/aws-redshift/current/sink_config_options.html#redshift-sink-config-options\"&gt;docs&lt;/a&gt; mention insert OR update (&amp;quot;&lt;em&gt;this will only apply when modifying a record; you can\u2019t use this mode to insert a new record if the record doesn\u2019t already exist&lt;/em&gt;&amp;quot;). Solution to run two parallel ones?&lt;/li&gt;\n&lt;li&gt;What other tests should one do? I&amp;#39;ve done basic data sanity checks so far, and plan to set up a kafka local to stream to redshift to test a dummy run.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Apologies if there&amp;#39;s basic issues in my writings. TIA, once again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "199105x", "is_robot_indexable": true, "report_reasons": null, "author": "LocksmithConnect6201", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199105x/redshift_sync_connector_to_replace_dms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199105x/redshift_sync_connector_to_replace_dms/", "subreddit_subscribers": 153735, "created_utc": 1705509739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an upcoming interview where one of the steps is to create a mock data model what should I be reading up on in preparation. And what are the key things they will wlbe looking out for and be considering when doing such an exercise?\n\nFor context I have decent amount of data experience just lacking formal data Modeling experience any tips would be appreciated thanks in advance", "author_fullname": "t2_n2nlx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Interview scenario questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_199nzng", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705577110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an upcoming interview where one of the steps is to create a mock data model what should I be reading up on in preparation. And what are the key things they will wlbe looking out for and be considering when doing such an exercise?&lt;/p&gt;\n\n&lt;p&gt;For context I have decent amount of data experience just lacking formal data Modeling experience any tips would be appreciated thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "199nzng", "is_robot_indexable": true, "report_reasons": null, "author": "yanicklloyd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199nzng/data_modeling_interview_scenario_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199nzng/data_modeling_interview_scenario_questions/", "subreddit_subscribers": 153735, "created_utc": 1705577110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://i.redd.it/lnl14vvul6dc1.gif\n\n[Article is here](https://blog.devgenius.io/exposing-snowflake-data-as-a-rest-api-a-step-by-step-guide-746ceefecaa3)", "author_fullname": "t2_jjbftfcy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to expose the data resides in snowflake via REST API for downstream consumption?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": true, "media_metadata": {"lnl14vvul6dc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/lnl14vvul6dc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=85cbdc411487f40e89e1a3d1549eb5aff5e6e269"}, {"y": 98, "x": 216, "u": "https://preview.redd.it/lnl14vvul6dc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=25ec0d74807989fa824334acc274caa243102b5a"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/lnl14vvul6dc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=f92287c14a6ae3fc24148ff18aa1cc2b9b4942da"}, {"y": 291, "x": 640, "u": "https://preview.redd.it/lnl14vvul6dc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=e3e296c59d3090a35ad4fda61b681cd64c598438"}, {"y": 437, "x": 960, "u": "https://preview.redd.it/lnl14vvul6dc1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=af4aa443af0140fdd5b0ca33e38cd09f59edcfb3"}, {"y": 492, "x": 1080, "u": "https://preview.redd.it/lnl14vvul6dc1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=68c72bc27dfb75b2485521757a5562f60f0fb396"}], "s": {"y": 503, "gif": "https://i.redd.it/lnl14vvul6dc1.gif", "mp4": "https://preview.redd.it/lnl14vvul6dc1.gif?format=mp4&amp;s=57e8de237dc4c9db1ad91d38b58b2f7dcc8cd331", "x": 1104}, "id": "lnl14vvul6dc1"}}, "name": "t3_199nt3j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/BtjkOji4csPvCafLHPhxIro2xi4nMtzTdAeVrXlLq34.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1705576405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/lnl14vvul6dc1.gif\"&gt;https://i.redd.it/lnl14vvul6dc1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.devgenius.io/exposing-snowflake-data-as-a-rest-api-a-step-by-step-guide-746ceefecaa3\"&gt;Article is here&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JIhhgwDvtACWoiUvbIWFHS6V56MfU_tMj2xz0goRj2I.jpg?auto=webp&amp;s=72761ed7d1250f22002b0231b8ced2e6569574f9", "width": 800, "height": 487}, "resolutions": [{"url": "https://external-preview.redd.it/JIhhgwDvtACWoiUvbIWFHS6V56MfU_tMj2xz0goRj2I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a6d85adb5474f570a96bd3af14c75caae6812fb", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/JIhhgwDvtACWoiUvbIWFHS6V56MfU_tMj2xz0goRj2I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c64fd8a80c569a1fbe95a215f02b92a458da887", "width": 216, "height": 131}, {"url": "https://external-preview.redd.it/JIhhgwDvtACWoiUvbIWFHS6V56MfU_tMj2xz0goRj2I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d0cd0986c8058b4667cb5d32d552c9bb05ac68b", "width": 320, "height": 194}, {"url": "https://external-preview.redd.it/JIhhgwDvtACWoiUvbIWFHS6V56MfU_tMj2xz0goRj2I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b9108a76580d1b3fee3f2b494f9e413b08feef1b", "width": 640, "height": 389}], "variants": {}, "id": "go2X7gEtBrGmdgQvl0M84bbCXbiOuCysCjzBLNvAMaY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "199nt3j", "is_robot_indexable": true, "report_reasons": null, "author": "BigNo3623", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199nt3j/how_to_expose_the_data_resides_in_snowflake_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199nt3j/how_to_expose_the_data_resides_in_snowflake_via/", "subreddit_subscribers": 153735, "created_utc": 1705576405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 15+ year exp in DW engg and 8+ yrs in cloud aws with big data tools  including spark and data bricks.  I also have few AWS certifications and cloudera certifications but they are not current now.\n\nI recently got laid off in November and have been looking for opportunities.  seems like now a days all the buzz is ML and AI which i am lacking.  Question to fellow Engineers is it better to learn additional tools/platforms like Snowflake + aws professional level certs or jump into AI/ML learning which i got to say is not natural to me i am finding it difficult to learn.  Any advice\n\n&amp;#x200B;", "author_fullname": "t2_j52nsle3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "laid off and looking for next best option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199n5mr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705573849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 15+ year exp in DW engg and 8+ yrs in cloud aws with big data tools  including spark and data bricks.  I also have few AWS certifications and cloudera certifications but they are not current now.&lt;/p&gt;\n\n&lt;p&gt;I recently got laid off in November and have been looking for opportunities.  seems like now a days all the buzz is ML and AI which i am lacking.  Question to fellow Engineers is it better to learn additional tools/platforms like Snowflake + aws professional level certs or jump into AI/ML learning which i got to say is not natural to me i am finding it difficult to learn.  Any advice&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "199n5mr", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Fee-4006", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199n5mr/laid_off_and_looking_for_next_best_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199n5mr/laid_off_and_looking_for_next_best_option/", "subreddit_subscribers": 153735, "created_utc": 1705573849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just created a custom GPT to explore various MMP DBs. \n\nIf you have access to the OpenAI GPT Marketplace, please give it a try at https://chat.openai.com/g/g-yrhRXkSOH-mpp-database-consultant. \n\nI would appreciate any feedback on what is working and what is missing.\n\nThank you!", "author_fullname": "t2_3z4w4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MPP Database Consultant GPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199j43i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705557433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just created a custom GPT to explore various MMP DBs. &lt;/p&gt;\n\n&lt;p&gt;If you have access to the OpenAI GPT Marketplace, please give it a try at &lt;a href=\"https://chat.openai.com/g/g-yrhRXkSOH-mpp-database-consultant\"&gt;https://chat.openai.com/g/g-yrhRXkSOH-mpp-database-consultant&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;I would appreciate any feedback on what is working and what is missing.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_0d2v6aqibcxdg487iCYbUALEPotmALam0QOsw8aFl4.jpg?auto=webp&amp;s=fc4ff1643f00d16cbee18c5355e308038628fefd", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/_0d2v6aqibcxdg487iCYbUALEPotmALam0QOsw8aFl4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0967c759cc7f7295cf3bb3f85f872bde8e419878", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/_0d2v6aqibcxdg487iCYbUALEPotmALam0QOsw8aFl4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98283101455b4af4693c655f98bb021c964e0119", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/_0d2v6aqibcxdg487iCYbUALEPotmALam0QOsw8aFl4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=db3e0df875ce96d2371235d730d219dcb3890e0b", "width": 320, "height": 320}], "variants": {}, "id": "UyedLX-UX5HbkaLTYTa--FpSFs-LTIzS4CmgPXvE6dc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "199j43i", "is_robot_indexable": true, "report_reasons": null, "author": "drighten", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199j43i/mpp_database_consultant_gpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199j43i/mpp_database_consultant_gpt/", "subreddit_subscribers": 153735, "created_utc": 1705557433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Coming from GCP, etls, pipelines, maintenance routines, data manipulation, everything is -or can be- code. (beam, airflow, spark, functions, bash scripts, terraform). Code that is usually version controlled on a git repo, and cicd pipelined to deploy. I am aware that there are some no-code tools, such as data fusion, but hadn't really seen those used for production.\n\nNow, I am facing an azure project for the first time, so having my first contact with this cloud. I've seen that in the team, everyone uses the web interface, so for example if required to check the contents of some parquet files in a storage container, they would download them from the storage, by using the web portal, to the local machine and run there a python script, while in gcp you tipically do that using a cloud shell or even a vm, by using shell commands (sdk or client libraries). Is this the way to go in azure? am I missing something?\n\nIn the same sense, when they work with data factory, they just click and configure. is this really a no-code tool?  If it is, is this at least creating a pipeline file in the backstage that you at least back up? can the data factory pipelines be version-controlled in a repo? \n\nby the way, this idea  of backing it up is coming because in the same way, they keep several versions of the power bi pbix files on their local machines. \n\n&amp;#x200B;", "author_fullname": "t2_14crgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "question for azure DEs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199gmbd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705549310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming from GCP, etls, pipelines, maintenance routines, data manipulation, everything is -or can be- code. (beam, airflow, spark, functions, bash scripts, terraform). Code that is usually version controlled on a git repo, and cicd pipelined to deploy. I am aware that there are some no-code tools, such as data fusion, but hadn&amp;#39;t really seen those used for production.&lt;/p&gt;\n\n&lt;p&gt;Now, I am facing an azure project for the first time, so having my first contact with this cloud. I&amp;#39;ve seen that in the team, everyone uses the web interface, so for example if required to check the contents of some parquet files in a storage container, they would download them from the storage, by using the web portal, to the local machine and run there a python script, while in gcp you tipically do that using a cloud shell or even a vm, by using shell commands (sdk or client libraries). Is this the way to go in azure? am I missing something?&lt;/p&gt;\n\n&lt;p&gt;In the same sense, when they work with data factory, they just click and configure. is this really a no-code tool?  If it is, is this at least creating a pipeline file in the backstage that you at least back up? can the data factory pipelines be version-controlled in a repo? &lt;/p&gt;\n\n&lt;p&gt;by the way, this idea  of backing it up is coming because in the same way, they keep several versions of the power bi pbix files on their local machines. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "199gmbd", "is_robot_indexable": true, "report_reasons": null, "author": "untalmau", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199gmbd/question_for_azure_des/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199gmbd/question_for_azure_des/", "subreddit_subscribers": 153735, "created_utc": 1705549310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title", "author_fullname": "t2_p9gvk8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you think the job market will be this year (2024)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199ghsm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705548907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "199ghsm", "is_robot_indexable": true, "report_reasons": null, "author": "marcelorojas56", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199ghsm/how_do_you_think_the_job_market_will_be_this_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199ghsm/how_do_you_think_the_job_market_will_be_this_year/", "subreddit_subscribers": 153735, "created_utc": 1705548907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m interviewing for a new data engineering position. I had the recruiter screening and they explained the rest of the interviews will be technical / about my experience, and then technical with data structures, algorithms, system design, and Bayesian probability problems. I\u2019m a data engineer currently and haven\u2019t touched any of that in years since my schooling. I\u2019m actually a little surprised any of this (other than data structures) would appear in a data engineering interview. \n\nAny good resources out there aside from just doing Leet Code?", "author_fullname": "t2_1yo0xaq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview prep - DS&amp;A, System Design, Probability", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_199fdad", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705545597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m interviewing for a new data engineering position. I had the recruiter screening and they explained the rest of the interviews will be technical / about my experience, and then technical with data structures, algorithms, system design, and Bayesian probability problems. I\u2019m a data engineer currently and haven\u2019t touched any of that in years since my schooling. I\u2019m actually a little surprised any of this (other than data structures) would appear in a data engineering interview. &lt;/p&gt;\n\n&lt;p&gt;Any good resources out there aside from just doing Leet Code?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "199fdad", "is_robot_indexable": true, "report_reasons": null, "author": "justanator101", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199fdad/interview_prep_dsa_system_design_probability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199fdad/interview_prep_dsa_system_design_probability/", "subreddit_subscribers": 153735, "created_utc": 1705545597.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}