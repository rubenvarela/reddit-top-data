{"kind": "Listing", "data": {"after": null, "dist": 3, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "DS and analytics is a vast field and most employees will have gaps in their knowledge/skill that need to be filled. Each employee is unique so they are the ones who can best tell what they need to learn in order to (a) do better at work and also (b) grow in their career.\n\nI feel many know what it is that they want to learn but cannot find time for it with their work load. And therefore, a dedicated learning week which can set expectations with all stakeholders that DS/analytics team is upgrading is must have. Maybe even employees can do knowledge sharing at end of week or start of next week. \n\nCompany can eventually provide learning resources (courses, workshops, trainers etc.) but they shouldn't restrict employees on what they need to learn. It should at max be a discussion between employee and manager, where manager puts in suggestions but employee takes the final call. \n\nPlease share your thoughts. Do you think such a thing would work?", "author_fullname": "t2_t8udov", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies should give employees a whole week (with no expected deliverables) dedicated to learning each year", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1abk6du", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706280947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DS and analytics is a vast field and most employees will have gaps in their knowledge/skill that need to be filled. Each employee is unique so they are the ones who can best tell what they need to learn in order to (a) do better at work and also (b) grow in their career.&lt;/p&gt;\n\n&lt;p&gt;I feel many know what it is that they want to learn but cannot find time for it with their work load. And therefore, a dedicated learning week which can set expectations with all stakeholders that DS/analytics team is upgrading is must have. Maybe even employees can do knowledge sharing at end of week or start of next week. &lt;/p&gt;\n\n&lt;p&gt;Company can eventually provide learning resources (courses, workshops, trainers etc.) but they shouldn&amp;#39;t restrict employees on what they need to learn. It should at max be a discussion between employee and manager, where manager puts in suggestions but employee takes the final call. &lt;/p&gt;\n\n&lt;p&gt;Please share your thoughts. Do you think such a thing would work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "1abk6du", "is_robot_indexable": true, "report_reasons": null, "author": "maverick_css", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1abk6du/companies_should_give_employees_a_whole_week_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1abk6du/companies_should_give_employees_a_whole_week_with/", "subreddit_subscribers": 1278755, "created_utc": 1706280947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In addition to the title, I have a more specific example: Let\u2019s say you\u2019re a broadly experienced senior data analyst who has worn many hats transitioning into a formal DS role.  You\u2019ve done some ML(and have the education like a math BS) but nothing crazy, mostly just extensions of data analyses you\u2019ve done.   Would you still be a junior data scientist or  would you be a mid level? Or is your opinion that junior, mid level, and senior is just based on independence of guidance? \n\nThis is obviously disregarding people who\u2019ve been hired out of their level, titles, etc. this is mostly a discussion purely about what you would consider early, mid, and senior DS.", "author_fullname": "t2_14wbpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What differentiates a junior, mid, or senior level data scientist?(in your opinion/experience)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1abndsd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706289053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In addition to the title, I have a more specific example: Let\u2019s say you\u2019re a broadly experienced senior data analyst who has worn many hats transitioning into a formal DS role.  You\u2019ve done some ML(and have the education like a math BS) but nothing crazy, mostly just extensions of data analyses you\u2019ve done.   Would you still be a junior data scientist or  would you be a mid level? Or is your opinion that junior, mid level, and senior is just based on independence of guidance? &lt;/p&gt;\n\n&lt;p&gt;This is obviously disregarding people who\u2019ve been hired out of their level, titles, etc. this is mostly a discussion purely about what you would consider early, mid, and senior DS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1abndsd", "is_robot_indexable": true, "report_reasons": null, "author": "kater543", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1abndsd/what_differentiates_a_junior_mid_or_senior_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1abndsd/what_differentiates_a_junior_mid_or_senior_level/", "subreddit_subscribers": 1278755, "created_utc": 1706289053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m working on tackling daily and weekly swings in some of our key metrics. These metrics are based on similar data coming through our logistics system that basically a waterfall. A change towards the beginning of the process will likely affect a change towards the middle and end unless materials fall out if the process somewhere. We have seen that these metrics do often live together but we don\u2019t currently have a clean way to see causation (or at least correlation) when x metric moves. So when we see a shift in metric A we\u2019re all running around pulling raw data and looking at old dashboards trying to come up with a story.\n\nBy building a table with daily granularity and breaking out each KPI by day I\u2019d like to write a model to determine feature importance (as a coefficient) all other metrics have on each other metric. Basically get multiple coefficient scores for each feature (metric) that represents how they impact each other metric. The methods I\u2019m thinking of testing are below, but before I start writing any code I figured I\u2019d ask here to make sure I\u2019m thinking about this the right way. Would also greatly appreciate input from anyone that has built a well-performing feature importance model. I\u2019ll be reading up this weekend as well. \n\nCART \nDecisionTree\nLiner regression\nXGBoost", "author_fullname": "t2_h9bp3xei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Importance for KPIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1abinn6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706276636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on tackling daily and weekly swings in some of our key metrics. These metrics are based on similar data coming through our logistics system that basically a waterfall. A change towards the beginning of the process will likely affect a change towards the middle and end unless materials fall out if the process somewhere. We have seen that these metrics do often live together but we don\u2019t currently have a clean way to see causation (or at least correlation) when x metric moves. So when we see a shift in metric A we\u2019re all running around pulling raw data and looking at old dashboards trying to come up with a story.&lt;/p&gt;\n\n&lt;p&gt;By building a table with daily granularity and breaking out each KPI by day I\u2019d like to write a model to determine feature importance (as a coefficient) all other metrics have on each other metric. Basically get multiple coefficient scores for each feature (metric) that represents how they impact each other metric. The methods I\u2019m thinking of testing are below, but before I start writing any code I figured I\u2019d ask here to make sure I\u2019m thinking about this the right way. Would also greatly appreciate input from anyone that has built a well-performing feature importance model. I\u2019ll be reading up this weekend as well. &lt;/p&gt;\n\n&lt;p&gt;CART \nDecisionTree\nLiner regression\nXGBoost&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "1abinn6", "is_robot_indexable": true, "report_reasons": null, "author": "yrmidon", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1abinn6/feature_importance_for_kpis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1abinn6/feature_importance_for_kpis/", "subreddit_subscribers": 1278755, "created_utc": 1706276636.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}