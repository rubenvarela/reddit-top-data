{"kind": "Listing", "data": {"after": "t3_1950lxe", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have been using databricks(aws) close to a year now and have started working with DLTs \\[Delta Live Tables\\]. I personally don't hate them as much as my teammates but I don't blame them, a lot of DLT limitations are in direct contradiction with the Databricks vision. Reasons listed below:\n\n* You have to be on shared compute, this complicates reading data and writing back out to s3 if you need to drop a file (need to be in single user mode)\n* BIGGEST COMPLAINT: You cannot \"hop\" catalogs or even schemas. This is so weird to me. They are rolling out DLT and UC \\[Unity Catalog\\] and are pushing customers hard on both, but DLTs directly contradict the medallion architecture. You want to have data land in a bronze catalog, then move it to a silver, gold, etc. Great, create a pipeline for each and kill your job runtime because you now have to spin up 3 different computes. They had a private preview that allowed you to write to multiple schemas but they killed it. Why?\n* DLTs have to run from workspace notebooks, because GIT providers can only point to a users specific repo, not a config'd repo and branch like a notebook job. Luckily we have DABs to control our deployment and skirt this issue but it seems so odd to us. The DLT documentation recommends setting up a repo per pipeline, thats insane!\n* Cannot share compute across multiple pipelines. To my second point, the limitation of not being able to hop schemas/catalogs wouldn't matter if I could specify DLT compute to use in the three pipelines processing the data. That solves a huge problem.\n* Documentation, community support is still weak.\n\nI do love the automation DLT brings with ingesting data, specifically CDC data. But there are some pain-points that make absolutely no sense. I think Databricks is doing too much too fast and needs to refocus on what they were initially, a data platform that provided one place to do everything.", "author_fullname": "t2_81ywblydd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My whole team hates DLTs and I don't blame them.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19501yg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 75, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 75, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705091443.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705079212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have been using databricks(aws) close to a year now and have started working with DLTs [Delta Live Tables]. I personally don&amp;#39;t hate them as much as my teammates but I don&amp;#39;t blame them, a lot of DLT limitations are in direct contradiction with the Databricks vision. Reasons listed below:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You have to be on shared compute, this complicates reading data and writing back out to s3 if you need to drop a file (need to be in single user mode)&lt;/li&gt;\n&lt;li&gt;BIGGEST COMPLAINT: You cannot &amp;quot;hop&amp;quot; catalogs or even schemas. This is so weird to me. They are rolling out DLT and UC [Unity Catalog] and are pushing customers hard on both, but DLTs directly contradict the medallion architecture. You want to have data land in a bronze catalog, then move it to a silver, gold, etc. Great, create a pipeline for each and kill your job runtime because you now have to spin up 3 different computes. They had a private preview that allowed you to write to multiple schemas but they killed it. Why?&lt;/li&gt;\n&lt;li&gt;DLTs have to run from workspace notebooks, because GIT providers can only point to a users specific repo, not a config&amp;#39;d repo and branch like a notebook job. Luckily we have DABs to control our deployment and skirt this issue but it seems so odd to us. The DLT documentation recommends setting up a repo per pipeline, thats insane!&lt;/li&gt;\n&lt;li&gt;Cannot share compute across multiple pipelines. To my second point, the limitation of not being able to hop schemas/catalogs wouldn&amp;#39;t matter if I could specify DLT compute to use in the three pipelines processing the data. That solves a huge problem.&lt;/li&gt;\n&lt;li&gt;Documentation, community support is still weak.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I do love the automation DLT brings with ingesting data, specifically CDC data. But there are some pain-points that make absolutely no sense. I think Databricks is doing too much too fast and needs to refocus on what they were initially, a data platform that provided one place to do everything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19501yg", "is_robot_indexable": true, "report_reasons": null, "author": "DataDoyle", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19501yg/my_whole_team_hates_dlts_and_i_dont_blame_them/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19501yg/my_whole_team_hates_dlts_and_i_dont_blame_them/", "subreddit_subscribers": 152283, "created_utc": 1705079212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a recruiter or a hiring manager for a data engineering entry level position what projects would impress you more or make a student stand out, I know quite a bit of SQL and Python (I can solve Leetcode medium to hard in both) what would you recommend as project that would help me get into DE, thanks", "author_fullname": "t2_a28jw39v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Projects that would impress you", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19533tp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705086798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a recruiter or a hiring manager for a data engineering entry level position what projects would impress you more or make a student stand out, I know quite a bit of SQL and Python (I can solve Leetcode medium to hard in both) what would you recommend as project that would help me get into DE, thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19533tp", "is_robot_indexable": true, "report_reasons": null, "author": "Some-Landscape-4763", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19533tp/projects_that_would_impress_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19533tp/projects_that_would_impress_you/", "subreddit_subscribers": 152283, "created_utc": 1705086798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious about how's the landscape out there, and what is the general maturity of ETL data pipelines. I've worked many years with old school server based GUI ETL tools like DataStage and PowerCenter, and then had to migrate to pipelines in Hive (Azure HDInsight) and blob storage/hdfs. Now our pipeline is just custom python scripts that run in parallel (threads) running queries on Google BigQuery (more of an ELT actually).  \n\n\nHow are you guys doing it?  \n\n\n1- Talend, DataStage, PowerCenter, SSIS?  \n2- Some custom solution?  \n3- Dataproc/HDInsight running spark/hive/pig?  \n4- Apache Beam?  \n5- Something else?", "author_fullname": "t2_q0c2atq8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your business implements their ETL pipeline (if at all)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194vdyx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705067065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious about how&amp;#39;s the landscape out there, and what is the general maturity of ETL data pipelines. I&amp;#39;ve worked many years with old school server based GUI ETL tools like DataStage and PowerCenter, and then had to migrate to pipelines in Hive (Azure HDInsight) and blob storage/hdfs. Now our pipeline is just custom python scripts that run in parallel (threads) running queries on Google BigQuery (more of an ELT actually).  &lt;/p&gt;\n\n&lt;p&gt;How are you guys doing it?  &lt;/p&gt;\n\n&lt;p&gt;1- Talend, DataStage, PowerCenter, SSIS?&lt;br/&gt;\n2- Some custom solution?&lt;br/&gt;\n3- Dataproc/HDInsight running spark/hive/pig?&lt;br/&gt;\n4- Apache Beam?&lt;br/&gt;\n5- Something else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194vdyx", "is_robot_indexable": true, "report_reasons": null, "author": "rikarleite", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194vdyx/how_does_your_business_implements_their_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194vdyx/how_does_your_business_implements_their_etl/", "subreddit_subscribers": 152283, "created_utc": 1705067065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sorry if this is a basic or stupid question, i guess it applies to many software engineering situations (compiling code, deploying, testing, etc) but in DE there's some times where I need to debug, a 10 min spark job on EMR as an example, and i struggle to know what i should do during those 10 minutes. Sure i could \"do something else\" in the meanwhile but i feel the context switching is what makes me feel burnt out at the end of the day. Yet i can't sit there and do nothing since if i have 12 errors, 2 hours of my day is gone. Again, basic question but i wonder what hacks i can implement to improve my efficiency and state.\n\nDo you maybe do related reading? busywork email? (push ups? just kidding.)", "author_fullname": "t2_hvng1539", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Work habits in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194wbtw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705075646.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705069620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is a basic or stupid question, i guess it applies to many software engineering situations (compiling code, deploying, testing, etc) but in DE there&amp;#39;s some times where I need to debug, a 10 min spark job on EMR as an example, and i struggle to know what i should do during those 10 minutes. Sure i could &amp;quot;do something else&amp;quot; in the meanwhile but i feel the context switching is what makes me feel burnt out at the end of the day. Yet i can&amp;#39;t sit there and do nothing since if i have 12 errors, 2 hours of my day is gone. Again, basic question but i wonder what hacks i can implement to improve my efficiency and state.&lt;/p&gt;\n\n&lt;p&gt;Do you maybe do related reading? busywork email? (push ups? just kidding.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "194wbtw", "is_robot_indexable": true, "report_reasons": null, "author": "Pretty_Meet2795", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194wbtw/work_habits_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194wbtw/work_habits_in_de/", "subreddit_subscribers": 152283, "created_utc": 1705069620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are just starting to plan out the data infrastructure but this is what it looks like so far:\n\n&amp;#x200B;\n\n* **Data sources**: SQL database, exported flat files that are stored in Google Cloud storage, a few APIs\n* Python to extract and load data into bigquery \n* Python code with unit tests, logging, modules, alerts, etc containerized with docker and pushed to  an artifact registry \n* The docker image is then deployed by cloud run jobs to run the container on a schedule to start extracting and loading data\n* dbt is then used for transformations + all the other goodies it comes with \n\nThe velocity and volume of our data is very minimal and is meant for internal BI/ML use. While I want to keep scalability, maintenance, and best practices in mind, the normal constraints of big data engineering jobs are not the main concern- mostly implementing the most cost-effective, minimal solution that follows best practices. ", "author_fullname": "t2_2qknd8ft", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on small organization's ELT implementation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194yo0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705075743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are just starting to plan out the data infrastructure but this is what it looks like so far:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data sources&lt;/strong&gt;: SQL database, exported flat files that are stored in Google Cloud storage, a few APIs&lt;/li&gt;\n&lt;li&gt;Python to extract and load data into bigquery &lt;/li&gt;\n&lt;li&gt;Python code with unit tests, logging, modules, alerts, etc containerized with docker and pushed to  an artifact registry &lt;/li&gt;\n&lt;li&gt;The docker image is then deployed by cloud run jobs to run the container on a schedule to start extracting and loading data&lt;/li&gt;\n&lt;li&gt;dbt is then used for transformations + all the other goodies it comes with &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The velocity and volume of our data is very minimal and is meant for internal BI/ML use. While I want to keep scalability, maintenance, and best practices in mind, the normal constraints of big data engineering jobs are not the main concern- mostly implementing the most cost-effective, minimal solution that follows best practices. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "194yo0s", "is_robot_indexable": true, "report_reasons": null, "author": "muneriver", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194yo0s/advice_on_small_organizations_elt_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194yo0s/advice_on_small_organizations_elt_implementation/", "subreddit_subscribers": 152283, "created_utc": 1705075743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video: Setting Up Apache Superset on your Laptop with Docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_19512hz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/604i8vaukZs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Apache Superset &amp;amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Apache Superset &amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/604i8vaukZs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Apache Superset &amp;amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/604i8vaukZs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/604i8vaukZs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Apache Superset &amp;amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/19512hz", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oVlDQo-alRVItOVypVLR7wWhtsaBJngjgsYBDlzngVM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705081726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=604i8vaukZs", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pi6a5dPpQyiZN07qUvMXSCex6BExjzSYXyHz_4Ebx-8.jpg?auto=webp&amp;s=016ce139a48feadd1b228bf0505a6c68270afffa", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/pi6a5dPpQyiZN07qUvMXSCex6BExjzSYXyHz_4Ebx-8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=694886e5fdc0a91128da13001ceb4f1b64e0f2fe", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/pi6a5dPpQyiZN07qUvMXSCex6BExjzSYXyHz_4Ebx-8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0fad22fe12731dd67210673f1a0ad60f559028e4", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/pi6a5dPpQyiZN07qUvMXSCex6BExjzSYXyHz_4Ebx-8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b70007611ada02582576b8d3556238ff79483793", "width": 320, "height": 240}], "variants": {}, "id": "i4YLT3SrljZIs-wWmojPiCdeQDpHy1sSxIAnW7cRtUI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "19512hz", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19512hz/video_setting_up_apache_superset_on_your_laptop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=604i8vaukZs", "subreddit_subscribers": 152283, "created_utc": 1705081726.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Apache Superset &amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/604i8vaukZs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Apache Superset &amp;amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/604i8vaukZs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a smallish company but we don\u2019t spend a lot on data team resourcing. So by default I\u2019m the all inclusive data engineer, architect, analyst and requests come from all departments. \n\nAnyone here find it really challenging to source, ingest,  model, shape AND then do analysis?\n\nI used to be analyst but had a much smaller slice of the pie and did no engineering, I was good at doing the analysis and making recommendations.  But now I get to the end of the whole process and I really struggle to analyse the data, anyone else been here or have any tips?", "author_fullname": "t2_uqyn3qdq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Fatigue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195k5tz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705137632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a smallish company but we don\u2019t spend a lot on data team resourcing. So by default I\u2019m the all inclusive data engineer, architect, analyst and requests come from all departments. &lt;/p&gt;\n\n&lt;p&gt;Anyone here find it really challenging to source, ingest,  model, shape AND then do analysis?&lt;/p&gt;\n\n&lt;p&gt;I used to be analyst but had a much smaller slice of the pie and did no engineering, I was good at doing the analysis and making recommendations.  But now I get to the end of the whole process and I really struggle to analyse the data, anyone else been here or have any tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195k5tz", "is_robot_indexable": true, "report_reasons": null, "author": "variance-explained", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195k5tz/data_fatigue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195k5tz/data_fatigue/", "subreddit_subscribers": 152283, "created_utc": 1705137632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious what kinda of utilization times folks have across various data orchestrators (airflow, prefect, dagster, etc.). All the big systems require some kind of always-on infrastructure to handle scheduling and provide API access, but in most cases require very little of that capacity most of the time.\n\nWe run a hybrid airflow+prefect platform at the office, but our 90% of our workloads run daily and 10% run hourly, with most jobs taking 5-15 minutes to finish. So we have a huge spike at midnight for an hour or so, then a few minutes of work each hour for the rest of the day. Besides, those servers are only responsible to manage compute that's being run on other services (like a k8s cluster), so even when the orchestrator's \"busy\", it has fairly little CPU burden and is mostly just polling external services every few seconds. Net result, our orchestrators use maybe \\~5% of their capacity on any given day, with almost all of that being during the first hour of each day. Still costs an arm and a leg (MWAA, Astronomer, Prefect cloud, they all cost a lot even if you're doing very little with them), and some of those components still have to be scaled for peak usage and can't easily auto-scale.\n\nAnyone else have this frustration? Any common solutions?", "author_fullname": "t2_ry3h6ade6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling like data orchestrators mostly waste compute resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1957xt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705098946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious what kinda of utilization times folks have across various data orchestrators (airflow, prefect, dagster, etc.). All the big systems require some kind of always-on infrastructure to handle scheduling and provide API access, but in most cases require very little of that capacity most of the time.&lt;/p&gt;\n\n&lt;p&gt;We run a hybrid airflow+prefect platform at the office, but our 90% of our workloads run daily and 10% run hourly, with most jobs taking 5-15 minutes to finish. So we have a huge spike at midnight for an hour or so, then a few minutes of work each hour for the rest of the day. Besides, those servers are only responsible to manage compute that&amp;#39;s being run on other services (like a k8s cluster), so even when the orchestrator&amp;#39;s &amp;quot;busy&amp;quot;, it has fairly little CPU burden and is mostly just polling external services every few seconds. Net result, our orchestrators use maybe ~5% of their capacity on any given day, with almost all of that being during the first hour of each day. Still costs an arm and a leg (MWAA, Astronomer, Prefect cloud, they all cost a lot even if you&amp;#39;re doing very little with them), and some of those components still have to be scaled for peak usage and can&amp;#39;t easily auto-scale.&lt;/p&gt;\n\n&lt;p&gt;Anyone else have this frustration? Any common solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1957xt1", "is_robot_indexable": true, "report_reasons": null, "author": "archeprototypical2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1957xt1/feeling_like_data_orchestrators_mostly_waste/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1957xt1/feeling_like_data_orchestrators_mostly_waste/", "subreddit_subscribers": 152283, "created_utc": 1705098946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a Structured-Streaming pipeline and have ran into what seems like a major issue for me which is that there is no great support for error handling. Example: if I have a dataset of rows that I am trying to process and one of those rows fails due to virtually any unexpected reason, the default behavior of Structured-Streaming is that the stream will crash. If I setup my job to restart on failure, and the error is not transient, then the stream will simply be unable to proceed beyond that point until some solution is implemented in the job code to handle it.\n\nIn my google-search for solutions to this problem, I have found a lot of very custom solutions to this. One solution is to write custom validation for each row to check for exception cases, and then conditionally handle rows differently depending on the outcome of validation, but this will only help in the cases that we can foresee, and not the unexpected.\n\nAnother solution is to handle all transformations inside of a forEachBatch, so that the whole batch transformation can be wrapped in a try/catch, of course this will result in the entire batch failing in the event of a single row failure.\n\nI expect that many others have had to implement pipelines that encounter poison-pill messages and so it seems odd to me that there is no clear solution for this.", "author_fullname": "t2_24qsknvi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Error Handling in Spark and Structured-Streaming, How to Avoid Stream Crashes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1956yj7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705096496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a Structured-Streaming pipeline and have ran into what seems like a major issue for me which is that there is no great support for error handling. Example: if I have a dataset of rows that I am trying to process and one of those rows fails due to virtually any unexpected reason, the default behavior of Structured-Streaming is that the stream will crash. If I setup my job to restart on failure, and the error is not transient, then the stream will simply be unable to proceed beyond that point until some solution is implemented in the job code to handle it.&lt;/p&gt;\n\n&lt;p&gt;In my google-search for solutions to this problem, I have found a lot of very custom solutions to this. One solution is to write custom validation for each row to check for exception cases, and then conditionally handle rows differently depending on the outcome of validation, but this will only help in the cases that we can foresee, and not the unexpected.&lt;/p&gt;\n\n&lt;p&gt;Another solution is to handle all transformations inside of a forEachBatch, so that the whole batch transformation can be wrapped in a try/catch, of course this will result in the entire batch failing in the event of a single row failure.&lt;/p&gt;\n\n&lt;p&gt;I expect that many others have had to implement pipelines that encounter poison-pill messages and so it seems odd to me that there is no clear solution for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1956yj7", "is_robot_indexable": true, "report_reasons": null, "author": "steve_thousand", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1956yj7/error_handling_in_spark_and_structuredstreaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1956yj7/error_handling_in_spark_and_structuredstreaming/", "subreddit_subscribers": 152283, "created_utc": 1705096496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have completed a few projects on data engineering (real world projects and not demo projects). I know how and where to use the common tools. I have mostly been doing this on Azure. So I am familiar with services like synapse analytics, data factory, databricks (pyspark) , SQL databases. And PowerBI for visualization purposes. I had done the basics of ML(classification, clustering, some simple Deep learning, etc...) a few years ago. But that's not enough. How much time would it take to get decent at ML and and probably be amongst the top 15% in this industry globally?", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard is it for a Data Engineer to move into ML/Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_195l6dn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705141912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have completed a few projects on data engineering (real world projects and not demo projects). I know how and where to use the common tools. I have mostly been doing this on Azure. So I am familiar with services like synapse analytics, data factory, databricks (pyspark) , SQL databases. And PowerBI for visualization purposes. I had done the basics of ML(classification, clustering, some simple Deep learning, etc...) a few years ago. But that&amp;#39;s not enough. How much time would it take to get decent at ML and and probably be amongst the top 15% in this industry globally?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195l6dn", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195l6dn/how_hard_is_it_for_a_data_engineer_to_move_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195l6dn/how_hard_is_it_for_a_data_engineer_to_move_into/", "subreddit_subscribers": 152283, "created_utc": 1705141912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I was learning about Spark with Scala I read that Datasets are a very powerful feature as they allow for compile-time type checking, as well as taking advantage of functional programming when performing transformations.\n\nBut most sources I read mentioned that they are also slower than DataFrames, although according to [this article](https://itnext.io/making-the-spark-dataframe-composition-type-safe-r-7b6fed524ec2) from 2021 the performance gap between these two is narrowing. Moving 2 years later, [another article](https://sparkbyexamples.com/spark/spark-rdd-vs-dataframe-vs-dataset/) (from November 2023) claims that Datasets are actually faster than DataFrames.\n\nCan anyone confirm if it's true? And if so, does it make sense to only use Datasets when processing data using Spark with Scala? Or are there any areas where DataFrames would be a better choice?", "author_fullname": "t2_wn5fz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Datasets vs DataFrames performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1955qoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705093375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was learning about Spark with Scala I read that Datasets are a very powerful feature as they allow for compile-time type checking, as well as taking advantage of functional programming when performing transformations.&lt;/p&gt;\n\n&lt;p&gt;But most sources I read mentioned that they are also slower than DataFrames, although according to &lt;a href=\"https://itnext.io/making-the-spark-dataframe-composition-type-safe-r-7b6fed524ec2\"&gt;this article&lt;/a&gt; from 2021 the performance gap between these two is narrowing. Moving 2 years later, &lt;a href=\"https://sparkbyexamples.com/spark/spark-rdd-vs-dataframe-vs-dataset/\"&gt;another article&lt;/a&gt; (from November 2023) claims that Datasets are actually faster than DataFrames.&lt;/p&gt;\n\n&lt;p&gt;Can anyone confirm if it&amp;#39;s true? And if so, does it make sense to only use Datasets when processing data using Spark with Scala? Or are there any areas where DataFrames would be a better choice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?auto=webp&amp;s=3659cb0ddeb74f683e31b3620c391557aab5b547", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8744007118b1803247340b55f9685e254e553344", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=97e18e3884ace6f756fe8bccd4414ea29a8a9a8e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=06d4c55c572f7bd130164ffbe711a21954f18d38", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aff6e3db79b99dc83947ef1c99ed3c8567779378", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9be1733b25c40df472838fe9dc4d62ec88946a0e", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a841da9143ad1ce3f334a9a20139318b27975924", "width": 1080, "height": 720}], "variants": {}, "id": "1DzNUL7ZJLW7OT6sHMlmsLRjaSVL1prwDVVMlK9OUe8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955qoh", "is_robot_indexable": true, "report_reasons": null, "author": "Cydros1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955qoh/spark_datasets_vs_dataframes_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955qoh/spark_datasets_vs_dataframes_performance/", "subreddit_subscribers": 152283, "created_utc": 1705093375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The co-creators of Apache Iceberg have their own startup called Tabular.io\n\nHas anyone had a demo or signed up as a customer yet? \n\nI\u2019m curious what a managed iceberg implementation helps with.", "author_fullname": "t2_41soa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Tabular.io?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1955ps1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705093309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The co-creators of Apache Iceberg have their own startup called Tabular.io&lt;/p&gt;\n\n&lt;p&gt;Has anyone had a demo or signed up as a customer yet? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what a managed iceberg implementation helps with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955ps1", "is_robot_indexable": true, "report_reasons": null, "author": "miqcie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955ps1/thoughts_on_tabulario/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955ps1/thoughts_on_tabulario/", "subreddit_subscribers": 152283, "created_utc": 1705093309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been asking people I know and the general consensus is that they're not that useful, but that's a biased people out there. I figure there must be people out there who find tools like Monte Carlo valuable, have you all found them generally useful?", "author_fullname": "t2_vxxrqrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone actually find their data quality/anomaly detection applications useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1952j59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705085371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been asking people I know and the general consensus is that they&amp;#39;re not that useful, but that&amp;#39;s a biased people out there. I figure there must be people out there who find tools like Monte Carlo valuable, have you all found them generally useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1952j59", "is_robot_indexable": true, "report_reasons": null, "author": "MrMosBiggestFan", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1952j59/does_anyone_actually_find_their_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1952j59/does_anyone_actually_find_their_data/", "subreddit_subscribers": 152283, "created_utc": 1705085371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you need a university degree to be employable? If so is a bsc in statistics(with courses in programming and economics as well not just the theoretical maths)good?(This is what I'm pursuing).Also does it matter what grade you finish with or is having the degree enough? If you are from europe(as that is where I'm studying) your answers are especially relevant. Thank you!", "author_fullname": "t2_8meol9a2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need university for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194x2i4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705071639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you need a university degree to be employable? If so is a bsc in statistics(with courses in programming and economics as well not just the theoretical maths)good?(This is what I&amp;#39;m pursuing).Also does it matter what grade you finish with or is having the degree enough? If you are from europe(as that is where I&amp;#39;m studying) your answers are especially relevant. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194x2i4", "is_robot_indexable": true, "report_reasons": null, "author": "Dizzy-Location4602", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194x2i4/do_you_need_university_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194x2i4/do_you_need_university_for_data_engineering/", "subreddit_subscribers": 152283, "created_utc": 1705071639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, thank you for reading this post.\n\nI'm currently working as a Data Engineer, primarily in ETL, with 1.8 years of experience across 3 projects using Azure Data Factory (ADF). I'm proficient in ADF, have intermediate SQL skills, and basic knowledge of Python. I'm contemplating a job switch and facing some uncertainties. Here are my main concerns:\n\n1. Choosing between Snowflake and Databricks, leaning towards Snowflake due to my strong SQL skills.\n\n2. Considering online master courses (e.g., Trendy Tech DE Master Program) for a structured learning approach and to stay motivated.\n\n3. Seeking advice on additional areas to focus on.\n\n4. Unsure if learning Python with DSA is essential and whether online or offline courses are preferable. PS - I don't like to code and also want to be in DE field but just going with the demand.\n\nYour insights would greatly help in easing my confusion and career pressure.\n\n", "author_fullname": "t2_i159isc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Serious Help/Suggestions for my Career.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194svgx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705059130.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705058877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, thank you for reading this post.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a Data Engineer, primarily in ETL, with 1.8 years of experience across 3 projects using Azure Data Factory (ADF). I&amp;#39;m proficient in ADF, have intermediate SQL skills, and basic knowledge of Python. I&amp;#39;m contemplating a job switch and facing some uncertainties. Here are my main concerns:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Choosing between Snowflake and Databricks, leaning towards Snowflake due to my strong SQL skills.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Considering online master courses (e.g., Trendy Tech DE Master Program) for a structured learning approach and to stay motivated.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Seeking advice on additional areas to focus on.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Unsure if learning Python with DSA is essential and whether online or offline courses are preferable. PS - I don&amp;#39;t like to code and also want to be in DE field but just going with the demand.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your insights would greatly help in easing my confusion and career pressure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194svgx", "is_robot_indexable": true, "report_reasons": null, "author": "Own_Zookeepergame256", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194svgx/need_serious_helpsuggestions_for_my_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194svgx/need_serious_helpsuggestions_for_my_career/", "subreddit_subscribers": 152283, "created_utc": 1705058877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\ude80 Introducing UCX v0.9.0: Enhanced Assessment, Migration, and Error Handling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_19572kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TNMCFXsgR41T19nR1UxOeSaBE6fD06aUmltGMmw0bkk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705096792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/databricks-labs/introducing-ucx-v0-9-0-enhanced-assessment-migration-and-error-handling-3ccc006e0e26", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?auto=webp&amp;s=c3a64525650ecc3b3246f72ff4c7731359e29643", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c127031ef68b5e7d090e57d1b544bb6dc8fe7ea6", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f33f40602699860f9ba0ee53b24a8229d2adcfe", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f01229576b99d538b96703137e171d63d36fb23", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c65db3de6bb9a9ff7f2744baf20b8593fa02810", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d93c71542a157e849d52106f12e66192578bfaf", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1a4fdddca0d72408e46877076397e8e83235b07a", "width": 1080, "height": 1080}], "variants": {}, "id": "X3VkNmf9xWp7yRf8PYLCd1FkoLiuA_kYVGG8Ot8M8c0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19572kd", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19572kd/introducing_ucx_v090_enhanced_assessment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/databricks-labs/introducing-ucx-v0-9-0-enhanced-assessment-migration-and-error-handling-3ccc006e0e26", "subreddit_subscribers": 152283, "created_utc": 1705096792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I might be shortsighted about this topic and I wouldn't have any problem in admitting it. However, I've never talked to a DE that has worked with Databricks, ever. I've worked in mid-sized companies and Databricks has never been a topic discussed.  \nMost positions I see don't ask for Databricks knowledge or experience, at least in Brazil, where I'm from, or Portugal, where I'm looking some opportunities recently. Looking at their website, it seems that only very large companies use their services. \n\nFrom a management point of view, why would you use another platform instead of using the cloud that your company already uses? Wouldn't it be cheaper and easier to negotiate some discounts (like reserved instances) and keep everything in 'one stack'?\n\nI want to emphasize that I'm not saying the Databricks is useless or bad. I only wants to understand what companies use it and why.  \n", "author_fullname": "t2_jsmqklq8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Databricks a niche enterprise platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1955990", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705092172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I might be shortsighted about this topic and I wouldn&amp;#39;t have any problem in admitting it. However, I&amp;#39;ve never talked to a DE that has worked with Databricks, ever. I&amp;#39;ve worked in mid-sized companies and Databricks has never been a topic discussed.&lt;br/&gt;\nMost positions I see don&amp;#39;t ask for Databricks knowledge or experience, at least in Brazil, where I&amp;#39;m from, or Portugal, where I&amp;#39;m looking some opportunities recently. Looking at their website, it seems that only very large companies use their services. &lt;/p&gt;\n\n&lt;p&gt;From a management point of view, why would you use another platform instead of using the cloud that your company already uses? Wouldn&amp;#39;t it be cheaper and easier to negotiate some discounts (like reserved instances) and keep everything in &amp;#39;one stack&amp;#39;?&lt;/p&gt;\n\n&lt;p&gt;I want to emphasize that I&amp;#39;m not saying the Databricks is useless or bad. I only wants to understand what companies use it and why.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955990", "is_robot_indexable": true, "report_reasons": null, "author": "Rude_effect_74", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955990/is_databricks_a_niche_enterprise_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955990/is_databricks_a_niche_enterprise_platform/", "subreddit_subscribers": 152283, "created_utc": 1705092172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm a data scientist at a very small startup, trying to grasp some DE concepts. I have a python script that downloads data from a database, does some processing in pandas and then uploads it to another service via their SDK. I want this script to run automatically once a day.\n\n&amp;#x200B;\n\nWe work with Azure and unlikely to move to AWS currently, but are open to using any other tools. Could I get some direction on how to set this up? I see Airflow could be relevant but I don't understand where the computation in Airflow actually run. Do I need to connect it to Azure somehow to give it access to computing power?", "author_fullname": "t2_dqzrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to set up a data processing script automatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195jn3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705135376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m a data scientist at a very small startup, trying to grasp some DE concepts. I have a python script that downloads data from a database, does some processing in pandas and then uploads it to another service via their SDK. I want this script to run automatically once a day.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We work with Azure and unlikely to move to AWS currently, but are open to using any other tools. Could I get some direction on how to set this up? I see Airflow could be relevant but I don&amp;#39;t understand where the computation in Airflow actually run. Do I need to connect it to Azure somehow to give it access to computing power?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195jn3v", "is_robot_indexable": true, "report_reasons": null, "author": "PixelPixell", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195jn3v/how_to_set_up_a_data_processing_script/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195jn3v/how_to_set_up_a_data_processing_script/", "subreddit_subscribers": 152283, "created_utc": 1705135376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm moving to a new team DataOps at 50% capacity. This was announced to be effective December 2023 no significant movement on the same. I tried to reach the team lead in December she mentioned she is busy and will reach back. Nothing happened. She gave me a link for video dated seven months its already a legacy as the meeting she mentioned there is going to be lot of changes. Again in January 2024 I reached out again asking for more information, spoke over zoom for the first time. Gave me few run books to look at. I asked provide me an architecture which I can understand what job I'm going into. Its been a week now no other progress don't know I will be blamed and it seems it might be a way to lay me off. Any advise on this. I cant blame the the tem lead to the director cos I have been already raising my voice to the director for the past couple of years about stagnation", "author_fullname": "t2_3i19ucis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joining a New Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1952e3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705085018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m moving to a new team DataOps at 50% capacity. This was announced to be effective December 2023 no significant movement on the same. I tried to reach the team lead in December she mentioned she is busy and will reach back. Nothing happened. She gave me a link for video dated seven months its already a legacy as the meeting she mentioned there is going to be lot of changes. Again in January 2024 I reached out again asking for more information, spoke over zoom for the first time. Gave me few run books to look at. I asked provide me an architecture which I can understand what job I&amp;#39;m going into. Its been a week now no other progress don&amp;#39;t know I will be blamed and it seems it might be a way to lay me off. Any advise on this. I cant blame the the tem lead to the director cos I have been already raising my voice to the director for the past couple of years about stagnation&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1952e3i", "is_robot_indexable": true, "report_reasons": null, "author": "BeginningAd4923", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1952e3i/joining_a_new_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1952e3i/joining_a_new_team/", "subreddit_subscribers": 152283, "created_utc": 1705085018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, looking for some suggestions on replicating an on-prem oracle DB to either Azure or a SQL Server db. ~10 million rows, so not huge by the standards of this sub.\n\nWe run dagster as our orchestrator right now (self hosted) so looking for something that integrates with it. No K8 either or CDC for the oracle source...\n\nLots of chatter around airbyte being an option, but not a huge fan of the startup-cost of it (# of containers for example) and the lack of K8. Does feel like the most straightforward option; certainly divided opinions on this sub about it.\n\nGenerally we have steered clear of data factory, but still on the table. I don't think it would play nice with dagster though.\n\nMy current best feeling is to just work through the data in chunks and replicate by date time. Combining that with partitions in dagster to make it manageable. Does feel a bit over-worked to have it essentially doing what AB or Meltano is doing (meltano has terrible oracle taps from my experience). plus i'd be dealing with the pyodbc overhead (no spark currently, but also on the table!)\n\nInitial sync would be slow, but the incremental chunks after would be ok. Downside is i need to essentially store the whole block in memory or disk while replicating.\n\nSuggestions/thoughts? Appreciate the help dealing with these \"legacy\" systems... cry for me too...", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replication options from Oracle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1950045", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705079088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, looking for some suggestions on replicating an on-prem oracle DB to either Azure or a SQL Server db. ~10 million rows, so not huge by the standards of this sub.&lt;/p&gt;\n\n&lt;p&gt;We run dagster as our orchestrator right now (self hosted) so looking for something that integrates with it. No K8 either or CDC for the oracle source...&lt;/p&gt;\n\n&lt;p&gt;Lots of chatter around airbyte being an option, but not a huge fan of the startup-cost of it (# of containers for example) and the lack of K8. Does feel like the most straightforward option; certainly divided opinions on this sub about it.&lt;/p&gt;\n\n&lt;p&gt;Generally we have steered clear of data factory, but still on the table. I don&amp;#39;t think it would play nice with dagster though.&lt;/p&gt;\n\n&lt;p&gt;My current best feeling is to just work through the data in chunks and replicate by date time. Combining that with partitions in dagster to make it manageable. Does feel a bit over-worked to have it essentially doing what AB or Meltano is doing (meltano has terrible oracle taps from my experience). plus i&amp;#39;d be dealing with the pyodbc overhead (no spark currently, but also on the table!)&lt;/p&gt;\n\n&lt;p&gt;Initial sync would be slow, but the incremental chunks after would be ok. Downside is i need to essentially store the whole block in memory or disk while replicating.&lt;/p&gt;\n\n&lt;p&gt;Suggestions/thoughts? Appreciate the help dealing with these &amp;quot;legacy&amp;quot; systems... cry for me too...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1950045", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1950045/replication_options_from_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1950045/replication_options_from_oracle/", "subreddit_subscribers": 152283, "created_utc": 1705079088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "can i work with it through the vscode extension tho? i'd like to know cause thats what we are studying in uni for now , but if thats not the case then i would be okay with a close equivalent  ", "author_fullname": "t2_6elmofyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "oracle equivalent for mac?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195ketb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705138691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;can i work with it through the vscode extension tho? i&amp;#39;d like to know cause thats what we are studying in uni for now , but if thats not the case then i would be okay with a close equivalent  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195ketb", "is_robot_indexable": true, "report_reasons": null, "author": "Getsuga_H", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195ketb/oracle_equivalent_for_mac/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195ketb/oracle_equivalent_for_mac/", "subreddit_subscribers": 152283, "created_utc": 1705138691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently using Athena with JSON files in S3. We use all Presto SQL features - our JSON files and corresponding Athena tables have arrays, etc. What would you recommend for a local stack on Unix? Install Presto + JSON as local files or Presto + Hadoop/Hive? Are there any other options? Thank you, -- Alex", "author_fullname": "t2_e1ws1vmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Migrate from Athena/JSON on S3 to Presto on Unix.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1954xw0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705091380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently using Athena with JSON files in S3. We use all Presto SQL features - our JSON files and corresponding Athena tables have arrays, etc. What would you recommend for a local stack on Unix? Install Presto + JSON as local files or Presto + Hadoop/Hive? Are there any other options? Thank you, -- Alex&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1954xw0", "is_robot_indexable": true, "report_reasons": null, "author": "flareplf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1954xw0/how_to_migrate_from_athenajson_on_s3_to_presto_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1954xw0/how_to_migrate_from_athenajson_on_s3_to_presto_on/", "subreddit_subscribers": 152283, "created_utc": 1705091380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While executing dbt run-operation generate_model_yaml it generates logs but I cannot find yml code in it.\n\nI m using dbt cloud", "author_fullname": "t2_sa16pkrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt &amp; codegen", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194solh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705058160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While executing dbt run-operation generate_model_yaml it generates logs but I cannot find yml code in it.&lt;/p&gt;\n\n&lt;p&gt;I m using dbt cloud&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "194solh", "is_robot_indexable": true, "report_reasons": null, "author": "misaaaa18", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194solh/dbt_codegen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194solh/dbt_codegen/", "subreddit_subscribers": 152283, "created_utc": 1705058160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nApologies if I shouldn't post this here. Long story short, I have been interning at a tiny startup (10 employees total) as the \"data guy\". My responsibilities have so far been a sort of data full stack: tons of web scraping, data cleaning, applying off the shelf algorithms, dashboarding, etc. They want to hire me on fulltime. Most of my time will be spent building data pipelines, building out a data infrastructure, building multiple front end for internal tools, etc. What's a reasonable salary expectation?\n\n\\- This is my first role in a data position/tech\n\n\\- Currently getting my masters in Data Science\n\n\\- Self-taught for 2 and a half years\n\n\\- Location is in a USA tech hub (Not CA WA or NY)\n\nThank you!\n\n\\*edited for location", "author_fullname": "t2_vnzouzyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Entry Level\" Salary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19572tl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705098735.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705096810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Apologies if I shouldn&amp;#39;t post this here. Long story short, I have been interning at a tiny startup (10 employees total) as the &amp;quot;data guy&amp;quot;. My responsibilities have so far been a sort of data full stack: tons of web scraping, data cleaning, applying off the shelf algorithms, dashboarding, etc. They want to hire me on fulltime. Most of my time will be spent building data pipelines, building out a data infrastructure, building multiple front end for internal tools, etc. What&amp;#39;s a reasonable salary expectation?&lt;/p&gt;\n\n&lt;p&gt;- This is my first role in a data position/tech&lt;/p&gt;\n\n&lt;p&gt;- Currently getting my masters in Data Science&lt;/p&gt;\n\n&lt;p&gt;- Self-taught for 2 and a half years&lt;/p&gt;\n\n&lt;p&gt;- Location is in a USA tech hub (Not CA WA or NY)&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;*edited for location&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19572tl", "is_robot_indexable": true, "report_reasons": null, "author": "crispybacon233", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19572tl/entry_level_salary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19572tl/entry_level_salary/", "subreddit_subscribers": 152283, "created_utc": 1705096810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm preparing myself for a interview for a data egeneer role next week, and I'm asking you for a good video material on Spark internal workings.\nIt should cover some of the following topics:\n1. Partitioning\n2. Shuffling\n3. Persistence and Caching\n4. Broadcasting\n5. Catalist optimiser\n6. Sort merge join\n\nReading materials would also be fine but I prefer video materials with good explanation of those topics. \n\nThanks in advance.", "author_fullname": "t2_p4cx7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great video on Spark internal workings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1950lxe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705080582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m preparing myself for a interview for a data egeneer role next week, and I&amp;#39;m asking you for a good video material on Spark internal workings.\nIt should cover some of the following topics:\n1. Partitioning\n2. Shuffling\n3. Persistence and Caching\n4. Broadcasting\n5. Catalist optimiser\n6. Sort merge join&lt;/p&gt;\n\n&lt;p&gt;Reading materials would also be fine but I prefer video materials with good explanation of those topics. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1950lxe", "is_robot_indexable": true, "report_reasons": null, "author": "dark_knight_bg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1950lxe/great_video_on_spark_internal_workings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1950lxe/great_video_on_spark_internal_workings/", "subreddit_subscribers": 152283, "created_utc": 1705080582.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}