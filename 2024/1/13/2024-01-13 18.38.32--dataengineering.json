{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a recruiter or a hiring manager for a data engineering entry level position what projects would impress you more or make a student stand out, I know quite a bit of SQL and Python (I can solve Leetcode medium to hard in both) what would you recommend as project that would help me get into DE, thanks", "author_fullname": "t2_a28jw39v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Projects that would impress you", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19533tp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705086798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a recruiter or a hiring manager for a data engineering entry level position what projects would impress you more or make a student stand out, I know quite a bit of SQL and Python (I can solve Leetcode medium to hard in both) what would you recommend as project that would help me get into DE, thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19533tp", "is_robot_indexable": true, "report_reasons": null, "author": "Some-Landscape-4763", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19533tp/projects_that_would_impress_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19533tp/projects_that_would_impress_you/", "subreddit_subscribers": 152636, "created_utc": 1705086798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a smallish company but we don\u2019t spend a lot on data team resourcing. So by default I\u2019m the all inclusive data engineer, architect, analyst and requests come from all departments. \n\nAnyone here find it really challenging to source, ingest,  model, shape AND then do analysis?\n\nI used to be analyst but had a much smaller slice of the pie and did no engineering, I was good at doing the analysis and making recommendations.  But now I get to the end of the whole process and I really struggle to analyse the data, anyone else been here or have any tips?", "author_fullname": "t2_uqyn3qdq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Fatigue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195k5tz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705137632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a smallish company but we don\u2019t spend a lot on data team resourcing. So by default I\u2019m the all inclusive data engineer, architect, analyst and requests come from all departments. &lt;/p&gt;\n\n&lt;p&gt;Anyone here find it really challenging to source, ingest,  model, shape AND then do analysis?&lt;/p&gt;\n\n&lt;p&gt;I used to be analyst but had a much smaller slice of the pie and did no engineering, I was good at doing the analysis and making recommendations.  But now I get to the end of the whole process and I really struggle to analyse the data, anyone else been here or have any tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195k5tz", "is_robot_indexable": true, "report_reasons": null, "author": "variance-explained", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195k5tz/data_fatigue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195k5tz/data_fatigue/", "subreddit_subscribers": 152636, "created_utc": 1705137632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious what kinda of utilization times folks have across various data orchestrators (airflow, prefect, dagster, etc.). All the big systems require some kind of always-on infrastructure to handle scheduling and provide API access, but in most cases require very little of that capacity most of the time.\n\nWe run a hybrid airflow+prefect platform at the office, but our 90% of our workloads run daily and 10% run hourly, with most jobs taking 5-15 minutes to finish. So we have a huge spike at midnight for an hour or so, then a few minutes of work each hour for the rest of the day. Besides, those servers are only responsible to manage compute that's being run on other services (like a k8s cluster), so even when the orchestrator's \"busy\", it has fairly little CPU burden and is mostly just polling external services every few seconds. Net result, our orchestrators use maybe \\~5% of their capacity on any given day, with almost all of that being during the first hour of each day. Still costs an arm and a leg (MWAA, Astronomer, Prefect cloud, they all cost a lot even if you're doing very little with them), and some of those components still have to be scaled for peak usage and can't easily auto-scale.\n\nAnyone else have this frustration? Any common solutions?", "author_fullname": "t2_ry3h6ade6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling like data orchestrators mostly waste compute resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1957xt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705098946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious what kinda of utilization times folks have across various data orchestrators (airflow, prefect, dagster, etc.). All the big systems require some kind of always-on infrastructure to handle scheduling and provide API access, but in most cases require very little of that capacity most of the time.&lt;/p&gt;\n\n&lt;p&gt;We run a hybrid airflow+prefect platform at the office, but our 90% of our workloads run daily and 10% run hourly, with most jobs taking 5-15 minutes to finish. So we have a huge spike at midnight for an hour or so, then a few minutes of work each hour for the rest of the day. Besides, those servers are only responsible to manage compute that&amp;#39;s being run on other services (like a k8s cluster), so even when the orchestrator&amp;#39;s &amp;quot;busy&amp;quot;, it has fairly little CPU burden and is mostly just polling external services every few seconds. Net result, our orchestrators use maybe ~5% of their capacity on any given day, with almost all of that being during the first hour of each day. Still costs an arm and a leg (MWAA, Astronomer, Prefect cloud, they all cost a lot even if you&amp;#39;re doing very little with them), and some of those components still have to be scaled for peak usage and can&amp;#39;t easily auto-scale.&lt;/p&gt;\n\n&lt;p&gt;Anyone else have this frustration? Any common solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1957xt1", "is_robot_indexable": true, "report_reasons": null, "author": "archeprototypical2", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1957xt1/feeling_like_data_orchestrators_mostly_waste/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1957xt1/feeling_like_data_orchestrators_mostly_waste/", "subreddit_subscribers": 152636, "created_utc": 1705098946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a Structured-Streaming pipeline and have ran into what seems like a major issue for me which is that there is no great support for error handling. Example: if I have a dataset of rows that I am trying to process and one of those rows fails due to virtually any unexpected reason, the default behavior of Structured-Streaming is that the stream will crash. If I setup my job to restart on failure, and the error is not transient, then the stream will simply be unable to proceed beyond that point until some solution is implemented in the job code to handle it.\n\nIn my google-search for solutions to this problem, I have found a lot of very custom solutions to this. One solution is to write custom validation for each row to check for exception cases, and then conditionally handle rows differently depending on the outcome of validation, but this will only help in the cases that we can foresee, and not the unexpected.\n\nAnother solution is to handle all transformations inside of a forEachBatch, so that the whole batch transformation can be wrapped in a try/catch, of course this will result in the entire batch failing in the event of a single row failure.\n\nI expect that many others have had to implement pipelines that encounter poison-pill messages and so it seems odd to me that there is no clear solution for this.", "author_fullname": "t2_24qsknvi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Error Handling in Spark and Structured-Streaming, How to Avoid Stream Crashes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1956yj7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705096496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a Structured-Streaming pipeline and have ran into what seems like a major issue for me which is that there is no great support for error handling. Example: if I have a dataset of rows that I am trying to process and one of those rows fails due to virtually any unexpected reason, the default behavior of Structured-Streaming is that the stream will crash. If I setup my job to restart on failure, and the error is not transient, then the stream will simply be unable to proceed beyond that point until some solution is implemented in the job code to handle it.&lt;/p&gt;\n\n&lt;p&gt;In my google-search for solutions to this problem, I have found a lot of very custom solutions to this. One solution is to write custom validation for each row to check for exception cases, and then conditionally handle rows differently depending on the outcome of validation, but this will only help in the cases that we can foresee, and not the unexpected.&lt;/p&gt;\n\n&lt;p&gt;Another solution is to handle all transformations inside of a forEachBatch, so that the whole batch transformation can be wrapped in a try/catch, of course this will result in the entire batch failing in the event of a single row failure.&lt;/p&gt;\n\n&lt;p&gt;I expect that many others have had to implement pipelines that encounter poison-pill messages and so it seems odd to me that there is no clear solution for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1956yj7", "is_robot_indexable": true, "report_reasons": null, "author": "steve_thousand", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1956yj7/error_handling_in_spark_and_structuredstreaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1956yj7/error_handling_in_spark_and_structuredstreaming/", "subreddit_subscribers": 152636, "created_utc": 1705096496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The co-creators of Apache Iceberg have their own startup called Tabular.io\n\nHas anyone had a demo or signed up as a customer yet? \n\nI\u2019m curious what a managed iceberg implementation helps with.", "author_fullname": "t2_41soa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Tabular.io?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1955ps1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705093309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The co-creators of Apache Iceberg have their own startup called Tabular.io&lt;/p&gt;\n\n&lt;p&gt;Has anyone had a demo or signed up as a customer yet? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what a managed iceberg implementation helps with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955ps1", "is_robot_indexable": true, "report_reasons": null, "author": "miqcie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955ps1/thoughts_on_tabulario/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955ps1/thoughts_on_tabulario/", "subreddit_subscribers": 152636, "created_utc": 1705093309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been asking people I know and the general consensus is that they're not that useful, but that's a biased people out there. I figure there must be people out there who find tools like Monte Carlo valuable, have you all found them generally useful?", "author_fullname": "t2_vxxrqrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone actually find their data quality/anomaly detection applications useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1952j59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705085371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been asking people I know and the general consensus is that they&amp;#39;re not that useful, but that&amp;#39;s a biased people out there. I figure there must be people out there who find tools like Monte Carlo valuable, have you all found them generally useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1952j59", "is_robot_indexable": true, "report_reasons": null, "author": "MrMosBiggestFan", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1952j59/does_anyone_actually_find_their_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1952j59/does_anyone_actually_find_their_data/", "subreddit_subscribers": 152636, "created_utc": 1705085371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I was learning about Spark with Scala I read that Datasets are a very powerful feature as they allow for compile-time type checking, as well as taking advantage of functional programming when performing transformations.\n\nBut most sources I read mentioned that they are also slower than DataFrames, although according to [this article](https://itnext.io/making-the-spark-dataframe-composition-type-safe-r-7b6fed524ec2) from 2021 the performance gap between these two is narrowing. Moving 2 years later, [another article](https://sparkbyexamples.com/spark/spark-rdd-vs-dataframe-vs-dataset/) (from November 2023) claims that Datasets are actually faster than DataFrames.\n\nCan anyone confirm if it's true? And if so, does it make sense to only use Datasets when processing data using Spark with Scala? Or are there any areas where DataFrames would be a better choice?", "author_fullname": "t2_wn5fz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Datasets vs DataFrames performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1955qoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705093375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was learning about Spark with Scala I read that Datasets are a very powerful feature as they allow for compile-time type checking, as well as taking advantage of functional programming when performing transformations.&lt;/p&gt;\n\n&lt;p&gt;But most sources I read mentioned that they are also slower than DataFrames, although according to &lt;a href=\"https://itnext.io/making-the-spark-dataframe-composition-type-safe-r-7b6fed524ec2\"&gt;this article&lt;/a&gt; from 2021 the performance gap between these two is narrowing. Moving 2 years later, &lt;a href=\"https://sparkbyexamples.com/spark/spark-rdd-vs-dataframe-vs-dataset/\"&gt;another article&lt;/a&gt; (from November 2023) claims that Datasets are actually faster than DataFrames.&lt;/p&gt;\n\n&lt;p&gt;Can anyone confirm if it&amp;#39;s true? And if so, does it make sense to only use Datasets when processing data using Spark with Scala? Or are there any areas where DataFrames would be a better choice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?auto=webp&amp;s=3659cb0ddeb74f683e31b3620c391557aab5b547", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8744007118b1803247340b55f9685e254e553344", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=97e18e3884ace6f756fe8bccd4414ea29a8a9a8e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=06d4c55c572f7bd130164ffbe711a21954f18d38", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aff6e3db79b99dc83947ef1c99ed3c8567779378", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9be1733b25c40df472838fe9dc4d62ec88946a0e", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a841da9143ad1ce3f334a9a20139318b27975924", "width": 1080, "height": 720}], "variants": {}, "id": "1DzNUL7ZJLW7OT6sHMlmsLRjaSVL1prwDVVMlK9OUe8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955qoh", "is_robot_indexable": true, "report_reasons": null, "author": "Cydros1", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955qoh/spark_datasets_vs_dataframes_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955qoh/spark_datasets_vs_dataframes_performance/", "subreddit_subscribers": 152636, "created_utc": 1705093375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nI'm creating a staging model that feeds on many source tables.  Initially i had a staging model for mails and one for sms that i'd join to create a consolidated staging model.\n\nBut it dawned on my i could just create one model that union sms and email avoiding to create two additional tables. however, i'm afraid there's a quota of UNION within a With clause in BigQuery.\n\nWhat is your point of view?\n\nHere's the query\n\n    WITH source1__data AS (\n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table\n    \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM  table\n    ),\n        source2__data as (\n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table\n      \n      UNION ALL\n    \n      SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n      FROM table\n    \n     )\n      \n    SELECT\n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n    FROM  source1__data\n    UNION ALL\n    SELECT     \n        'X' AS type,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X,\n        X\n    FROM  source2__data\n\nBest!", "author_fullname": "t2_m0fkuha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery and joins!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195nntp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705151369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m creating a staging model that feeds on many source tables.  Initially i had a staging model for mails and one for sms that i&amp;#39;d join to create a consolidated staging model.&lt;/p&gt;\n\n&lt;p&gt;But it dawned on my i could just create one model that union sms and email avoiding to create two additional tables. however, i&amp;#39;m afraid there&amp;#39;s a quota of UNION within a With clause in BigQuery.&lt;/p&gt;\n\n&lt;p&gt;What is your point of view?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the query&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;WITH source1__data AS (\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM  table\n),\n    source2__data as (\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table\n\n  UNION ALL\n\n  SELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\n  FROM table\n\n )\n\nSELECT\n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\nFROM  source1__data\nUNION ALL\nSELECT     \n    &amp;#39;X&amp;#39; AS type,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X,\n    X\nFROM  source2__data\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Best!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195nntp", "is_robot_indexable": true, "report_reasons": null, "author": "anfawave", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195nntp/bigquery_and_joins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195nntp/bigquery_and_joins/", "subreddit_subscribers": 152636, "created_utc": 1705151369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm a data scientist at a very small startup, trying to grasp some DE concepts. I have a python script that downloads data from a database, does some processing in pandas and then uploads it to another service via their SDK. I want this script to run automatically once a day.\n\n&amp;#x200B;\n\nWe work with Azure and unlikely to move to AWS currently, but are open to using any other tools. Could I get some direction on how to set this up? I see Airflow could be relevant but I don't understand where the computation in Airflow actually run. Do I need to connect it to Azure somehow to give it access to computing power?", "author_fullname": "t2_dqzrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to set up a data processing script automatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195jn3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705135376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m a data scientist at a very small startup, trying to grasp some DE concepts. I have a python script that downloads data from a database, does some processing in pandas and then uploads it to another service via their SDK. I want this script to run automatically once a day.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We work with Azure and unlikely to move to AWS currently, but are open to using any other tools. Could I get some direction on how to set this up? I see Airflow could be relevant but I don&amp;#39;t understand where the computation in Airflow actually run. Do I need to connect it to Azure somehow to give it access to computing power?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195jn3v", "is_robot_indexable": true, "report_reasons": null, "author": "PixelPixell", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195jn3v/how_to_set_up_a_data_processing_script/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195jn3v/how_to_set_up_a_data_processing_script/", "subreddit_subscribers": 152636, "created_utc": 1705135376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\ude80 Introducing UCX v0.9.0: Enhanced Assessment, Migration, and Error Handling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_19572kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TNMCFXsgR41T19nR1UxOeSaBE6fD06aUmltGMmw0bkk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705096792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/databricks-labs/introducing-ucx-v0-9-0-enhanced-assessment-migration-and-error-handling-3ccc006e0e26", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?auto=webp&amp;s=c3a64525650ecc3b3246f72ff4c7731359e29643", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c127031ef68b5e7d090e57d1b544bb6dc8fe7ea6", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f33f40602699860f9ba0ee53b24a8229d2adcfe", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f01229576b99d538b96703137e171d63d36fb23", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c65db3de6bb9a9ff7f2744baf20b8593fa02810", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d93c71542a157e849d52106f12e66192578bfaf", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/jSaShN_VIpgA7XTfW7p24TdRoAIrNKV-8iSojWh8CQs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1a4fdddca0d72408e46877076397e8e83235b07a", "width": 1080, "height": 1080}], "variants": {}, "id": "X3VkNmf9xWp7yRf8PYLCd1FkoLiuA_kYVGG8Ot8M8c0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19572kd", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19572kd/introducing_ucx_v090_enhanced_assessment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/databricks-labs/introducing-ucx-v0-9-0-enhanced-assessment-migration-and-error-handling-3ccc006e0e26", "subreddit_subscribers": 152636, "created_utc": 1705096792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I might be shortsighted about this topic and I wouldn't have any problem in admitting it. However, I've never talked to a DE that has worked with Databricks, ever. I've worked in mid-sized companies and Databricks has never been a topic discussed.  \nMost positions I see don't ask for Databricks knowledge or experience, at least in Brazil, where I'm from, or Portugal, where I'm looking some opportunities recently. Looking at their website, it seems that only very large companies use their services. \n\nFrom a management point of view, why would you use another platform instead of using the cloud that your company already uses? Wouldn't it be cheaper and easier to negotiate some discounts (like reserved instances) and keep everything in 'one stack'?\n\nI want to emphasize that I'm not saying the Databricks is useless or bad. I only wants to understand what companies use it and why.  \n", "author_fullname": "t2_jsmqklq8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Databricks a niche enterprise platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1955990", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705092172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I might be shortsighted about this topic and I wouldn&amp;#39;t have any problem in admitting it. However, I&amp;#39;ve never talked to a DE that has worked with Databricks, ever. I&amp;#39;ve worked in mid-sized companies and Databricks has never been a topic discussed.&lt;br/&gt;\nMost positions I see don&amp;#39;t ask for Databricks knowledge or experience, at least in Brazil, where I&amp;#39;m from, or Portugal, where I&amp;#39;m looking some opportunities recently. Looking at their website, it seems that only very large companies use their services. &lt;/p&gt;\n\n&lt;p&gt;From a management point of view, why would you use another platform instead of using the cloud that your company already uses? Wouldn&amp;#39;t it be cheaper and easier to negotiate some discounts (like reserved instances) and keep everything in &amp;#39;one stack&amp;#39;?&lt;/p&gt;\n\n&lt;p&gt;I want to emphasize that I&amp;#39;m not saying the Databricks is useless or bad. I only wants to understand what companies use it and why.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955990", "is_robot_indexable": true, "report_reasons": null, "author": "Rude_effect_74", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955990/is_databricks_a_niche_enterprise_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955990/is_databricks_a_niche_enterprise_platform/", "subreddit_subscribers": 152636, "created_utc": 1705092172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've noticed people say on some old Reddit posts that certain companies use Databricks for their Bronze and Silver data layers, and then transfer this data into Snowflake for the Gold layer.\n\nIn such scenarios, as Data Engineers, we often need to reconnect to Snowflake from Databricks to retrieve data\u2014sometimes a significant amount, depending on the table sizes and number of tables. This step is crucial when we have substantial data from sources not integrated into the data warehouse, as it allows us to enrich this data with warehouse data to create specialized datasets for data scientists' ML models.\n\nConsidering the use of both platforms, wouldn't it be more logical to fully establish the data warehouse in Snowflake and only transfer data into Databricks when necessary for creating these specialized, enriched datasets for data science and ML models?\n\nI\u2019m not familiar with the cost implications of these options, but I assume the latter approach might be more practical and efficient, especially for companies whose data warehouse teams have limited proficiency in Python.", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Databricks for Data Science/ML and Snowflake for Data Warehousing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_195txyv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705168968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed people say on some old Reddit posts that certain companies use Databricks for their Bronze and Silver data layers, and then transfer this data into Snowflake for the Gold layer.&lt;/p&gt;\n\n&lt;p&gt;In such scenarios, as Data Engineers, we often need to reconnect to Snowflake from Databricks to retrieve data\u2014sometimes a significant amount, depending on the table sizes and number of tables. This step is crucial when we have substantial data from sources not integrated into the data warehouse, as it allows us to enrich this data with warehouse data to create specialized datasets for data scientists&amp;#39; ML models.&lt;/p&gt;\n\n&lt;p&gt;Considering the use of both platforms, wouldn&amp;#39;t it be more logical to fully establish the data warehouse in Snowflake and only transfer data into Databricks when necessary for creating these specialized, enriched datasets for data science and ML models?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not familiar with the cost implications of these options, but I assume the latter approach might be more practical and efficient, especially for companies whose data warehouse teams have limited proficiency in Python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195txyv", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195txyv/using_databricks_for_data_scienceml_and_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195txyv/using_databricks_for_data_scienceml_and_snowflake/", "subreddit_subscribers": 152636, "created_utc": 1705168968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am the sole data analyst/engineer for a smallish manufacturing company where I have practically built the whole thing from scratch: ETL from ERP/other sources using SSIS and Python, into a SQL data warehouse, and then into Power BI and SSRS for end users. \n\nI am starting to look at roles outside the company (for both my professional development as well as some red flags popping up at the office) but I am starting to feel that I am a bit of a cul-de-sac with my experience and don't have the hottest tools and software on my resume. \n\nI don't have \"formal\" data architecture/engineering knowledge (if that is a thing) so I have been trying to cobble together my knowledge from articles, youtube videos, etc, and have noticed there were several mistakes I made early on that I would have caught with best practices re: data warehouse design.\n\nFurthermore, I have not learned any of the newer \"cutting edge\" cloud tools as I don't think I can justify the cost and the time it would require to rebuild the whole thing in the cloud, nor do we need a lot of the high performance big data tools, even though I feel it would be personally beneficial for my career to get some experience with them.\n\nCan anyone recommend some books or something that would help me brush up on current best practices and also some suggestions how I might be able to get some experience with some of the newer tools? We are mostly Microsoft so I am taking some Udemy courses that cover the DP203 Azure Data Engineer Cert but if there are cheaper open source versions that I might be able to stick into my process somewhere that would be helpful as well.\n\nThanks for your help!", "author_fullname": "t2_466z52hl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shoring up resume with best practices/gaining cloud experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_195trbo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705168494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the sole data analyst/engineer for a smallish manufacturing company where I have practically built the whole thing from scratch: ETL from ERP/other sources using SSIS and Python, into a SQL data warehouse, and then into Power BI and SSRS for end users. &lt;/p&gt;\n\n&lt;p&gt;I am starting to look at roles outside the company (for both my professional development as well as some red flags popping up at the office) but I am starting to feel that I am a bit of a cul-de-sac with my experience and don&amp;#39;t have the hottest tools and software on my resume. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have &amp;quot;formal&amp;quot; data architecture/engineering knowledge (if that is a thing) so I have been trying to cobble together my knowledge from articles, youtube videos, etc, and have noticed there were several mistakes I made early on that I would have caught with best practices re: data warehouse design.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, I have not learned any of the newer &amp;quot;cutting edge&amp;quot; cloud tools as I don&amp;#39;t think I can justify the cost and the time it would require to rebuild the whole thing in the cloud, nor do we need a lot of the high performance big data tools, even though I feel it would be personally beneficial for my career to get some experience with them.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend some books or something that would help me brush up on current best practices and also some suggestions how I might be able to get some experience with some of the newer tools? We are mostly Microsoft so I am taking some Udemy courses that cover the DP203 Azure Data Engineer Cert but if there are cheaper open source versions that I might be able to stick into my process somewhere that would be helpful as well.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "195trbo", "is_robot_indexable": true, "report_reasons": null, "author": "Midnight_Old", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195trbo/shoring_up_resume_with_best_practicesgaining/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195trbo/shoring_up_resume_with_best_practicesgaining/", "subreddit_subscribers": 152636, "created_utc": 1705168494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familar with reasources for beginning in Python, but am wondering if there are any specific to Synapse Serverless PySpark.\n\nGenerally it works best for me, to start with things I can immediately apply.  Not always, but with Python being a general purpose language, I'm thinking it might be best to try starting with that.", "author_fullname": "t2_3bc49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 Python Beginner Resources, that focus on Synapse Serverless PySpark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_195t3cn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705166748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familar with reasources for beginning in Python, but am wondering if there are any specific to Synapse Serverless PySpark.&lt;/p&gt;\n\n&lt;p&gt;Generally it works best for me, to start with things I can immediately apply.  Not always, but with Python being a general purpose language, I&amp;#39;m thinking it might be best to try starting with that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195t3cn", "is_robot_indexable": true, "report_reasons": null, "author": "cdigioia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195t3cn/1_python_beginner_resources_that_focus_on_synapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195t3cn/1_python_beginner_resources_that_focus_on_synapse/", "subreddit_subscribers": 152636, "created_utc": 1705166748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have completed a few projects on data engineering (real world projects and not demo projects). I know how and where to use the common tools. I have mostly been doing this on Azure. So I am familiar with services like synapse analytics, data factory, databricks (pyspark) , SQL databases. And PowerBI for visualization purposes. I had done the basics of ML(classification, clustering, some simple Deep learning, etc...) a few years ago. But that's not enough. How much time would it take to get decent at ML and and probably be amongst the top 15% in this industry globally?", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard is it for a Data Engineer to move into ML/Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195l6dn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705141912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have completed a few projects on data engineering (real world projects and not demo projects). I know how and where to use the common tools. I have mostly been doing this on Azure. So I am familiar with services like synapse analytics, data factory, databricks (pyspark) , SQL databases. And PowerBI for visualization purposes. I had done the basics of ML(classification, clustering, some simple Deep learning, etc...) a few years ago. But that&amp;#39;s not enough. How much time would it take to get decent at ML and and probably be amongst the top 15% in this industry globally?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195l6dn", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195l6dn/how_hard_is_it_for_a_data_engineer_to_move_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195l6dn/how_hard_is_it_for_a_data_engineer_to_move_into/", "subreddit_subscribers": 152636, "created_utc": 1705141912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "can i work with it through the vscode extension tho? i'd like to know cause thats what we are studying in uni for now , but if thats not the case then i would be okay with a close equivalent  ", "author_fullname": "t2_6elmofyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "oracle equivalent for mac?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195ketb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705138691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;can i work with it through the vscode extension tho? i&amp;#39;d like to know cause thats what we are studying in uni for now , but if thats not the case then i would be okay with a close equivalent  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "195ketb", "is_robot_indexable": true, "report_reasons": null, "author": "Getsuga_H", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195ketb/oracle_equivalent_for_mac/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195ketb/oracle_equivalent_for_mac/", "subreddit_subscribers": 152636, "created_utc": 1705138691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm moving to a new team DataOps at 50% capacity. This was announced to be effective December 2023 no significant movement on the same. I tried to reach the team lead in December she mentioned she is busy and will reach back. Nothing happened. She gave me a link for video dated seven months its already a legacy as the meeting she mentioned there is going to be lot of changes. Again in January 2024 I reached out again asking for more information, spoke over zoom for the first time. Gave me few run books to look at. I asked provide me an architecture which I can understand what job I'm going into. Its been a week now no other progress don't know I will be blamed and it seems it might be a way to lay me off. Any advise on this. I cant blame the the tem lead to the director cos I have been already raising my voice to the director for the past couple of years about stagnation", "author_fullname": "t2_3i19ucis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joining a New Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1952e3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705085018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m moving to a new team DataOps at 50% capacity. This was announced to be effective December 2023 no significant movement on the same. I tried to reach the team lead in December she mentioned she is busy and will reach back. Nothing happened. She gave me a link for video dated seven months its already a legacy as the meeting she mentioned there is going to be lot of changes. Again in January 2024 I reached out again asking for more information, spoke over zoom for the first time. Gave me few run books to look at. I asked provide me an architecture which I can understand what job I&amp;#39;m going into. Its been a week now no other progress don&amp;#39;t know I will be blamed and it seems it might be a way to lay me off. Any advise on this. I cant blame the the tem lead to the director cos I have been already raising my voice to the director for the past couple of years about stagnation&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1952e3i", "is_robot_indexable": true, "report_reasons": null, "author": "BeginningAd4923", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1952e3i/joining_a_new_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1952e3i/joining_a_new_team/", "subreddit_subscribers": 152636, "created_utc": 1705085018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was hired as a consultant and started to work as a Data Engineer on a startup. A lot of work but I really enjoyed working on it. However, they decided to fire a entire team and put me instead as the developer of that project. When I opened the files, it is just a mess. Spaghetti codes, multiple logics that just gets overwritten and no documentation at all. I discovered that the logic didn't work at all and I have been mostly finding issues with the code.\n\nI asked the business analyst to help me understand all the logic and he doesn't know either. There is no proper documentation of the reqs of the project (the original business analyst was fired for this too), they changed the project owner since the original moved to another company and this new guy doesn't know either what to do.\n\nWell, I suggested to spend time to try to understand the project itself but got called off by everyone since they need this done by February. It just happens that I am in a trial period in this job and it also ends in February. They are expecting me to finish this one but honestly I feel lost since there is no one to contact about the full scope of the project, I am working blinding and doing some \"screaming\" qa.\n\nBy the way, the original stack was Python Pandas, DBT, Airflow, AWS, Postgresql and they were planning to move to Snowflake, and now in this project is just plain SQL for MariaDB. The fricking test to enter the company were hard, I studied a lot of these data engineer tools to enter, even Kubernetes, Docker, Terraform and now I am just a SQL developer. Honestly, I don't mind working with SQL but because the incompetence of other people, they switched me over since they are out of people and they are no plans to hire a new team for this. I just hope that I can recover back my original role.", "author_fullname": "t2_gdhxcn2h6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After finally getting my dream job, I was switched to other role against my will.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_195tn9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705168405.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705168197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was hired as a consultant and started to work as a Data Engineer on a startup. A lot of work but I really enjoyed working on it. However, they decided to fire a entire team and put me instead as the developer of that project. When I opened the files, it is just a mess. Spaghetti codes, multiple logics that just gets overwritten and no documentation at all. I discovered that the logic didn&amp;#39;t work at all and I have been mostly finding issues with the code.&lt;/p&gt;\n\n&lt;p&gt;I asked the business analyst to help me understand all the logic and he doesn&amp;#39;t know either. There is no proper documentation of the reqs of the project (the original business analyst was fired for this too), they changed the project owner since the original moved to another company and this new guy doesn&amp;#39;t know either what to do.&lt;/p&gt;\n\n&lt;p&gt;Well, I suggested to spend time to try to understand the project itself but got called off by everyone since they need this done by February. It just happens that I am in a trial period in this job and it also ends in February. They are expecting me to finish this one but honestly I feel lost since there is no one to contact about the full scope of the project, I am working blinding and doing some &amp;quot;screaming&amp;quot; qa.&lt;/p&gt;\n\n&lt;p&gt;By the way, the original stack was Python Pandas, DBT, Airflow, AWS, Postgresql and they were planning to move to Snowflake, and now in this project is just plain SQL for MariaDB. The fricking test to enter the company were hard, I studied a lot of these data engineer tools to enter, even Kubernetes, Docker, Terraform and now I am just a SQL developer. Honestly, I don&amp;#39;t mind working with SQL but because the incompetence of other people, they switched me over since they are out of people and they are no plans to hire a new team for this. I just hope that I can recover back my original role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "195tn9u", "is_robot_indexable": true, "report_reasons": null, "author": "DataSenpai", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195tn9u/after_finally_getting_my_dream_job_i_was_switched/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195tn9u/after_finally_getting_my_dream_job_i_was_switched/", "subreddit_subscribers": 152636, "created_utc": 1705168197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI\u2019m currently involved in migrating data from a legacy system to a cloud platform. What are the key considerations when initiating such operations? In other words, how do I plan for such a project from scratch?\n\nI\u2019m keen to learn from your experiences. How have you successfully managed projects like these? Your insights and thoughts are incredibly valuable to me.\n\nThank you!", "author_fullname": "t2_azqk02tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the things that we should consider when migrating data from legacy systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_195oj1a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705154125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently involved in migrating data from a legacy system to a cloud platform. What are the key considerations when initiating such operations? In other words, how do I plan for such a project from scratch?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m keen to learn from your experiences. How have you successfully managed projects like these? Your insights and thoughts are incredibly valuable to me.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "195oj1a", "is_robot_indexable": true, "report_reasons": null, "author": "adatascientistSl", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/195oj1a/what_are_the_things_that_we_should_consider_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/195oj1a/what_are_the_things_that_we_should_consider_when/", "subreddit_subscribers": 152636, "created_utc": 1705154125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nApologies if I shouldn't post this here. Long story short, I have been interning at a tiny startup (10 employees total) as the \"data guy\". My responsibilities have so far been a sort of data full stack: tons of web scraping, data cleaning, applying off the shelf algorithms, dashboarding, etc. They want to hire me on fulltime. Most of my time will be spent building data pipelines, building out a data infrastructure, building multiple front end for internal tools, etc. What's a reasonable salary expectation?\n\n\\- This is my first role in a data position/tech\n\n\\- Currently getting my masters in Data Science\n\n\\- Self-taught for 2 and a half years\n\n\\- Location is in a USA tech hub (Not CA WA or NY)\n\nThank you!\n\n\\*edited for location", "author_fullname": "t2_vnzouzyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Entry Level\" Salary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19572tl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705098735.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705096810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Apologies if I shouldn&amp;#39;t post this here. Long story short, I have been interning at a tiny startup (10 employees total) as the &amp;quot;data guy&amp;quot;. My responsibilities have so far been a sort of data full stack: tons of web scraping, data cleaning, applying off the shelf algorithms, dashboarding, etc. They want to hire me on fulltime. Most of my time will be spent building data pipelines, building out a data infrastructure, building multiple front end for internal tools, etc. What&amp;#39;s a reasonable salary expectation?&lt;/p&gt;\n\n&lt;p&gt;- This is my first role in a data position/tech&lt;/p&gt;\n\n&lt;p&gt;- Currently getting my masters in Data Science&lt;/p&gt;\n\n&lt;p&gt;- Self-taught for 2 and a half years&lt;/p&gt;\n\n&lt;p&gt;- Location is in a USA tech hub (Not CA WA or NY)&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;*edited for location&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19572tl", "is_robot_indexable": true, "report_reasons": null, "author": "crispybacon233", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19572tl/entry_level_salary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19572tl/entry_level_salary/", "subreddit_subscribers": 152636, "created_utc": 1705096810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently using Athena with JSON files in S3. We use all Presto SQL features - our JSON files and corresponding Athena tables have arrays, etc. What would you recommend for a local stack on Unix? Install Presto + JSON as local files or Presto + Hadoop/Hive? Are there any other options? Thank you, -- Alex", "author_fullname": "t2_e1ws1vmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Migrate from Athena/JSON on S3 to Presto on Unix.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1954xw0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705091380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently using Athena with JSON files in S3. We use all Presto SQL features - our JSON files and corresponding Athena tables have arrays, etc. What would you recommend for a local stack on Unix? Install Presto + JSON as local files or Presto + Hadoop/Hive? Are there any other options? Thank you, -- Alex&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1954xw0", "is_robot_indexable": true, "report_reasons": null, "author": "flareplf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1954xw0/how_to_migrate_from_athenajson_on_s3_to_presto_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1954xw0/how_to_migrate_from_athenajson_on_s3_to_presto_on/", "subreddit_subscribers": 152636, "created_utc": 1705091380.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}