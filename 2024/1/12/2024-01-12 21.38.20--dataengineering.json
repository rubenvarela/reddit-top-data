{"kind": "Listing", "data": {"after": "t3_19503tx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\nI hope you guys are well. I'm curious about your opinions. I'm a data engineer trainee. I want to learn A LOT. Not only SQL, Python, but PySpak, etc, etc.\n\nBut I'm curious: What's the best course, or certification (specialization) or degree of all time for you, that you can end the course and say: \"Wow, f\\*\\*\\*\\*\\*\\* hell! This was amazing! I learned so much with this!\"\n\nI want to know your opinions :)\n\nYou can also share books, share what really help you with to grow as a Data Engineer and as a professional :)\n\nHave a good day/night", "author_fullname": "t2_dfo75n0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer - What's the best course, certification or degree of all time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194d07l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705009061.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705008482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I hope you guys are well. I&amp;#39;m curious about your opinions. I&amp;#39;m a data engineer trainee. I want to learn A LOT. Not only SQL, Python, but PySpak, etc, etc.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m curious: What&amp;#39;s the best course, or certification (specialization) or degree of all time for you, that you can end the course and say: &amp;quot;Wow, f****** hell! This was amazing! I learned so much with this!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I want to know your opinions :)&lt;/p&gt;\n\n&lt;p&gt;You can also share books, share what really help you with to grow as a Data Engineer and as a professional :)&lt;/p&gt;\n\n&lt;p&gt;Have a good day/night&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194d07l", "is_robot_indexable": true, "report_reasons": null, "author": "GigabyteWarrior", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194d07l/data_engineer_whats_the_best_course_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194d07l/data_engineer_whats_the_best_course_certification/", "subreddit_subscribers": 152171, "created_utc": 1705008482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have been using databricks(aws) close to a year now and have started working with DLTs \\[Delta Live Tables\\]. I personally don't hate them as much as my teammates but I don't blame them, a lot of DLT limitations are in direct contradiction with the Databricks vision. Reasons listed below:\n\n* You have to be on shared compute, this complicates reading data and writing back out to s3 if you need to drop a file (need to be in single user mode)\n* BIGGEST COMPLAINT: You cannot \"hop\" catalogs or even schemas. This is so weird to me. They are rolling out DLT and UC \\[Unity Catalog\\] and are pushing customers hard on both, but DLTs directly contradict the medallion architecture. You want to have data land in a bronze catalog, then move it to a silver, gold, etc. Great, create a pipeline for each and kill your job runtime because you now have to spin up 3 different computes. They had a private preview that allowed you to write to multiple schemas but they killed it. Why?\n* DLTs have to run from workspace notebooks, because GIT providers can only point to a users specific repo, not a config'd repo and branch like a notebook job. Luckily we have DABs to control our deployment and skirt this issue but it seems so odd to us. The DLT documentation recommends setting up a repo per pipeline, thats insane!\n* Cannot share compute across multiple pipelines. To my second point, the limitation of not being able to hop schemas/catalogs wouldn't matter if I could specify DLT compute to use in the three pipelines processing the data. That solves a huge problem.\n* Documentation, community support is still weak.\n\nI do love the automation DLT brings with ingesting data, specifically CDC data. But there are some pain-points that make absolutely no sense. I think Databricks is doing too much too fast and needs to refocus on what they were initially, a data platform that provided one place to do everything.", "author_fullname": "t2_81ywblydd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My whole team hates DLTs and I don't blame them.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19501yg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705091443.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705079212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have been using databricks(aws) close to a year now and have started working with DLTs [Delta Live Tables]. I personally don&amp;#39;t hate them as much as my teammates but I don&amp;#39;t blame them, a lot of DLT limitations are in direct contradiction with the Databricks vision. Reasons listed below:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You have to be on shared compute, this complicates reading data and writing back out to s3 if you need to drop a file (need to be in single user mode)&lt;/li&gt;\n&lt;li&gt;BIGGEST COMPLAINT: You cannot &amp;quot;hop&amp;quot; catalogs or even schemas. This is so weird to me. They are rolling out DLT and UC [Unity Catalog] and are pushing customers hard on both, but DLTs directly contradict the medallion architecture. You want to have data land in a bronze catalog, then move it to a silver, gold, etc. Great, create a pipeline for each and kill your job runtime because you now have to spin up 3 different computes. They had a private preview that allowed you to write to multiple schemas but they killed it. Why?&lt;/li&gt;\n&lt;li&gt;DLTs have to run from workspace notebooks, because GIT providers can only point to a users specific repo, not a config&amp;#39;d repo and branch like a notebook job. Luckily we have DABs to control our deployment and skirt this issue but it seems so odd to us. The DLT documentation recommends setting up a repo per pipeline, thats insane!&lt;/li&gt;\n&lt;li&gt;Cannot share compute across multiple pipelines. To my second point, the limitation of not being able to hop schemas/catalogs wouldn&amp;#39;t matter if I could specify DLT compute to use in the three pipelines processing the data. That solves a huge problem.&lt;/li&gt;\n&lt;li&gt;Documentation, community support is still weak.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I do love the automation DLT brings with ingesting data, specifically CDC data. But there are some pain-points that make absolutely no sense. I think Databricks is doing too much too fast and needs to refocus on what they were initially, a data platform that provided one place to do everything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19501yg", "is_robot_indexable": true, "report_reasons": null, "author": "DataDoyle", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19501yg/my_whole_team_hates_dlts_and_i_dont_blame_them/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19501yg/my_whole_team_hates_dlts_and_i_dont_blame_them/", "subreddit_subscribers": 152171, "created_utc": 1705079212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently joined a data engineering team after a few years as a web engineer. I am not and expert but know the basic design patterns and principles. The team I joined writes really bad code.. but to be honest I\u2019m not sure it matters? Most of these scripts never need to be adjusted and will continue to move data. \n\nI\u2019m curious what coding standards you implement in your code. Are you using object oriented designs?", "author_fullname": "t2_e70iqfxk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How clean is your code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194q4yk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705047765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently joined a data engineering team after a few years as a web engineer. I am not and expert but know the basic design patterns and principles. The team I joined writes really bad code.. but to be honest I\u2019m not sure it matters? Most of these scripts never need to be adjusted and will continue to move data. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what coding standards you implement in your code. Are you using object oriented designs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194q4yk", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Wall8245", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194q4yk/how_clean_is_your_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194q4yk/how_clean_is_your_code/", "subreddit_subscribers": 152171, "created_utc": 1705047765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, I am having 5.5 years of experience in data engineering mostly worked on teradata. Currently in gcp services. Before making another switch I want to be fundamentally good at pyspark by having some hands-on experience. What will be best way I can follow to learn pyspark or and good courses that I can take if any. Please suggest.", "author_fullname": "t2_pe79l62ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to learn pyspark.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194rp77", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705054268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I am having 5.5 years of experience in data engineering mostly worked on teradata. Currently in gcp services. Before making another switch I want to be fundamentally good at pyspark by having some hands-on experience. What will be best way I can follow to learn pyspark or and good courses that I can take if any. Please suggest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194rp77", "is_robot_indexable": true, "report_reasons": null, "author": "TheErenYeager03", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194rp77/best_way_to_learn_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194rp77/best_way_to_learn_pyspark/", "subreddit_subscribers": 152171, "created_utc": 1705054268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all!\n\nI've seen a lot of posts recently across Reddit of SWEs feeling the pain from layoffs and having trouble finding new positions out there.\n\nAs someone in constant fear of being laid off (mostly just anxiety) I see these sorts of things and get a bit nervous, however, I have seen much less of this in the Data Engineering community.\n\nNot sure if it's just because it's a smaller community or if it's because there's still a good market for Data Engineers.\n\nAny thoughts from the community about the market in comparison to Software Engineering?", "author_fullname": "t2_eatn2f80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SWE Market Vs DE Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194m0y8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705033103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a lot of posts recently across Reddit of SWEs feeling the pain from layoffs and having trouble finding new positions out there.&lt;/p&gt;\n\n&lt;p&gt;As someone in constant fear of being laid off (mostly just anxiety) I see these sorts of things and get a bit nervous, however, I have seen much less of this in the Data Engineering community.&lt;/p&gt;\n\n&lt;p&gt;Not sure if it&amp;#39;s just because it&amp;#39;s a smaller community or if it&amp;#39;s because there&amp;#39;s still a good market for Data Engineers.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts from the community about the market in comparison to Software Engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194m0y8", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional-Ad-8670", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194m0y8/swe_market_vs_de_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194m0y8/swe_market_vs_de_market/", "subreddit_subscribers": 152171, "created_utc": 1705033103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I pay for a hosted SQL Server because a 3rd party makes data available for analytics only through this hosted service. I get SSL access to this database for a cost. The database gets refreshed nightly with my account data, so basically it\u2019s an OLAP that gets updated every 24hrs.\n\nAt the same time, I incur egress fees for data leaving this storage. This is unfortunate because analytics often use the same data over and over again. So I am effectively paying to pull out the same data several times over. What a waste of money when the data only changes once every 24hrs.\n\nI want to replicate the data once a data and just run analytics on my replication. However, I have an existing database (Postgres) that I use for similar analytics with data I garner locally. It would be ideal if I could just move the daily SQL Server data into my Postgres instance,\n\nWhat are the best tools for achieving such replication when you aren\u2019t an admin of the database to be replicated? Is my best bet building a CSV from a SELECT statement for every table, then importing to Postgres? Is there a better way?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the best approach for replicating all data from an SQL Server instance to a Postgres instance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194iz0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705023868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I pay for a hosted SQL Server because a 3rd party makes data available for analytics only through this hosted service. I get SSL access to this database for a cost. The database gets refreshed nightly with my account data, so basically it\u2019s an OLAP that gets updated every 24hrs.&lt;/p&gt;\n\n&lt;p&gt;At the same time, I incur egress fees for data leaving this storage. This is unfortunate because analytics often use the same data over and over again. So I am effectively paying to pull out the same data several times over. What a waste of money when the data only changes once every 24hrs.&lt;/p&gt;\n\n&lt;p&gt;I want to replicate the data once a data and just run analytics on my replication. However, I have an existing database (Postgres) that I use for similar analytics with data I garner locally. It would be ideal if I could just move the daily SQL Server data into my Postgres instance,&lt;/p&gt;\n\n&lt;p&gt;What are the best tools for achieving such replication when you aren\u2019t an admin of the database to be replicated? Is my best bet building a CSV from a SELECT statement for every table, then importing to Postgres? Is there a better way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194iz0f", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194iz0f/whats_the_best_approach_for_replicating_all_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194iz0f/whats_the_best_approach_for_replicating_all_data/", "subreddit_subscribers": 152171, "created_utc": 1705023868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious about how's the landscape out there, and what is the general maturity of ETL data pipelines. I've worked many years with old school server based GUI ETL tools like DataStage and PowerCenter, and then had to migrate to pipelines in Hive (Azure HDInsight) and blob storage/hdfs. Now our pipeline is just custom python scripts that run in parallel (threads) running queries on Google BigQuery (more of an ELT actually).  \n\n\nHow are you guys doing it?  \n\n\n1- Talend, DataStage, PowerCenter, SSIS?  \n2- Some custom solution?  \n3- Dataproc/HDInsight running spark/hive/pig?  \n4- Apache Beam?  \n5- Something else?", "author_fullname": "t2_q0c2atq8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your business implements their ETL pipeline (if at all)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194vdyx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705067065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious about how&amp;#39;s the landscape out there, and what is the general maturity of ETL data pipelines. I&amp;#39;ve worked many years with old school server based GUI ETL tools like DataStage and PowerCenter, and then had to migrate to pipelines in Hive (Azure HDInsight) and blob storage/hdfs. Now our pipeline is just custom python scripts that run in parallel (threads) running queries on Google BigQuery (more of an ELT actually).  &lt;/p&gt;\n\n&lt;p&gt;How are you guys doing it?  &lt;/p&gt;\n\n&lt;p&gt;1- Talend, DataStage, PowerCenter, SSIS?&lt;br/&gt;\n2- Some custom solution?&lt;br/&gt;\n3- Dataproc/HDInsight running spark/hive/pig?&lt;br/&gt;\n4- Apache Beam?&lt;br/&gt;\n5- Something else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194vdyx", "is_robot_indexable": true, "report_reasons": null, "author": "rikarleite", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194vdyx/how_does_your_business_implements_their_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194vdyx/how_does_your_business_implements_their_etl/", "subreddit_subscribers": 152171, "created_utc": 1705067065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w6hkluod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouses vs Data Lakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_194gh3f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Warehouses vs Data Lakes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xbtK43WlkMs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/194gh3f", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oB8_ilnk9vQ2eW0UEwgkrNRE68LKUHbqUGGwzrNxoAg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705017049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xbtK43WlkMs?si=RR_Kn6e_4DuIbf9u", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AbPG6wDO7qLLJmHEOkFtKWqk8Epjbijr88u4Cz9Fwis.jpg?auto=webp&amp;s=ec5fe1f9180f791f5a505912dc38b81ff4623330", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/AbPG6wDO7qLLJmHEOkFtKWqk8Epjbijr88u4Cz9Fwis.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=756721c559ceb9ffad969c0874cca31d7fe8b6e4", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/AbPG6wDO7qLLJmHEOkFtKWqk8Epjbijr88u4Cz9Fwis.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=843a64fa731153b5ef755c11a20397ad376f8b3c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/AbPG6wDO7qLLJmHEOkFtKWqk8Epjbijr88u4Cz9Fwis.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df041474b3ac17e595b9625e78964cac0ebaa6f8", "width": 320, "height": 240}], "variants": {}, "id": "y1-ztg6CqTUIpsSMCro3W1_odauB7Vb_7yUnCwY1H7o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "194gh3f", "is_robot_indexable": true, "report_reasons": null, "author": "danipudani", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194gh3f/data_warehouses_vs_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xbtK43WlkMs?si=RR_Kn6e_4DuIbf9u", "subreddit_subscribers": 152171, "created_utc": 1705017049.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Warehouses vs Data Lakes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xbtK43WlkMs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sorry if this is a basic or stupid question, i guess it applies to many software engineering situations (compiling code, deploying, testing, etc) but in DE there's some times where I need to debug, a 10 min spark job on EMR as an example, and i struggle to know what i should do during those 10 minutes. Sure i could \"do something else\" in the meanwhile but i feel the context switching is what makes me feel burnt out at the end of the day. Yet i can't sit there and do nothing since if i have 12 errors, 2 hours of my day is gone. Again, basic question but i wonder what hacks i can implement to improve my efficiency and state.\n\nDo you maybe do related reading? busywork email? (push ups? just kidding.)", "author_fullname": "t2_hvng1539", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Work habits in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194wbtw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705075646.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705069620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is a basic or stupid question, i guess it applies to many software engineering situations (compiling code, deploying, testing, etc) but in DE there&amp;#39;s some times where I need to debug, a 10 min spark job on EMR as an example, and i struggle to know what i should do during those 10 minutes. Sure i could &amp;quot;do something else&amp;quot; in the meanwhile but i feel the context switching is what makes me feel burnt out at the end of the day. Yet i can&amp;#39;t sit there and do nothing since if i have 12 errors, 2 hours of my day is gone. Again, basic question but i wonder what hacks i can implement to improve my efficiency and state.&lt;/p&gt;\n\n&lt;p&gt;Do you maybe do related reading? busywork email? (push ups? just kidding.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "194wbtw", "is_robot_indexable": true, "report_reasons": null, "author": "Pretty_Meet2795", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194wbtw/work_habits_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194wbtw/work_habits_in_de/", "subreddit_subscribers": 152171, "created_utc": 1705069620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c9ymz7vr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL made easy using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_194sed6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/E_idWOUF_TeXjNzvl_9nm5B1AhxqIxpsBEP22jOnyaY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705057113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/python-in-plain-english/sql-aggregations-are-made-easy-using-ai-216f9c4a406b", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?auto=webp&amp;s=7c903c13dc75e3d1caa922d721fdb56bff4f877d", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=82058ce2dfd3d07eae450510497aa5e5fa922436", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=940a035aba7966cb75e9f3be5145544a01f8e432", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2fb2db77f1f2b765850647ffccdde9121f5b3e2d", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ef0005758cd1fd54309cc1a2446b0fa9c6a83e5", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6cd4e3307c6a54fd7d1ca325df92c22b9cde1aa2", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3182f4035b91a8b1a02447d9ab8cf4c965210a98", "width": 1080, "height": 1080}], "variants": {}, "id": "ywuNk0kBtw9nHT_Wzv9hfXqV4pQ3u7YA2553E0hxYRM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "194sed6", "is_robot_indexable": true, "report_reasons": null, "author": "United_Engineer_198", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194sed6/sql_made_easy_using_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/python-in-plain-english/sql-aggregations-are-made-easy-using-ai-216f9c4a406b", "subreddit_subscribers": 152171, "created_utc": 1705057113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'll start with some good news; I recently got my first job as a data engineer!  It's contract-to-hire at a public health insurance agency and I am very excited for it.\n\nBefore this position, I studied an MS Information Systems degree where I learned a lot about data science, ML and statistics.  In this job, it looks like I will be using none of it.  I'm trying to think if there are any ways I can use the data science knowledge I learned in grad school to grow in my data engineering career, or whether it was just lost time.  Could it come in handy if I focus on data engineering for ML in the future?  Could there be overlap where it could come in handy?  Maybe should I look for ways to apply this knowledge in my new role and not worry about how it fits into the bigger picture? \n Let me know - right now feeling a bit sad that I'm not putting anything I learned in grad school to good use, like it was a waste of time.\n\nThanks in advance for your thoughts!", "author_fullname": "t2_aewcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Utility of Data Science / Statistics / ML Knowledge in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194o6gm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705040223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll start with some good news; I recently got my first job as a data engineer!  It&amp;#39;s contract-to-hire at a public health insurance agency and I am very excited for it.&lt;/p&gt;\n\n&lt;p&gt;Before this position, I studied an MS Information Systems degree where I learned a lot about data science, ML and statistics.  In this job, it looks like I will be using none of it.  I&amp;#39;m trying to think if there are any ways I can use the data science knowledge I learned in grad school to grow in my data engineering career, or whether it was just lost time.  Could it come in handy if I focus on data engineering for ML in the future?  Could there be overlap where it could come in handy?  Maybe should I look for ways to apply this knowledge in my new role and not worry about how it fits into the bigger picture? \n Let me know - right now feeling a bit sad that I&amp;#39;m not putting anything I learned in grad school to good use, like it was a waste of time.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194o6gm", "is_robot_indexable": true, "report_reasons": null, "author": "i_am_baldilocks", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194o6gm/utility_of_data_science_statistics_ml_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194o6gm/utility_of_data_science_statistics_ml_knowledge/", "subreddit_subscribers": 152171, "created_utc": 1705040223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, thank you for reading this post.\n\nI'm currently working as a Data Engineer, primarily in ETL, with 1.8 years of experience across 3 projects using Azure Data Factory (ADF). I'm proficient in ADF, have intermediate SQL skills, and basic knowledge of Python. I'm contemplating a job switch and facing some uncertainties. Here are my main concerns:\n\n1. Choosing between Snowflake and Databricks, leaning towards Snowflake due to my strong SQL skills.\n\n2. Considering online master courses (e.g., Trendy Tech DE Master Program) for a structured learning approach and to stay motivated.\n\n3. Seeking advice on additional areas to focus on.\n\n4. Unsure if learning Python with DSA is essential and whether online or offline courses are preferable. PS - I don't like to code and also want to be in DE field but just going with the demand.\n\nYour insights would greatly help in easing my confusion and career pressure.\n\n", "author_fullname": "t2_i159isc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Serious Help/Suggestions for my Career.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194svgx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705059130.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705058877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, thank you for reading this post.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a Data Engineer, primarily in ETL, with 1.8 years of experience across 3 projects using Azure Data Factory (ADF). I&amp;#39;m proficient in ADF, have intermediate SQL skills, and basic knowledge of Python. I&amp;#39;m contemplating a job switch and facing some uncertainties. Here are my main concerns:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Choosing between Snowflake and Databricks, leaning towards Snowflake due to my strong SQL skills.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Considering online master courses (e.g., Trendy Tech DE Master Program) for a structured learning approach and to stay motivated.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Seeking advice on additional areas to focus on.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Unsure if learning Python with DSA is essential and whether online or offline courses are preferable. PS - I don&amp;#39;t like to code and also want to be in DE field but just going with the demand.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your insights would greatly help in easing my confusion and career pressure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194svgx", "is_robot_indexable": true, "report_reasons": null, "author": "Own_Zookeepergame256", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194svgx/need_serious_helpsuggestions_for_my_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194svgx/need_serious_helpsuggestions_for_my_career/", "subreddit_subscribers": 152171, "created_utc": 1705058877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video: Setting Up Apache Superset on your Laptop with Docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_19512hz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/604i8vaukZs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Apache Superset &amp;amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Apache Superset &amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/604i8vaukZs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Apache Superset &amp;amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/604i8vaukZs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/604i8vaukZs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Apache Superset &amp;amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/19512hz", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oVlDQo-alRVItOVypVLR7wWhtsaBJngjgsYBDlzngVM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705081726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=604i8vaukZs", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pi6a5dPpQyiZN07qUvMXSCex6BExjzSYXyHz_4Ebx-8.jpg?auto=webp&amp;s=016ce139a48feadd1b228bf0505a6c68270afffa", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/pi6a5dPpQyiZN07qUvMXSCex6BExjzSYXyHz_4Ebx-8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=694886e5fdc0a91128da13001ceb4f1b64e0f2fe", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/pi6a5dPpQyiZN07qUvMXSCex6BExjzSYXyHz_4Ebx-8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0fad22fe12731dd67210673f1a0ad60f559028e4", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/pi6a5dPpQyiZN07qUvMXSCex6BExjzSYXyHz_4Ebx-8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b70007611ada02582576b8d3556238ff79483793", "width": 320, "height": 240}], "variants": {}, "id": "i4YLT3SrljZIs-wWmojPiCdeQDpHy1sSxIAnW7cRtUI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "19512hz", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19512hz/video_setting_up_apache_superset_on_your_laptop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=604i8vaukZs", "subreddit_subscribers": 152171, "created_utc": 1705081726.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Apache Superset &amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/604i8vaukZs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Apache Superset &amp;amp; Dremio: How Run Superset from Docker and Connect to Dremio Cloud\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/604i8vaukZs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are just starting to plan out the data infrastructure but this is what it looks like so far:\n\n&amp;#x200B;\n\n* **Data sources**: SQL database, exported flat files that are stored in Google Cloud storage, a few APIs\n* Python to extract and load data into bigquery \n* Python code with unit tests, logging, modules, alerts, etc containerized with docker and pushed to  an artifact registry \n* The docker image is then deployed by cloud run jobs to run the container on a schedule to start extracting and loading data\n* dbt is then used for transformations + all the other goodies it comes with \n\nThe velocity and volume of our data is very minimal and is meant for internal BI/ML use. While I want to keep scalability, maintenance, and best practices in mind, the normal constraints of big data engineering jobs are not the main concern- mostly implementing the most cost-effective, minimal solution that follows best practices. ", "author_fullname": "t2_2qknd8ft", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on small organization's ELT implementation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194yo0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705075743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are just starting to plan out the data infrastructure but this is what it looks like so far:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data sources&lt;/strong&gt;: SQL database, exported flat files that are stored in Google Cloud storage, a few APIs&lt;/li&gt;\n&lt;li&gt;Python to extract and load data into bigquery &lt;/li&gt;\n&lt;li&gt;Python code with unit tests, logging, modules, alerts, etc containerized with docker and pushed to  an artifact registry &lt;/li&gt;\n&lt;li&gt;The docker image is then deployed by cloud run jobs to run the container on a schedule to start extracting and loading data&lt;/li&gt;\n&lt;li&gt;dbt is then used for transformations + all the other goodies it comes with &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The velocity and volume of our data is very minimal and is meant for internal BI/ML use. While I want to keep scalability, maintenance, and best practices in mind, the normal constraints of big data engineering jobs are not the main concern- mostly implementing the most cost-effective, minimal solution that follows best practices. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "194yo0s", "is_robot_indexable": true, "report_reasons": null, "author": "muneriver", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194yo0s/advice_on_small_organizations_elt_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194yo0s/advice_on_small_organizations_elt_implementation/", "subreddit_subscribers": 152171, "created_utc": 1705075743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One argument is that you may only want to explicitly update your date. `UPSERT` is ambiguous in that, before you send the query, you don\u2019t know what the resulting outcome will be. You know `if/else` the outcome, but that is still more ambiguous. One might say they want to make sure they\u2019re either updating the data or not.\n\nOn the other hand, `UPSERT` probably just does the same thing but more efficiently\u2026\n\nWhat\u2019s the right call? What\u2019s it depend on?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you UPSERT, or SELECT, check for differences and update explicitly where needed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194lllx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705031750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One argument is that you may only want to explicitly update your date. &lt;code&gt;UPSERT&lt;/code&gt; is ambiguous in that, before you send the query, you don\u2019t know what the resulting outcome will be. You know &lt;code&gt;if/else&lt;/code&gt; the outcome, but that is still more ambiguous. One might say they want to make sure they\u2019re either updating the data or not.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, &lt;code&gt;UPSERT&lt;/code&gt; probably just does the same thing but more efficiently\u2026&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the right call? What\u2019s it depend on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194lllx", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194lllx/do_you_upsert_or_select_check_for_differences_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194lllx/do_you_upsert_or_select_check_for_differences_and/", "subreddit_subscribers": 152171, "created_utc": 1705031750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please help me solve a fight between the architects on my team....\n\nHere's the situation - we have a set of data that one of our teams currently work with as spreadsheets. There are about 100 different data sources involved. 90% of them come from other databases, the remaining 10% come in as flat files that are transformed and then exported as spreadsheets using some old code that we can't do much with.\n\nThe data changes infrequently, anywhere from monthly to yearly. The flat files need some transformation and manipulation, but the others are basically straight copy.\n\nWe want to take all of these files and move them into something more sophisticated so the team can use tools like PowerBI etc on them.\n\nOne architect wants to go a pretty traditional route and do Python loader scripts into an Azure SQL or Postgres database. One wants to use Azure Data Factory to move the data to a database. One wants to use Azure Synapse/Azure Databricks. \n\nThe Python scripts feel oldschool but solid, and the Synapse solution feels overpowered and overpriced for our needs.\n\nWWYD?", "author_fullname": "t2_9u2ld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low-Volume ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194k0s8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705026876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please help me solve a fight between the architects on my team....&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the situation - we have a set of data that one of our teams currently work with as spreadsheets. There are about 100 different data sources involved. 90% of them come from other databases, the remaining 10% come in as flat files that are transformed and then exported as spreadsheets using some old code that we can&amp;#39;t do much with.&lt;/p&gt;\n\n&lt;p&gt;The data changes infrequently, anywhere from monthly to yearly. The flat files need some transformation and manipulation, but the others are basically straight copy.&lt;/p&gt;\n\n&lt;p&gt;We want to take all of these files and move them into something more sophisticated so the team can use tools like PowerBI etc on them.&lt;/p&gt;\n\n&lt;p&gt;One architect wants to go a pretty traditional route and do Python loader scripts into an Azure SQL or Postgres database. One wants to use Azure Data Factory to move the data to a database. One wants to use Azure Synapse/Azure Databricks. &lt;/p&gt;\n\n&lt;p&gt;The Python scripts feel oldschool but solid, and the Synapse solution feels overpowered and overpriced for our needs.&lt;/p&gt;\n\n&lt;p&gt;WWYD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "194k0s8", "is_robot_indexable": true, "report_reasons": null, "author": "edugeek", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194k0s8/lowvolume_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194k0s8/lowvolume_etl/", "subreddit_subscribers": 152171, "created_utc": 1705026876.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nReaching out regarding specifics of how ELT is typically implemented when the data source is out of your control - a 3rd party RESTful API.\n\nTypically I use Postgres for ETL. However, due to needing to store raw JSON data from an API, would ELT warrant a NoSQL database like MongoDB?\n\nHow do you handle defining your schema? Do you just not define it, configure your application to notify you in case of error, and manually patch in any data structure changes introduced by the API? Or rather, do you worry about forward compatibility and make sure failure is less likely occur? \n\nIn the case of forward compatibility, how do you implement the it? I\u2019m only aware of Protobuf and I think that\u2019s just for use from the application side of things\u2026 where would the forward compatibility implementation fit in? Is it logic decisions made by the DBA during schema design, or is it handled prior to load by the ELT pipeline (ignoring new data fields)?\n\nLastly, what comes next\u2026 do you typically setup an ETL to load your ELT results into a warehouse? Or rather, is the *T* in ELT where you run your analytical queries?\n\nCurious what your answers will be. Thanks for any insights as I become more familiar with this approach.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build ELT pipelines in contrast to ETL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194hqq5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705020460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Reaching out regarding specifics of how ELT is typically implemented when the data source is out of your control - a 3rd party RESTful API.&lt;/p&gt;\n\n&lt;p&gt;Typically I use Postgres for ETL. However, due to needing to store raw JSON data from an API, would ELT warrant a NoSQL database like MongoDB?&lt;/p&gt;\n\n&lt;p&gt;How do you handle defining your schema? Do you just not define it, configure your application to notify you in case of error, and manually patch in any data structure changes introduced by the API? Or rather, do you worry about forward compatibility and make sure failure is less likely occur? &lt;/p&gt;\n\n&lt;p&gt;In the case of forward compatibility, how do you implement the it? I\u2019m only aware of Protobuf and I think that\u2019s just for use from the application side of things\u2026 where would the forward compatibility implementation fit in? Is it logic decisions made by the DBA during schema design, or is it handled prior to load by the ELT pipeline (ignoring new data fields)?&lt;/p&gt;\n\n&lt;p&gt;Lastly, what comes next\u2026 do you typically setup an ETL to load your ELT results into a warehouse? Or rather, is the &lt;em&gt;T&lt;/em&gt; in ELT where you run your analytical queries?&lt;/p&gt;\n\n&lt;p&gt;Curious what your answers will be. Thanks for any insights as I become more familiar with this approach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194hqq5", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194hqq5/how_to_build_elt_pipelines_in_contrast_to_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194hqq5/how_to_build_elt_pipelines_in_contrast_to_etl/", "subreddit_subscribers": 152171, "created_utc": 1705020460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I was learning about Spark with Scala I read that Datasets are a very powerful feature as they allow for compile-time type checking, as well as taking advantage of functional programming when performing transformations.\n\nBut most sources I read mentioned that they are also slower than DataFrames, although according to [this article](https://itnext.io/making-the-spark-dataframe-composition-type-safe-r-7b6fed524ec2) from 2021 the performance gap between these two is narrowing. Moving 2 years later, [another article](https://sparkbyexamples.com/spark/spark-rdd-vs-dataframe-vs-dataset/) (from November 2023) claims that Datasets are actually faster than DataFrames.\n\nCan anyone confirm if it's true? And if so, does it make sense to only use Datasets when processing data using Spark with Scala? Or are there any areas where DataFrames would be a better choice?", "author_fullname": "t2_wn5fz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Datasets vs DataFrames performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1955qoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705093375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was learning about Spark with Scala I read that Datasets are a very powerful feature as they allow for compile-time type checking, as well as taking advantage of functional programming when performing transformations.&lt;/p&gt;\n\n&lt;p&gt;But most sources I read mentioned that they are also slower than DataFrames, although according to &lt;a href=\"https://itnext.io/making-the-spark-dataframe-composition-type-safe-r-7b6fed524ec2\"&gt;this article&lt;/a&gt; from 2021 the performance gap between these two is narrowing. Moving 2 years later, &lt;a href=\"https://sparkbyexamples.com/spark/spark-rdd-vs-dataframe-vs-dataset/\"&gt;another article&lt;/a&gt; (from November 2023) claims that Datasets are actually faster than DataFrames.&lt;/p&gt;\n\n&lt;p&gt;Can anyone confirm if it&amp;#39;s true? And if so, does it make sense to only use Datasets when processing data using Spark with Scala? Or are there any areas where DataFrames would be a better choice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?auto=webp&amp;s=3659cb0ddeb74f683e31b3620c391557aab5b547", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8744007118b1803247340b55f9685e254e553344", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=97e18e3884ace6f756fe8bccd4414ea29a8a9a8e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=06d4c55c572f7bd130164ffbe711a21954f18d38", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aff6e3db79b99dc83947ef1c99ed3c8567779378", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9be1733b25c40df472838fe9dc4d62ec88946a0e", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/OvEGLLSphTqd60ZFUDxwmbbFPwjTlkApwFaseM9rPPA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a841da9143ad1ce3f334a9a20139318b27975924", "width": 1080, "height": 720}], "variants": {}, "id": "1DzNUL7ZJLW7OT6sHMlmsLRjaSVL1prwDVVMlK9OUe8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955qoh", "is_robot_indexable": true, "report_reasons": null, "author": "Cydros1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955qoh/spark_datasets_vs_dataframes_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955qoh/spark_datasets_vs_dataframes_performance/", "subreddit_subscribers": 152171, "created_utc": 1705093375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The co-creators of Apache Iceberg have their own startup called Tabular.io\n\nHas anyone had a demo or signed up as a customer yet? \n\nI\u2019m curious what a managed iceberg implementation helps with.", "author_fullname": "t2_41soa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Tabular.io?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1955ps1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705093309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The co-creators of Apache Iceberg have their own startup called Tabular.io&lt;/p&gt;\n\n&lt;p&gt;Has anyone had a demo or signed up as a customer yet? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what a managed iceberg implementation helps with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955ps1", "is_robot_indexable": true, "report_reasons": null, "author": "miqcie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955ps1/thoughts_on_tabulario/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955ps1/thoughts_on_tabulario/", "subreddit_subscribers": 152171, "created_utc": 1705093309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I might be shortsighted about this topic and I wouldn't have any problem in admitting it. However, I've never talked to a DE that has worked with Databricks, ever. I've worked in mid-sized companies and Databricks has never been a topic discussed.  \nMost positions I see don't ask for Databricks knowledge or experience, at least in Brazil, where I'm from, or Portugal, where I'm looking some opportunities recently. Looking at their website, it seems that only very large companies use their services. \n\nFrom a management point of view, why would you use another platform instead of using the cloud that your company already uses? Wouldn't it be cheaper and easier to negotiate some discounts (like reserved instances) and keep everything in 'one stack'?\n\nI want to emphasize that I'm not saying the Databricks is useless or bad. I only wants to understand what companies use it and why.  \n", "author_fullname": "t2_jsmqklq8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Databricks a niche enterprise platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1955990", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705092172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I might be shortsighted about this topic and I wouldn&amp;#39;t have any problem in admitting it. However, I&amp;#39;ve never talked to a DE that has worked with Databricks, ever. I&amp;#39;ve worked in mid-sized companies and Databricks has never been a topic discussed.&lt;br/&gt;\nMost positions I see don&amp;#39;t ask for Databricks knowledge or experience, at least in Brazil, where I&amp;#39;m from, or Portugal, where I&amp;#39;m looking some opportunities recently. Looking at their website, it seems that only very large companies use their services. &lt;/p&gt;\n\n&lt;p&gt;From a management point of view, why would you use another platform instead of using the cloud that your company already uses? Wouldn&amp;#39;t it be cheaper and easier to negotiate some discounts (like reserved instances) and keep everything in &amp;#39;one stack&amp;#39;?&lt;/p&gt;\n\n&lt;p&gt;I want to emphasize that I&amp;#39;m not saying the Databricks is useless or bad. I only wants to understand what companies use it and why.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1955990", "is_robot_indexable": true, "report_reasons": null, "author": "Rude_effect_74", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1955990/is_databricks_a_niche_enterprise_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1955990/is_databricks_a_niche_enterprise_platform/", "subreddit_subscribers": 152171, "created_utc": 1705092172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Comprehensive LangChain Overview", "author_fullname": "t2_w6hkluod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intro to LangChain - Full Documentation Overview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_1953r5e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/dXP841pBcJw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Intro to LangChain - Full Documentation Overview\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Intro to LangChain - Full Documentation Overview", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/dXP841pBcJw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Intro to LangChain - Full Documentation Overview\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/dXP841pBcJw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/dXP841pBcJw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Intro to LangChain - Full Documentation Overview\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1953r5e", "height": 200}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/wIm2grfzg4WklEENiIFFhILJlmZw14inxeb0rTGSV08.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705088427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Comprehensive LangChain Overview&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/dXP841pBcJw?si=V03bfGxR0E2DVOA8", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?auto=webp&amp;s=497bf76b2ef9374ce320044a84b6d3583edb50ab", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a4e2291e5855e424e7bff55df318fa6db516bdb", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fade83913d2a78ad8469df7bd14faf03cf052805", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=362f231282720dbda6fe4de5188bd10440805d1e", "width": 320, "height": 240}], "variants": {}, "id": "2nxPz3zTCakYoPq2FC4RBH3y4pQDapZO_2BdgPQDMT8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1953r5e", "is_robot_indexable": true, "report_reasons": null, "author": "danipudani", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1953r5e/intro_to_langchain_full_documentation_overview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/dXP841pBcJw?si=V03bfGxR0E2DVOA8", "subreddit_subscribers": 152171, "created_utc": 1705088427.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Intro to LangChain - Full Documentation Overview", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/dXP841pBcJw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Intro to LangChain - Full Documentation Overview\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/dXP841pBcJw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been asking people I know and the general consensus is that they're not that useful, but that's a biased people out there. I figure there must be people out there who find tools like Monte Carlo valuable, have you all found them generally useful?", "author_fullname": "t2_vxxrqrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone actually find their data quality/anomaly detection applications useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1952j59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705085371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been asking people I know and the general consensus is that they&amp;#39;re not that useful, but that&amp;#39;s a biased people out there. I figure there must be people out there who find tools like Monte Carlo valuable, have you all found them generally useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1952j59", "is_robot_indexable": true, "report_reasons": null, "author": "MrMosBiggestFan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1952j59/does_anyone_actually_find_their_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1952j59/does_anyone_actually_find_their_data/", "subreddit_subscribers": 152171, "created_utc": 1705085371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm moving to a new team DataOps at 50% capacity. This was announced to be effective December 2023 no significant movement on the same. I tried to reach the team lead in December she mentioned she is busy and will reach back. Nothing happened. She gave me a link for video dated seven months its already a legacy as the meeting she mentioned there is going to be lot of changes. Again in January 2024 I reached out again asking for more information, spoke over zoom for the first time. Gave me few run books to look at. I asked provide me an architecture which I can understand what job I'm going into. Its been a week now no other progress don't know I will be blamed and it seems it might be a way to lay me off. Any advise on this. I cant blame the the tem lead to the director cos I have been already raising my voice to the director for the past couple of years about stagnation", "author_fullname": "t2_3i19ucis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joining a New Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1952e3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705085018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m moving to a new team DataOps at 50% capacity. This was announced to be effective December 2023 no significant movement on the same. I tried to reach the team lead in December she mentioned she is busy and will reach back. Nothing happened. She gave me a link for video dated seven months its already a legacy as the meeting she mentioned there is going to be lot of changes. Again in January 2024 I reached out again asking for more information, spoke over zoom for the first time. Gave me few run books to look at. I asked provide me an architecture which I can understand what job I&amp;#39;m going into. Its been a week now no other progress don&amp;#39;t know I will be blamed and it seems it might be a way to lay me off. Any advise on this. I cant blame the the tem lead to the director cos I have been already raising my voice to the director for the past couple of years about stagnation&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1952e3i", "is_robot_indexable": true, "report_reasons": null, "author": "BeginningAd4923", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1952e3i/joining_a_new_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1952e3i/joining_a_new_team/", "subreddit_subscribers": 152171, "created_utc": 1705085018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm preparing myself for a interview for a data egeneer role next week, and I'm asking you for a good video material on Spark internal workings.\nIt should cover some of the following topics:\n1. Partitioning\n2. Shuffling\n3. Persistence and Caching\n4. Broadcasting\n5. Catalist optimiser\n6. Sort merge join\n\nReading materials would also be fine but I prefer video materials with good explanation of those topics. \n\nThanks in advance.", "author_fullname": "t2_p4cx7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great video on Spark internal workings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1950lxe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705080582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m preparing myself for a interview for a data egeneer role next week, and I&amp;#39;m asking you for a good video material on Spark internal workings.\nIt should cover some of the following topics:\n1. Partitioning\n2. Shuffling\n3. Persistence and Caching\n4. Broadcasting\n5. Catalist optimiser\n6. Sort merge join&lt;/p&gt;\n\n&lt;p&gt;Reading materials would also be fine but I prefer video materials with good explanation of those topics. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1950lxe", "is_robot_indexable": true, "report_reasons": null, "author": "dark_knight_bg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1950lxe/great_video_on_spark_internal_workings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1950lxe/great_video_on_spark_internal_workings/", "subreddit_subscribers": 152171, "created_utc": 1705080582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If someone wants to move into Data Engineering role from IT background having basic coding experience with python how difficult it will be for the transition? Anyone here transformed into Data Engineering role from IT infrastructure background? Thank you", "author_fullname": "t2_8cdpdjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much code is needed for a Data Engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19503tx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705079339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If someone wants to move into Data Engineering role from IT background having basic coding experience with python how difficult it will be for the transition? Anyone here transformed into Data Engineering role from IT infrastructure background? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19503tx", "is_robot_indexable": true, "report_reasons": null, "author": "niaznishu", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19503tx/how_much_code_is_needed_for_a_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19503tx/how_much_code_is_needed_for_a_data_engineering/", "subreddit_subscribers": 152171, "created_utc": 1705079339.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}