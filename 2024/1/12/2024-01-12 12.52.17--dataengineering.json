{"kind": "Listing", "data": {"after": "t3_194lllx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guess the data type \u0ca0_\u0ca0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1945s14", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 416, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 416, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6OUWGdi7zMP1eZSi_VoZQEu6EsikAvzSqJz6d5ovrEc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704990687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/t9nn0bq88ubc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/t9nn0bq88ubc1.png?auto=webp&amp;s=cad6c0561f9df548a29f20fa31ad6eae64e1fc60", "width": 778, "height": 1200}, "resolutions": [{"url": "https://preview.redd.it/t9nn0bq88ubc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6424c32802e9fba636d819f274dc1f1eba931b44", "width": 108, "height": 166}, {"url": "https://preview.redd.it/t9nn0bq88ubc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ebf60f950e042c9f9b237b37c8baa29031edaf21", "width": 216, "height": 333}, {"url": "https://preview.redd.it/t9nn0bq88ubc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe80fc967b18438c4a7241d3d6d13d347645d178", "width": 320, "height": 493}, {"url": "https://preview.redd.it/t9nn0bq88ubc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d047d996e9b90ae744ab20efc5bbe8d390b0072d", "width": 640, "height": 987}], "variants": {}, "id": "eGQWKC-q_uhJok7ugfder92YSYVbV5wEkt-NcHXwHw8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1945s14", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1945s14/guess_the_data_type_\u0ca0_\u0ca0/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/t9nn0bq88ubc1.png", "subreddit_subscribers": 152076, "created_utc": 1704990687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\nI hope you guys are well. I'm curious about your opinions. I'm a data engineer trainee. I want to learn A LOT. Not only SQL, Python, but PySpak, etc, etc.\n\nBut I'm curious: What's the best course, or certification (specialization) or degree of all time for you, that you can end the course and say: \"Wow, f\\*\\*\\*\\*\\*\\* hell! This was amazing! I learned so much with this!\"\n\nI want to know your opinions :)\n\nYou can also share books, share what really help you with to grow as a Data Engineer and as a professional :)\n\nHave a good day/night", "author_fullname": "t2_dfo75n0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer - What's the best course, certification or degree of all time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194d07l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705009061.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705008482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I hope you guys are well. I&amp;#39;m curious about your opinions. I&amp;#39;m a data engineer trainee. I want to learn A LOT. Not only SQL, Python, but PySpak, etc, etc.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m curious: What&amp;#39;s the best course, or certification (specialization) or degree of all time for you, that you can end the course and say: &amp;quot;Wow, f****** hell! This was amazing! I learned so much with this!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I want to know your opinions :)&lt;/p&gt;\n\n&lt;p&gt;You can also share books, share what really help you with to grow as a Data Engineer and as a professional :)&lt;/p&gt;\n\n&lt;p&gt;Have a good day/night&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194d07l", "is_robot_indexable": true, "report_reasons": null, "author": "GigabyteWarrior", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194d07l/data_engineer_whats_the_best_course_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194d07l/data_engineer_whats_the_best_course_certification/", "subreddit_subscribers": 152076, "created_utc": 1705008482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all!\n\nI've seen a lot of posts recently across Reddit of SWEs feeling the pain from layoffs and having trouble finding new positions out there.\n\nAs someone in constant fear of being laid off (mostly just anxiety) I see these sorts of things and get a bit nervous, however, I have seen much less of this in the Data Engineering community.\n\nNot sure if it's just because it's a smaller community or if it's because there's still a good market for Data Engineers.\n\nAny thoughts from the community about the market in comparison to Software Engineering?", "author_fullname": "t2_eatn2f80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SWE Market Vs DE Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194m0y8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705033103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a lot of posts recently across Reddit of SWEs feeling the pain from layoffs and having trouble finding new positions out there.&lt;/p&gt;\n\n&lt;p&gt;As someone in constant fear of being laid off (mostly just anxiety) I see these sorts of things and get a bit nervous, however, I have seen much less of this in the Data Engineering community.&lt;/p&gt;\n\n&lt;p&gt;Not sure if it&amp;#39;s just because it&amp;#39;s a smaller community or if it&amp;#39;s because there&amp;#39;s still a good market for Data Engineers.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts from the community about the market in comparison to Software Engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194m0y8", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional-Ad-8670", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194m0y8/swe_market_vs_de_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194m0y8/swe_market_vs_de_market/", "subreddit_subscribers": 152076, "created_utc": 1705033103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I pay for a hosted SQL Server because a 3rd party makes data available for analytics only through this hosted service. I get SSL access to this database for a cost. The database gets refreshed nightly with my account data, so basically it\u2019s an OLAP that gets updated every 24hrs.\n\nAt the same time, I incur egress fees for data leaving this storage. This is unfortunate because analytics often use the same data over and over again. So I am effectively paying to pull out the same data several times over. What a waste of money when the data only changes once every 24hrs.\n\nI want to replicate the data once a data and just run analytics on my replication. However, I have an existing database (Postgres) that I use for similar analytics with data I garner locally. It would be ideal if I could just move the daily SQL Server data into my Postgres instance,\n\nWhat are the best tools for achieving such replication when you aren\u2019t an admin of the database to be replicated? Is my best bet building a CSV from a SELECT statement for every table, then importing to Postgres? Is there a better way?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the best approach for replicating all data from an SQL Server instance to a Postgres instance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194iz0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705023868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I pay for a hosted SQL Server because a 3rd party makes data available for analytics only through this hosted service. I get SSL access to this database for a cost. The database gets refreshed nightly with my account data, so basically it\u2019s an OLAP that gets updated every 24hrs.&lt;/p&gt;\n\n&lt;p&gt;At the same time, I incur egress fees for data leaving this storage. This is unfortunate because analytics often use the same data over and over again. So I am effectively paying to pull out the same data several times over. What a waste of money when the data only changes once every 24hrs.&lt;/p&gt;\n\n&lt;p&gt;I want to replicate the data once a data and just run analytics on my replication. However, I have an existing database (Postgres) that I use for similar analytics with data I garner locally. It would be ideal if I could just move the daily SQL Server data into my Postgres instance,&lt;/p&gt;\n\n&lt;p&gt;What are the best tools for achieving such replication when you aren\u2019t an admin of the database to be replicated? Is my best bet building a CSV from a SELECT statement for every table, then importing to Postgres? Is there a better way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194iz0f", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194iz0f/whats_the_best_approach_for_replicating_all_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194iz0f/whats_the_best_approach_for_replicating_all_data/", "subreddit_subscribers": 152076, "created_utc": 1705023868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently joined a data engineering team after a few years as a web engineer. I am not and expert but know the basic design patterns and principles. The team I joined writes really bad code.. but to be honest I\u2019m not sure it matters? Most of these scripts never need to be adjusted and will continue to move data. \n\nI\u2019m curious what coding standards you implement in your code. Are you using object oriented designs?", "author_fullname": "t2_e70iqfxk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How clean is your code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194q4yk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705047765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently joined a data engineering team after a few years as a web engineer. I am not and expert but know the basic design patterns and principles. The team I joined writes really bad code.. but to be honest I\u2019m not sure it matters? Most of these scripts never need to be adjusted and will continue to move data. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what coding standards you implement in your code. Are you using object oriented designs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194q4yk", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Wall8245", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194q4yk/how_clean_is_your_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194q4yk/how_clean_is_your_code/", "subreddit_subscribers": 152076, "created_utc": 1705047765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w6hkluod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouses vs Data Lakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_194gh3f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Warehouses vs Data Lakes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xbtK43WlkMs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/194gh3f", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oB8_ilnk9vQ2eW0UEwgkrNRE68LKUHbqUGGwzrNxoAg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705017049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xbtK43WlkMs?si=RR_Kn6e_4DuIbf9u", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AbPG6wDO7qLLJmHEOkFtKWqk8Epjbijr88u4Cz9Fwis.jpg?auto=webp&amp;s=ec5fe1f9180f791f5a505912dc38b81ff4623330", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/AbPG6wDO7qLLJmHEOkFtKWqk8Epjbijr88u4Cz9Fwis.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=756721c559ceb9ffad969c0874cca31d7fe8b6e4", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/AbPG6wDO7qLLJmHEOkFtKWqk8Epjbijr88u4Cz9Fwis.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=843a64fa731153b5ef755c11a20397ad376f8b3c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/AbPG6wDO7qLLJmHEOkFtKWqk8Epjbijr88u4Cz9Fwis.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df041474b3ac17e595b9625e78964cac0ebaa6f8", "width": 320, "height": 240}], "variants": {}, "id": "y1-ztg6CqTUIpsSMCro3W1_odauB7Vb_7yUnCwY1H7o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "194gh3f", "is_robot_indexable": true, "report_reasons": null, "author": "danipudani", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194gh3f/data_warehouses_vs_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xbtK43WlkMs?si=RR_Kn6e_4DuIbf9u", "subreddit_subscribers": 152076, "created_utc": 1705017049.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Warehouses vs Data Lakes", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xbtK43WlkMs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Warehouses vs Data Lakes\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xbtK43WlkMs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, I am having 5.5 years of experience in data engineering mostly worked on teradata. Currently in gcp services. Before making another switch I want to be fundamentally good at pyspark by having some hands-on experience. What will be best way I can follow to learn pyspark or and good courses that I can take if any. Please suggest.", "author_fullname": "t2_pe79l62ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to learn pyspark.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194rp77", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705054268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I am having 5.5 years of experience in data engineering mostly worked on teradata. Currently in gcp services. Before making another switch I want to be fundamentally good at pyspark by having some hands-on experience. What will be best way I can follow to learn pyspark or and good courses that I can take if any. Please suggest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194rp77", "is_robot_indexable": true, "report_reasons": null, "author": "TheErenYeager03", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194rp77/best_way_to_learn_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194rp77/best_way_to_learn_pyspark/", "subreddit_subscribers": 152076, "created_utc": 1705054268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently saw a post on this sub[(7) Will you stop using dashboards? : dataengineering (reddit.com)](https://www.reddit.com/r/dataengineering/comments/193xq76/will_you_stop_using_dashboards/?sort=new) where it seems like dashboarding tools are not as useful for pushing back to databases. Are there any tools out there that do help to build dashboards and write back to databases? Any frameworks specific to python?", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PowerBI vs Streamlit(Python) for Interactive Dashboards?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194aua2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705003121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently saw a post on this sub&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/193xq76/will_you_stop_using_dashboards/?sort=new\"&gt;(7) Will you stop using dashboards? : dataengineering (reddit.com)&lt;/a&gt; where it seems like dashboarding tools are not as useful for pushing back to databases. Are there any tools out there that do help to build dashboards and write back to databases? Any frameworks specific to python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194aua2", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194aua2/powerbi_vs_streamlitpython_for_interactive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194aua2/powerbi_vs_streamlitpython_for_interactive/", "subreddit_subscribers": 152076, "created_utc": 1705003121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to transition from sales to data engineering. I currently sell a product in the data engineering space and it's revitalized my interest in engineering. I don't have a degree. Pretty much my only relevant professional experience would be selling a data product.\n\n&amp;#x200B;\n\nI've coded on and off (mostly off lol) since the start of the pandemic. At this point I know basic python up to OOP and could probably throw together a web scraper or something basic. I'm starting to learn sql and have actually used it for some extremely basic queries at work. \n\n&amp;#x200B;\n\nI've just started the IBM Data Engineering cert hoping that this will give me a good route to actually learning the industry as a whole. After this I want to complete Google's equivalent (if necessary) as I've heard its a more in depth cert for people already working in the space. While learning I plan to simultaneously start putting together some DE projects. (Pulling data, storing it in the cloud, sql to make tables, data visualization.)\n\n&amp;#x200B;\n\nIs it realistic to be aiming for a data engineering role with my background? Or should I start as an analyst? (My job is trying to get me into an analyst role in the next 6-12 months but 1 the role is very high level, think tableau and excel. No one uses programming currently. 2 by the time i get in that role, I could be well on my way to finishing both certs. 3 I believe the pay would be higher if I went the DE route, think \\~80-95 vs I'm assuming at least 115-120 for a DE", "author_fullname": "t2_6y6wxfoo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sales to Data Engineering Transition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194abpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705001810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to transition from sales to data engineering. I currently sell a product in the data engineering space and it&amp;#39;s revitalized my interest in engineering. I don&amp;#39;t have a degree. Pretty much my only relevant professional experience would be selling a data product.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve coded on and off (mostly off lol) since the start of the pandemic. At this point I know basic python up to OOP and could probably throw together a web scraper or something basic. I&amp;#39;m starting to learn sql and have actually used it for some extremely basic queries at work. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just started the IBM Data Engineering cert hoping that this will give me a good route to actually learning the industry as a whole. After this I want to complete Google&amp;#39;s equivalent (if necessary) as I&amp;#39;ve heard its a more in depth cert for people already working in the space. While learning I plan to simultaneously start putting together some DE projects. (Pulling data, storing it in the cloud, sql to make tables, data visualization.)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is it realistic to be aiming for a data engineering role with my background? Or should I start as an analyst? (My job is trying to get me into an analyst role in the next 6-12 months but 1 the role is very high level, think tableau and excel. No one uses programming currently. 2 by the time i get in that role, I could be well on my way to finishing both certs. 3 I believe the pay would be higher if I went the DE route, think ~80-95 vs I&amp;#39;m assuming at least 115-120 for a DE&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194abpq", "is_robot_indexable": true, "report_reasons": null, "author": "ColivarTT", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194abpq/sales_to_data_engineering_transition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194abpq/sales_to_data_engineering_transition/", "subreddit_subscribers": 152076, "created_utc": 1705001810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'll start with some good news; I recently got my first job as a data engineer!  It's contract-to-hire at a public health insurance agency and I am very excited for it.\n\nBefore this position, I studied an MS Information Systems degree where I learned a lot about data science, ML and statistics.  In this job, it looks like I will be using none of it.  I'm trying to think if there are any ways I can use the data science knowledge I learned in grad school to grow in my data engineering career, or whether it was just lost time.  Could it come in handy if I focus on data engineering for ML in the future?  Could there be overlap where it could come in handy?  Maybe should I look for ways to apply this knowledge in my new role and not worry about how it fits into the bigger picture? \n Let me know - right now feeling a bit sad that I'm not putting anything I learned in grad school to good use, like it was a waste of time.\n\nThanks in advance for your thoughts!", "author_fullname": "t2_aewcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Utility of Data Science / Statistics / ML Knowledge in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194o6gm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705040223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll start with some good news; I recently got my first job as a data engineer!  It&amp;#39;s contract-to-hire at a public health insurance agency and I am very excited for it.&lt;/p&gt;\n\n&lt;p&gt;Before this position, I studied an MS Information Systems degree where I learned a lot about data science, ML and statistics.  In this job, it looks like I will be using none of it.  I&amp;#39;m trying to think if there are any ways I can use the data science knowledge I learned in grad school to grow in my data engineering career, or whether it was just lost time.  Could it come in handy if I focus on data engineering for ML in the future?  Could there be overlap where it could come in handy?  Maybe should I look for ways to apply this knowledge in my new role and not worry about how it fits into the bigger picture? \n Let me know - right now feeling a bit sad that I&amp;#39;m not putting anything I learned in grad school to good use, like it was a waste of time.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194o6gm", "is_robot_indexable": true, "report_reasons": null, "author": "i_am_baldilocks", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194o6gm/utility_of_data_science_statistics_ml_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194o6gm/utility_of_data_science_statistics_ml_knowledge/", "subreddit_subscribers": 152076, "created_utc": 1705040223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm the author of this guide to logical replication in Postgres. I break down some of the internal components of Postgres to make CDC easier to understand. I hope you find it informative and learn something new!  \n\n\n[https://airbyte.com/blog/a-guide-to-logical-replication-and-cdc-in-postgresql](https://airbyte.com/blog/a-guide-to-logical-replication-and-cdc-in-postgresql)", "author_fullname": "t2_5h5nqi7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Technical Dive into PostgreSQL's replication mechanisms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1945xlx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704991074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m the author of this guide to logical replication in Postgres. I break down some of the internal components of Postgres to make CDC easier to understand. I hope you find it informative and learn something new!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://airbyte.com/blog/a-guide-to-logical-replication-and-cdc-in-postgresql\"&gt;https://airbyte.com/blog/a-guide-to-logical-replication-and-cdc-in-postgresql&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EzsTjjvkYq85tYMJM94Rg-FkeSSfaOVklY-rrZCGrC8.jpg?auto=webp&amp;s=9515e66cd8f13f2a1dca61f0163a8a75b0174642", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/EzsTjjvkYq85tYMJM94Rg-FkeSSfaOVklY-rrZCGrC8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=83b29078bcf067ed68763f8c17a57e9b04fbc606", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/EzsTjjvkYq85tYMJM94Rg-FkeSSfaOVklY-rrZCGrC8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e05004a3058e45746325e4574fe92aa275729d7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/EzsTjjvkYq85tYMJM94Rg-FkeSSfaOVklY-rrZCGrC8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=af2b3b70ea1c354bc34d603275f59f90434d4785", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/EzsTjjvkYq85tYMJM94Rg-FkeSSfaOVklY-rrZCGrC8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a19775e3bd8feb47c0cbf9cf832166940e0059b5", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/EzsTjjvkYq85tYMJM94Rg-FkeSSfaOVklY-rrZCGrC8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a7334e16a2cabb7e597852b417b1a28e04d9f09b", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/EzsTjjvkYq85tYMJM94Rg-FkeSSfaOVklY-rrZCGrC8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2b9eb8649d858aa647185b5a7d241d1ca76f527a", "width": 1080, "height": 565}], "variants": {}, "id": "rZw_N468oAzYIoTZy4SyJC-DaQSJvh480u3XU8PeyuI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1945xlx", "is_robot_indexable": true, "report_reasons": null, "author": "Chemical-Treat6596", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1945xlx/a_technical_dive_into_postgresqls_replication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1945xlx/a_technical_dive_into_postgresqls_replication/", "subreddit_subscribers": 152076, "created_utc": 1704991074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why the Modern Data Stack sucks for data consultancies looking to productize", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_1940jpl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z80amFoGZF4uKOW3ePYmKPJw815hUsMMEdqHJ_f3Rmg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704976019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arch.dev", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arch.dev/blog/why-the-modern-data-stack-sucks-for-data-consultancies-looking-to-productize/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?auto=webp&amp;s=d881a43f6049b89e4e066fdec179ca867234699a", "width": 1792, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d50965a9c8e4dfb95d059efbb0ca8874a7e9fd24", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d51552db0d7f00af72c2917c137535e480b083fb", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=abada4d1af8927e2dee9a58e9931ad829e98a32b", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7129035f695679de5a1082d9bad5e24b3cf5f9ff", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0fca419eef28bf35b5f5827f58a0d8841aab8355", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/2TIvmEmBcxrV7XLN389zAFH2ntXlGvYETUM8QQPA9AM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0509de0824804f288d0bc095bfdf0d6bad45829a", "width": 1080, "height": 617}], "variants": {}, "id": "WpZH0isc5AN4ZOJ6PliPBgbg_B4B6TaTgAHr3YBSZII"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1940jpl", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1940jpl/why_the_modern_data_stack_sucks_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arch.dev/blog/why-the-modern-data-stack-sucks-for-data-consultancies-looking-to-productize/", "subreddit_subscribers": 152076, "created_utc": 1704976019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c9ymz7vr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL made easy using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_194sed6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/E_idWOUF_TeXjNzvl_9nm5B1AhxqIxpsBEP22jOnyaY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705057113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/python-in-plain-english/sql-aggregations-are-made-easy-using-ai-216f9c4a406b", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?auto=webp&amp;s=7c903c13dc75e3d1caa922d721fdb56bff4f877d", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=82058ce2dfd3d07eae450510497aa5e5fa922436", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=940a035aba7966cb75e9f3be5145544a01f8e432", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2fb2db77f1f2b765850647ffccdde9121f5b3e2d", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ef0005758cd1fd54309cc1a2446b0fa9c6a83e5", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6cd4e3307c6a54fd7d1ca325df92c22b9cde1aa2", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/kakmtwsxuj0PZtBSNgY1c0RBpGR2j7oCW1daOvxm9EQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3182f4035b91a8b1a02447d9ab8cf4c965210a98", "width": 1080, "height": 1080}], "variants": {}, "id": "ywuNk0kBtw9nHT_Wzv9hfXqV4pQ3u7YA2553E0hxYRM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "194sed6", "is_robot_indexable": true, "report_reasons": null, "author": "United_Engineer_198", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194sed6/sql_made_easy_using_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/python-in-plain-english/sql-aggregations-are-made-easy-using-ai-216f9c4a406b", "subreddit_subscribers": 152076, "created_utc": 1705057113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI'm currently a mechanical engineer working in aerospace, looking to transition into data engineering. However, I'm unsure at what level I should be \"selling\" my skills.\n\nI've basically been doing some kind of data analyst/software engineer/data engineer/data scientist job for the past two years, but I don't really have anyone experienced around to compare myself to, so I don't know if I'm competent or totally inept.\n\nI'm happy using Python, pandas, and scikit-learn to do some transforming, cleaning, and machine learning predictions. I also have decent experience with our in-house tool (Palantir Foundry) using PySpark and PostreSQL, and creating some simple dashboards using HTML / CSS / JS.\n\nI've also developed some in-house structural analysis tools using Python, and I'm familiar with object oriented programming, data structures, algorithms etc. but again I don't know if my code is great or total shit as a competent software engineer has never reviewed it.\n\nI'd like to move to a job where I have seniors to learn from, but I'm not sure if I'm ready. I also have no idea how much my walled-garden experience with Palantir Foundry would carry over to things like AWS, Azure etc.\n\nIs there a certain level of competence I should be looking for before trying to move over? I don't want to blag my way into a job and get fired after a couple of months.\n\nThanks", "author_fullname": "t2_iemkebmei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unsure of my skill level?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1948ba1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704996822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a mechanical engineer working in aerospace, looking to transition into data engineering. However, I&amp;#39;m unsure at what level I should be &amp;quot;selling&amp;quot; my skills.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve basically been doing some kind of data analyst/software engineer/data engineer/data scientist job for the past two years, but I don&amp;#39;t really have anyone experienced around to compare myself to, so I don&amp;#39;t know if I&amp;#39;m competent or totally inept.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m happy using Python, pandas, and scikit-learn to do some transforming, cleaning, and machine learning predictions. I also have decent experience with our in-house tool (Palantir Foundry) using PySpark and PostreSQL, and creating some simple dashboards using HTML / CSS / JS.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also developed some in-house structural analysis tools using Python, and I&amp;#39;m familiar with object oriented programming, data structures, algorithms etc. but again I don&amp;#39;t know if my code is great or total shit as a competent software engineer has never reviewed it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to move to a job where I have seniors to learn from, but I&amp;#39;m not sure if I&amp;#39;m ready. I also have no idea how much my walled-garden experience with Palantir Foundry would carry over to things like AWS, Azure etc.&lt;/p&gt;\n\n&lt;p&gt;Is there a certain level of competence I should be looking for before trying to move over? I don&amp;#39;t want to blag my way into a job and get fired after a couple of months.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1948ba1", "is_robot_indexable": true, "report_reasons": null, "author": "anonymous_lurker_01", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1948ba1/unsure_of_my_skill_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1948ba1/unsure_of_my_skill_level/", "subreddit_subscribers": 152076, "created_utc": 1704996822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working as ETL developer since 4 months(fresher) in a service based company, with tech stak snowflake, IICS. \nFirst of all IICS is the worst tool, they are very slow and very unpredictable. Idk about powercenter, but informstica cloud is so much slow. We have to face constant issue saving a taskflow. , and updating a taskflow. \n\nBut thank god I got lucky,  i got chance to use snowflake that is great software. one day my project leader was absent, and a BRE template was needed. I took the weekend that was able to process join condition also. \nThen I was asked to created a stored procedure for a part of project that will process around csv data from around 50 vendors having 4 file type from each vendor I.e 200 files. And load it into staging layer in 20 channels. That's also not a straight pass, many to one mapping. I have successfully implemented that procedure. \n\nDamn my nightmare begins now, first client changed all the  STTM, then our functional group who  made grave mistake they, followed every instructions blindly without analyzing sample data from client. Then data architect changed all the data model. I improvised the code made up the changes. Forcefully developed code to process STTM that will great data model accordingly. My manager was asking to check thoe file mannually \ud83d\ude35\u200d\ud83d\udcab test those ingestion. Disagreeing with him, I automated testing process. I have to debate over that for 2 hours with testing lead. Why is it necessary. \nAfter that they are changing vendor to channel map constantly (following sample data). Basically vendor to channel map is being done on basis of a column. And they are undecisive of those map they are changing it every few days. Simple they say you have automated it. Do it! But those automated process is not so formalised. I had developed to easy my work not to automate the process. You should have give more time. . It takes lot of concentration to avoid those unforseen \n\nI am constantly asking my manager that we are following wrong approach since I have analysed sample data from that on distinct value of that particular column is mapped into each channel. Which is the trigger for that orocedure. When in product environment it will break down graduall. In real data there may be many code. But my manager, god knows why is not forwarding that input. All are acting as per wish. Then they expect refined data. God knows what they do. \ud83e\udd72\ud83e\udd72\ud83e\udd72", "author_fullname": "t2_1ubfs6x4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rant! How functional group and bad management affect Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1946ghu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704992623.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704992387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working as ETL developer since 4 months(fresher) in a service based company, with tech stak snowflake, IICS. \nFirst of all IICS is the worst tool, they are very slow and very unpredictable. Idk about powercenter, but informstica cloud is so much slow. We have to face constant issue saving a taskflow. , and updating a taskflow. &lt;/p&gt;\n\n&lt;p&gt;But thank god I got lucky,  i got chance to use snowflake that is great software. one day my project leader was absent, and a BRE template was needed. I took the weekend that was able to process join condition also. \nThen I was asked to created a stored procedure for a part of project that will process around csv data from around 50 vendors having 4 file type from each vendor I.e 200 files. And load it into staging layer in 20 channels. That&amp;#39;s also not a straight pass, many to one mapping. I have successfully implemented that procedure. &lt;/p&gt;\n\n&lt;p&gt;Damn my nightmare begins now, first client changed all the  STTM, then our functional group who  made grave mistake they, followed every instructions blindly without analyzing sample data from client. Then data architect changed all the data model. I improvised the code made up the changes. Forcefully developed code to process STTM that will great data model accordingly. My manager was asking to check thoe file mannually \ud83d\ude35\u200d\ud83d\udcab test those ingestion. Disagreeing with him, I automated testing process. I have to debate over that for 2 hours with testing lead. Why is it necessary. \nAfter that they are changing vendor to channel map constantly (following sample data). Basically vendor to channel map is being done on basis of a column. And they are undecisive of those map they are changing it every few days. Simple they say you have automated it. Do it! But those automated process is not so formalised. I had developed to easy my work not to automate the process. You should have give more time. . It takes lot of concentration to avoid those unforseen &lt;/p&gt;\n\n&lt;p&gt;I am constantly asking my manager that we are following wrong approach since I have analysed sample data from that on distinct value of that particular column is mapped into each channel. Which is the trigger for that orocedure. When in product environment it will break down graduall. In real data there may be many code. But my manager, god knows why is not forwarding that input. All are acting as per wish. Then they expect refined data. God knows what they do. \ud83e\udd72\ud83e\udd72\ud83e\udd72&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1946ghu", "is_robot_indexable": true, "report_reasons": null, "author": "asud_w_asud", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1946ghu/rant_how_functional_group_and_bad_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1946ghu/rant_how_functional_group_and_bad_management/", "subreddit_subscribers": 152076, "created_utc": 1704992387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors,\n\n&amp;#x200B;\n\nI've been working as a data engineer with expertise in Google Cloud Platform (GCP) for a while now. Despite my proficiency in GCP, I've been noticing fewer opportunities in the market and I'm contemplating expanding my skill set to include AWS.\n\n&amp;#x200B;\n\nFor those who have made a similar transition or have experience with both platforms, how familiar is AWS for someone who knows GCP well? What challenges did you face, and how did you overcome them? Are there any specific resources or learning paths you recommend for someone in my position?\n\n&amp;#x200B;\n\nI appreciate any insights or advice you can share. Thanks in advance!", "author_fullname": "t2_hm7bbgnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Considering a Shift from GCP to AWS: Data Engineer Seeking Advice on Transitioning and Market Opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19466ch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704991690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working as a data engineer with expertise in Google Cloud Platform (GCP) for a while now. Despite my proficiency in GCP, I&amp;#39;ve been noticing fewer opportunities in the market and I&amp;#39;m contemplating expanding my skill set to include AWS.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For those who have made a similar transition or have experience with both platforms, how familiar is AWS for someone who knows GCP well? What challenges did you face, and how did you overcome them? Are there any specific resources or learning paths you recommend for someone in my position?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I appreciate any insights or advice you can share. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19466ch", "is_robot_indexable": true, "report_reasons": null, "author": "TheOtherNormalOne", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19466ch/considering_a_shift_from_gcp_to_aws_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19466ch/considering_a_shift_from_gcp_to_aws_data_engineer/", "subreddit_subscribers": 152076, "created_utc": 1704991690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Each data platform I can think of seems to handle database security similarly: They require privileged access to your database/warehouse through an \"admin\" account and then add their security layer on top. This means no central access governance and no centralized logs, making it hard to put together a picture of who is accessing what. What are people's solutions to this and how do you manage this?", "author_fullname": "t2_q5jcx79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do people manage data security at scale when each vendor adds their security layer on top?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1945pt7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704990534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Each data platform I can think of seems to handle database security similarly: They require privileged access to your database/warehouse through an &amp;quot;admin&amp;quot; account and then add their security layer on top. This means no central access governance and no centralized logs, making it hard to put together a picture of who is accessing what. What are people&amp;#39;s solutions to this and how do you manage this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1945pt7", "is_robot_indexable": true, "report_reasons": null, "author": "bk1007", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1945pt7/how_do_people_manage_data_security_at_scale_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1945pt7/how_do_people_manage_data_security_at_scale_when/", "subreddit_subscribers": 152076, "created_utc": 1704990534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "we\u2019re currently working on our data, and we just entered the the phase where we\u2019re transforming our data using dbt. \n\nI\u2019m trying to watch closely what my team (1 person) is doing and tbh i didn\u2019t notice any changes!\n\nI mean, I find it exactly replicating the data from the data source. that\u2019s it. I can\u2019t see the added value. \n\nWe only re-group data into facts and dimensions, remove duplicates and rename the columns\u2026 I thought this phase will hold A LOT more. So, it\u2019s clear that we didn\u2019t understand how to use it properly. \n\nas an example, hubspot is one of our data sources and I found the transformed data not adding any value.. and we only have 7 tables from this source (?) leads, deals, quotations and contacts.\n\nI\u2019d appreciate if you can give examples of data transformation the people usually use and apply (I totally understand that this depends on the data/business/ business logic) but I\u2019m here trying to understand what are we missing and why i find it useless here.", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data transformation; what does it really mean?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1941wzt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704980310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;we\u2019re currently working on our data, and we just entered the the phase where we\u2019re transforming our data using dbt. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to watch closely what my team (1 person) is doing and tbh i didn\u2019t notice any changes!&lt;/p&gt;\n\n&lt;p&gt;I mean, I find it exactly replicating the data from the data source. that\u2019s it. I can\u2019t see the added value. &lt;/p&gt;\n\n&lt;p&gt;We only re-group data into facts and dimensions, remove duplicates and rename the columns\u2026 I thought this phase will hold A LOT more. So, it\u2019s clear that we didn\u2019t understand how to use it properly. &lt;/p&gt;\n\n&lt;p&gt;as an example, hubspot is one of our data sources and I found the transformed data not adding any value.. and we only have 7 tables from this source (?) leads, deals, quotations and contacts.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d appreciate if you can give examples of data transformation the people usually use and apply (I totally understand that this depends on the data/business/ business logic) but I\u2019m here trying to understand what are we missing and why i find it useless here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1941wzt", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1941wzt/data_transformation_what_does_it_really_mean/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1941wzt/data_transformation_what_does_it_really_mean/", "subreddit_subscribers": 152076, "created_utc": 1704980310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, thank you for reading this post.\n\nI'm currently working as a Data Engineer, primarily in ETL, with 1.8 years of experience across 3 projects using Azure Data Factory (ADF). I'm proficient in ADF, have intermediate SQL skills, and basic knowledge of Python. I'm contemplating a job switch and facing some uncertainties. Here are my main concerns:\n\n1. Choosing between Snowflake and Databricks, leaning towards Snowflake due to my strong SQL skills.\n\n2. Considering online master courses (e.g., Trendy Tech DE Master Program) for a structured learning approach and to stay motivated.\n\n3. Seeking advice on additional areas to focus on.\n\n4. Unsure if learning Python with DSA is essential and whether online or offline courses are preferable. PS - I don't like to code and also want to be in DE field but just going with the demand.\n\nYour insights would greatly help in easing my confusion and career pressure.\n\n", "author_fullname": "t2_i159isc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Serious Help/Suggestions for my Career.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_194svgx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705059130.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705058877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, thank you for reading this post.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a Data Engineer, primarily in ETL, with 1.8 years of experience across 3 projects using Azure Data Factory (ADF). I&amp;#39;m proficient in ADF, have intermediate SQL skills, and basic knowledge of Python. I&amp;#39;m contemplating a job switch and facing some uncertainties. Here are my main concerns:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Choosing between Snowflake and Databricks, leaning towards Snowflake due to my strong SQL skills.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Considering online master courses (e.g., Trendy Tech DE Master Program) for a structured learning approach and to stay motivated.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Seeking advice on additional areas to focus on.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Unsure if learning Python with DSA is essential and whether online or offline courses are preferable. PS - I don&amp;#39;t like to code and also want to be in DE field but just going with the demand.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your insights would greatly help in easing my confusion and career pressure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "194svgx", "is_robot_indexable": true, "report_reasons": null, "author": "Own_Zookeepergame256", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194svgx/need_serious_helpsuggestions_for_my_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194svgx/need_serious_helpsuggestions_for_my_career/", "subreddit_subscribers": 152076, "created_utc": 1705058877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nReaching out regarding specifics of how ELT is typically implemented when the data source is out of your control - a 3rd party RESTful API.\n\nTypically I use Postgres for ETL. However, due to needing to store raw JSON data from an API, would ELT warrant a NoSQL database like MongoDB?\n\nHow do you handle defining your schema? Do you just not define it, configure your application to notify you in case of error, and manually patch in any data structure changes introduced by the API? Or rather, do you worry about forward compatibility and make sure failure is less likely occur? \n\nIn the case of forward compatibility, how do you implement the it? I\u2019m only aware of Protobuf and I think that\u2019s just for use from the application side of things\u2026 where would the forward compatibility implementation fit in? Is it logic decisions made by the DBA during schema design, or is it handled prior to load by the ELT pipeline (ignoring new data fields)?\n\nLastly, what comes next\u2026 do you typically setup an ETL to load your ELT results into a warehouse? Or rather, is the *T* in ELT where you run your analytical queries?\n\nCurious what your answers will be. Thanks for any insights as I become more familiar with this approach.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build ELT pipelines in contrast to ETL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194hqq5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705020460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Reaching out regarding specifics of how ELT is typically implemented when the data source is out of your control - a 3rd party RESTful API.&lt;/p&gt;\n\n&lt;p&gt;Typically I use Postgres for ETL. However, due to needing to store raw JSON data from an API, would ELT warrant a NoSQL database like MongoDB?&lt;/p&gt;\n\n&lt;p&gt;How do you handle defining your schema? Do you just not define it, configure your application to notify you in case of error, and manually patch in any data structure changes introduced by the API? Or rather, do you worry about forward compatibility and make sure failure is less likely occur? &lt;/p&gt;\n\n&lt;p&gt;In the case of forward compatibility, how do you implement the it? I\u2019m only aware of Protobuf and I think that\u2019s just for use from the application side of things\u2026 where would the forward compatibility implementation fit in? Is it logic decisions made by the DBA during schema design, or is it handled prior to load by the ELT pipeline (ignoring new data fields)?&lt;/p&gt;\n\n&lt;p&gt;Lastly, what comes next\u2026 do you typically setup an ETL to load your ELT results into a warehouse? Or rather, is the &lt;em&gt;T&lt;/em&gt; in ELT where you run your analytical queries?&lt;/p&gt;\n\n&lt;p&gt;Curious what your answers will be. Thanks for any insights as I become more familiar with this approach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194hqq5", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194hqq5/how_to_build_elt_pipelines_in_contrast_to_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194hqq5/how_to_build_elt_pipelines_in_contrast_to_etl/", "subreddit_subscribers": 152076, "created_utc": 1705020460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are folks using to ingest large tabular files from Java into Parquet and friends?\n\nThe data is ultimately going to be reprocessed/joined with other tables and queried through an engine like Trino.\n\nToday a dataset will come in as various tabular formats, our users clean and map it using the Java backend, and it's stored in PostgreSQL. I love postgres, but we're bumping up against size and cost limits for some of the larger datasets; each dataset gets its own postgres instance while it's actively being used. I'd like to try moving away from it and toward the Iceberg ecosystem with object storage and a caching layer.\n\nOnce the data is already in object storage, or in a relational database, there's lots of ways to convert between formats using Trino or Spark, and tons of benchmarks and guides. But what's the best way to get it in there in the first place? How is big data formed?\n\nI've used ParquetWriter and Avro GenericData.Record a bit in the past. It's quite low-level. I'd like to have a bit of control over how the Parquet files are sorted and partitioned, either during the ingestion process or with some post-processing. I'll bet you can do anything with ParquetWriter and the Iceberg library, but getting it right, so the sorting/partitioning I do in the app, matches what I put in the metadata, would be hard, and the kind of thing I'd normally want a DBMS to handle.\n\nI was wondering about bulk loading into Trino via JDBC. I haven't been able to find performance numbers or guidance on whether this is a sane approach. I'm open to almost anything: using ParquetWriter directly, or DuckDB, or a JDBC connection to Trino or StarRocks, whatever makes sense.", "author_fullname": "t2_4m8rzb2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting to Parquet/Iceberg/object storage from Java", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1941ulb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704980107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are folks using to ingest large tabular files from Java into Parquet and friends?&lt;/p&gt;\n\n&lt;p&gt;The data is ultimately going to be reprocessed/joined with other tables and queried through an engine like Trino.&lt;/p&gt;\n\n&lt;p&gt;Today a dataset will come in as various tabular formats, our users clean and map it using the Java backend, and it&amp;#39;s stored in PostgreSQL. I love postgres, but we&amp;#39;re bumping up against size and cost limits for some of the larger datasets; each dataset gets its own postgres instance while it&amp;#39;s actively being used. I&amp;#39;d like to try moving away from it and toward the Iceberg ecosystem with object storage and a caching layer.&lt;/p&gt;\n\n&lt;p&gt;Once the data is already in object storage, or in a relational database, there&amp;#39;s lots of ways to convert between formats using Trino or Spark, and tons of benchmarks and guides. But what&amp;#39;s the best way to get it in there in the first place? How is big data formed?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used ParquetWriter and Avro GenericData.Record a bit in the past. It&amp;#39;s quite low-level. I&amp;#39;d like to have a bit of control over how the Parquet files are sorted and partitioned, either during the ingestion process or with some post-processing. I&amp;#39;ll bet you can do anything with ParquetWriter and the Iceberg library, but getting it right, so the sorting/partitioning I do in the app, matches what I put in the metadata, would be hard, and the kind of thing I&amp;#39;d normally want a DBMS to handle.&lt;/p&gt;\n\n&lt;p&gt;I was wondering about bulk loading into Trino via JDBC. I haven&amp;#39;t been able to find performance numbers or guidance on whether this is a sane approach. I&amp;#39;m open to almost anything: using ParquetWriter directly, or DuckDB, or a JDBC connection to Trino or StarRocks, whatever makes sense.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1941ulb", "is_robot_indexable": true, "report_reasons": null, "author": "t0astix", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1941ulb/ingesting_to_parqueticebergobject_storage_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1941ulb/ingesting_to_parqueticebergobject_storage_from/", "subreddit_subscribers": 152076, "created_utc": 1704980107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got an offer from a consulting company as Expert Level Support - Level 3 (There's no Level 4). I originally applied for Big Data Engineer, which they changed later during my interview process. My team manager uses DevOps Manager on his LinkedIn.\n\nI read that some people have tried to negotiate their titles during the job offer stage. Is it a good idea to negotiate it to Staff Data Engineer / Principal Data Engineer or even DevOps Engineer? Which title aligns better with expectations in the industry?\n\nThe thing is, I'm not sure if I would apply to another DE role in the future or try DevOps. Perhaps the vagueness of the current title could work in my favor if I ever want to explore other opportunities, perhaps not. Are there significantly more remote opportunities for DE over DevOps? That could be a factor.", "author_fullname": "t2_5qu7qetq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Negotiating job title - Staff Data Engineer or Expert Level Support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19412ic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704977724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got an offer from a consulting company as Expert Level Support - Level 3 (There&amp;#39;s no Level 4). I originally applied for Big Data Engineer, which they changed later during my interview process. My team manager uses DevOps Manager on his LinkedIn.&lt;/p&gt;\n\n&lt;p&gt;I read that some people have tried to negotiate their titles during the job offer stage. Is it a good idea to negotiate it to Staff Data Engineer / Principal Data Engineer or even DevOps Engineer? Which title aligns better with expectations in the industry?&lt;/p&gt;\n\n&lt;p&gt;The thing is, I&amp;#39;m not sure if I would apply to another DE role in the future or try DevOps. Perhaps the vagueness of the current title could work in my favor if I ever want to explore other opportunities, perhaps not. Are there significantly more remote opportunities for DE over DevOps? That could be a factor.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19412ic", "is_robot_indexable": true, "report_reasons": null, "author": "aguhon", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19412ic/negotiating_job_title_staff_data_engineer_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19412ic/negotiating_job_title_staff_data_engineer_or/", "subreddit_subscribers": 152076, "created_utc": 1704977724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While executing dbt run-operation generate_model_yaml it generates logs but I cannot find yml code in it.\n\nI m using dbt cloud", "author_fullname": "t2_sa16pkrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt &amp; codegen", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_194solh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705058160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While executing dbt run-operation generate_model_yaml it generates logs but I cannot find yml code in it.&lt;/p&gt;\n\n&lt;p&gt;I m using dbt cloud&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "194solh", "is_robot_indexable": true, "report_reasons": null, "author": "misaaaa18", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194solh/dbt_codegen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194solh/dbt_codegen/", "subreddit_subscribers": 152076, "created_utc": 1705058160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lk4nwwq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional Certificate: Google IT Automation with Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_194plfy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b4Xqh2-Ti__qpf-q_zGdwymgcsnoZBLBSoLzEct9AyM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705045616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pythoncoursesonline.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pythoncoursesonline.com/certificate-google-it-automation/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uQd8KYY0Bo3bPsC6cbIMEEF3K7FT7jqoetoVgsR9jvU.jpg?auto=webp&amp;s=220a526f52fa1ae2251d787698862a7507a04212", "width": 1024, "height": 536}, "resolutions": [{"url": "https://external-preview.redd.it/uQd8KYY0Bo3bPsC6cbIMEEF3K7FT7jqoetoVgsR9jvU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2b3d0f2bfa72461e075faf7b001f3a4b0169650", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/uQd8KYY0Bo3bPsC6cbIMEEF3K7FT7jqoetoVgsR9jvU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=00227189b573b9b23e861eeaa20fd85938981171", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/uQd8KYY0Bo3bPsC6cbIMEEF3K7FT7jqoetoVgsR9jvU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5132d15477b82392fc84c86a87145fd46fdea98e", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/uQd8KYY0Bo3bPsC6cbIMEEF3K7FT7jqoetoVgsR9jvU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0e68936ad8cff98c13490f4570b768fd07258da6", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/uQd8KYY0Bo3bPsC6cbIMEEF3K7FT7jqoetoVgsR9jvU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=044048d4bf5adb64ed0f99710149b79e00b299db", "width": 960, "height": 502}], "variants": {}, "id": "xW05hKYwCApLcK-GZTpYHDDnsRDAJzfYH7skKaQInsU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194plfy", "is_robot_indexable": true, "report_reasons": null, "author": "iphone6plususer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194plfy/professional_certificate_google_it_automation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pythoncoursesonline.com/certificate-google-it-automation/", "subreddit_subscribers": 152076, "created_utc": 1705045616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One argument is that you may only want to explicitly update your date. `UPSERT` is ambiguous in that, before you send the query, you don\u2019t know what the resulting outcome will be. You know `if/else` the outcome, but that is still more ambiguous. One might say they want to make sure they\u2019re either updating the data or not.\n\nOn the other hand, `UPSERT` probably just does the same thing but more efficiently\u2026\n\nWhat\u2019s the right call? What\u2019s it depend on?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you UPSERT, or SELECT, check for differences and update explicitly where needed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_194lllx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705031750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One argument is that you may only want to explicitly update your date. &lt;code&gt;UPSERT&lt;/code&gt; is ambiguous in that, before you send the query, you don\u2019t know what the resulting outcome will be. You know &lt;code&gt;if/else&lt;/code&gt; the outcome, but that is still more ambiguous. One might say they want to make sure they\u2019re either updating the data or not.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, &lt;code&gt;UPSERT&lt;/code&gt; probably just does the same thing but more efficiently\u2026&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the right call? What\u2019s it depend on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "194lllx", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/194lllx/do_you_upsert_or_select_check_for_differences_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/194lllx/do_you_upsert_or_select_check_for_differences_and/", "subreddit_subscribers": 152076, "created_utc": 1705031750.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}