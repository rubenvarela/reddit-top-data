{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on multiple things at the same time and last week a PM added some tasks and was pushy about it but other priorities are taking place, all the sudden he emails me a python code and asked me just to schedule it. I don't know how to react to this situation, and the code he sent is flawless, I'm at the point that I feel I can easily get replaced. Wanted to vent out with fellow DEs. What would you do if you were in my position?", "author_fullname": "t2_jtekxc8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I be offended? Project manager send me a code from Chatgpt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vdch8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704045945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on multiple things at the same time and last week a PM added some tasks and was pushy about it but other priorities are taking place, all the sudden he emails me a python code and asked me just to schedule it. I don&amp;#39;t know how to react to this situation, and the code he sent is flawless, I&amp;#39;m at the point that I feel I can easily get replaced. Wanted to vent out with fellow DEs. What would you do if you were in my position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18vdch8", "is_robot_indexable": true, "report_reasons": null, "author": "Zack-s21", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vdch8/should_i_be_offended_project_manager_send_me_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vdch8/should_i_be_offended_project_manager_send_me_a/", "subreddit_subscribers": 149826, "created_utc": 1704045945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are you planning to learn this year? Are satisfied how the last year ended? What are some your personal goals for this year?   \n\n\nIf you have any ideas to follow any Udemy courses. Feel free to drop the link here. I am planning to do a couple more courses on Udemy. ", "author_fullname": "t2_auriunhuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Happy new year engineers and data enthusiasts!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vubnp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704105850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are you planning to learn this year? Are satisfied how the last year ended? What are some your personal goals for this year?   &lt;/p&gt;\n\n&lt;p&gt;If you have any ideas to follow any Udemy courses. Feel free to drop the link here. I am planning to do a couple more courses on Udemy. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18vubnp", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Rub-3984", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18vubnp/happy_new_year_engineers_and_data_enthusiasts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vubnp/happy_new_year_engineers_and_data_enthusiasts/", "subreddit_subscribers": 149826, "created_utc": 1704105850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s the best way so I can\u2019t practice writing my etl before pushing it to prod?", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you have an etl that is using python to extract data from an api and land it in s3 the write to Postgres - how do you manage local / dev / qa/ prod envs ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vsz8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704099917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the best way so I can\u2019t practice writing my etl before pushing it to prod?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vsz8v", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vsz8v/if_you_have_an_etl_that_is_using_python_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vsz8v/if_you_have_an_etl_that_is_using_python_to/", "subreddit_subscribers": 149826, "created_utc": 1704099917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a column named 'normalized-losses' in a csv file about cars, this column has 40 missing values, I thought about replacing them with the mean of the whole column but as I humbly know I can't do that unless the graph looks like a Bell-shape and there are no outliers or skewness, which appears to not be the case here unless I am observing it wrong, the x-axis is the values of the column and the y-axis is the frequency of those values. I would be glad to hear what would you guys recommend me to do in this situation. Thanks\u00a0in\u00a0advance\n\n&amp;#x200B;\n\nhttps://preview.redd.it/iq0ty9pyut9c1.png?width=710&amp;format=png&amp;auto=webp&amp;s=f29e1af711003115fe90d00b85fec080c01eb271\n\nhttps://preview.redd.it/ignyqkpyut9c1.png?width=1037&amp;format=png&amp;auto=webp&amp;s=51a2858f63d99edbe72dbd030f582f18a87197c7", "author_fullname": "t2_l8jdxq43u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I replace NaN values?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"iq0ty9pyut9c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/iq0ty9pyut9c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a887e9971fc7b14d28f050f5c0d329e25f45298"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/iq0ty9pyut9c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb77d43ddb02b0135b8f144e65388dfd3693ac64"}, {"y": 234, "x": 320, "u": "https://preview.redd.it/iq0ty9pyut9c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=45e232946f26905a39f4f91d257da924e041bf09"}, {"y": 469, "x": 640, "u": "https://preview.redd.it/iq0ty9pyut9c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=94643b189a39f45d36136d2beac12d439d258dbe"}], "s": {"y": 521, "x": 710, "u": "https://preview.redd.it/iq0ty9pyut9c1.png?width=710&amp;format=png&amp;auto=webp&amp;s=f29e1af711003115fe90d00b85fec080c01eb271"}, "id": "iq0ty9pyut9c1"}, "ignyqkpyut9c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 21, "x": 108, "u": "https://preview.redd.it/ignyqkpyut9c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6bb5bb5c96a0de412dbd8364d8c32f5521ef15ae"}, {"y": 43, "x": 216, "u": "https://preview.redd.it/ignyqkpyut9c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fa0748d850ae605bfd97fd87aacc2905f83323d3"}, {"y": 64, "x": 320, "u": "https://preview.redd.it/ignyqkpyut9c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a55a3a0bd94684e1866b1df3c6b11251d90f0791"}, {"y": 128, "x": 640, "u": "https://preview.redd.it/ignyqkpyut9c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=29203c9a3dd6d22d202f19a96c50ac873530cd83"}, {"y": 192, "x": 960, "u": "https://preview.redd.it/ignyqkpyut9c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fbfe9f76067ad771889ec9a781f87ca9698a7a31"}], "s": {"y": 208, "x": 1037, "u": "https://preview.redd.it/ignyqkpyut9c1.png?width=1037&amp;format=png&amp;auto=webp&amp;s=51a2858f63d99edbe72dbd030f582f18a87197c7"}, "id": "ignyqkpyut9c1"}}, "name": "t3_18vwegq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HwLnBitzCqeVUmXoyOYcL8tX8A-8CGpWfWzk7ZjN5_I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704114404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a column named &amp;#39;normalized-losses&amp;#39; in a csv file about cars, this column has 40 missing values, I thought about replacing them with the mean of the whole column but as I humbly know I can&amp;#39;t do that unless the graph looks like a Bell-shape and there are no outliers or skewness, which appears to not be the case here unless I am observing it wrong, the x-axis is the values of the column and the y-axis is the frequency of those values. I would be glad to hear what would you guys recommend me to do in this situation. Thanks\u00a0in\u00a0advance&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/iq0ty9pyut9c1.png?width=710&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f29e1af711003115fe90d00b85fec080c01eb271\"&gt;https://preview.redd.it/iq0ty9pyut9c1.png?width=710&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f29e1af711003115fe90d00b85fec080c01eb271&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ignyqkpyut9c1.png?width=1037&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=51a2858f63d99edbe72dbd030f582f18a87197c7\"&gt;https://preview.redd.it/ignyqkpyut9c1.png?width=1037&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=51a2858f63d99edbe72dbd030f582f18a87197c7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18vwegq", "is_robot_indexable": true, "report_reasons": null, "author": "Darktrader21", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vwegq/how_should_i_replace_nan_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vwegq/how_should_i_replace_nan_values/", "subreddit_subscribers": 149826, "created_utc": 1704114404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been reading a ton of books about modern data management, data mesh, is modeling/dwh dead, etc., lately. Now I'd like to hear some real-life examples of how different companies/ppl architect their data warehouses/lakes/swamps/meshes and what things work or don't and why. E.g.:\n\n**Centralized vs decentralized** \\- do you have one centralized data engineering team that handles everything for the whole company or do you have a mini-team per department? What are some upsides/downsides of your setup?\n\n**Streaming/real-time** \\- Do you do batch vs stream processing or both? Is there a push for real-time analytics in your company and are you able to deliver?\n\n**Data modeling** \\- How do you approach data modeling, have you tried creating and maintaining one huge or several smaller \"generic\" data models or do you have a data model per domain or even a data model per report? Do you use star schema, snowflake or data vault or one bit table?\n\n**Self-service** \\- what do you do to maximize the ability of your consumers to self-serve?\n\nAlternatively, if anybody knows of more public docs like the [Gitlabs handbook](https://handbook.gitlab.com/handbook/business-technology/data-team/platform/edw/) let me know.\n\nThanks!", "author_fullname": "t2_gx2hs6l34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enterprise data solutions - how does your look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vyykn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704122901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been reading a ton of books about modern data management, data mesh, is modeling/dwh dead, etc., lately. Now I&amp;#39;d like to hear some real-life examples of how different companies/ppl architect their data warehouses/lakes/swamps/meshes and what things work or don&amp;#39;t and why. E.g.:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Centralized vs decentralized&lt;/strong&gt; - do you have one centralized data engineering team that handles everything for the whole company or do you have a mini-team per department? What are some upsides/downsides of your setup?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Streaming/real-time&lt;/strong&gt; - Do you do batch vs stream processing or both? Is there a push for real-time analytics in your company and are you able to deliver?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data modeling&lt;/strong&gt; - How do you approach data modeling, have you tried creating and maintaining one huge or several smaller &amp;quot;generic&amp;quot; data models or do you have a data model per domain or even a data model per report? Do you use star schema, snowflake or data vault or one bit table?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Self-service&lt;/strong&gt; - what do you do to maximize the ability of your consumers to self-serve?&lt;/p&gt;\n\n&lt;p&gt;Alternatively, if anybody knows of more public docs like the &lt;a href=\"https://handbook.gitlab.com/handbook/business-technology/data-team/platform/edw/\"&gt;Gitlabs handbook&lt;/a&gt; let me know.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UglaOVILJ_CxNzNc0sHwmfkzd_dL9QDi-Gxn3VyjC1o.jpg?auto=webp&amp;s=af544e78828882798d7fe4d1c42454d6bd21dc22", "width": 875, "height": 612}, "resolutions": [{"url": "https://external-preview.redd.it/UglaOVILJ_CxNzNc0sHwmfkzd_dL9QDi-Gxn3VyjC1o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=828e0ee040e1722af1bf0dbb719d2b846ec766b4", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/UglaOVILJ_CxNzNc0sHwmfkzd_dL9QDi-Gxn3VyjC1o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f99184941ef4a831059c95c0f3bfb24a7de84249", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/UglaOVILJ_CxNzNc0sHwmfkzd_dL9QDi-Gxn3VyjC1o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b5e1d3118a33c25bab44e78f2a95e971cbca6e5", "width": 320, "height": 223}, {"url": "https://external-preview.redd.it/UglaOVILJ_CxNzNc0sHwmfkzd_dL9QDi-Gxn3VyjC1o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2a04b3ad42aa3e307db53deca2024a610d384848", "width": 640, "height": 447}], "variants": {}, "id": "v9bukcUTEDutaePTQidDeR95NYA8AyYs-tp2j6EyUkc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18vyykn", "is_robot_indexable": true, "report_reasons": null, "author": "InsightInk", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vyykn/enterprise_data_solutions_how_does_your_look_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vyykn/enterprise_data_solutions_how_does_your_look_like/", "subreddit_subscribers": 149826, "created_utc": 1704122901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nI'm on the lookout for some cool data engineering courses to level up my skills and hopefully snag a great job. Any tips or suggestions? Thanks a bunch!", "author_fullname": "t2_v9jjyjtc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for the best data engineering course from basic to advanced", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vws8a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704115784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on the lookout for some cool data engineering courses to level up my skills and hopefully snag a great job. Any tips or suggestions? Thanks a bunch!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vws8a", "is_robot_indexable": true, "report_reasons": null, "author": "brainvale", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vws8a/looking_for_the_best_data_engineering_course_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vws8a/looking_for_the_best_data_engineering_course_from/", "subreddit_subscribers": 149826, "created_utc": 1704115784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. Just wanted some suggestions on the approach of how to do a data reconciliation between two tables.\n\nConsider two tables as A and B. The table A contains 300 million records and table B also contains close to 300 million records. Now I want to do a data reconciliation in such a manner that it would find an exact match, a partial match and a no match from table A to B and vice versa. \n\nSince the data volume is so huge, I'm currently finding delta of A between yesterday vs today's record and then reconciling it with Table B (and vice versa). But I want to do a complete Reconciliation on a daily basis and for that I'm looking for a plan over here. I've a buffer time of 8-9 hours for completion of the job.\n\nAny suggestions would be appreciated!!\n\nUpdate: logic for exact match, partial match and no match.\n\nSo when it comes to comparison logic on high level, for an IP, if source, destination,port, and protocols matches exactly then that is an exact match. The logic of partial match is if any one of them does not matches keeping other fields matching then it's a partial match. And if none of them is matching then it's no match.\n", "author_fullname": "t2_pl5rcgmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Reconciliation in PySpark SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vr5ja", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704106042.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704092066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. Just wanted some suggestions on the approach of how to do a data reconciliation between two tables.&lt;/p&gt;\n\n&lt;p&gt;Consider two tables as A and B. The table A contains 300 million records and table B also contains close to 300 million records. Now I want to do a data reconciliation in such a manner that it would find an exact match, a partial match and a no match from table A to B and vice versa. &lt;/p&gt;\n\n&lt;p&gt;Since the data volume is so huge, I&amp;#39;m currently finding delta of A between yesterday vs today&amp;#39;s record and then reconciling it with Table B (and vice versa). But I want to do a complete Reconciliation on a daily basis and for that I&amp;#39;m looking for a plan over here. I&amp;#39;ve a buffer time of 8-9 hours for completion of the job.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be appreciated!!&lt;/p&gt;\n\n&lt;p&gt;Update: logic for exact match, partial match and no match.&lt;/p&gt;\n\n&lt;p&gt;So when it comes to comparison logic on high level, for an IP, if source, destination,port, and protocols matches exactly then that is an exact match. The logic of partial match is if any one of them does not matches keeping other fields matching then it&amp;#39;s a partial match. And if none of them is matching then it&amp;#39;s no match.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18vr5ja", "is_robot_indexable": true, "report_reasons": null, "author": "AdQueasy6234", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vr5ja/data_reconciliation_in_pyspark_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vr5ja/data_reconciliation_in_pyspark_sql/", "subreddit_subscribers": 149826, "created_utc": 1704092066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Happy new year! I, a grad student, am planning on working on a data analytics project with my friend who is living in a different state. In this project we are trying to simulate a data lifecycle. We will use a big 'data' set from Kaggle (please recommend any better sources). I (acting as DE and DBA) will create a data engineering pipeline to perform ETL tasks using Python and load this data into a SQL based software that can be remotely accessed by both of us where I will act as a DB admin. My friend(acting as DA) will have access to this database and use it to analyze the data and create reports. This project is very basic and completely theoretical in terms of how the data is connected from one point to the next.\nMy questions are,\nIs there a SQL software that permits this? Please suggest some names that are available for free or are open source.\nIs there a way to connect the flow of data? (I'm considering to completely use SQL to perform the ETL tasks)\nIs there anything we can do to improve the project?", "author_fullname": "t2_hqiwxblm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DB solutions for remote student project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vkqlm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704068088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happy new year! I, a grad student, am planning on working on a data analytics project with my friend who is living in a different state. In this project we are trying to simulate a data lifecycle. We will use a big &amp;#39;data&amp;#39; set from Kaggle (please recommend any better sources). I (acting as DE and DBA) will create a data engineering pipeline to perform ETL tasks using Python and load this data into a SQL based software that can be remotely accessed by both of us where I will act as a DB admin. My friend(acting as DA) will have access to this database and use it to analyze the data and create reports. This project is very basic and completely theoretical in terms of how the data is connected from one point to the next.\nMy questions are,\nIs there a SQL software that permits this? Please suggest some names that are available for free or are open source.\nIs there a way to connect the flow of data? (I&amp;#39;m considering to completely use SQL to perform the ETL tasks)\nIs there anything we can do to improve the project?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vkqlm", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Reason59", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vkqlm/db_solutions_for_remote_student_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vkqlm/db_solutions_for_remote_student_project/", "subreddit_subscribers": 149826, "created_utc": 1704068088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone using Unity Catalog extensively at their org? Looking for honest reviews on performance, ease of use, and whether the value add is worth having the additional overhead of yet another tool.\n\nI\u2019ve been skeptical of some goals Databricks has claimed in the past to be open and compatible with a variety of open source technologies. However, with the announcement of [Unity Lakehouse Federation](https://www.databricks.com/blog/introducing-lakehouse-federation-capabilities-unity-catalog) and the [Open Apache Hive Metastore API](https://www.databricks.com/blog/extending-databricks-unity-catalog-open-apache-hive-metastore-api), I\u2019m starting to see that they are pretty serious about this. \n\nWe\u2019ve got a few Postgres databases that have been used as both ODS and historically as data warehouse but also have a BigQuery instance where we\u2019ve put larger datasets, for reference. Direct query performance of Postgres has been good but we usually find BigQuery lacking. Also have yet to work in Databricks at all and honestly not a huge fan of their transformation framework.", "author_fullname": "t2_ahqse5d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unity Catalog Opinions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vg9oj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704054233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone using Unity Catalog extensively at their org? Looking for honest reviews on performance, ease of use, and whether the value add is worth having the additional overhead of yet another tool.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been skeptical of some goals Databricks has claimed in the past to be open and compatible with a variety of open source technologies. However, with the announcement of &lt;a href=\"https://www.databricks.com/blog/introducing-lakehouse-federation-capabilities-unity-catalog\"&gt;Unity Lakehouse Federation&lt;/a&gt; and the &lt;a href=\"https://www.databricks.com/blog/extending-databricks-unity-catalog-open-apache-hive-metastore-api\"&gt;Open Apache Hive Metastore API&lt;/a&gt;, I\u2019m starting to see that they are pretty serious about this. &lt;/p&gt;\n\n&lt;p&gt;We\u2019ve got a few Postgres databases that have been used as both ODS and historically as data warehouse but also have a BigQuery instance where we\u2019ve put larger datasets, for reference. Direct query performance of Postgres has been good but we usually find BigQuery lacking. Also have yet to work in Databricks at all and honestly not a huge fan of their transformation framework.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LYuZWUPaC0Y5y846LBxlaGedfzW9ylpT8kLzA05oH88.jpg?auto=webp&amp;s=96ccb9c5fa71e5862cea53afeaeafa5d1ebba14f", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/LYuZWUPaC0Y5y846LBxlaGedfzW9ylpT8kLzA05oH88.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9dccb735338e1f279dbfb21ea3128600f216b866", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LYuZWUPaC0Y5y846LBxlaGedfzW9ylpT8kLzA05oH88.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=079a23daa31cf6fe382b3871c9e1e3f4d0f9bd1e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LYuZWUPaC0Y5y846LBxlaGedfzW9ylpT8kLzA05oH88.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=543e8436e65ba5aaf5ef93a623d721ae2ef4dea6", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/LYuZWUPaC0Y5y846LBxlaGedfzW9ylpT8kLzA05oH88.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2103d4e7d59721b2eece5daddcbd945c296f8b12", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/LYuZWUPaC0Y5y846LBxlaGedfzW9ylpT8kLzA05oH88.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b7f9a8fd13fa11c74badfdf02145d9773c6ae300", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/LYuZWUPaC0Y5y846LBxlaGedfzW9ylpT8kLzA05oH88.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d9e66a6561f2be08cbb3ddf1ab97f5e6ce6bb913", "width": 1080, "height": 565}], "variants": {}, "id": "8ooGHNa4aTZTS_509BAc4_8M-bm112QUmcYDDgtCxXA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18vg9oj", "is_robot_indexable": true, "report_reasons": null, "author": "Express-Comb8675", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vg9oj/unity_catalog_opinions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vg9oj/unity_catalog_opinions/", "subreddit_subscribers": 149826, "created_utc": 1704054233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Jan 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c", "t3_17lfedu", "t3_188grkl", "t3_18w0y5n"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1704128435.952, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18w0y5n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1704128435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6vEzzTTcLuxs_WhXm15FGX9Q8lSScnSbFNjm5w1mP58.jpg?auto=webp&amp;s=a3d9e8461a9baf9bb27e06e1d6b27e2c85baf1e8", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/6vEzzTTcLuxs_WhXm15FGX9Q8lSScnSbFNjm5w1mP58.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e72878bdb12c2e2103d5e7121ca806e468e31f0f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6vEzzTTcLuxs_WhXm15FGX9Q8lSScnSbFNjm5w1mP58.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=db6ed5960f73ec86eaca80ba9b350806442c0294", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6vEzzTTcLuxs_WhXm15FGX9Q8lSScnSbFNjm5w1mP58.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=444f5f54270aea66f490b2eebc963362d9d0917f", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/6vEzzTTcLuxs_WhXm15FGX9Q8lSScnSbFNjm5w1mP58.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce8c3041b9fe9dad9d8da214b8bdfa280adf7b73", "width": 640, "height": 333}], "variants": {}, "id": "rRXk_aE_pxsAg4FEkSKNuvScY3QSkzt6dMIdXDYr2-U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18w0y5n", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18w0y5n/monthly_general_discussion_jan_2024/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/18w0y5n/monthly_general_discussion_jan_2024/", "subreddit_subscribers": 149826, "created_utc": 1704128435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, does anyone have any good resources for icon packs for data engineering including brand logos etc? Looking to build out some architecture packs", "author_fullname": "t2_8fb47pbl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Data Engineering Icon Packs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vw89a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704113805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, does anyone have any good resources for icon packs for data engineering including brand logos etc? Looking to build out some architecture packs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vw89a", "is_robot_indexable": true, "report_reasons": null, "author": "ForMrKite", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vw89a/looking_for_data_engineering_icon_packs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vw89a/looking_for_data_engineering_icon_packs/", "subreddit_subscribers": 149826, "created_utc": 1704113805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Cleaning up data with sed\n\nSo at work. I have this giant pipe delimited file from a dos server and ofncourse I'm dealing with carriage returns line feed he'll. Without giving away too much info, a few fields have essay sized note columns and I need to basically erase those. But there were multiple carriage return line feeds that make it hard to parse. \n\nEnter Sed.\n\nSed combined with tr have been amazing but still having issues.ive used from Unix and unixtodos to get rid of these line breaks but then I'm stuck with the same issue, just parsing \\n instead of \\r\\n.\n\nMy colleagues are lacking in advice bc they say shkt like \"oh just load it in pandas \" \u2620\ufe0f like you can see my issue here. Also the spreadsheers a few gigabytes so vash scrupting is much more efficient for parsing than an interpreter language.\n\nIt's proprietary data so I can't share examples other than vague recreations but it looks like this rn:\n\nCol1|col2|...|bad_col|bad_col2|...|end_col\\n\n\nAaaa|bbb|...|\\n\n\nBla bla blabla\\n\n\n\\n\n\nMore bad data..\\n\n\n|Another essay data...\\n\n\n\\n\n\nmore data...\\n\n\n|more bad data...\\n\n\n\\n\n\nMore worthless text data\\n\n\n|good|from|...|here|row should end.\\n\n\nNew|row|starts\\n\n\nAnd now it beings...\\n\n\n|all over again.\\n\n\n...\\n\n\n|and so on...\n\n\n\nAll pipe delimiters are at the front of each line that would be it's own field i git that far. I need.to find a way to erase all.the junk between a line that starts with a pipe until the next line that starts with a pipe\nI've been hitting the sed faq and Messing with conditionals but in driving myself nuts. Any advice or wisdom on using sed or tr or any other packages to parse spreadsheets delimited ny pipes, with no quotations, where some columns have multiple paragraphs? \n\nI'll upload my sed script I'm working with but I don't wanna sign into my reddit on my company owned lapt9p lol", "author_fullname": "t2_3vm76xzm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cleaning data with sed and tr", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vkg7o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704067152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cleaning up data with sed&lt;/p&gt;\n\n&lt;p&gt;So at work. I have this giant pipe delimited file from a dos server and ofncourse I&amp;#39;m dealing with carriage returns line feed he&amp;#39;ll. Without giving away too much info, a few fields have essay sized note columns and I need to basically erase those. But there were multiple carriage return line feeds that make it hard to parse. &lt;/p&gt;\n\n&lt;p&gt;Enter Sed.&lt;/p&gt;\n\n&lt;p&gt;Sed combined with tr have been amazing but still having issues.ive used from Unix and unixtodos to get rid of these line breaks but then I&amp;#39;m stuck with the same issue, just parsing \\n instead of \\r\\n.&lt;/p&gt;\n\n&lt;p&gt;My colleagues are lacking in advice bc they say shkt like &amp;quot;oh just load it in pandas &amp;quot; \u2620\ufe0f like you can see my issue here. Also the spreadsheers a few gigabytes so vash scrupting is much more efficient for parsing than an interpreter language.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s proprietary data so I can&amp;#39;t share examples other than vague recreations but it looks like this rn:&lt;/p&gt;\n\n&lt;p&gt;Col1|col2|...|bad_col|bad_col2|...|end_col\\n&lt;/p&gt;\n\n&lt;p&gt;Aaaa|bbb|...|\\n&lt;/p&gt;\n\n&lt;p&gt;Bla bla blabla\\n&lt;/p&gt;\n\n&lt;p&gt;\\n&lt;/p&gt;\n\n&lt;p&gt;More bad data..\\n&lt;/p&gt;\n\n&lt;p&gt;|Another essay data...\\n&lt;/p&gt;\n\n&lt;p&gt;\\n&lt;/p&gt;\n\n&lt;p&gt;more data...\\n&lt;/p&gt;\n\n&lt;p&gt;|more bad data...\\n&lt;/p&gt;\n\n&lt;p&gt;\\n&lt;/p&gt;\n\n&lt;p&gt;More worthless text data\\n&lt;/p&gt;\n\n&lt;p&gt;|good|from|...|here|row should end.\\n&lt;/p&gt;\n\n&lt;p&gt;New|row|starts\\n&lt;/p&gt;\n\n&lt;p&gt;And now it beings...\\n&lt;/p&gt;\n\n&lt;p&gt;|all over again.\\n&lt;/p&gt;\n\n&lt;p&gt;...\\n&lt;/p&gt;\n\n&lt;p&gt;|and so on...&lt;/p&gt;\n\n&lt;p&gt;All pipe delimiters are at the front of each line that would be it&amp;#39;s own field i git that far. I need.to find a way to erase all.the junk between a line that starts with a pipe until the next line that starts with a pipe\nI&amp;#39;ve been hitting the sed faq and Messing with conditionals but in driving myself nuts. Any advice or wisdom on using sed or tr or any other packages to parse spreadsheets delimited ny pipes, with no quotations, where some columns have multiple paragraphs? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll upload my sed script I&amp;#39;m working with but I don&amp;#39;t wanna sign into my reddit on my company owned lapt9p lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vkg7o", "is_robot_indexable": true, "report_reasons": null, "author": "JucheCouture69420", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vkg7o/cleaning_data_with_sed_and_tr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vkg7o/cleaning_data_with_sed_and_tr/", "subreddit_subscribers": 149826, "created_utc": 1704067152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!  \nI released a new open source library and would like to get some feedback from r/dataengineering!\n\nThe library is a modern UI for apache spark. It can show you in which step your query is currently running, which steps is the longest and alert on potential performance issues\n\nLink to the github page: [https://github.com/dataflint/spark](https://github.com/dataflint/spark)\n\n[DataFlint Demo](https://reddit.com/link/18w1ufk/video/td74k6056v9c1/player)", "author_fullname": "t2_i2b8380mi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataFlint, a new open source Performance Monitoring for Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "media_metadata": {"td74k6056v9c1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/18w1ufk/asset/td74k6056v9c1/DASHPlaylist.mpd?a=1706726300%2CNTFlNmJiMzQ5YTM4M2QyYzRjNTM3M2I4N2M5NTg2N2Q1OWFkNDZmYzNhMDg5YTRhYjIyNzVhYzAyYTdjNTU1Ng%3D%3D&amp;v=1&amp;f=sd", "x": 1280, "y": 648, "hlsUrl": "https://v.redd.it/link/18w1ufk/asset/td74k6056v9c1/HLSPlaylist.m3u8?a=1706726300%2COTU3NWU3MWI4NzJjN2JhNTQ2YTg1ZjQ2OWY1MWU5NjBmMmEyYTJjMzdkOTBmZWFmZDcwZDFhZDk0NDc5Zjk2Mw%3D%3D&amp;v=1&amp;f=sd", "id": "td74k6056v9c1", "isGif": false}}, "name": "t3_18w1ufk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4GtLoknj2YGr9NK8ORfJeOtwa1MJrjG74w63T95dxSU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1704130812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;br/&gt;\nI released a new open source library and would like to get some feedback from &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;The library is a modern UI for apache spark. It can show you in which step your query is currently running, which steps is the longest and alert on potential performance issues&lt;/p&gt;\n\n&lt;p&gt;Link to the github page: &lt;a href=\"https://github.com/dataflint/spark\"&gt;https://github.com/dataflint/spark&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/18w1ufk/video/td74k6056v9c1/player\"&gt;DataFlint Demo&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DnNyIXlcfEQFBiTT1yn2gMQWZ92ys-tjrPK5ULyiE_A.jpg?auto=webp&amp;s=be0e90451258a2a1ce63f90016308f0f15c99cc8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/DnNyIXlcfEQFBiTT1yn2gMQWZ92ys-tjrPK5ULyiE_A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d294196e9e00d6ee716ce16e37596f833b1efb4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/DnNyIXlcfEQFBiTT1yn2gMQWZ92ys-tjrPK5ULyiE_A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a38c54ff87953dc68f413ea4ab90e4715a91119b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/DnNyIXlcfEQFBiTT1yn2gMQWZ92ys-tjrPK5ULyiE_A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=274f4749ee094e46fbfe2e9f589fe79ed4db1e71", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/DnNyIXlcfEQFBiTT1yn2gMQWZ92ys-tjrPK5ULyiE_A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a33116b184654f9656cb450b1956fec287bff28", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/DnNyIXlcfEQFBiTT1yn2gMQWZ92ys-tjrPK5ULyiE_A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=656fc3465823807c018550fde06f998957335d1f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/DnNyIXlcfEQFBiTT1yn2gMQWZ92ys-tjrPK5ULyiE_A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=58c3b293e884cd329cee524426278e873cfbb63c", "width": 1080, "height": 540}], "variants": {}, "id": "hzPBYn3K6qtbd4X8ppKl43rauR-Q_QAujjbYrduf49k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18w1ufk", "is_robot_indexable": true, "report_reasons": null, "author": "menishmueli", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18w1ufk/dataflint_a_new_open_source_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18w1ufk/dataflint_a_new_open_source_performance/", "subreddit_subscribers": 149826, "created_utc": 1704130812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,   \nI've been doing a fairly small project for the client, where I was assured that each country consist of the same amount of columns with the same names and business context. We've ingested the data into one dataset and now I want to enrich it but found out, that the assumption was not true. What do I mean is:\n\nLets pretend we have few countries though lets take into consideration - GB and US and each have 20 columns. Most of those columns have the same meaning, but there are pairs which not, like:\n\nSB1 for US is Strength Evaluation\n\nSB2 for US is Power Evaluation\n\nwhile \n\nSB1 for GB is Power Evaluation\n\nSB2 for GB is Strength Evaluation  \n\n\nand its case in whole dataset that one country SB1 is Power SB2 strength, for another its reversed and so on. My silver layer looks like that\n\n  \n| ID | Market | CK  | SB1 | SB2 | SbX | ColX |\n|----|--------|-----|-----|-----|-----|------|\n| 1  | US     | 1US | 2   | 1   | 9   | 9    |\n| 2  | US     | 2US | 2   | 2   | 9   | 9    |\n| 3  | US     | 3US | 1   | 1   | 9   | 9    |\n| 1  | GB     | 1GB | 3   | 5   | 9   | 9    |\n| 2  | GB     | 2GB | 4   | 4   | 9   | 9    |\n| 3  | GB     | 3GB | 5   | 3   | 9   | 9    |\n\nWhat is expected output in that scenario I guess is (look at SB1 SB2 cols)\n\n| ID | Market | CK  | SB1 | SB2 | SbX | ColX |\n|----|--------|-----|-----|-----|-----|------|\n| 1  | US     | 1US | 2   | 1   | 9   | 9    |\n| 2  | US     | 2US | 2   | 2   | 9   | 9    |\n| 3  | US     | 3US | 1   | 1   | 9   | 9    |\n| 1  | GB     | 1GB | 5   | 3   | 9   | 9    |\n| 2  | GB     | 2GB | 4   | 4   | 9   | 9    |\n| 3  | GB     | 3GB | 3   | 5   | 9   | 9    |\n\nand I have to keep it in mind that its for multiple pairs and multiple countries across. Any protips, ideas how to handle that? I guess it can't be solved on ingestion level, so raw and curated zone is not the place to make it happen, the silver dataset has to be transformed and values filled accordingly", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to tackle inconsistency in schemas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vzsfe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704126689.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704125282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nI&amp;#39;ve been doing a fairly small project for the client, where I was assured that each country consist of the same amount of columns with the same names and business context. We&amp;#39;ve ingested the data into one dataset and now I want to enrich it but found out, that the assumption was not true. What do I mean is:&lt;/p&gt;\n\n&lt;p&gt;Lets pretend we have few countries though lets take into consideration - GB and US and each have 20 columns. Most of those columns have the same meaning, but there are pairs which not, like:&lt;/p&gt;\n\n&lt;p&gt;SB1 for US is Strength Evaluation&lt;/p&gt;\n\n&lt;p&gt;SB2 for US is Power Evaluation&lt;/p&gt;\n\n&lt;p&gt;while &lt;/p&gt;\n\n&lt;p&gt;SB1 for GB is Power Evaluation&lt;/p&gt;\n\n&lt;p&gt;SB2 for GB is Strength Evaluation  &lt;/p&gt;\n\n&lt;p&gt;and its case in whole dataset that one country SB1 is Power SB2 strength, for another its reversed and so on. My silver layer looks like that&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;ID&lt;/th&gt;\n&lt;th&gt;Market&lt;/th&gt;\n&lt;th&gt;CK&lt;/th&gt;\n&lt;th&gt;SB1&lt;/th&gt;\n&lt;th&gt;SB2&lt;/th&gt;\n&lt;th&gt;SbX&lt;/th&gt;\n&lt;th&gt;ColX&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;US&lt;/td&gt;\n&lt;td&gt;1US&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;US&lt;/td&gt;\n&lt;td&gt;2US&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;US&lt;/td&gt;\n&lt;td&gt;3US&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;GB&lt;/td&gt;\n&lt;td&gt;1GB&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;GB&lt;/td&gt;\n&lt;td&gt;2GB&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;GB&lt;/td&gt;\n&lt;td&gt;3GB&lt;/td&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;What is expected output in that scenario I guess is (look at SB1 SB2 cols)&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;ID&lt;/th&gt;\n&lt;th&gt;Market&lt;/th&gt;\n&lt;th&gt;CK&lt;/th&gt;\n&lt;th&gt;SB1&lt;/th&gt;\n&lt;th&gt;SB2&lt;/th&gt;\n&lt;th&gt;SbX&lt;/th&gt;\n&lt;th&gt;ColX&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;US&lt;/td&gt;\n&lt;td&gt;1US&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;US&lt;/td&gt;\n&lt;td&gt;2US&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;US&lt;/td&gt;\n&lt;td&gt;3US&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;GB&lt;/td&gt;\n&lt;td&gt;1GB&lt;/td&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;GB&lt;/td&gt;\n&lt;td&gt;2GB&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;GB&lt;/td&gt;\n&lt;td&gt;3GB&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;and I have to keep it in mind that its for multiple pairs and multiple countries across. Any protips, ideas how to handle that? I guess it can&amp;#39;t be solved on ingestion level, so raw and curated zone is not the place to make it happen, the silver dataset has to be transformed and values filled accordingly&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vzsfe", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vzsfe/how_to_tackle_inconsistency_in_schemas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vzsfe/how_to_tackle_inconsistency_in_schemas/", "subreddit_subscribers": 149826, "created_utc": 1704125282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3dyum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "50+ Incredible Big Data Statistics for 2024: Facts, Market Size &amp; Industry Growth", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_18vyu06", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vlUxDD9weyBDUs1V_r0_Cit73bUGmLUmn1G37-p24jI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704122512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bigdataanalyticsnews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bigdataanalyticsnews.com/big-data-statistics/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/t-Mw7SPnNyfNDd5wdkie00ZKooBWlaNe7f9kdoVl_GA.jpg?auto=webp&amp;s=e46f2536cf6003bdab10a463f0507baac3de8313", "width": 1000, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/t-Mw7SPnNyfNDd5wdkie00ZKooBWlaNe7f9kdoVl_GA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12a9e1a1ae12628529d03d0fe1a47dab780668de", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/t-Mw7SPnNyfNDd5wdkie00ZKooBWlaNe7f9kdoVl_GA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f4f605ab4f7873e7b8e2fc133da8a5997472342", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/t-Mw7SPnNyfNDd5wdkie00ZKooBWlaNe7f9kdoVl_GA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=848ede9c87c68a93f5e962ea8bf47fd67d26be4c", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/t-Mw7SPnNyfNDd5wdkie00ZKooBWlaNe7f9kdoVl_GA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a25dd76325ab2e4d6722c7bab79580326fd70b01", "width": 640, "height": 384}, {"url": "https://external-preview.redd.it/t-Mw7SPnNyfNDd5wdkie00ZKooBWlaNe7f9kdoVl_GA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2cbed5b59f02d466d889fa188e81f571c800a1bc", "width": 960, "height": 576}], "variants": {}, "id": "G7vw-wHW51NEHsU3rbN0_5-agzBurbGYMoMOLsl1mPY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18vyu06", "is_robot_indexable": true, "report_reasons": null, "author": "Veerans", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vyu06/50_incredible_big_data_statistics_for_2024_facts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bigdataanalyticsnews.com/big-data-statistics/", "subreddit_subscribers": 149826, "created_utc": 1704122512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A small blog post on open-source, data engineering, and blogging", "author_fullname": "t2_2bhtmk4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reflecting on the Year 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_18vyiap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0tw-pydEEaymWbeizXjFotyfm1_QaYPZFXz5YQz-rdM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704121534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ssmertin.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A small blog post on open-source, data engineering, and blogging&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ssmertin.com/articles/reflecting-on-year-2023/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d4tFgB2-s2sWsVt1q4Pal5x10s2EFEcIDpYjKzevOE4.jpg?auto=webp&amp;s=1a09e56e7641075040486f7189b54cb98076a572", "width": 3840, "height": 2158}, "resolutions": [{"url": "https://external-preview.redd.it/d4tFgB2-s2sWsVt1q4Pal5x10s2EFEcIDpYjKzevOE4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=33dfb55ddd030d2cb537108514aa51b2987ded35", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/d4tFgB2-s2sWsVt1q4Pal5x10s2EFEcIDpYjKzevOE4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd1fa87258d8d9eae7ee6f264faa9d4d2f1dbd13", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/d4tFgB2-s2sWsVt1q4Pal5x10s2EFEcIDpYjKzevOE4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e4140802654b52f5edbd27deb8fd691cd45aa187", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/d4tFgB2-s2sWsVt1q4Pal5x10s2EFEcIDpYjKzevOE4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=70a80e27dafc8321817b8568b20171bf2892fa50", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/d4tFgB2-s2sWsVt1q4Pal5x10s2EFEcIDpYjKzevOE4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f80477c5cca7c521a5b72fab1610482d85e704f0", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/d4tFgB2-s2sWsVt1q4Pal5x10s2EFEcIDpYjKzevOE4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6cce6622ee2cffb892e313574243dc4f4ae02a17", "width": 1080, "height": 606}], "variants": {}, "id": "JBTcceHBOjoeZxknyf0btIks9RWwd2sWR5Yo1qBt_6s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18vyiap", "is_robot_indexable": true, "report_reasons": null, "author": "nf_x", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vyiap/reflecting_on_the_year_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ssmertin.com/articles/reflecting-on-year-2023/", "subreddit_subscribers": 149826, "created_utc": 1704121534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to migrate files from Aliyun OSS to GCP Cloud Storage. As I see, Transfer service just supports AWS and Azure Blob storage natively.\n\nWorkaround will be to use Rclone for this job, but is there any other alternative?\n\nAlso, is there any better easy way to transfer files from private blob storage located in public cloud such as Aliyun to GCP cloud storage?", "author_fullname": "t2_8xdeh5fz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aliyun OSS to GCP Cloud Storage migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vw3fi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704113251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to migrate files from Aliyun OSS to GCP Cloud Storage. As I see, Transfer service just supports AWS and Azure Blob storage natively.&lt;/p&gt;\n\n&lt;p&gt;Workaround will be to use Rclone for this job, but is there any other alternative?&lt;/p&gt;\n\n&lt;p&gt;Also, is there any better easy way to transfer files from private blob storage located in public cloud such as Aliyun to GCP cloud storage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18vw3fi", "is_robot_indexable": true, "report_reasons": null, "author": "Winter-Activity-6938", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vw3fi/aliyun_oss_to_gcp_cloud_storage_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vw3fi/aliyun_oss_to_gcp_cloud_storage_migration/", "subreddit_subscribers": 149826, "created_utc": 1704113251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any suggestions on where to find side projects or consulting gigs, for people wanting to learn more about Data Engineering from real use cases?", "author_fullname": "t2_igetxkds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Contribute to DE projects or consultancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vuscb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704107870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any suggestions on where to find side projects or consulting gigs, for people wanting to learn more about Data Engineering from real use cases?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vuscb", "is_robot_indexable": true, "report_reasons": null, "author": "Azar_e", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vuscb/contribute_to_de_projects_or_consultancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vuscb/contribute_to_de_projects_or_consultancy/", "subreddit_subscribers": 149826, "created_utc": 1704107870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Happy new year! I, a grad student, am planning on working on a data analytics project with my friend who is living in a different state. In this project we are trying to simulate a data lifecycle. We will use a big 'data' set from Kaggle (please recommend any better sources). I (acting as DE and DBA) will create a data engineering pipeline to perform ETL tasks using Python and load this data into a SQL based software that can be remotely accessed by both of us where I will act as a DB admin. My friend(acting as DA) will have access to this database and use it to analyze the data and create reports. This project is very basic and completely theoretical in terms of how the data is connected from one point to the next.\n\nMy questions are, \n\n* Is there a SQL software that permits this? Please suggest some names that are available for free or are open source. \n* Is there a way to connect the flow of data? (I'm considering to completely use SQL to perform the ETL tasks)\n* Is there anything we can do to improve the project? \n\n&amp;#x200B;", "author_fullname": "t2_qpoqsjlmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DB solution for remote student project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vko16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704067853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happy new year! I, a grad student, am planning on working on a data analytics project with my friend who is living in a different state. In this project we are trying to simulate a data lifecycle. We will use a big &amp;#39;data&amp;#39; set from Kaggle (please recommend any better sources). I (acting as DE and DBA) will create a data engineering pipeline to perform ETL tasks using Python and load this data into a SQL based software that can be remotely accessed by both of us where I will act as a DB admin. My friend(acting as DA) will have access to this database and use it to analyze the data and create reports. This project is very basic and completely theoretical in terms of how the data is connected from one point to the next.&lt;/p&gt;\n\n&lt;p&gt;My questions are, &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is there a SQL software that permits this? Please suggest some names that are available for free or are open source. &lt;/li&gt;\n&lt;li&gt;Is there a way to connect the flow of data? (I&amp;#39;m considering to completely use SQL to perform the ETL tasks)&lt;/li&gt;\n&lt;li&gt;Is there anything we can do to improve the project? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vko16", "is_robot_indexable": true, "report_reasons": null, "author": "Dull-Atmosphere8478", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vko16/db_solution_for_remote_student_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vko16/db_solution_for_remote_student_project/", "subreddit_subscribers": 149826, "created_utc": 1704067853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,   \nWondering if there's any experienced data engineers / SWE out there who would be willing to chat a bit and share some perspective.\n\nContext:  \nNew to data engineering role, with 1 year experience. Previously 4 years as a data analyst.  \nLive &amp; work in Australia  \nLooking to understand:  \n\\- where I sit in terms of skills - particularly in industry outside of Australia as it's siloed  \n\\- next steps or how I could 'level-up' in skills or professionally  \n\\- understanding how remote jobs work  \n\n\nYour time and perspective would really be appreciated and valuable to me  \n\n\nThanks,", "author_fullname": "t2_bazyi61n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Data Engineer Seeking Experienced Engineers Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vlz7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704072233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nWondering if there&amp;#39;s any experienced data engineers / SWE out there who would be willing to chat a bit and share some perspective.&lt;/p&gt;\n\n&lt;p&gt;Context:&lt;br/&gt;\nNew to data engineering role, with 1 year experience. Previously 4 years as a data analyst.&lt;br/&gt;\nLive &amp;amp; work in Australia&lt;br/&gt;\nLooking to understand:&lt;br/&gt;\n- where I sit in terms of skills - particularly in industry outside of Australia as it&amp;#39;s siloed&lt;br/&gt;\n- next steps or how I could &amp;#39;level-up&amp;#39; in skills or professionally&lt;br/&gt;\n- understanding how remote jobs work  &lt;/p&gt;\n\n&lt;p&gt;Your time and perspective would really be appreciated and valuable to me  &lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18vlz7h", "is_robot_indexable": true, "report_reasons": null, "author": "Foe317", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vlz7h/new_data_engineer_seeking_experienced_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vlz7h/new_data_engineer_seeking_experienced_engineers/", "subreddit_subscribers": 149826, "created_utc": 1704072233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am a data analyst and have been prepping for this role for a few weeks now. It's time I start applying for interviews. A bit nervous as I am going to have to lie of 2.5 years experience as ADE instead of DA for salary sake. \n\nFirstly, if anyone is applying for same role pls do get in touch with me so we can share our interview questions/experience. \n\nSecondly for the community, as someone with 4.5 YOE and 2.5 YOE in ADE, what qsns can I expect apart from the ones in SQL and python as that I can manage.\n\nAlso, if someone could tell me how their project architecture is, and how they handle transformations, data cleaning, etc in pyspark, it would be very helpful. \n\nThanks a lot. Looking forward to listening from you industry folks.", "author_fullname": "t2_f86nbjeq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Engineer Interview Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vi3gn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704059663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am a data analyst and have been prepping for this role for a few weeks now. It&amp;#39;s time I start applying for interviews. A bit nervous as I am going to have to lie of 2.5 years experience as ADE instead of DA for salary sake. &lt;/p&gt;\n\n&lt;p&gt;Firstly, if anyone is applying for same role pls do get in touch with me so we can share our interview questions/experience. &lt;/p&gt;\n\n&lt;p&gt;Secondly for the community, as someone with 4.5 YOE and 2.5 YOE in ADE, what qsns can I expect apart from the ones in SQL and python as that I can manage.&lt;/p&gt;\n\n&lt;p&gt;Also, if someone could tell me how their project architecture is, and how they handle transformations, data cleaning, etc in pyspark, it would be very helpful. &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot. Looking forward to listening from you industry folks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18vi3gn", "is_robot_indexable": true, "report_reasons": null, "author": "Vikinghehe", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vi3gn/azure_data_engineer_interview_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vi3gn/azure_data_engineer_interview_help/", "subreddit_subscribers": 149826, "created_utc": 1704059663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI\u2019m considering creating a data product that combines a data lake service with AI-generated insights. Despite existing products like Databricks and Snowflake, along with various AI-based insight companies - Do you think it\u2019s still a viable venture?\n\nAny comments or suggestions? Are there any gaps in the current market that you think should be addressed?\n\nThanks!", "author_fullname": "t2_8vjbfemu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Startup Idea Validation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vlbsy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704070061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m considering creating a data product that combines a data lake service with AI-generated insights. Despite existing products like Databricks and Snowflake, along with various AI-based insight companies - Do you think it\u2019s still a viable venture?&lt;/p&gt;\n\n&lt;p&gt;Any comments or suggestions? Are there any gaps in the current market that you think should be addressed?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18vlbsy", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Guy81", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vlbsy/startup_idea_validation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vlbsy/startup_idea_validation/", "subreddit_subscribers": 149826, "created_utc": 1704070061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am apologizing beforehand if somehow is offended by my question.\n\nI am in a dilemma on which role should I venture into - data engineer or data scientist. I am more inclined towards data engineer as it pertains to my skill set but I am in doubt if there is a ceiling in the career growth. Like can a data engineer be offered a executive role or be a part of the board of directors?", "author_fullname": "t2_6aijectm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who is hierarchically superior - data engineer or data scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18vev5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.14, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704050250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am apologizing beforehand if somehow is offended by my question.&lt;/p&gt;\n\n&lt;p&gt;I am in a dilemma on which role should I venture into - data engineer or data scientist. I am more inclined towards data engineer as it pertains to my skill set but I am in doubt if there is a ceiling in the career growth. Like can a data engineer be offered a executive role or be a part of the board of directors?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18vev5r", "is_robot_indexable": true, "report_reasons": null, "author": "X_Warrior361", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18vev5r/who_is_hierarchically_superior_data_engineer_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18vev5r/who_is_hierarchically_superior_data_engineer_or/", "subreddit_subscribers": 149826, "created_utc": 1704050250.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}