{"kind": "Listing", "data": {"after": "t3_18yq23g", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a big believer in the data lake, even during the Snowflake hype. But it\u2019s always been difficult to setup and use. Iceberg (as well as Hudi and Delta) made data lakes easier with built-in support for upserts and optimizations.\n\nDatabricks had been pushing Delta and I\u2019ve seen it used in production at varying scales. But I think Iceberg is a better, more open alternative. Aside from Netflix I haven\u2019t seen much about companies using it in production.\n\nAre you using Iceberg in production? \nAre you considering migrating existing data lake to Iceberg?", "author_fullname": "t2_vhiekvgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are you using Iceberg in production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ym35o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704397803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a big believer in the data lake, even during the Snowflake hype. But it\u2019s always been difficult to setup and use. Iceberg (as well as Hudi and Delta) made data lakes easier with built-in support for upserts and optimizations.&lt;/p&gt;\n\n&lt;p&gt;Databricks had been pushing Delta and I\u2019ve seen it used in production at varying scales. But I think Iceberg is a better, more open alternative. Aside from Netflix I haven\u2019t seen much about companies using it in production.&lt;/p&gt;\n\n&lt;p&gt;Are you using Iceberg in production? \nAre you considering migrating existing data lake to Iceberg?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ym35o", "is_robot_indexable": true, "report_reasons": null, "author": "royondata", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ym35o/are_you_using_iceberg_in_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ym35o/are_you_using_iceberg_in_production/", "subreddit_subscribers": 150553, "created_utc": 1704397803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am adding the link below, have a great day!\n\n[https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra\\_5PGH&amp;index=8&amp;t=74s](https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;index=8&amp;t=74s)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recorded a PySpark Big Data Course (1+ Hour) and uploaded it on YouTube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ynoig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704401735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am adding the link below, have a great day!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;amp;index=8&amp;amp;t=74s\"&gt;https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;amp;index=8&amp;amp;t=74s&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?auto=webp&amp;s=7b0166bc5867a7ce4385d67dcd3f4fa50683d4e7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3274ea7312a04e8647f5f09e239e3f683673b5d4", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b64d29a1fcbb01247ec43c00bac15338baed0ad7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=552a93dafd66279606f2612ed030dabdce4eaf26", "width": 320, "height": 240}], "variants": {}, "id": "BSXYISB8lzOgeFswenJST8Pji3lho2I6izN4zeF7t9g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ynoig", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ynoig/i_recorded_a_pyspark_big_data_course_1_hour_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ynoig/i_recorded_a_pyspark_big_data_course_1_hour_and/", "subreddit_subscribers": 150553, "created_utc": 1704401735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a developer for over a decade, but I'm new to Data Engineering. I set up a couple Iceberg tables in AWS Glue and S3. I've been replicating my production data to these tables for a couple of weeks (\\~100k-300k inserts per day) and saw that our S3 storage size was exploding. After a little analysis, 99% of this storage was metadata. In the worst case, one table had only 13GB of actual data and 66TB of metadata (I emptied that bucket pretty quickly). Several other buckets had 200 MB to 2GB of data and still had 5TB to 7TB of metadata.\n\nIs it normal for Iceberg to accumulate metadata so quickly? or is this just a factor of having so many inserts on a daily basis?\n\nI tried running the \"OPTIMIZE table\" query in Athena, which I got from the Athena documentation, but it only scans about 2GB and takes 30 mins per run, which is way too slow to do by hand on 5TB. After a couple days of Googling and reading the docs, I still don't feel like I'm getting anywhere. How does anybody manage this stuff? Seriously, any feedback, suggestions or links are appreciated.\n\nThanks!\n\n[Let's play \\\\\"Can you spot the Iceberg tables?\\\\\"](https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;format=png&amp;auto=webp&amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d)", "author_fullname": "t2_7bbdmrz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I manage Apache Iceberg metadata that grows exponentially in AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lcr99hk47kac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a1b7837f4fae1d7f68bbd90490b37a5f695c129"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d755a7f89ba18938b987d2b85ad07e8adcb077c6"}, {"y": 151, "x": 320, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e5303a9111265a2930a5a8d2e3056a665ed1588"}, {"y": 303, "x": 640, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8365e957704b3c8373b620e68dfa86a2432f846d"}, {"y": 455, "x": 960, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6c1a004e28ff5956dfcfed4060e280da34aa953"}, {"y": 512, "x": 1080, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c4617c6b32921be277786e1d1d76526717fcdcf"}], "s": {"y": 671, "x": 1413, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;format=png&amp;auto=webp&amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d"}, "id": "lcr99hk47kac1"}}, "name": "t3_18yzbp8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oVWz_Ai75gN3qXlNd_kDLeVGJGlYy6b1KcV2YtcfCMA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704433321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a developer for over a decade, but I&amp;#39;m new to Data Engineering. I set up a couple Iceberg tables in AWS Glue and S3. I&amp;#39;ve been replicating my production data to these tables for a couple of weeks (~100k-300k inserts per day) and saw that our S3 storage size was exploding. After a little analysis, 99% of this storage was metadata. In the worst case, one table had only 13GB of actual data and 66TB of metadata (I emptied that bucket pretty quickly). Several other buckets had 200 MB to 2GB of data and still had 5TB to 7TB of metadata.&lt;/p&gt;\n\n&lt;p&gt;Is it normal for Iceberg to accumulate metadata so quickly? or is this just a factor of having so many inserts on a daily basis?&lt;/p&gt;\n\n&lt;p&gt;I tried running the &amp;quot;OPTIMIZE table&amp;quot; query in Athena, which I got from the Athena documentation, but it only scans about 2GB and takes 30 mins per run, which is way too slow to do by hand on 5TB. After a couple days of Googling and reading the docs, I still don&amp;#39;t feel like I&amp;#39;m getting anywhere. How does anybody manage this stuff? Seriously, any feedback, suggestions or links are appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d\"&gt;Let&amp;#39;s play \\&amp;quot;Can you spot the Iceberg tables?\\&amp;quot;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18yzbp8", "is_robot_indexable": true, "report_reasons": null, "author": "EntrepreneurFitz", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yzbp8/how_do_i_manage_apache_iceberg_metadata_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yzbp8/how_do_i_manage_apache_iceberg_metadata_that/", "subreddit_subscribers": 150553, "created_utc": 1704433321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Over the past 2 months, we've delved deep into the preferences of jobseekers and salaries in Germany (DE) and Switzerland (CH).\n\nThe results of over 6'300 salary data points and 12'500 survey answers are collected in the Transparent IT Job Market Reports. If you are interested in the findings, you can find direct links below (no paywalls, no gatekeeping, just raw PDFs):\n\n[https://static.swissdevjobs.ch/market-reports/IT-Market-Report-2023-SwissDevJobs.pdf](https://static.swissdevjobs.ch/market-reports/IT-Market-Report-2023-SwissDevJobs.pdf)\n\n[https://static.germantechjobs.de/market-reports/IT-Market-Report-2023-GermanTechJobs.pdf](https://static.germantechjobs.de/market-reports/IT-Market-Report-2023-GermanTechJobs.pdf)", "author_fullname": "t2_ifmd6ow8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking Down IT Salaries: Job Market Report for Germany and Switzerland!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yo31h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704402735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the past 2 months, we&amp;#39;ve delved deep into the preferences of jobseekers and salaries in Germany (DE) and Switzerland (CH).&lt;/p&gt;\n\n&lt;p&gt;The results of over 6&amp;#39;300 salary data points and 12&amp;#39;500 survey answers are collected in the Transparent IT Job Market Reports. If you are interested in the findings, you can find direct links below (no paywalls, no gatekeeping, just raw PDFs):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://static.swissdevjobs.ch/market-reports/IT-Market-Report-2023-SwissDevJobs.pdf\"&gt;https://static.swissdevjobs.ch/market-reports/IT-Market-Report-2023-SwissDevJobs.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://static.germantechjobs.de/market-reports/IT-Market-Report-2023-GermanTechJobs.pdf\"&gt;https://static.germantechjobs.de/market-reports/IT-Market-Report-2023-GermanTechJobs.pdf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18yo31h", "is_robot_indexable": true, "report_reasons": null, "author": "One-Durian2205", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yo31h/breaking_down_it_salaries_job_market_report_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yo31h/breaking_down_it_salaries_job_market_report_for/", "subreddit_subscribers": 150553, "created_utc": 1704402735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "how did you land your first proper paying data engineering role, i have worked in shadow for 2 senior data engineers in a MNC doing all their work all by myself for 700 USD/month. Despite having skill set and experience ,because i am in a third world country(Nepal) i cannot find a decent data engineering job.\n\nWould you guys care to join in and share your experience and guide DEs like me?", "author_fullname": "t2_b5mm0rim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having a very hard time as a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yy280", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704429276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how did you land your first proper paying data engineering role, i have worked in shadow for 2 senior data engineers in a MNC doing all their work all by myself for 700 USD/month. Despite having skill set and experience ,because i am in a third world country(Nepal) i cannot find a decent data engineering job.&lt;/p&gt;\n\n&lt;p&gt;Would you guys care to join in and share your experience and guide DEs like me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18yy280", "is_robot_indexable": true, "report_reasons": null, "author": "Horror_Comment6061", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yy280/having_a_very_hard_time_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yy280/having_a_very_hard_time_as_a_data_engineer/", "subreddit_subscribers": 150553, "created_utc": 1704429276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, came across this joins cheat sheet, and it seems to me like 'album' table is not referenced in this query so how could album title be in the result. Am I missing something?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wxtn8alvglac1.png?width=645&amp;format=png&amp;auto=webp&amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7\n\nhttps://preview.redd.it/oizzzwvuglac1.png?width=642&amp;format=png&amp;auto=webp&amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce", "author_fullname": "t2_qjx23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this SQL joins cheat sheet correct?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 43, "top_awarded_type": null, "hide_score": false, "media_metadata": {"oizzzwvuglac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=51d1bd7d2631aec22f118fc71e3fa9dc86ee5ad6"}, {"y": 69, "x": 216, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1268595805b32f89a98298a501457c5260fca98a"}, {"y": 103, "x": 320, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d22d01d2e9e8670796742b79d6ae197530814147"}, {"y": 207, "x": 640, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=56810c60188611bd327ab53759ac4edde0b00f39"}], "s": {"y": 208, "x": 642, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;format=png&amp;auto=webp&amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce"}, "id": "oizzzwvuglac1"}, "wxtn8alvglac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a00ab3eb11e56cabd2cccb2985d55c927ec8860d"}, {"y": 66, "x": 216, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f57f1e320ecf1e44ab102b255c45631c3342448b"}, {"y": 99, "x": 320, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d3ee7366e5fa5326962047deaa34ea5bf73d5e5e"}, {"y": 198, "x": 640, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7667f729196b6254e650f8d4268ca8e40044721b"}], "s": {"y": 200, "x": 645, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;format=png&amp;auto=webp&amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7"}, "id": "wxtn8alvglac1"}}, "name": "t3_18z3cl6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LrJgaKYu7kxOoyduyOuCvjVsernzGHh_eIkdkPfZ9CM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704448649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, came across this joins cheat sheet, and it seems to me like &amp;#39;album&amp;#39; table is not referenced in this query so how could album title be in the result. Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7\"&gt;https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce\"&gt;https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18z3cl6", "is_robot_indexable": true, "report_reasons": null, "author": "In_Dust_We_Trust", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18z3cl6/is_this_sql_joins_cheat_sheet_correct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z3cl6/is_this_sql_joins_cheat_sheet_correct/", "subreddit_subscribers": 150553, "created_utc": 1704448649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to learn Data engineering part, the warehousing, etl/elt part and everything involved in the process. I work in data governance and want to learn Data Engineering part too. How can I start? Any recommendations of books?", "author_fullname": "t2_i96qhyw4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get started with data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7bk9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704462608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn Data engineering part, the warehousing, etl/elt part and everything involved in the process. I work in data governance and want to learn Data Engineering part too. How can I start? Any recommendations of books?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18z7bk9", "is_robot_indexable": true, "report_reasons": null, "author": "mindmybusine55", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z7bk9/how_to_get_started_with_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z7bk9/how_to_get_started_with_data_engineering/", "subreddit_subscribers": 150553, "created_utc": 1704462608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learning Machine Learning, I\u2019ve always been interested in **PyTorch** and its **Autograd engine** (which creates the backprop automatically).\n\nIn [this project](https://github.com/eduardoleao052/Autograd-from-scratch.git), I tried to **reimplement most of PyTorch** (including the Autograd) from scratch in a **well-documented, unit tested, and interpretable** way. It was really useful for me, and I hope it can help you understand Autograd better as well! \n\nHope you enjoy! \n\nGitHub repository [here](https://github.com/eduardoleao052/Autograd-from-scratch.git)!", "author_fullname": "t2_jxw66snkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made an Educational Autograd from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7b0l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704462565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning Machine Learning, I\u2019ve always been interested in &lt;strong&gt;PyTorch&lt;/strong&gt; and its &lt;strong&gt;Autograd engine&lt;/strong&gt; (which creates the backprop automatically).&lt;/p&gt;\n\n&lt;p&gt;In &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;this project&lt;/a&gt;, I tried to &lt;strong&gt;reimplement most of PyTorch&lt;/strong&gt; (including the Autograd) from scratch in a &lt;strong&gt;well-documented, unit tested, and interpretable&lt;/strong&gt; way. It was really useful for me, and I hope it can help you understand Autograd better as well! &lt;/p&gt;\n\n&lt;p&gt;Hope you enjoy! &lt;/p&gt;\n\n&lt;p&gt;GitHub repository &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;here&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?auto=webp&amp;s=b08e23957e84e2548f84ee1a2e3edd55eddcdbc0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=715035611c8f0749273ffc8fca0f864e07c111dc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=357e021032137fbfd977589f8642a71656f1beeb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fedb49819520758e10657a49e29c3cb01f6bacc6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=55e700e4bd3ad5eccbac38718f8edeee778531c3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=46188ed2d9e02ebb2805572b76d6768aebc9faee", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69357870a81c7ee5e7c70ac602acf833079a1b5a", "width": 1080, "height": 540}], "variants": {}, "id": "vF4SW5Y1xXGDQ_lFUvafehmQT8uNb-Di9I6Ty9lBl5g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18z7b0l", "is_robot_indexable": true, "report_reasons": null, "author": "suspicious_beam", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z7b0l/i_made_an_educational_autograd_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z7b0l/i_made_an_educational_autograd_from_scratch/", "subreddit_subscribers": 150553, "created_utc": 1704462565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I'm working as a Lead DBA/DBOps in my current organisation which is a UK based company and I have around 6+ YOE. I was looking for some guidance to what can be my career path in Data engineering.\n\nI have done alot of POC and implementation on ELT/ETL in the current organisation using Kafka/Airbyte/DBT(around 1.5yrs of hands on experience on these). And I'm starting to really get into ELT/ETL as they are much more engaging then the current DBA/DBOps work I do and my manager has taken that into consideration and have assigned alot of work related to such ELT/ETL. I have worked on Liquibase as well as a source control and automated deployments as well and its the main thing which is being used in our team for all the deployments of SQL scripts. I have experience on SQL development and automations using python, bash and powershell. In a nutshell even though my official designation is of a DBA but in my current organisation we do most of the ETL/ELT, sql development, automation, source/schema control and have all the freedom to spinup all the required ec2 instances for RND proposes. On the Datawarehousing front we also work all the livestreaming implementation to BigQuery. The databases I have worked on are MSSQL and MYSQL. \n\nSo was wondering what more do I need to learn so I can transition to more Data related career as I'm currently bored with the just the DBA work and would like to work on more ETL/ELT and eventually move into some senior position in DE and/or relevant profile. What does a typical senior/lead DE professional have experience in and if someone can guide me in the said learning materials.", "author_fullname": "t2_16uh2x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to transition to a DE from DBA/DBOps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yvhxx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704421668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I&amp;#39;m working as a Lead DBA/DBOps in my current organisation which is a UK based company and I have around 6+ YOE. I was looking for some guidance to what can be my career path in Data engineering.&lt;/p&gt;\n\n&lt;p&gt;I have done alot of POC and implementation on ELT/ETL in the current organisation using Kafka/Airbyte/DBT(around 1.5yrs of hands on experience on these). And I&amp;#39;m starting to really get into ELT/ETL as they are much more engaging then the current DBA/DBOps work I do and my manager has taken that into consideration and have assigned alot of work related to such ELT/ETL. I have worked on Liquibase as well as a source control and automated deployments as well and its the main thing which is being used in our team for all the deployments of SQL scripts. I have experience on SQL development and automations using python, bash and powershell. In a nutshell even though my official designation is of a DBA but in my current organisation we do most of the ETL/ELT, sql development, automation, source/schema control and have all the freedom to spinup all the required ec2 instances for RND proposes. On the Datawarehousing front we also work all the livestreaming implementation to BigQuery. The databases I have worked on are MSSQL and MYSQL. &lt;/p&gt;\n\n&lt;p&gt;So was wondering what more do I need to learn so I can transition to more Data related career as I&amp;#39;m currently bored with the just the DBA work and would like to work on more ETL/ELT and eventually move into some senior position in DE and/or relevant profile. What does a typical senior/lead DE professional have experience in and if someone can guide me in the said learning materials.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18yvhxx", "is_robot_indexable": true, "report_reasons": null, "author": "KilluaHatake", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yvhxx/how_to_transition_to_a_de_from_dbadbops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yvhxx/how_to_transition_to_a_de_from_dbadbops/", "subreddit_subscribers": 150553, "created_utc": 1704421668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Personally, I think that communication skills are one of the aspects at the top of the list. Additionally, a depth in database technology, distributed systems, ETL/ELT, and business use cases. But for how long will those aspects remain true, since many things evolve over time, especially rapidly?\n\nDo you think have intermediate ML engineering knowledge, high performance computing, or any other present tangential knowledge will become table stakes? ", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In your opinion, what makes for an \"elite\" data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18z9z3x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704469824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Personally, I think that communication skills are one of the aspects at the top of the list. Additionally, a depth in database technology, distributed systems, ETL/ELT, and business use cases. But for how long will those aspects remain true, since many things evolve over time, especially rapidly?&lt;/p&gt;\n\n&lt;p&gt;Do you think have intermediate ML engineering knowledge, high performance computing, or any other present tangential knowledge will become table stakes? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18z9z3x", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z9z3x/in_your_opinion_what_makes_for_an_elite_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z9z3x/in_your_opinion_what_makes_for_an_elite_data/", "subreddit_subscribers": 150553, "created_utc": 1704469824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our security team has decreed that production data will no longer be permitted in dev environments (it will still be permitted in all other environments). The analysts on my team are upset because they don\u2019t believe they can create dashboards on the tiny static, synthetic dataset that\u2019s being proposed as a replacement, and given all the time series analysis they do I see their point (hard to compute sales in the last 30 days if your data only has timestamps from 2 years ago).\n\nHow do you handle this at your org? Do analysts build their reports solely against prod? Or have some other strategy?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dev data for reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18z8lgr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704466153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our security team has decreed that production data will no longer be permitted in dev environments (it will still be permitted in all other environments). The analysts on my team are upset because they don\u2019t believe they can create dashboards on the tiny static, synthetic dataset that\u2019s being proposed as a replacement, and given all the time series analysis they do I see their point (hard to compute sales in the last 30 days if your data only has timestamps from 2 years ago).&lt;/p&gt;\n\n&lt;p&gt;How do you handle this at your org? Do analysts build their reports solely against prod? Or have some other strategy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z8lgr", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z8lgr/dev_data_for_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z8lgr/dev_data_for_reports/", "subreddit_subscribers": 150553, "created_utc": 1704466153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi community,\n\n**Context**: In my current company, we have a data-pipeline (one of the biggest pipelines), which in short works like this: \n\n* We get raw json events from Kafka dumped in s3. \n* We run a batch job (Airflow) daily, this job picks up the raw jsons in s3, enforces a data parser logic.\n* Data parser logic is simply, a service written in python where we explicitly define what attributes we want from raw json, these attributes are accordingly picked up from the json. There could be nested attributes as well which is taken care of.\n* Post this parsing, the final filtered json is loaded in a dataframe where later this parsed data is converted to CSV/parquet formats and dumped in s3 in another folder.\n* Later this processed CSV is loaded into tables, which is used for analytics, ml models, etc.\n\n**Problem**: \n\n* Today for every new event we generate and get from Kafka-S3 (raw event), we have to write a parser logic from scratch, if the event structure is different. In case of small changes in event we can update attributes we want to parse in code itself. \n* Post that we have to deploy the service changes (regardless of changes in a json event parser is small or big) which again takes time. \n* If there is someone from a different team publishing the event into Kafka and writes parser logic, he has to learn through our codebase, understand how to write a parser which is can be a time-taking learning curve.  \n\n**Solution** (I can think of):\n\n* Can we have a UI interface, where we abstract all this code (thereby making it language agnostic), and the engineer simply has to select the attributes from json (that could include nested attributes), and post selecting it, the batch job gets that information, applies the parser logic selected from UI and then runs rest of the pipeline as it is. \n* This could help us in avoiding tons of code for parsers, avoid or minimize deployments in for smaller changes, and as our data size grows I think it would be better to abstract things make it language agnostic and streamline stuff. There could be other benefits as well I suppose. \n\n**Other thoughts**: \n\n* Is there a smart way of doing it? \n* Do we have any open source alternatives here? \n* Or any good engineering blogs which has covered such/similar scenario?\n* How do big companies handle the humongous volume of data and parse relevant stuff into their tables or datalake, etc? \n\n&amp;#x200B;", "author_fullname": "t2_nbm4prsxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Big Data] How does data parsing happen in your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z0vko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704438742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;: In my current company, we have a data-pipeline (one of the biggest pipelines), which in short works like this: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We get raw json events from Kafka dumped in s3. &lt;/li&gt;\n&lt;li&gt;We run a batch job (Airflow) daily, this job picks up the raw jsons in s3, enforces a data parser logic.&lt;/li&gt;\n&lt;li&gt;Data parser logic is simply, a service written in python where we explicitly define what attributes we want from raw json, these attributes are accordingly picked up from the json. There could be nested attributes as well which is taken care of.&lt;/li&gt;\n&lt;li&gt;Post this parsing, the final filtered json is loaded in a dataframe where later this parsed data is converted to CSV/parquet formats and dumped in s3 in another folder.&lt;/li&gt;\n&lt;li&gt;Later this processed CSV is loaded into tables, which is used for analytics, ml models, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Today for every new event we generate and get from Kafka-S3 (raw event), we have to write a parser logic from scratch, if the event structure is different. In case of small changes in event we can update attributes we want to parse in code itself. &lt;/li&gt;\n&lt;li&gt;Post that we have to deploy the service changes (regardless of changes in a json event parser is small or big) which again takes time. &lt;/li&gt;\n&lt;li&gt;If there is someone from a different team publishing the event into Kafka and writes parser logic, he has to learn through our codebase, understand how to write a parser which is can be a time-taking learning curve.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt; (I can think of):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Can we have a UI interface, where we abstract all this code (thereby making it language agnostic), and the engineer simply has to select the attributes from json (that could include nested attributes), and post selecting it, the batch job gets that information, applies the parser logic selected from UI and then runs rest of the pipeline as it is. &lt;/li&gt;\n&lt;li&gt;This could help us in avoiding tons of code for parsers, avoid or minimize deployments in for smaller changes, and as our data size grows I think it would be better to abstract things make it language agnostic and streamline stuff. There could be other benefits as well I suppose. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Other thoughts&lt;/strong&gt;: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is there a smart way of doing it? &lt;/li&gt;\n&lt;li&gt;Do we have any open source alternatives here? &lt;/li&gt;\n&lt;li&gt;Or any good engineering blogs which has covered such/similar scenario?&lt;/li&gt;\n&lt;li&gt;How do big companies handle the humongous volume of data and parse relevant stuff into their tables or datalake, etc? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z0vko", "is_robot_indexable": true, "report_reasons": null, "author": "jarusv7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z0vko/big_data_how_does_data_parsing_happen_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z0vko/big_data_how_does_data_parsing_happen_in_your/", "subreddit_subscribers": 150553, "created_utc": 1704438742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello my fellow table guys.\n\nCan you help me about my future?\n\nI'm from South America, working as DE for the biggest bank in Brazil. With my fiance, we're planning to immigrate to Canada, for multiple reasons, by the end of the year or the begining of the next. Can you guys help me with some stuff?\n\n1 - What are the most in demand skills to data engineering in Canada?\n\n2 - What do you think is the best city for me to keep my career in data engineering?\n\n3 - How do you think is the most effective way to create network and apply to jobs?\n\n4 - What to avoid?\n\n5 - How about remote jobs? Does it still exists?\n\n6 - Any other suggestions?", "author_fullname": "t2_8b8htzyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help a 3rd world country colleague about hist future", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yhfnc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704386391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello my fellow table guys.&lt;/p&gt;\n\n&lt;p&gt;Can you help me about my future?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from South America, working as DE for the biggest bank in Brazil. With my fiance, we&amp;#39;re planning to immigrate to Canada, for multiple reasons, by the end of the year or the begining of the next. Can you guys help me with some stuff?&lt;/p&gt;\n\n&lt;p&gt;1 - What are the most in demand skills to data engineering in Canada?&lt;/p&gt;\n\n&lt;p&gt;2 - What do you think is the best city for me to keep my career in data engineering?&lt;/p&gt;\n\n&lt;p&gt;3 - How do you think is the most effective way to create network and apply to jobs?&lt;/p&gt;\n\n&lt;p&gt;4 - What to avoid?&lt;/p&gt;\n\n&lt;p&gt;5 - How about remote jobs? Does it still exists?&lt;/p&gt;\n\n&lt;p&gt;6 - Any other suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18yhfnc", "is_robot_indexable": true, "report_reasons": null, "author": "SantoPVL", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yhfnc/help_a_3rd_world_country_colleague_about_hist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yhfnc/help_a_3rd_world_country_colleague_about_hist/", "subreddit_subscribers": 150553, "created_utc": 1704386391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dive into a hands-on data engineering project this weekend! This [GitHub repo](https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_prefect_bigquery) showcases the combined powers of Airbyte, Prefect, and dbt in a practical setting.\n\nIn under an hour, you can establish a complete data stack ready to manage e-commerce sample data. The project uses BigQuery, but you can adapt it to any other data platform with slight modifications. Just follow the instructions in the README.\n\nThis project is designed to be straightforward yet adaptable, perfect for professionals with limited time and those eager to learn.\n\nI look forward to your thoughts and suggestions for improvement!\n\nDisclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help fellow engineers experiment and learn\n\n&amp;#x200B;\n\n[Prefect DAG](https://preview.redd.it/58whu832dnac1.png?width=2388&amp;format=png&amp;auto=webp&amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6)", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrating Airbyte, Prefect &amp; dbt \ud83d\udc47", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": true, "media_metadata": {"58whu832dnac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/58whu832dnac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a58ca984976930763648cc1dfe4e6053c8669025"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/58whu832dnac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b17a25956b24085cf0f1cf2ba3115f314fb2d71e"}, {"y": 84, "x": 320, "u": "https://preview.redd.it/58whu832dnac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d38a2a0ab14b02b2e37948cb481079abf2b0db83"}, {"y": 169, "x": 640, "u": "https://preview.redd.it/58whu832dnac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9806e31765fb6a3777d17beac5081bf14c0e0b4d"}, {"y": 254, "x": 960, "u": "https://preview.redd.it/58whu832dnac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2ddacff7f196636cf939fd272cdc4cbac35ec38"}, {"y": 286, "x": 1080, "u": "https://preview.redd.it/58whu832dnac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c20869b901e5f98bc1c9ee68e6801f57416611a3"}], "s": {"y": 634, "x": 2388, "u": "https://preview.redd.it/58whu832dnac1.png?width=2388&amp;format=png&amp;auto=webp&amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6"}, "id": "58whu832dnac1"}}, "name": "t3_18za481", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DNJvLwFdru0gUEopvUO3gjJdp_FFUEhS5uW6kP7_lPE.jpg", "edited": 1704471581.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704470189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dive into a hands-on data engineering project this weekend! This &lt;a href=\"https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_prefect_bigquery\"&gt;GitHub repo&lt;/a&gt; showcases the combined powers of Airbyte, Prefect, and dbt in a practical setting.&lt;/p&gt;\n\n&lt;p&gt;In under an hour, you can establish a complete data stack ready to manage e-commerce sample data. The project uses BigQuery, but you can adapt it to any other data platform with slight modifications. Just follow the instructions in the README.&lt;/p&gt;\n\n&lt;p&gt;This project is designed to be straightforward yet adaptable, perfect for professionals with limited time and those eager to learn.&lt;/p&gt;\n\n&lt;p&gt;I look forward to your thoughts and suggestions for improvement!&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help fellow engineers experiment and learn&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/58whu832dnac1.png?width=2388&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6\"&gt;Prefect DAG&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18za481", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18za481/integrating_airbyte_prefect_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18za481/integrating_airbyte_prefect_dbt/", "subreddit_subscribers": 150553, "created_utc": 1704470189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a newer data engineer at a large health tech company and our company's ETL is mainly simple SSIS packages to load raw data, then extensive config tables in SQL containing snippets that are used to generate our transformations and subsequent loads entirely with dynamic SQL. \n\nIs this a design pattern any of you have heard of, or some SQL anti-pattern that went out of control? It seems like it would have been easier to debug if we had just used pandas since it has made working on our ETL pipelines a lot more difficult to get the hang of when Its not always obvious which table relates to which translation, or where validation takes place, but it at least has generally useful errors and a lot of validation behind the scene. \n\nIs this a red flag or just a standard process I've never heard of?", "author_fullname": "t2_m1g1wym31", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL with extensive dynamic SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18za1m7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704470000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a newer data engineer at a large health tech company and our company&amp;#39;s ETL is mainly simple SSIS packages to load raw data, then extensive config tables in SQL containing snippets that are used to generate our transformations and subsequent loads entirely with dynamic SQL. &lt;/p&gt;\n\n&lt;p&gt;Is this a design pattern any of you have heard of, or some SQL anti-pattern that went out of control? It seems like it would have been easier to debug if we had just used pandas since it has made working on our ETL pipelines a lot more difficult to get the hang of when Its not always obvious which table relates to which translation, or where validation takes place, but it at least has generally useful errors and a lot of validation behind the scene. &lt;/p&gt;\n\n&lt;p&gt;Is this a red flag or just a standard process I&amp;#39;ve never heard of?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18za1m7", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Egg-561", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18za1m7/etl_with_extensive_dynamic_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18za1m7/etl_with_extensive_dynamic_sql/", "subreddit_subscribers": 150553, "created_utc": 1704470000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nCurious if this golden goose might exist. Are there any open source apps that I can just spin up as a docker service, that offer a frontend for login and user account management in Postgres? Maybe with an `admin` page just for manually managing accounts, though ideally it should be able to manage accounts in an automated fashion.\n\nI would want a reverse proxy to send new sessions to this for login, and upon successful login redirect the user to the desired service (based on url).\n\nI guess it can work by sending any request without a valid session cookie to the authentication service. The user performs login and gets a session cookie. The reverse proxy then sends them to their desired application. Invite only, no sign up.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any quick and easy dockerized authentication apps that I can run with an app and reverse proxy, preferably persisting user accounts in Postgres?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18z9fbb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704468666.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704468376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Curious if this golden goose might exist. Are there any open source apps that I can just spin up as a docker service, that offer a frontend for login and user account management in Postgres? Maybe with an &lt;code&gt;admin&lt;/code&gt; page just for manually managing accounts, though ideally it should be able to manage accounts in an automated fashion.&lt;/p&gt;\n\n&lt;p&gt;I would want a reverse proxy to send new sessions to this for login, and upon successful login redirect the user to the desired service (based on url).&lt;/p&gt;\n\n&lt;p&gt;I guess it can work by sending any request without a valid session cookie to the authentication service. The user performs login and gets a session cookie. The reverse proxy then sends them to their desired application. Invite only, no sign up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z9fbb", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z9fbb/are_there_any_quick_and_easy_dockerized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z9fbb/are_there_any_quick_and_easy_dockerized/", "subreddit_subscribers": 150553, "created_utc": 1704468376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark 3.5 + Notebook Docker Image - alexmerced/spark35-notebook - For Practicing Spark Locally (youtube.com/@alexmerceddata)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7c0d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/d3jg9cv9mmac1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/d3jg9cv9mmac1/DASH_96.mp4", "dash_url": "https://v.redd.it/d3jg9cv9mmac1/DASHPlaylist.mpd?a=1707064855%2CNzE4MTg3MjZkNjQwNzViYTcxNGQzMzk0ZmY2NDU0ODg5YzU3YmY4NTdiNzc3OWIxNWVmNWVkYTA2ZDRiNGE1Mw%3D%3D&amp;v=1&amp;f=sd", "duration": 414, "hls_url": "https://v.redd.it/d3jg9cv9mmac1/HLSPlaylist.m3u8?a=1707064855%2CMWNjODkwMGY1YjJiYzZhZjAyODNmNWFjM2Y1N2JmOWQ1ZDA3MGRmMzgwOTQyMGQwYTQxZDU0ZjI0Yzk2ODhhYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=fc352d471d4adf586ee1a48b55a55d80734e31dd", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704462642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/d3jg9cv9mmac1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?format=pjpg&amp;auto=webp&amp;s=c393f9878953c98f47ab6bb53955dd798958eca3", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=997eac41370b3d148e1c2caf694177adf28f7125", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7b2dd8203f34ce579421bf6085040752705c62d0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5ee66917fc8a2987ffdfaf058e3d244f73dc3753", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f6b6ca2a29f7abff6bd1de065360592ecb1a9a00", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3898f4940cf197e8de928e0d934dd1b436382ac7", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=95b3a0b0c09f81a95c934458660c3a3feb9ec0be", "width": 1080, "height": 607}], "variants": {}, "id": "Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18z7c0d", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z7c0d/apache_spark_35_notebook_docker_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/d3jg9cv9mmac1", "subreddit_subscribers": 150553, "created_utc": 1704462642.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/d3jg9cv9mmac1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/d3jg9cv9mmac1/DASH_96.mp4", "dash_url": "https://v.redd.it/d3jg9cv9mmac1/DASHPlaylist.mpd?a=1707064855%2CNzE4MTg3MjZkNjQwNzViYTcxNGQzMzk0ZmY2NDU0ODg5YzU3YmY4NTdiNzc3OWIxNWVmNWVkYTA2ZDRiNGE1Mw%3D%3D&amp;v=1&amp;f=sd", "duration": 414, "hls_url": "https://v.redd.it/d3jg9cv9mmac1/HLSPlaylist.m3u8?a=1707064855%2CMWNjODkwMGY1YjJiYzZhZjAyODNmNWFjM2Y1N2JmOWQ1ZDA3MGRmMzgwOTQyMGQwYTQxZDU0ZjI0Yzk2ODhhYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a QE - ETL Lead with over a decade experience having strong knowledge in SQL,  good knowledge on Python, ETL &amp; DW concepts, Data modelling. \n\nPlanning to switch into DE. Only reason for this switch is the routine tasks, which is not challenging in my current role. I\u2019m more inclined towards technical side of things.\n\nWant to understand the challenges switching my career option. I\u2019m a quick learner, how much time would it normally take to be data engineer. \n\nThank you", "author_fullname": "t2_numf636zk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions from QE to DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ywtl4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704425446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a QE - ETL Lead with over a decade experience having strong knowledge in SQL,  good knowledge on Python, ETL &amp;amp; DW concepts, Data modelling. &lt;/p&gt;\n\n&lt;p&gt;Planning to switch into DE. Only reason for this switch is the routine tasks, which is not challenging in my current role. I\u2019m more inclined towards technical side of things.&lt;/p&gt;\n\n&lt;p&gt;Want to understand the challenges switching my career option. I\u2019m a quick learner, how much time would it normally take to be data engineer. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18ywtl4", "is_robot_indexable": true, "report_reasons": null, "author": "FaithlessnessDry4116", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ywtl4/suggestions_from_qe_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ywtl4/suggestions_from_qe_to_de/", "subreddit_subscribers": 150553, "created_utc": 1704425446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a BSc  in CS (mostly software engineering) and an MSc in NLP (a good UK uni). I then did most of a PhD in CS (esoteric stuff not really DE) but didn\u2019t finish for personal reasons. After that I did 7 years in a research engineer role. In that I\u2019ve done many tasks including: training DL models, full stack development, some basic AWS, conceptualising new projects and presentations, writing reports, setting up data preprocessing and databases + dashboards, scraping and I help co-organise a discussion group with a well known university on A.I. (mostly conceptual).\n\nI should be in a senior position but\u2026 I mostly did what feels like random projects that didn\u2019t have much external impact. I never really published (just a couple of times). I did a lot of things but without proper supervision or a team so I question my standards and I feel I have very broad but shallow experience. I\u2019m mostly self taught with ML though I did take some courses and my math level is mostly conceptual: I\u2019ve read a bunch of text books and I get the high level concepts but it\u2019s not internalised. I couldn\u2019t apply it to novel problems easily.\n\nI crave working with a team in a constructive environment (very people oriented) but I have no idea what actual in-the-wild projects involve and how to position myself in the market. I want to be genuinely useful and not bullshit my way into a job. Any advice?", "author_fullname": "t2_15jntj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adapting Career Path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ys2ca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704412438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a BSc  in CS (mostly software engineering) and an MSc in NLP (a good UK uni). I then did most of a PhD in CS (esoteric stuff not really DE) but didn\u2019t finish for personal reasons. After that I did 7 years in a research engineer role. In that I\u2019ve done many tasks including: training DL models, full stack development, some basic AWS, conceptualising new projects and presentations, writing reports, setting up data preprocessing and databases + dashboards, scraping and I help co-organise a discussion group with a well known university on A.I. (mostly conceptual).&lt;/p&gt;\n\n&lt;p&gt;I should be in a senior position but\u2026 I mostly did what feels like random projects that didn\u2019t have much external impact. I never really published (just a couple of times). I did a lot of things but without proper supervision or a team so I question my standards and I feel I have very broad but shallow experience. I\u2019m mostly self taught with ML though I did take some courses and my math level is mostly conceptual: I\u2019ve read a bunch of text books and I get the high level concepts but it\u2019s not internalised. I couldn\u2019t apply it to novel problems easily.&lt;/p&gt;\n\n&lt;p&gt;I crave working with a team in a constructive environment (very people oriented) but I have no idea what actual in-the-wild projects involve and how to position myself in the market. I want to be genuinely useful and not bullshit my way into a job. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18ys2ca", "is_robot_indexable": true, "report_reasons": null, "author": "readthereadit", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ys2ca/adapting_career_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ys2ca/adapting_career_path/", "subreddit_subscribers": 150553, "created_utc": 1704412438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI\u2019m working with a company who makes their data available only through UI and OData. Before breaking out selenium, I\u2019m curious if I can consume the data via OData.\n\nI see PyOData seems only to support the v2 protocol out of all 4 versions. Is there a more mature way?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you consume an OData feed for ETL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ypqtc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704406822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m working with a company who makes their data available only through UI and OData. Before breaking out selenium, I\u2019m curious if I can consume the data via OData.&lt;/p&gt;\n\n&lt;p&gt;I see PyOData seems only to support the v2 protocol out of all 4 versions. Is there a more mature way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ypqtc", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ypqtc/how_do_you_consume_an_odata_feed_for_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ypqtc/how_do_you_consume_an_odata_feed_for_etl/", "subreddit_subscribers": 150553, "created_utc": 1704406822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Airflow v1.10.7 running in `LocalExecutor` mode.\n\nTrying to find a way to determine what tasks in a DAG have recently jumped up in duration time; the Task Duration web UI for the DAG is being slow and unresponsive. Is there another way to do this? (Any way to debug the slowness of the web UI?)\n\nTrying to view the Task Duration screen for a DAG with many tasks (mostly Apache Sqoop jobs), but web browser keeps hanging when attempting this (happens regardless of web browser type and even when trying locally on the machine running the `airflow-webserver`).\n\nIf I wait very long, I can see the graph load (showing way more than the default 'last 25 number of runs' for some reason) and can see that around the past month a few tasks made a step-wise jump in duration and have since stayed at that elevated level for each subsequent run. Now I am trying to figure out what those tasks are, but the fact that the web UI is so laggy when looking at this DAG is making the Task Duration page impossible to use.\n\nAny other common best-practices way to debug this situation? (Any suggestions for debugging the web UI so I can use the Task Duration page again?)\n\nThanks.", "author_fullname": "t2_4rwmx54d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to view task durations over time when Airflow web UI Task Duration screen for DAG is laggy / non-responsive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yp76x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704417218.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704405511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Airflow v1.10.7 running in &lt;code&gt;LocalExecutor&lt;/code&gt; mode.&lt;/p&gt;\n\n&lt;p&gt;Trying to find a way to determine what tasks in a DAG have recently jumped up in duration time; the Task Duration web UI for the DAG is being slow and unresponsive. Is there another way to do this? (Any way to debug the slowness of the web UI?)&lt;/p&gt;\n\n&lt;p&gt;Trying to view the Task Duration screen for a DAG with many tasks (mostly Apache Sqoop jobs), but web browser keeps hanging when attempting this (happens regardless of web browser type and even when trying locally on the machine running the &lt;code&gt;airflow-webserver&lt;/code&gt;).&lt;/p&gt;\n\n&lt;p&gt;If I wait very long, I can see the graph load (showing way more than the default &amp;#39;last 25 number of runs&amp;#39; for some reason) and can see that around the past month a few tasks made a step-wise jump in duration and have since stayed at that elevated level for each subsequent run. Now I am trying to figure out what those tasks are, but the fact that the web UI is so laggy when looking at this DAG is making the Task Duration page impossible to use.&lt;/p&gt;\n\n&lt;p&gt;Any other common best-practices way to debug this situation? (Any suggestions for debugging the web UI so I can use the Task Duration page again?)&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18yp76x", "is_robot_indexable": true, "report_reasons": null, "author": "Anxious_Reporter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yp76x/how_to_view_task_durations_over_time_when_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yp76x/how_to_view_task_durations_over_time_when_airflow/", "subreddit_subscribers": 150553, "created_utc": 1704405511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need help trying to recreate this data format in a different program. We use our current system \n\n[Original old system](https://preview.redd.it/et78viqfbgac1.jpg?width=517&amp;format=pjpg&amp;auto=webp&amp;s=f5db0a9a5118acb99ede0bbdf00d491064df280f)\n\n[This is what exporting the data looks like into Google Sheets.](https://preview.redd.it/34y7beegbgac1.jpg?width=614&amp;format=pjpg&amp;auto=webp&amp;s=f44f702995fadb16b21076ad5a430c274036ce28)\n\n[This is an edited version of the above data to attempt to make it more understandable.](https://preview.redd.it/oyfpwpvgbgac1.jpg?width=1075&amp;format=pjpg&amp;auto=webp&amp;s=f2638052e655a34a2427d13acc672ac88470fcff)", "author_fullname": "t2_eafncbrjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for assistance with managing data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"34y7beegbgac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 121, "x": 108, "u": "https://preview.redd.it/34y7beegbgac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=10ce8cbcae8d305b3ec7c8dcfd81bb84a1fa9009"}, {"y": 243, "x": 216, "u": "https://preview.redd.it/34y7beegbgac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3bec87221b0269c7e894e9d744cc9f6d8c69548d"}, {"y": 361, "x": 320, "u": "https://preview.redd.it/34y7beegbgac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf157e6b0ce5f665d5284139075d24372f1fb46c"}], "s": {"y": 693, "x": 614, "u": "https://preview.redd.it/34y7beegbgac1.jpg?width=614&amp;format=pjpg&amp;auto=webp&amp;s=f44f702995fadb16b21076ad5a430c274036ce28"}, "id": "34y7beegbgac1"}, "et78viqfbgac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 130, "x": 108, "u": "https://preview.redd.it/et78viqfbgac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d7fa0e0d9152a18849df60f92951693d348e1800"}, {"y": 261, "x": 216, "u": "https://preview.redd.it/et78viqfbgac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa483abcd720fa97dc313da959383ccc446a622f"}, {"y": 387, "x": 320, "u": "https://preview.redd.it/et78viqfbgac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5e5c9d54e6661f54c285de064fbfb4eba3bed3a7"}], "s": {"y": 626, "x": 517, "u": "https://preview.redd.it/et78viqfbgac1.jpg?width=517&amp;format=pjpg&amp;auto=webp&amp;s=f5db0a9a5118acb99ede0bbdf00d491064df280f"}, "id": "et78viqfbgac1"}, "oyfpwpvgbgac1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/oyfpwpvgbgac1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=adee067292517269b92b7a41c88df253a6b1ecbf"}, {"y": 145, "x": 216, "u": "https://preview.redd.it/oyfpwpvgbgac1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e1810a89c312f41be19bb5e808b265595d7a933"}, {"y": 216, "x": 320, "u": "https://preview.redd.it/oyfpwpvgbgac1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7ee98515925d7dba56f8e1a7ddede67fa66d07ec"}, {"y": 432, "x": 640, "u": "https://preview.redd.it/oyfpwpvgbgac1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd2e95e70aba057b469f21d5dbc08ae235cd76a8"}, {"y": 648, "x": 960, "u": "https://preview.redd.it/oyfpwpvgbgac1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=24c09e3cee50187cf296915c54511f9612e4292c"}], "s": {"y": 726, "x": 1075, "u": "https://preview.redd.it/oyfpwpvgbgac1.jpg?width=1075&amp;format=pjpg&amp;auto=webp&amp;s=f2638052e655a34a2427d13acc672ac88470fcff"}, "id": "oyfpwpvgbgac1"}}, "name": "t3_18yifsy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BCuWGL9HhLhHFQvGUEG77D1DwntnCqYskIHxkmEloeM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704388896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need help trying to recreate this data format in a different program. We use our current system &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/et78viqfbgac1.jpg?width=517&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f5db0a9a5118acb99ede0bbdf00d491064df280f\"&gt;Original old system&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/34y7beegbgac1.jpg?width=614&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f44f702995fadb16b21076ad5a430c274036ce28\"&gt;This is what exporting the data looks like into Google Sheets.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oyfpwpvgbgac1.jpg?width=1075&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f2638052e655a34a2427d13acc672ac88470fcff\"&gt;This is an edited version of the above data to attempt to make it more understandable.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18yifsy", "is_robot_indexable": true, "report_reasons": null, "author": "No-Introduction111", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yifsy/looking_for_assistance_with_managing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yifsy/looking_for_assistance_with_managing_data/", "subreddit_subscribers": 150553, "created_utc": 1704388896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title\\^\n\nBut to be more specific, I'm trying to keep up with how hardware tech development that affects software tech development. \n\nThings like breakthoughs in CPU or storage, etc. \n\nAlso if you know of any educational people to follow that talk about hardware? I'm quite a novice. ", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommendations for people on Linkedin to follow to stay up to date with the hardware side of technology?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18z9ku4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704468773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title^&lt;/p&gt;\n\n&lt;p&gt;But to be more specific, I&amp;#39;m trying to keep up with how hardware tech development that affects software tech development. &lt;/p&gt;\n\n&lt;p&gt;Things like breakthoughs in CPU or storage, etc. &lt;/p&gt;\n\n&lt;p&gt;Also if you know of any educational people to follow that talk about hardware? I&amp;#39;m quite a novice. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18z9ku4", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18z9ku4/any_recommendations_for_people_on_linkedin_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z9ku4/any_recommendations_for_people_on_linkedin_to/", "subreddit_subscribers": 150553, "created_utc": 1704468773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8682bqw4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Learning roadmap for 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7acj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VQKshwJh4iFv-9lXdqVTTYcSOwRzlWV5XzdOsJIFflw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704462509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "niteshx2.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://niteshx2.medium.com/faang-data-engineer-learning-roadmap-for-2024-199b1c831bca", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mpvjD6ArONDFZAqrbDRSyjcSm11hx4qdOyvUtSmbPjE.jpg?auto=webp&amp;s=39638cd4e507cb68715cce8b3ffa39480ddd5f2d", "width": 810, "height": 446}, "resolutions": [{"url": "https://external-preview.redd.it/mpvjD6ArONDFZAqrbDRSyjcSm11hx4qdOyvUtSmbPjE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bc1d2a4521d827e995ccbc1c617ca5ff96cf0fa", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/mpvjD6ArONDFZAqrbDRSyjcSm11hx4qdOyvUtSmbPjE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d118ea3053f8e6ccbb2ffb6073fbed916b4e72af", "width": 216, "height": 118}, {"url": "https://external-preview.redd.it/mpvjD6ArONDFZAqrbDRSyjcSm11hx4qdOyvUtSmbPjE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d2efcac0b47320ac1f3c5bbbe9cfb0d94c6b5acd", "width": 320, "height": 176}, {"url": "https://external-preview.redd.it/mpvjD6ArONDFZAqrbDRSyjcSm11hx4qdOyvUtSmbPjE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=52f567ee4a100ad3bc426e0648521e7aee898b6d", "width": 640, "height": 352}], "variants": {}, "id": "xPYmUDnBG2MB-90EzJvEhFc4qzRsymJwJZSpmsUwXew"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18z7acj", "is_robot_indexable": true, "report_reasons": null, "author": "GreekYogurtt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z7acj/data_engineer_learning_roadmap_for_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://niteshx2.medium.com/faang-data-engineer-learning-roadmap-for-2024-199b1c831bca", "subreddit_subscribers": 150553, "created_utc": 1704462509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tasked with leading a BI/BW team for a mid sized organization.  Plenty of $$$, moderate amount of data.  Many data sources (100+). I am not an experienced data engineer, but I did stay at a Holiday Inn Express last night.  \n\nDoing my research I have read up on Kimball and dimensional modeling and data normalization.  Sounds fucking painful.\n\nMe and my team are Pretty good with Power BI.  Fucking love the Transform data within Power BI.  Using Azure Synapse/ Data Lake for central repository.\n\nThe dimensional modeling and normalization seems to be a massive lift.  Feels like we could spend years working on that - meanwhile the rest of the organization is wondering what the fuck we are doing?\n\nI can take two dimensional tables from various sources and just model them in PowerBI.  Do it 1 project at a time.  Can turn a project around in just a few weeks.  People can see we are producing some dashboards in the near future.\n\nWith MPP processing power and columnar data bases - am I crazy to say fuck Kimball and fuck OLAP cubes?  I just want to store denormalized tables in the Datalake and model them in PowerBi as needed for individual projects.\n\nPart of me thinks this might be short sighted, but I don\u2019t feel like I have years available to work through fucking Kimball methods for 100+ data sources.\n\nFeedback / suggestions are appreciated.", "author_fullname": "t2_7cyma1ni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do we really need to perform dimensional modeling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yq23g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.48, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704407756.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704407510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tasked with leading a BI/BW team for a mid sized organization.  Plenty of $$$, moderate amount of data.  Many data sources (100+). I am not an experienced data engineer, but I did stay at a Holiday Inn Express last night.  &lt;/p&gt;\n\n&lt;p&gt;Doing my research I have read up on Kimball and dimensional modeling and data normalization.  Sounds fucking painful.&lt;/p&gt;\n\n&lt;p&gt;Me and my team are Pretty good with Power BI.  Fucking love the Transform data within Power BI.  Using Azure Synapse/ Data Lake for central repository.&lt;/p&gt;\n\n&lt;p&gt;The dimensional modeling and normalization seems to be a massive lift.  Feels like we could spend years working on that - meanwhile the rest of the organization is wondering what the fuck we are doing?&lt;/p&gt;\n\n&lt;p&gt;I can take two dimensional tables from various sources and just model them in PowerBI.  Do it 1 project at a time.  Can turn a project around in just a few weeks.  People can see we are producing some dashboards in the near future.&lt;/p&gt;\n\n&lt;p&gt;With MPP processing power and columnar data bases - am I crazy to say fuck Kimball and fuck OLAP cubes?  I just want to store denormalized tables in the Datalake and model them in PowerBi as needed for individual projects.&lt;/p&gt;\n\n&lt;p&gt;Part of me thinks this might be short sighted, but I don\u2019t feel like I have years available to work through fucking Kimball methods for 100+ data sources.&lt;/p&gt;\n\n&lt;p&gt;Feedback / suggestions are appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18yq23g", "is_robot_indexable": true, "report_reasons": null, "author": "AdhesivenessOne6188", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yq23g/do_we_really_need_to_perform_dimensional_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yq23g/do_we_really_need_to_perform_dimensional_modeling/", "subreddit_subscribers": 150553, "created_utc": 1704407510.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}