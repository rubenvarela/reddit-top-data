{"kind": "Listing", "data": {"after": "t3_18z7c0d", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am adding the link below, have a great day!\n\n[https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra\\_5PGH&amp;index=8&amp;t=74s](https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;index=8&amp;t=74s)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recorded a PySpark Big Data Course (1+ Hour) and uploaded it on YouTube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ynoig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704401735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am adding the link below, have a great day!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;amp;index=8&amp;amp;t=74s\"&gt;https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;amp;index=8&amp;amp;t=74s&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?auto=webp&amp;s=7b0166bc5867a7ce4385d67dcd3f4fa50683d4e7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3274ea7312a04e8647f5f09e239e3f683673b5d4", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b64d29a1fcbb01247ec43c00bac15338baed0ad7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=552a93dafd66279606f2612ed030dabdce4eaf26", "width": 320, "height": 240}], "variants": {}, "id": "BSXYISB8lzOgeFswenJST8Pji3lho2I6izN4zeF7t9g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ynoig", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ynoig/i_recorded_a_pyspark_big_data_course_1_hour_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ynoig/i_recorded_a_pyspark_big_data_course_1_hour_and/", "subreddit_subscribers": 150592, "created_utc": 1704401735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Personally, I think that communication skills are one of the aspects at the top of the list. Additionally, a depth in database technology, distributed systems, ETL/ELT, and business use cases. But for how long will those aspects remain true, since many things evolve over time, especially rapidly?\n\nDo you think have intermediate ML engineering knowledge, high performance computing, or any other present tangential knowledge will become table stakes? ", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In your opinion, what makes for an \"elite\" data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z9z3x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704469824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Personally, I think that communication skills are one of the aspects at the top of the list. Additionally, a depth in database technology, distributed systems, ETL/ELT, and business use cases. But for how long will those aspects remain true, since many things evolve over time, especially rapidly?&lt;/p&gt;\n\n&lt;p&gt;Do you think have intermediate ML engineering knowledge, high performance computing, or any other present tangential knowledge will become table stakes? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18z9z3x", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z9z3x/in_your_opinion_what_makes_for_an_elite_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z9z3x/in_your_opinion_what_makes_for_an_elite_data/", "subreddit_subscribers": 150592, "created_utc": 1704469824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a developer for over a decade, but I'm new to Data Engineering. I set up a couple Iceberg tables in AWS Glue and S3. I've been replicating my production data to these tables for a couple of weeks (\\~100k-300k inserts per day) and saw that our S3 storage size was exploding. After a little analysis, 99% of this storage was metadata. In the worst case, one table had only 13GB of actual data and 66TB of metadata (I emptied that bucket pretty quickly). Several other buckets had 200 MB to 2GB of data and still had 5TB to 7TB of metadata.\n\nIs it normal for Iceberg to accumulate metadata so quickly? or is this just a factor of having so many inserts on a daily basis?\n\nI tried running the \"OPTIMIZE table\" query in Athena, which I got from the Athena documentation, but it only scans about 2GB and takes 30 mins per run, which is way too slow to do by hand on 5TB. After a couple days of Googling and reading the docs, I still don't feel like I'm getting anywhere. How does anybody manage this stuff? Seriously, any feedback, suggestions or links are appreciated.\n\nThanks!\n\n[Let's play \\\\\"Can you spot the Iceberg tables?\\\\\"](https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;format=png&amp;auto=webp&amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d)", "author_fullname": "t2_7bbdmrz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I manage Apache Iceberg metadata that grows exponentially in AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lcr99hk47kac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a1b7837f4fae1d7f68bbd90490b37a5f695c129"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d755a7f89ba18938b987d2b85ad07e8adcb077c6"}, {"y": 151, "x": 320, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e5303a9111265a2930a5a8d2e3056a665ed1588"}, {"y": 303, "x": 640, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8365e957704b3c8373b620e68dfa86a2432f846d"}, {"y": 455, "x": 960, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6c1a004e28ff5956dfcfed4060e280da34aa953"}, {"y": 512, "x": 1080, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c4617c6b32921be277786e1d1d76526717fcdcf"}], "s": {"y": 671, "x": 1413, "u": "https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;format=png&amp;auto=webp&amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d"}, "id": "lcr99hk47kac1"}}, "name": "t3_18yzbp8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oVWz_Ai75gN3qXlNd_kDLeVGJGlYy6b1KcV2YtcfCMA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704433321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a developer for over a decade, but I&amp;#39;m new to Data Engineering. I set up a couple Iceberg tables in AWS Glue and S3. I&amp;#39;ve been replicating my production data to these tables for a couple of weeks (~100k-300k inserts per day) and saw that our S3 storage size was exploding. After a little analysis, 99% of this storage was metadata. In the worst case, one table had only 13GB of actual data and 66TB of metadata (I emptied that bucket pretty quickly). Several other buckets had 200 MB to 2GB of data and still had 5TB to 7TB of metadata.&lt;/p&gt;\n\n&lt;p&gt;Is it normal for Iceberg to accumulate metadata so quickly? or is this just a factor of having so many inserts on a daily basis?&lt;/p&gt;\n\n&lt;p&gt;I tried running the &amp;quot;OPTIMIZE table&amp;quot; query in Athena, which I got from the Athena documentation, but it only scans about 2GB and takes 30 mins per run, which is way too slow to do by hand on 5TB. After a couple days of Googling and reading the docs, I still don&amp;#39;t feel like I&amp;#39;m getting anywhere. How does anybody manage this stuff? Seriously, any feedback, suggestions or links are appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lcr99hk47kac1.png?width=1413&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c9dcb18f207369eb5443b17cfc4bf29cc951bc7d\"&gt;Let&amp;#39;s play \\&amp;quot;Can you spot the Iceberg tables?\\&amp;quot;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18yzbp8", "is_robot_indexable": true, "report_reasons": null, "author": "EntrepreneurFitz", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yzbp8/how_do_i_manage_apache_iceberg_metadata_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yzbp8/how_do_i_manage_apache_iceberg_metadata_that/", "subreddit_subscribers": 150592, "created_utc": 1704433321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "how did you land your first proper paying data engineering role, i have worked in shadow for 2 senior data engineers in a MNC doing all their work all by myself for 700 USD/month. Despite having skill set and experience ,because i am in a third world country(Nepal) i cannot find a decent data engineering job.\n\nWould you guys care to join in and share your experience and guide DEs like me?", "author_fullname": "t2_b5mm0rim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having a very hard time as a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yy280", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704429276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how did you land your first proper paying data engineering role, i have worked in shadow for 2 senior data engineers in a MNC doing all their work all by myself for 700 USD/month. Despite having skill set and experience ,because i am in a third world country(Nepal) i cannot find a decent data engineering job.&lt;/p&gt;\n\n&lt;p&gt;Would you guys care to join in and share your experience and guide DEs like me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18yy280", "is_robot_indexable": true, "report_reasons": null, "author": "Horror_Comment6061", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yy280/having_a_very_hard_time_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yy280/having_a_very_hard_time_as_a_data_engineer/", "subreddit_subscribers": 150592, "created_utc": 1704429276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Over the past 2 months, we've delved deep into the preferences of jobseekers and salaries in Germany (DE) and Switzerland (CH).\n\nThe results of over 6'300 salary data points and 12'500 survey answers are collected in the Transparent IT Job Market Reports. If you are interested in the findings, you can find direct links below (no paywalls, no gatekeeping, just raw PDFs):\n\n[https://static.swissdevjobs.ch/market-reports/IT-Market-Report-2023-SwissDevJobs.pdf](https://static.swissdevjobs.ch/market-reports/IT-Market-Report-2023-SwissDevJobs.pdf)\n\n[https://static.germantechjobs.de/market-reports/IT-Market-Report-2023-GermanTechJobs.pdf](https://static.germantechjobs.de/market-reports/IT-Market-Report-2023-GermanTechJobs.pdf)", "author_fullname": "t2_ifmd6ow8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking Down IT Salaries: Job Market Report for Germany and Switzerland!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yo31h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704402735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the past 2 months, we&amp;#39;ve delved deep into the preferences of jobseekers and salaries in Germany (DE) and Switzerland (CH).&lt;/p&gt;\n\n&lt;p&gt;The results of over 6&amp;#39;300 salary data points and 12&amp;#39;500 survey answers are collected in the Transparent IT Job Market Reports. If you are interested in the findings, you can find direct links below (no paywalls, no gatekeeping, just raw PDFs):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://static.swissdevjobs.ch/market-reports/IT-Market-Report-2023-SwissDevJobs.pdf\"&gt;https://static.swissdevjobs.ch/market-reports/IT-Market-Report-2023-SwissDevJobs.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://static.germantechjobs.de/market-reports/IT-Market-Report-2023-GermanTechJobs.pdf\"&gt;https://static.germantechjobs.de/market-reports/IT-Market-Report-2023-GermanTechJobs.pdf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18yo31h", "is_robot_indexable": true, "report_reasons": null, "author": "One-Durian2205", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yo31h/breaking_down_it_salaries_job_market_report_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yo31h/breaking_down_it_salaries_job_market_report_for/", "subreddit_subscribers": 150592, "created_utc": 1704402735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dive into a hands-on data engineering project this weekend! This [GitHub repo](https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_prefect_bigquery) showcases the combined powers of Airbyte, Prefect, and dbt in a practical setting.\n\nIn under an hour, you can establish a complete data stack ready to manage e-commerce sample data. The project uses BigQuery, but you can adapt it to any other data platform with slight modifications. Just follow the instructions in the README.\n\nThis project is designed to be straightforward yet adaptable, perfect for professionals with limited time and those eager to learn.\n\nI look forward to your thoughts and suggestions for improvement!\n\nDisclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help fellow engineers experiment and learn\n\n&amp;#x200B;\n\n[Prefect DAG](https://preview.redd.it/58whu832dnac1.png?width=2388&amp;format=png&amp;auto=webp&amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6)", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrating Airbyte, Prefect &amp; dbt \ud83d\udc47", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": false, "media_metadata": {"58whu832dnac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/58whu832dnac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a58ca984976930763648cc1dfe4e6053c8669025"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/58whu832dnac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b17a25956b24085cf0f1cf2ba3115f314fb2d71e"}, {"y": 84, "x": 320, "u": "https://preview.redd.it/58whu832dnac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d38a2a0ab14b02b2e37948cb481079abf2b0db83"}, {"y": 169, "x": 640, "u": "https://preview.redd.it/58whu832dnac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9806e31765fb6a3777d17beac5081bf14c0e0b4d"}, {"y": 254, "x": 960, "u": "https://preview.redd.it/58whu832dnac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2ddacff7f196636cf939fd272cdc4cbac35ec38"}, {"y": 286, "x": 1080, "u": "https://preview.redd.it/58whu832dnac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c20869b901e5f98bc1c9ee68e6801f57416611a3"}], "s": {"y": 634, "x": 2388, "u": "https://preview.redd.it/58whu832dnac1.png?width=2388&amp;format=png&amp;auto=webp&amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6"}, "id": "58whu832dnac1"}}, "name": "t3_18za481", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DNJvLwFdru0gUEopvUO3gjJdp_FFUEhS5uW6kP7_lPE.jpg", "edited": 1704471581.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704470189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dive into a hands-on data engineering project this weekend! This &lt;a href=\"https://github.com/airbytehq/quickstarts/tree/main/airbyte_dbt_prefect_bigquery\"&gt;GitHub repo&lt;/a&gt; showcases the combined powers of Airbyte, Prefect, and dbt in a practical setting.&lt;/p&gt;\n\n&lt;p&gt;In under an hour, you can establish a complete data stack ready to manage e-commerce sample data. The project uses BigQuery, but you can adapt it to any other data platform with slight modifications. Just follow the instructions in the README.&lt;/p&gt;\n\n&lt;p&gt;This project is designed to be straightforward yet adaptable, perfect for professionals with limited time and those eager to learn.&lt;/p&gt;\n\n&lt;p&gt;I look forward to your thoughts and suggestions for improvement!&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I\u2019m part of the Airbyte team, and it\u2019s my personal interest to help fellow engineers experiment and learn&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/58whu832dnac1.png?width=2388&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6c8a1dae20c2f3638c6818e9dbdad3e14735f4b6\"&gt;Prefect DAG&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18za481", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18za481/integrating_airbyte_prefect_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18za481/integrating_airbyte_prefect_dbt/", "subreddit_subscribers": 150592, "created_utc": 1704470189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Catch up to speed: Summer of 2023 Friend of mine told me to look into DE work as a career switch since I am already doing excel monkey work as an DA. Next 6 months I teach my self SQL, beginner Python and pass 2 Microsoft azure DE certs.\n\nCurrently applying to DE jobs and most of the jobs I am seeing seem to be like from consulting/contracting gigs. Are these legit in terms of job security? \n\nI would be leaving my current industry which is defense (think Lockheed or Boeing)  which I guess felt so \u201csecure\u201d because of all the govt fund we receive.\n\nTLDR: does anybody here work DE for a consulting/contracting gig, how\u2019s the job security? \n\nBonus question : if you don\u2019t work in consulting/contracting, what industry are you in and how\u2019s the job security? Thanks", "author_fullname": "t2_22q9pua0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Security", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zckja", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704476289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Catch up to speed: Summer of 2023 Friend of mine told me to look into DE work as a career switch since I am already doing excel monkey work as an DA. Next 6 months I teach my self SQL, beginner Python and pass 2 Microsoft azure DE certs.&lt;/p&gt;\n\n&lt;p&gt;Currently applying to DE jobs and most of the jobs I am seeing seem to be like from consulting/contracting gigs. Are these legit in terms of job security? &lt;/p&gt;\n\n&lt;p&gt;I would be leaving my current industry which is defense (think Lockheed or Boeing)  which I guess felt so \u201csecure\u201d because of all the govt fund we receive.&lt;/p&gt;\n\n&lt;p&gt;TLDR: does anybody here work DE for a consulting/contracting gig, how\u2019s the job security? &lt;/p&gt;\n\n&lt;p&gt;Bonus question : if you don\u2019t work in consulting/contracting, what industry are you in and how\u2019s the job security? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18zckja", "is_robot_indexable": true, "report_reasons": null, "author": "PoloParachutes", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zckja/job_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zckja/job_security/", "subreddit_subscribers": 150592, "created_utc": 1704476289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learning Machine Learning, I\u2019ve always been interested in **PyTorch** and its **Autograd engine** (which creates the backprop automatically).\n\nIn [this project](https://github.com/eduardoleao052/Autograd-from-scratch.git), I tried to **reimplement most of PyTorch** (including the Autograd) from scratch in a **well-documented, unit tested, and interpretable** way. It was really useful for me, and I hope it can help you understand Autograd better as well! \n\nHope you enjoy! \n\nGitHub repository [here](https://github.com/eduardoleao052/Autograd-from-scratch.git)!", "author_fullname": "t2_jxw66snkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made an Educational Autograd from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7b0l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704462565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning Machine Learning, I\u2019ve always been interested in &lt;strong&gt;PyTorch&lt;/strong&gt; and its &lt;strong&gt;Autograd engine&lt;/strong&gt; (which creates the backprop automatically).&lt;/p&gt;\n\n&lt;p&gt;In &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;this project&lt;/a&gt;, I tried to &lt;strong&gt;reimplement most of PyTorch&lt;/strong&gt; (including the Autograd) from scratch in a &lt;strong&gt;well-documented, unit tested, and interpretable&lt;/strong&gt; way. It was really useful for me, and I hope it can help you understand Autograd better as well! &lt;/p&gt;\n\n&lt;p&gt;Hope you enjoy! &lt;/p&gt;\n\n&lt;p&gt;GitHub repository &lt;a href=\"https://github.com/eduardoleao052/Autograd-from-scratch.git\"&gt;here&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?auto=webp&amp;s=b08e23957e84e2548f84ee1a2e3edd55eddcdbc0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=715035611c8f0749273ffc8fca0f864e07c111dc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=357e021032137fbfd977589f8642a71656f1beeb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fedb49819520758e10657a49e29c3cb01f6bacc6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=55e700e4bd3ad5eccbac38718f8edeee778531c3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=46188ed2d9e02ebb2805572b76d6768aebc9faee", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5AZSrVRRJagsjnn2okQkJHIS8OwX67V3TOVFAtEW7Wg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69357870a81c7ee5e7c70ac602acf833079a1b5a", "width": 1080, "height": 540}], "variants": {}, "id": "vF4SW5Y1xXGDQ_lFUvafehmQT8uNb-Di9I6Ty9lBl5g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "18z7b0l", "is_robot_indexable": true, "report_reasons": null, "author": "suspicious_beam", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z7b0l/i_made_an_educational_autograd_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z7b0l/i_made_an_educational_autograd_from_scratch/", "subreddit_subscribers": 150592, "created_utc": 1704462565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to learn Data engineering part, the warehousing, etl/elt part and everything involved in the process. I work in data governance and want to learn Data Engineering part too. How can I start? Any recommendations of books?", "author_fullname": "t2_i96qhyw4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get started with data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7bk9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704462608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn Data engineering part, the warehousing, etl/elt part and everything involved in the process. I work in data governance and want to learn Data Engineering part too. How can I start? Any recommendations of books?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18z7bk9", "is_robot_indexable": true, "report_reasons": null, "author": "mindmybusine55", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z7bk9/how_to_get_started_with_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z7bk9/how_to_get_started_with_data_engineering/", "subreddit_subscribers": 150592, "created_utc": 1704462608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, came across this joins cheat sheet, and it seems to me like 'album' table is not referenced in this query so how could album title be in the result. Am I missing something?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wxtn8alvglac1.png?width=645&amp;format=png&amp;auto=webp&amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7\n\nhttps://preview.redd.it/oizzzwvuglac1.png?width=642&amp;format=png&amp;auto=webp&amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce", "author_fullname": "t2_qjx23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this SQL joins cheat sheet correct?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 43, "top_awarded_type": null, "hide_score": false, "media_metadata": {"oizzzwvuglac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=51d1bd7d2631aec22f118fc71e3fa9dc86ee5ad6"}, {"y": 69, "x": 216, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1268595805b32f89a98298a501457c5260fca98a"}, {"y": 103, "x": 320, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d22d01d2e9e8670796742b79d6ae197530814147"}, {"y": 207, "x": 640, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=56810c60188611bd327ab53759ac4edde0b00f39"}], "s": {"y": 208, "x": 642, "u": "https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;format=png&amp;auto=webp&amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce"}, "id": "oizzzwvuglac1"}, "wxtn8alvglac1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a00ab3eb11e56cabd2cccb2985d55c927ec8860d"}, {"y": 66, "x": 216, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f57f1e320ecf1e44ab102b255c45631c3342448b"}, {"y": 99, "x": 320, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d3ee7366e5fa5326962047deaa34ea5bf73d5e5e"}, {"y": 198, "x": 640, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7667f729196b6254e650f8d4268ca8e40044721b"}], "s": {"y": 200, "x": 645, "u": "https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;format=png&amp;auto=webp&amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7"}, "id": "wxtn8alvglac1"}}, "name": "t3_18z3cl6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LrJgaKYu7kxOoyduyOuCvjVsernzGHh_eIkdkPfZ9CM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704448649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, came across this joins cheat sheet, and it seems to me like &amp;#39;album&amp;#39; table is not referenced in this query so how could album title be in the result. Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7\"&gt;https://preview.redd.it/wxtn8alvglac1.png?width=645&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b374aa7c2a7428657e255bdd85726dce3c760f7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce\"&gt;https://preview.redd.it/oizzzwvuglac1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9480fffa0842d02439d7cf7fd939bf02ad40c9ce&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18z3cl6", "is_robot_indexable": true, "report_reasons": null, "author": "In_Dust_We_Trust", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18z3cl6/is_this_sql_joins_cheat_sheet_correct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z3cl6/is_this_sql_joins_cheat_sheet_correct/", "subreddit_subscribers": 150592, "created_utc": 1704448649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I'm working as a Lead DBA/DBOps in my current organisation which is a UK based company and I have around 6+ YOE. I was looking for some guidance to what can be my career path in Data engineering.\n\nI have done alot of POC and implementation on ELT/ETL in the current organisation using Kafka/Airbyte/DBT(around 1.5yrs of hands on experience on these). And I'm starting to really get into ELT/ETL as they are much more engaging then the current DBA/DBOps work I do and my manager has taken that into consideration and have assigned alot of work related to such ELT/ETL. I have worked on Liquibase as well as a source control and automated deployments as well and its the main thing which is being used in our team for all the deployments of SQL scripts. I have experience on SQL development and automations using python, bash and powershell. In a nutshell even though my official designation is of a DBA but in my current organisation we do most of the ETL/ELT, sql development, automation, source/schema control and have all the freedom to spinup all the required ec2 instances for RND proposes. On the Datawarehousing front we also work all the livestreaming implementation to BigQuery. The databases I have worked on are MSSQL and MYSQL. \n\nSo was wondering what more do I need to learn so I can transition to more Data related career as I'm currently bored with the just the DBA work and would like to work on more ETL/ELT and eventually move into some senior position in DE and/or relevant profile. What does a typical senior/lead DE professional have experience in and if someone can guide me in the said learning materials.", "author_fullname": "t2_16uh2x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to transition to a DE from DBA/DBOps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18yvhxx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704421668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I&amp;#39;m working as a Lead DBA/DBOps in my current organisation which is a UK based company and I have around 6+ YOE. I was looking for some guidance to what can be my career path in Data engineering.&lt;/p&gt;\n\n&lt;p&gt;I have done alot of POC and implementation on ELT/ETL in the current organisation using Kafka/Airbyte/DBT(around 1.5yrs of hands on experience on these). And I&amp;#39;m starting to really get into ELT/ETL as they are much more engaging then the current DBA/DBOps work I do and my manager has taken that into consideration and have assigned alot of work related to such ELT/ETL. I have worked on Liquibase as well as a source control and automated deployments as well and its the main thing which is being used in our team for all the deployments of SQL scripts. I have experience on SQL development and automations using python, bash and powershell. In a nutshell even though my official designation is of a DBA but in my current organisation we do most of the ETL/ELT, sql development, automation, source/schema control and have all the freedom to spinup all the required ec2 instances for RND proposes. On the Datawarehousing front we also work all the livestreaming implementation to BigQuery. The databases I have worked on are MSSQL and MYSQL. &lt;/p&gt;\n\n&lt;p&gt;So was wondering what more do I need to learn so I can transition to more Data related career as I&amp;#39;m currently bored with the just the DBA work and would like to work on more ETL/ELT and eventually move into some senior position in DE and/or relevant profile. What does a typical senior/lead DE professional have experience in and if someone can guide me in the said learning materials.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18yvhxx", "is_robot_indexable": true, "report_reasons": null, "author": "KilluaHatake", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18yvhxx/how_to_transition_to_a_de_from_dbadbops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18yvhxx/how_to_transition_to_a_de_from_dbadbops/", "subreddit_subscribers": 150592, "created_utc": 1704421668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nHappy new year! I have a few friends that work at enterprise companies are pretty heavy in AWS and spending quite a lot on EMR. The topic came up on whether they should be switching those workloads from EMR over to Glue. Others have mentioned that they could save a lot of money by moving the workloads from EMR to Databricks. Does anyone have a perspective for companies trying to save money and achieve better performance on whether they should move to Glue or Databricks?\n\nI have started to go down the rabbit hole and have realized it is not as simple as I thought it would be...", "author_fullname": "t2_gm9wx145o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS EMR to AWS Glue or Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18ze6v4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704480311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Happy new year! I have a few friends that work at enterprise companies are pretty heavy in AWS and spending quite a lot on EMR. The topic came up on whether they should be switching those workloads from EMR over to Glue. Others have mentioned that they could save a lot of money by moving the workloads from EMR to Databricks. Does anyone have a perspective for companies trying to save money and achieve better performance on whether they should move to Glue or Databricks?&lt;/p&gt;\n\n&lt;p&gt;I have started to go down the rabbit hole and have realized it is not as simple as I thought it would be...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ze6v4", "is_robot_indexable": true, "report_reasons": null, "author": "NYCDataGuy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ze6v4/aws_emr_to_aws_glue_or_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ze6v4/aws_emr_to_aws_glue_or_databricks/", "subreddit_subscribers": 150592, "created_utc": 1704480311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Engineers, quite a few years have passed and recently I am in need to use SSIS for a personal project. But when I see all the data engineering software landscape it seems like we're completely in a new era (DBT, Kafka, Databricks, Trino, Presto, Spark etc).\n\n**-Which are the current days use cases and if it has long future'?**  \n**-Is it becoming a classic outdated tool?**  \n**-Which are the tools considered SSIS replacement?**", "author_fullname": "t2_9sk2qr0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Microsoft Integration Services (SSIS) still being used?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zdo9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704483395.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704479003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Engineers, quite a few years have passed and recently I am in need to use SSIS for a personal project. But when I see all the data engineering software landscape it seems like we&amp;#39;re completely in a new era (DBT, Kafka, Databricks, Trino, Presto, Spark etc).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;-Which are the current days use cases and if it has long future&amp;#39;?&lt;/strong&gt;&lt;br/&gt;\n&lt;strong&gt;-Is it becoming a classic outdated tool?&lt;/strong&gt;&lt;br/&gt;\n&lt;strong&gt;-Which are the tools considered SSIS replacement?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18zdo9c", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Flow_465", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zdo9c/is_microsoft_integration_services_ssis_still/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zdo9c/is_microsoft_integration_services_ssis_still/", "subreddit_subscribers": 150592, "created_utc": 1704479003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our security team has decreed that production data will no longer be permitted in dev environments (it will still be permitted in all other environments). The analysts on my team are upset because they don\u2019t believe they can create dashboards on the tiny static, synthetic dataset that\u2019s being proposed as a replacement, and given all the time series analysis they do I see their point (hard to compute sales in the last 30 days if your data only has timestamps from 2 years ago).\n\nHow do you handle this at your org? Do analysts build their reports solely against prod? Or have some other strategy?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dev data for reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z8lgr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704466153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our security team has decreed that production data will no longer be permitted in dev environments (it will still be permitted in all other environments). The analysts on my team are upset because they don\u2019t believe they can create dashboards on the tiny static, synthetic dataset that\u2019s being proposed as a replacement, and given all the time series analysis they do I see their point (hard to compute sales in the last 30 days if your data only has timestamps from 2 years ago).&lt;/p&gt;\n\n&lt;p&gt;How do you handle this at your org? Do analysts build their reports solely against prod? Or have some other strategy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z8lgr", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z8lgr/dev_data_for_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z8lgr/dev_data_for_reports/", "subreddit_subscribers": 150592, "created_utc": 1704466153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi community,\n\n**Context**: In my current company, we have a data-pipeline (one of the biggest pipelines), which in short works like this: \n\n* We get raw json events from Kafka dumped in s3. \n* We run a batch job (Airflow) daily, this job picks up the raw jsons in s3, enforces a data parser logic.\n* Data parser logic is simply, a service written in python where we explicitly define what attributes we want from raw json, these attributes are accordingly picked up from the json. There could be nested attributes as well which is taken care of.\n* Post this parsing, the final filtered json is loaded in a dataframe where later this parsed data is converted to CSV/parquet formats and dumped in s3 in another folder.\n* Later this processed CSV is loaded into tables, which is used for analytics, ml models, etc.\n\n**Problem**: \n\n* Today for every new event we generate and get from Kafka-S3 (raw event), we have to write a parser logic from scratch, if the event structure is different. In case of small changes in event we can update attributes we want to parse in code itself. \n* Post that we have to deploy the service changes (regardless of changes in a json event parser is small or big) which again takes time. \n* If there is someone from a different team publishing the event into Kafka and writes parser logic, he has to learn through our codebase, understand how to write a parser which is can be a time-taking learning curve.  \n\n**Solution** (I can think of):\n\n* Can we have a UI interface, where we abstract all this code (thereby making it language agnostic), and the engineer simply has to select the attributes from json (that could include nested attributes), and post selecting it, the batch job gets that information, applies the parser logic selected from UI and then runs rest of the pipeline as it is. \n* This could help us in avoiding tons of code for parsers, avoid or minimize deployments in for smaller changes, and as our data size grows I think it would be better to abstract things make it language agnostic and streamline stuff. There could be other benefits as well I suppose. \n\n**Other thoughts**: \n\n* Is there a smart way of doing it? \n* Do we have any open source alternatives here? \n* Or any good engineering blogs which has covered such/similar scenario?\n* How do big companies handle the humongous volume of data and parse relevant stuff into their tables or datalake, etc? \n\n&amp;#x200B;", "author_fullname": "t2_nbm4prsxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Big Data] How does data parsing happen in your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z0vko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704438742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;: In my current company, we have a data-pipeline (one of the biggest pipelines), which in short works like this: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We get raw json events from Kafka dumped in s3. &lt;/li&gt;\n&lt;li&gt;We run a batch job (Airflow) daily, this job picks up the raw jsons in s3, enforces a data parser logic.&lt;/li&gt;\n&lt;li&gt;Data parser logic is simply, a service written in python where we explicitly define what attributes we want from raw json, these attributes are accordingly picked up from the json. There could be nested attributes as well which is taken care of.&lt;/li&gt;\n&lt;li&gt;Post this parsing, the final filtered json is loaded in a dataframe where later this parsed data is converted to CSV/parquet formats and dumped in s3 in another folder.&lt;/li&gt;\n&lt;li&gt;Later this processed CSV is loaded into tables, which is used for analytics, ml models, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Today for every new event we generate and get from Kafka-S3 (raw event), we have to write a parser logic from scratch, if the event structure is different. In case of small changes in event we can update attributes we want to parse in code itself. &lt;/li&gt;\n&lt;li&gt;Post that we have to deploy the service changes (regardless of changes in a json event parser is small or big) which again takes time. &lt;/li&gt;\n&lt;li&gt;If there is someone from a different team publishing the event into Kafka and writes parser logic, he has to learn through our codebase, understand how to write a parser which is can be a time-taking learning curve.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt; (I can think of):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Can we have a UI interface, where we abstract all this code (thereby making it language agnostic), and the engineer simply has to select the attributes from json (that could include nested attributes), and post selecting it, the batch job gets that information, applies the parser logic selected from UI and then runs rest of the pipeline as it is. &lt;/li&gt;\n&lt;li&gt;This could help us in avoiding tons of code for parsers, avoid or minimize deployments in for smaller changes, and as our data size grows I think it would be better to abstract things make it language agnostic and streamline stuff. There could be other benefits as well I suppose. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Other thoughts&lt;/strong&gt;: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is there a smart way of doing it? &lt;/li&gt;\n&lt;li&gt;Do we have any open source alternatives here? &lt;/li&gt;\n&lt;li&gt;Or any good engineering blogs which has covered such/similar scenario?&lt;/li&gt;\n&lt;li&gt;How do big companies handle the humongous volume of data and parse relevant stuff into their tables or datalake, etc? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z0vko", "is_robot_indexable": true, "report_reasons": null, "author": "jarusv7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z0vko/big_data_how_does_data_parsing_happen_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z0vko/big_data_how_does_data_parsing_happen_in_your/", "subreddit_subscribers": 150592, "created_utc": 1704438742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will try not to dox myself but the end goal for me is to end up as a Senior DE at a large tech company. At the moment I'm ambivalent on whether this results in Data Platform Engineering or Data Analytics Engineering.\n\nHere is my general framework for studying:\n\n1. LC Easy/Medium (Arrays &amp; Hashing, Two Pointers, Sliding Window, Stack, Binary Search, try to solve in 20-25 minutes with no/minimal help)\n2. SQL Medium/Hard (Try to solve in 3-5 minutes with no/minimal help)\n3. Data Modeling (Identify business needs using Product Sense and create a Star/Snowflake schema from this)\n4. Behavioral (standard STAR answers)\n\nI am decidedly not good at algorithmic questions, which is part of the reason why I transitioned to DE (also I think it's cooler, among other things). Is this a good framework to abide by to target dedicated DE roles at FAANG+ companies (I specifically have Meta and Amazon in mind)? Any comments or insight would be welcomed.", "author_fullname": "t2_o3ojm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for DE Interviews at FAANG+ companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18zfz14", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704484799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will try not to dox myself but the end goal for me is to end up as a Senior DE at a large tech company. At the moment I&amp;#39;m ambivalent on whether this results in Data Platform Engineering or Data Analytics Engineering.&lt;/p&gt;\n\n&lt;p&gt;Here is my general framework for studying:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;LC Easy/Medium (Arrays &amp;amp; Hashing, Two Pointers, Sliding Window, Stack, Binary Search, try to solve in 20-25 minutes with no/minimal help)&lt;/li&gt;\n&lt;li&gt;SQL Medium/Hard (Try to solve in 3-5 minutes with no/minimal help)&lt;/li&gt;\n&lt;li&gt;Data Modeling (Identify business needs using Product Sense and create a Star/Snowflake schema from this)&lt;/li&gt;\n&lt;li&gt;Behavioral (standard STAR answers)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am decidedly not good at algorithmic questions, which is part of the reason why I transitioned to DE (also I think it&amp;#39;s cooler, among other things). Is this a good framework to abide by to target dedicated DE roles at FAANG+ companies (I specifically have Meta and Amazon in mind)? Any comments or insight would be welcomed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18zfz14", "is_robot_indexable": true, "report_reasons": null, "author": "KingTyranitar", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zfz14/preparing_for_de_interviews_at_faang_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zfz14/preparing_for_de_interviews_at_faang_companies/", "subreddit_subscribers": 150592, "created_utc": 1704484799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I've got this personal finance webscraper project I'm building and I'd like to take it severless so it just goes without worry. My current issue is trying to get selenium to run on aws lambda and I see a number of approaches online, but not sure what's the best approach to take. Can I just upload the library with the rest of my code? Should I be doing this on Docker?\n\nThanks!", "author_fullname": "t2_3k4h7uai", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running selenium on aws lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18zfat6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704483114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;ve got this personal finance webscraper project I&amp;#39;m building and I&amp;#39;d like to take it severless so it just goes without worry. My current issue is trying to get selenium to run on aws lambda and I see a number of approaches online, but not sure what&amp;#39;s the best approach to take. Can I just upload the library with the rest of my code? Should I be doing this on Docker?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18zfat6", "is_robot_indexable": true, "report_reasons": null, "author": "peepoo123", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zfat6/running_selenium_on_aws_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zfat6/running_selenium_on_aws_lambda/", "subreddit_subscribers": 150592, "created_utc": 1704483114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Please don't ignore \ud83d\ude4f.  \nHey all, I want to learn Databricks for Machine learning starting from scratch, I want to complete some courses particularly related to MLOps (mlfow, feature store) etc. On the way there are some notebooks provided by Databricks that I want to use for LLM use cases.  \n**QUES**: My question is how much it is going to cost me? I have a very tight budget constraint. Is there any way to use hands-on data bricks without paying that much, I work at a small company, so they are not that helpful in this journey, so going for a 14-day trial version is not possible for me as I need way too much time to learn. Any type of help/suggestion is welcome.  \nP.S. My \"AI services\" company doesn't want to help me with this, they literally have money it's just that they don't want to spend on an employee like me, even asked them and they said no,and I earn hardly 200$ to 300$, but want to upskill myself. Sorry to be rude, but dont give me suggestion about my Job I cant change it and dont want to talk about it (Bond).  \nNote: This is my *first* time posting in this types of sub, if is there any mistakes or rules that I have broken, please let me know. But don't delete this post, I am in desperate need as majorly the projects are for Databricks and my manager just don't let me learn it. ", "author_fullname": "t2_foph9qub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn Databricks for ML in budget?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18ze3rf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704480088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please don&amp;#39;t ignore \ud83d\ude4f.&lt;br/&gt;\nHey all, I want to learn Databricks for Machine learning starting from scratch, I want to complete some courses particularly related to MLOps (mlfow, feature store) etc. On the way there are some notebooks provided by Databricks that I want to use for LLM use cases.&lt;br/&gt;\n&lt;strong&gt;QUES&lt;/strong&gt;: My question is how much it is going to cost me? I have a very tight budget constraint. Is there any way to use hands-on data bricks without paying that much, I work at a small company, so they are not that helpful in this journey, so going for a 14-day trial version is not possible for me as I need way too much time to learn. Any type of help/suggestion is welcome.&lt;br/&gt;\nP.S. My &amp;quot;AI services&amp;quot; company doesn&amp;#39;t want to help me with this, they literally have money it&amp;#39;s just that they don&amp;#39;t want to spend on an employee like me, even asked them and they said no,and I earn hardly 200$ to 300$, but want to upskill myself. Sorry to be rude, but dont give me suggestion about my Job I cant change it and dont want to talk about it (Bond).&lt;br/&gt;\nNote: This is my &lt;em&gt;first&lt;/em&gt; time posting in this types of sub, if is there any mistakes or rules that I have broken, please let me know. But don&amp;#39;t delete this post, I am in desperate need as majorly the projects are for Databricks and my manager just don&amp;#39;t let me learn it. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ze3rf", "is_robot_indexable": true, "report_reasons": null, "author": "Secret-nerd01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ze3rf/how_to_learn_databricks_for_ml_in_budget/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ze3rf/how_to_learn_databricks_for_ml_in_budget/", "subreddit_subscribers": 150592, "created_utc": 1704480088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings Everyone !  \nI am creating a Project Recommendation System using ML which will recommend exciting projects for engineering students. Project Topics will be related to different domains.  \nI am looking for a project dataset containing Title, Description, Keywords etc. dwhich will help me train my model, I am unable to find such dataset on kaggle or dataworld.   \n\n\nIf you guys are aware about any such dataset do let me know .  \nThanks !", "author_fullname": "t2_dp9ta1x4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Topics Dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ze0yd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704479893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings Everyone !&lt;br/&gt;\nI am creating a Project Recommendation System using ML which will recommend exciting projects for engineering students. Project Topics will be related to different domains.&lt;br/&gt;\nI am looking for a project dataset containing Title, Description, Keywords etc. dwhich will help me train my model, I am unable to find such dataset on kaggle or dataworld.   &lt;/p&gt;\n\n&lt;p&gt;If you guys are aware about any such dataset do let me know .&lt;br/&gt;\nThanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ze0yd", "is_robot_indexable": true, "report_reasons": null, "author": "mangoresoham", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ze0yd/project_topics_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ze0yd/project_topics_dataset/", "subreddit_subscribers": 150592, "created_utc": 1704479893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just hoping for some clarity or suggestions so thank you in advance\n\nWe have an existing dev catalog and a test catalog is soon to be created.  The current plan of action it seems is that once the new environment(catalog) is up we will be creating the schemas and tables based on ddl exported from dev, essentially the same method we used to create the schemas and tables manually in dev.  Is there a simpler and/or better method of creating the schemas and tables (with or without data from dev)?", "author_fullname": "t2_8st0puwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks - Best way to create test or prod catalog based on existing dev catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zcxm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704477200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just hoping for some clarity or suggestions so thank you in advance&lt;/p&gt;\n\n&lt;p&gt;We have an existing dev catalog and a test catalog is soon to be created.  The current plan of action it seems is that once the new environment(catalog) is up we will be creating the schemas and tables based on ddl exported from dev, essentially the same method we used to create the schemas and tables manually in dev.  Is there a simpler and/or better method of creating the schemas and tables (with or without data from dev)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18zcxm4", "is_robot_indexable": true, "report_reasons": null, "author": "in-Ron-Howards-voice", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zcxm4/databricks_best_way_to_create_test_or_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zcxm4/databricks_best_way_to_create_test_or_prod/", "subreddit_subscribers": 150592, "created_utc": 1704477200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not sure if this is the right group but I am trying to get data from an API JSON to a CSV file hosted online. I would like to CSV file name to be static so I can read it into Excel and have the API automated to run daily. \n\nDoes one know of a site(s) I can look at to achieve this. I have been looking at: Make, retool and nocodb", "author_fullname": "t2_6mt3uar3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "JSON to CSV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18zb1nw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704472498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if this is the right group but I am trying to get data from an API JSON to a CSV file hosted online. I would like to CSV file name to be static so I can read it into Excel and have the API automated to run daily. &lt;/p&gt;\n\n&lt;p&gt;Does one know of a site(s) I can look at to achieve this. I have been looking at: Make, retool and nocodb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18zb1nw", "is_robot_indexable": true, "report_reasons": null, "author": "bird_egg0", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18zb1nw/json_to_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18zb1nw/json_to_csv/", "subreddit_subscribers": 150592, "created_utc": 1704472498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a newer data engineer at a large health tech company and our company's ETL is mainly simple SSIS packages to load raw data, then extensive config tables in SQL containing snippets that are used to generate our transformations and subsequent loads entirely with dynamic SQL. \n\nIs this a design pattern any of you have heard of, or some SQL anti-pattern that went out of control? It seems like it would have been easier to debug if we had just used pandas since it has made working on our ETL pipelines a lot more difficult to get the hang of when Its not always obvious which table relates to which translation, or where validation takes place, but it at least has generally useful errors and a lot of validation behind the scenes.\n\nIs this a red flag or just a standard process I've never heard of?", "author_fullname": "t2_m1g1wym31", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL with extensive dynamic SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18za1m7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704473628.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704470000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a newer data engineer at a large health tech company and our company&amp;#39;s ETL is mainly simple SSIS packages to load raw data, then extensive config tables in SQL containing snippets that are used to generate our transformations and subsequent loads entirely with dynamic SQL. &lt;/p&gt;\n\n&lt;p&gt;Is this a design pattern any of you have heard of, or some SQL anti-pattern that went out of control? It seems like it would have been easier to debug if we had just used pandas since it has made working on our ETL pipelines a lot more difficult to get the hang of when Its not always obvious which table relates to which translation, or where validation takes place, but it at least has generally useful errors and a lot of validation behind the scenes.&lt;/p&gt;\n\n&lt;p&gt;Is this a red flag or just a standard process I&amp;#39;ve never heard of?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18za1m7", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Egg-561", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18za1m7/etl_with_extensive_dynamic_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18za1m7/etl_with_extensive_dynamic_sql/", "subreddit_subscribers": 150592, "created_utc": 1704470000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title\\^\n\nBut to be more specific, I'm trying to keep up with how hardware tech development that affects software tech development. \n\nThings like breakthoughs in CPU or storage, etc. \n\nAlso if you know of any educational people to follow that talk about hardware? I'm quite a novice. ", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommendations for people on Linkedin to follow to stay up to date with the hardware side of technology?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z9ku4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704468773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title^&lt;/p&gt;\n\n&lt;p&gt;But to be more specific, I&amp;#39;m trying to keep up with how hardware tech development that affects software tech development. &lt;/p&gt;\n\n&lt;p&gt;Things like breakthoughs in CPU or storage, etc. &lt;/p&gt;\n\n&lt;p&gt;Also if you know of any educational people to follow that talk about hardware? I&amp;#39;m quite a novice. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18z9ku4", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/18z9ku4/any_recommendations_for_people_on_linkedin_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z9ku4/any_recommendations_for_people_on_linkedin_to/", "subreddit_subscribers": 150592, "created_utc": 1704468773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nCurious if this golden goose might exist. Are there any open source apps that I can just spin up as a docker service, that offer a frontend for login and user account management in Postgres? Maybe with an `admin` page just for manually managing accounts, though ideally it should be able to manage accounts in an automated fashion.\n\nI would want a reverse proxy to send new sessions to this for login, and upon successful login redirect the user to the desired service (based on url).\n\nI guess it can work by sending any request without a valid session cookie to the authentication service. The user performs login and gets a session cookie. The reverse proxy then sends them to their desired application. Invite only, no sign up.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any quick and easy dockerized authentication apps that I can run with an app and reverse proxy, preferably persisting user accounts in Postgres?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18z9fbb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704468666.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704468376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Curious if this golden goose might exist. Are there any open source apps that I can just spin up as a docker service, that offer a frontend for login and user account management in Postgres? Maybe with an &lt;code&gt;admin&lt;/code&gt; page just for manually managing accounts, though ideally it should be able to manage accounts in an automated fashion.&lt;/p&gt;\n\n&lt;p&gt;I would want a reverse proxy to send new sessions to this for login, and upon successful login redirect the user to the desired service (based on url).&lt;/p&gt;\n\n&lt;p&gt;I guess it can work by sending any request without a valid session cookie to the authentication service. The user performs login and gets a session cookie. The reverse proxy then sends them to their desired application. Invite only, no sign up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18z9fbb", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z9fbb/are_there_any_quick_and_easy_dockerized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18z9fbb/are_there_any_quick_and_easy_dockerized/", "subreddit_subscribers": 150592, "created_utc": 1704468376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark 3.5 + Notebook Docker Image - alexmerced/spark35-notebook - For Practicing Spark Locally (youtube.com/@alexmerceddata)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_18z7c0d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/d3jg9cv9mmac1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/d3jg9cv9mmac1/DASH_96.mp4", "dash_url": "https://v.redd.it/d3jg9cv9mmac1/DASHPlaylist.mpd?a=1707079096%2CM2UwMzJjOTY1NGRhZjkwZDc3OTdlNjY0NTY3NzcwM2M4MmE5MTNjMTFkMjZmZDg0Njk1NjE5MWQ5NjNhNzMzMQ%3D%3D&amp;v=1&amp;f=sd", "duration": 414, "hls_url": "https://v.redd.it/d3jg9cv9mmac1/HLSPlaylist.m3u8?a=1707079096%2CYjcyZjgyM2M1NDM1YTU2OGM4MjVlOTIyZmZjNTk1NTBhOGRhZWMxZWI3NDBjMWJmNjlhMGZkZjMxZjM5MDIwYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=fc352d471d4adf586ee1a48b55a55d80734e31dd", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704462642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/d3jg9cv9mmac1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?format=pjpg&amp;auto=webp&amp;s=c393f9878953c98f47ab6bb53955dd798958eca3", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=997eac41370b3d148e1c2caf694177adf28f7125", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7b2dd8203f34ce579421bf6085040752705c62d0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5ee66917fc8a2987ffdfaf058e3d244f73dc3753", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f6b6ca2a29f7abff6bd1de065360592ecb1a9a00", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3898f4940cf197e8de928e0d934dd1b436382ac7", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=95b3a0b0c09f81a95c934458660c3a3feb9ec0be", "width": 1080, "height": 607}], "variants": {}, "id": "Z3R4OXhvamltbWFjMfSuwtMFsz81_YvBeCujB9YP6NmQY-Q3EZ8LTnVSHDmg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18z7c0d", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18z7c0d/apache_spark_35_notebook_docker_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/d3jg9cv9mmac1", "subreddit_subscribers": 150592, "created_utc": 1704462642.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/d3jg9cv9mmac1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/d3jg9cv9mmac1/DASH_96.mp4", "dash_url": "https://v.redd.it/d3jg9cv9mmac1/DASHPlaylist.mpd?a=1707079096%2CM2UwMzJjOTY1NGRhZjkwZDc3OTdlNjY0NTY3NzcwM2M4MmE5MTNjMTFkMjZmZDg0Njk1NjE5MWQ5NjNhNzMzMQ%3D%3D&amp;v=1&amp;f=sd", "duration": 414, "hls_url": "https://v.redd.it/d3jg9cv9mmac1/HLSPlaylist.m3u8?a=1707079096%2CYjcyZjgyM2M1NDM1YTU2OGM4MjVlOTIyZmZjNTk1NTBhOGRhZWMxZWI3NDBjMWJmNjlhMGZkZjMxZjM5MDIwYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}], "before": null}}