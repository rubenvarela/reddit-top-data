{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I used to work at an extremely big company (actually one of the biggest corps in the world) as a data engineer. Their offer was great, great salary, fully remote and other nice perks.\n\nI joined in and my first thought was how incredibly disorganized everything was. There wasn't even like an internal tooling to check your organization members. I only knew who my direct boss was, but I had no idea about any further hierarchy or even who my other teammates were.\n\nIt took them literally around a month and a half for them to assign work to me. Despite being part of an established team, I was \"loaned\" to another team led by a contractor and this guy was completely unaware about my capacities, so he was not able to properly assign work to me because he just couldn't find a task that fit me. The work I was assigned was literally just writing view definitions with SELECTs and JOINs. They'd give me a humongous Excel listing the columns they wanted, and their datatypes, but it was a major PITA because the amount of columns was huge, and every single one of them had an encoded name, so I was essentially modeling data from a blackbox. I NEVER knew what this data was, who was its consumer, or what could they do with it.\n\nTo this day, I'm still not sure what these people were doing, as in, what was being developed? What did the pipelines process? Were there even pipelines? No clue, all I I did was looking at an Impala UI and writing SELECT.\n\nNeedless to say, I left pretty fast. Happy to be at a place where you're actually aware of what is going on.", "author_fullname": "t2_s75gwyxxt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was your DE job from hell?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ac9fpf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 65, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706357153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to work at an extremely big company (actually one of the biggest corps in the world) as a data engineer. Their offer was great, great salary, fully remote and other nice perks.&lt;/p&gt;\n\n&lt;p&gt;I joined in and my first thought was how incredibly disorganized everything was. There wasn&amp;#39;t even like an internal tooling to check your organization members. I only knew who my direct boss was, but I had no idea about any further hierarchy or even who my other teammates were.&lt;/p&gt;\n\n&lt;p&gt;It took them literally around a month and a half for them to assign work to me. Despite being part of an established team, I was &amp;quot;loaned&amp;quot; to another team led by a contractor and this guy was completely unaware about my capacities, so he was not able to properly assign work to me because he just couldn&amp;#39;t find a task that fit me. The work I was assigned was literally just writing view definitions with SELECTs and JOINs. They&amp;#39;d give me a humongous Excel listing the columns they wanted, and their datatypes, but it was a major PITA because the amount of columns was huge, and every single one of them had an encoded name, so I was essentially modeling data from a blackbox. I NEVER knew what this data was, who was its consumer, or what could they do with it.&lt;/p&gt;\n\n&lt;p&gt;To this day, I&amp;#39;m still not sure what these people were doing, as in, what was being developed? What did the pipelines process? Were there even pipelines? No clue, all I I did was looking at an Impala UI and writing SELECT.&lt;/p&gt;\n\n&lt;p&gt;Needless to say, I left pretty fast. Happy to be at a place where you&amp;#39;re actually aware of what is going on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ac9fpf", "is_robot_indexable": true, "report_reasons": null, "author": "yourAvgSE", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ac9fpf/what_was_your_de_job_from_hell/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ac9fpf/what_was_your_de_job_from_hell/", "subreddit_subscribers": 156318, "created_utc": 1706357153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let me tell you all my story. \nI am currently a mid level data engineer in a middle size retail company. The company is quite stable and have public stock. \n\nThe reason why I considering cloud data engineer  is because the market where I am right now is very heavy into cloud and spark. So if i need to advance my paygrade I need to have experience with these field.\n\nThe problem is my company does everything on premise. So most thing will do via python, SQL with some legacy cron but mostly using Airflow to orchestrate thing.   Also some use CDC Debezium, Kafka for some critical streaming data.   I also provide dashboard with alert daily in the form of Superset  also.\n\nThere is no spark usage because the data is not that big and the cost and infra need for it outweight ours need at the moment. Some data do exist in Google BigQuery but thats the reponsibility of other team. I do ingest it for some case.\n\nHow would I gain 'actual' experience for those fields? I do study and does some demo workshop pipeline with AWS, Google and Azure but its all very basic with static data.\n\nAs for spark i do pratice with my personal project and make it as custom docker image. But again it not the same as what you will face in actual work environment right?\n\nThank for taking your time to read and for any advice. Sorry if something might seem weird as english is not my native language.", "author_fullname": "t2_5hb3w8bs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you break into cloud data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1accv8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706368216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let me tell you all my story. \nI am currently a mid level data engineer in a middle size retail company. The company is quite stable and have public stock. &lt;/p&gt;\n\n&lt;p&gt;The reason why I considering cloud data engineer  is because the market where I am right now is very heavy into cloud and spark. So if i need to advance my paygrade I need to have experience with these field.&lt;/p&gt;\n\n&lt;p&gt;The problem is my company does everything on premise. So most thing will do via python, SQL with some legacy cron but mostly using Airflow to orchestrate thing.   Also some use CDC Debezium, Kafka for some critical streaming data.   I also provide dashboard with alert daily in the form of Superset  also.&lt;/p&gt;\n\n&lt;p&gt;There is no spark usage because the data is not that big and the cost and infra need for it outweight ours need at the moment. Some data do exist in Google BigQuery but thats the reponsibility of other team. I do ingest it for some case.&lt;/p&gt;\n\n&lt;p&gt;How would I gain &amp;#39;actual&amp;#39; experience for those fields? I do study and does some demo workshop pipeline with AWS, Google and Azure but its all very basic with static data.&lt;/p&gt;\n\n&lt;p&gt;As for spark i do pratice with my personal project and make it as custom docker image. But again it not the same as what you will face in actual work environment right?&lt;/p&gt;\n\n&lt;p&gt;Thank for taking your time to read and for any advice. Sorry if something might seem weird as english is not my native language.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1accv8x", "is_robot_indexable": true, "report_reasons": null, "author": "vclz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1accv8x/how_would_you_break_into_cloud_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1accv8x/how_would_you_break_into_cloud_data_engineer/", "subreddit_subscribers": 156318, "created_utc": 1706368216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm contacting this incredible community for collective wisdom and a pep talk. Here's the gist:\n\nI've been in the data engineering game for about 7 years now, starting my journey at a well-known bank where I cut my teeth on all things data \u2013 from Spark  Scala, Hive, Hadoop, Kafka to Kibana. I moved up the ranks, eventually taking on a tech lead role and entering the data pipeline wizardry.\n\nFast forward, I made the leap from a stable, permanent job to the world of freelancing. It's been a wild ride with some dummy projects (but short-term), but the freedom/money was great at first.\n\nBut here's the twist \u2013 I've recently started a family, and the timing couldn't be more challenging. When riding solo, I was on top of my game, but now that I need stability more than ever, I'm in troubled waters.\n\nSince 2021, I've felt my skills stagnating, and I'm not the interview champ I once was. It's like I've lost my mojo, and it's hitting me hard, especially when my family is counting on me. The industry has sprinted ahead (DBT, ML, Cloud Certs), and I'm a few paces behind, trying to catch up.\n\nHas anyone faced a similar career vs. family challenge? How did you handle it?\n- Tips for upskilling and staying relevant in the freelance market while juggling family life?\n\nFor context, my background is heavy in data processing and pipeline development. Still, while working on premise, I did a lot of coding and data product builds (we still needed to get these new cloud services features without paying a provider).\n\nI'm all ears for any advice or resources.", "author_fullname": "t2_vncr806l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hit a Rough Patch in Data Engineering Mid Career Life Amidst New Family Responsibilities \u2013 Need Advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acb6bb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706363195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m contacting this incredible community for collective wisdom and a pep talk. Here&amp;#39;s the gist:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been in the data engineering game for about 7 years now, starting my journey at a well-known bank where I cut my teeth on all things data \u2013 from Spark  Scala, Hive, Hadoop, Kafka to Kibana. I moved up the ranks, eventually taking on a tech lead role and entering the data pipeline wizardry.&lt;/p&gt;\n\n&lt;p&gt;Fast forward, I made the leap from a stable, permanent job to the world of freelancing. It&amp;#39;s been a wild ride with some dummy projects (but short-term), but the freedom/money was great at first.&lt;/p&gt;\n\n&lt;p&gt;But here&amp;#39;s the twist \u2013 I&amp;#39;ve recently started a family, and the timing couldn&amp;#39;t be more challenging. When riding solo, I was on top of my game, but now that I need stability more than ever, I&amp;#39;m in troubled waters.&lt;/p&gt;\n\n&lt;p&gt;Since 2021, I&amp;#39;ve felt my skills stagnating, and I&amp;#39;m not the interview champ I once was. It&amp;#39;s like I&amp;#39;ve lost my mojo, and it&amp;#39;s hitting me hard, especially when my family is counting on me. The industry has sprinted ahead (DBT, ML, Cloud Certs), and I&amp;#39;m a few paces behind, trying to catch up.&lt;/p&gt;\n\n&lt;p&gt;Has anyone faced a similar career vs. family challenge? How did you handle it?\n- Tips for upskilling and staying relevant in the freelance market while juggling family life?&lt;/p&gt;\n\n&lt;p&gt;For context, my background is heavy in data processing and pipeline development. Still, while working on premise, I did a lot of coding and data product builds (we still needed to get these new cloud services features without paying a provider).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m all ears for any advice or resources.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1acb6bb", "is_robot_indexable": true, "report_reasons": null, "author": "SpiritedSparrow8314", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acb6bb/hit_a_rough_patch_in_data_engineering_mid_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acb6bb/hit_a_rough_patch_in_data_engineering_mid_career/", "subreddit_subscribers": 156318, "created_utc": 1706363195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!  \n\n\nFirst of all, all my apologies if that question has been asked before.\n\nI need to design a data platform on GCP.     \nI gave some thoughts about the possible ingestion and aggregation approaches.    \nIn the past I used a full BigQuery approach (Option 2 below).    \nI was wondering if keeping the raw and staging data in Cloud Storage and using Spark for transformation could make sense.    \nI think it can be great because of cost and being cloud agnostic. In that scenario the Data Warehouse will be split between Cloud Storage and BigQuery.\n\nDo you guys have any experience with using external tables and Cloud Storage + Spark compared to a full Big Query Data Warehouse approach?  \nHow about the cost?\n\n## 1) First Option\n\n* The csv/json files will be ingested in a Cloud Storage Bucket.\n* The csv/json files can be read and written in parquet format in another bucket (staging area).\n* Data transformations are done with Spark.\n* The resulting transformations (usable by data users &amp; BI tools) are accessible through BigQuery external (or internal) tables.\n\n## 2) Second Option\n\n* The csv/json files will be ingested in a Cloud Storage Bucket.\n* The data are ingested into BigQuery as raw tables (staging area).\n* Data transformations are done with BigQuery (SQL) directly.\n* The resulting transformations (usable by data users &amp; BI tools) are accessible through BigQuery tables.\n\n## 3) Third Option\n\n* The csv/json files will be ingested in a Cloud Storage Bucket.\n* The data are ingested into BigQuery as raw external tables (staging area).\n* Data transformations are done with BigQuery (SQL) directly.\n* The resulting transformations (usable by data users &amp; BI tools) are accessible through BigQuery external tables.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/db1jzh7l23fc1.png?width=1357&amp;format=png&amp;auto=webp&amp;s=9d404ee6da16310d3f7b05a62b9b6429f5bbaf79", "author_fullname": "t2_3wj092gm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse approaches on GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "media_metadata": {"db1jzh7l23fc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/db1jzh7l23fc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=46f4dbb73b260d388f526fd095ece8f50b807f08"}, {"y": 86, "x": 216, "u": "https://preview.redd.it/db1jzh7l23fc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=af7caa338cc489513d1258f458bd86d13554c4d7"}, {"y": 128, "x": 320, "u": "https://preview.redd.it/db1jzh7l23fc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=061f6cba8f257bbf529ebf9e29d5d891b4f8a8fb"}, {"y": 257, "x": 640, "u": "https://preview.redd.it/db1jzh7l23fc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=510d4b629ae13823fd9a44f98feca35eaa0ce3f9"}, {"y": 386, "x": 960, "u": "https://preview.redd.it/db1jzh7l23fc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f8ce3633358005a008cd3b761cbad7ff99317cdb"}, {"y": 434, "x": 1080, "u": "https://preview.redd.it/db1jzh7l23fc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2d38cb33c54b958ad46fa605f3650a90ac935164"}], "s": {"y": 546, "x": 1357, "u": "https://preview.redd.it/db1jzh7l23fc1.png?width=1357&amp;format=png&amp;auto=webp&amp;s=9d404ee6da16310d3f7b05a62b9b6429f5bbaf79"}, "id": "db1jzh7l23fc1"}}, "name": "t3_1acqprq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/y_gFdwHAOULgxo5xxRYrKm0mmBevHsnxN4PNFAfVSxk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706405232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!  &lt;/p&gt;\n\n&lt;p&gt;First of all, all my apologies if that question has been asked before.&lt;/p&gt;\n\n&lt;p&gt;I need to design a data platform on GCP.&lt;br/&gt;\nI gave some thoughts about the possible ingestion and aggregation approaches.&lt;br/&gt;\nIn the past I used a full BigQuery approach (Option 2 below).&lt;br/&gt;\nI was wondering if keeping the raw and staging data in Cloud Storage and using Spark for transformation could make sense.&lt;br/&gt;\nI think it can be great because of cost and being cloud agnostic. In that scenario the Data Warehouse will be split between Cloud Storage and BigQuery.&lt;/p&gt;\n\n&lt;p&gt;Do you guys have any experience with using external tables and Cloud Storage + Spark compared to a full Big Query Data Warehouse approach?&lt;br/&gt;\nHow about the cost?&lt;/p&gt;\n\n&lt;h2&gt;1) First Option&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The csv/json files will be ingested in a Cloud Storage Bucket.&lt;/li&gt;\n&lt;li&gt;The csv/json files can be read and written in parquet format in another bucket (staging area).&lt;/li&gt;\n&lt;li&gt;Data transformations are done with Spark.&lt;/li&gt;\n&lt;li&gt;The resulting transformations (usable by data users &amp;amp; BI tools) are accessible through BigQuery external (or internal) tables.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;2) Second Option&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The csv/json files will be ingested in a Cloud Storage Bucket.&lt;/li&gt;\n&lt;li&gt;The data are ingested into BigQuery as raw tables (staging area).&lt;/li&gt;\n&lt;li&gt;Data transformations are done with BigQuery (SQL) directly.&lt;/li&gt;\n&lt;li&gt;The resulting transformations (usable by data users &amp;amp; BI tools) are accessible through BigQuery tables.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;3) Third Option&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The csv/json files will be ingested in a Cloud Storage Bucket.&lt;/li&gt;\n&lt;li&gt;The data are ingested into BigQuery as raw external tables (staging area).&lt;/li&gt;\n&lt;li&gt;Data transformations are done with BigQuery (SQL) directly.&lt;/li&gt;\n&lt;li&gt;The resulting transformations (usable by data users &amp;amp; BI tools) are accessible through BigQuery external tables.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/db1jzh7l23fc1.png?width=1357&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9d404ee6da16310d3f7b05a62b9b6429f5bbaf79\"&gt;https://preview.redd.it/db1jzh7l23fc1.png?width=1357&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9d404ee6da16310d3f7b05a62b9b6429f5bbaf79&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1acqprq", "is_robot_indexable": true, "report_reasons": null, "author": "yinshangyi", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acqprq/data_warehouse_approaches_on_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acqprq/data_warehouse_approaches_on_gcp/", "subreddit_subscribers": 156318, "created_utc": 1706405232.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I am the data guy at my company. I have a Data Analyst working under me, but other than that we are the only people focused on data-related tasks. We currently pull all data from reporting databases, which are just replicas of the system's OLTP database. This, predictably, has been hampering us as we grow and more operations folks want to obtain data, but don't understand the DB structure and/or the database fails at retrieving relevant data points in a reasonable amount of time. We do all our reporting in Metabase.\n\nI am putting together some relatively simple ETL pipelines to create a DW / Data Lake and would like to get some feedback on architectures that I am exploring:\n\n[Data Lake Architecture](https://preview.redd.it/jm5o8e9cqzec1.png?width=1245&amp;format=png&amp;auto=webp&amp;s=c8bf6dbd2934a763786aec59b82b6d43541c4445)\n\n[Data Warehouse Architecture](https://preview.redd.it/bvn8zygeqzec1.png?width=1188&amp;format=png&amp;auto=webp&amp;s=44b5e1bdfaacb0351da4036bb09df3a57ae8e325)\n\nOne thing I am particularly unsure about is the number of EC2 instances running Airbyte / dbt / Airflow. Do we want these running separately? That seems harder to get them to communicate with each other. Should I just run them all on one EC2?\n\nOverall, I am leaning to the Data Warehouse Architecture route. It seems easier to implement as it doesn't involve Glue and Athena. The reason to not use redshift is cost and its probably not necessary. Our DB is in the 100s of GB range so its not a massive amount of data. Any thoughts? I'm not married to either architecture so I'm open to alternative options. ", "author_fullname": "t2_sy8h9nynj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advise - Which is better?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 88, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bvn8zygeqzec1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/bvn8zygeqzec1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=41953acbe701fcdd5d6723309fa722640ef6ec7e"}, {"y": 140, "x": 216, "u": "https://preview.redd.it/bvn8zygeqzec1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c2291dcf5ca0b8deec1c388c7cc67f49c563d70b"}, {"y": 207, "x": 320, "u": "https://preview.redd.it/bvn8zygeqzec1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1dffc78601060e0085845005fdc594a2b7a71172"}, {"y": 414, "x": 640, "u": "https://preview.redd.it/bvn8zygeqzec1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d3ef932a637192c8abc6c09110fdf694476ba2c"}, {"y": 622, "x": 960, "u": "https://preview.redd.it/bvn8zygeqzec1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d624358b6afdca0380a6cd7b54c17d251cb1ff86"}, {"y": 700, "x": 1080, "u": "https://preview.redd.it/bvn8zygeqzec1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd333f46f8d321942186aa55809c84ac0f06fc4e"}], "s": {"y": 770, "x": 1188, "u": "https://preview.redd.it/bvn8zygeqzec1.png?width=1188&amp;format=png&amp;auto=webp&amp;s=44b5e1bdfaacb0351da4036bb09df3a57ae8e325"}, "id": "bvn8zygeqzec1"}, "jm5o8e9cqzec1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 68, "x": 108, "u": "https://preview.redd.it/jm5o8e9cqzec1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3411306d66ee35ccc9e81850e062a8bcc0fd3ad1"}, {"y": 137, "x": 216, "u": "https://preview.redd.it/jm5o8e9cqzec1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d160e2e3bbca044811e67255d968012094db79bf"}, {"y": 203, "x": 320, "u": "https://preview.redd.it/jm5o8e9cqzec1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b6434adc9814d9c789a419043701d2003683a65a"}, {"y": 406, "x": 640, "u": "https://preview.redd.it/jm5o8e9cqzec1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e23b2ff15fed16fdee3f9f864c4c2e5f26857b0"}, {"y": 609, "x": 960, "u": "https://preview.redd.it/jm5o8e9cqzec1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d704ed0377dd0044a2b5b79f38fb457017443d55"}, {"y": 686, "x": 1080, "u": "https://preview.redd.it/jm5o8e9cqzec1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=720871f6d6797d499c91fd4b0edbd21b0093d56e"}], "s": {"y": 791, "x": 1245, "u": "https://preview.redd.it/jm5o8e9cqzec1.png?width=1245&amp;format=png&amp;auto=webp&amp;s=c8bf6dbd2934a763786aec59b82b6d43541c4445"}, "id": "jm5o8e9cqzec1"}}, "name": "t3_1acbse2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/73YrjjBxUNQtnFfR5wF5kPlH5DFzZKaWXVvvnlW91Pk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706365076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I am the data guy at my company. I have a Data Analyst working under me, but other than that we are the only people focused on data-related tasks. We currently pull all data from reporting databases, which are just replicas of the system&amp;#39;s OLTP database. This, predictably, has been hampering us as we grow and more operations folks want to obtain data, but don&amp;#39;t understand the DB structure and/or the database fails at retrieving relevant data points in a reasonable amount of time. We do all our reporting in Metabase.&lt;/p&gt;\n\n&lt;p&gt;I am putting together some relatively simple ETL pipelines to create a DW / Data Lake and would like to get some feedback on architectures that I am exploring:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jm5o8e9cqzec1.png?width=1245&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c8bf6dbd2934a763786aec59b82b6d43541c4445\"&gt;Data Lake Architecture&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bvn8zygeqzec1.png?width=1188&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=44b5e1bdfaacb0351da4036bb09df3a57ae8e325\"&gt;Data Warehouse Architecture&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;One thing I am particularly unsure about is the number of EC2 instances running Airbyte / dbt / Airflow. Do we want these running separately? That seems harder to get them to communicate with each other. Should I just run them all on one EC2?&lt;/p&gt;\n\n&lt;p&gt;Overall, I am leaning to the Data Warehouse Architecture route. It seems easier to implement as it doesn&amp;#39;t involve Glue and Athena. The reason to not use redshift is cost and its probably not necessary. Our DB is in the 100s of GB range so its not a massive amount of data. Any thoughts? I&amp;#39;m not married to either architecture so I&amp;#39;m open to alternative options. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1acbse2", "is_robot_indexable": true, "report_reasons": null, "author": "TetrapodTyranny", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acbse2/looking_for_advise_which_is_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acbse2/looking_for_advise_which_is_better/", "subreddit_subscribers": 156318, "created_utc": 1706365076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is the job market for data engineering in south east Asia now? Or is it still bad as last year? I have been on market for six months now and not receiving any enquiries(not even HR calls).\n\n\nPS: I am a foreigner to these countries and so my job chances are limited to the opportunities which can sponsor visas in those countries.", "author_fullname": "t2_o51po378", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the job market up for DE in south east Asia now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ac74ox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706347700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is the job market for data engineering in south east Asia now? Or is it still bad as last year? I have been on market for six months now and not receiving any enquiries(not even HR calls).&lt;/p&gt;\n\n&lt;p&gt;PS: I am a foreigner to these countries and so my job chances are limited to the opportunities which can sponsor visas in those countries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ac74ox", "is_robot_indexable": true, "report_reasons": null, "author": "NeighborhoodCold5339", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ac74ox/is_the_job_market_up_for_de_in_south_east_asia_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ac74ox/is_the_job_market_up_for_de_in_south_east_asia_now/", "subreddit_subscribers": 156318, "created_utc": 1706347700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working for a client as an ETL developer who is using 1010data . The tool uses XML to do the transformations compared to current SQL based tools. Having a good grip on this tool, will it help me in future or should I look for other opportunities elsewhere?", "author_fullname": "t2_9y85ksm3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is 1010data still relevant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ac543u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706339494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working for a client as an ETL developer who is using 1010data . The tool uses XML to do the transformations compared to current SQL based tools. Having a good grip on this tool, will it help me in future or should I look for other opportunities elsewhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ac543u", "is_robot_indexable": true, "report_reasons": null, "author": "stinger_sks_22", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ac543u/is_1010data_still_relevant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ac543u/is_1010data_still_relevant/", "subreddit_subscribers": 156318, "created_utc": 1706339494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys our pipelines are migrating to the azure stack so ADF with Databricks spark transforms and then output to delta tables ADLS gen 2 storage and on to consumption mainly in Power BI.\n\nBut it looks like we'll be building the models very slightly differently in each PBI report which looks crazy inefficient to me. I think we should be building out common reusable data models for each function in our large corporate business.\n\nAre Common Data Models the answer here or is there another best practice we should be doing? No one seems to be thinking about shared data models in my org", "author_fullname": "t2_8lw2xwwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to use for shared data modelling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acghfv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706377752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys our pipelines are migrating to the azure stack so ADF with Databricks spark transforms and then output to delta tables ADLS gen 2 storage and on to consumption mainly in Power BI.&lt;/p&gt;\n\n&lt;p&gt;But it looks like we&amp;#39;ll be building the models very slightly differently in each PBI report which looks crazy inefficient to me. I think we should be building out common reusable data models for each function in our large corporate business.&lt;/p&gt;\n\n&lt;p&gt;Are Common Data Models the answer here or is there another best practice we should be doing? No one seems to be thinking about shared data models in my org&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1acghfv", "is_robot_indexable": true, "report_reasons": null, "author": "Secure_Bandicoot_576", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acghfv/what_to_use_for_shared_data_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acghfv/what_to_use_for_shared_data_modelling/", "subreddit_subscribers": 156318, "created_utc": 1706377752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\nHi,\nI currently work as a Business intelligence developer with my cogito,  clarity, caboodle, and revenue data model certs. I know that EPIC will be transitioning to azure in a couple years. I know BID cap out somewhere around 120k in my area.\n\nHow can I best prepare myself to be a data engineer within Healthcare? Should I prepare for DP 203 Microsoft certified azure data engineer and learn python? \nI want to be able to reach at least starting 125k+ fully remote salary in the midwest.\n\nThanks", "author_fullname": "t2_5x2dzayp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Epic report writer to data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acda11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706369355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI currently work as a Business intelligence developer with my cogito,  clarity, caboodle, and revenue data model certs. I know that EPIC will be transitioning to azure in a couple years. I know BID cap out somewhere around 120k in my area.&lt;/p&gt;\n\n&lt;p&gt;How can I best prepare myself to be a data engineer within Healthcare? Should I prepare for DP 203 Microsoft certified azure data engineer and learn python? \nI want to be able to reach at least starting 125k+ fully remote salary in the midwest.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1acda11", "is_robot_indexable": true, "report_reasons": null, "author": "Bionic50", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acda11/epic_report_writer_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acda11/epic_report_writer_to_data_engineer/", "subreddit_subscribers": 156318, "created_utc": 1706369355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Inputs\n\n* multiple teams with various hours available per month.\n* multiple projects with various hours to complete and months from the deadline.\n\nAssumption\n\n* project hours/month will not exceed team capacity.\n* month 1 in solution is next month (June 2024)\n\nIn the data below team A has 3 projects. The projects require 1000 monthly hours each (3000 hours divided by 3 months). Team A has 2000 monthly capacity hours to dedicate to any number of projects. I want to write code that will define the start month and then smartly know when to start the next project with that team until all projects are done. In the example, team A can do projects 1 and 2 simultaneously because it is below their capacity and start on project 3 in month 4 as project 1 wraps up and their capacity increases to a point where they can start working on project 3.\n\nProject Data\n\n|Project|Team|Priority|Month|Project Hours|\n|:-|:-|:-|:-|:-|\n|1|A|1|3|3000|\n|2|A|2|6|6000|\n|3|A|3|3|3000|\n|4|B|1|6|1500|\n\nTeam Capacity Dimension\n\n|Team|Monthly Capacity|\n|:-|:-|\n|a|2000|\n|b|2000|\n\nOutput\n\n|Project|Team|Month|\n|:-|:-|:-|\n|1|a|1|\n|1|a|2|\n|1|a|3|\n|2|a|1|\n|2|a|2|\n|2|a|3|\n|2|a|4|\n|2|a|5|\n|2|a|6|\n|3|a|4|\n|3|a|5|\n|3|a|6|\n|4|b|1|\n|4|b|2|\n|4|b|3|\n|4|b|4|\n|4|b|5|\n|4|b|6|\n\nI\u2019m thinking a loop and/ or an over (partition by,  order) would be my best option. Thoughts?\n\nThanks in advance, jamkgrif", "author_fullname": "t2_7dkzx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Define project start and end time by team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1acse7q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706412368.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706410368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Inputs&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;multiple teams with various hours available per month.&lt;/li&gt;\n&lt;li&gt;multiple projects with various hours to complete and months from the deadline.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Assumption&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;project hours/month will not exceed team capacity.&lt;/li&gt;\n&lt;li&gt;month 1 in solution is next month (June 2024)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In the data below team A has 3 projects. The projects require 1000 monthly hours each (3000 hours divided by 3 months). Team A has 2000 monthly capacity hours to dedicate to any number of projects. I want to write code that will define the start month and then smartly know when to start the next project with that team until all projects are done. In the example, team A can do projects 1 and 2 simultaneously because it is below their capacity and start on project 3 in month 4 as project 1 wraps up and their capacity increases to a point where they can start working on project 3.&lt;/p&gt;\n\n&lt;p&gt;Project Data&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Project&lt;/th&gt;\n&lt;th align=\"left\"&gt;Team&lt;/th&gt;\n&lt;th align=\"left\"&gt;Priority&lt;/th&gt;\n&lt;th align=\"left\"&gt;Month&lt;/th&gt;\n&lt;th align=\"left\"&gt;Project Hours&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;3000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;td align=\"left\"&gt;6000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;3000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;B&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;td align=\"left\"&gt;1500&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Team Capacity Dimension&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Team&lt;/th&gt;\n&lt;th align=\"left\"&gt;Monthly Capacity&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;2000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;b&lt;/td&gt;\n&lt;td align=\"left\"&gt;2000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Output&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Project&lt;/th&gt;\n&lt;th align=\"left\"&gt;Team&lt;/th&gt;\n&lt;th align=\"left\"&gt;Month&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;a&lt;/td&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;b&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;b&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;b&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;b&lt;/td&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;b&lt;/td&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;b&lt;/td&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I\u2019m thinking a loop and/ or an over (partition by,  order) would be my best option. Thoughts?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance, jamkgrif&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1acse7q", "is_robot_indexable": true, "report_reasons": null, "author": "jamkgrif", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acse7q/define_project_start_and_end_time_by_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acse7q/define_project_start_and_end_time_by_team/", "subreddit_subscribers": 156318, "created_utc": 1706410368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\nI\u2019m sorry to be mean , but offlate some of the weekly zoom calls have really bad speakers . There is a guy who wears Blippi glasses and when asked questions , he says the tutorial is in progress and asks the audience to follow his LinkedIn profile . It sounds more like he is interested in getting followers rather than he knowing the subject . I doubt he knows things about langchain, llama index , etc , when asked about it , he gives a nod and lame smile . These zoom calls were excellent when Akmal ran the show . I never missed Akmal\u2019s calls. Nowadays I get out of the call when that blippi joins . \n#singlestore #weeklycalls", "author_fullname": "t2_7v604kty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Singlestore Zoom call reviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aciszo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706383793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m sorry to be mean , but offlate some of the weekly zoom calls have really bad speakers . There is a guy who wears Blippi glasses and when asked questions , he says the tutorial is in progress and asks the audience to follow his LinkedIn profile . It sounds more like he is interested in getting followers rather than he knowing the subject . I doubt he knows things about langchain, llama index , etc , when asked about it , he gives a nod and lame smile . These zoom calls were excellent when Akmal ran the show . I never missed Akmal\u2019s calls. Nowadays I get out of the call when that blippi joins . &lt;/p&gt;\n\n&lt;h1&gt;singlestore #weeklycalls&lt;/h1&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aciszo", "is_robot_indexable": true, "report_reasons": null, "author": "plutobot-0203", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aciszo/singlestore_zoom_call_reviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aciszo/singlestore_zoom_call_reviews/", "subreddit_subscribers": 156318, "created_utc": 1706383793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a GitHub repo filled with scala code where the CI creates jar and submits to gcs bucket. Then airflow will use this jar. The jars in gcs bucket are timestamped. \n\nHow do I get airflow to use the latest jar always? Airflow python code in DAG which belongs to same GitHub repo is currently hard coded to a specific timestamp version and its tedious to constantly update it. Is there a way to just say, use the latest bucket timestamp for this jar name?", "author_fullname": "t2_f4rnp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use latest airflow jars?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ac4a9i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706336253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a GitHub repo filled with scala code where the CI creates jar and submits to gcs bucket. Then airflow will use this jar. The jars in gcs bucket are timestamped. &lt;/p&gt;\n\n&lt;p&gt;How do I get airflow to use the latest jar always? Airflow python code in DAG which belongs to same GitHub repo is currently hard coded to a specific timestamp version and its tedious to constantly update it. Is there a way to just say, use the latest bucket timestamp for this jar name?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ac4a9i", "is_robot_indexable": true, "report_reasons": null, "author": "alwaysSearching23", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ac4a9i/how_to_use_latest_airflow_jars/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ac4a9i/how_to_use_latest_airflow_jars/", "subreddit_subscribers": 156318, "created_utc": 1706336253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know the above two fields are completely different\u2026 but would love to get your valuable inputs if i have to choose between this two which will be the safe bet for long run? Thanks", "author_fullname": "t2_8cdpdjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career in Data Engineering vs Cybersecurity which one is/will be more demanding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ac9sco", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706358466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know the above two fields are completely different\u2026 but would love to get your valuable inputs if i have to choose between this two which will be the safe bet for long run? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ac9sco", "is_robot_indexable": true, "report_reasons": null, "author": "niaznishu", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ac9sco/career_in_data_engineering_vs_cybersecurity_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ac9sco/career_in_data_engineering_vs_cybersecurity_which/", "subreddit_subscribers": 156318, "created_utc": 1706358466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know it depends but say you're on a Junior role. How much of overtime or staying behind can I expect? \n\nAlso, how much of the job is about coding? Like how many hours do you spend programming? \n\nThanks", "author_fullname": "t2_rrtbk3gwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE is the dream job. How common are overtime?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acgj4m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706377873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it depends but say you&amp;#39;re on a Junior role. How much of overtime or staying behind can I expect? &lt;/p&gt;\n\n&lt;p&gt;Also, how much of the job is about coding? Like how many hours do you spend programming? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1acgj4m", "is_robot_indexable": true, "report_reasons": null, "author": "Timeframe98", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acgj4m/de_is_the_dream_job_how_common_are_overtime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acgj4m/de_is_the_dream_job_how_common_are_overtime/", "subreddit_subscribers": 156318, "created_utc": 1706377873.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}