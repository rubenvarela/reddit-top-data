{"kind": "Listing", "data": {"after": "t3_19d2m9p", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a company I would consider to be top-tier. Great pay for where I live, nice work culture, great people, and good upside potential (company could sell or do IPO in the next few years). But I just feel bored. It's not challenging anymore. When I came on board 6 months ago, I rebuilt everything from scratch and now it's all working almost flawlessly. Our team is small, and we've scaled efficiently so not created more work for ourselves. I do 2-3 hours of real work every day. I have 1-2 short meetings a day if that, answer questions, fix small things that break. I like to feel like I've done something at the end of the day, and more recently the past few months, this is rare. Honestly, most days I feel guilty for not working more. I take time during the day to listen to audiobooks (while working), I work out, take lunch with friends, or similar. It's the opposite of burnout. It's unnerving to not be busy or feel like I'm adding value.  \n\nIs anyone else's shop like this? What are your recommendations?", "author_fullname": "t2_12aazb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often do you get bored?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19d18sj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705945011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a company I would consider to be top-tier. Great pay for where I live, nice work culture, great people, and good upside potential (company could sell or do IPO in the next few years). But I just feel bored. It&amp;#39;s not challenging anymore. When I came on board 6 months ago, I rebuilt everything from scratch and now it&amp;#39;s all working almost flawlessly. Our team is small, and we&amp;#39;ve scaled efficiently so not created more work for ourselves. I do 2-3 hours of real work every day. I have 1-2 short meetings a day if that, answer questions, fix small things that break. I like to feel like I&amp;#39;ve done something at the end of the day, and more recently the past few months, this is rare. Honestly, most days I feel guilty for not working more. I take time during the day to listen to audiobooks (while working), I work out, take lunch with friends, or similar. It&amp;#39;s the opposite of burnout. It&amp;#39;s unnerving to not be busy or feel like I&amp;#39;m adding value.  &lt;/p&gt;\n\n&lt;p&gt;Is anyone else&amp;#39;s shop like this? What are your recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19d18sj", "is_robot_indexable": true, "report_reasons": null, "author": "ntdoyfanboy", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19d18sj/how_often_do_you_get_bored/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19d18sj/how_often_do_you_get_bored/", "subreddit_subscribers": 154964, "created_utc": 1705945011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys! seeking some advice on my data engineering career.\n\nLong story short: in 3 years I have had 4 different jobs. I left all of them. I don't know if I am asking too much to companies or I am the problem.\n\nLong story:\n\nI am in my mid 20s. I left all companies due to different factors (no pay raise, bad projects, bad management...). My longest job has been 9 months (actual job). Recruiters keep sending me offers but, would jumping so much affect me in the long run?\n\nAnother question I have: why do folks stay at a bad company? I have seen tons of tech employees working at a company they don't like for years. Obviously I am not saying just leave, but look for opportunities. It really amazes me.\n\nThose are my main points because I am starting to think that I am the problem and I should stay at a company although it doesn't have all the requirements I need...\n\nThoughts on this?", "author_fullname": "t2_p4nzh8v1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I too fussy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cxuav", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705936452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! seeking some advice on my data engineering career.&lt;/p&gt;\n\n&lt;p&gt;Long story short: in 3 years I have had 4 different jobs. I left all of them. I don&amp;#39;t know if I am asking too much to companies or I am the problem.&lt;/p&gt;\n\n&lt;p&gt;Long story:&lt;/p&gt;\n\n&lt;p&gt;I am in my mid 20s. I left all companies due to different factors (no pay raise, bad projects, bad management...). My longest job has been 9 months (actual job). Recruiters keep sending me offers but, would jumping so much affect me in the long run?&lt;/p&gt;\n\n&lt;p&gt;Another question I have: why do folks stay at a bad company? I have seen tons of tech employees working at a company they don&amp;#39;t like for years. Obviously I am not saying just leave, but look for opportunities. It really amazes me.&lt;/p&gt;\n\n&lt;p&gt;Those are my main points because I am starting to think that I am the problem and I should stay at a company although it doesn&amp;#39;t have all the requirements I need...&lt;/p&gt;\n\n&lt;p&gt;Thoughts on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19cxuav", "is_robot_indexable": true, "report_reasons": null, "author": "data_macrolide", "discussion_type": null, "num_comments": 81, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cxuav/am_i_too_fussy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cxuav/am_i_too_fussy/", "subreddit_subscribers": 154964, "created_utc": 1705936452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I see arguments from time to time that it\u2019s fine going straight into using spark, airflow, highly available rdbms, advanced git vc architectures, CI/CD, kubernetes, or whatever. The argument is typically that the designer expects the business to need to go this route eventually, and why design a system that you know you\u2019ll have to redesign later on for scalability reasons?\n\nThen there\u2019s the other argument that these systems are completely unnecessary for small time guys, despite the fact that they offer many unique quality-of-life features that aren\u2019t replicated elsewhere. The complexity of these systems alone seems to warrant a need for implementation, and if that need isn\u2019t satisfied them it\u2019s considered an unnecessary effort. Resume driven development.\n\nSo where\u2019s the line between these perspectives? Does it depend on team size and knowledge? What else?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where\u2019s the boundary between \u201cthe added complexity doesnt outweigh the benefit\u201d and \u201cscalability?\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cyd9g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705937856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see arguments from time to time that it\u2019s fine going straight into using spark, airflow, highly available rdbms, advanced git vc architectures, CI/CD, kubernetes, or whatever. The argument is typically that the designer expects the business to need to go this route eventually, and why design a system that you know you\u2019ll have to redesign later on for scalability reasons?&lt;/p&gt;\n\n&lt;p&gt;Then there\u2019s the other argument that these systems are completely unnecessary for small time guys, despite the fact that they offer many unique quality-of-life features that aren\u2019t replicated elsewhere. The complexity of these systems alone seems to warrant a need for implementation, and if that need isn\u2019t satisfied them it\u2019s considered an unnecessary effort. Resume driven development.&lt;/p&gt;\n\n&lt;p&gt;So where\u2019s the line between these perspectives? Does it depend on team size and knowledge? What else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19cyd9g", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cyd9g/wheres_the_boundary_between_the_added_complexity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cyd9g/wheres_the_boundary_between_the_added_complexity/", "subreddit_subscribers": 154964, "created_utc": 1705937856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Backstory - First let me say I\u2019m a newish BI analyst and in a department of me. We are starting to develop a data culture but I need to show value. I\u2019m using PBI and made several reports from on prem databases. \n\nMy goal is to connect to an API and put the acquired data into a MS Access database. The API returns the data in JSON format. \n\nI\u2019ve written a very simple Python program that pulls the data from the API on a daily basis and places it in a JSON file to be consumed by PBI. \n\nI\u2019m not a data engineer by any stretch of the imagination but I figured this would be the right sub to ask this question. \n\nIs it possible for Python to pull the data from the API and insert into an Access database while also performing some ETL? Am I in way over my head if I\u2019m very new to Python?", "author_fullname": "t2_3hma2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First time connecting to an API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19d6f86", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705957729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Backstory - First let me say I\u2019m a newish BI analyst and in a department of me. We are starting to develop a data culture but I need to show value. I\u2019m using PBI and made several reports from on prem databases. &lt;/p&gt;\n\n&lt;p&gt;My goal is to connect to an API and put the acquired data into a MS Access database. The API returns the data in JSON format. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve written a very simple Python program that pulls the data from the API on a daily basis and places it in a JSON file to be consumed by PBI. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not a data engineer by any stretch of the imagination but I figured this would be the right sub to ask this question. &lt;/p&gt;\n\n&lt;p&gt;Is it possible for Python to pull the data from the API and insert into an Access database while also performing some ETL? Am I in way over my head if I\u2019m very new to Python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19d6f86", "is_robot_indexable": true, "report_reasons": null, "author": "jebert32", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19d6f86/first_time_connecting_to_an_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19d6f86/first_time_connecting_to_an_api/", "subreddit_subscribers": 154964, "created_utc": 1705957729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been wondering recently just how much of a problem this really is.\n\nTo run a data engineering department, you have, in some capacity, all of the following:  \n\\- source data (API's, files, external DB tables)  \n\\- storage (blobs, databases, lakehouses, more files)  \n\\- pipelines (code, no-code, low-code  \n\\- dashboards (customer facing, internal, observability) \n\nAll of these exist across different codebases/repositories, tools, teams, software.\n\nHow the hell do you manage all of it?\n\nSure, you can say \"documentation\", but even in the best case, you have a Confluence that has the documentation which explains everything, a README in the Git repo, but it still does little to explain everything that you own and how it all links together, short of a few diagrams that are likely outdated.\n\nDoes anybody do this in what they would consider a \"good\" way? Or even any way at all that isn't just documentation?\n\nWe're looking into OpenMetadata as a tool to help with some of this on a more granular level, but it still doesn't answer it at the scale I'm talking about.", "author_fullname": "t2_x0jju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage the amount of data \"assets\" in your business?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cukvp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705926627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been wondering recently just how much of a problem this really is.&lt;/p&gt;\n\n&lt;p&gt;To run a data engineering department, you have, in some capacity, all of the following:&lt;br/&gt;\n- source data (API&amp;#39;s, files, external DB tables)&lt;br/&gt;\n- storage (blobs, databases, lakehouses, more files)&lt;br/&gt;\n- pipelines (code, no-code, low-code&lt;br/&gt;\n- dashboards (customer facing, internal, observability) &lt;/p&gt;\n\n&lt;p&gt;All of these exist across different codebases/repositories, tools, teams, software.&lt;/p&gt;\n\n&lt;p&gt;How the hell do you manage all of it?&lt;/p&gt;\n\n&lt;p&gt;Sure, you can say &amp;quot;documentation&amp;quot;, but even in the best case, you have a Confluence that has the documentation which explains everything, a README in the Git repo, but it still does little to explain everything that you own and how it all links together, short of a few diagrams that are likely outdated.&lt;/p&gt;\n\n&lt;p&gt;Does anybody do this in what they would consider a &amp;quot;good&amp;quot; way? Or even any way at all that isn&amp;#39;t just documentation?&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re looking into OpenMetadata as a tool to help with some of this on a more granular level, but it still doesn&amp;#39;t answer it at the scale I&amp;#39;m talking about.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19cukvp", "is_robot_indexable": true, "report_reasons": null, "author": "theDro54", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cukvp/how_do_you_manage_the_amount_of_data_assets_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cukvp/how_do_you_manage_the_amount_of_data_assets_in/", "subreddit_subscribers": 154964, "created_utc": 1705926627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Github link: [https://github.com/Zzdragon66/university-reddit-data-dashboard](https://github.com/Zzdragon66/university-reddit-data-dashboard)\n\n* Any Suggestions are welcome. If you find this project useful, consider giving it a star on GitHub. This helps me know there's interest and supports the project's visibility.\n* GPU on GCP right now is hard to get, so terraform may fail on the project initialization. You may change the docker command in DAG and \\`main.tf\\` to run the deep learning docker image without nvidia-gpu\n* There may still some bugs. I will test and fix them as soon as possible.\n\n# University Reddit Data Dashboard\n\nThe University Reddit Data Dashboard provides a comprehensive view of key statistics from the university's subreddit, encompassing both posts and comments over the past week. It features an in-depth analysis of sentiments expressed in these posts, comments, and by the authors themselves, all tracked and evaluated over the same seven-day period.\n\n## Features\n\nThe project is entirely hosted on the Google Cloud Platform and is ***horizontal scalable***. The scraping workload is evenly distributed across the computer engines(VM). Data manipulation is done through the Spark cluster(Google dataproc), where by increasing the worker node, the workload will be distributed across and finished more quickly.\n\n## Project Structure\n\nhttps://preview.redd.it/4t4tagdp2zdc1.jpg?width=1651&amp;format=pjpg&amp;auto=webp&amp;s=12f4e0f6dd1456191d349ed10d2200ca80c5df86\n\n## Examples\n\nThe following [dashboard](https://lookerstudio.google.com/reporting/97414aef-54dc-4fc8-8bf5-054f0ac75d2c) is generated with following parameters: 1 VM for airflow, 2 VMs for scraping, 1 VM with Nvidia-T4 GPU, Spark cluster(2 worker node 1 manager node), 10 universities in California.\n\n## Example Dashboard\n\nhttps://preview.redd.it/zd9ykrnq2zdc1.png?width=2886&amp;format=png&amp;auto=webp&amp;s=0d11ccac6550a059fd1f4c10b1433ae327792096\n\n## Example DAG\n\nhttps://preview.redd.it/qcyo7njr2zdc1.png?width=2932&amp;format=png&amp;auto=webp&amp;s=f2e6d7fbbaebbc5a69ffb0725a86704486bd708e\n\n## Tools\n\n1. Python\n   1. PyTorch\n   2. Google Cloud Client Library\n   3. Huggingface\n2. Spark(*Data manipulation*)\n3. Apache Airflow(*Data orchestration*)\n   1. Dynamic DAG generation\n   2. Xcom\n   3. Variables\n   4. TaskGroup\n4. Google Cloud Platform\n   1. Computer Engine(*VM &amp; Deep learning*)\n   2. Dataproc (*Spark*)\n   3. Bigquery (*SQL*)\n   4. Cloud Storage (*Data Storage*)\n   5. Looker Studio (*Data visualization*)\n   6. VPC Network and Firewall Rules\n5. Terraform(*Cloud Infrastructure Management*)\n6. Docker(*containerization*) and Dockerhub(*Distribute container images*)\n7. SQL(*Data Manipulation*)\n8. Makefile", "author_fullname": "t2_5igde9z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "University Subreddit Data Dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qcyo7njr2zdc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/qcyo7njr2zdc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=651a921d8dfc1bbe76cc870706aa5acca888e32b"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/qcyo7njr2zdc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=eddb05221ce523ab8662ee965287fb30fd702280"}, {"y": 114, "x": 320, "u": "https://preview.redd.it/qcyo7njr2zdc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=048febafab51425368b220ae8cc43f49adc245e7"}, {"y": 228, "x": 640, "u": "https://preview.redd.it/qcyo7njr2zdc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=51756b1ce35553cb8ad9377a05510d85b3c5c977"}, {"y": 342, "x": 960, "u": "https://preview.redd.it/qcyo7njr2zdc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=14354aa9e9cba7f9d17cdff868a738a1c8990110"}, {"y": 385, "x": 1080, "u": "https://preview.redd.it/qcyo7njr2zdc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da56c2cc4df57f3bb5fef26e345457603ba49590"}], "s": {"y": 1046, "x": 2932, "u": "https://preview.redd.it/qcyo7njr2zdc1.png?width=2932&amp;format=png&amp;auto=webp&amp;s=f2e6d7fbbaebbc5a69ffb0725a86704486bd708e"}, "id": "qcyo7njr2zdc1"}, "4t4tagdp2zdc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/4t4tagdp2zdc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad6016a7cd3f71abf04cde8818bf33ebb37f4c12"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/4t4tagdp2zdc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fd4e1ee720fbbf5bad80ccb7ca36c2e211fe847f"}, {"y": 140, "x": 320, "u": "https://preview.redd.it/4t4tagdp2zdc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6d6ccde8428f241ae7d4b94f0b0f580047d25f5c"}, {"y": 281, "x": 640, "u": "https://preview.redd.it/4t4tagdp2zdc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e802398bac8439812c14f2854a26b36822123f30"}, {"y": 422, "x": 960, "u": "https://preview.redd.it/4t4tagdp2zdc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05f98027ccf41e86222e714d961f6ac1d7025557"}, {"y": 474, "x": 1080, "u": "https://preview.redd.it/4t4tagdp2zdc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=34f5287fe7be5095fe127423cca277b8d6365718"}], "s": {"y": 726, "x": 1651, "u": "https://preview.redd.it/4t4tagdp2zdc1.jpg?width=1651&amp;format=pjpg&amp;auto=webp&amp;s=12f4e0f6dd1456191d349ed10d2200ca80c5df86"}, "id": "4t4tagdp2zdc1"}, "zd9ykrnq2zdc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/zd9ykrnq2zdc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6ff300936f3ba86380e4ee5035c482a5aefe735"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/zd9ykrnq2zdc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=15c357fb63ee1053e20f571830af0dfd9355c06f"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/zd9ykrnq2zdc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f5542f5705fcbb758d149dca175c42c7ad3bd621"}, {"y": 474, "x": 640, "u": "https://preview.redd.it/zd9ykrnq2zdc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9495fde689813790ccd6932c97109f92d29bad5"}, {"y": 711, "x": 960, "u": "https://preview.redd.it/zd9ykrnq2zdc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=31b87ddde547c9c7cec3b0963fc2ef91c60b1830"}, {"y": 800, "x": 1080, "u": "https://preview.redd.it/zd9ykrnq2zdc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7736a29786fcec32c2bf151e054bef45452f0f81"}], "s": {"y": 2138, "x": 2886, "u": "https://preview.redd.it/zd9ykrnq2zdc1.png?width=2886&amp;format=png&amp;auto=webp&amp;s=0d11ccac6550a059fd1f4c10b1433ae327792096"}, "id": "zd9ykrnq2zdc1"}}, "name": "t3_19ct24n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3PJjTgBpXRsxAM7NPgu7LKS0YQ4UaypEpK-vLeXlVyc.jpg", "edited": 1705947619.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1705921035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Github link: &lt;a href=\"https://github.com/Zzdragon66/university-reddit-data-dashboard\"&gt;https://github.com/Zzdragon66/university-reddit-data-dashboard&lt;/a&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Any Suggestions are welcome. If you find this project useful, consider giving it a star on GitHub. This helps me know there&amp;#39;s interest and supports the project&amp;#39;s visibility.&lt;/li&gt;\n&lt;li&gt;GPU on GCP right now is hard to get, so terraform may fail on the project initialization. You may change the docker command in DAG and `main.tf` to run the deep learning docker image without nvidia-gpu&lt;/li&gt;\n&lt;li&gt;There may still some bugs. I will test and fix them as soon as possible.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;University Reddit Data Dashboard&lt;/h1&gt;\n\n&lt;p&gt;The University Reddit Data Dashboard provides a comprehensive view of key statistics from the university&amp;#39;s subreddit, encompassing both posts and comments over the past week. It features an in-depth analysis of sentiments expressed in these posts, comments, and by the authors themselves, all tracked and evaluated over the same seven-day period.&lt;/p&gt;\n\n&lt;h2&gt;Features&lt;/h2&gt;\n\n&lt;p&gt;The project is entirely hosted on the Google Cloud Platform and is &lt;strong&gt;&lt;em&gt;horizontal scalable&lt;/em&gt;&lt;/strong&gt;. The scraping workload is evenly distributed across the computer engines(VM). Data manipulation is done through the Spark cluster(Google dataproc), where by increasing the worker node, the workload will be distributed across and finished more quickly.&lt;/p&gt;\n\n&lt;h2&gt;Project Structure&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4t4tagdp2zdc1.jpg?width=1651&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=12f4e0f6dd1456191d349ed10d2200ca80c5df86\"&gt;https://preview.redd.it/4t4tagdp2zdc1.jpg?width=1651&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=12f4e0f6dd1456191d349ed10d2200ca80c5df86&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Examples&lt;/h2&gt;\n\n&lt;p&gt;The following &lt;a href=\"https://lookerstudio.google.com/reporting/97414aef-54dc-4fc8-8bf5-054f0ac75d2c\"&gt;dashboard&lt;/a&gt; is generated with following parameters: 1 VM for airflow, 2 VMs for scraping, 1 VM with Nvidia-T4 GPU, Spark cluster(2 worker node 1 manager node), 10 universities in California.&lt;/p&gt;\n\n&lt;h2&gt;Example Dashboard&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zd9ykrnq2zdc1.png?width=2886&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d11ccac6550a059fd1f4c10b1433ae327792096\"&gt;https://preview.redd.it/zd9ykrnq2zdc1.png?width=2886&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d11ccac6550a059fd1f4c10b1433ae327792096&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Example DAG&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qcyo7njr2zdc1.png?width=2932&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f2e6d7fbbaebbc5a69ffb0725a86704486bd708e\"&gt;https://preview.redd.it/qcyo7njr2zdc1.png?width=2932&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f2e6d7fbbaebbc5a69ffb0725a86704486bd708e&lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Tools&lt;/h2&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python\n\n&lt;ol&gt;\n&lt;li&gt;PyTorch&lt;/li&gt;\n&lt;li&gt;Google Cloud Client Library&lt;/li&gt;\n&lt;li&gt;Huggingface&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Spark(&lt;em&gt;Data manipulation&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Apache Airflow(&lt;em&gt;Data orchestration&lt;/em&gt;)\n\n&lt;ol&gt;\n&lt;li&gt;Dynamic DAG generation&lt;/li&gt;\n&lt;li&gt;Xcom&lt;/li&gt;\n&lt;li&gt;Variables&lt;/li&gt;\n&lt;li&gt;TaskGroup&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Google Cloud Platform\n\n&lt;ol&gt;\n&lt;li&gt;Computer Engine(&lt;em&gt;VM &amp;amp; Deep learning&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Dataproc (&lt;em&gt;Spark&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Bigquery (&lt;em&gt;SQL&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Cloud Storage (&lt;em&gt;Data Storage&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Looker Studio (&lt;em&gt;Data visualization&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;VPC Network and Firewall Rules&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Terraform(&lt;em&gt;Cloud Infrastructure Management&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Docker(&lt;em&gt;containerization&lt;/em&gt;) and Dockerhub(&lt;em&gt;Distribute container images&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;SQL(&lt;em&gt;Data Manipulation&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Makefile&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YyDCrHf0et0U9Lq0s8c6R_5WEAmjQyIa0_ps5huXrsg.jpg?auto=webp&amp;s=0723070d4f6717b611fd6e7d6226a8c33e35c403", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/YyDCrHf0et0U9Lq0s8c6R_5WEAmjQyIa0_ps5huXrsg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c901ff70d4c0a7129cd342e63a6dc8308c898f5a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/YyDCrHf0et0U9Lq0s8c6R_5WEAmjQyIa0_ps5huXrsg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b68e9f61650e97e21af4b4078226b241cef3ec03", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/YyDCrHf0et0U9Lq0s8c6R_5WEAmjQyIa0_ps5huXrsg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c41c0d26632bafcbe3a14ae7e7ce6aa548947351", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/YyDCrHf0et0U9Lq0s8c6R_5WEAmjQyIa0_ps5huXrsg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=826e695efe8d84e9e04ce445a892df42b53e7df5", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/YyDCrHf0et0U9Lq0s8c6R_5WEAmjQyIa0_ps5huXrsg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5641aa8bdd34e54783ac3c5a29ed1eb20a2ac9bc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/YyDCrHf0et0U9Lq0s8c6R_5WEAmjQyIa0_ps5huXrsg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b7710b38ac1827351fa7d94d262387332234fe6e", "width": 1080, "height": 540}], "variants": {}, "id": "dVl6Gggt6lThsY0rLoELKyR7cqPQs8H1yzgWN6s91pI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "19ct24n", "is_robot_indexable": true, "report_reasons": null, "author": "AffectionateEmu8146", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19ct24n/university_subreddit_data_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19ct24n/university_subreddit_data_dashboard/", "subreddit_subscribers": 154964, "created_utc": 1705921035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "have an education in software development check.\n\ndo allot of courses on courserea and build a portfolio\n\nget a data analyst job\n\nget a data engineer job after a few years.\n\n&amp;#x200B;\n\ndont know if it matters but im in canada.", "author_fullname": "t2_szy83vbu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "my path on being a data engineer, advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19d4lq3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705965010.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705953260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;have an education in software development check.&lt;/p&gt;\n\n&lt;p&gt;do allot of courses on courserea and build a portfolio&lt;/p&gt;\n\n&lt;p&gt;get a data analyst job&lt;/p&gt;\n\n&lt;p&gt;get a data engineer job after a few years.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;dont know if it matters but im in canada.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19d4lq3", "is_robot_indexable": true, "report_reasons": null, "author": "BornYoghurt8710", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19d4lq3/my_path_on_being_a_data_engineer_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19d4lq3/my_path_on_being_a_data_engineer_advice/", "subreddit_subscribers": 154964, "created_utc": 1705953260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! I'm trying to set up a new infrastructure for data in my organization. I'm not a data engineer, but I'm trying to understand the problem and look for the best solutions. I wanted to ask you for some advice:\n\nI need to extract data from a source (using Airbyte), place this data in a warehouse (using Clickhouse), transform this data to generate better visualizations (dbt) and eventually visualize this data (Metabase).\n\nI wanted to know if this makes sense. My focus is open source tools, which I can deploy locally and manage, hence the tools mentioned.\n\nAfter that, I would also like to be able to perform some actions on this data. For example, using Retool or some tool that allows me to perform actions to insert data into my data. So I don't know exactly how to proceed.\n\nI can connect Retool directly to my warehouse and perform actions with the data there, inserting new rows that represent other information linked to some table (for example, a users table), but I understand that this would not be the best way to proceed.\n\nI know that there are \"Reverse ETLs\", which took the data from the warehouse and placed it elsewhere, for example in Retool itself. But, how (preferably using some tool) can I insert new lines of information into my data using this architecture?\n\nI thought that Reverse ETL could connect to Postgres, replicate the data that I think is relevant from the warehouse, then Retool connects to that Postgres and eventually performs data insertions in that database, then Airbyte ingests the data again, doing rewrite of the old data. That makes sense?\n\nAny information, advice or help would be great!\n\nhttps://preview.redd.it/qhmeb6g1wzdc1.png?width=938&amp;format=png&amp;auto=webp&amp;s=b497632952d22c447aa79da1dc842c4a967d338f", "author_fullname": "t2_6cona65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on data infrastructure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 99, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qhmeb6g1wzdc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/qhmeb6g1wzdc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=44398c6f12f101b319cde42a9021ea370df6ecf5"}, {"y": 153, "x": 216, "u": "https://preview.redd.it/qhmeb6g1wzdc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=59a000e5e7a2b19a6ae464bcfdebc215de0860e6"}, {"y": 227, "x": 320, "u": "https://preview.redd.it/qhmeb6g1wzdc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e6cce5873e5a98f8d542964fa1b3c444ad81443b"}, {"y": 454, "x": 640, "u": "https://preview.redd.it/qhmeb6g1wzdc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=24cbc1cfec45365c0cad62ab7b700987db367e75"}], "s": {"y": 666, "x": 938, "u": "https://preview.redd.it/qhmeb6g1wzdc1.png?width=938&amp;format=png&amp;auto=webp&amp;s=b497632952d22c447aa79da1dc842c4a967d338f"}, "id": "qhmeb6g1wzdc1"}}, "name": "t3_19cvtuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iulZ2kXZGBc7hVz0WxRXgmHvSHrzpVjB882vsil5n6Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705930744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I&amp;#39;m trying to set up a new infrastructure for data in my organization. I&amp;#39;m not a data engineer, but I&amp;#39;m trying to understand the problem and look for the best solutions. I wanted to ask you for some advice:&lt;/p&gt;\n\n&lt;p&gt;I need to extract data from a source (using Airbyte), place this data in a warehouse (using Clickhouse), transform this data to generate better visualizations (dbt) and eventually visualize this data (Metabase).&lt;/p&gt;\n\n&lt;p&gt;I wanted to know if this makes sense. My focus is open source tools, which I can deploy locally and manage, hence the tools mentioned.&lt;/p&gt;\n\n&lt;p&gt;After that, I would also like to be able to perform some actions on this data. For example, using Retool or some tool that allows me to perform actions to insert data into my data. So I don&amp;#39;t know exactly how to proceed.&lt;/p&gt;\n\n&lt;p&gt;I can connect Retool directly to my warehouse and perform actions with the data there, inserting new rows that represent other information linked to some table (for example, a users table), but I understand that this would not be the best way to proceed.&lt;/p&gt;\n\n&lt;p&gt;I know that there are &amp;quot;Reverse ETLs&amp;quot;, which took the data from the warehouse and placed it elsewhere, for example in Retool itself. But, how (preferably using some tool) can I insert new lines of information into my data using this architecture?&lt;/p&gt;\n\n&lt;p&gt;I thought that Reverse ETL could connect to Postgres, replicate the data that I think is relevant from the warehouse, then Retool connects to that Postgres and eventually performs data insertions in that database, then Airbyte ingests the data again, doing rewrite of the old data. That makes sense?&lt;/p&gt;\n\n&lt;p&gt;Any information, advice or help would be great!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qhmeb6g1wzdc1.png?width=938&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b497632952d22c447aa79da1dc842c4a967d338f\"&gt;https://preview.redd.it/qhmeb6g1wzdc1.png?width=938&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b497632952d22c447aa79da1dc842c4a967d338f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19cvtuu", "is_robot_indexable": true, "report_reasons": null, "author": "Doveliver2", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cvtuu/advice_on_data_infrastructure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cvtuu/advice_on_data_infrastructure/", "subreddit_subscribers": 154964, "created_utc": 1705930744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, guys,\n\nWe believe the best way to reduce costs is to measure them first, so i got three questions.\n\n1. Do u need a tool that provide u realtime(or hourly) AWS EMR costs at the task\\_name level ?\n2. If its a SaaS tool, are u willing to pay for it ?\n3. How much? Assuming monthly bill.\n\nSo, whats your anwsers?  :)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/y6e0pb721ydc1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=8e41af35453dcc8f7c682a456328a24d482b4d81", "author_fullname": "t2_a97hfbng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The best way to reduce AWS EMR costs.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"y6e0pb721ydc1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/y6e0pb721ydc1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=880d869d5ca66e2a4471121a36a1412b2ba7fdd3"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/y6e0pb721ydc1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=227e31f68c1b83463c9ba4fbeeddbd9b7f75e568"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/y6e0pb721ydc1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=be2453dc4ddbd7528c82555bb416a471205e3d3f"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/y6e0pb721ydc1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d38e1ed52425b3ab16080d75c5e993c91154f110"}, {"y": 502, "x": 960, "u": "https://preview.redd.it/y6e0pb721ydc1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e654f3882e6dd2883b573fbfcec8ac046d44e5a"}, {"y": 565, "x": 1080, "u": "https://preview.redd.it/y6e0pb721ydc1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c59b615b86de2e3ffd68986216b96f3dad45c614"}], "s": {"y": 628, "x": 1200, "u": "https://preview.redd.it/y6e0pb721ydc1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=8e41af35453dcc8f7c682a456328a24d482b4d81"}, "id": "y6e0pb721ydc1"}}, "name": "t3_19cpb97", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/YZbcZ9qwlmQY5QrqUDKlJr7KM8hm7kLODuDkkd2V3y0.jpg", "edited": 1705908268.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705904973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, guys,&lt;/p&gt;\n\n&lt;p&gt;We believe the best way to reduce costs is to measure them first, so i got three questions.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do u need a tool that provide u realtime(or hourly) AWS EMR costs at the task_name level ?&lt;/li&gt;\n&lt;li&gt;If its a SaaS tool, are u willing to pay for it ?&lt;/li&gt;\n&lt;li&gt;How much? Assuming monthly bill.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So, whats your anwsers?  :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/y6e0pb721ydc1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=8e41af35453dcc8f7c682a456328a24d482b4d81\"&gt;https://preview.redd.it/y6e0pb721ydc1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=8e41af35453dcc8f7c682a456328a24d482b4d81&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19cpb97", "is_robot_indexable": true, "report_reasons": null, "author": "No_Structure3465", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cpb97/the_best_way_to_reduce_aws_emr_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cpb97/the_best_way_to_reduce_aws_emr_costs/", "subreddit_subscribers": 154964, "created_utc": 1705904973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Guys,\nI\u2019m working as a Data Engineer at mid size company. I mostly work on Snowflake, and Tableau. But, I\u2019m trying to convince my manager to assign a ETL project so that I can get some exposure to Aws and Snowpark.\nIn parallel, I want to expand my expertise as well, so here are my queries: \nFirstly, I want to learn spark, how can I start learning, to learn it quicker?\nSecondly, the reason I chose a career in data is because I didn\u2019t enjoy DSA, I\u2019m bad at and no motivation to learn as well. So, is it the end of road for me to achieve a data role at FAANG?\nThirdly, how do you guys manage time after work to do side projects when learning new skills?\nFinally, Azure or Aws? I found azure to be too much drag and drop. And, more tool based. What do you guys recommend?", "author_fullname": "t2_h9x4f7q6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Doubts on being a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19con24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705904712.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705902493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Guys,\nI\u2019m working as a Data Engineer at mid size company. I mostly work on Snowflake, and Tableau. But, I\u2019m trying to convince my manager to assign a ETL project so that I can get some exposure to Aws and Snowpark.\nIn parallel, I want to expand my expertise as well, so here are my queries: \nFirstly, I want to learn spark, how can I start learning, to learn it quicker?\nSecondly, the reason I chose a career in data is because I didn\u2019t enjoy DSA, I\u2019m bad at and no motivation to learn as well. So, is it the end of road for me to achieve a data role at FAANG?\nThirdly, how do you guys manage time after work to do side projects when learning new skills?\nFinally, Azure or Aws? I found azure to be too much drag and drop. And, more tool based. What do you guys recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19con24", "is_robot_indexable": true, "report_reasons": null, "author": "GulabiGovind", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19con24/doubts_on_being_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19con24/doubts_on_being_a_data_engineer/", "subreddit_subscribers": 154964, "created_utc": 1705902493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Partitioning isn't always a win, like any optimization it's a mix balancing trade-offs in favor of the type of workloads that higher priority and seen more often.  \n\n\nWhen determining how large data set should be partitioned, what questions do you ask yourself?  \n\n\nWhen determining how large a data set should be partitioned, what questions do you ask yourself?  \n", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What questions to ask when deciding on partitioning strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19d44ul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705952091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Partitioning isn&amp;#39;t always a win, like any optimization it&amp;#39;s a mix balancing trade-offs in favor of the type of workloads that higher priority and seen more often.  &lt;/p&gt;\n\n&lt;p&gt;When determining how large data set should be partitioned, what questions do you ask yourself?  &lt;/p&gt;\n\n&lt;p&gt;When determining how large a data set should be partitioned, what questions do you ask yourself?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19d44ul", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19d44ul/what_questions_to_ask_when_deciding_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19d44ul/what_questions_to_ask_when_deciding_on/", "subreddit_subscribers": 154964, "created_utc": 1705952091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey r/dataengineering,  \nWe have seen increased Terraform adoption amongst Data Engineers over the last 2 or so years, but have seen that most of them aren't aware of  Terraform Automation and Collaboration tools that help in CI/CD for terraform and enable RBAC, drift detection and concurrency in the process, so that Terraform can be used efficiently at scale.  \n\n\nThere are several open source tools that help with this (Disclosure: I am building Digger, one of the tools):  \n\n\n[Digger](https://github.com/diggerhq/digger)\n\n[Atlantis](https://github.com/runatlantis/atlantis)\n\n[OTF](https://github.com/leg100/otf)\n\n[Terrakube](https://github.com/AzBuilder/terrakube)  \n\n\nFeel free to check them out and share feedback if you are already using any of them. Also please share any challenges you face while using Terraform as a team, it would be useful for us to learn!", "author_fullname": "t2_olwmmcn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Define and manage infrastructure using HCL (Terraform)? You may need a Terraform Automation and Collaboration tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cxvi9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705936547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;br/&gt;\nWe have seen increased Terraform adoption amongst Data Engineers over the last 2 or so years, but have seen that most of them aren&amp;#39;t aware of  Terraform Automation and Collaboration tools that help in CI/CD for terraform and enable RBAC, drift detection and concurrency in the process, so that Terraform can be used efficiently at scale.  &lt;/p&gt;\n\n&lt;p&gt;There are several open source tools that help with this (Disclosure: I am building Digger, one of the tools):  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/diggerhq/digger\"&gt;Digger&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/runatlantis/atlantis\"&gt;Atlantis&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/leg100/otf\"&gt;OTF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/AzBuilder/terrakube\"&gt;Terrakube&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Feel free to check them out and share feedback if you are already using any of them. Also please share any challenges you face while using Terraform as a team, it would be useful for us to learn!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_dWkOAp3SYcs9VVIAVZ157nFmNphgGYGaQbAapCKFLc.jpg?auto=webp&amp;s=0d3cfeba4a07d6b78ff9b4d15a2d97954bbd7ae0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_dWkOAp3SYcs9VVIAVZ157nFmNphgGYGaQbAapCKFLc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8271ca2ae42cc3c8ff040f7698707a467b5dfed8", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_dWkOAp3SYcs9VVIAVZ157nFmNphgGYGaQbAapCKFLc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f81a731101aed07db4e355e6c689894e89c5db3b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_dWkOAp3SYcs9VVIAVZ157nFmNphgGYGaQbAapCKFLc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=81c625f39e0e3d7c22ec5ae03b77833c25d219e5", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_dWkOAp3SYcs9VVIAVZ157nFmNphgGYGaQbAapCKFLc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=643c5723e8b2e876f0d67f0f8ef18076e24dc03f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_dWkOAp3SYcs9VVIAVZ157nFmNphgGYGaQbAapCKFLc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=390b9ad0eb22d0ad99a59316ec2de1d142069eb5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_dWkOAp3SYcs9VVIAVZ157nFmNphgGYGaQbAapCKFLc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e6fed435cc70984aff6e307cd20efc7d804d6c74", "width": 1080, "height": 540}], "variants": {}, "id": "3MBjLwv-ZT35hxaeD0XESVyLyfkkgKF7R2YsB0EDhH8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "19cxvi9", "is_robot_indexable": true, "report_reasons": null, "author": "utpalnadiger", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cxvi9/define_and_manage_infrastructure_using_hcl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cxvi9/define_and_manage_infrastructure_using_hcl/", "subreddit_subscribers": 154964, "created_utc": 1705936547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My boss asked me to build a system that can quickly search and retrieve data. Right now I just process text data. It can be  thousands of T of data.\n\nThe data source is  giant  and come from vary resources and format (txt, csv, xlsx, json, ...) (the data from the same resource can be different format and data structure (fields) too).   Data between sources is linked and has overlapping fields but can take different values.  I mean, maybe for the same linked point sample, the data  received from each resource can be different, and wrong.  I cannot elaborate on the details of the project due to  security issue.\n\nRight now, i have Minio as data lake for store raw data, PostgreSQL to store processed data from raw data and using Airflow for running the processses. Right now I  encountered performance problems when upsert data to postgre.\n\nIs there any way to improve upsert performance? Or any other way to store and query data?  \nDo you have any suggestions and Tech-stack  for this?\n\nThanks you for your help!", "author_fullname": "t2_vfose2ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big Data build on On-Premise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19csc3q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705930155.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705917914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My boss asked me to build a system that can quickly search and retrieve data. Right now I just process text data. It can be  thousands of T of data.&lt;/p&gt;\n\n&lt;p&gt;The data source is  giant  and come from vary resources and format (txt, csv, xlsx, json, ...) (the data from the same resource can be different format and data structure (fields) too).   Data between sources is linked and has overlapping fields but can take different values.  I mean, maybe for the same linked point sample, the data  received from each resource can be different, and wrong.  I cannot elaborate on the details of the project due to  security issue.&lt;/p&gt;\n\n&lt;p&gt;Right now, i have Minio as data lake for store raw data, PostgreSQL to store processed data from raw data and using Airflow for running the processses. Right now I  encountered performance problems when upsert data to postgre.&lt;/p&gt;\n\n&lt;p&gt;Is there any way to improve upsert performance? Or any other way to store and query data?&lt;br/&gt;\nDo you have any suggestions and Tech-stack  for this?&lt;/p&gt;\n\n&lt;p&gt;Thanks you for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19csc3q", "is_robot_indexable": true, "report_reasons": null, "author": "Midori-Yuu", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19csc3q/big_data_build_on_onpremise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19csc3q/big_data_build_on_onpremise/", "subreddit_subscribers": 154964, "created_utc": 1705917914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently launched a POC data pipeline and now that it\u2019s seeing production workloads I want to refactor it. It\u2019s like a combination of 3 data pipelines, synchronously working, and I want to turn it into 3 smaller pipelines that run asynchronously.\n\nI figure this will result in three smaller projects that steal code from the POC and depreciation of the POC. So, what is typically done to the POC?\n\nI use git like most.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do with depreciated applications in your code base?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19dde12", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705976026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently launched a POC data pipeline and now that it\u2019s seeing production workloads I want to refactor it. It\u2019s like a combination of 3 data pipelines, synchronously working, and I want to turn it into 3 smaller pipelines that run asynchronously.&lt;/p&gt;\n\n&lt;p&gt;I figure this will result in three smaller projects that steal code from the POC and depreciation of the POC. So, what is typically done to the POC?&lt;/p&gt;\n\n&lt;p&gt;I use git like most.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19dde12", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19dde12/what_do_you_do_with_depreciated_applications_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19dde12/what_do_you_do_with_depreciated_applications_in/", "subreddit_subscribers": 154964, "created_utc": 1705976026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've scheduled my GCP PDE exam for 30th Jan, but heard that Google has significantly changed the exam pattern in November. Has anybody appeared for the exam after the pattern change? Are there any dumps available as per the new pattern? What new topics should I focus on for the exam?", "author_fullname": "t2_3dhdayfh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP Professional Data Engineer new pattern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cpy1e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705907475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve scheduled my GCP PDE exam for 30th Jan, but heard that Google has significantly changed the exam pattern in November. Has anybody appeared for the exam after the pattern change? Are there any dumps available as per the new pattern? What new topics should I focus on for the exam?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19cpy1e", "is_robot_indexable": true, "report_reasons": null, "author": "bashed_it", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cpy1e/gcp_professional_data_engineer_new_pattern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cpy1e/gcp_professional_data_engineer_new_pattern/", "subreddit_subscribers": 154964, "created_utc": 1705907475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What data tokenization tools have folks found to work really well? (Eg Protegrity? Thales? Acra? Other?) \n\nThanks!", "author_fullname": "t2_3x3r7v7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data tokenization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19d1jnj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705945973.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705945727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What data tokenization tools have folks found to work really well? (Eg Protegrity? Thales? Acra? Other?) &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19d1jnj", "is_robot_indexable": true, "report_reasons": null, "author": "iad05", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19d1jnj/data_tokenization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19d1jnj/data_tokenization/", "subreddit_subscribers": 154964, "created_utc": 1705945727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2cbhndmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is stateful stream processing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_19cz7sp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KDPUGDTHwhFomVv4xaexWofUbvsLWKqIrCzLMnkNGHI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705940039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arroyo.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arroyo.dev/blog/stateful-stream-processing", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rqTM-tWq2W_BCBdFYjNveUzH-IgpNmrxFtseuxc32Uw.jpg?auto=webp&amp;s=4fcede94110ea87ebe80206e92e67e3a53940d2e", "width": 2688, "height": 1792}, "resolutions": [{"url": "https://external-preview.redd.it/rqTM-tWq2W_BCBdFYjNveUzH-IgpNmrxFtseuxc32Uw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c1b748d065645137f524119eaa4e9d09a00332b", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/rqTM-tWq2W_BCBdFYjNveUzH-IgpNmrxFtseuxc32Uw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e553ec3099f86f8eaf1e28768670a7485dd1f76", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/rqTM-tWq2W_BCBdFYjNveUzH-IgpNmrxFtseuxc32Uw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b27bbafa5ed4b7f1f748f643d42af0e746f2f7d", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/rqTM-tWq2W_BCBdFYjNveUzH-IgpNmrxFtseuxc32Uw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5c80c3332c56bbe803201044a8c2660624edb2f8", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/rqTM-tWq2W_BCBdFYjNveUzH-IgpNmrxFtseuxc32Uw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1c74f73edd644a319d4629550c4e2b608958a7f5", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/rqTM-tWq2W_BCBdFYjNveUzH-IgpNmrxFtseuxc32Uw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=087e5ec0f8d04185143068e24e1bf21c8ae436aa", "width": 1080, "height": 720}], "variants": {}, "id": "lYYlFjuV_317mtzf0XjIUsvXlT9FXido9hd6OzAvvnw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19cz7sp", "is_robot_indexable": true, "report_reasons": null, "author": "mwylde_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cz7sp/what_is_stateful_stream_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arroyo.dev/blog/stateful-stream-processing", "subreddit_subscribers": 154964, "created_utc": 1705940039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm seeking for some cloud platforms to experiment with as I began learning Hadoop and Spark conceptually and my laptop is too sluggish to handle any big data projects on it. Would you kindly recommend some platfoms to me ?", "author_fullname": "t2_dgy6xh6j3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "cloud-based Hadoop and Spark experimentation platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19csi4o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705918635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m seeking for some cloud platforms to experiment with as I began learning Hadoop and Spark conceptually and my laptop is too sluggish to handle any big data projects on it. Would you kindly recommend some platfoms to me ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19csi4o", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_bdnt", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19csi4o/cloudbased_hadoop_and_spark_experimentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19csi4o/cloudbased_hadoop_and_spark_experimentation/", "subreddit_subscribers": 154964, "created_utc": 1705918635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am planning to build a data pipeline for a new project, which would be in pyspark sagemaker notebooks Technologies used as below\nOrchestration: Airlfow\nStorage: S3\nFinal transformed tables will be created in athena.\n\nHow would you structure a git repo that's written in pyspark notebooks and with a dag folder. We are also looking to implement CI/CD in the future.\n\nWould like to hear all your suggestions and any github repo examples would be highly appreciated.\n Thanks!", "author_fullname": "t2_6n03d0sf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to structure a data pipeline repo for pyspark jupyter notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cq4gk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705908595.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705908219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to build a data pipeline for a new project, which would be in pyspark sagemaker notebooks Technologies used as below\nOrchestration: Airlfow\nStorage: S3\nFinal transformed tables will be created in athena.&lt;/p&gt;\n\n&lt;p&gt;How would you structure a git repo that&amp;#39;s written in pyspark notebooks and with a dag folder. We are also looking to implement CI/CD in the future.&lt;/p&gt;\n\n&lt;p&gt;Would like to hear all your suggestions and any github repo examples would be highly appreciated.\n Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19cq4gk", "is_robot_indexable": true, "report_reasons": null, "author": "arunrajan96", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cq4gk/how_to_structure_a_data_pipeline_repo_for_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cq4gk/how_to_structure_a_data_pipeline_repo_for_pyspark/", "subreddit_subscribers": 154964, "created_utc": 1705908219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I began using Airflow recently. I am using it for my process server which user can import their file to data lake. Then I will pass these file location, ways to process and processed file destination to **Airflow** webserver throught API. **CeleryExecutor** then will add job to **rabbitMQ** and **workers** will execute that **DAG**. **DAG** contain 3 task: **Extract** (download data from data lake and read it as dataframe), **Transform** (perform some transformation to that df) and **Load** (load processed df back to data lake). My question is Is it common to reload data from data lake every time a dag is executed. I mean if user want to perform many process separately, then workers will have to reload data to RAM over and over again. Is there any way to optimize this or is there any better way to do this? Thanks for your reading ", "author_fullname": "t2_oj5xmc65m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Airflow to execute preprocessing data for machine learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19dega8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705979189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I began using Airflow recently. I am using it for my process server which user can import their file to data lake. Then I will pass these file location, ways to process and processed file destination to &lt;strong&gt;Airflow&lt;/strong&gt; webserver throught API. &lt;strong&gt;CeleryExecutor&lt;/strong&gt; then will add job to &lt;strong&gt;rabbitMQ&lt;/strong&gt; and &lt;strong&gt;workers&lt;/strong&gt; will execute that &lt;strong&gt;DAG&lt;/strong&gt;. &lt;strong&gt;DAG&lt;/strong&gt; contain 3 task: &lt;strong&gt;Extract&lt;/strong&gt; (download data from data lake and read it as dataframe), &lt;strong&gt;Transform&lt;/strong&gt; (perform some transformation to that df) and &lt;strong&gt;Load&lt;/strong&gt; (load processed df back to data lake). My question is Is it common to reload data from data lake every time a dag is executed. I mean if user want to perform many process separately, then workers will have to reload data to RAM over and over again. Is there any way to optimize this or is there any better way to do this? Thanks for your reading &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19dega8", "is_robot_indexable": true, "report_reasons": null, "author": "resrrdttrt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19dega8/using_airflow_to_execute_preprocessing_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19dega8/using_airflow_to_execute_preprocessing_data_for/", "subreddit_subscribers": 154964, "created_utc": 1705979189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My goal is to get a fully-remote, entry-level job in data engineering. How unrealistic is that?\n\nBe brutally honest... better to crush my dreams now rather than study for months only to find out later.\n\nI have no experience in data engineering, but I do have a phd in a stem field and 4 years working as a data scientist", "author_fullname": "t2_fq68u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Entry level + Fully Remote... How unrealistic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19de5wg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705978332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is to get a fully-remote, entry-level job in data engineering. How unrealistic is that?&lt;/p&gt;\n\n&lt;p&gt;Be brutally honest... better to crush my dreams now rather than study for months only to find out later.&lt;/p&gt;\n\n&lt;p&gt;I have no experience in data engineering, but I do have a phd in a stem field and 4 years working as a data scientist&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19de5wg", "is_robot_indexable": true, "report_reasons": null, "author": "KimchiFitness", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19de5wg/entry_level_fully_remote_how_unrealistic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19de5wg/entry_level_fully_remote_how_unrealistic/", "subreddit_subscribers": 154964, "created_utc": 1705978332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im currently doing my final year in btech Artificial Intelligence and Data Science and I got an internship through placements at a startup . The thing is , this company made me to handle a client with no prior experience (literally 0) and makes me do everything under a module . As an intern I want to learn more and help but Im stressing  myself working on pipelines, modifying transformation logic , fixing pipelines, documentation, cloud , writing apis and more . Im extremely exhausted and feel Ive wasted my time here .And at time I feel if i stayed back and just learnt stuff I would have got a better job.  Is this a common thing out there ?? (Ps : my stipend is only 155 dollars / month and i still handle the client )", "author_fullname": "t2_m5olwi2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need career advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19daecg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705967589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im currently doing my final year in btech Artificial Intelligence and Data Science and I got an internship through placements at a startup . The thing is , this company made me to handle a client with no prior experience (literally 0) and makes me do everything under a module . As an intern I want to learn more and help but Im stressing  myself working on pipelines, modifying transformation logic , fixing pipelines, documentation, cloud , writing apis and more . Im extremely exhausted and feel Ive wasted my time here .And at time I feel if i stayed back and just learnt stuff I would have got a better job.  Is this a common thing out there ?? (Ps : my stipend is only 155 dollars / month and i still handle the client )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19daecg", "is_robot_indexable": true, "report_reasons": null, "author": "pradishhh", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19daecg/need_career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19daecg/need_career_advice/", "subreddit_subscribers": 154964, "created_utc": 1705967589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I\u2019ve been a junior DE for around 8 months now. I lack a CS degree and don\u2019t currently plan to get a masters degree, though I\u2019m pretty committed to self learning. At the moment however, I\u2019m not 100% set on being a DE. I mostly ended up here due to placements after a rotational software engineering program. \n\nIf I get a different position within my org as an analyst, would it be bad for my career? I feel that I may be a good fit for analytics as I used to work in an R&amp;D science &amp; engineering department for a manufacturer and did a ton of analytics on lab data. I think I\u2019d enjoy the work. \n\nWould this be a step backwards, as analysts are typically considered to be less technical than engineers? \nI see a lot of people trying to switch from analytics into data engineering and am wondering if I\u2019m crazy for trying the reverse haha.", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching to data analyst position from engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19d54ho", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705954552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I\u2019ve been a junior DE for around 8 months now. I lack a CS degree and don\u2019t currently plan to get a masters degree, though I\u2019m pretty committed to self learning. At the moment however, I\u2019m not 100% set on being a DE. I mostly ended up here due to placements after a rotational software engineering program. &lt;/p&gt;\n\n&lt;p&gt;If I get a different position within my org as an analyst, would it be bad for my career? I feel that I may be a good fit for analytics as I used to work in an R&amp;amp;D science &amp;amp; engineering department for a manufacturer and did a ton of analytics on lab data. I think I\u2019d enjoy the work. &lt;/p&gt;\n\n&lt;p&gt;Would this be a step backwards, as analysts are typically considered to be less technical than engineers? \nI see a lot of people trying to switch from analytics into data engineering and am wondering if I\u2019m crazy for trying the reverse haha.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19d54ho", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19d54ho/switching_to_data_analyst_position_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19d54ho/switching_to_data_analyst_position_from/", "subreddit_subscribers": 154964, "created_utc": 1705954552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: Work in strategy and ops | Non-technical\n\nAre there open source projects that accept volunteers from non-technical backgrounds?\n\nHow do I get started?\n\nWhat would be good open source projects to target?", "author_fullname": "t2_3f4wscvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to become a committer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19d2pj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705948531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: Work in strategy and ops | Non-technical&lt;/p&gt;\n\n&lt;p&gt;Are there open source projects that accept volunteers from non-technical backgrounds?&lt;/p&gt;\n\n&lt;p&gt;How do I get started?&lt;/p&gt;\n\n&lt;p&gt;What would be good open source projects to target?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19d2pj8", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessorFinanceBro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19d2pj8/how_to_become_a_committer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19d2pj8/how_to_become_a_committer/", "subreddit_subscribers": 154964, "created_utc": 1705948531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I took a job as a data and analytics engineer two years ago. The job is very limited in its growth and skill ability, and the majority of the harder data engineering work is done through an out-of-the-country contracting firm. My position is mainly translating requirements for them to be able to build and maintain. I am looking to leave this firm to continue growing my skill set, but I am out of practice interviewing, especially in the current market. I am specifically targeting Sr. Data Engineer positions with growth potential as either a Staff Engineer or a Data Architect. Does anyone have any groups for mock interviews and/or study curriculum in order to review for interviews? I specifically need assistance in Python algorithms and system design.", "author_fullname": "t2_kfuzrpj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help with Interview Practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19d2m9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705948316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I took a job as a data and analytics engineer two years ago. The job is very limited in its growth and skill ability, and the majority of the harder data engineering work is done through an out-of-the-country contracting firm. My position is mainly translating requirements for them to be able to build and maintain. I am looking to leave this firm to continue growing my skill set, but I am out of practice interviewing, especially in the current market. I am specifically targeting Sr. Data Engineer positions with growth potential as either a Staff Engineer or a Data Architect. Does anyone have any groups for mock interviews and/or study curriculum in order to review for interviews? I specifically need assistance in Python algorithms and system design.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "19d2m9p", "is_robot_indexable": true, "report_reasons": null, "author": "Jonesy-2010", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19d2m9p/need_help_with_interview_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19d2m9p/need_help_with_interview_practice/", "subreddit_subscribers": 154964, "created_utc": 1705948316.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}