{"kind": "Listing", "data": {"after": "t3_198idro", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As per title, my company put out 3 entry level data engineer jobs last year. The pay range was terrible, 60 - 80k. \n\nWe ended up hiring a data engineer with 3 yoe at a Fortune 100, a data engineer with 1 yoe and a masters in machine learning, and a self taught engineer who has built applications that literally make my applications look like children's books. \n\nThey've jumped on projects with some of our previous entry level hires from 2019-2022 and made them look like chumps. \n\nAll of them were looking for jobs for at least 4-6 months. \n\nJust wanted to share a data point on the state of the market last year in 2023. \n\nFunny thing is that I don't expect any of them to stay when the job market picks up, and we may have a mass exodus on our hands. ", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My company just put out 3 data engineering jobs last year, guess who we got?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198kif0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 329, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 329, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705455890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As per title, my company put out 3 entry level data engineer jobs last year. The pay range was terrible, 60 - 80k. &lt;/p&gt;\n\n&lt;p&gt;We ended up hiring a data engineer with 3 yoe at a Fortune 100, a data engineer with 1 yoe and a masters in machine learning, and a self taught engineer who has built applications that literally make my applications look like children&amp;#39;s books. &lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;ve jumped on projects with some of our previous entry level hires from 2019-2022 and made them look like chumps. &lt;/p&gt;\n\n&lt;p&gt;All of them were looking for jobs for at least 4-6 months. &lt;/p&gt;\n\n&lt;p&gt;Just wanted to share a data point on the state of the market last year in 2023. &lt;/p&gt;\n\n&lt;p&gt;Funny thing is that I don&amp;#39;t expect any of them to stay when the job market picks up, and we may have a mass exodus on our hands. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "198kif0", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 78, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/198kif0/my_company_just_put_out_3_data_engineering_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198kif0/my_company_just_put_out_3_data_engineering_jobs/", "subreddit_subscribers": 153550, "created_utc": 1705455890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lakehouse architecture improved the traditional RDBMS-OLAP based data warehousing architecture. It has been around for a while. \nIs there something new in this space ready to replace lakeshouses?", "author_fullname": "t2_9815cpn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is next after Lakehouse architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198lq59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705459248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lakehouse architecture improved the traditional RDBMS-OLAP based data warehousing architecture. It has been around for a while. \nIs there something new in this space ready to replace lakeshouses?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "198lq59", "is_robot_indexable": true, "report_reasons": null, "author": "brokeRichieRich", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198lq59/what_is_next_after_lakehouse_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198lq59/what_is_next_after_lakehouse_architecture/", "subreddit_subscribers": 153550, "created_utc": 1705459248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1c6f704", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Ultimate Guide to Unit Testing With dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_198w13u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "transparent", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kn_7noFCcJ0D3GC3fMXCYuMoZKNZe0YzGczP5o_Lm9E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705496494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datagibberish.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datagibberish.com/p/unit-testing-with-dbt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dMVSnzYeOz4m-v9_lFGHhqBVERA9g-3W0dnAdpsBiQs.jpg?auto=webp&amp;s=64087a3f1c05693b324e04792b5fe96ff216a457", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/dMVSnzYeOz4m-v9_lFGHhqBVERA9g-3W0dnAdpsBiQs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9174980cce3f2892735c33b75d4870bcd8ee80f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/dMVSnzYeOz4m-v9_lFGHhqBVERA9g-3W0dnAdpsBiQs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1c099adcd7a125bb2db8ac947f05ddbe3f0d6cb4", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/dMVSnzYeOz4m-v9_lFGHhqBVERA9g-3W0dnAdpsBiQs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f357a9fdd3ad5f6d9af7cad962d97242a563e81", "width": 320, "height": 320}], "variants": {}, "id": "OawLUvz2FSM3rDsbu-rhVg-PnA7GkLGIR6DvBSR00eE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "198w13u", "is_robot_indexable": true, "report_reasons": null, "author": "ivanovyordan", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/198w13u/the_ultimate_guide_to_unit_testing_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datagibberish.com/p/unit-testing-with-dbt", "subreddit_subscribers": 153550, "created_utc": 1705496494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I've been using databricks for some time now. I looked into DLT when it first came out and didn't like it. It had a lot of missing features/limitations. \n\nI've since moved to a new org that wants to implement databricks. The sales reps have already turned them on to DLT and I feel pretty uneasy about it.\n\nWhen loading data (files in cloud storage) to an append only bronze table, why use DLT? Why not just use autoloader? \n\nI was watching a demo wherein a SCD2 was able to be created with a simple declaration (from a table stream). You had to tell it the id and the sequence, but what if you had multiple IDs that define uniqueness? And multiple dates to use to figure out the order? Does it support that? \n\n\nAnyway, how far has DLT come? I'd like to keep a config that I can loop through to spin up jobs and run in parallel. Is that even compatible with DLT? I really don't want to be manually creating \"pipelines\" for every single table..", "author_fullname": "t2_43fb03vm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My new org thinks databricks DLT can do everything", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198p5hw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705469889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;ve been using databricks for some time now. I looked into DLT when it first came out and didn&amp;#39;t like it. It had a lot of missing features/limitations. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve since moved to a new org that wants to implement databricks. The sales reps have already turned them on to DLT and I feel pretty uneasy about it.&lt;/p&gt;\n\n&lt;p&gt;When loading data (files in cloud storage) to an append only bronze table, why use DLT? Why not just use autoloader? &lt;/p&gt;\n\n&lt;p&gt;I was watching a demo wherein a SCD2 was able to be created with a simple declaration (from a table stream). You had to tell it the id and the sequence, but what if you had multiple IDs that define uniqueness? And multiple dates to use to figure out the order? Does it support that? &lt;/p&gt;\n\n&lt;p&gt;Anyway, how far has DLT come? I&amp;#39;d like to keep a config that I can loop through to spin up jobs and run in parallel. Is that even compatible with DLT? I really don&amp;#39;t want to be manually creating &amp;quot;pipelines&amp;quot; for every single table..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "198p5hw", "is_robot_indexable": true, "report_reasons": null, "author": "idiotlog", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198p5hw/my_new_org_thinks_databricks_dlt_can_do_everything/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198p5hw/my_new_org_thinks_databricks_dlt_can_do_everything/", "subreddit_subscribers": 153550, "created_utc": 1705469889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I could use some thoughts and advice.\n\nI am at a company with 200 employees and just a few data people. Will add more data people soon. We use Snowflake, planning on using DBT as well.\n\nCurrently we are querying a combination of event tables and transactional database tables and have no comprehensive strategy for data modeling. Lots of random views created by various engineers.\n\n* What data modeling approaches have you tried and found most useful? What strikes the right balance of being easiest to maintain and keeping a single source of truth?\n* What is your opinion and experience with the Unified Star Schema approach?\n* Data Vault?\n* Pure Inmon?\n* if you use Kimball star schema, how do you keep the dim and fact tables in a useful multi fact warehouse instead of a bunch of disparate data marts?\n* Do you have any success stories you can share with me? I want to know what it's ke once data is successfully modeled and cleaned.\n\nSorry if this isn't the most coherent question. I don't know what I don't know.", "author_fullname": "t2_jn9782e69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small data team beginning data modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198fqk7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705443688.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705443483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I could use some thoughts and advice.&lt;/p&gt;\n\n&lt;p&gt;I am at a company with 200 employees and just a few data people. Will add more data people soon. We use Snowflake, planning on using DBT as well.&lt;/p&gt;\n\n&lt;p&gt;Currently we are querying a combination of event tables and transactional database tables and have no comprehensive strategy for data modeling. Lots of random views created by various engineers.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What data modeling approaches have you tried and found most useful? What strikes the right balance of being easiest to maintain and keeping a single source of truth?&lt;/li&gt;\n&lt;li&gt;What is your opinion and experience with the Unified Star Schema approach?&lt;/li&gt;\n&lt;li&gt;Data Vault?&lt;/li&gt;\n&lt;li&gt;Pure Inmon?&lt;/li&gt;\n&lt;li&gt;if you use Kimball star schema, how do you keep the dim and fact tables in a useful multi fact warehouse instead of a bunch of disparate data marts?&lt;/li&gt;\n&lt;li&gt;Do you have any success stories you can share with me? I want to know what it&amp;#39;s ke once data is successfully modeled and cleaned.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Sorry if this isn&amp;#39;t the most coherent question. I don&amp;#39;t know what I don&amp;#39;t know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "198fqk7", "is_robot_indexable": true, "report_reasons": null, "author": "Agreeable_Coast_4859", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198fqk7/small_data_team_beginning_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198fqk7/small_data_team_beginning_data_modeling/", "subreddit_subscribers": 153550, "created_utc": 1705443483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\n&amp;#x200B;\n\nI'm currently learning Dagster (open source). At the moment I'm stucked on setting up the snowflake IO Manager. I want to load all my tables which are in my database\\_test DB stored in my schema\\_test schema.\n\n&amp;#x200B;\n\nFollowing the docs ( [Using Dagster with Snowflake | Dagster Docs](https://docs.dagster.io/integrations/snowflake/using-snowflake-with-dagster) ) didn't help at all.\n\n&amp;#x200B;\n\nWhat's the easiest code example to connect to my Snowflake DB?\n\n&amp;#x200B;\n\nThanks in advance!", "author_fullname": "t2_19ci35mg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster - Snowflake IO Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198wapm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705497600.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705497344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently learning Dagster (open source). At the moment I&amp;#39;m stucked on setting up the snowflake IO Manager. I want to load all my tables which are in my database_test DB stored in my schema_test schema.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Following the docs ( &lt;a href=\"https://docs.dagster.io/integrations/snowflake/using-snowflake-with-dagster\"&gt;Using Dagster with Snowflake | Dagster Docs&lt;/a&gt; ) didn&amp;#39;t help at all.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the easiest code example to connect to my Snowflake DB?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?auto=webp&amp;s=d9eec3bfbfc3fd565643229f8a84c399bc1fe73b", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=499be57a5b257c149c9417e04fb72b227c3fc6bc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=41c03559a31ecfba73ee7ff44bd6293216bcd5f6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1f3696c3a4f7025280b0a98110eadfe130536c4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a12aeb324dd791c5dbd277a3131545efcfa5b3fe", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bceae394da1ca70512dad8f5ec6ce1e142472e86", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/f_qGYoavWVH20j0QhjrqbfrQFEuALkYkaXBnJtU_xs4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=29800a80de6287c32b91b05133f7c8e4a2d57eb2", "width": 1080, "height": 567}], "variants": {}, "id": "gUU0nwKC8lE8qWjp6y6pjjOolTxbCTTaSrkKGe3Kq6A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "198wapm", "is_robot_indexable": true, "report_reasons": null, "author": "JEY1337", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198wapm/dagster_snowflake_io_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198wapm/dagster_snowflake_io_manager/", "subreddit_subscribers": 153550, "created_utc": 1705497344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m fairly new to both dagster and dbt cloud but do have some experience with both. \n\nI\u2019ve successfully setup a pipeline in dagster that grabs raw data from an API, loads it to cloud storage and copies the raw data from parquet format into snowflake. \n\nI separately have dbt setup to take that raw data and build some data models. \n\nNow I simply want to trigger the dbt cloud job to run once the data pippeline job runs via dagster but I can\u2019t for the life of me figure out the syntax. I\u2019m able to get everything to run in one \u201crun everything\u201d job but this defeats the purpose of having my dbt cloud assets be dependent on the completion of the data pipeline job. Please help???\n\nHas anyone done this before using dbt cloud (not dbt core)?", "author_fullname": "t2_63dasqqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automate dbt cloud using Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198o11q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705466168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m fairly new to both dagster and dbt cloud but do have some experience with both. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve successfully setup a pipeline in dagster that grabs raw data from an API, loads it to cloud storage and copies the raw data from parquet format into snowflake. &lt;/p&gt;\n\n&lt;p&gt;I separately have dbt setup to take that raw data and build some data models. &lt;/p&gt;\n\n&lt;p&gt;Now I simply want to trigger the dbt cloud job to run once the data pippeline job runs via dagster but I can\u2019t for the life of me figure out the syntax. I\u2019m able to get everything to run in one \u201crun everything\u201d job but this defeats the purpose of having my dbt cloud assets be dependent on the completion of the data pipeline job. Please help???&lt;/p&gt;\n\n&lt;p&gt;Has anyone done this before using dbt cloud (not dbt core)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "198o11q", "is_robot_indexable": true, "report_reasons": null, "author": "skiyogagolfbeer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198o11q/automate_dbt_cloud_using_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198o11q/automate_dbt_cloud_using_dagster/", "subreddit_subscribers": 153550, "created_utc": 1705466168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello experienced devs,\nI am a noob DE working in ADF, SSMS, data modelling and data warehousing with the government as a contractor. \n\nI am posting this as I recently switched from Manufacturing to IT and want to maintain a network with people that have exp in DE so I can learn and grow to become a completely capable software engineer; occasional chats/call is the most I\u2019m going to ask for. Since I\u2019m a contractor, I cannot connect/ask for guidance in my workplace\n\nCouple of years back I was an IE working on process improvements. I slowly learnt to write sql queries, get data from different internal systems, analyze the data and find opportunities for improvement. \n\nOne day I found out that what I was doing was not very different from our in-house data analyst\u2019s role. \n\nThen, I learned Azure services and got a job as a contractor. Now I\u2019m struggling to move up and would need your mentorship. I am in NYC area, so I can meetup at your convineance.\n\ntl;dr: a noob DE want a mentor to help navigate through the data carrier.", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got some time to mentor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1991m63", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705511140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello experienced devs,\nI am a noob DE working in ADF, SSMS, data modelling and data warehousing with the government as a contractor. &lt;/p&gt;\n\n&lt;p&gt;I am posting this as I recently switched from Manufacturing to IT and want to maintain a network with people that have exp in DE so I can learn and grow to become a completely capable software engineer; occasional chats/call is the most I\u2019m going to ask for. Since I\u2019m a contractor, I cannot connect/ask for guidance in my workplace&lt;/p&gt;\n\n&lt;p&gt;Couple of years back I was an IE working on process improvements. I slowly learnt to write sql queries, get data from different internal systems, analyze the data and find opportunities for improvement. &lt;/p&gt;\n\n&lt;p&gt;One day I found out that what I was doing was not very different from our in-house data analyst\u2019s role. &lt;/p&gt;\n\n&lt;p&gt;Then, I learned Azure services and got a job as a contractor. Now I\u2019m struggling to move up and would need your mentorship. I am in NYC area, so I can meetup at your convineance.&lt;/p&gt;\n\n&lt;p&gt;tl;dr: a noob DE want a mentor to help navigate through the data carrier.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1991m63", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1991m63/got_some_time_to_mentor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1991m63/got_some_time_to_mentor/", "subreddit_subscribers": 153550, "created_utc": 1705511140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cqao8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL for Google Sheets with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_198sy24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QonQ2q6Ct33jQlxSJKFOz1dervwrpJTqlYAOSuX9XZA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705484917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arecadata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arecadata.com/sql-for-google-sheets-with-duckdb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7ZRQvuU8PKFok9cDWlvTgXaB0oac1_t3sOGjdgWBP8c.jpg?auto=webp&amp;s=79cf82dfea254c1f96569009765549b4cac35c7e", "width": 1665, "height": 904}, "resolutions": [{"url": "https://external-preview.redd.it/7ZRQvuU8PKFok9cDWlvTgXaB0oac1_t3sOGjdgWBP8c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f23bb3403b5a5a4d943532485c9e42b8c375d8ad", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/7ZRQvuU8PKFok9cDWlvTgXaB0oac1_t3sOGjdgWBP8c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cf8729134fcbbcadea38a781c94cdc9b480cc4c7", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/7ZRQvuU8PKFok9cDWlvTgXaB0oac1_t3sOGjdgWBP8c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5cf52379a8af91a21f1355d748fb655f02d61bdc", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/7ZRQvuU8PKFok9cDWlvTgXaB0oac1_t3sOGjdgWBP8c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb026b5956879b04f7fc428f1a9a568984da0d58", "width": 640, "height": 347}, {"url": "https://external-preview.redd.it/7ZRQvuU8PKFok9cDWlvTgXaB0oac1_t3sOGjdgWBP8c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=51c253aa237b7b3a301cd606688bfec449f994a6", "width": 960, "height": 521}, {"url": "https://external-preview.redd.it/7ZRQvuU8PKFok9cDWlvTgXaB0oac1_t3sOGjdgWBP8c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=944dcf6fbf757fd57cf8e86abaf10425ca135714", "width": 1080, "height": 586}], "variants": {}, "id": "o9IGQNlzMMFSGi3oonRSmbtuC-Rh9y1ZsRkdqm26PEA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "198sy24", "is_robot_indexable": true, "report_reasons": null, "author": "dan_the_lion", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198sy24/sql_for_google_sheets_with_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arecadata.com/sql-for-google-sheets-with-duckdb/", "subreddit_subscribers": 153550, "created_utc": 1705484917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Reddit, i turn to you once again for a DE issue. TIA.\n\n&amp;#x200B;\n\n**Currently:**\n\n\"RDS MySQL &gt; DMS &gt; Redshift\"\n\nDMS is configured for a \\`full load, ongoing replication\\` (lags around 6-12 hours everyday ig)\n\n&amp;#x200B;\n\n**Problem:**\n\nExpense (unutilized instance after initial full load) and want to move away CDC to a different tool, as a POC\n\n&amp;#x200B;\n\n**POC** **TODO**: (*no choice here*)\n\nMySQL &gt; Kafka &gt; *Redshift sync connector (necessarily)*\n\n&amp;#x200B;\n\nAssuming the POC *has* to be done..\n\n*Questions:*\n\n1. **Duplicates**: There's mention of \"atleast once delivery\" into sync'd table, and a dummy topic set up on confluent cloud confirmed presence of \\~10k dupes per 1mil rows. Support could not answer pattern on when/why it occurs. How should one tackle this? Not sure if ksqdDB/single message transform can help here.\n2. **CDC:** There is a latest\\_updated\\_ts to help determine updates, how can the sync connector handle upserting? [docs](https://docs.confluent.io/kafka-connectors/aws-redshift/current/sink_config_options.html#redshift-sink-config-options) mention insert OR update (\"*this will only apply when modifying a record; you can\u2019t use this mode to insert a new record if the record doesn\u2019t already exist*\"). Solution to run two parallel ones?\n3. What other tests should one do? I've done basic data sanity checks so far, and plan to set up a kafka local to stream to redshift to test a dummy run.\n\nApologies if there's basic issues in my writings. TIA, once again!", "author_fullname": "t2_vvcegq1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift sync connector to replace DMS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_199105x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705511098.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705509739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Reddit, i turn to you once again for a DE issue. TIA.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Currently:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;RDS MySQL &amp;gt; DMS &amp;gt; Redshift&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;DMS is configured for a `full load, ongoing replication` (lags around 6-12 hours everyday ig)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Expense (unutilized instance after initial full load) and want to move away CDC to a different tool, as a POC&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;POC&lt;/strong&gt; &lt;strong&gt;TODO&lt;/strong&gt;: (&lt;em&gt;no choice here&lt;/em&gt;)&lt;/p&gt;\n\n&lt;p&gt;MySQL &amp;gt; Kafka &amp;gt; &lt;em&gt;Redshift sync connector (necessarily)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Assuming the POC &lt;em&gt;has&lt;/em&gt; to be done..&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Questions:&lt;/em&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Duplicates&lt;/strong&gt;: There&amp;#39;s mention of &amp;quot;atleast once delivery&amp;quot; into sync&amp;#39;d table, and a dummy topic set up on confluent cloud confirmed presence of ~10k dupes per 1mil rows. Support could not answer pattern on when/why it occurs. How should one tackle this? Not sure if ksqdDB/single message transform can help here.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;CDC:&lt;/strong&gt; There is a latest_updated_ts to help determine updates, how can the sync connector handle upserting? &lt;a href=\"https://docs.confluent.io/kafka-connectors/aws-redshift/current/sink_config_options.html#redshift-sink-config-options\"&gt;docs&lt;/a&gt; mention insert OR update (&amp;quot;&lt;em&gt;this will only apply when modifying a record; you can\u2019t use this mode to insert a new record if the record doesn\u2019t already exist&lt;/em&gt;&amp;quot;). Solution to run two parallel ones?&lt;/li&gt;\n&lt;li&gt;What other tests should one do? I&amp;#39;ve done basic data sanity checks so far, and plan to set up a kafka local to stream to redshift to test a dummy run.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Apologies if there&amp;#39;s basic issues in my writings. TIA, once again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "199105x", "is_robot_indexable": true, "report_reasons": null, "author": "LocksmithConnect6201", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/199105x/redshift_sync_connector_to_replace_dms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/199105x/redshift_sync_connector_to_replace_dms/", "subreddit_subscribers": 153550, "created_utc": 1705509739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jjbftfcy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accelerate Your Data Journey: Practical Guide to S3-to-RDS ETL Using Lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "name": "t3_198upu8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/J7g7kkt1GV3YQ4ar8AkMRKEF_h6ipyCPAbOjuogqqsg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705491971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@naveenkumarmurugan/accelerate-your-data-journey-practical-guide-to-s3-to-rds-etl-using-lambda-daf14010a68f", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gJxK7HTbOShTpW3iKMHsfmPV0m8lFI7WDOoyF03XEl8.jpg?auto=webp&amp;s=4cccdace1f06100e8b15d7f71dbd25041348c066", "width": 1200, "height": 560}, "resolutions": [{"url": "https://external-preview.redd.it/gJxK7HTbOShTpW3iKMHsfmPV0m8lFI7WDOoyF03XEl8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb61276e7771e05fbb066256f5ebb80401253729", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/gJxK7HTbOShTpW3iKMHsfmPV0m8lFI7WDOoyF03XEl8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=018d40d1544e69e68116c4446c506ed3fce9e65c", "width": 216, "height": 100}, {"url": "https://external-preview.redd.it/gJxK7HTbOShTpW3iKMHsfmPV0m8lFI7WDOoyF03XEl8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=58fb13ba4bc48ff170c66d82805481e4293a9826", "width": 320, "height": 149}, {"url": "https://external-preview.redd.it/gJxK7HTbOShTpW3iKMHsfmPV0m8lFI7WDOoyF03XEl8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f5b5e858a201d5a6d09f6f3add94ce64703f448", "width": 640, "height": 298}, {"url": "https://external-preview.redd.it/gJxK7HTbOShTpW3iKMHsfmPV0m8lFI7WDOoyF03XEl8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b8d2b20c5b8556b5af4fcade3bbe29227f8528b3", "width": 960, "height": 448}, {"url": "https://external-preview.redd.it/gJxK7HTbOShTpW3iKMHsfmPV0m8lFI7WDOoyF03XEl8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2c630ddb170f561cb6e302b4227065f25b1e18bb", "width": 1080, "height": 504}], "variants": {}, "id": "ewiNCqTi5aC4JriP7acXZF3BPP20WAetGZKr2BsRSLg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "198upu8", "is_robot_indexable": true, "report_reasons": null, "author": "BigNo3623", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198upu8/accelerate_your_data_journey_practical_guide_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@naveenkumarmurugan/accelerate-your-data-journey-practical-guide-to-s3-to-rds-etl-using-lambda-daf14010a68f", "subreddit_subscribers": 153550, "created_utc": 1705491971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jjbftfcy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to use Client-side AWS KMS encryption and How?: A step by step Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_198uhpg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yeM_HQbmU8B7P0K5rySXckKX__36z3I7Y2ATXmWUVzI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705491134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yzvszoppkzcc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yzvszoppkzcc1.png?auto=webp&amp;s=369274cb48b154e34781caf9e11fa7eaa227d35d", "width": 2203, "height": 1039}, "resolutions": [{"url": "https://preview.redd.it/yzvszoppkzcc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=de736b19444400c2e4a6036b85f282351cfa4c69", "width": 108, "height": 50}, {"url": "https://preview.redd.it/yzvszoppkzcc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5fc8aa0f22157431c64ce08509fff734e32d4ce3", "width": 216, "height": 101}, {"url": "https://preview.redd.it/yzvszoppkzcc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=05d129a9de643917cd902df03a1d75c9c475cd8b", "width": 320, "height": 150}, {"url": "https://preview.redd.it/yzvszoppkzcc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=07c0bdc61d316e34d2d64a0fac7ba6d7a2be51c1", "width": 640, "height": 301}, {"url": "https://preview.redd.it/yzvszoppkzcc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4196ba19dbafc5a5cf65f5d23bff885820c4bf7c", "width": 960, "height": 452}, {"url": "https://preview.redd.it/yzvszoppkzcc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3e547e855418bdd043cdc2a88c82419f8f2b9a1a", "width": 1080, "height": 509}], "variants": {}, "id": "rXfkmCXHpeSvTPCKimUXQCm_lZFbE8yKHXsqW1-afeU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "198uhpg", "is_robot_indexable": true, "report_reasons": null, "author": "BigNo3623", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198uhpg/when_to_use_clientside_aws_kms_encryption_and_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yzvszoppkzcc1.png", "subreddit_subscribers": 153550, "created_utc": 1705491134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nHow would you approach a project, where a DWH is to be migrated from on-prem, teradata, to a private cloud, spark based solution?\n\nI only know spark as a processing engine, and from what I've been reading, no one actually uses it for it's data storage functionalities ('databases', 'tables', and so on). \n\nSo I don't know too much about data architecture, as I've always been just implementing stuff that someone designed (mostly ETL pipelines with spark/airflow). And spark was used to get data from point A to point B, with transformations in between.\n\nDoes any of you work with spark as a processing engine for DWH? How does it work? Can DWH even be in a form of parquet files lying in buckets? How would the data architecture be imposed then? Would dbt help here?\n\nAs you can see, I'm new to the architecture side of data engineering, so please forgive me if some of the questions don't make sense. I'd gladly check out any recommended resources. \n\nThanks", "author_fullname": "t2_gejetxj65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark in pair with DWH?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198pgon", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705470969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;How would you approach a project, where a DWH is to be migrated from on-prem, teradata, to a private cloud, spark based solution?&lt;/p&gt;\n\n&lt;p&gt;I only know spark as a processing engine, and from what I&amp;#39;ve been reading, no one actually uses it for it&amp;#39;s data storage functionalities (&amp;#39;databases&amp;#39;, &amp;#39;tables&amp;#39;, and so on). &lt;/p&gt;\n\n&lt;p&gt;So I don&amp;#39;t know too much about data architecture, as I&amp;#39;ve always been just implementing stuff that someone designed (mostly ETL pipelines with spark/airflow). And spark was used to get data from point A to point B, with transformations in between.&lt;/p&gt;\n\n&lt;p&gt;Does any of you work with spark as a processing engine for DWH? How does it work? Can DWH even be in a form of parquet files lying in buckets? How would the data architecture be imposed then? Would dbt help here?&lt;/p&gt;\n\n&lt;p&gt;As you can see, I&amp;#39;m new to the architecture side of data engineering, so please forgive me if some of the questions don&amp;#39;t make sense. I&amp;#39;d gladly check out any recommended resources. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "198pgon", "is_robot_indexable": true, "report_reasons": null, "author": "Visual-Exercise8031", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198pgon/spark_in_pair_with_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198pgon/spark_in_pair_with_dwh/", "subreddit_subscribers": 153550, "created_utc": 1705470969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi my brother finished a few years ago his bachlor degree and I want to give him as a gift for his birthday a course that would be relevant for his career and help him in his profession \n\nThx for the helpers", "author_fullname": "t2_6csylq0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Relevant Course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198cvhr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705436657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi my brother finished a few years ago his bachlor degree and I want to give him as a gift for his birthday a course that would be relevant for his career and help him in his profession &lt;/p&gt;\n\n&lt;p&gt;Thx for the helpers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "198cvhr", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Issue4573", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198cvhr/relevant_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198cvhr/relevant_course/", "subreddit_subscribers": 153550, "created_utc": 1705436657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_evm58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hoping fellow DE can give me some feedback on my resume.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_1992zlr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GUloKlOt58hPWw9uQa9XsAYI4lv530Z046qTziME1KU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705514287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/utxbz18gh1dc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/utxbz18gh1dc1.png?auto=webp&amp;s=6e53052d7786d5fa629a1612de73d00d4708034c", "width": 772, "height": 928}, "resolutions": [{"url": "https://preview.redd.it/utxbz18gh1dc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=33badf8fd6365ccd3af6ca5ecab1f688b274f211", "width": 108, "height": 129}, {"url": "https://preview.redd.it/utxbz18gh1dc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb8e996a2125dd20c89fca1322eb9010f86513d2", "width": 216, "height": 259}, {"url": "https://preview.redd.it/utxbz18gh1dc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c6f4e673a161f5d4991bd8acc68a0e9735c371d8", "width": 320, "height": 384}, {"url": "https://preview.redd.it/utxbz18gh1dc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b1c2b36082501e5de6bd43e71319de43fc0a7df", "width": 640, "height": 769}], "variants": {}, "id": "o1z7VMsHfR4YCBavQ4MEahYGIEtDAidvNR4BRBV4bd4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1992zlr", "is_robot_indexable": true, "report_reasons": null, "author": "yason2", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1992zlr/hoping_fellow_de_can_give_me_some_feedback_on_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/utxbz18gh1dc1.png", "subreddit_subscribers": 153550, "created_utc": 1705514287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intro to SQL Indexes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": true, "name": "t3_1991uni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2DRFBEjOvA1bk39vxVMwPZ3SCS2QfqVEESm-rljHqYQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705511648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/intro-to-sql-indexes", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?auto=webp&amp;s=db0dd46d348e43b93993efd89a3ab3188a2f750b", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb2ea7d2253e0b13f31c2b3a501bdb079c99f02a", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=774a9c7b5b1e9f2a6f0c3ad95da0fc6d8a27e60d", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59a28b06415dd585266957e277e86b821c702bb2", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe6f8284bd45732fa8e0bf3c2c0a5161ba9cfde4", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/jv05JgvI3EHf1zXyxBXB7grYHCq0OAKya3QUKdXwQt0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fadc5fdf695a74ba6f949375c70332ad149ab17d", "width": 960, "height": 562}], "variants": {}, "id": "Xv37p1IZSW1jS6YQK2dPjfcAGpVMaRZFFbZVqXsuRIE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1991uni", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1991uni/intro_to_sql_indexes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/intro-to-sql-indexes", "subreddit_subscribers": 153550, "created_utc": 1705511648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All!\n\nToday, I'm launching [a project that I have been working on](https://www.linkedin.com/posts/briana-okyere_introducing-the-astronomer-champions-program-activity-7153422011896074240-qimp?utm_source=share&amp;utm_medium=member_desktop) for the last 6 months, and I want to share it with all of you.\n\nThe Astronomer Champions Program for Apache Airflow aims to **recognize outstanding data practitioners worldwide** who have **demonstrated excellence in leveraging the full capabilities of Apache Airflow in diverse capacities**. Today, I'm celebrating our Inaugural Cohort, and if you are passionate about Airflow, please [apply](https://docs.google.com/forms/d/e/1FAIpQLScSKVzfRf3wppjUbzx0dUzFLwoP66ZfQ6rYLjk9ZASzpKA2Dw/viewform) to our next cohort.\n\n[**Learn more about the program here**](https://www.astronomer.io/blog/introducing-the-astronomer-champions-program-for-apache-airflow/)**, and feel free to respond with any questions!**", "author_fullname": "t2_l5gu8nhgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Champions Program for Apache Airflow- Invite to Apply", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1991so2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705511520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All!&lt;/p&gt;\n\n&lt;p&gt;Today, I&amp;#39;m launching &lt;a href=\"https://www.linkedin.com/posts/briana-okyere_introducing-the-astronomer-champions-program-activity-7153422011896074240-qimp?utm_source=share&amp;amp;utm_medium=member_desktop\"&gt;a project that I have been working on&lt;/a&gt; for the last 6 months, and I want to share it with all of you.&lt;/p&gt;\n\n&lt;p&gt;The Astronomer Champions Program for Apache Airflow aims to &lt;strong&gt;recognize outstanding data practitioners worldwide&lt;/strong&gt; who have &lt;strong&gt;demonstrated excellence in leveraging the full capabilities of Apache Airflow in diverse capacities&lt;/strong&gt;. Today, I&amp;#39;m celebrating our Inaugural Cohort, and if you are passionate about Airflow, please &lt;a href=\"https://docs.google.com/forms/d/e/1FAIpQLScSKVzfRf3wppjUbzx0dUzFLwoP66ZfQ6rYLjk9ZASzpKA2Dw/viewform\"&gt;apply&lt;/a&gt; to our next cohort.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.astronomer.io/blog/introducing-the-astronomer-champions-program-for-apache-airflow/\"&gt;&lt;strong&gt;Learn more about the program here&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;, and feel free to respond with any questions!&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?auto=webp&amp;s=2d909d5a7d65908ef8fcfd7949a9b73664913bbe", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e0e68f887e066789358abba6b4426e3b4fe124a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f61ce6fc49f2b1d4585439a5738a62f4939e4a8e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d116fced6575e8124b63ea2f80a67d1954f3ee92", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/xzWehCXnt8MMYbfp5pL-1OxB_6AgZ7eophBngnzVD60.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac1df5a47081fff76bdfe8de826b9f1b9b741c3a", "width": 640, "height": 360}], "variants": {}, "id": "yH5v3ow6vBGicYhsqdR2lMV56YgJD_KEIWRCxL-rZac"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1991so2", "is_robot_indexable": true, "report_reasons": null, "author": "BrianaGraceOkyere", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1991so2/champions_program_for_apache_airflow_invite_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1991so2/champions_program_for_apache_airflow_invite_to/", "subreddit_subscribers": 153550, "created_utc": 1705511520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "API Orchestration Solutions\n\nHi,\n\nI am looking for an API Orchestrator solution.\n\nRequirements:\n\n1. Given a list of API endpoints represented in a configuration of sequence and parallel execution, I want the orchestrator to call the APIs in the serial/parallel order as described in the configuration. The first API in the list will accept the input for the sequence, and the last API will produce the output.\n2. I am looking for an OpenSource library-based solution. I am not interested in a fully hosted solution. Happy to consider Azure solutions since I use Azure. \n3. I want to provide my customers with a domain-specific language (DSL) that they can use to define their orchestration configuration. The system will accept the configuration, create the Orchestration, and expose the API. \n4. I want to provide a way in the DSL for Customers to specify the mapping between the input/output data types to chain the APIs in the configuration.\n5. I want the call to the API Orchestration to be synchronous (not an asynchronous / polling model). Given a request, I want the API Orchestrator to execute the APIs as specified in the configuration and return the response synchronously in a few milliseconds to less than a couple of seconds. The APIs being orchestrated will ensure they return responses in the order of milliseconds.", "author_fullname": "t2_8xmun4y0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API Orchestrator Solutions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198zyr4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705507304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;API Orchestration Solutions&lt;/p&gt;\n\n&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am looking for an API Orchestrator solution.&lt;/p&gt;\n\n&lt;p&gt;Requirements:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Given a list of API endpoints represented in a configuration of sequence and parallel execution, I want the orchestrator to call the APIs in the serial/parallel order as described in the configuration. The first API in the list will accept the input for the sequence, and the last API will produce the output.&lt;/li&gt;\n&lt;li&gt;I am looking for an OpenSource library-based solution. I am not interested in a fully hosted solution. Happy to consider Azure solutions since I use Azure. &lt;/li&gt;\n&lt;li&gt;I want to provide my customers with a domain-specific language (DSL) that they can use to define their orchestration configuration. The system will accept the configuration, create the Orchestration, and expose the API. &lt;/li&gt;\n&lt;li&gt;I want to provide a way in the DSL for Customers to specify the mapping between the input/output data types to chain the APIs in the configuration.&lt;/li&gt;\n&lt;li&gt;I want the call to the API Orchestration to be synchronous (not an asynchronous / polling model). Given a request, I want the API Orchestrator to execute the APIs as specified in the configuration and return the response synchronously in a few milliseconds to less than a couple of seconds. The APIs being orchestrated will ensure they return responses in the order of milliseconds.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "198zyr4", "is_robot_indexable": true, "report_reasons": null, "author": "RedHawk004", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198zyr4/api_orchestrator_solutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198zyr4/api_orchestrator_solutions/", "subreddit_subscribers": 153550, "created_utc": 1705507304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Had an interesting debate at work (RTO brings those stuff) regarding IntelliJ community edition and VSCode. I am looking to install plugins for working with Kafka.\n\nWhile IntelliJ has Kafka plugin available as part of their Ultimate edition, there is no way to install one with the community edition. VSCode is more flexible on that front yet lacks some capabilities on the actual programming side. \n\n&amp;#x200B;\n\nI wonder if you had similar experiences and which IDE are you currently using? ", "author_fullname": "t2_q0v84hhtb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VSCode vs. IntelliJ community edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198zbgn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705505712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had an interesting debate at work (RTO brings those stuff) regarding IntelliJ community edition and VSCode. I am looking to install plugins for working with Kafka.&lt;/p&gt;\n\n&lt;p&gt;While IntelliJ has Kafka plugin available as part of their Ultimate edition, there is no way to install one with the community edition. VSCode is more flexible on that front yet lacks some capabilities on the actual programming side. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I wonder if you had similar experiences and which IDE are you currently using? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "198zbgn", "is_robot_indexable": true, "report_reasons": null, "author": "joinjoin_oom", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198zbgn/vscode_vs_intellij_community_edition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198zbgn/vscode_vs_intellij_community_edition/", "subreddit_subscribers": 153550, "created_utc": 1705505712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have a project where I need to compare two different knowledge graph in SQL. \nIs there a paper or a book that I can refer to that can point me in the right direction?\n\nI know there is schema comparison for SQL but not sure if that is even applicable for graph database types. \n\nAny help is much appreciated.", "author_fullname": "t2_9cma3444", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing graph databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198w3ao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705496681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a project where I need to compare two different knowledge graph in SQL. \nIs there a paper or a book that I can refer to that can point me in the right direction?&lt;/p&gt;\n\n&lt;p&gt;I know there is schema comparison for SQL but not sure if that is even applicable for graph database types. &lt;/p&gt;\n\n&lt;p&gt;Any help is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "198w3ao", "is_robot_indexable": true, "report_reasons": null, "author": "Whole-Yogurtcloset16", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198w3ao/comparing_graph_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198w3ao/comparing_graph_databases/", "subreddit_subscribers": 153550, "created_utc": 1705496681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "HI All, \n\nI'm currently going through a Microsoft tutorial on data warehousing and came across a T-SQL script that has raised some questions about best practices. Here's the full code from the tutorial:\n\n     CREATE SCHEMA [Sales]\n     GO\n            \n     IF NOT EXISTS (SELECT * FROM sys.tables WHERE name='Fact_Sales' AND SCHEMA_NAME(schema_id)='Sales')\n     \tCREATE TABLE Sales.Fact_Sales (\n     \t\tCustomerID VARCHAR(255) NOT NULL,\n     \t\tItemID VARCHAR(255) NOT NULL,\n     \t\tSalesOrderNumber VARCHAR(30),\n     \t\tSalesOrderLineNumber INT,\n     \t\tOrderDate DATE,\n     \t\tQuantity INT,\n     \t\tTaxAmount FLOAT,\n     \t\tUnitPrice FLOAT\n     \t);\n        \n     IF NOT EXISTS (SELECT * FROM sys.tables WHERE name='Dim_Customer' AND SCHEMA_NAME(schema_id)='Sales')\n         CREATE TABLE Sales.Dim_Customer (\n             CustomerID VARCHAR(255) NOT NULL,\n             CustomerName VARCHAR(255) NOT NULL,\n             EmailAddress VARCHAR(255) NOT NULL\n         );\n            \n     ALTER TABLE Sales.Dim_Customer add CONSTRAINT PK_Dim_Customer PRIMARY KEY NONCLUSTERED (CustomerID) NOT ENFORCED\n     GO\n        \n     IF NOT EXISTS (SELECT * FROM sys.tables WHERE name='Dim_Item' AND SCHEMA_NAME(schema_id)='Sales')\n         CREATE TABLE Sales.Dim_Item (\n             ItemID VARCHAR(255) NOT NULL,\n             ItemName VARCHAR(255) NOT NULL\n         );\n            \n     ALTER TABLE Sales.Dim_Item add CONSTRAINT PK_Dim_Item PRIMARY KEY NONCLUSTERED (ItemID) NOT ENFORCED\n     GO\n        \n     CREATE VIEW [Sales].[Staging_Sales]\n     AS\n         SELECT * FROM [ExternalData].[dbo].[staging_sales];\n     GO\n\n My question revolves around the use of the following line:\n\n     IF NOT EXISTS (SELECT * FROM sys.tables WHERE name='Fact_Sales' AND SCHEMA_NAME(schema_id)='Sales')\n    \n\nIn this script, a schema is created, and then there's a check if a table exists within that schema. I find this approach unusual. Why would a table exist in a schema if the schema itself was just created? I've read several other Microsoft materials, but this is the first time I've seen this implementation. Also, concerning the line:\n\n    ALTER TABLE Sales.Dim_Customer add CONSTRAINT PK_Dim_Customer PRIMARY KEY NONCLUSTERED (CustomerID) NOT ENFORCED \n\nI recall other Microsoft tutorials where tables and constraints were created simultaneously, without using ALTER TABLE.\n\nIs this a common or recommended practice in SQL, or is there a specific reason for this approach in the context of data warehousing?\n\nAny insights or clarifications would be greatly appreciated. Thank you!", "author_fullname": "t2_7r901d2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question About SQL Practices in Microsoft Data Warehousing Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198ur91", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705492116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HI All, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently going through a Microsoft tutorial on data warehousing and came across a T-SQL script that has raised some questions about best practices. Here&amp;#39;s the full code from the tutorial:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; CREATE SCHEMA [Sales]\n GO\n\n IF NOT EXISTS (SELECT * FROM sys.tables WHERE name=&amp;#39;Fact_Sales&amp;#39; AND SCHEMA_NAME(schema_id)=&amp;#39;Sales&amp;#39;)\n    CREATE TABLE Sales.Fact_Sales (\n        CustomerID VARCHAR(255) NOT NULL,\n        ItemID VARCHAR(255) NOT NULL,\n        SalesOrderNumber VARCHAR(30),\n        SalesOrderLineNumber INT,\n        OrderDate DATE,\n        Quantity INT,\n        TaxAmount FLOAT,\n        UnitPrice FLOAT\n    );\n\n IF NOT EXISTS (SELECT * FROM sys.tables WHERE name=&amp;#39;Dim_Customer&amp;#39; AND SCHEMA_NAME(schema_id)=&amp;#39;Sales&amp;#39;)\n     CREATE TABLE Sales.Dim_Customer (\n         CustomerID VARCHAR(255) NOT NULL,\n         CustomerName VARCHAR(255) NOT NULL,\n         EmailAddress VARCHAR(255) NOT NULL\n     );\n\n ALTER TABLE Sales.Dim_Customer add CONSTRAINT PK_Dim_Customer PRIMARY KEY NONCLUSTERED (CustomerID) NOT ENFORCED\n GO\n\n IF NOT EXISTS (SELECT * FROM sys.tables WHERE name=&amp;#39;Dim_Item&amp;#39; AND SCHEMA_NAME(schema_id)=&amp;#39;Sales&amp;#39;)\n     CREATE TABLE Sales.Dim_Item (\n         ItemID VARCHAR(255) NOT NULL,\n         ItemName VARCHAR(255) NOT NULL\n     );\n\n ALTER TABLE Sales.Dim_Item add CONSTRAINT PK_Dim_Item PRIMARY KEY NONCLUSTERED (ItemID) NOT ENFORCED\n GO\n\n CREATE VIEW [Sales].[Staging_Sales]\n AS\n     SELECT * FROM [ExternalData].[dbo].[staging_sales];\n GO\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My question revolves around the use of the following line:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; IF NOT EXISTS (SELECT * FROM sys.tables WHERE name=&amp;#39;Fact_Sales&amp;#39; AND SCHEMA_NAME(schema_id)=&amp;#39;Sales&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;In this script, a schema is created, and then there&amp;#39;s a check if a table exists within that schema. I find this approach unusual. Why would a table exist in a schema if the schema itself was just created? I&amp;#39;ve read several other Microsoft materials, but this is the first time I&amp;#39;ve seen this implementation. Also, concerning the line:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ALTER TABLE Sales.Dim_Customer add CONSTRAINT PK_Dim_Customer PRIMARY KEY NONCLUSTERED (CustomerID) NOT ENFORCED \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I recall other Microsoft tutorials where tables and constraints were created simultaneously, without using ALTER TABLE.&lt;/p&gt;\n\n&lt;p&gt;Is this a common or recommended practice in SQL, or is there a specific reason for this approach in the context of data warehousing?&lt;/p&gt;\n\n&lt;p&gt;Any insights or clarifications would be greatly appreciated. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "198ur91", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Necessary-6455", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198ur91/question_about_sql_practices_in_microsoft_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198ur91/question_about_sql_practices_in_microsoft_data/", "subreddit_subscribers": 153550, "created_utc": 1705492116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_etdi5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB vs ClickHouse performance comparison for structured data serialization and in-memory TPC-DS queries execution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198tb7f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1705486447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bicortex.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "http://bicortex.com/duckdb-vs-clickhouse-performance-comparison-for-structured-data-serialization-and-in-memory-tpc-ds-queries-execution/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "198tb7f", "is_robot_indexable": true, "report_reasons": null, "author": "dingopole", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198tb7f/duckdb_vs_clickhouse_performance_comparison_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "http://bicortex.com/duckdb-vs-clickhouse-performance-comparison-for-structured-data-serialization-and-in-memory-tpc-ds-queries-execution/", "subreddit_subscribers": 153550, "created_utc": 1705486447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any data quality libraries for Spark that you recommend based on your experience? We plan to gather metrics in Spark after processing the data and send them to Prometheus for visualization in Grafana. Any suggestions?", "author_fullname": "t2_lagrx3zi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data quality library for spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198sxiv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705484845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any data quality libraries for Spark that you recommend based on your experience? We plan to gather metrics in Spark after processing the data and send them to Prometheus for visualization in Grafana. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "198sxiv", "is_robot_indexable": true, "report_reasons": null, "author": "VegetableRecord2633", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198sxiv/data_quality_library_for_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198sxiv/data_quality_library_for_spark/", "subreddit_subscribers": 153550, "created_utc": 1705484845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Customers run MinIO wherever they need fast, resilient, scalable object storage. MinIO includes several types of replication to make sure that every application is working with the most recent data regardless of where it runs. We\u2019ve gone into great detail about the various replication options available and their best practices in previous posts about [Batch Replication](https://blog.min.io/announcing-minio-batch-framework-batch-replication/), [Site Replication](https://blog.min.io/minio-replication-best-practices/) and [Bucket Replication](https://blog.min.io/active-active-replication/).\u00a0\n\n[https://blog.min.io/how-do-i-know-replication-is-up-to-date/?utm\\_source=reddit&amp;utm\\_medium=organic-social+&amp;utm\\_campaign=replication\\_up\\_to\\_date](https://blog.min.io/how-do-i-know-replication-is-up-to-date/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=replication_up_to_date)", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know replication is up to date?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198oz5d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705469308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Customers run MinIO wherever they need fast, resilient, scalable object storage. MinIO includes several types of replication to make sure that every application is working with the most recent data regardless of where it runs. We\u2019ve gone into great detail about the various replication options available and their best practices in previous posts about &lt;a href=\"https://blog.min.io/announcing-minio-batch-framework-batch-replication/\"&gt;Batch Replication&lt;/a&gt;, &lt;a href=\"https://blog.min.io/minio-replication-best-practices/\"&gt;Site Replication&lt;/a&gt; and &lt;a href=\"https://blog.min.io/active-active-replication/\"&gt;Bucket Replication&lt;/a&gt;.\u00a0&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.min.io/how-do-i-know-replication-is-up-to-date/?utm_source=reddit&amp;amp;utm_medium=organic-social+&amp;amp;utm_campaign=replication_up_to_date\"&gt;https://blog.min.io/how-do-i-know-replication-is-up-to-date/?utm_source=reddit&amp;amp;utm_medium=organic-social+&amp;amp;utm_campaign=replication_up_to_date&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EdiUbUE45qIB7SuzLWpSA6xzdqe1UemnAiYWocQiOVU.jpg?auto=webp&amp;s=f4724fd8a3c5d0ab52643082abf3c212e88e84a2", "width": 1200, "height": 637}, "resolutions": [{"url": "https://external-preview.redd.it/EdiUbUE45qIB7SuzLWpSA6xzdqe1UemnAiYWocQiOVU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f3fe5b1cf76f3492b446267368de262fb427a82", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/EdiUbUE45qIB7SuzLWpSA6xzdqe1UemnAiYWocQiOVU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=51e82dadc2ad24789fea119cfc7a4d3830015844", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/EdiUbUE45qIB7SuzLWpSA6xzdqe1UemnAiYWocQiOVU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a84c227f2b9af5e885f9e2811a3d6f9038cc5260", "width": 320, "height": 169}, {"url": "https://external-preview.redd.it/EdiUbUE45qIB7SuzLWpSA6xzdqe1UemnAiYWocQiOVU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d24e7b846f1d43a36249fab1b29d546235db036b", "width": 640, "height": 339}, {"url": "https://external-preview.redd.it/EdiUbUE45qIB7SuzLWpSA6xzdqe1UemnAiYWocQiOVU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f734414266ea3b6c7120b85f0a55b971e16cfa31", "width": 960, "height": 509}, {"url": "https://external-preview.redd.it/EdiUbUE45qIB7SuzLWpSA6xzdqe1UemnAiYWocQiOVU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b90789748e2f4ec2d094213d499190be7c865dda", "width": 1080, "height": 573}], "variants": {}, "id": "vdalyfwTqzF7eYv7fQnGFdEkm9lbgzpSPrYXuZ-DgGY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "198oz5d", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198oz5d/how_do_i_know_replication_is_up_to_date/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198oz5d/how_do_i_know_replication_is_up_to_date/", "subreddit_subscribers": 153550, "created_utc": 1705469308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently in my freshman year of college and am thinking of going into data engineering, and had a few questions before I start my sophmore year (hopefully in data engineering).\n\nWhat are the best majors or minors to pair with data engineering degree. Is it a good idea to to a business major alongside it?\n\nAlso if you have any tips whatsoever on what I should be working on over the summer, or if there's anything I can learn to hopefully get me an internship in my sophmore year or to just get ahead of the competition.", "author_fullname": "t2_64rysrha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips for summer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_198idro", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705450149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently in my freshman year of college and am thinking of going into data engineering, and had a few questions before I start my sophmore year (hopefully in data engineering).&lt;/p&gt;\n\n&lt;p&gt;What are the best majors or minors to pair with data engineering degree. Is it a good idea to to a business major alongside it?&lt;/p&gt;\n\n&lt;p&gt;Also if you have any tips whatsoever on what I should be working on over the summer, or if there&amp;#39;s anything I can learn to hopefully get me an internship in my sophmore year or to just get ahead of the competition.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "198idro", "is_robot_indexable": true, "report_reasons": null, "author": "Karma-4U", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/198idro/tips_for_summer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/198idro/tips_for_summer/", "subreddit_subscribers": 153550, "created_utc": 1705450149.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}