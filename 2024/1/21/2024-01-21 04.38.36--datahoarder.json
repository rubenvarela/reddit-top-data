{"kind": "Listing", "data": {"after": "t3_19bmkcr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_uo08s890", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial has an 7.68TB NVMe for $350", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_19bduhx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 214, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 214, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/9nS67UXMjuypn9uwBv1YjErPBk75fqm6_WAjExdtsZ8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705763516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "crucial.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.crucial.com/ssd/7400_pro/mtfdkcb7t6tdz-2az18abyyr#reach", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?auto=webp&amp;s=e2421e6c60b21be472095e594db58bd778600d0f", "width": 1200, "height": 680}, "resolutions": [{"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6a4edc4610d4cb640bedd66be7355faec77ca22", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b80e53c196e0d71cb6768e16b3e461beead737c2", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7e2ed9ebc9833094c4f25cbab410a25e60e8124", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a0791fba73a60e469bde8e51ca7f958d506bf20f", "width": 640, "height": 362}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc93901b52df48149de9e881ac6e469a5c38f02", "width": 960, "height": 544}, {"url": "https://external-preview.redd.it/JRaoKGPlW2zdYhbun_GgEGTpZpxRScY4bTqFa_e2gu4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e97fc43d31f603e47696b6292579785447d2a4f2", "width": 1080, "height": 612}], "variants": {}, "id": "zby-HJAO_eydDuSwVzafSoulGLhD91dKRo6wSmctlmY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "19bduhx", "is_robot_indexable": true, "report_reasons": null, "author": "ThreeLeggedChimp", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bduhx/crucial_has_an_768tb_nvme_for_350/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.crucial.com/ssd/7400_pro/mtfdkcb7t6tdz-2az18abyyr#reach", "subreddit_subscribers": 726821, "created_utc": 1705763516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been scanning important documents with the android \"Adobe Scan\" app, and storing them onto my backed up storage. How worried do I have to be that this format may become unreadable in the future ?", "author_fullname": "t2_akkry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How future-proof is the PDF format ? I use it to store all my scanned paperwork", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b73gl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 88, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705738942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been scanning important documents with the android &amp;quot;Adobe Scan&amp;quot; app, and storing them onto my backed up storage. How worried do I have to be that this format may become unreadable in the future ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19b73gl", "is_robot_indexable": true, "report_reasons": null, "author": "BakGikHung", "discussion_type": null, "num_comments": 98, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19b73gl/how_futureproof_is_the_pdf_format_i_use_it_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19b73gl/how_futureproof_is_the_pdf_format_i_use_it_to/", "subreddit_subscribers": 726821, "created_utc": 1705738942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_956m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know why my 14TB HDDs are showing up as 6TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 132, "top_awarded_type": null, "hide_score": false, "name": "t3_19bemf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7IjFPSGWNWBrrp_3Az7HIFb9lTTAEiAM4ZLc7OjVNmE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705765686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/l3fdcvdt8mdc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/l3fdcvdt8mdc1.png?auto=webp&amp;s=02d45034c7f61de4e91852e041427dd51106379e", "width": 1090, "height": 1030}, "resolutions": [{"url": "https://preview.redd.it/l3fdcvdt8mdc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ec3225cffa0f6d849448e27754085290046ac42", "width": 108, "height": 102}, {"url": "https://preview.redd.it/l3fdcvdt8mdc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e32a5eab2b40c77ef5a49935124fb0f4aa98fec1", "width": 216, "height": 204}, {"url": "https://preview.redd.it/l3fdcvdt8mdc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5094c478f154b46f89d5fa0c76c5a503cd4b0527", "width": 320, "height": 302}, {"url": "https://preview.redd.it/l3fdcvdt8mdc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f13bd5c4d8e84beb001d150529e33799b54ca787", "width": 640, "height": 604}, {"url": "https://preview.redd.it/l3fdcvdt8mdc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee05bda06c8680515b9a96463a751c304899fc70", "width": 960, "height": 907}, {"url": "https://preview.redd.it/l3fdcvdt8mdc1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=48692106c11ea484aa6bb923a58dbce54dd66b33", "width": 1080, "height": 1020}], "variants": {}, "id": "_twTMhrJDmVqseaAfYIaazbkZSkHAs31DeGhFgCA_Bw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bemf0", "is_robot_indexable": true, "report_reasons": null, "author": "Silicon_Knight", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bemf0/anyone_know_why_my_14tb_hdds_are_showing_up_as_6tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/l3fdcvdt8mdc1.png", "subreddit_subscribers": 726821, "created_utc": 1705765686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a group of friends who are into the Soulseek thing, Hi-Fi rips and scans of obscure music. I would like to host a media server to hold all of their great digitizations, for downloading and/or streaming.I don\u2019t know exactly how much they have, but probably more than 3TB. I have amassed a lot of hardware from the ewaste recycling center I used to work at once we liquidated. The attached picture is most of my horde of storage devices. I have:\n- Four Lenovo Thinkcentres. Two have a 256GB SSD and two have a 512GB SSD. All four also have a 16GB intel optane drive.\n- Five 128GB SATA m.2 SSDs\n- Four 256Gb SATA m.2 SSDs\n- Two 2.5\u201d 320GB HDDs\n- Two 2.5\u201d 240GB HDDs\n- Three 3.5\u201d 1TB HDDs\n- One 1TB m.2 NVMe SSD\n- Some other small SSDs and HDDs that are &lt;100GB\n\nI also have many laptops and a spare desktop. A Lenovo Thinkcentre M83, which only has room for one 3.5\u201d drive. and the thinkpads I have only have one 2.5\u201d bay, an mSATA port inside, and the SATA slot where the DVD drive goes that I could cram another drive into if I wanted.\n\nIf it\u2019s not clear already, most of this stuff is varying levels of used. And a majority of the drives are small capacities. I don\u2019t really know what to do with all of these, how to bring them together into a formation that can store terabytes of data with either redundancy or backups. I could just go buy a couple new 4TB hard drives and a PC to throw them into, but then I\u2019m just spending more money and buying more hardware, which you can understand I would like to avoid. I want to use what I have. I have a couple network switches and routers too, by the way. I appreciate any advice you have to give a technomaniac like me.", "author_fullname": "t2_n1wnr2p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardware hoarder looking to make a robust storage server from what I have around", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_19bk69d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PCR_2CwSp0flQdK7VCHbo8shvhtlCA2Tb3w8IYeJxIc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705780232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a group of friends who are into the Soulseek thing, Hi-Fi rips and scans of obscure music. I would like to host a media server to hold all of their great digitizations, for downloading and/or streaming.I don\u2019t know exactly how much they have, but probably more than 3TB. I have amassed a lot of hardware from the ewaste recycling center I used to work at once we liquidated. The attached picture is most of my horde of storage devices. I have:\n- Four Lenovo Thinkcentres. Two have a 256GB SSD and two have a 512GB SSD. All four also have a 16GB intel optane drive.\n- Five 128GB SATA m.2 SSDs\n- Four 256Gb SATA m.2 SSDs\n- Two 2.5\u201d 320GB HDDs\n- Two 2.5\u201d 240GB HDDs\n- Three 3.5\u201d 1TB HDDs\n- One 1TB m.2 NVMe SSD\n- Some other small SSDs and HDDs that are &amp;lt;100GB&lt;/p&gt;\n\n&lt;p&gt;I also have many laptops and a spare desktop. A Lenovo Thinkcentre M83, which only has room for one 3.5\u201d drive. and the thinkpads I have only have one 2.5\u201d bay, an mSATA port inside, and the SATA slot where the DVD drive goes that I could cram another drive into if I wanted.&lt;/p&gt;\n\n&lt;p&gt;If it\u2019s not clear already, most of this stuff is varying levels of used. And a majority of the drives are small capacities. I don\u2019t really know what to do with all of these, how to bring them together into a formation that can store terabytes of data with either redundancy or backups. I could just go buy a couple new 4TB hard drives and a PC to throw them into, but then I\u2019m just spending more money and buying more hardware, which you can understand I would like to avoid. I want to use what I have. I have a couple network switches and routers too, by the way. I appreciate any advice you have to give a technomaniac like me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/avx3ujpegndc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?auto=webp&amp;s=5fa37619b117ebeb79b52b8f83e96a59e41bd434", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2fea6e24b6ab60246566fbb50b9f519c7376f6b7", "width": 108, "height": 81}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e672da4d220447a83464a1d88d8035801a62c2b", "width": 216, "height": 162}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4d4a06a8a825e31eeaeef137db8f92cab388b1d5", "width": 320, "height": 240}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=52d6fac7cdac93908c196c8dff2f574e982eeafb", "width": 640, "height": 480}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e647135c4239e0ddf4562e7ce3a987a1542bed35", "width": 960, "height": 720}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1c77438dae9a12b88523525bfb27dfed8fecdd6", "width": 1080, "height": 810}], "variants": {}, "id": "S1IeJhkO7Ij_BryvFsi45XRxKAoDWm3X0ou9HCDgBZA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bk69d", "is_robot_indexable": true, "report_reasons": null, "author": "type9freak", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bk69d/hardware_hoarder_looking_to_make_a_robust_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/avx3ujpegndc1.jpeg", "subreddit_subscribers": 726821, "created_utc": 1705780232.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Today I was thinking about the R/W speeds of most HDD to realize that even a 7200RPM won't get further than 150 MB/s. This means that a regular GbE will underperform only a little, but a 2.5GbE will overperform by too much. So I wondered if it's worthy at all.\n\nIn fact, I'm not even sure if nowadays 5400RPM vs 7200RPM is worthy at all because the difference is minimal (from benchmarks I've read like 120 vs 160 in the best scenarios)\n\nSo basically, a 7200RPM will better profit from a 2.5GbE, but minimally.\n\nThis comes because it happens that I installed one 10\u00a0GB 7200RPM on my PC, but I would rather not have my PC like 24/7 online, so I was thinking of moving to a NAS\n\nI found two options:\n\nAsustor Drivestor 2 AS1102T and Synology DS223J. The main difference is that the former has a 2.5GbE port and the later a regular 1GbE. Both have 1\u00a0GB RAM, RTD1296 vs RTD1619B, a little more efficient the Synology one given it's newer, but nothing  brutal, so spec wise apart from the 2.5GbE vs 1Gb and the fact that DSM is kind of more mature than ADM from ASUS, so plenty of people prefer (specially when opening ports to the internet which I'm not going to do), seems to be the only differences. And for me, prices for the two are almost identical, like $10 up or down.\n\nBut since HDD are the real hindrance here in terms of performance, is it really worthy going with the 2.5GbE port?\n\nI've seen a ton of videos of guys trying to install a 2.5GbE USB adapter to their Synology and still, I cannot understand if it really makes sense (or even going for a 5/10GbE which blows my mind unless they have moved to SSD which makes no sense for me in terms of TB for the buck).\n\nHas anyone had the experience of moving  to 2.5GbE and found it life-changing in any sense, or it feels more of a whimsical minor improvement, just for the sake of it?\n\nThe only real thing that makes me think about this is the fact that I have the whole site based on 2.5GbE (with 2.5GbE switches all over the place).", "author_fullname": "t2_lzcls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think that 2.5GbE worthy at all for a home NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b9y2d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705751131.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705750772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today I was thinking about the R/W speeds of most HDD to realize that even a 7200RPM won&amp;#39;t get further than 150 MB/s. This means that a regular GbE will underperform only a little, but a 2.5GbE will overperform by too much. So I wondered if it&amp;#39;s worthy at all.&lt;/p&gt;\n\n&lt;p&gt;In fact, I&amp;#39;m not even sure if nowadays 5400RPM vs 7200RPM is worthy at all because the difference is minimal (from benchmarks I&amp;#39;ve read like 120 vs 160 in the best scenarios)&lt;/p&gt;\n\n&lt;p&gt;So basically, a 7200RPM will better profit from a 2.5GbE, but minimally.&lt;/p&gt;\n\n&lt;p&gt;This comes because it happens that I installed one 10\u00a0GB 7200RPM on my PC, but I would rather not have my PC like 24/7 online, so I was thinking of moving to a NAS&lt;/p&gt;\n\n&lt;p&gt;I found two options:&lt;/p&gt;\n\n&lt;p&gt;Asustor Drivestor 2 AS1102T and Synology DS223J. The main difference is that the former has a 2.5GbE port and the later a regular 1GbE. Both have 1\u00a0GB RAM, RTD1296 vs RTD1619B, a little more efficient the Synology one given it&amp;#39;s newer, but nothing  brutal, so spec wise apart from the 2.5GbE vs 1Gb and the fact that DSM is kind of more mature than ADM from ASUS, so plenty of people prefer (specially when opening ports to the internet which I&amp;#39;m not going to do), seems to be the only differences. And for me, prices for the two are almost identical, like $10 up or down.&lt;/p&gt;\n\n&lt;p&gt;But since HDD are the real hindrance here in terms of performance, is it really worthy going with the 2.5GbE port?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a ton of videos of guys trying to install a 2.5GbE USB adapter to their Synology and still, I cannot understand if it really makes sense (or even going for a 5/10GbE which blows my mind unless they have moved to SSD which makes no sense for me in terms of TB for the buck).&lt;/p&gt;\n\n&lt;p&gt;Has anyone had the experience of moving  to 2.5GbE and found it life-changing in any sense, or it feels more of a whimsical minor improvement, just for the sake of it?&lt;/p&gt;\n\n&lt;p&gt;The only real thing that makes me think about this is the fact that I have the whole site based on 2.5GbE (with 2.5GbE switches all over the place).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19b9y2d", "is_robot_indexable": true, "report_reasons": null, "author": "SirLouen", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19b9y2d/do_you_think_that_25gbe_worthy_at_all_for_a_home/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19b9y2d/do_you_think_that_25gbe_worthy_at_all_for_a_home/", "subreddit_subscribers": 726821, "created_utc": 1705750772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to share one of my backup drives with a friend. He told me it needs to be encrypted to store it in his house. I do trust him but he wants the data encrypted. I said fine with me. It's just medical and financial records as well as families movies like Christmas mornings. \n\nThe problem is that while my Linux desktop could always decrypt the drives with my gpg key or password. I'm trying to plan on a situation where something bad happens and I can't access the computer. Maybe I forget the password or something like that. \n\nI thought about buying a cheap waterproof USB drive and just burying it someplace.", "author_fullname": "t2_dui3ih3xt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for backing up keys and passwords of backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19brvds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705801182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to share one of my backup drives with a friend. He told me it needs to be encrypted to store it in his house. I do trust him but he wants the data encrypted. I said fine with me. It&amp;#39;s just medical and financial records as well as families movies like Christmas mornings. &lt;/p&gt;\n\n&lt;p&gt;The problem is that while my Linux desktop could always decrypt the drives with my gpg key or password. I&amp;#39;m trying to plan on a situation where something bad happens and I can&amp;#39;t access the computer. Maybe I forget the password or something like that. &lt;/p&gt;\n\n&lt;p&gt;I thought about buying a cheap waterproof USB drive and just burying it someplace.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19brvds", "is_robot_indexable": true, "report_reasons": null, "author": "sir_topham_biff", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19brvds/ideas_for_backing_up_keys_and_passwords_of_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19brvds/ideas_for_backing_up_keys_and_passwords_of_backups/", "subreddit_subscribers": 726821, "created_utc": 1705801182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello.\n\nI recently got a set of new SSDs for my NAS to replace my current HDDs. I got a bit overanxious about write cycles for flash storage. For example, I bought Kingston DC600M which have a pretty high TBW rating.\n\nYet, I am still worried. The thing that currently worries me is that the filesystem or some usage pattern might bombard the same flash cell over and over again by rewriting the same block. I even wrote a small test suite that records the pattern of used blocks when executing some IO benchmarks.\n\nAfter reading a bit more online, I figured that all the testing might have been irrelevant. The SSD controller will remap logical blocks (as addressed by the host system) to physical blocks. It might even move data around to other blocks. All this happens hidden from the host system. The only indicator it needs, is which blocks are currently unused, so it can move data there. This happens via trim/discard which all modern systems seem to support.\n\nIs my understanding correct and unequal flash wear is basically not an issue with SSDs? Even if rewriting the same logical block over and over again, it will not hit the same flash cell, but the controlle will move it to different physical blocks to make sure they all get the same write cycles?\n\nThank you!", "author_fullname": "t2_6b78jyrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do SSD controllers move blocks around to equalize flash wear?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bigol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705775808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I recently got a set of new SSDs for my NAS to replace my current HDDs. I got a bit overanxious about write cycles for flash storage. For example, I bought Kingston DC600M which have a pretty high TBW rating.&lt;/p&gt;\n\n&lt;p&gt;Yet, I am still worried. The thing that currently worries me is that the filesystem or some usage pattern might bombard the same flash cell over and over again by rewriting the same block. I even wrote a small test suite that records the pattern of used blocks when executing some IO benchmarks.&lt;/p&gt;\n\n&lt;p&gt;After reading a bit more online, I figured that all the testing might have been irrelevant. The SSD controller will remap logical blocks (as addressed by the host system) to physical blocks. It might even move data around to other blocks. All this happens hidden from the host system. The only indicator it needs, is which blocks are currently unused, so it can move data there. This happens via trim/discard which all modern systems seem to support.&lt;/p&gt;\n\n&lt;p&gt;Is my understanding correct and unequal flash wear is basically not an issue with SSDs? Even if rewriting the same logical block over and over again, it will not hit the same flash cell, but the controlle will move it to different physical blocks to make sure they all get the same write cycles?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bigol", "is_robot_indexable": true, "report_reasons": null, "author": "thomas001le", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bigol/do_ssd_controllers_move_blocks_around_to_equalize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bigol/do_ssd_controllers_move_blocks_around_to_equalize/", "subreddit_subscribers": 726821, "created_utc": 1705775808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_khv8a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data loss", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 130, "top_awarded_type": null, "hide_score": false, "name": "t3_19bskph", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pN2afERXDXhcYPynYtziZNQJRgsLLva1r7nfHTOLeqU.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705803342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/nsrbf374dpdc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/nsrbf374dpdc1.png?auto=webp&amp;s=783f6dacc1b5f2dd195e23591a9d99754e71e68a", "width": 640, "height": 595}, "resolutions": [{"url": "https://preview.redd.it/nsrbf374dpdc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7150eb8f1a9a990fe5edf8a0eab7fa452b9fa9d2", "width": 108, "height": 100}, {"url": "https://preview.redd.it/nsrbf374dpdc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d73f0c01616fbac161a36a04d5ec26eed4e5571c", "width": 216, "height": 200}, {"url": "https://preview.redd.it/nsrbf374dpdc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bd50f9ed19e501091e30eda2b73815cfb155719", "width": 320, "height": 297}, {"url": "https://preview.redd.it/nsrbf374dpdc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b9a47b18986260d7fa44294ff6732ff4746d32d3", "width": 640, "height": 595}], "variants": {}, "id": "TLAguhZcIrokK_yaZguJ6pEEq_pbpSOYgllMHf9O59Q"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "12TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bskph", "is_robot_indexable": true, "report_reasons": null, "author": "Brancliff", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19bskph/data_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/nsrbf374dpdc1.png", "subreddit_subscribers": 726821, "created_utc": 1705803342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone have thoughts about specific products?\n\nTo my enormous surprise the LG burner that has been a workhorse for years seems to have suddenly decided that its Blu Ray writing days are over (tried on various computers with different OSes... all BR writing attempts fail). \n\nMy desktop doesn't have a spare tray to take an internal drive so I'll have to go the external route. \n\nI've read (here) suggestions that the slimline type products are to be avoided. \n\nI see Verbatim make one and the Asus Turbo Drives look closest to the kind of thing I'm envisioning (no attention to aesthetics - something big and powerful - ideally with an AC power supply so it doesn't have to rely on getting stable power from the PSU). \n\nAny specific product recommendations? \n\nTIA!", "author_fullname": "t2_poc45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most reliable external Blu Ray burner / writer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b6ive", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705736571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have thoughts about specific products?&lt;/p&gt;\n\n&lt;p&gt;To my enormous surprise the LG burner that has been a workhorse for years seems to have suddenly decided that its Blu Ray writing days are over (tried on various computers with different OSes... all BR writing attempts fail). &lt;/p&gt;\n\n&lt;p&gt;My desktop doesn&amp;#39;t have a spare tray to take an internal drive so I&amp;#39;ll have to go the external route. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read (here) suggestions that the slimline type products are to be avoided. &lt;/p&gt;\n\n&lt;p&gt;I see Verbatim make one and the Asus Turbo Drives look closest to the kind of thing I&amp;#39;m envisioning (no attention to aesthetics - something big and powerful - ideally with an AC power supply so it doesn&amp;#39;t have to rely on getting stable power from the PSU). &lt;/p&gt;\n\n&lt;p&gt;Any specific product recommendations? &lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19b6ive", "is_robot_indexable": true, "report_reasons": null, "author": "danielrosehill", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19b6ive/most_reliable_external_blu_ray_burner_writer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19b6ive/most_reliable_external_blu_ray_burner_writer/", "subreddit_subscribers": 726821, "created_utc": 1705736571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nWanted to seek some advice. I am scanning all the documents I have / will get and saving them locally and on the cloud. (Redundancy.)  But all the scanners are always so slow, I have a HUGE pile, and the printer/scanner I have now takes about 30 seconds for 1 side of a single paper. (Please come and save me) I currently have an HP DeskJet 2734e, which I no longer print so stopped paying for the service. Little did I know that would make me unable to print NOR use the scanner....\n\n&amp;#x200B;\n\nWhat am I looking for?\n\n* A scanner. \n   * It can be an all-in-one printer but if it requires a paid service, I will ignore it lol.\n* Preferably quick but maintains the quality.\n* Can be saved as PDF or JPG.\n* Does not cost an arm and a leg.\n* Highly prefer to be connected to Wi-Fi (or Bluetooth) but if it costs less to use cable, I will deal with it.\n\nAdditional Information\n\n* Some are one-sided, and some are double-sided.\n* Some have mutliple pages.\n* Some have multiple pages. that are one-sided and double-sided. -\\_-\n\n&amp;#x200B;\n\nThank you in advance for any suggestions!!!", "author_fullname": "t2_o4hbhngt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast Scanner W/O Printer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19blxon", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705784844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Wanted to seek some advice. I am scanning all the documents I have / will get and saving them locally and on the cloud. (Redundancy.)  But all the scanners are always so slow, I have a HUGE pile, and the printer/scanner I have now takes about 30 seconds for 1 side of a single paper. (Please come and save me) I currently have an HP DeskJet 2734e, which I no longer print so stopped paying for the service. Little did I know that would make me unable to print NOR use the scanner....&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What am I looking for?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A scanner. \n\n&lt;ul&gt;\n&lt;li&gt;It can be an all-in-one printer but if it requires a paid service, I will ignore it lol.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Preferably quick but maintains the quality.&lt;/li&gt;\n&lt;li&gt;Can be saved as PDF or JPG.&lt;/li&gt;\n&lt;li&gt;Does not cost an arm and a leg.&lt;/li&gt;\n&lt;li&gt;Highly prefer to be connected to Wi-Fi (or Bluetooth) but if it costs less to use cable, I will deal with it.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Additional Information&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Some are one-sided, and some are double-sided.&lt;/li&gt;\n&lt;li&gt;Some have mutliple pages.&lt;/li&gt;\n&lt;li&gt;Some have multiple pages. that are one-sided and double-sided. -_-&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any suggestions!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19blxon", "is_robot_indexable": true, "report_reasons": null, "author": "Jordanbr25", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19blxon/fast_scanner_wo_printer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19blxon/fast_scanner_wo_printer/", "subreddit_subscribers": 726821, "created_utc": 1705784844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "HI5 used to be super popular - you think there's any way to find and parse the old data to find the stupid posts of my younger self?", "author_fullname": "t2_1thvgufh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone saved the HI5 data (the social network that has part of my teeange years on it)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bd7sb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705761759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HI5 used to be super popular - you think there&amp;#39;s any way to find and parse the old data to find the stupid posts of my younger self?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bd7sb", "is_robot_indexable": true, "report_reasons": null, "author": "laterral", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bd7sb/has_anyone_saved_the_hi5_data_the_social_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bd7sb/has_anyone_saved_the_hi5_data_the_social_network/", "subreddit_subscribers": 726821, "created_utc": 1705761759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone.  I upgraded my 12TB (2x6TB) PR2100 with two 10TB WD Red drives.  Everything seemed to go well, but I'm running into problem that I cant figure out a solution to.  I'm trying to transfer a video file to a folder on the drive and I'm getting an error that says:\n\n \"There is not enough space on videos\n\n 0 bytes is needed to copy this item. Delete or move files so you have enough space\"\n\nThere is plenty of space on the drives so this is throwing me for a loop.  Does anyone have a recommendation as to how I can fix this.\n\nThanks in advance for any help.", "author_fullname": "t2_wk1uv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PR2100 Drive Upgrade Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bpxak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705795543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone.  I upgraded my 12TB (2x6TB) PR2100 with two 10TB WD Red drives.  Everything seemed to go well, but I&amp;#39;m running into problem that I cant figure out a solution to.  I&amp;#39;m trying to transfer a video file to a folder on the drive and I&amp;#39;m getting an error that says:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;There is not enough space on videos&lt;/p&gt;\n\n&lt;p&gt;0 bytes is needed to copy this item. Delete or move files so you have enough space&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;There is plenty of space on the drives so this is throwing me for a loop.  Does anyone have a recommendation as to how I can fix this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bpxak", "is_robot_indexable": true, "report_reasons": null, "author": "JohnnyDanger79", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bpxak/pr2100_drive_upgrade_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bpxak/pr2100_drive_upgrade_problem/", "subreddit_subscribers": 726821, "created_utc": 1705795543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can I data transfer from both my pc and android. I downloaded that Microsoft expat thing and the file manager and it still won't transfer data. Should I just get an ssd?", "author_fullname": "t2_ruygnefd7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "passport wd hdd samsung s22+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bn19w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705787743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can I data transfer from both my pc and android. I downloaded that Microsoft expat thing and the file manager and it still won&amp;#39;t transfer data. Should I just get an ssd?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bn19w", "is_robot_indexable": true, "report_reasons": null, "author": "corvus_corax_birdz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bn19w/passport_wd_hdd_samsung_s22/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bn19w/passport_wd_hdd_samsung_s22/", "subreddit_subscribers": 726821, "created_utc": 1705787743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 2 18TB Seagate Ironwolfs that I plan to use in RAID1.\n\nI just finished badblocking both (took 10 days) and one came back with all the \"important\" SMART metrics (Reallocated\\_Sector\\_Ct, Current\\_Pending\\_Sector, Offline\\_Uncorrectable, Reported\\_Uncorrect and Spin\\_Retry\\_Count, Command\\_Timeout and UDMA\\_CRC\\_Error\\_Count) being 0s. The other one also had 0s except for 2 of the metrics, Command\\_Timeout and UDMA\\_CRC\\_Error\\_Count which were set to 1.\n\nFrom some of the websearching I have done, having a Command\\_Timeout of 1 seems to indicate that this may be an issue with the SATA cable or a hiccup in the power being supplied to the drive.\n\nHave any of you encountered a situation like this before? Should I RMA the disk?", "author_fullname": "t2_1fmy10hj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just finished badblocking my drive and I have 1 for Command_Timeout and UDMA_CRC_Error_Count", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19blz2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705784944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 18TB Seagate Ironwolfs that I plan to use in RAID1.&lt;/p&gt;\n\n&lt;p&gt;I just finished badblocking both (took 10 days) and one came back with all the &amp;quot;important&amp;quot; SMART metrics (Reallocated_Sector_Ct, Current_Pending_Sector, Offline_Uncorrectable, Reported_Uncorrect and Spin_Retry_Count, Command_Timeout and UDMA_CRC_Error_Count) being 0s. The other one also had 0s except for 2 of the metrics, Command_Timeout and UDMA_CRC_Error_Count which were set to 1.&lt;/p&gt;\n\n&lt;p&gt;From some of the websearching I have done, having a Command_Timeout of 1 seems to indicate that this may be an issue with the SATA cable or a hiccup in the power being supplied to the drive.&lt;/p&gt;\n\n&lt;p&gt;Have any of you encountered a situation like this before? Should I RMA the disk?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19blz2q", "is_robot_indexable": true, "report_reasons": null, "author": "zztop5269", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19blz2q/just_finished_badblocking_my_drive_and_i_have_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19blz2q/just_finished_badblocking_my_drive_and_i_have_1/", "subreddit_subscribers": 726821, "created_utc": 1705784944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been archiving data onto BD-R discs since summer 2010 and placing the discs in standard CD binders in a cabinet.  Personally I have not noticed any corruption anytime I've had to pull data off these discs.   I have been using PlexDisc 633-214's since 2016, before that Memorex 98499 and 97854's and Rosewill SB-25I.\n\nI'm wondering what your experience has been.\n\nI agree that HDDs are cheap but I don't think they're that cheap, plus having everything on spinning rust is a bad idea, and the cloud isn't really suitable in my case.", "author_fullname": "t2_xjkyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What has your experience been with long-term data reliability on Blu-Ray discs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bkppo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705781635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been archiving data onto BD-R discs since summer 2010 and placing the discs in standard CD binders in a cabinet.  Personally I have not noticed any corruption anytime I&amp;#39;ve had to pull data off these discs.   I have been using PlexDisc 633-214&amp;#39;s since 2016, before that Memorex 98499 and 97854&amp;#39;s and Rosewill SB-25I.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what your experience has been.&lt;/p&gt;\n\n&lt;p&gt;I agree that HDDs are cheap but I don&amp;#39;t think they&amp;#39;re that cheap, plus having everything on spinning rust is a bad idea, and the cloud isn&amp;#39;t really suitable in my case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "19bkppo", "is_robot_indexable": true, "report_reasons": null, "author": "AnthillOmbudsman", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bkppo/what_has_your_experience_been_with_longterm_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bkppo/what_has_your_experience_been_with_longterm_data/", "subreddit_subscribers": 726821, "created_utc": 1705781635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How can i check if a usb flash drive reports a fake capacity? My brother got a 128 gb drive from amazon and its incredibly slow and hangs after writing ~200 mb to it.\n\nEdit: maybe its just a bad drive in general, it doesnt even show up in disk management anymore", "author_fullname": "t2_9kqgspet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Check if USB stick reports fake capacity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bh44j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705784051.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705772315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can i check if a usb flash drive reports a fake capacity? My brother got a 128 gb drive from amazon and its incredibly slow and hangs after writing ~200 mb to it.&lt;/p&gt;\n\n&lt;p&gt;Edit: maybe its just a bad drive in general, it doesnt even show up in disk management anymore&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bh44j", "is_robot_indexable": true, "report_reasons": null, "author": "BlincxYT", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bh44j/check_if_usb_stick_reports_fake_capacity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bh44j/check_if_usb_stick_reports_fake_capacity/", "subreddit_subscribers": 726821, "created_utc": 1705772315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Maybe a stupid question, maybe not.  \nI want to make sure the tools I use for various tasks will always be available for me to be used.\n\nMost importantly stuff like the 'bulk renaming utility' and 'advanced renamer' but also stuff like ffmpeg or yt-dlp and more.\n\nBut how would I go about this? Often programs require an internet connection or without updates they can't be used on newer operation systems. Also how would I archive programs that don't come in portable little zip archives?   \n", "author_fullname": "t2_kt6lumrsd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving programs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bept9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705765944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe a stupid question, maybe not.&lt;br/&gt;\nI want to make sure the tools I use for various tasks will always be available for me to be used.&lt;/p&gt;\n\n&lt;p&gt;Most importantly stuff like the &amp;#39;bulk renaming utility&amp;#39; and &amp;#39;advanced renamer&amp;#39; but also stuff like ffmpeg or yt-dlp and more.&lt;/p&gt;\n\n&lt;p&gt;But how would I go about this? Often programs require an internet connection or without updates they can&amp;#39;t be used on newer operation systems. Also how would I archive programs that don&amp;#39;t come in portable little zip archives?   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bept9", "is_robot_indexable": true, "report_reasons": null, "author": "Kingslord25", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bept9/archiving_programs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bept9/archiving_programs/", "subreddit_subscribers": 726821, "created_utc": 1705765944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "cant login and the site is just buffering indefinitely, my guess is theres some maintenance happening. anyone else experiencing issues with mega at the moment? ", "author_fullname": "t2_2b290q9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MEGA loading forever??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bd10f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705761210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;cant login and the site is just buffering indefinitely, my guess is theres some maintenance happening. anyone else experiencing issues with mega at the moment? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bd10f", "is_robot_indexable": true, "report_reasons": null, "author": "OnoxiMyth", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bd10f/mega_loading_forever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bd10f/mega_loading_forever/", "subreddit_subscribers": 726821, "created_utc": 1705761210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to preserve a very long RPG play-by-post game written on a discord server. It's about 1.5 million words of text. All the other posts I've seen asking about preserving things from discord are concerned with saving photos/attachments or reactions, but I want literally just the text people have written and to specifically *exclude* things like usernames, dates, and reactions so that it reads like a book. It seems like there should be an easy way to have a program grab just the text and export it to a text file, but I haven't found anything.\n\nWant to keep: The responses people write, formatting if possible (e.g. italics)\n\nDon't want to keep: Usernames, dates, reactions, images, attachments\n\nAny suggestions? I can get admin access to the server as well if that affects what can be done.", "author_fullname": "t2_boege", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to archive ONLY text from a discord server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19bthfz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705806171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to preserve a very long RPG play-by-post game written on a discord server. It&amp;#39;s about 1.5 million words of text. All the other posts I&amp;#39;ve seen asking about preserving things from discord are concerned with saving photos/attachments or reactions, but I want literally just the text people have written and to specifically &lt;em&gt;exclude&lt;/em&gt; things like usernames, dates, and reactions so that it reads like a book. It seems like there should be an easy way to have a program grab just the text and export it to a text file, but I haven&amp;#39;t found anything.&lt;/p&gt;\n\n&lt;p&gt;Want to keep: The responses people write, formatting if possible (e.g. italics)&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t want to keep: Usernames, dates, reactions, images, attachments&lt;/p&gt;\n\n&lt;p&gt;Any suggestions? I can get admin access to the server as well if that affects what can be done.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bthfz", "is_robot_indexable": true, "report_reasons": null, "author": "Lycanthrotree", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bthfz/best_way_to_archive_only_text_from_a_discord/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bthfz/best_way_to_archive_only_text_from_a_discord/", "subreddit_subscribers": 726821, "created_utc": 1705806171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\nI am lookimg for some alternative solution to organize my documents.\nI am using Paperless-ng for a while, but now looking for some new alternatives.\n\nI love to just drop my scanned pdf or doc to a folder, and Paperless can ocr, and crate thumbnails. The only missing feature for me is the post organizing. If I set a string to search and tagging a document, the Paperless not going to do it on all documents already stored, but new ones\u2026", "author_fullname": "t2_hbfecd8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pdf, doc, catalogize on linux", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bq1cc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705795858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!\nI am lookimg for some alternative solution to organize my documents.\nI am using Paperless-ng for a while, but now looking for some new alternatives.&lt;/p&gt;\n\n&lt;p&gt;I love to just drop my scanned pdf or doc to a folder, and Paperless can ocr, and crate thumbnails. The only missing feature for me is the post organizing. If I set a string to search and tagging a document, the Paperless not going to do it on all documents already stored, but new ones\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bq1cc", "is_robot_indexable": true, "report_reasons": null, "author": "donkey_and_the_maid", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bq1cc/pdf_doc_catalogize_on_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bq1cc/pdf_doc_catalogize_on_linux/", "subreddit_subscribers": 726821, "created_utc": 1705795858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased three external hard drives, all 2 TB. I am backing up my Macbook on all three external hard drives using Time Machine. I am just wondering if this is a solid back-up plan. I am aware of the 3-2-1 rule. Hence the three external hard drives. I know that the Rule says I am supposed to have at least 2 different methods for backing up. In which case, for one of my back-ups instead of Time Machine I could use the software that the external hard drives come with. However Time Machine has turned out to be so simple, and these softwares that accompany the external hard drives are a bit more complex to set up. So I'm thinking to just keep things simple by using Time Machine for all three of my external hard drives. \n\nIs there anything wrong with that? ", "author_fullname": "t2_4u6autkj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time Machine as my Back-Up Method on all three of my external hard drives \u2013 is this a solid back-up plan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bptve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705795285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased three external hard drives, all 2 TB. I am backing up my Macbook on all three external hard drives using Time Machine. I am just wondering if this is a solid back-up plan. I am aware of the 3-2-1 rule. Hence the three external hard drives. I know that the Rule says I am supposed to have at least 2 different methods for backing up. In which case, for one of my back-ups instead of Time Machine I could use the software that the external hard drives come with. However Time Machine has turned out to be so simple, and these softwares that accompany the external hard drives are a bit more complex to set up. So I&amp;#39;m thinking to just keep things simple by using Time Machine for all three of my external hard drives. &lt;/p&gt;\n\n&lt;p&gt;Is there anything wrong with that? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bptve", "is_robot_indexable": true, "report_reasons": null, "author": "OrvilleSpencer34", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bptve/time_machine_as_my_backup_method_on_all_three_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bptve/time_machine_as_my_backup_method_on_all_three_of/", "subreddit_subscribers": 726821, "created_utc": 1705795285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm removing a data disk that has about 6tb of data on it from Snapraid. I followed the Manual verbatim and pointed the disk to an empty directory, removed content reference to that disk in my config.\n\nI then ran Snapraid sync -E and it says it will take 12 hours. \n\nI'm wondering if I messed something up or is this a normal timeframe.  Since the dir I pointed to is empty I assume it should be near instant?\n\nFor clarification I edited my config from....\n\ndata d3 X:\\\n\nto\n\ndata d3 X:\\myemptydir\\\n\n\n\nAny help is appreciated.", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should Snapraid Sync-E (force empty) take hours?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19boiqh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705791715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m removing a data disk that has about 6tb of data on it from Snapraid. I followed the Manual verbatim and pointed the disk to an empty directory, removed content reference to that disk in my config.&lt;/p&gt;\n\n&lt;p&gt;I then ran Snapraid sync -E and it says it will take 12 hours. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if I messed something up or is this a normal timeframe.  Since the dir I pointed to is empty I assume it should be near instant?&lt;/p&gt;\n\n&lt;p&gt;For clarification I edited my config from....&lt;/p&gt;\n\n&lt;p&gt;data d3 X:\\&lt;/p&gt;\n\n&lt;p&gt;to&lt;/p&gt;\n\n&lt;p&gt;data d3 X:\\myemptydir\\&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19boiqh", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19boiqh/should_snapraid_synce_force_empty_take_hours/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19boiqh/should_snapraid_synce_force_empty_take_hours/", "subreddit_subscribers": 726821, "created_utc": 1705791715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I am a wannabe data hoarder lmao  \n\n\nI have a spare pc that I don't use, it's an old 1155 gigabyte ga-b75n motherboard with an intel i7 2600k and 16gb ddr3. I also have a box with x14 500gb laptop hard drives that check good on crystaldisk info. That motherboard just has 4 sata ports. I need one of them for the ssd, another one for a wd red 3tb nas drive, and then the other 2 for 2 of these 2.5\" drives that I have.  \n\n\nI've seen cards that can output sata ports from pci express, but that was a long time ago, when I started searching on here I saw so many types of cards, I kind of got lost.  \n\n\nThe main purpose of this build is to have a server I can use for torrent and jellyfin and basically everything I use my raspberry pi 3b+ for (plus nextcloud which my old pi can't do), but because I have no money to buy a decent modern SBC (like the ODRIOD H3 which could handle nextcloud and some other stuff although no more than 2 sata drives)  \n\n\nFor what I've seen, a normal ammount of sata ports in one of those cards seems to be 8 ports. Anything above that, looks like it's bad quality pci-e 2x.  \n\n\nBut no idea of what card to buy, I saw this one on [ebay](https://www.ebay.es/itm/144210451235?hash=item21939cdb23:g:WuEAAOSwHWRhSJ8y&amp;amdata=enc%3AAQAIAAAAwC%2BiXEwAVaYAyphYHkqdN5rMEpTESXfX3t59m298SgH1Nx0xcBQcR2Yz2cuxQQw46yz%2B1sEBqiv6iXHk%2FFHM2ctv6Vdy73jMCNfBeihXR96ZCciO6hbU%2FDl6LLRB0%2BVwaBifJbDef3iy0xI5Cjspgmi2j3woRAkFTKS8bW9wbBJw9RmGIow9aChikNhzxMAwxfSGvu%2B89kG0U169pMPu5ngunBOKmzxiNkXEif8NaEvg0xDkk4z%2F0u6lGM0FehzlrQ%3D%3D%7Ctkp%3ABk9SR8ri_Y-lYw) . 26\u20ac for it seems cheap, also comes from china so no idea if it's good.  \n\n\nAlso, my drives are sata, and don't know what does that card have but I guess I need an adapter.  \n\n\nSince I guess people here are expert on this matter, I would appreciate some help! Thanks and sorry for the wall of text!", "author_fullname": "t2_q87sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to connect ~10 hdd to my pc, unsure how. Help is appreciated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bo7v4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705790925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am a wannabe data hoarder lmao  &lt;/p&gt;\n\n&lt;p&gt;I have a spare pc that I don&amp;#39;t use, it&amp;#39;s an old 1155 gigabyte ga-b75n motherboard with an intel i7 2600k and 16gb ddr3. I also have a box with x14 500gb laptop hard drives that check good on crystaldisk info. That motherboard just has 4 sata ports. I need one of them for the ssd, another one for a wd red 3tb nas drive, and then the other 2 for 2 of these 2.5&amp;quot; drives that I have.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen cards that can output sata ports from pci express, but that was a long time ago, when I started searching on here I saw so many types of cards, I kind of got lost.  &lt;/p&gt;\n\n&lt;p&gt;The main purpose of this build is to have a server I can use for torrent and jellyfin and basically everything I use my raspberry pi 3b+ for (plus nextcloud which my old pi can&amp;#39;t do), but because I have no money to buy a decent modern SBC (like the ODRIOD H3 which could handle nextcloud and some other stuff although no more than 2 sata drives)  &lt;/p&gt;\n\n&lt;p&gt;For what I&amp;#39;ve seen, a normal ammount of sata ports in one of those cards seems to be 8 ports. Anything above that, looks like it&amp;#39;s bad quality pci-e 2x.  &lt;/p&gt;\n\n&lt;p&gt;But no idea of what card to buy, I saw this one on &lt;a href=\"https://www.ebay.es/itm/144210451235?hash=item21939cdb23:g:WuEAAOSwHWRhSJ8y&amp;amp;amdata=enc%3AAQAIAAAAwC%2BiXEwAVaYAyphYHkqdN5rMEpTESXfX3t59m298SgH1Nx0xcBQcR2Yz2cuxQQw46yz%2B1sEBqiv6iXHk%2FFHM2ctv6Vdy73jMCNfBeihXR96ZCciO6hbU%2FDl6LLRB0%2BVwaBifJbDef3iy0xI5Cjspgmi2j3woRAkFTKS8bW9wbBJw9RmGIow9aChikNhzxMAwxfSGvu%2B89kG0U169pMPu5ngunBOKmzxiNkXEif8NaEvg0xDkk4z%2F0u6lGM0FehzlrQ%3D%3D%7Ctkp%3ABk9SR8ri_Y-lYw\"&gt;ebay&lt;/a&gt; . 26\u20ac for it seems cheap, also comes from china so no idea if it&amp;#39;s good.  &lt;/p&gt;\n\n&lt;p&gt;Also, my drives are sata, and don&amp;#39;t know what does that card have but I guess I need an adapter.  &lt;/p&gt;\n\n&lt;p&gt;Since I guess people here are expert on this matter, I would appreciate some help! Thanks and sorry for the wall of text!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?auto=webp&amp;s=ecb8019d97a50921834f2592a9af64513eca9f5d", "width": 400, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=36d785f27544862c20cb5d15eca758e4dc4a8ef1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2521cd5aacef09fab648c925746b167ce962a011", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6163d552292c2244476550f52a0aaa7bd2b8eb33", "width": 320, "height": 240}], "variants": {}, "id": "4SNq5slnQHY5ukuvhQh51R7fc-UIue5XnqAfNqEw6iI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bo7v4", "is_robot_indexable": true, "report_reasons": null, "author": "LanguageManiac", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bo7v4/want_to_connect_10_hdd_to_my_pc_unsure_how_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bo7v4/want_to_connect_10_hdd_to_my_pc_unsure_how_help/", "subreddit_subscribers": 726821, "created_utc": 1705790925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have quite a hoard of photos, and I know I have duplicates, some of which have different names, too.  What is the best free software for finding these so that I can check them and delete them to free up space on my external drives?  Someone suggested a free Polish software once, but I don't remember the name.   Thanks so much!", "author_fullname": "t2_5t026hxo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A good software for finding and deleting duplicate photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bnf96", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705788774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have quite a hoard of photos, and I know I have duplicates, some of which have different names, too.  What is the best free software for finding these so that I can check them and delete them to free up space on my external drives?  Someone suggested a free Polish software once, but I don&amp;#39;t remember the name.   Thanks so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bnf96", "is_robot_indexable": true, "report_reasons": null, "author": "fufairytoo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bnf96/a_good_software_for_finding_and_deleting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bnf96/a_good_software_for_finding_and_deleting/", "subreddit_subscribers": 726821, "created_utc": 1705788774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a folder of images (around 7k) which i messed up the exif data of by moving them from android phone's own memory to the sd card with the file manager app.\n\nIt reset all of the images' dates to the current date.\n\nI was using an android app called \"Image &amp; Video Date Fixer\" to fix them. First i categorized the images that need to be in order/next to each other into the same folders, then i renamed them on Windows with 1 second differences (like 20231122\\_11223\\*\\*3\\*\\* and 20231122\\_11223\\*\\*4\\*\\* and so on) then i used this app to set the EXIF dates into the names of pictures. \n\nBut i realized that gallery on my android app doesn't respect one second differences and still mixes the images around their seconds' range. I want to space around those images for 5 seconds but i don't want to repeat this process manually, i am already tired, i was so happy that it was finally over, then i got this problem. it was very time consuming and most people would not bother with what i am doing to be honest.\n\nIs there any reliable software / or a process to automate this? I heard Exiftool but i don't know how to use write codes for it. \n\n&amp;#x200B;\n\nNot a definite goal of course, but maybe it could be something like this: I'd like detection for exif dates with 1 second differences, group those together, and then extend them based on the selected one image's date in the group.", "author_fullname": "t2_nv30o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk images metadata / EXIF editing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bmkcr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705786504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a folder of images (around 7k) which i messed up the exif data of by moving them from android phone&amp;#39;s own memory to the sd card with the file manager app.&lt;/p&gt;\n\n&lt;p&gt;It reset all of the images&amp;#39; dates to the current date.&lt;/p&gt;\n\n&lt;p&gt;I was using an android app called &amp;quot;Image &amp;amp; Video Date Fixer&amp;quot; to fix them. First i categorized the images that need to be in order/next to each other into the same folders, then i renamed them on Windows with 1 second differences (like 20231122_11223**3** and 20231122_11223**4** and so on) then i used this app to set the EXIF dates into the names of pictures. &lt;/p&gt;\n\n&lt;p&gt;But i realized that gallery on my android app doesn&amp;#39;t respect one second differences and still mixes the images around their seconds&amp;#39; range. I want to space around those images for 5 seconds but i don&amp;#39;t want to repeat this process manually, i am already tired, i was so happy that it was finally over, then i got this problem. it was very time consuming and most people would not bother with what i am doing to be honest.&lt;/p&gt;\n\n&lt;p&gt;Is there any reliable software / or a process to automate this? I heard Exiftool but i don&amp;#39;t know how to use write codes for it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Not a definite goal of course, but maybe it could be something like this: I&amp;#39;d like detection for exif dates with 1 second differences, group those together, and then extend them based on the selected one image&amp;#39;s date in the group.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bmkcr", "is_robot_indexable": true, "report_reasons": null, "author": "RiusGoneMad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bmkcr/bulk_images_metadata_exif_editing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bmkcr/bulk_images_metadata_exif_editing/", "subreddit_subscribers": 726821, "created_utc": 1705786504.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}