{"kind": "Listing", "data": {"after": "t3_19ccg7y", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_poc45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody know of a resource explaining the differences between these checksum algorithms at a fairly basic level (pros, cons, etc)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_19c1i83", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pgaxQYNaszskmUFYuj8pN7AKq_qQSMuaVFDeUQKq4Ws.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705836721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rvosn91b4sdc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rvosn91b4sdc1.png?auto=webp&amp;s=210dd504440e5659069f03f6ac07b97d7a9e880a", "width": 978, "height": 657}, "resolutions": [{"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=93631ac6ed38c35554d2812b1ad097e19f3f697a", "width": 108, "height": 72}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=da02ebe634c43acf9800f9bbaeadc7d22501ce0a", "width": 216, "height": 145}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fb03d6e74e89a408d7dbf4a2b6140877ea9f9f22", "width": 320, "height": 214}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5aee88d10b3efc41876da9f802ae6ebaca63c6c", "width": 640, "height": 429}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=06e3d410e75b4ccc402b66068b75503f7f444580", "width": 960, "height": 644}], "variants": {}, "id": "aNxWOGfGK9il-LQFREbw-rVJ_dUzpvkQiVEhK9Jd5ho"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c1i83", "is_robot_indexable": true, "report_reasons": null, "author": "danielrosehill", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c1i83/anybody_know_of_a_resource_explaining_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rvosn91b4sdc1.png", "subreddit_subscribers": 726981, "created_utc": 1705836721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to share one of my backup drives with a friend. He told me it needs to be encrypted to store it in his house. I do trust him but he wants the data encrypted. I said fine with me. It's just medical and financial records as well as families movies like Christmas mornings. \n\nThe problem is that while my Linux desktop could always decrypt the drives with my gpg key or password. I'm trying to plan on a situation where something bad happens and I can't access the computer. Maybe I forget the password or something like that. \n\nI thought about buying a cheap waterproof USB drive and just burying it someplace.", "author_fullname": "t2_dui3ih3xt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for backing up keys and passwords of backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19brvds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705801182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to share one of my backup drives with a friend. He told me it needs to be encrypted to store it in his house. I do trust him but he wants the data encrypted. I said fine with me. It&amp;#39;s just medical and financial records as well as families movies like Christmas mornings. &lt;/p&gt;\n\n&lt;p&gt;The problem is that while my Linux desktop could always decrypt the drives with my gpg key or password. I&amp;#39;m trying to plan on a situation where something bad happens and I can&amp;#39;t access the computer. Maybe I forget the password or something like that. &lt;/p&gt;\n\n&lt;p&gt;I thought about buying a cheap waterproof USB drive and just burying it someplace.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19brvds", "is_robot_indexable": true, "report_reasons": null, "author": "sir_topham_biff", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19brvds/ideas_for_backing_up_keys_and_passwords_of_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19brvds/ideas_for_backing_up_keys_and_passwords_of_backups/", "subreddit_subscribers": 726981, "created_utc": 1705801182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Do you physically destroy them at home and toss the pieces into trash? Go to a place that have drive shredders (can't find many around my location)?\n\nThank you for reading and hopefully answering soon. :)", "author_fullname": "t2_4a27h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do with your personal home dead/broken storage drives (e.g., old HDDs) that you want to get rid of?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c6x2a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705853900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you physically destroy them at home and toss the pieces into trash? Go to a place that have drive shredders (can&amp;#39;t find many around my location)?&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading and hopefully answering soon. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Where's the big floppy disk(ette) flair? :P", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c6x2a", "is_robot_indexable": true, "report_reasons": null, "author": "antdude", "discussion_type": null, "num_comments": 41, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19c6x2a/what_do_you_do_with_your_personal_home_deadbroken/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c6x2a/what_do_you_do_with_your_personal_home_deadbroken/", "subreddit_subscribers": 726981, "created_utc": 1705853900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We've come a long way", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_19ccxmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_7ndf2", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interesting", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2d0bfed1a6d3cd366e4e91f627f5dee320de89fe", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Damnthatsinteresting", "selftext": "", "author_fullname": "t2_41eoq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store data in 1982", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Damnthatsinteresting", "hidden": false, "pwls": 6, "link_flair_css_class": "video", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_19c7ls1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2717, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/i2iwtohtotdc1/DASH_720.mp4?source=fallback", "has_audio": true, "height": 740, "width": 720, "scrubber_media_url": "https://v.redd.it/i2iwtohtotdc1/DASH_96.mp4", "dash_url": "https://v.redd.it/i2iwtohtotdc1/DASHPlaylist.mpd?a=1708465102%2CYzI5ZWRlMzAzNzdlOTU0NGJlNmZiNGI2Yjg5MzA1OTQwMmE1OWM3YTNhNDM1NGM5YmFhNDhkOTEzZWY5M2EzMw%3D%3D&amp;v=1&amp;f=sd", "duration": 190, "hls_url": "https://v.redd.it/i2iwtohtotdc1/HLSPlaylist.m3u8?a=1708465102%2CZjVhOTQxMTg3YWZkNDIzMjE5MzIwMzRhMDJmNjAzNTczNTZlZWY3NDhkZjk5OGVlN2ZlMmFmN2U1Zjg4NjE5Yw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Video", "can_mod_post": false, "score": 2717, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2d0bfed1a6d3cd366e4e91f627f5dee320de89fe", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "mod_note": null, "created": 1705855705.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/i2iwtohtotdc1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?format=pjpg&amp;auto=webp&amp;s=d258c7ecb446ee667bde33ed5225b67732a69c85", "width": 720, "height": 740}, "resolutions": [{"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6d9e111712b71a001a35bdec47864e4a4d3c2159", "width": 108, "height": 110}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0e5ada3d49e57fca7a38e4391834772f49b5570e", "width": 216, "height": 221}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b53629eed6e8abcb010e6ce452a1e00230e3e5bf", "width": 320, "height": 328}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=fdfe3204d5a62a16c5d0c74af28f0b4c3147b04c", "width": 640, "height": 657}], "variants": {}, "id": "Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2xxyj", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "19c7ls1", "is_robot_indexable": true, "report_reasons": null, "author": "Pasargad", "discussion_type": null, "num_comments": 137, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Damnthatsinteresting/comments/19c7ls1/how_to_store_data_in_1982/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/i2iwtohtotdc1", "subreddit_subscribers": 13434693, "created_utc": 1705855705.0, "num_crossposts": 2, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/i2iwtohtotdc1/DASH_720.mp4?source=fallback", "has_audio": true, "height": 740, "width": 720, "scrubber_media_url": "https://v.redd.it/i2iwtohtotdc1/DASH_96.mp4", "dash_url": "https://v.redd.it/i2iwtohtotdc1/DASHPlaylist.mpd?a=1708465102%2CYzI5ZWRlMzAzNzdlOTU0NGJlNmZiNGI2Yjg5MzA1OTQwMmE1OWM3YTNhNDM1NGM5YmFhNDhkOTEzZWY5M2EzMw%3D%3D&amp;v=1&amp;f=sd", "duration": 190, "hls_url": "https://v.redd.it/i2iwtohtotdc1/HLSPlaylist.m3u8?a=1708465102%2CZjVhOTQxMTg3YWZkNDIzMjE5MzIwMzRhMDJmNjAzNTczNTZlZWY3NDhkZjk5OGVlN2ZlMmFmN2U1Zjg4NjE5Yw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}], "created": 1705869038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/i2iwtohtotdc1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?auto=webp&amp;s=f652d1331011773e19ecc12146ed2e77bec997ac", "width": 720, "height": 740}, "resolutions": [{"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=387509397e8677ccf617a86f7fe675c1c5799275", "width": 108, "height": 110}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=471739abfdabb307f58048bb1f4aa2707a906e98", "width": 216, "height": 221}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a73735793ef0516c74bc7778c7011d341351508f", "width": 320, "height": 328}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=91948c148ec5e24b6cdb75428e76d8ad493c0347", "width": 640, "height": 657}], "variants": {}, "id": "Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "19ccxmc", "is_robot_indexable": true, "report_reasons": null, "author": "pelosnecios", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_19c7ls1", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccxmc/weve_come_a_long_way/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/i2iwtohtotdc1", "subreddit_subscribers": 726981, "created_utc": 1705869038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nWanted to seek some advice. I am scanning all the documents I have / will get and saving them locally and on the cloud. (Redundancy.)  But all the scanners are always so slow, I have a HUGE pile, and the printer/scanner I have now takes about 30 seconds for 1 side of a single paper. (Please come and save me) I currently have an HP DeskJet 2734e, which I no longer print so stopped paying for the service. Little did I know that would make me unable to print NOR use the scanner....\n\n&amp;#x200B;\n\nWhat am I looking for?\n\n* A scanner. \n   * It can be an all-in-one printer but if it requires a paid service, I will ignore it lol.\n* Preferably quick but maintains the quality.\n* Can be saved as PDF or JPG.\n* Does not cost an arm and a leg.\n* Highly prefer to be connected to Wi-Fi (or Bluetooth) but if it costs less to use cable, I will deal with it.\n\nAdditional Information\n\n* Some are one-sided, and some are double-sided.\n* Some have mutliple pages.\n* Some have multiple pages. that are one-sided and double-sided. -\\_-\n\n&amp;#x200B;\n\nThank you in advance for any suggestions!!!", "author_fullname": "t2_o4hbhngt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast Scanner W/O Printer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19blxon", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705784844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Wanted to seek some advice. I am scanning all the documents I have / will get and saving them locally and on the cloud. (Redundancy.)  But all the scanners are always so slow, I have a HUGE pile, and the printer/scanner I have now takes about 30 seconds for 1 side of a single paper. (Please come and save me) I currently have an HP DeskJet 2734e, which I no longer print so stopped paying for the service. Little did I know that would make me unable to print NOR use the scanner....&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What am I looking for?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A scanner. \n\n&lt;ul&gt;\n&lt;li&gt;It can be an all-in-one printer but if it requires a paid service, I will ignore it lol.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Preferably quick but maintains the quality.&lt;/li&gt;\n&lt;li&gt;Can be saved as PDF or JPG.&lt;/li&gt;\n&lt;li&gt;Does not cost an arm and a leg.&lt;/li&gt;\n&lt;li&gt;Highly prefer to be connected to Wi-Fi (or Bluetooth) but if it costs less to use cable, I will deal with it.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Additional Information&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Some are one-sided, and some are double-sided.&lt;/li&gt;\n&lt;li&gt;Some have mutliple pages.&lt;/li&gt;\n&lt;li&gt;Some have multiple pages. that are one-sided and double-sided. -_-&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any suggestions!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19blxon", "is_robot_indexable": true, "report_reasons": null, "author": "Jordanbr25", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19blxon/fast_scanner_wo_printer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19blxon/fast_scanner_wo_printer/", "subreddit_subscribers": 726981, "created_utc": 1705784844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am fairly new to this and just recently in the past 6 months or so (June 2023) started to organize my life and data to have better control and archiving. I've got 4 kids, a few businesses, wife, and as everyone can imagine - countless data, docs and files that I should save and stop paying cloud providers for.\n\nI'm now about 8 TB deep into my system. I see how this will get out of control quickly, and my issue that I didn't consider is retrieval.\n\n**How does everyone organize or index their data?** \n\nI don't mean like file name conventions, tag or folder systems. I am curious if you build a database to store key information such as:\n\n* Backup Archives\n   * File Name | Archiving Date | File Summary | Etc. \n* Directory MOC\n   * Directory Name | File Types/Rules | Dates and Source Locations | etc... \n\n&amp;#x200B;\n\nI want to avoid the pitfall of when I need to find that one set of PDFs or photos from that one period I think was maybe between August 2016 and March 2017... for example. \n\n&amp;#x200B;\n\nJust curious of the process some bigger hoarders have taken to help me avoid a nightmare. ", "author_fullname": "t2_aikbtreq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Documenting and Indexing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c70r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705854163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am fairly new to this and just recently in the past 6 months or so (June 2023) started to organize my life and data to have better control and archiving. I&amp;#39;ve got 4 kids, a few businesses, wife, and as everyone can imagine - countless data, docs and files that I should save and stop paying cloud providers for.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m now about 8 TB deep into my system. I see how this will get out of control quickly, and my issue that I didn&amp;#39;t consider is retrieval.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How does everyone organize or index their data?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t mean like file name conventions, tag or folder systems. I am curious if you build a database to store key information such as:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Backup Archives\n\n&lt;ul&gt;\n&lt;li&gt;File Name | Archiving Date | File Summary | Etc. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Directory MOC\n\n&lt;ul&gt;\n&lt;li&gt;Directory Name | File Types/Rules | Dates and Source Locations | etc... &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to avoid the pitfall of when I need to find that one set of PDFs or photos from that one period I think was maybe between August 2016 and March 2017... for example. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Just curious of the process some bigger hoarders have taken to help me avoid a nightmare. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "8TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c70r5", "is_robot_indexable": true, "report_reasons": null, "author": "HisNameWasShagbark", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19c70r5/documenting_and_indexing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c70r5/documenting_and_indexing/", "subreddit_subscribers": 726981, "created_utc": 1705854163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello.\nI've been trying to manage my library for years without success.\nI have photos, backups of these photos, copies with different names, some of them with fucked date metadata...\n\nI wonder if there is a software that finds duplicates, and keep ALL metadata merged, picking the oldest date available for example.\n\nCan you guide me to start organizing this mess?\nI would be happy renaming all files with it's date\n\nIm talking about 500.000 files aprox.\n\nI'm using Windows 10\n\nThank you!", "author_fullname": "t2_b969b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need photo/video management help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c29y2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705840492.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705839687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.\nI&amp;#39;ve been trying to manage my library for years without success.\nI have photos, backups of these photos, copies with different names, some of them with fucked date metadata...&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is a software that finds duplicates, and keep ALL metadata merged, picking the oldest date available for example.&lt;/p&gt;\n\n&lt;p&gt;Can you guide me to start organizing this mess?\nI would be happy renaming all files with it&amp;#39;s date&lt;/p&gt;\n\n&lt;p&gt;Im talking about 500.000 files aprox.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Windows 10&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c29y2", "is_robot_indexable": true, "report_reasons": null, "author": "smaiderman", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c29y2/i_need_photovideo_management_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c29y2/i_need_photovideo_management_help/", "subreddit_subscribers": 726981, "created_utc": 1705839687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My wife passed away years ago. She left behind a sizable collection of pre-digital prints and negatives, which is being scanned, and a big collection in Google Photos.\n\nI like that Google Photos shows me my old pictures daily, and it would be nice to see her pics too. It would also be nice for other family members to be able to browse the pictures.\n\nShould I move her Google Photo pictures to my account? Leave them in hers? Should I put them in my Google Drive account? Somewhere else?\n\nBonus question: the scanned pictures are going to have the scanning date as the EXIF date. What's the done thing here? Should I update the EXIF date with the actual picture date? Put the actual date somewhere else? How can I make sure that Google Photos, for example, will show the pictures in correct chronological order?", "author_fullname": "t2_mwhfv38o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do with my deceased wife's photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bvqos", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705813870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My wife passed away years ago. She left behind a sizable collection of pre-digital prints and negatives, which is being scanned, and a big collection in Google Photos.&lt;/p&gt;\n\n&lt;p&gt;I like that Google Photos shows me my old pictures daily, and it would be nice to see her pics too. It would also be nice for other family members to be able to browse the pictures.&lt;/p&gt;\n\n&lt;p&gt;Should I move her Google Photo pictures to my account? Leave them in hers? Should I put them in my Google Drive account? Somewhere else?&lt;/p&gt;\n\n&lt;p&gt;Bonus question: the scanned pictures are going to have the scanning date as the EXIF date. What&amp;#39;s the done thing here? Should I update the EXIF date with the actual picture date? Put the actual date somewhere else? How can I make sure that Google Photos, for example, will show the pictures in correct chronological order?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bvqos", "is_robot_indexable": true, "report_reasons": null, "author": "optimisticlemur", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bvqos/what_to_do_with_my_deceased_wifes_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bvqos/what_to_do_with_my_deceased_wifes_photos/", "subreddit_subscribers": 726981, "created_utc": 1705813870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have always been interested in data hoarding, but never had enough storage to do so. But now that I have it, I have don't know where to go from here. I have downloaded a few popular operating systems,  but other than that I have nothing. I am very new to this kind of thing, so I would like to start this thread not only for me, but for anybody in the future looking to get into datahoarding.", "author_fullname": "t2_d4tw5puh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hello! I just received and started up my new 8 Terabyte HDD. This is the first time I have ever had this kind of storage.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19cddev", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705870151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have always been interested in data hoarding, but never had enough storage to do so. But now that I have it, I have don&amp;#39;t know where to go from here. I have downloaded a few popular operating systems,  but other than that I have nothing. I am very new to this kind of thing, so I would like to start this thread not only for me, but for anybody in the future looking to get into datahoarding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19cddev", "is_robot_indexable": true, "report_reasons": null, "author": "ckJay286444", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19cddev/hello_i_just_received_and_started_up_my_new_8/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19cddev/hello_i_just_received_and_started_up_my_new_8/", "subreddit_subscribers": 726981, "created_utc": 1705870151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "G\u2019day - title may have been weird if so apologies, and I did a search but couldn\u2019t find what I was after\n\nI have a few hundred hard drives - both in servers and also externals \n\nIs there a program \u2018anywhere\u2019 that would allow me to scan these drives , and list the contents, and alert me when there are dupes ?\n\nKinda like a big database ?\n\nBe even more helpful if once the scanning process was done, that \u2018this program\u2019 would add new downloads to the database etc\n\nI keep finding that I have multiple copies of various things which is not only a waste of bandwidth but more importantly hard drive space , and the system I\u2019m currently using is obviously really bad\n\nSo I figure that there has to be a decent way or organization out there right ??", "author_fullname": "t2_dak0xorw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Program to scan drives for content to list dupes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19ccac2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705867433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;G\u2019day - title may have been weird if so apologies, and I did a search but couldn\u2019t find what I was after&lt;/p&gt;\n\n&lt;p&gt;I have a few hundred hard drives - both in servers and also externals &lt;/p&gt;\n\n&lt;p&gt;Is there a program \u2018anywhere\u2019 that would allow me to scan these drives , and list the contents, and alert me when there are dupes ?&lt;/p&gt;\n\n&lt;p&gt;Kinda like a big database ?&lt;/p&gt;\n\n&lt;p&gt;Be even more helpful if once the scanning process was done, that \u2018this program\u2019 would add new downloads to the database etc&lt;/p&gt;\n\n&lt;p&gt;I keep finding that I have multiple copies of various things which is not only a waste of bandwidth but more importantly hard drive space , and the system I\u2019m currently using is obviously really bad&lt;/p&gt;\n\n&lt;p&gt;So I figure that there has to be a decent way or organization out there right ??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19ccac2", "is_robot_indexable": true, "report_reasons": null, "author": "ectoplasmic-warrior", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccac2/program_to_scan_drives_for_content_to_list_dupes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ccac2/program_to_scan_drives_for_content_to_list_dupes/", "subreddit_subscribers": 726981, "created_utc": 1705867433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\n# \n\nI accidentally deleted my documents on my laptop(windows os) and I need them in two days. Any tools for recovery that are easy to use?", "author_fullname": "t2_k1mgo7uwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data recovery softwares", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19cbtmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705866277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I accidentally deleted my documents on my laptop(windows os) and I need them in two days. Any tools for recovery that are easy to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19cbtmn", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent_Eye1248", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19cbtmn/data_recovery_softwares/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19cbtmn/data_recovery_softwares/", "subreddit_subscribers": 726981, "created_utc": 1705866277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hard drives, as I understand it, often exhibit warning symptoms before they fail. And SSDs, maybe not so much. But still, I'm certain there must be some software out that to notify you if your drive health is showing anything concerning.\n\nIs there a good light-weight system tray app that can run in the background and run daily checks or something?\n\nI have a Windows desktop machine in my office with 14 GB of storage, and a Windows desktop acting as a server in the living room with 20 GB storage.", "author_fullname": "t2_4uv8kp1km", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best software for monitoring hard drive health status? (Windows)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19caacs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705862425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hard drives, as I understand it, often exhibit warning symptoms before they fail. And SSDs, maybe not so much. But still, I&amp;#39;m certain there must be some software out that to notify you if your drive health is showing anything concerning.&lt;/p&gt;\n\n&lt;p&gt;Is there a good light-weight system tray app that can run in the background and run daily checks or something?&lt;/p&gt;\n\n&lt;p&gt;I have a Windows desktop machine in my office with 14 GB of storage, and a Windows desktop acting as a server in the living room with 20 GB storage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "30TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19caacs", "is_robot_indexable": true, "report_reasons": null, "author": "raging_pastafarian", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19caacs/best_software_for_monitoring_hard_drive_health/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19caacs/best_software_for_monitoring_hard_drive_health/", "subreddit_subscribers": 726981, "created_utc": 1705862425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to preserve a very long RPG play-by-post game written on a discord server. It's about 1.5 million words of text. All the other posts I've seen asking about preserving things from discord are concerned with saving photos/attachments or reactions, but I want literally just the text people have written and to specifically *exclude* things like usernames, dates, and reactions so that it reads like a book. It seems like there should be an easy way to have a program grab just the text and export it to a text file, but I haven't found anything.\n\nWant to keep: The responses people write, formatting if possible (e.g. italics)\n\nDon't want to keep: Usernames, dates, reactions, images, attachments\n\nAny suggestions? I can get admin access to the server as well if that affects what can be done.", "author_fullname": "t2_boege", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to archive ONLY text from a discord server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bthfz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705806171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to preserve a very long RPG play-by-post game written on a discord server. It&amp;#39;s about 1.5 million words of text. All the other posts I&amp;#39;ve seen asking about preserving things from discord are concerned with saving photos/attachments or reactions, but I want literally just the text people have written and to specifically &lt;em&gt;exclude&lt;/em&gt; things like usernames, dates, and reactions so that it reads like a book. It seems like there should be an easy way to have a program grab just the text and export it to a text file, but I haven&amp;#39;t found anything.&lt;/p&gt;\n\n&lt;p&gt;Want to keep: The responses people write, formatting if possible (e.g. italics)&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t want to keep: Usernames, dates, reactions, images, attachments&lt;/p&gt;\n\n&lt;p&gt;Any suggestions? I can get admin access to the server as well if that affects what can be done.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bthfz", "is_robot_indexable": true, "report_reasons": null, "author": "Lycanthrotree", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bthfz/best_way_to_archive_only_text_from_a_discord/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bthfz/best_way_to_archive_only_text_from_a_discord/", "subreddit_subscribers": 726981, "created_utc": 1705806171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone.  I upgraded my 12TB (2x6TB) PR2100 with two 10TB WD Red drives.  Everything seemed to go well, but I'm running into problem that I cant figure out a solution to.  I'm trying to transfer a video file to a folder on the drive and I'm getting an error that says:\n\n \"There is not enough space on videos\n\n 0 bytes is needed to copy this item. Delete or move files so you have enough space\"\n\nThere is plenty of space on the drives so this is throwing me for a loop.  Does anyone have a recommendation as to how I can fix this.\n\nThanks in advance for any help.", "author_fullname": "t2_wk1uv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PR2100 Drive Upgrade Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bpxak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705795543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone.  I upgraded my 12TB (2x6TB) PR2100 with two 10TB WD Red drives.  Everything seemed to go well, but I&amp;#39;m running into problem that I cant figure out a solution to.  I&amp;#39;m trying to transfer a video file to a folder on the drive and I&amp;#39;m getting an error that says:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;There is not enough space on videos&lt;/p&gt;\n\n&lt;p&gt;0 bytes is needed to copy this item. Delete or move files so you have enough space&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;There is plenty of space on the drives so this is throwing me for a loop.  Does anyone have a recommendation as to how I can fix this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bpxak", "is_robot_indexable": true, "report_reasons": null, "author": "JohnnyDanger79", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bpxak/pr2100_drive_upgrade_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bpxak/pr2100_drive_upgrade_problem/", "subreddit_subscribers": 726981, "created_utc": 1705795543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a folder of images (around 7k) which i messed up the exif data of by moving them from android phone's own memory to the sd card with the file manager app.\n\nIt reset all of the images' dates to the current date.\n\nI was using an android app called \"Image &amp; Video Date Fixer\" to fix them. First i categorized the images that need to be in order/next to each other into the same folders, then i renamed them on Windows with 1 second differences (like 20231122\\_11223\\*\\*3\\*\\* and 20231122\\_11223\\*\\*4\\*\\* and so on) then i used this app to set the EXIF dates into the names of pictures. \n\nBut i realized that gallery on my android app doesn't respect one second differences and still mixes the images around their seconds' range. I want to space around those images for 5 seconds but i don't want to repeat this process manually, i am already tired, i was so happy that it was finally over, then i got this problem. it was very time consuming and most people would not bother with what i am doing to be honest.\n\nIs there any reliable software / or a process to automate this? I heard Exiftool but i don't know how to use write codes for it. \n\n&amp;#x200B;\n\nNot a definite goal of course, but maybe it could be something like this: I'd like detection for exif dates with 1 second differences, group those together, and then extend them based on the selected one image's date in the group.", "author_fullname": "t2_nv30o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk images metadata / EXIF editing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bmkcr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705786504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a folder of images (around 7k) which i messed up the exif data of by moving them from android phone&amp;#39;s own memory to the sd card with the file manager app.&lt;/p&gt;\n\n&lt;p&gt;It reset all of the images&amp;#39; dates to the current date.&lt;/p&gt;\n\n&lt;p&gt;I was using an android app called &amp;quot;Image &amp;amp; Video Date Fixer&amp;quot; to fix them. First i categorized the images that need to be in order/next to each other into the same folders, then i renamed them on Windows with 1 second differences (like 20231122_11223**3** and 20231122_11223**4** and so on) then i used this app to set the EXIF dates into the names of pictures. &lt;/p&gt;\n\n&lt;p&gt;But i realized that gallery on my android app doesn&amp;#39;t respect one second differences and still mixes the images around their seconds&amp;#39; range. I want to space around those images for 5 seconds but i don&amp;#39;t want to repeat this process manually, i am already tired, i was so happy that it was finally over, then i got this problem. it was very time consuming and most people would not bother with what i am doing to be honest.&lt;/p&gt;\n\n&lt;p&gt;Is there any reliable software / or a process to automate this? I heard Exiftool but i don&amp;#39;t know how to use write codes for it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Not a definite goal of course, but maybe it could be something like this: I&amp;#39;d like detection for exif dates with 1 second differences, group those together, and then extend them based on the selected one image&amp;#39;s date in the group.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bmkcr", "is_robot_indexable": true, "report_reasons": null, "author": "RiusGoneMad", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bmkcr/bulk_images_metadata_exif_editing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bmkcr/bulk_images_metadata_exif_editing/", "subreddit_subscribers": 726981, "created_utc": 1705786504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to move my backups to different location, since in the case of fire or theft I could lose all data.\n\nI was thinking to copy everything on external 2.5\" HDDs and store them far away from my apartment.\n\nI have:\n\n* Maxtor M3 Portable External Hard Drive (**4TB**)\n* Seagate Basic Portable Drive (**5TB**)\n* and plan to buy WD Elements Portable Black 2.5 (**5TB**)  \n\n\nAll drives are new and not used much. I have a house in a countryside and that is where I plan to keep my offsite backup. No one lives there and temperature can go from -20\u00b0C to 40\u00b0C.   \nI was wondering do you have any suggestions on how to store these drives? I guess I need to keep them in shade and keep them dry. Do I need to buy some protective materials to isolate them better? \n\nI would like to keep them in a good health for 10 years and to replace them after. Not sure if these ones are able to live that long (even when not used), since they are the cheapest I could find.  \n", "author_fullname": "t2_26c1b19v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store external HDD as an offsite backup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19ccz2t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705869140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to move my backups to different location, since in the case of fire or theft I could lose all data.&lt;/p&gt;\n\n&lt;p&gt;I was thinking to copy everything on external 2.5&amp;quot; HDDs and store them far away from my apartment.&lt;/p&gt;\n\n&lt;p&gt;I have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Maxtor M3 Portable External Hard Drive (&lt;strong&gt;4TB&lt;/strong&gt;)&lt;/li&gt;\n&lt;li&gt;Seagate Basic Portable Drive (&lt;strong&gt;5TB&lt;/strong&gt;)&lt;/li&gt;\n&lt;li&gt;and plan to buy WD Elements Portable Black 2.5 (&lt;strong&gt;5TB&lt;/strong&gt;)&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All drives are new and not used much. I have a house in a countryside and that is where I plan to keep my offsite backup. No one lives there and temperature can go from -20\u00b0C to 40\u00b0C.&lt;br/&gt;\nI was wondering do you have any suggestions on how to store these drives? I guess I need to keep them in shade and keep them dry. Do I need to buy some protective materials to isolate them better? &lt;/p&gt;\n\n&lt;p&gt;I would like to keep them in a good health for 10 years and to replace them after. Not sure if these ones are able to live that long (even when not used), since they are the cheapest I could find.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19ccz2t", "is_robot_indexable": true, "report_reasons": null, "author": "zp-87", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccz2t/how_to_store_external_hdd_as_an_offsite_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ccz2t/how_to_store_external_hdd_as_an_offsite_backup/", "subreddit_subscribers": 726981, "created_utc": 1705869140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know that there is individual that share storage between themselves and I know that there is FileCoin\n\nBut no fren and FIL is actually just a currency to give to classic providers\n\nI search for a way to share my storage P2P on a network with random people and get the same transfer/storage amount in return, no money\n\nOnly problem being availability as I don't have a server, so I can't be online all the time. And my data is metered so I want to share really few data because basically it'll cost me 4 times the data amount I want to save (like backup 1 GB of data means one upload of me, one of the other one, one download per person too, multiply it by wanted backups)", "author_fullname": "t2_5slsu5xg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mutual storage sharing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19ccgq2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Serious answer only", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705867870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that there is individual that share storage between themselves and I know that there is FileCoin&lt;/p&gt;\n\n&lt;p&gt;But no fren and FIL is actually just a currency to give to classic providers&lt;/p&gt;\n\n&lt;p&gt;I search for a way to share my storage P2P on a network with random people and get the same transfer/storage amount in return, no money&lt;/p&gt;\n\n&lt;p&gt;Only problem being availability as I don&amp;#39;t have a server, so I can&amp;#39;t be online all the time. And my data is metered so I want to share really few data because basically it&amp;#39;ll cost me 4 times the data amount I want to save (like backup 1 GB of data means one upload of me, one of the other one, one download per person too, multiply it by wanted backups)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "19ccgq2", "is_robot_indexable": true, "report_reasons": null, "author": "xqoe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccgq2/mutual_storage_sharing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ccgq2/mutual_storage_sharing/", "subreddit_subscribers": 726981, "created_utc": 1705867870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to find a good capture card for digitizing tapes.\nHaulage pvr2 is my go to for capture but I understand stand it doesn't work with VirtualDub and it has built in compression.\n\nTried a cheap 5 dollar capture card I bought online and it works with VDub but so far it seems to have Jpg artifacts in the recording, haven't determined if it's the tape or the card but I see compression in VDubs control panel and assume its hardware since I can't turn it off.\n\nI also have a Diamond VC500 that I haven't tried.\nPc is running latest Windows.", "author_fullname": "t2_fk8e08x1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need personal recommendations on capture cards.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cb7gl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705864724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to find a good capture card for digitizing tapes.\nHaulage pvr2 is my go to for capture but I understand stand it doesn&amp;#39;t work with VirtualDub and it has built in compression.&lt;/p&gt;\n\n&lt;p&gt;Tried a cheap 5 dollar capture card I bought online and it works with VDub but so far it seems to have Jpg artifacts in the recording, haven&amp;#39;t determined if it&amp;#39;s the tape or the card but I see compression in VDubs control panel and assume its hardware since I can&amp;#39;t turn it off.&lt;/p&gt;\n\n&lt;p&gt;I also have a Diamond VC500 that I haven&amp;#39;t tried.\nPc is running latest Windows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19cb7gl", "is_robot_indexable": true, "report_reasons": null, "author": "KWalthersArt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19cb7gl/need_personal_recommendations_on_capture_cards/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19cb7gl/need_personal_recommendations_on_capture_cards/", "subreddit_subscribers": 726981, "created_utc": 1705864724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am digitizing a bunch of old family photos 1976-1978 onwards some even date to 1970s , and it is also our family tree, so apart from giving relevant file names how can i make a comment or note in the photo as to who are the people in the photo. I am scanning photos in our flatbed scanner as jpg file.  \n\nI am thinking of using image editor and add a text line below the photo or wherever there is empty space in photo, but is this a good method of tagging or recording comments about photos? ", "author_fullname": "t2_ogj32tug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to tag people in photos - scanned old ones", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bxual", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705821672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am digitizing a bunch of old family photos 1976-1978 onwards some even date to 1970s , and it is also our family tree, so apart from giving relevant file names how can i make a comment or note in the photo as to who are the people in the photo. I am scanning photos in our flatbed scanner as jpg file.  &lt;/p&gt;\n\n&lt;p&gt;I am thinking of using image editor and add a text line below the photo or wherever there is empty space in photo, but is this a good method of tagging or recording comments about photos? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bxual", "is_robot_indexable": true, "report_reasons": null, "author": "Sudden-Air-243", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bxual/how_to_tag_people_in_photos_scanned_old_ones/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bxual/how_to_tag_people_in_photos_scanned_old_ones/", "subreddit_subscribers": 726981, "created_utc": 1705821672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, \n\n&amp;#x200B;\n\nI'm looking for a tool that would allow me to backup:\n\n\\- All my tweets, retweets, liked and bookmarked tweets with the associated media\n\n\\- My followers list\n\n\\- My lists\n\n&amp;#x200B;\n\nIf this tool does not exist, is there a way for me to have programmatical access to my data without using Twitter official API (100USD/Month)? I could write a script or a browser extension.", "author_fullname": "t2_at77r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download an extensive backup of my own twitter account", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19butmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705810692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a tool that would allow me to backup:&lt;/p&gt;\n\n&lt;p&gt;- All my tweets, retweets, liked and bookmarked tweets with the associated media&lt;/p&gt;\n\n&lt;p&gt;- My followers list&lt;/p&gt;\n\n&lt;p&gt;- My lists&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If this tool does not exist, is there a way for me to have programmatical access to my data without using Twitter official API (100USD/Month)? I could write a script or a browser extension.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19butmc", "is_robot_indexable": true, "report_reasons": null, "author": "bobberkarl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19butmc/download_an_extensive_backup_of_my_own_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19butmc/download_an_extensive_backup_of_my_own_twitter/", "subreddit_subscribers": 726981, "created_utc": 1705810692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Moving into DAS and was recommended that Toshiba\u2019s are pretty solid for DAS? Anyone uses them and can vouch for it? I just got a Thunderbay 8 from OWC and im planning to use 10tb wd red\u2019s or the Exos but now checking if I should just go with Toshiba\u2019s since its what OWC recommends.", "author_fullname": "t2_4ma0eche", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toshiba? Best HDD for OWC DAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bq7cz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705796323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Moving into DAS and was recommended that Toshiba\u2019s are pretty solid for DAS? Anyone uses them and can vouch for it? I just got a Thunderbay 8 from OWC and im planning to use 10tb wd red\u2019s or the Exos but now checking if I should just go with Toshiba\u2019s since its what OWC recommends.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bq7cz", "is_robot_indexable": true, "report_reasons": null, "author": "Arjay188", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bq7cz/toshiba_best_hdd_for_owc_das/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bq7cz/toshiba_best_hdd_for_owc_das/", "subreddit_subscribers": 726981, "created_utc": 1705796323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased three external hard drives, all 2 TB. I am backing up my Macbook on all three external hard drives using Time Machine. I am just wondering if this is a solid back-up plan. I am aware of the 3-2-1 rule. Hence the three external hard drives. I know that the Rule says I am supposed to have at least 2 different methods for backing up. In which case, for one of my back-ups instead of Time Machine I could use the software that the external hard drives come with. However Time Machine has turned out to be so simple, and these softwares that accompany the external hard drives are a bit more complex to set up. So I'm thinking to just keep things simple by using Time Machine for all three of my external hard drives. \n\nIs there anything wrong with that? ", "author_fullname": "t2_4u6autkj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time Machine as my Back-Up Method on all three of my external hard drives \u2013 is this a solid back-up plan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bptve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705795285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased three external hard drives, all 2 TB. I am backing up my Macbook on all three external hard drives using Time Machine. I am just wondering if this is a solid back-up plan. I am aware of the 3-2-1 rule. Hence the three external hard drives. I know that the Rule says I am supposed to have at least 2 different methods for backing up. In which case, for one of my back-ups instead of Time Machine I could use the software that the external hard drives come with. However Time Machine has turned out to be so simple, and these softwares that accompany the external hard drives are a bit more complex to set up. So I&amp;#39;m thinking to just keep things simple by using Time Machine for all three of my external hard drives. &lt;/p&gt;\n\n&lt;p&gt;Is there anything wrong with that? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bptve", "is_robot_indexable": true, "report_reasons": null, "author": "OrvilleSpencer34", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bptve/time_machine_as_my_backup_method_on_all_three_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bptve/time_machine_as_my_backup_method_on_all_three_of/", "subreddit_subscribers": 726981, "created_utc": 1705795285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I am a wannabe data hoarder lmao  \n\n\nI have a spare pc that I don't use, it's an old 1155 gigabyte ga-b75n motherboard with an intel i7 2600k and 16gb ddr3. I also have a box with x14 500gb laptop hard drives that check good on crystaldisk info. That motherboard just has 4 sata ports. I need one of them for the ssd, another one for a wd red 3tb nas drive, and then the other 2 for 2 of these 2.5\" drives that I have.  \n\n\nI've seen cards that can output sata ports from pci express, but that was a long time ago, when I started searching on here I saw so many types of cards, I kind of got lost.  \n\n\nThe main purpose of this build is to have a server I can use for torrent and jellyfin and basically everything I use my raspberry pi 3b+ for (plus nextcloud which my old pi can't do), but because I have no money to buy a decent modern SBC (like the ODRIOD H3 which could handle nextcloud and some other stuff although no more than 2 sata drives)  \n\n\nFor what I've seen, a normal ammount of sata ports in one of those cards seems to be 8 ports. Anything above that, looks like it's bad quality pci-e 2x.  \n\n\nBut no idea of what card to buy, I saw this one on [ebay](https://www.ebay.es/itm/144210451235?hash=item21939cdb23:g:WuEAAOSwHWRhSJ8y&amp;amdata=enc%3AAQAIAAAAwC%2BiXEwAVaYAyphYHkqdN5rMEpTESXfX3t59m298SgH1Nx0xcBQcR2Yz2cuxQQw46yz%2B1sEBqiv6iXHk%2FFHM2ctv6Vdy73jMCNfBeihXR96ZCciO6hbU%2FDl6LLRB0%2BVwaBifJbDef3iy0xI5Cjspgmi2j3woRAkFTKS8bW9wbBJw9RmGIow9aChikNhzxMAwxfSGvu%2B89kG0U169pMPu5ngunBOKmzxiNkXEif8NaEvg0xDkk4z%2F0u6lGM0FehzlrQ%3D%3D%7Ctkp%3ABk9SR8ri_Y-lYw) . 26\u20ac for it seems cheap, also comes from china so no idea if it's good.  \n\n\nAlso, my drives are sata, and don't know what does that card have but I guess I need an adapter.  \n\n\nSince I guess people here are expert on this matter, I would appreciate some help! Thanks and sorry for the wall of text!", "author_fullname": "t2_q87sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to connect ~10 hdd to my pc, unsure how. Help is appreciated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bo7v4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705790925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am a wannabe data hoarder lmao  &lt;/p&gt;\n\n&lt;p&gt;I have a spare pc that I don&amp;#39;t use, it&amp;#39;s an old 1155 gigabyte ga-b75n motherboard with an intel i7 2600k and 16gb ddr3. I also have a box with x14 500gb laptop hard drives that check good on crystaldisk info. That motherboard just has 4 sata ports. I need one of them for the ssd, another one for a wd red 3tb nas drive, and then the other 2 for 2 of these 2.5&amp;quot; drives that I have.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen cards that can output sata ports from pci express, but that was a long time ago, when I started searching on here I saw so many types of cards, I kind of got lost.  &lt;/p&gt;\n\n&lt;p&gt;The main purpose of this build is to have a server I can use for torrent and jellyfin and basically everything I use my raspberry pi 3b+ for (plus nextcloud which my old pi can&amp;#39;t do), but because I have no money to buy a decent modern SBC (like the ODRIOD H3 which could handle nextcloud and some other stuff although no more than 2 sata drives)  &lt;/p&gt;\n\n&lt;p&gt;For what I&amp;#39;ve seen, a normal ammount of sata ports in one of those cards seems to be 8 ports. Anything above that, looks like it&amp;#39;s bad quality pci-e 2x.  &lt;/p&gt;\n\n&lt;p&gt;But no idea of what card to buy, I saw this one on &lt;a href=\"https://www.ebay.es/itm/144210451235?hash=item21939cdb23:g:WuEAAOSwHWRhSJ8y&amp;amp;amdata=enc%3AAQAIAAAAwC%2BiXEwAVaYAyphYHkqdN5rMEpTESXfX3t59m298SgH1Nx0xcBQcR2Yz2cuxQQw46yz%2B1sEBqiv6iXHk%2FFHM2ctv6Vdy73jMCNfBeihXR96ZCciO6hbU%2FDl6LLRB0%2BVwaBifJbDef3iy0xI5Cjspgmi2j3woRAkFTKS8bW9wbBJw9RmGIow9aChikNhzxMAwxfSGvu%2B89kG0U169pMPu5ngunBOKmzxiNkXEif8NaEvg0xDkk4z%2F0u6lGM0FehzlrQ%3D%3D%7Ctkp%3ABk9SR8ri_Y-lYw\"&gt;ebay&lt;/a&gt; . 26\u20ac for it seems cheap, also comes from china so no idea if it&amp;#39;s good.  &lt;/p&gt;\n\n&lt;p&gt;Also, my drives are sata, and don&amp;#39;t know what does that card have but I guess I need an adapter.  &lt;/p&gt;\n\n&lt;p&gt;Since I guess people here are expert on this matter, I would appreciate some help! Thanks and sorry for the wall of text!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?auto=webp&amp;s=ecb8019d97a50921834f2592a9af64513eca9f5d", "width": 400, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=36d785f27544862c20cb5d15eca758e4dc4a8ef1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2521cd5aacef09fab648c925746b167ce962a011", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6163d552292c2244476550f52a0aaa7bd2b8eb33", "width": 320, "height": 240}], "variants": {}, "id": "4SNq5slnQHY5ukuvhQh51R7fc-UIue5XnqAfNqEw6iI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bo7v4", "is_robot_indexable": true, "report_reasons": null, "author": "LanguageManiac", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bo7v4/want_to_connect_10_hdd_to_my_pc_unsure_how_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bo7v4/want_to_connect_10_hdd_to_my_pc_unsure_how_help/", "subreddit_subscribers": 726981, "created_utc": 1705790925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI need help connecting my old Buffalo TerraStation Model HS-DH0.0TGL/R5. Buffalo no longer offers the NAS server software. When I try to use the IP address, it doesn't recognize the user and password I provided. I'm using a MAC Studio with Sonoma 14.2.1.\u00a0\n\nAny assistance would be greatly appreciated!", "author_fullname": "t2_ftg55infz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with an old Buffalo TerraStation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bmg89", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705786209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I need help connecting my old Buffalo TerraStation Model HS-DH0.0TGL/R5. Buffalo no longer offers the NAS server software. When I try to use the IP address, it doesn&amp;#39;t recognize the user and password I provided. I&amp;#39;m using a MAC Studio with Sonoma 14.2.1.\u00a0&lt;/p&gt;\n\n&lt;p&gt;Any assistance would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bmg89", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Week-6906", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bmg89/help_with_an_old_buffalo_terrastation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bmg89/help_with_an_old_buffalo_terrastation/", "subreddit_subscribers": 726981, "created_utc": 1705786209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I'm unsure if this is the best sub to ask this but I was wondering if anyone has any insight on this topic. There's a couple of recipe sites I like and I'd like to back them up for offline (non ad-supported) use.\n\nMost of them use the same wordpress recipe platform and yoast SEO plugin. So I was wondering if it's somehow possible to rip the entire site via the XML sitemap list. Preferably the 'printable' versions.\n\nExample sites:\n\n[https://sweetsimplevegan.com/post-sitemap.xml](https://sweetsimplevegan.com/post-sitemap.xml)\n\n[https://thebananadiaries.com/post-sitemap.xml](https://thebananadiaries.com/post-sitemap.xml)\n\n[https://www.averiecooks.com/post-sitemap.xml](https://www.averiecooks.com/post-sitemap.xml)\n\nNot asking anyone to do it for me, i'm fairly tech savvy, just not positive how to approach this other than doing it semi-manually with an autohotkey macro or something. Seems like an extremely niche thing but maybe there's software for this? \n\nThanks.", "author_fullname": "t2_31e5hgk9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to rip wordpress-based recipe sites?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19ccg7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705867838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m unsure if this is the best sub to ask this but I was wondering if anyone has any insight on this topic. There&amp;#39;s a couple of recipe sites I like and I&amp;#39;d like to back them up for offline (non ad-supported) use.&lt;/p&gt;\n\n&lt;p&gt;Most of them use the same wordpress recipe platform and yoast SEO plugin. So I was wondering if it&amp;#39;s somehow possible to rip the entire site via the XML sitemap list. Preferably the &amp;#39;printable&amp;#39; versions.&lt;/p&gt;\n\n&lt;p&gt;Example sites:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://sweetsimplevegan.com/post-sitemap.xml\"&gt;https://sweetsimplevegan.com/post-sitemap.xml&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://thebananadiaries.com/post-sitemap.xml\"&gt;https://thebananadiaries.com/post-sitemap.xml&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.averiecooks.com/post-sitemap.xml\"&gt;https://www.averiecooks.com/post-sitemap.xml&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Not asking anyone to do it for me, i&amp;#39;m fairly tech savvy, just not positive how to approach this other than doing it semi-manually with an autohotkey macro or something. Seems like an extremely niche thing but maybe there&amp;#39;s software for this? &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19ccg7y", "is_robot_indexable": true, "report_reasons": null, "author": "LIBERT4D", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccg7y/any_way_to_rip_wordpressbased_recipe_sites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ccg7y/any_way_to_rip_wordpressbased_recipe_sites/", "subreddit_subscribers": 726981, "created_utc": 1705867838.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}