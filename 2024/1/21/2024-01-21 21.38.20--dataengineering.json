{"kind": "Listing", "data": {"after": "t3_19bvcjk", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My first job title in tech was Data Scientist, now I'm officially a Data Engineer, but working somewhere in Data Science/Engineering, MLOps and as a Python Dev.\n\nI'm not claiming to be a good programmer with two and a half years of professional experience, but I think some of our Data Scientists write bad Python code.  \n\n\nHere I explain why:\n\n* Using generic execptions instead of thinking about what error they really want to catch\n* They try to encapsulate all functions as static methods in classes, even though it's okay to use free standing functions sometimes\n* They don't use enums (or don't know what enums are used for)\n* Sometimes they use bad method names -&gt; they think `da_file2tbl_file()` is better than `convert_data_asset_to_mltalble()` (What do you think is better?)\n* Overengineering: Use of design patterns with 70 lines of code, although one simple free-standing function with 10 lines would have sufficed (-&gt; but I respect the fact that an effort is made here to learn and try out new things)\n* Use of global variables, although this could easily have been solved with an instance variable or a parameter extension in the method header\n* Too many useless and redundant comments like:  \n`# Creating dataframe`  \n`df = pd.DataFrame(...)`\n* Use of magic strings/numbers instead of constants\n* etc ...\n\nWhat are your experiences with Data Scientists or Data Engineers using Python?\n\nI don't despise anyone who makes such mistakes, but what's bad is that some Data Scientists are stubborn and say in code reviews: \"But I want to encapsulate all functions as static methods in a class or \"I think my 70-line design pattern is better than your 10-code-line function\" or \"I'd rather use global variables. I don't want to rewrite the code now.\" I find that very annoying. Some people have too big an ego. But code reviews aren't about being the smartest in the room, they're about learning from each other and making the product better.  \n\n\nLast year I started learning more programming languages. Kotlin and Rust.  I'm working on a personal project in Kotlin to rebuild our machine learning infrastructure and I'm still at tutorial level with Rust.  Both languages are amazing so far and both have already helped me to be a better (Python) programmer. What is your experience? Do you also think that learning more (statically typed) languages makes you a better developer? ", "author_fullname": "t2_1mzvtswi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some Data Scientists write bad Python code and are stubborn in code reviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c2ftl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 114, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 114, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705840279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My first job title in tech was Data Scientist, now I&amp;#39;m officially a Data Engineer, but working somewhere in Data Science/Engineering, MLOps and as a Python Dev.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not claiming to be a good programmer with two and a half years of professional experience, but I think some of our Data Scientists write bad Python code.  &lt;/p&gt;\n\n&lt;p&gt;Here I explain why:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Using generic execptions instead of thinking about what error they really want to catch&lt;/li&gt;\n&lt;li&gt;They try to encapsulate all functions as static methods in classes, even though it&amp;#39;s okay to use free standing functions sometimes&lt;/li&gt;\n&lt;li&gt;They don&amp;#39;t use enums (or don&amp;#39;t know what enums are used for)&lt;/li&gt;\n&lt;li&gt;Sometimes they use bad method names -&amp;gt; they think &lt;code&gt;da_file2tbl_file()&lt;/code&gt; is better than &lt;code&gt;convert_data_asset_to_mltalble()&lt;/code&gt; (What do you think is better?)&lt;/li&gt;\n&lt;li&gt;Overengineering: Use of design patterns with 70 lines of code, although one simple free-standing function with 10 lines would have sufficed (-&amp;gt; but I respect the fact that an effort is made here to learn and try out new things)&lt;/li&gt;\n&lt;li&gt;Use of global variables, although this could easily have been solved with an instance variable or a parameter extension in the method header&lt;/li&gt;\n&lt;li&gt;Too many useless and redundant comments like:&lt;br/&gt;\n&lt;code&gt;# Creating dataframe&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;df = pd.DataFrame(...)&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Use of magic strings/numbers instead of constants&lt;/li&gt;\n&lt;li&gt;etc ...&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What are your experiences with Data Scientists or Data Engineers using Python?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t despise anyone who makes such mistakes, but what&amp;#39;s bad is that some Data Scientists are stubborn and say in code reviews: &amp;quot;But I want to encapsulate all functions as static methods in a class or &amp;quot;I think my 70-line design pattern is better than your 10-code-line function&amp;quot; or &amp;quot;I&amp;#39;d rather use global variables. I don&amp;#39;t want to rewrite the code now.&amp;quot; I find that very annoying. Some people have too big an ego. But code reviews aren&amp;#39;t about being the smartest in the room, they&amp;#39;re about learning from each other and making the product better.  &lt;/p&gt;\n\n&lt;p&gt;Last year I started learning more programming languages. Kotlin and Rust.  I&amp;#39;m working on a personal project in Kotlin to rebuild our machine learning infrastructure and I&amp;#39;m still at tutorial level with Rust.  Both languages are amazing so far and both have already helped me to be a better (Python) programmer. What is your experience? Do you also think that learning more (statically typed) languages makes you a better developer? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19c2ftl", "is_robot_indexable": true, "report_reasons": null, "author": "noisescience", "discussion_type": null, "num_comments": 86, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c2ftl/some_data_scientists_write_bad_python_code_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c2ftl/some_data_scientists_write_bad_python_code_and/", "subreddit_subscribers": 154612, "created_utc": 1705840279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A number of data folks I respect has recently nudged me with an idea to create a data streaming 101 course since I have been managing an open source data streaming project and a managed cloud service for over a year now.\n\nI have thought about it a few times in 2023, and I'd like to ask the community, if you folks would like a data streaming 101 course.\n\nA bunch of good ones already exist. Here is how this one would be different.\n\nThe implementation and hands on labs of this data streaming course would be based on Rust and Web Assembly. It would be entirely self hosted. There would be a bit of complexity to grasp, but I would work to make it as simple as possible.\n\nI am thinking 7 emails with the course content delivered with text, video, and supporting code in a GitHub repo.\n\nThe only investment for the course would be time. And that too not a lot. Say 2 - 3 hours to consume the content and 2 - 3 hours to implement the labs.\n\nDoes this sound interesting? Let me know in the comments.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there interested in a Data streaming 101 course based on Rust and WebAssembly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bvq2q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705813808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A number of data folks I respect has recently nudged me with an idea to create a data streaming 101 course since I have been managing an open source data streaming project and a managed cloud service for over a year now.&lt;/p&gt;\n\n&lt;p&gt;I have thought about it a few times in 2023, and I&amp;#39;d like to ask the community, if you folks would like a data streaming 101 course.&lt;/p&gt;\n\n&lt;p&gt;A bunch of good ones already exist. Here is how this one would be different.&lt;/p&gt;\n\n&lt;p&gt;The implementation and hands on labs of this data streaming course would be based on Rust and Web Assembly. It would be entirely self hosted. There would be a bit of complexity to grasp, but I would work to make it as simple as possible.&lt;/p&gt;\n\n&lt;p&gt;I am thinking 7 emails with the course content delivered with text, video, and supporting code in a GitHub repo.&lt;/p&gt;\n\n&lt;p&gt;The only investment for the course would be time. And that too not a lot. Say 2 - 3 hours to consume the content and 2 - 3 hours to implement the labs.&lt;/p&gt;\n\n&lt;p&gt;Does this sound interesting? Let me know in the comments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Head of Product - Data Platform ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bvq2q", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/19bvq2q/is_there_interested_in_a_data_streaming_101/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bvq2q/is_there_interested_in_a_data_streaming_101/", "subreddit_subscribers": 154612, "created_utc": 1705813808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I hopped on board with this new company last month, and turns out they're on a bit of a staff exodus spree. Come next month, it's just gonna be me and two junior engineers left on the engineering team -  not just data engineering but the whole engineering team!! \ud83d\ude2c\n\nThinking of pulling the plug and bouncing to a new gig. As a data engineer, I'll be dealing with numerous data-related questions, but the challenge lies in not having someone to ask why the data is structured in a particular way.\n\nAny of you been in a situation like this? What did you do, and what should I be considering before making my exit?", "author_fullname": "t2_mbbdv7y98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of Bailing on My New Job - Need Some Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19brn6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705800529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I hopped on board with this new company last month, and turns out they&amp;#39;re on a bit of a staff exodus spree. Come next month, it&amp;#39;s just gonna be me and two junior engineers left on the engineering team -  not just data engineering but the whole engineering team!! \ud83d\ude2c&lt;/p&gt;\n\n&lt;p&gt;Thinking of pulling the plug and bouncing to a new gig. As a data engineer, I&amp;#39;ll be dealing with numerous data-related questions, but the challenge lies in not having someone to ask why the data is structured in a particular way.&lt;/p&gt;\n\n&lt;p&gt;Any of you been in a situation like this? What did you do, and what should I be considering before making my exit?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19brn6q", "is_robot_indexable": true, "report_reasons": null, "author": "Kindly-Screen-2557", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19brn6q/thinking_of_bailing_on_my_new_job_need_some_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19brn6q/thinking_of_bailing_on_my_new_job_need_some_advice/", "subreddit_subscribers": 154612, "created_utc": 1705800529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://i.redd.it/zhg215lraudc1.gif", "author_fullname": "t2_s0007gng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is it that you do for work again?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zhg215lraudc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/zhg215lraudc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=20ad58a925fd5ca997d235ee89d4cacf1e1e1a68"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/zhg215lraudc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=0d378f4179392dcb093ac9e979a6c1dadbf39ff1"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/zhg215lraudc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=6f3f1ac578604c17cb433e5945dcbdf773e2a7a3"}], "s": {"y": 480, "gif": "https://i.redd.it/zhg215lraudc1.gif", "mp4": "https://preview.redd.it/zhg215lraudc1.gif?format=mp4&amp;s=4c0f5d6482cff1b45e8e33f00a7d2e75f2bbacfd", "x": 480}, "id": "zhg215lraudc1"}}, "name": "t3_19cak0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pdm6xJ_cDi1CW2p-VbU7EBMIrk4wBZQgO3pUDi-Isu0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705863096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/zhg215lraudc1.gif\"&gt;https://i.redd.it/zhg215lraudc1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "19cak0s", "is_robot_indexable": true, "report_reasons": null, "author": "mesirmysir", "discussion_type": null, "num_comments": 9, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cak0s/what_is_it_that_you_do_for_work_again/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cak0s/what_is_it_that_you_do_for_work_again/", "subreddit_subscribers": 154612, "created_utc": 1705863096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a grad student with 2 YOE working with Snaplogic. I'm trying to get some job opportunity with coding, so i can grad with coding experience, I've always believed that it could open doors in future and make me more employable. \nBut now a recruiter reached me out to work in a Snaplogic project for a foreign financial institution that would pay me 3 times what i currently earn. \n\nIs going deeper into such a tool as Snaplogic going to limit my options in future? \n\nShould i keep focusing on getting a job that requires deeper tech skills?\n\nIs low code a dead end? Will i be stuck in low code forever if i keep working on it?", "author_fullname": "t2_2q0ga84g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is working with Low code ETL tools worth it career wise? (Snaplogic)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bznpt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705829144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a grad student with 2 YOE working with Snaplogic. I&amp;#39;m trying to get some job opportunity with coding, so i can grad with coding experience, I&amp;#39;ve always believed that it could open doors in future and make me more employable. \nBut now a recruiter reached me out to work in a Snaplogic project for a foreign financial institution that would pay me 3 times what i currently earn. &lt;/p&gt;\n\n&lt;p&gt;Is going deeper into such a tool as Snaplogic going to limit my options in future? &lt;/p&gt;\n\n&lt;p&gt;Should i keep focusing on getting a job that requires deeper tech skills?&lt;/p&gt;\n\n&lt;p&gt;Is low code a dead end? Will i be stuck in low code forever if i keep working on it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19bznpt", "is_robot_indexable": true, "report_reasons": null, "author": "meioaesmo", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bznpt/is_working_with_low_code_etl_tools_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bznpt/is_working_with_low_code_etl_tools_worth_it/", "subreddit_subscribers": 154612, "created_utc": 1705829144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have been interviewing for this company who were looking for data engineers or folks who are eager to learn data engineering skills. Now I always loved data related skills. I used to love studying about RDBMS, NoSQL and other basic areas back in college. But after college I got hired as a Java dev and that's where I stayed for 5 years.\n\nWhen I saw this job posting recently about the DE role, I could sense that this is something I would love to do. Reached out to HR and they also said that they will help me upskill in DE related technologies if I crack the interviews. Now the interviews were very thorough in coding, system design and deep in Java and Multi-threading but thankfully I cracked it and got the damn job! I still can't believe it lol. I am really excited but also quite nervous because I don't want to fuck this up. I am afraid because I am going in with 0 relevant experience and probably won't be able to make much positive contribution to org anytime soon.\n\nWhat would you guys suggest to someone who's just getting started in this area? What are some things to keep in mind and how should I approach upskilling myself?", "author_fullname": "t2_q979mh0vk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am moving from Java Backend role (5 YOE) to Data Engineering and I am super nervous about it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c4l5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705847410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have been interviewing for this company who were looking for data engineers or folks who are eager to learn data engineering skills. Now I always loved data related skills. I used to love studying about RDBMS, NoSQL and other basic areas back in college. But after college I got hired as a Java dev and that&amp;#39;s where I stayed for 5 years.&lt;/p&gt;\n\n&lt;p&gt;When I saw this job posting recently about the DE role, I could sense that this is something I would love to do. Reached out to HR and they also said that they will help me upskill in DE related technologies if I crack the interviews. Now the interviews were very thorough in coding, system design and deep in Java and Multi-threading but thankfully I cracked it and got the damn job! I still can&amp;#39;t believe it lol. I am really excited but also quite nervous because I don&amp;#39;t want to fuck this up. I am afraid because I am going in with 0 relevant experience and probably won&amp;#39;t be able to make much positive contribution to org anytime soon.&lt;/p&gt;\n\n&lt;p&gt;What would you guys suggest to someone who&amp;#39;s just getting started in this area? What are some things to keep in mind and how should I approach upskilling myself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19c4l5o", "is_robot_indexable": true, "report_reasons": null, "author": "ShaliniMalhotra9512", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c4l5o/i_am_moving_from_java_backend_role_5_yoe_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c4l5o/i_am_moving_from_java_backend_role_5_yoe_to_data/", "subreddit_subscribers": 154612, "created_utc": 1705847410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have the Databricks ML / DE Professional Certifications.\n\nI'm currently a DE wanting to move to a better (higher paying) DE position or an MLE position. How are the certifications regarded by the companies, especially at FAANG? If they are not that well regarded, what else should I be focusing on to transition to an MLE position?", "author_fullname": "t2_sd4utrozl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How valuable are Certifications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c3sst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705844965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have the Databricks ML / DE Professional Certifications.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a DE wanting to move to a better (higher paying) DE position or an MLE position. How are the certifications regarded by the companies, especially at FAANG? If they are not that well regarded, what else should I be focusing on to transition to an MLE position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19c3sst", "is_robot_indexable": true, "report_reasons": null, "author": "asozers", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c3sst/how_valuable_are_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c3sst/how_valuable_are_certifications/", "subreddit_subscribers": 154612, "created_utc": 1705844965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I need to collect data from people, I\u2019m presented with countless options:\n\nRetrieval:\n\n* Email me the data,\n* Put the data on a shared drive,\n* Drop the data in an S3 bucket,\n* Create a forum,\n* Give people database access,\n* \u2026\n\nThen comes validation:\n\n* Check the data manually,\n* Automate checking of common issues on the backend,\n* Reject incorrect data immediately from the frontend,\n* \u2026\n\nThen how to handle the results of validation:\n\n* Clean it manually,\n* Attempt to automate cleaning of common issues and attempt to re-validate,\n* Have the user fix the data,\n* \u2026\n\nThen after these you should have your data as expected, ready to be integrated into your platform and used for whatever. Until this point, however, there\u2019s a lot of grey area for me.\n\nRuling the decision is considerations like:\n\n* Corporate culture,\n* Engineers Technical Knowledge,\n* End Users Technical Knowledge,\n* Existing Infrastructure Available,\n* What\u2019s quickest?\n* What\u2019s easiest?\n* What\u2019s securest?\n* What\u2019s most robust to changing requirements?\n* \u2026\n\nand not particularly in that order.\n\nLet\u2019s say you\u2019re developing a new platform for a company filled with nontechnical users. They store things in spreadsheets and have for years, manually maintaining integrity like a bunch of humanoid relational database monsters. Now the company is growing on an order of magnitude, they want a culture shift to manage the growth. They want to have a platform that they can rely on just as they\u2019d relied on their HRDBMs for so long.\n\nSo you have studied their workflow, learned how and why things operate the way they do. You\u2019ve built systems to help lift a lot of the load, but now you find that you\u2019re still manually patching data into the system yourself. \n\nIt\u2019s time to develop a data integration standard. What do you do? How do you standardize this part of the pipeline?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Retrieval From Nontechnical Users - How To Standardize?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bnb55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705788470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I need to collect data from people, I\u2019m presented with countless options:&lt;/p&gt;\n\n&lt;p&gt;Retrieval:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Email me the data,&lt;/li&gt;\n&lt;li&gt;Put the data on a shared drive,&lt;/li&gt;\n&lt;li&gt;Drop the data in an S3 bucket,&lt;/li&gt;\n&lt;li&gt;Create a forum,&lt;/li&gt;\n&lt;li&gt;Give people database access,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then comes validation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Check the data manually,&lt;/li&gt;\n&lt;li&gt;Automate checking of common issues on the backend,&lt;/li&gt;\n&lt;li&gt;Reject incorrect data immediately from the frontend,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then how to handle the results of validation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Clean it manually,&lt;/li&gt;\n&lt;li&gt;Attempt to automate cleaning of common issues and attempt to re-validate,&lt;/li&gt;\n&lt;li&gt;Have the user fix the data,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then after these you should have your data as expected, ready to be integrated into your platform and used for whatever. Until this point, however, there\u2019s a lot of grey area for me.&lt;/p&gt;\n\n&lt;p&gt;Ruling the decision is considerations like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Corporate culture,&lt;/li&gt;\n&lt;li&gt;Engineers Technical Knowledge,&lt;/li&gt;\n&lt;li&gt;End Users Technical Knowledge,&lt;/li&gt;\n&lt;li&gt;Existing Infrastructure Available,&lt;/li&gt;\n&lt;li&gt;What\u2019s quickest?&lt;/li&gt;\n&lt;li&gt;What\u2019s easiest?&lt;/li&gt;\n&lt;li&gt;What\u2019s securest?&lt;/li&gt;\n&lt;li&gt;What\u2019s most robust to changing requirements?&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;and not particularly in that order.&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say you\u2019re developing a new platform for a company filled with nontechnical users. They store things in spreadsheets and have for years, manually maintaining integrity like a bunch of humanoid relational database monsters. Now the company is growing on an order of magnitude, they want a culture shift to manage the growth. They want to have a platform that they can rely on just as they\u2019d relied on their HRDBMs for so long.&lt;/p&gt;\n\n&lt;p&gt;So you have studied their workflow, learned how and why things operate the way they do. You\u2019ve built systems to help lift a lot of the load, but now you find that you\u2019re still manually patching data into the system yourself. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s time to develop a data integration standard. What do you do? How do you standardize this part of the pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bnb55", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bnb55/data_retrieval_from_nontechnical_users_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bnb55/data_retrieval_from_nontechnical_users_how_to/", "subreddit_subscribers": 154612, "created_utc": 1705788470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm reaching out for some valuable insights and advice as I embark on a journey to transition from my current Big Data role to a Data Engineering position in the Cloud. I've been a Big Data developer, primarily working with Apache Spark, Hive, and Kafka, handling data ingestion, processing, and storage, all in an on-premises HDP cluster.\n\nWhile I've had my fair share of bug fixes and minor enhancements, I'm ready to take the plunge into the exciting world of Cloud Data Engineering. I've already obtained my GCP Data Engineering certification and have an upcoming Azure Data Engineering certification scheduled. However, getting interviews for Data Engineering positions has been quite a challenge, and even when I do get the chance, I'm unsure if my current experience is sufficient.\n\nI'm reaching out to this community to learn more about your day-to-day experiences as Data Engineers in the Cloud. I'm particularly interested in knowing:\n\n1. **Project Details**: What kind of projects are you currently working on? Whether it's building data pipelines, setting up data lakes, or any other exciting data-related tasks, I'd love to hear about them.\n2. **Tooling and Technologies**: What tools and technologies are you using in your projects? Whether it's cloud platforms, ETL frameworks, data warehouses, or any other technical stack, please share your insights.\n\nBy sharing your experiences, you'll not only help me but also others  like me who are eager to make the leap into Cloud Data Engineering. My  goal is to gather this information to better understand the field and  potentially align my current experience with these insights to enhance  my resume and prepare for interviews.", "author_fullname": "t2_7lxzxgj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers in the Cloud - Tell Me About Your Daily Work and Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c4kmx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705847371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m reaching out for some valuable insights and advice as I embark on a journey to transition from my current Big Data role to a Data Engineering position in the Cloud. I&amp;#39;ve been a Big Data developer, primarily working with Apache Spark, Hive, and Kafka, handling data ingestion, processing, and storage, all in an on-premises HDP cluster.&lt;/p&gt;\n\n&lt;p&gt;While I&amp;#39;ve had my fair share of bug fixes and minor enhancements, I&amp;#39;m ready to take the plunge into the exciting world of Cloud Data Engineering. I&amp;#39;ve already obtained my GCP Data Engineering certification and have an upcoming Azure Data Engineering certification scheduled. However, getting interviews for Data Engineering positions has been quite a challenge, and even when I do get the chance, I&amp;#39;m unsure if my current experience is sufficient.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out to this community to learn more about your day-to-day experiences as Data Engineers in the Cloud. I&amp;#39;m particularly interested in knowing:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Project Details&lt;/strong&gt;: What kind of projects are you currently working on? Whether it&amp;#39;s building data pipelines, setting up data lakes, or any other exciting data-related tasks, I&amp;#39;d love to hear about them.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Tooling and Technologies&lt;/strong&gt;: What tools and technologies are you using in your projects? Whether it&amp;#39;s cloud platforms, ETL frameworks, data warehouses, or any other technical stack, please share your insights.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;By sharing your experiences, you&amp;#39;ll not only help me but also others  like me who are eager to make the leap into Cloud Data Engineering. My  goal is to gather this information to better understand the field and  potentially align my current experience with these insights to enhance  my resume and prepare for interviews.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19c4kmx", "is_robot_indexable": true, "report_reasons": null, "author": "Consistent_Ad5511", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c4kmx/data_engineers_in_the_cloud_tell_me_about_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c4kmx/data_engineers_in_the_cloud_tell_me_about_your/", "subreddit_subscribers": 154612, "created_utc": 1705847371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Diagram as Code](https://i.redd.it/lnjhr11ctsdc1.gif)\n\n&gt;Creating architectural diagrams with traditional graphical tools can be a hassle. Drag-and-drop interfaces are frustrating, achieving perfect alignment is a challenge, and versioning becomes a nightmare. Diagram as Code offers a solution, allowing diagrams to be written with coding precision, versioned like code, and generated effortlessly. This approach simplifies diagramming tasks and brings order to the chaos.\n\nHow to create Diagram using code: [Youtube Video](https://www.youtube.com/watch?v=jCy3jUgN3GQ&amp;t=4s)", "author_fullname": "t2_jjbftfcy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build cloud Architecture Diagrams in 1 Minute (This Tool is Crazy Fast!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lnjhr11ctsdc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/lnjhr11ctsdc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=099c32b2c9f2735a41aa419366243ff8ac20a2d4"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/lnjhr11ctsdc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=720a4fd3f7eb40f69c10141f980eaa95f6020056"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/lnjhr11ctsdc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=cba64b743218baab3e50696273edff14d288d752"}, {"y": 640, "x": 640, "u": "https://preview.redd.it/lnjhr11ctsdc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=45bdfb030e158db7b9416de705b67b1bd5ae918e"}], "s": {"y": 900, "gif": "https://i.redd.it/lnjhr11ctsdc1.gif", "mp4": "https://preview.redd.it/lnjhr11ctsdc1.gif?format=mp4&amp;s=703705fb9a3c95c03bd82e0665f1d8e0e47e11a8", "x": 900}, "id": "lnjhr11ctsdc1"}}, "name": "t3_19c3vs0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jCy3jUgN3GQ?start=4&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jCy3jUgN3GQ?start=4&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )\"&gt;&lt;/iframe&gt;", "author_name": "Bitwise learning", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jCy3jUgN3GQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@naveenkumarmurugan1962"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jCy3jUgN3GQ?start=4&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/19c3vs0", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_dwsOCuWDwZNQLjtvvtSvHRz6Gn9JwNfGWb5bbHEB4I.jpg", "edited": 1705845745.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1705845217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/lnjhr11ctsdc1.gif\"&gt;Diagram as Code&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Creating architectural diagrams with traditional graphical tools can be a hassle. Drag-and-drop interfaces are frustrating, achieving perfect alignment is a challenge, and versioning becomes a nightmare. Diagram as Code offers a solution, allowing diagrams to be written with coding precision, versioned like code, and generated effortlessly. This approach simplifies diagramming tasks and brings order to the chaos.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;How to create Diagram using code: &lt;a href=\"https://www.youtube.com/watch?v=jCy3jUgN3GQ&amp;amp;t=4s\"&gt;Youtube Video&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/k2M6UKltaKJ6wL7S__B7keppLO8YDSmwxoscO31p8Y8.jpg?auto=webp&amp;s=e33dc4771e13b4095c3735cd07b83bab85c39662", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/k2M6UKltaKJ6wL7S__B7keppLO8YDSmwxoscO31p8Y8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b41c85a18c622c350b303a5e60ae47983d346a64", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/k2M6UKltaKJ6wL7S__B7keppLO8YDSmwxoscO31p8Y8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7798c962fe38ffcc68ccc3f5c2a950439c5a4119", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/k2M6UKltaKJ6wL7S__B7keppLO8YDSmwxoscO31p8Y8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=22f5339ac5c27b80c3cd6bcc4899fd30bf7c8e5b", "width": 320, "height": 240}], "variants": {}, "id": "1-UvaHhiYPAXq_n4Xu3SwJuFT_taoKGhBzHesfyNP9c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "19c3vs0", "is_robot_indexable": true, "report_reasons": null, "author": "BigNo3623", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c3vs0/build_cloud_architecture_diagrams_in_1_minute/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c3vs0/build_cloud_architecture_diagrams_in_1_minute/", "subreddit_subscribers": 154612, "created_utc": 1705845217.0, "num_crossposts": 2, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jCy3jUgN3GQ?start=4&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )\"&gt;&lt;/iframe&gt;", "author_name": "Bitwise learning", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jCy3jUgN3GQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@naveenkumarmurugan1962"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I need some career advice, please: \n\nI'm currently employed as a Data Analyst for an IT consulting company. However, my recent project involves tasks unrelated to data analytics, focusing more on process mapping and ERP adjustments. Despite expressing my concerns to my manager, they've mentioned that reassignment to a different project is unlikely until 2025.\n\nI've received an offer from a small AIaaS company to work as a Data Analyst within the Data Engineering team, and the role seems very exciting. My ultimate goal is to transition into a Data Engineering role by the end of the year.\n\nThe dilemma is that my current job offers a great salary, extra vacation days, and access to diverse future projects. On the other hand, the startup offer involves a roughly 30% salary cut and no additional vacation days. While I can manage the pay cut since I live with my parents, it's a significant downgrade.\n\nSo, what would you advise? Should I stick with my current job, even though I'm not enjoying it at all, but enjoying the perks while independently learning Data Engineering? Or should I accept the startup offer, taking a pay cut but gaining experience under the Data Engineering team?\n\nThanks in advance for your perspectives. I truly appreciate it.", "author_fullname": "t2_4iz2pipg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice: More interesting job for less money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bqqbe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705797834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I need some career advice, please: &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently employed as a Data Analyst for an IT consulting company. However, my recent project involves tasks unrelated to data analytics, focusing more on process mapping and ERP adjustments. Despite expressing my concerns to my manager, they&amp;#39;ve mentioned that reassignment to a different project is unlikely until 2025.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve received an offer from a small AIaaS company to work as a Data Analyst within the Data Engineering team, and the role seems very exciting. My ultimate goal is to transition into a Data Engineering role by the end of the year.&lt;/p&gt;\n\n&lt;p&gt;The dilemma is that my current job offers a great salary, extra vacation days, and access to diverse future projects. On the other hand, the startup offer involves a roughly 30% salary cut and no additional vacation days. While I can manage the pay cut since I live with my parents, it&amp;#39;s a significant downgrade.&lt;/p&gt;\n\n&lt;p&gt;So, what would you advise? Should I stick with my current job, even though I&amp;#39;m not enjoying it at all, but enjoying the perks while independently learning Data Engineering? Or should I accept the startup offer, taking a pay cut but gaining experience under the Data Engineering team?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your perspectives. I truly appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19bqqbe", "is_robot_indexable": true, "report_reasons": null, "author": "_Lavender_Brown_", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bqqbe/career_advice_more_interesting_job_for_less_money/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bqqbe/career_advice_more_interesting_job_for_less_money/", "subreddit_subscribers": 154612, "created_utc": 1705797834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm currently working on developing email notifications for impending software license expirations within our organization. I'm adopting an event-based automation approach. The architecture I've proposed would use existing instances of Prefect and Postgres, while introducing Redis and Celery as an intermediary to allow Postgres to communicate with Prefect.\n\nThe automations are handled via a Postgres `jobs` table. INSERT instigates a NOTIFY which Redis accepts as a PUBLISHER. This propagates to Celery passing along information to the Prefect API.\n\nThe job will include details about the deployment to run and the parameters to pass into the deployment. So Redis and Celery are not stuck to any single automation. Furthermore, Celery would query the Prefect API for updates on the Flow Runs status and update the `jobs` table respectively.\n\nThe linked architecture (https://imgur.com/a/H5kC6wE) is designed to prevent the creation of isolated solutions for every issue as the code base evolves and matures, avoiding a complex and convoluted long run. I\u2019m hoping this approach to email notifications is not too complicated while offering a much higher benefit. I'd appreciate feedback on this approach.\n\nOur capabilities are limited digitally and it\u2019s in the organizations interest right now to improve our \u201cdata platform,\u201d so to speak. So I don\u2019t see this as an unnecessary effort necessary, if it\u2019s generally applicable to unknown future needs. What\u2019s your impression on the design?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on an Event Based Automation System?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19carxy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705867858.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705863654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on developing email notifications for impending software license expirations within our organization. I&amp;#39;m adopting an event-based automation approach. The architecture I&amp;#39;ve proposed would use existing instances of Prefect and Postgres, while introducing Redis and Celery as an intermediary to allow Postgres to communicate with Prefect.&lt;/p&gt;\n\n&lt;p&gt;The automations are handled via a Postgres &lt;code&gt;jobs&lt;/code&gt; table. INSERT instigates a NOTIFY which Redis accepts as a PUBLISHER. This propagates to Celery passing along information to the Prefect API.&lt;/p&gt;\n\n&lt;p&gt;The job will include details about the deployment to run and the parameters to pass into the deployment. So Redis and Celery are not stuck to any single automation. Furthermore, Celery would query the Prefect API for updates on the Flow Runs status and update the &lt;code&gt;jobs&lt;/code&gt; table respectively.&lt;/p&gt;\n\n&lt;p&gt;The linked architecture (&lt;a href=\"https://imgur.com/a/H5kC6wE\"&gt;https://imgur.com/a/H5kC6wE&lt;/a&gt;) is designed to prevent the creation of isolated solutions for every issue as the code base evolves and matures, avoiding a complex and convoluted long run. I\u2019m hoping this approach to email notifications is not too complicated while offering a much higher benefit. I&amp;#39;d appreciate feedback on this approach.&lt;/p&gt;\n\n&lt;p&gt;Our capabilities are limited digitally and it\u2019s in the organizations interest right now to improve our \u201cdata platform,\u201d so to speak. So I don\u2019t see this as an unnecessary effort necessary, if it\u2019s generally applicable to unknown future needs. What\u2019s your impression on the design?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/O4gY8JOgrpDR42iPyXU2xa1gS6WzDRIGSrsroZW4-a8.jpg?auto=webp&amp;s=1693ddaf0d29a191f2964d80a12f1686f82c1aa1", "width": 1221, "height": 681}, "resolutions": [{"url": "https://external-preview.redd.it/O4gY8JOgrpDR42iPyXU2xa1gS6WzDRIGSrsroZW4-a8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95f04f6b08e141e5b72be80f055b62eff20b2de0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/O4gY8JOgrpDR42iPyXU2xa1gS6WzDRIGSrsroZW4-a8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=abfa24e63e1a25608e9f9e30cc526b323d3f9bce", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/O4gY8JOgrpDR42iPyXU2xa1gS6WzDRIGSrsroZW4-a8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=827e50d7bcf718ae17ba453a93964323ec7fdc0b", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/O4gY8JOgrpDR42iPyXU2xa1gS6WzDRIGSrsroZW4-a8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9aa73aa6034342c4b02aa4c1f84ca4f8880d2816", "width": 640, "height": 356}, {"url": "https://external-preview.redd.it/O4gY8JOgrpDR42iPyXU2xa1gS6WzDRIGSrsroZW4-a8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2485f9aec1a18adc112f4dde3191fa5e68e0342f", "width": 960, "height": 535}, {"url": "https://external-preview.redd.it/O4gY8JOgrpDR42iPyXU2xa1gS6WzDRIGSrsroZW4-a8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c5c0bf60480cbf40ba04d8da24de3d9fe109c0c0", "width": 1080, "height": 602}], "variants": {}, "id": "durbPODIwpxXIy41rZC6jMeOBWSP55iMETY6RTKQYlY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19carxy", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19carxy/feedback_on_an_event_based_automation_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19carxy/feedback_on_an_event_based_automation_system/", "subreddit_subscribers": 154612, "created_utc": 1705863654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a company with eight employees, and was recently hired as a data/business analyst. The company uses an in-house software to manage online retail sales. There is a huge amount of data available, and I need to design a workflow to capture sales data and business analytics. Currently, most of the company\u2019s data is stored in a combination of a MySQL database and DynamoDB.\n\nI would like to design a workflow that queries one or both of these databases to record daily statistics (i.e. sales of groups of products over time), cleans the data, and records it in a new \u201canalytics\u201d database. This new data would then be easier to handle for visualization, modeling, etc.\n\nCurrently I\u2019m taking a course in AWS Lambda, because it seems like that\u2019s the best way to go to automate my scripts. I\u2019m looking into relational database and NoSQL models, and am leaning towards the latter but I\u2019m unsure.\n\nDoes anyone have advice on this workflow, ideas on where to start, or resources to consult? This is my first job in the field, so I really appreciate any advice!\n\nTl;dr - I am designing a workflow to query a MySQL database &gt; clean data &gt; record statistics in a new \u201canalytics\u201d database &gt; use cleaned data for visualization", "author_fullname": "t2_8dzpaik5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Designing a data workflow for a small company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19caao0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705866032.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705862446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a company with eight employees, and was recently hired as a data/business analyst. The company uses an in-house software to manage online retail sales. There is a huge amount of data available, and I need to design a workflow to capture sales data and business analytics. Currently, most of the company\u2019s data is stored in a combination of a MySQL database and DynamoDB.&lt;/p&gt;\n\n&lt;p&gt;I would like to design a workflow that queries one or both of these databases to record daily statistics (i.e. sales of groups of products over time), cleans the data, and records it in a new \u201canalytics\u201d database. This new data would then be easier to handle for visualization, modeling, etc.&lt;/p&gt;\n\n&lt;p&gt;Currently I\u2019m taking a course in AWS Lambda, because it seems like that\u2019s the best way to go to automate my scripts. I\u2019m looking into relational database and NoSQL models, and am leaning towards the latter but I\u2019m unsure.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have advice on this workflow, ideas on where to start, or resources to consult? This is my first job in the field, so I really appreciate any advice!&lt;/p&gt;\n\n&lt;p&gt;Tl;dr - I am designing a workflow to query a MySQL database &amp;gt; clean data &amp;gt; record statistics in a new \u201canalytics\u201d database &amp;gt; use cleaned data for visualization&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19caao0", "is_robot_indexable": true, "report_reasons": null, "author": "Strong-Mission-118", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19caao0/designing_a_data_workflow_for_a_small_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19caao0/designing_a_data_workflow_for_a_small_company/", "subreddit_subscribers": 154612, "created_utc": 1705862446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Jailer is a tool for database subsetting and relational data browsing](https://github.com/Wisser/Jailer).\n\nIt  creates small slices from your database and lets you navigate through  your database following the relationships.Ideal for creating small  samples of test data or for local problem analysis with relevant  production data.\n\n* The  Subsetter creates small slices from your database (consistent and  referentially intact) as SQL (topologically sorted), DbUnit records or  XML.Ideal for creating small samples of test data or for local problem  analysis with relevant production data.\n* The  Data Browser lets you navigate through your database  following the  relationships (foreign key-based or user-defined) between  tables.\n\nFeatures\n\n* Exports  consistent and referentially intact row-sets from your productive  database and imports the data into your development and test  environment.\n* Improves database performance by removing and archiving obsolete data without violating integrity.\n* Generates topologically sorted SQL-DML, hierarchically structured XML and DbUnit datasets.\n* Data Browsing. Navigate bidirectionally through the database by following foreign-key-based or user-defined relationships.\n* SQL Console with code completion, syntax highlighting and database metadata visualization.\n* A demo database is included with which you can get a first impression without any configuration effort.", "author_fullname": "t2_9om3w9rn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Subsetting and Relational Data Browsing Tool.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bz1je", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705826580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/Wisser/Jailer\"&gt;Jailer is a tool for database subsetting and relational data browsing&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It  creates small slices from your database and lets you navigate through  your database following the relationships.Ideal for creating small  samples of test data or for local problem analysis with relevant  production data.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The  Subsetter creates small slices from your database (consistent and  referentially intact) as SQL (topologically sorted), DbUnit records or  XML.Ideal for creating small samples of test data or for local problem  analysis with relevant production data.&lt;/li&gt;\n&lt;li&gt;The  Data Browser lets you navigate through your database  following the  relationships (foreign key-based or user-defined) between  tables.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Features&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Exports  consistent and referentially intact row-sets from your productive  database and imports the data into your development and test  environment.&lt;/li&gt;\n&lt;li&gt;Improves database performance by removing and archiving obsolete data without violating integrity.&lt;/li&gt;\n&lt;li&gt;Generates topologically sorted SQL-DML, hierarchically structured XML and DbUnit datasets.&lt;/li&gt;\n&lt;li&gt;Data Browsing. Navigate bidirectionally through the database by following foreign-key-based or user-defined relationships.&lt;/li&gt;\n&lt;li&gt;SQL Console with code completion, syntax highlighting and database metadata visualization.&lt;/li&gt;\n&lt;li&gt;A demo database is included with which you can get a first impression without any configuration effort.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?auto=webp&amp;s=7d91f911921103d21536574e4c7377773af0a670", "width": 1071, "height": 877}, "resolutions": [{"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e51c380ca288d5df077a3a384d83f1283af1dfad", "width": 108, "height": 88}, {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=edfda93cb422d3efad77e36b313c8486384fed39", "width": 216, "height": 176}, {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=768bea441c2ed39a7ea1ca358fc0acc1070e7011", "width": 320, "height": 262}, {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5305979fe027b9e970b26afc10bee2b020853c4f", "width": 640, "height": 524}, {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c8ea989da1ef3be0e3fc570a45fe1e946088ba8", "width": 960, "height": 786}], "variants": {}, "id": "RG-fODuBFpjyJxP9IX0wg2hg36dqvEa-gISyg1_JD2k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "19bz1je", "is_robot_indexable": true, "report_reasons": null, "author": "Apprehensive-Fix-996", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bz1je/database_subsetting_and_relational_data_browsing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bz1je/database_subsetting_and_relational_data_browsing/", "subreddit_subscribers": 154612, "created_utc": 1705826580.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nBased on the current data engineering landscape, I believe most of the data engineering tools that is used by us are outside of the SAP realm. However, I would like to test and understand if this is true. \n\nAre there any data engineers lurking here familiar with tools like SAP Data Services, SAP HANA, SAP BW/4HANA, SAP Data Sphere and SAP Analytics Cloud. Some can argue that these are not standard data engineering tools but it still very capable tools to process and serve the data for their intended purpose. \n\nAlso, is it desirable to get into the SAP ecosystem and work on SAP specific data projects?", "author_fullname": "t2_5b8k9nl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone here working on data engineering roles using SAP tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19byhep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705824283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;Based on the current data engineering landscape, I believe most of the data engineering tools that is used by us are outside of the SAP realm. However, I would like to test and understand if this is true. &lt;/p&gt;\n\n&lt;p&gt;Are there any data engineers lurking here familiar with tools like SAP Data Services, SAP HANA, SAP BW/4HANA, SAP Data Sphere and SAP Analytics Cloud. Some can argue that these are not standard data engineering tools but it still very capable tools to process and serve the data for their intended purpose. &lt;/p&gt;\n\n&lt;p&gt;Also, is it desirable to get into the SAP ecosystem and work on SAP specific data projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19byhep", "is_robot_indexable": true, "report_reasons": null, "author": "scht1980", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19byhep/anyone_here_working_on_data_engineering_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19byhep/anyone_here_working_on_data_engineering_roles/", "subreddit_subscribers": 154612, "created_utc": 1705824283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically the title, if it can be done with Postgres\u2026 is something like rabbitmq worthwhile?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any real benefit to a queue service over a makeshift queue with Postgres for small scale stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19btc8i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705805719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title, if it can be done with Postgres\u2026 is something like rabbitmq worthwhile?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19btc8i", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19btc8i/any_real_benefit_to_a_queue_service_over_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19btc8i/any_real_benefit_to_a_queue_service_over_a/", "subreddit_subscribers": 154612, "created_utc": 1705805719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company wants to organize our data in Databricks and I have been looking at some documentation on best practices for directory structures. \n\nOne of the documentations suggested: \u201cCatalogs often mirror organizational units or software development lifecycle scopes. You may choose, for example, to have a catalog for production data and a catalog for development data\u201d \n\nI\u2019ve read in many articles that there should be a catalog for dev, prod, stage, etc\u2026 and one schema for each of the Bronze, Silver, and Gold medallion structures.\n\nHere\u2019s what my company has in place at the moment:\n\n* We have different workspaces for test, dev, and prod (for example, dev\\_us\\_west, prod\\_us\\_west, test\\_us\\_east, test\\_uk,...) \n* In our current setup, catalogs within each workspace represent individual projects. For example, demand\\_forecast, sales\\_prediction,... \n* The schemas group related tables. For example, inside the demand\\_forecast catalog, there are the following schemas: \u2018customers\u2019, and \u2018products\u2019. The \u2018customers\u2019 schema contains tables like churn (raw, untransformed) and customer\\_preference (transformed). And the \u2018products\u2019 schema contains tables like prices (raw), reviews (raw)\n* The way it works right now is if someone has a project that only needs some analysis and doesn't involve pushing codes into production, they will go into the test workspace. There, they can create a catalog for that project, and create the necessary schemas and tables. If someone needs to create a model that will be used in production, they will use the prod workspace and create a catalog for their project there. \n* I\u2019ve read that \u201c*Databricks no longer recommends mounting external data locations to Databricks Filesystem\u201d.* Right now, the way that we load files into Databricks is by using DBFS S3 bucket mount points. In the future, we would want to switch to using volumes to store unstructured data. Right now, each sub-directory in our S3 bucket contains files related to a project. \n\nI\u2019m not from a Data Engineering background and am not very experienced with Unity Catalog. Could you recommend best practices for isolating and organizing data using workspaces, catalogs, schemas, and volumes? \n\nThank you in advance!", "author_fullname": "t2_8rwu4pz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing data and setting up directory structures for Databricks Unity Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bnqyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705789663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company wants to organize our data in Databricks and I have been looking at some documentation on best practices for directory structures. &lt;/p&gt;\n\n&lt;p&gt;One of the documentations suggested: \u201cCatalogs often mirror organizational units or software development lifecycle scopes. You may choose, for example, to have a catalog for production data and a catalog for development data\u201d &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve read in many articles that there should be a catalog for dev, prod, stage, etc\u2026 and one schema for each of the Bronze, Silver, and Gold medallion structures.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s what my company has in place at the moment:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We have different workspaces for test, dev, and prod (for example, dev_us_west, prod_us_west, test_us_east, test_uk,...) &lt;/li&gt;\n&lt;li&gt;In our current setup, catalogs within each workspace represent individual projects. For example, demand_forecast, sales_prediction,... &lt;/li&gt;\n&lt;li&gt;The schemas group related tables. For example, inside the demand_forecast catalog, there are the following schemas: \u2018customers\u2019, and \u2018products\u2019. The \u2018customers\u2019 schema contains tables like churn (raw, untransformed) and customer_preference (transformed). And the \u2018products\u2019 schema contains tables like prices (raw), reviews (raw)&lt;/li&gt;\n&lt;li&gt;The way it works right now is if someone has a project that only needs some analysis and doesn&amp;#39;t involve pushing codes into production, they will go into the test workspace. There, they can create a catalog for that project, and create the necessary schemas and tables. If someone needs to create a model that will be used in production, they will use the prod workspace and create a catalog for their project there. &lt;/li&gt;\n&lt;li&gt;I\u2019ve read that \u201c&lt;em&gt;Databricks no longer recommends mounting external data locations to Databricks Filesystem\u201d.&lt;/em&gt; Right now, the way that we load files into Databricks is by using DBFS S3 bucket mount points. In the future, we would want to switch to using volumes to store unstructured data. Right now, each sub-directory in our S3 bucket contains files related to a project. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m not from a Data Engineering background and am not very experienced with Unity Catalog. Could you recommend best practices for isolating and organizing data using workspaces, catalogs, schemas, and volumes? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19bnqyq", "is_robot_indexable": true, "report_reasons": null, "author": "lunalita_99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bnqyq/organizing_data_and_setting_up_directory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bnqyq/organizing_data_and_setting_up_directory/", "subreddit_subscribers": 154612, "created_utc": 1705789663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. As is typical (for me at least), I\u2019m looking to garner some insights on approches for a common kind of application before I built one.\n\nI\u2019m going to build an email notification system. Its first set of requirements will be to send out notices a few weeks before some documents expire, unless those documents have been renewed already.\n\nThe source data lives in an excel spreadsheet stored in a shared SharePoint drive. It gets updated at regular intervals by some kind of ghost entity that magically knows when/how to update the data.\n\nMy first thoughts are that I\u2019m going to need to store the document names and their expiration date, as well as a recipient list somewhere that can be polled daily. If the poll finds any records matching the conditions I\u2019ve described, send an email to the documents recipient list. \n\nHowever, I started to wonder if there might be a better approach. For example, maybe the polling service can simply update a `status` column based on how close a document is to expiration. If `status` gets set to `soon to expire`, then a [postgres] `NOTIFY` can get sent to a `LISTEN`ing channel. On the `LISTEN`ing channel, there can be an application that handles these \u201cevent based\u201d emails. This decouples the polling service from the email service, and theoretically the email service can get used for any email.\n\nAfter this, I started to wonder Postgres actually has some built in method to automatically `NOTIFY` if a records `date` column approaches less than X days from current time. I\u2019m doubtful about this, as it just sounds like a built in polling service, or maybe a nasty looking trigger function, but who knows.\n\nFor reference I use Postgres for storage, Prefect for orchestration, Python for the nooks and crannies, \u2026 I want a solution that\u2019s generally applicable though and can get reused for future projects. \n\nWhat\u2019s the typical \u201cgenerally applicable\u201d approach for email notifications? Thanks!", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Common Architectures for Event &amp; Schedule Based Email Notifications System?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bm0w0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705786231.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705785073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. As is typical (for me at least), I\u2019m looking to garner some insights on approches for a common kind of application before I built one.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m going to build an email notification system. Its first set of requirements will be to send out notices a few weeks before some documents expire, unless those documents have been renewed already.&lt;/p&gt;\n\n&lt;p&gt;The source data lives in an excel spreadsheet stored in a shared SharePoint drive. It gets updated at regular intervals by some kind of ghost entity that magically knows when/how to update the data.&lt;/p&gt;\n\n&lt;p&gt;My first thoughts are that I\u2019m going to need to store the document names and their expiration date, as well as a recipient list somewhere that can be polled daily. If the poll finds any records matching the conditions I\u2019ve described, send an email to the documents recipient list. &lt;/p&gt;\n\n&lt;p&gt;However, I started to wonder if there might be a better approach. For example, maybe the polling service can simply update a &lt;code&gt;status&lt;/code&gt; column based on how close a document is to expiration. If &lt;code&gt;status&lt;/code&gt; gets set to &lt;code&gt;soon to expire&lt;/code&gt;, then a [postgres] &lt;code&gt;NOTIFY&lt;/code&gt; can get sent to a &lt;code&gt;LISTEN&lt;/code&gt;ing channel. On the &lt;code&gt;LISTEN&lt;/code&gt;ing channel, there can be an application that handles these \u201cevent based\u201d emails. This decouples the polling service from the email service, and theoretically the email service can get used for any email.&lt;/p&gt;\n\n&lt;p&gt;After this, I started to wonder Postgres actually has some built in method to automatically &lt;code&gt;NOTIFY&lt;/code&gt; if a records &lt;code&gt;date&lt;/code&gt; column approaches less than X days from current time. I\u2019m doubtful about this, as it just sounds like a built in polling service, or maybe a nasty looking trigger function, but who knows.&lt;/p&gt;\n\n&lt;p&gt;For reference I use Postgres for storage, Prefect for orchestration, Python for the nooks and crannies, \u2026 I want a solution that\u2019s generally applicable though and can get reused for future projects. &lt;/p&gt;\n\n&lt;p&gt;What\u2019s the typical \u201cgenerally applicable\u201d approach for email notifications? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bm0w0", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bm0w0/common_architectures_for_event_schedule_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bm0w0/common_architectures_for_event_schedule_based/", "subreddit_subscribers": 154612, "created_utc": 1705785073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been using Synapse for a couple of years, and as of 1/13, our private endpoints in Azure stopped working. I'm working on setting it up with a new client, and we can't get private endpoints deployed there, either.  I've heard from some Microsoft engineers that Synapse can no longer run on a private endpoint.  This is against the security policy where I am.  Has anyone else experienced this? ", "author_fullname": "t2_5yj82gi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anybody using Azure Synapse, and if so, are you having any issues with private endpoints?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19cdg40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705870338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using Synapse for a couple of years, and as of 1/13, our private endpoints in Azure stopped working. I&amp;#39;m working on setting it up with a new client, and we can&amp;#39;t get private endpoints deployed there, either.  I&amp;#39;ve heard from some Microsoft engineers that Synapse can no longer run on a private endpoint.  This is against the security policy where I am.  Has anyone else experienced this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19cdg40", "is_robot_indexable": true, "report_reasons": null, "author": "Swimming_Cry_6841", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cdg40/is_anybody_using_azure_synapse_and_if_so_are_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cdg40/is_anybody_using_azure_synapse_and_if_so_are_you/", "subreddit_subscribers": 154612, "created_utc": 1705870338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone! I\u2019m currently enrolled in an intensive 12-month data engineering program in South Africa, and I\u2019m seeking advice on how to strategically position myself for success. The program includes eight months of learning followed by a four-month internship with sponsoring companies. My goal is not only to secure a job locally but also to be attractive to international employers for better earning potential, considering the current exchange rates. What skills and strategies do you recommend to enhance my marketability? Your insights will be invaluable as I navigate this exciting journey. Thanks in advance!", "author_fullname": "t2_d54pk8w0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to optimise my learning journey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19cda7q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705869922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I\u2019m currently enrolled in an intensive 12-month data engineering program in South Africa, and I\u2019m seeking advice on how to strategically position myself for success. The program includes eight months of learning followed by a four-month internship with sponsoring companies. My goal is not only to secure a job locally but also to be attractive to international employers for better earning potential, considering the current exchange rates. What skills and strategies do you recommend to enhance my marketability? Your insights will be invaluable as I navigate this exciting journey. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19cda7q", "is_robot_indexable": true, "report_reasons": null, "author": "Fearless_Jicama2909", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19cda7q/how_to_optimise_my_learning_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19cda7q/how_to_optimise_my_learning_journey/", "subreddit_subscribers": 154612, "created_utc": 1705869922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4w31it2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Checkpoints for System Design interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_19c9s8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EyNJPVhldOiHMK9cMKyIBi--D5U-6ZbAUxdjAdc5YUA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705861178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "rahulraj.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://rahulraj.io/essential-data-modeling-checklist-for-cracking-the-system-design-interview", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ABDAC9squubBrxCrc4C2XKZ4gRjAZ4WYMfX7b0X9L8s.jpg?auto=webp&amp;s=bfc73a55a914e0421690901abf0414f544542046", "width": 1200, "height": 799}, "resolutions": [{"url": "https://external-preview.redd.it/ABDAC9squubBrxCrc4C2XKZ4gRjAZ4WYMfX7b0X9L8s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6aaea891b5329cb53201094a64a4b25816db4fb2", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/ABDAC9squubBrxCrc4C2XKZ4gRjAZ4WYMfX7b0X9L8s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f5000fa5748f5ba58efb8a1167edb142f5ca35df", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/ABDAC9squubBrxCrc4C2XKZ4gRjAZ4WYMfX7b0X9L8s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cfa1d0e2a67ae50f5981b763de2e7fa66abf4cc8", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/ABDAC9squubBrxCrc4C2XKZ4gRjAZ4WYMfX7b0X9L8s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b90f25b68ff24ef8dc3dcc18cdf8a231ba41bf8", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/ABDAC9squubBrxCrc4C2XKZ4gRjAZ4WYMfX7b0X9L8s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=53d99de7e3329f761b80a9f1228e67218645a459", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/ABDAC9squubBrxCrc4C2XKZ4gRjAZ4WYMfX7b0X9L8s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=20d2a433088f408a441ee75bf58bb610599e34dc", "width": 1080, "height": 719}], "variants": {}, "id": "PsuOH9FJDt8whA6RsagpLbEcDJocc8iYQN3t79odi88"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "19c9s8f", "is_robot_indexable": true, "report_reasons": null, "author": "willis7747", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c9s8f/data_modeling_checkpoints_for_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://rahulraj.io/essential-data-modeling-checklist-for-cracking-the-system-design-interview", "subreddit_subscribers": 154612, "created_utc": 1705861178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Kubernetes, Cloud Managed Service, etc.  \n\n\nWhen given the option, what do you prefer?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you prefer to deploy infrastructure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c6d38", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705852441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kubernetes, Cloud Managed Service, etc.  &lt;/p&gt;\n\n&lt;p&gt;When given the option, what do you prefer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19c6d38", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c6d38/how_do_you_prefer_to_deploy_infrastructure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c6d38/how_do_you_prefer_to_deploy_infrastructure/", "subreddit_subscribers": 154612, "created_utc": 1705852441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey! I'm currently working on integrating my dbt (data build tool) project, which is stored locally on my PC, with Airflow in a Cloud Composer environment on GCP using BigQuery. I'm a bit torn between using BashOperator, DockerOperator, or GKEPodOperator to execute the dbt project in my Airflow DAG.\n\nAny advice or insights on which operator is the best fit for running dbt in this setup? And if you've got any tips to share, that would be a huge help!\n\n1. BashOperator\n```\nrun_dbt_task = BashOperator(\n    task_id='run_dbt',\n    bash_command='dbt run',\n    dag=dag,\n)\n```\n2. DockerOperator:\n```\nrun_dbt_task = DockerOperator(\n    task_id='run_dbt',\n    image='your_dbt_docker_image',\n    api_version='auto',\n    command='dbt run',\n    dag=dag,\n)\n```\n3. GKEPodOperator:\n```\nrun_dbt_task = GKEPodOperator(\n    task_id='run_dbt',\n    project_id='your_project_id',\n    location='your_gke_cluster_location',\n    cluster_name='your_gke_cluster_name',\n    pod_name='run-dbt-pod',\n    image='gcr.io/your_project/your_dbt_image',\n    cmds=['dbt', 'run'],\n    dag=dag,\n)\n```\nOut of these three operators - which one would be the best one to use to run my dbt project in my Airflow DAG?\n\nAny help/advice would be good, thanks!", "author_fullname": "t2_13ussz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best method to run a dbt project in an Airflow DAG (Cloud Composer) with GCP/BigQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c5i59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705850105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! I&amp;#39;m currently working on integrating my dbt (data build tool) project, which is stored locally on my PC, with Airflow in a Cloud Composer environment on GCP using BigQuery. I&amp;#39;m a bit torn between using BashOperator, DockerOperator, or GKEPodOperator to execute the dbt project in my Airflow DAG.&lt;/p&gt;\n\n&lt;p&gt;Any advice or insights on which operator is the best fit for running dbt in this setup? And if you&amp;#39;ve got any tips to share, that would be a huge help!&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;BashOperator\n&lt;code&gt;\nrun_dbt_task = BashOperator(\ntask_id=&amp;#39;run_dbt&amp;#39;,\nbash_command=&amp;#39;dbt run&amp;#39;,\ndag=dag,\n)\n&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;DockerOperator:\n&lt;code&gt;\nrun_dbt_task = DockerOperator(\ntask_id=&amp;#39;run_dbt&amp;#39;,\nimage=&amp;#39;your_dbt_docker_image&amp;#39;,\napi_version=&amp;#39;auto&amp;#39;,\ncommand=&amp;#39;dbt run&amp;#39;,\ndag=dag,\n)\n&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;GKEPodOperator:\n&lt;code&gt;\nrun_dbt_task = GKEPodOperator(\ntask_id=&amp;#39;run_dbt&amp;#39;,\nproject_id=&amp;#39;your_project_id&amp;#39;,\nlocation=&amp;#39;your_gke_cluster_location&amp;#39;,\ncluster_name=&amp;#39;your_gke_cluster_name&amp;#39;,\npod_name=&amp;#39;run-dbt-pod&amp;#39;,\nimage=&amp;#39;gcr.io/your_project/your_dbt_image&amp;#39;,\ncmds=[&amp;#39;dbt&amp;#39;, &amp;#39;run&amp;#39;],\ndag=dag,\n)\n&lt;/code&gt;\nOut of these three operators - which one would be the best one to use to run my dbt project in my Airflow DAG?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any help/advice would be good, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19c5i59", "is_robot_indexable": true, "report_reasons": null, "author": "saucyhambon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c5i59/best_method_to_run_a_dbt_project_in_an_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c5i59/best_method_to_run_a_dbt_project_in_an_airflow/", "subreddit_subscribers": 154612, "created_utc": 1705850105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the data space there is this new movement of ZeroETL (started by AWS) that advocates the replacement of traditional data movement pipelines (generally implemented using Spark and Airflow) with real-time CDC replication. What is your take on it ? Did anyone fully implemented it ?", "author_fullname": "t2_5efs1s7d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZeroETL vs. Pipelines, Jobs, Schedules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bx9w9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705819472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the data space there is this new movement of ZeroETL (started by AWS) that advocates the replacement of traditional data movement pipelines (generally implemented using Spark and Airflow) with real-time CDC replication. What is your take on it ? Did anyone fully implemented it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bx9w9", "is_robot_indexable": true, "report_reasons": null, "author": "matteopelati76", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bx9w9/zeroetl_vs_pipelines_jobs_schedules/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bx9w9/zeroetl_vs_pipelines_jobs_schedules/", "subreddit_subscribers": 154612, "created_utc": 1705819472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, \nLong story short-  I am trying to switch companies as i think i am going to be put into PIP at a FAANG. I have 2 years of experience as a data engineer. What other good companies that i can apply to? I know the market is pretty bad now a days but i wanna target and try applying to some good companies as well. I work in India. \n1. I always wanted to work in European companies. Is there a chance now given current market? If yes how do i do it. Just go to company\u2019s career site and apply or is there someother way?\n2. I also know that trying to work elsewhere is not very optimal rn . Even in India i would like to get some good data engineer companies.\nPlease let me know if anyone has any ideas or suggestions.", "author_fullname": "t2_nusmz3fhp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with companies shortlisting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bvcjk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705812532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, \nLong story short-  I am trying to switch companies as i think i am going to be put into PIP at a FAANG. I have 2 years of experience as a data engineer. What other good companies that i can apply to? I know the market is pretty bad now a days but i wanna target and try applying to some good companies as well. I work in India. \n1. I always wanted to work in European companies. Is there a chance now given current market? If yes how do i do it. Just go to company\u2019s career site and apply or is there someother way?\n2. I also know that trying to work elsewhere is not very optimal rn . Even in India i would like to get some good data engineer companies.\nPlease let me know if anyone has any ideas or suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19bvcjk", "is_robot_indexable": true, "report_reasons": null, "author": "mad_peace", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bvcjk/need_help_with_companies_shortlisting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bvcjk/need_help_with_companies_shortlisting/", "subreddit_subscribers": 154612, "created_utc": 1705812532.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}