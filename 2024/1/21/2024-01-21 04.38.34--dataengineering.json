{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Meeting 2 days per week for an hour each. \n\nRight now I\u2019m thinking: \n\n- one week of SQL\n- one week of Python (focusing on REST APIs too) \n- one week of Snowflake \n- one week of orchestration with Airflow\n- one week of data quality \n- one week of communication and soft skills \n\nWhat other topics should be covered and/or removed? I want to keep it time boxed to 6 weeks. \n\nWhat other things should I consider when launching this? \n\nIf you make a free account at dataexpert.io/signup you can get access once the boot camp launches. \n\nThanks for your feedback in advance!", "author_fullname": "t2_2xnlhe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m releasing a free data engineering boot camp in March", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bg4jf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 215, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 215, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705770201.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705769710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Meeting 2 days per week for an hour each. &lt;/p&gt;\n\n&lt;p&gt;Right now I\u2019m thinking: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;one week of SQL&lt;/li&gt;\n&lt;li&gt;one week of Python (focusing on REST APIs too) &lt;/li&gt;\n&lt;li&gt;one week of Snowflake &lt;/li&gt;\n&lt;li&gt;one week of orchestration with Airflow&lt;/li&gt;\n&lt;li&gt;one week of data quality &lt;/li&gt;\n&lt;li&gt;one week of communication and soft skills &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What other topics should be covered and/or removed? I want to keep it time boxed to 6 weeks. &lt;/p&gt;\n\n&lt;p&gt;What other things should I consider when launching this? &lt;/p&gt;\n\n&lt;p&gt;If you make a free account at dataexpert.io/signup you can get access once the boot camp launches. &lt;/p&gt;\n\n&lt;p&gt;Thanks for your feedback in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bg4jf", "is_robot_indexable": true, "report_reasons": null, "author": "eczachly", "discussion_type": null, "num_comments": 100, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bg4jf/im_releasing_a_free_data_engineering_boot_camp_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bg4jf/im_releasing_a_free_data_engineering_boot_camp_in/", "subreddit_subscribers": 154397, "created_utc": 1705769710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi techies!\n\nI started using ruff and sqlfluff for my repos. It\u2019s truly amazing \ud83e\udd29\u2026 I really recommend them. A must. \n\nI was wondering if you are developing with these plus another similar tools and why. \n\nIn my case, my repos are coded with python for orchestration (airflow), python for processing (spark) and a lot of sql. \n\nGreat to hear your experience. \n\nHave a great weekend everyone here \ud83d\ude0e", "author_fullname": "t2_nobkhscod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linters and formatters for Python and SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b94kv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705747415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi techies!&lt;/p&gt;\n\n&lt;p&gt;I started using ruff and sqlfluff for my repos. It\u2019s truly amazing \ud83e\udd29\u2026 I really recommend them. A must. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if you are developing with these plus another similar tools and why. &lt;/p&gt;\n\n&lt;p&gt;In my case, my repos are coded with python for orchestration (airflow), python for processing (spark) and a lot of sql. &lt;/p&gt;\n\n&lt;p&gt;Great to hear your experience. &lt;/p&gt;\n\n&lt;p&gt;Have a great weekend everyone here \ud83d\ude0e&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19b94kv", "is_robot_indexable": true, "report_reasons": null, "author": "A-Global-Citizen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19b94kv/linters_and_formatters_for_python_and_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19b94kv/linters_and_formatters_for_python_and_sql/", "subreddit_subscribers": 154397, "created_utc": 1705747415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I hopped on board with this new company last month, and turns out they're on a bit of a staff exodus spree. Come next month, it's just gonna be me and two junior engineers left on the engineering team -  not just data engineering but the whole engineering team!! \ud83d\ude2c\n\nThinking of pulling the plug and bouncing to a new gig. As a data engineer, I'll be dealing with numerous data-related questions, but the challenge lies in not having someone to ask why the data is structured in a particular way.\n\nAny of you been in a situation like this? What did you do, and what should I be considering before making my exit?", "author_fullname": "t2_mbbdv7y98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of Bailing on My New Job - Need Some Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19brn6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705800529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I hopped on board with this new company last month, and turns out they&amp;#39;re on a bit of a staff exodus spree. Come next month, it&amp;#39;s just gonna be me and two junior engineers left on the engineering team -  not just data engineering but the whole engineering team!! \ud83d\ude2c&lt;/p&gt;\n\n&lt;p&gt;Thinking of pulling the plug and bouncing to a new gig. As a data engineer, I&amp;#39;ll be dealing with numerous data-related questions, but the challenge lies in not having someone to ask why the data is structured in a particular way.&lt;/p&gt;\n\n&lt;p&gt;Any of you been in a situation like this? What did you do, and what should I be considering before making my exit?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19brn6q", "is_robot_indexable": true, "report_reasons": null, "author": "Kindly-Screen-2557", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19brn6q/thinking_of_bailing_on_my_new_job_need_some_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19brn6q/thinking_of_bailing_on_my_new_job_need_some_advice/", "subreddit_subscribers": 154397, "created_utc": 1705800529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m posting this here as my data engineering teams are responsible for putting into production the work done by the Data Science team. If this is you, were you also involved in the discussions around the architecture?\n\nExamples: do you support any of the vector databases, or have you settled on a standard that must be used (similar to settling on DynamoDB for all microservices)? Do you use a single database for multiple RAG systems (can you even do that?) or do each have their own db?\n\nKeen to understand where businesses are at on this front.", "author_fullname": "t2_ojr03vx2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you handling AI Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b324v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705724017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m posting this here as my data engineering teams are responsible for putting into production the work done by the Data Science team. If this is you, were you also involved in the discussions around the architecture?&lt;/p&gt;\n\n&lt;p&gt;Examples: do you support any of the vector databases, or have you settled on a standard that must be used (similar to settling on DynamoDB for all microservices)? Do you use a single database for multiple RAG systems (can you even do that?) or do each have their own db?&lt;/p&gt;\n\n&lt;p&gt;Keen to understand where businesses are at on this front.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19b324v", "is_robot_indexable": true, "report_reasons": null, "author": "nydasco", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19b324v/how_are_you_handling_ai_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19b324v/how_are_you_handling_ai_architecture/", "subreddit_subscribers": 154397, "created_utc": 1705724017.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I need to collect data from people, I\u2019m presented with countless options:\n\nRetrieval:\n\n* Email me the data,\n* Put the data on a shared drive,\n* Drop the data in an S3 bucket,\n* Create a forum,\n* Give people database access,\n* \u2026\n\nThen comes validation:\n\n* Check the data manually,\n* Automate checking of common issues on the backend,\n* Reject incorrect data immediately from the frontend,\n* \u2026\n\nThen how to handle the results of validation:\n\n* Clean it manually,\n* Attempt to automate cleaning of common issues and attempt to re-validate,\n* Have the user fix the data,\n* \u2026\n\nThen after these you should have your data as expected, ready to be integrated into your platform and used for whatever. Until this point, however, there\u2019s a lot of grey area for me.\n\nRuling the decision is considerations like:\n\n* Corporate culture,\n* Engineers Technical Knowledge,\n* End Users Technical Knowledge,\n* Existing Infrastructure Available,\n* What\u2019s quickest?\n* What\u2019s easiest?\n* What\u2019s securest?\n* What\u2019s most robust to changing requirements?\n* \u2026\n\nand not particularly in that order.\n\nLet\u2019s say you\u2019re developing a new platform for a company filled with nontechnical users. They store things in spreadsheets and have for years, manually maintaining integrity like a bunch of humanoid relational database monsters. Now the company is growing on an order of magnitude, they want a culture shift to manage the growth. They want to have a platform that they can rely on just as they\u2019d relied on their HRDBMs for so long.\n\nSo you have studied their workflow, learned how and why things operate the way they do. You\u2019ve built systems to help lift a lot of the load, but now you find that you\u2019re still manually patching data into the system yourself. \n\nIt\u2019s time to develop a data integration standard. What do you do? How do you standardize this part of the pipeline?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Retrieval From Nontechnical Users - How To Standardize?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bnb55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705788470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I need to collect data from people, I\u2019m presented with countless options:&lt;/p&gt;\n\n&lt;p&gt;Retrieval:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Email me the data,&lt;/li&gt;\n&lt;li&gt;Put the data on a shared drive,&lt;/li&gt;\n&lt;li&gt;Drop the data in an S3 bucket,&lt;/li&gt;\n&lt;li&gt;Create a forum,&lt;/li&gt;\n&lt;li&gt;Give people database access,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then comes validation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Check the data manually,&lt;/li&gt;\n&lt;li&gt;Automate checking of common issues on the backend,&lt;/li&gt;\n&lt;li&gt;Reject incorrect data immediately from the frontend,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then how to handle the results of validation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Clean it manually,&lt;/li&gt;\n&lt;li&gt;Attempt to automate cleaning of common issues and attempt to re-validate,&lt;/li&gt;\n&lt;li&gt;Have the user fix the data,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then after these you should have your data as expected, ready to be integrated into your platform and used for whatever. Until this point, however, there\u2019s a lot of grey area for me.&lt;/p&gt;\n\n&lt;p&gt;Ruling the decision is considerations like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Corporate culture,&lt;/li&gt;\n&lt;li&gt;Engineers Technical Knowledge,&lt;/li&gt;\n&lt;li&gt;End Users Technical Knowledge,&lt;/li&gt;\n&lt;li&gt;Existing Infrastructure Available,&lt;/li&gt;\n&lt;li&gt;What\u2019s quickest?&lt;/li&gt;\n&lt;li&gt;What\u2019s easiest?&lt;/li&gt;\n&lt;li&gt;What\u2019s securest?&lt;/li&gt;\n&lt;li&gt;What\u2019s most robust to changing requirements?&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;and not particularly in that order.&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say you\u2019re developing a new platform for a company filled with nontechnical users. They store things in spreadsheets and have for years, manually maintaining integrity like a bunch of humanoid relational database monsters. Now the company is growing on an order of magnitude, they want a culture shift to manage the growth. They want to have a platform that they can rely on just as they\u2019d relied on their HRDBMs for so long.&lt;/p&gt;\n\n&lt;p&gt;So you have studied their workflow, learned how and why things operate the way they do. You\u2019ve built systems to help lift a lot of the load, but now you find that you\u2019re still manually patching data into the system yourself. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s time to develop a data integration standard. What do you do? How do you standardize this part of the pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bnb55", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bnb55/data_retrieval_from_nontechnical_users_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bnb55/data_retrieval_from_nontechnical_users_how_to/", "subreddit_subscribers": 154397, "created_utc": 1705788470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys\n\nI've been googling lots of different unit tests/automated testing for ADF pipelines and databricks notebooks (ran in ADF) and I've got a basic idea lined up, but it's got me curious what other professionals in the industry use for testing and what's generally considered best practice for you guys.", "author_fullname": "t2_56o0g58i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you guys prefer to Unit test/automate test ADF pipelines/databricks notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bi0pn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705774669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been googling lots of different unit tests/automated testing for ADF pipelines and databricks notebooks (ran in ADF) and I&amp;#39;ve got a basic idea lined up, but it&amp;#39;s got me curious what other professionals in the industry use for testing and what&amp;#39;s generally considered best practice for you guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bi0pn", "is_robot_indexable": true, "report_reasons": null, "author": "IG-55", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bi0pn/how_do_you_guys_prefer_to_unit_testautomate_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bi0pn/how_do_you_guys_prefer_to_unit_testautomate_test/", "subreddit_subscribers": 154397, "created_utc": 1705774669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a DE with 2 years of experience as (lead) data/platform engineer using mainly Azure Synapse. Currently I am asked by our data architect to create a solution using the following requirements:\n\n-we receive an xml full load of a big dataset every day in an S3 bucket.\n-we want to create iceberg tables in S3 by doing CDC on the xml data (in some fashion)\n-goal is to be able to efficiently timetravel the database. \n\nHow would you tackle this problem?", "author_fullname": "t2_11rpnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to AWS, need some advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b9cwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705748405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a DE with 2 years of experience as (lead) data/platform engineer using mainly Azure Synapse. Currently I am asked by our data architect to create a solution using the following requirements:&lt;/p&gt;\n\n&lt;p&gt;-we receive an xml full load of a big dataset every day in an S3 bucket.\n-we want to create iceberg tables in S3 by doing CDC on the xml data (in some fashion)\n-goal is to be able to efficiently timetravel the database. &lt;/p&gt;\n\n&lt;p&gt;How would you tackle this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19b9cwv", "is_robot_indexable": true, "report_reasons": null, "author": "Schuurspons93", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19b9cwv/new_to_aws_need_some_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19b9cwv/new_to_aws_need_some_advice/", "subreddit_subscribers": 154397, "created_utc": 1705748405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, quick question.\n\nI've been a DE roughly 3 years and just applied to a senior DE role at a consultancy and was pleasantly surprised to get offered the role. Hurrah.\n\nAnyway I received the contract and the title was technical project manager. I love being a data engineer and I don't want to not be close to the code or etl. In your experience if some one had technical project manager on their cv would you discount that as DE experience? Or are the roles synonymous?\n\nThanks", "author_fullname": "t2_17h92l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job title... What do you think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b8e6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705744400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, quick question.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a DE roughly 3 years and just applied to a senior DE role at a consultancy and was pleasantly surprised to get offered the role. Hurrah.&lt;/p&gt;\n\n&lt;p&gt;Anyway I received the contract and the title was technical project manager. I love being a data engineer and I don&amp;#39;t want to not be close to the code or etl. In your experience if some one had technical project manager on their cv would you discount that as DE experience? Or are the roles synonymous?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19b8e6v", "is_robot_indexable": true, "report_reasons": null, "author": "tcfcfc", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19b8e6v/job_title_what_do_you_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19b8e6v/job_title_what_do_you_think/", "subreddit_subscribers": 154397, "created_utc": 1705744400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. As is typical (for me at least), I\u2019m looking to garner some insights on approches for a common kind of application before I built one.\n\nI\u2019m going to build an email notification system. Its first set of requirements will be to send out notices a few weeks before some documents expire, unless those documents have been renewed already.\n\nThe source data lives in an excel spreadsheet stored in a shared SharePoint drive. It gets updated at regular intervals by some kind of ghost entity that magically knows when/how to update the data.\n\nMy first thoughts are that I\u2019m going to need to store the document names and their expiration date, as well as a recipient list somewhere that can be polled daily. If the poll finds any records matching the conditions I\u2019ve described, send an email to the documents recipient list. \n\nHowever, I started to wonder if there might be a better approach. For example, maybe the polling service can simply update a `status` column based on how close a document is to expiration. If `status` gets set to `soon to expire`, then a [postgres] `NOTIFY` can get sent to a `LISTEN`ing channel. On the `LISTEN`ing channel, there can be an application that handles these \u201cevent based\u201d emails. This decouples the polling service from the email service, and theoretically the email service can get used for any email.\n\nAfter this, I started to wonder Postgres actually has some built in method to automatically `NOTIFY` if a records `date` column approaches less than X days from current time. I\u2019m doubtful about this, as it just sounds like a built in polling service, or maybe a nasty looking trigger function, but who knows.\n\nFor reference I use Postgres for storage, Prefect for orchestration, Python for the nooks and crannies, \u2026 I want a solution that\u2019s generally applicable though and can get reused for future projects. \n\nWhat\u2019s the typical \u201cgenerally applicable\u201d approach for email notifications? Thanks!", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Common Architectures for Event &amp; Schedule Based Email Notifications System?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bm0w0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705786231.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705785073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. As is typical (for me at least), I\u2019m looking to garner some insights on approches for a common kind of application before I built one.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m going to build an email notification system. Its first set of requirements will be to send out notices a few weeks before some documents expire, unless those documents have been renewed already.&lt;/p&gt;\n\n&lt;p&gt;The source data lives in an excel spreadsheet stored in a shared SharePoint drive. It gets updated at regular intervals by some kind of ghost entity that magically knows when/how to update the data.&lt;/p&gt;\n\n&lt;p&gt;My first thoughts are that I\u2019m going to need to store the document names and their expiration date, as well as a recipient list somewhere that can be polled daily. If the poll finds any records matching the conditions I\u2019ve described, send an email to the documents recipient list. &lt;/p&gt;\n\n&lt;p&gt;However, I started to wonder if there might be a better approach. For example, maybe the polling service can simply update a &lt;code&gt;status&lt;/code&gt; column based on how close a document is to expiration. If &lt;code&gt;status&lt;/code&gt; gets set to &lt;code&gt;soon to expire&lt;/code&gt;, then a [postgres] &lt;code&gt;NOTIFY&lt;/code&gt; can get sent to a &lt;code&gt;LISTEN&lt;/code&gt;ing channel. On the &lt;code&gt;LISTEN&lt;/code&gt;ing channel, there can be an application that handles these \u201cevent based\u201d emails. This decouples the polling service from the email service, and theoretically the email service can get used for any email.&lt;/p&gt;\n\n&lt;p&gt;After this, I started to wonder Postgres actually has some built in method to automatically &lt;code&gt;NOTIFY&lt;/code&gt; if a records &lt;code&gt;date&lt;/code&gt; column approaches less than X days from current time. I\u2019m doubtful about this, as it just sounds like a built in polling service, or maybe a nasty looking trigger function, but who knows.&lt;/p&gt;\n\n&lt;p&gt;For reference I use Postgres for storage, Prefect for orchestration, Python for the nooks and crannies, \u2026 I want a solution that\u2019s generally applicable though and can get reused for future projects. &lt;/p&gt;\n\n&lt;p&gt;What\u2019s the typical \u201cgenerally applicable\u201d approach for email notifications? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bm0w0", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bm0w0/common_architectures_for_event_schedule_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bm0w0/common_architectures_for_event_schedule_based/", "subreddit_subscribers": 154397, "created_utc": 1705785073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I've been running my business as a marketing agency owner for a couple of years right now. \n\nI started developing my martech stack, duplicate for each client, made by a mix of OS and licensed products which are:\n1. Hubspot CRM (just for the sales part)\n2. Mautic (marketing automation)\n3. Sendgrid\n4. Mailsync (for feeding Hubspot timeline with SendGrid's events)\n5. Make.com (former Integromat) as IPaaS (I have an old subscription with a super cheap deal)\n6. Coda.io as a productivity tool shared with clients\n7. WordPress as a CMS with Elementor Pro\n7. Oviond for analytics dashboards\n\nI've started understanding the competitive advantage of OS (only Mautic and WordPress are on this list) by having them hosted on Google Cloud Platform with virtual images that I duplicate each time and two up-and-running main machines for maintenance. \n\nI'm looking for any type of suggestions about this because I'm starting to look into RudderStack as a data lake for getting all events but probably it's too big for my clients and we don't have so many events to manage. Still thinking about it and I'm struggling a bit. \n\nThanks to anyone who will give me any feedback!\nSee you", "author_fullname": "t2_w42eilem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Marketing agency tech stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19b8kma", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705745128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I&amp;#39;ve been running my business as a marketing agency owner for a couple of years right now. &lt;/p&gt;\n\n&lt;p&gt;I started developing my martech stack, duplicate for each client, made by a mix of OS and licensed products which are:\n1. Hubspot CRM (just for the sales part)\n2. Mautic (marketing automation)\n3. Sendgrid\n4. Mailsync (for feeding Hubspot timeline with SendGrid&amp;#39;s events)\n5. Make.com (former Integromat) as IPaaS (I have an old subscription with a super cheap deal)\n6. Coda.io as a productivity tool shared with clients\n7. WordPress as a CMS with Elementor Pro\n7. Oviond for analytics dashboards&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve started understanding the competitive advantage of OS (only Mautic and WordPress are on this list) by having them hosted on Google Cloud Platform with virtual images that I duplicate each time and two up-and-running main machines for maintenance. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for any type of suggestions about this because I&amp;#39;m starting to look into RudderStack as a data lake for getting all events but probably it&amp;#39;s too big for my clients and we don&amp;#39;t have so many events to manage. Still thinking about it and I&amp;#39;m struggling a bit. &lt;/p&gt;\n\n&lt;p&gt;Thanks to anyone who will give me any feedback!\nSee you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19b8kma", "is_robot_indexable": true, "report_reasons": null, "author": "SpookyLibra45817", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19b8kma/marketing_agency_tech_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19b8kma/marketing_agency_tech_stack/", "subreddit_subscribers": 154397, "created_utc": 1705745128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically the title, if it can be done with Postgres\u2026 is something like rabbitmq worthwhile?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any real benefit to a queue service over a makeshift queue with Postgres for small scale stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19btc8i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705805719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title, if it can be done with Postgres\u2026 is something like rabbitmq worthwhile?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19btc8i", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19btc8i/any_real_benefit_to_a_queue_service_over_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19btc8i/any_real_benefit_to_a_queue_service_over_a/", "subreddit_subscribers": 154397, "created_utc": 1705805719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company wants to organize our data in Databricks and I have been looking at some documentation on best practices for directory structures. \n\nOne of the documentations suggested: \u201cCatalogs often mirror organizational units or software development lifecycle scopes. You may choose, for example, to have a catalog for production data and a catalog for development data\u201d \n\nI\u2019ve read in many articles that there should be a catalog for dev, prod, stage, etc\u2026 and one schema for each of the Bronze, Silver, and Gold medallion structures.\n\nHere\u2019s what my company has in place at the moment:\n\n* We have different workspaces for test, dev, and prod (for example, dev\\_us\\_west, prod\\_us\\_west, test\\_us\\_east, test\\_uk,...) \n* In our current setup, catalogs within each workspace represent individual projects. For example, demand\\_forecast, sales\\_prediction,... \n* The schemas group related tables. For example, inside the demand\\_forecast catalog, there are the following schemas: \u2018customers\u2019, and \u2018products\u2019. The \u2018customers\u2019 schema contains tables like churn (raw, untransformed) and customer\\_preference (transformed). And the \u2018products\u2019 schema contains tables like prices (raw), reviews (raw)\n* The way it works right now is if someone has a project that only needs some analysis and doesn't involve pushing codes into production, they will go into the test workspace. There, they can create a catalog for that project, and create the necessary schemas and tables. If someone needs to create a model that will be used in production, they will use the prod workspace and create a catalog for their project there. \n* I\u2019ve read that \u201c*Databricks no longer recommends mounting external data locations to Databricks Filesystem\u201d.* Right now, the way that we load files into Databricks is by using DBFS S3 bucket mount points. In the future, we would want to switch to using volumes to store unstructured data. Right now, each sub-directory in our S3 bucket contains files related to a project. \n\nI\u2019m not from a Data Engineering background and am not very experienced with Unity Catalog. Could you recommend best practices for isolating and organizing data using workspaces, catalogs, schemas, and volumes? \n\nThank you in advance!", "author_fullname": "t2_8rwu4pz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing data and setting up directory structures for Databricks Unity Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bnqyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705789663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company wants to organize our data in Databricks and I have been looking at some documentation on best practices for directory structures. &lt;/p&gt;\n\n&lt;p&gt;One of the documentations suggested: \u201cCatalogs often mirror organizational units or software development lifecycle scopes. You may choose, for example, to have a catalog for production data and a catalog for development data\u201d &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve read in many articles that there should be a catalog for dev, prod, stage, etc\u2026 and one schema for each of the Bronze, Silver, and Gold medallion structures.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s what my company has in place at the moment:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We have different workspaces for test, dev, and prod (for example, dev_us_west, prod_us_west, test_us_east, test_uk,...) &lt;/li&gt;\n&lt;li&gt;In our current setup, catalogs within each workspace represent individual projects. For example, demand_forecast, sales_prediction,... &lt;/li&gt;\n&lt;li&gt;The schemas group related tables. For example, inside the demand_forecast catalog, there are the following schemas: \u2018customers\u2019, and \u2018products\u2019. The \u2018customers\u2019 schema contains tables like churn (raw, untransformed) and customer_preference (transformed). And the \u2018products\u2019 schema contains tables like prices (raw), reviews (raw)&lt;/li&gt;\n&lt;li&gt;The way it works right now is if someone has a project that only needs some analysis and doesn&amp;#39;t involve pushing codes into production, they will go into the test workspace. There, they can create a catalog for that project, and create the necessary schemas and tables. If someone needs to create a model that will be used in production, they will use the prod workspace and create a catalog for their project there. &lt;/li&gt;\n&lt;li&gt;I\u2019ve read that \u201c&lt;em&gt;Databricks no longer recommends mounting external data locations to Databricks Filesystem\u201d.&lt;/em&gt; Right now, the way that we load files into Databricks is by using DBFS S3 bucket mount points. In the future, we would want to switch to using volumes to store unstructured data. Right now, each sub-directory in our S3 bucket contains files related to a project. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m not from a Data Engineering background and am not very experienced with Unity Catalog. Could you recommend best practices for isolating and organizing data using workspaces, catalogs, schemas, and volumes? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19bnqyq", "is_robot_indexable": true, "report_reasons": null, "author": "lunalita_99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bnqyq/organizing_data_and_setting_up_directory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bnqyq/organizing_data_and_setting_up_directory/", "subreddit_subscribers": 154397, "created_utc": 1705789663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(The reason I put urgent is because the deadline for me to choose courses is in 2 days \ud83e\udd72 i know not the best)\n\nHello, I\u2019m a fourth year undergrad student majoring in Statistics and minoring in GIS and Human Geography at a university in Canada and I\u2019m looking to become a data engineer after graduating but I\u2019ll likely start as a data analyst first before transitioning into a DE. \n\nI\u2019m wondering if it would be worth it to take CS courses for an extra 2 semesters to change my Human Geography minor into a CS minor. \n\nThe thing is, CS at my school can be pretty theoretical, and 2 required courses focus on making projects in Java and C which I\u2019m not sure how relevant those languages are for DEs. However, I do have the option of choosing an SQL course and machine learning courses after I complete those required courses so it\u2019s something I\u2019m considering as I assume it is relevant to the data science industry. \n\nHowever, if I\u2019m not gonna really use a lot of things I learn such as math proofs, Java and C  during work then I honestly think those courses might be overkill, but if CS will overall teach me skills that are fundamental to the engineering aspect of DE then I\u2019m willing to just push through and finish the CS minor. I know for a fact that I learn better in classroom settings than on my own so that is also something to consider. \n\nFor those who work as a data engineer, what are the most important languages/technical skills to learn in order to start a career as a DE? I know Python is very important and I\u2019m currently using it a lot in one of my upper year stats courses, but how about languages such as Java or C? I\u2019m already familiar with R and will learn SQL on my own. \n\nIf anyone can provide me insight on the current industry and tips on how to get hired in Canada or the US it would be much appreciated!", "author_fullname": "t2_89iqzb4b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Urgent: Taking 2 extra semesters for a CS Minor as a Stats major?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bhkx4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705784300.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705773551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(The reason I put urgent is because the deadline for me to choose courses is in 2 days \ud83e\udd72 i know not the best)&lt;/p&gt;\n\n&lt;p&gt;Hello, I\u2019m a fourth year undergrad student majoring in Statistics and minoring in GIS and Human Geography at a university in Canada and I\u2019m looking to become a data engineer after graduating but I\u2019ll likely start as a data analyst first before transitioning into a DE. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering if it would be worth it to take CS courses for an extra 2 semesters to change my Human Geography minor into a CS minor. &lt;/p&gt;\n\n&lt;p&gt;The thing is, CS at my school can be pretty theoretical, and 2 required courses focus on making projects in Java and C which I\u2019m not sure how relevant those languages are for DEs. However, I do have the option of choosing an SQL course and machine learning courses after I complete those required courses so it\u2019s something I\u2019m considering as I assume it is relevant to the data science industry. &lt;/p&gt;\n\n&lt;p&gt;However, if I\u2019m not gonna really use a lot of things I learn such as math proofs, Java and C  during work then I honestly think those courses might be overkill, but if CS will overall teach me skills that are fundamental to the engineering aspect of DE then I\u2019m willing to just push through and finish the CS minor. I know for a fact that I learn better in classroom settings than on my own so that is also something to consider. &lt;/p&gt;\n\n&lt;p&gt;For those who work as a data engineer, what are the most important languages/technical skills to learn in order to start a career as a DE? I know Python is very important and I\u2019m currently using it a lot in one of my upper year stats courses, but how about languages such as Java or C? I\u2019m already familiar with R and will learn SQL on my own. &lt;/p&gt;\n\n&lt;p&gt;If anyone can provide me insight on the current industry and tips on how to get hired in Canada or the US it would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19bhkx4", "is_robot_indexable": true, "report_reasons": null, "author": "smol_llama", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bhkx4/urgent_taking_2_extra_semesters_for_a_cs_minor_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bhkx4/urgent_taking_2_extra_semesters_for_a_cs_minor_as/", "subreddit_subscribers": 154397, "created_utc": 1705773551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI'm currently working on a project that involves creating a searchable database. As the database is expected to grow into millions of records with titles, description and others, I'm looking for an efficient and scalable search engine solution.\n\nHere's a brief overview of my requirements:\n\n* **Data Size**: The database will contain millions of records.\n* **Functionality**: I need to aggregate and deduplicate search results from multiple queries. Each user can have multiple favorite search queries, and I want to provide a personalized feed based on these queries.\n* **Challenges**:\n   * Some queries might return thousands of results.\n   * The aggregated results need to be sorted globally (e.g., by date or relevance).\n   * The aggregated results should possibly be filtered by columns like filestypes\\[\\] and is\\_free\n   * The solution needs to be efficient and scalable to handle the increasing data size and query load.\n   * The solution needs to be selfhosted.\n\n**Current Approach**: I'm currently considering using Typesense for its simplicity and speed, but I'm open to other solutions that might better suit my needs, especially considering the need for efficient multi-query aggregation and global sorting of results.\n\nI would appreciate any suggestions or insights on:\n\n* Which search engines you would recommend for this use case.\n* Strategies for efficiently aggregating and deduplicating results from multiple queries.\n* Any other considerations or tips for managing large-scale search operations.\n\nThank you in advance for your help!\n\nBtw. if there are subreddits that are more suitable for my question please let me know.", "author_fullname": "t2_xfhxx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for a Scalable Search Engine for Aggregating Results from Multiple Queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bghjl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705770638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on a project that involves creating a searchable database. As the database is expected to grow into millions of records with titles, description and others, I&amp;#39;m looking for an efficient and scalable search engine solution.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a brief overview of my requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data Size&lt;/strong&gt;: The database will contain millions of records.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Functionality&lt;/strong&gt;: I need to aggregate and deduplicate search results from multiple queries. Each user can have multiple favorite search queries, and I want to provide a personalized feed based on these queries.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Challenges&lt;/strong&gt;:\n\n&lt;ul&gt;\n&lt;li&gt;Some queries might return thousands of results.&lt;/li&gt;\n&lt;li&gt;The aggregated results need to be sorted globally (e.g., by date or relevance).&lt;/li&gt;\n&lt;li&gt;The aggregated results should possibly be filtered by columns like filestypes[] and is_free&lt;/li&gt;\n&lt;li&gt;The solution needs to be efficient and scalable to handle the increasing data size and query load.&lt;/li&gt;\n&lt;li&gt;The solution needs to be selfhosted.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Current Approach&lt;/strong&gt;: I&amp;#39;m currently considering using Typesense for its simplicity and speed, but I&amp;#39;m open to other solutions that might better suit my needs, especially considering the need for efficient multi-query aggregation and global sorting of results.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any suggestions or insights on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Which search engines you would recommend for this use case.&lt;/li&gt;\n&lt;li&gt;Strategies for efficiently aggregating and deduplicating results from multiple queries.&lt;/li&gt;\n&lt;li&gt;Any other considerations or tips for managing large-scale search operations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n\n&lt;p&gt;Btw. if there are subreddits that are more suitable for my question please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19bghjl", "is_robot_indexable": true, "report_reasons": null, "author": "LarsSorensen", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bghjl/suggestions_for_a_scalable_search_engine_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bghjl/suggestions_for_a_scalable_search_engine_for/", "subreddit_subscribers": 154397, "created_utc": 1705770638.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In on of my project, I have  a stored procedure in snowflake that is generating ingestion query of around 100 raw files into around 20 tables. Right now we are using sample Data, each one has few thousands rows. And ingestion time is around 10 minutes. \nBut i m sure in production environment each file will contain millions of rows any my estimate is that will takes 30 minutes to ingest. \n\nRight now, I am running all ingestions queries in sequential manner, one by one. But I want to ingest Data parallely in asynchronous manner/Mutlithreading whichone is the right term, I have no idea. \nInside snowflake, I m using python which has features to do parallel processing. But is it possible to do so in snowflake. Or any theoritical modification, you are thinking to suggest. \n\nFrom business perspective it's not necessary, since these are DWH layer and processing is of batch type. I m just exploring probable options from learning perspective. \n\nThanks in advance. Any lead will be appreciated.", "author_fullname": "t2_1ubfs6x4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "parallel ingestion in snowflake!?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bb6ru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705755890.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705755387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In on of my project, I have  a stored procedure in snowflake that is generating ingestion query of around 100 raw files into around 20 tables. Right now we are using sample Data, each one has few thousands rows. And ingestion time is around 10 minutes. \nBut i m sure in production environment each file will contain millions of rows any my estimate is that will takes 30 minutes to ingest. &lt;/p&gt;\n\n&lt;p&gt;Right now, I am running all ingestions queries in sequential manner, one by one. But I want to ingest Data parallely in asynchronous manner/Mutlithreading whichone is the right term, I have no idea. \nInside snowflake, I m using python which has features to do parallel processing. But is it possible to do so in snowflake. Or any theoritical modification, you are thinking to suggest. &lt;/p&gt;\n\n&lt;p&gt;From business perspective it&amp;#39;s not necessary, since these are DWH layer and processing is of batch type. I m just exploring probable options from learning perspective. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance. Any lead will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bb6ru", "is_robot_indexable": true, "report_reasons": null, "author": "asud_w_asud", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bb6ru/parallel_ingestion_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bb6ru/parallel_ingestion_in_snowflake/", "subreddit_subscribers": 154397, "created_utc": 1705755387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I need some career advice, please: \n\nI'm currently employed as a Data Analyst for an IT consulting company. However, my recent project involves tasks unrelated to data analytics, focusing more on process mapping and ERP adjustments. Despite expressing my concerns to my manager, they've mentioned that reassignment to a different project is unlikely until 2025.\n\nI've received an offer from a small AIaaS company to work as a Data Analyst within the Data Engineering team, and the role seems very exciting. My ultimate goal is to transition into a Data Engineering role by the end of the year.\n\nThe dilemma is that my current job offers a great salary, extra vacation days, and access to diverse future projects. On the other hand, the startup offer involves a roughly 30% salary cut and no additional vacation days. While I can manage the pay cut since I live with my parents, it's a significant downgrade.\n\nSo, what would you advise? Should I stick with my current job, even though I'm not enjoying it at all, but enjoying the perks while independently learning Data Engineering? Or should I accept the startup offer, taking a pay cut but gaining experience under the Data Engineering team?\n\nThanks in advance for your perspectives. I truly appreciate it.", "author_fullname": "t2_4iz2pipg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice: More interesting job for less money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bqqbe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705797834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I need some career advice, please: &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently employed as a Data Analyst for an IT consulting company. However, my recent project involves tasks unrelated to data analytics, focusing more on process mapping and ERP adjustments. Despite expressing my concerns to my manager, they&amp;#39;ve mentioned that reassignment to a different project is unlikely until 2025.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve received an offer from a small AIaaS company to work as a Data Analyst within the Data Engineering team, and the role seems very exciting. My ultimate goal is to transition into a Data Engineering role by the end of the year.&lt;/p&gt;\n\n&lt;p&gt;The dilemma is that my current job offers a great salary, extra vacation days, and access to diverse future projects. On the other hand, the startup offer involves a roughly 30% salary cut and no additional vacation days. While I can manage the pay cut since I live with my parents, it&amp;#39;s a significant downgrade.&lt;/p&gt;\n\n&lt;p&gt;So, what would you advise? Should I stick with my current job, even though I&amp;#39;m not enjoying it at all, but enjoying the perks while independently learning Data Engineering? Or should I accept the startup offer, taking a pay cut but gaining experience under the Data Engineering team?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your perspectives. I truly appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19bqqbe", "is_robot_indexable": true, "report_reasons": null, "author": "_Lavender_Brown_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bqqbe/career_advice_more_interesting_job_for_less_money/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bqqbe/career_advice_more_interesting_job_for_less_money/", "subreddit_subscribers": 154397, "created_utc": 1705797834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you\u2026\n\n- currently use a data lakehouse\n\n- if so, do you like it?\n\n- if not, do you want to?\n\n- if not, why not?\n\n(Data lakehouse = doing more analytics from your data lake using table formats like iceberg/delta/hudi to use the lake more like a traditional warehouse)", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you data lakehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bcijh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.47, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705759623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you\u2026&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;currently use a data lakehouse&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;if so, do you like it?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;if not, do you want to?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;if not, why not?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;(Data lakehouse = doing more analytics from your data lake using table formats like iceberg/delta/hudi to use the lake more like a traditional warehouse)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bcijh", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bcijh/do_you_data_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bcijh/do_you_data_lakehouse/", "subreddit_subscribers": 154397, "created_utc": 1705759623.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}