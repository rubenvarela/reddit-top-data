{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Meeting 2 days per week for an hour each. \n\nRight now I\u2019m thinking: \n\n- one week of SQL\n- one week of Python (focusing on REST APIs too) \n- one week of Snowflake \n- one week of orchestration with Airflow\n- one week of data quality \n- one week of communication and soft skills \n\nWhat other topics should be covered and/or removed? I want to keep it time boxed to 6 weeks. \n\nWhat other things should I consider when launching this? \n\nIf you make a free account at dataexpert.io/signup you can get access once the boot camp launches. \n\nThanks for your feedback in advance!", "author_fullname": "t2_2xnlhe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m releasing a free data engineering boot camp in March", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bg4jf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 288, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 288, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705770201.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705769710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Meeting 2 days per week for an hour each. &lt;/p&gt;\n\n&lt;p&gt;Right now I\u2019m thinking: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;one week of SQL&lt;/li&gt;\n&lt;li&gt;one week of Python (focusing on REST APIs too) &lt;/li&gt;\n&lt;li&gt;one week of Snowflake &lt;/li&gt;\n&lt;li&gt;one week of orchestration with Airflow&lt;/li&gt;\n&lt;li&gt;one week of data quality &lt;/li&gt;\n&lt;li&gt;one week of communication and soft skills &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What other topics should be covered and/or removed? I want to keep it time boxed to 6 weeks. &lt;/p&gt;\n\n&lt;p&gt;What other things should I consider when launching this? &lt;/p&gt;\n\n&lt;p&gt;If you make a free account at dataexpert.io/signup you can get access once the boot camp launches. &lt;/p&gt;\n\n&lt;p&gt;Thanks for your feedback in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bg4jf", "is_robot_indexable": true, "report_reasons": null, "author": "eczachly", "discussion_type": null, "num_comments": 127, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bg4jf/im_releasing_a_free_data_engineering_boot_camp_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bg4jf/im_releasing_a_free_data_engineering_boot_camp_in/", "subreddit_subscribers": 154500, "created_utc": 1705769710.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A number of data folks I respect has recently nudged me with an idea to create a data streaming 101 course since I have been managing an open source data streaming project and a managed cloud service for over a year now.\n\nI have thought about it a few times in 2023, and I'd like to ask the community, if you folks would like a data streaming 101 course.\n\nA bunch of good ones already exist. Here is how this one would be different.\n\nThe implementation and hands on labs of this data streaming course would be based on Rust and Web Assembly. It would be entirely self hosted. There would be a bit of complexity to grasp, but I would work to make it as simple as possible.\n\nI am thinking 7 emails with the course content delivered with text, video, and supporting code in a GitHub repo.\n\nThe only investment for the course would be time. And that too not a lot. Say 2 - 3 hours to consume the content and 2 - 3 hours to implement the labs.\n\nDoes this sound interesting? Let me know in the comments.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there interested in a Data streaming 101 course based on Rust and WebAssembly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bvq2q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705813808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A number of data folks I respect has recently nudged me with an idea to create a data streaming 101 course since I have been managing an open source data streaming project and a managed cloud service for over a year now.&lt;/p&gt;\n\n&lt;p&gt;I have thought about it a few times in 2023, and I&amp;#39;d like to ask the community, if you folks would like a data streaming 101 course.&lt;/p&gt;\n\n&lt;p&gt;A bunch of good ones already exist. Here is how this one would be different.&lt;/p&gt;\n\n&lt;p&gt;The implementation and hands on labs of this data streaming course would be based on Rust and Web Assembly. It would be entirely self hosted. There would be a bit of complexity to grasp, but I would work to make it as simple as possible.&lt;/p&gt;\n\n&lt;p&gt;I am thinking 7 emails with the course content delivered with text, video, and supporting code in a GitHub repo.&lt;/p&gt;\n\n&lt;p&gt;The only investment for the course would be time. And that too not a lot. Say 2 - 3 hours to consume the content and 2 - 3 hours to implement the labs.&lt;/p&gt;\n\n&lt;p&gt;Does this sound interesting? Let me know in the comments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Head of Product - Data Platform ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bvq2q", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/19bvq2q/is_there_interested_in_a_data_streaming_101/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bvq2q/is_there_interested_in_a_data_streaming_101/", "subreddit_subscribers": 154500, "created_utc": 1705813808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My first job title in tech was Data Scientist, now I'm officially a Data Engineer, but working somewhere in Data Science/Engineering, MLOps and as a Python Dev.\n\nI'm not claiming to be a good programmer with two and a half years of professional experience, but I think some of our Data Scientists write bad Python code.  \n\n\nHere I explain why:\n\n* Using generic execptions instead of thinking about what error they really want to catch\n* They try to encapsulate all functions as static methods in classes, even though it's okay to use free standing functions sometimes\n* They don't use enums (or don't know what enums are used for)\n* Sometimes they use bad method names -&gt; they think `da_file2tbl_file()` is better than `convert_data_asset_to_mltalble()` (What do you think is better?)\n* Overengineering: Use of design patterns with 70 lines of code, although one simple free-standing function with 10 lines would have sufficed (-&gt; but I respect the fact that an effort is made here to learn and try out new things)\n* Use of global variables, although this could easily have been solved with an instance variable or a parameter extension in the method header\n* Too many useless and redundant comments like:  \n`# Creating dataframe`  \n`df = pd.DataFrame(...)`\n* Use of magic strings/numbers instead of constants\n* etc ...\n\nWhat are your experiences with Data Scientists or Data Engineers using Python?\n\nI don't despise anyone who makes such mistakes, but what's bad is that some Data Scientists are stubborn and say in code reviews: \"But I want to encapsulate all functions as static methods in a class or \"I think my 70-line design pattern is better than your 10-code-line function\" or \"I'd rather use global variables. I don't want to rewrite the code now.\" I find that very annoying. Some people have too big an ego. But code reviews aren't about being the smartest in the room, they're about learning from each other and making the product better.  \n\n\nLast year I started learning more programming languages. Kotlin and Rust.  I'm working on a personal project in Kotlin to rebuild our machine learning infrastructure and I'm still at tutorial level with Rust.  Both languages are amazing so far and both have already helped me to be a better (Python) programmer. What is your experience? Do you also think that learning more (statically typed) languages makes you a better developer? ", "author_fullname": "t2_1mzvtswi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some Data Scientists write bad Python code and are stubborn in code reviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c2ftl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705840279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My first job title in tech was Data Scientist, now I&amp;#39;m officially a Data Engineer, but working somewhere in Data Science/Engineering, MLOps and as a Python Dev.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not claiming to be a good programmer with two and a half years of professional experience, but I think some of our Data Scientists write bad Python code.  &lt;/p&gt;\n\n&lt;p&gt;Here I explain why:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Using generic execptions instead of thinking about what error they really want to catch&lt;/li&gt;\n&lt;li&gt;They try to encapsulate all functions as static methods in classes, even though it&amp;#39;s okay to use free standing functions sometimes&lt;/li&gt;\n&lt;li&gt;They don&amp;#39;t use enums (or don&amp;#39;t know what enums are used for)&lt;/li&gt;\n&lt;li&gt;Sometimes they use bad method names -&amp;gt; they think &lt;code&gt;da_file2tbl_file()&lt;/code&gt; is better than &lt;code&gt;convert_data_asset_to_mltalble()&lt;/code&gt; (What do you think is better?)&lt;/li&gt;\n&lt;li&gt;Overengineering: Use of design patterns with 70 lines of code, although one simple free-standing function with 10 lines would have sufficed (-&amp;gt; but I respect the fact that an effort is made here to learn and try out new things)&lt;/li&gt;\n&lt;li&gt;Use of global variables, although this could easily have been solved with an instance variable or a parameter extension in the method header&lt;/li&gt;\n&lt;li&gt;Too many useless and redundant comments like:&lt;br/&gt;\n&lt;code&gt;# Creating dataframe&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;df = pd.DataFrame(...)&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Use of magic strings/numbers instead of constants&lt;/li&gt;\n&lt;li&gt;etc ...&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What are your experiences with Data Scientists or Data Engineers using Python?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t despise anyone who makes such mistakes, but what&amp;#39;s bad is that some Data Scientists are stubborn and say in code reviews: &amp;quot;But I want to encapsulate all functions as static methods in a class or &amp;quot;I think my 70-line design pattern is better than your 10-code-line function&amp;quot; or &amp;quot;I&amp;#39;d rather use global variables. I don&amp;#39;t want to rewrite the code now.&amp;quot; I find that very annoying. Some people have too big an ego. But code reviews aren&amp;#39;t about being the smartest in the room, they&amp;#39;re about learning from each other and making the product better.  &lt;/p&gt;\n\n&lt;p&gt;Last year I started learning more programming languages. Kotlin and Rust.  I&amp;#39;m working on a personal project in Kotlin to rebuild our machine learning infrastructure and I&amp;#39;m still at tutorial level with Rust.  Both languages are amazing so far and both have already helped me to be a better (Python) programmer. What is your experience? Do you also think that learning more (statically typed) languages makes you a better developer? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19c2ftl", "is_robot_indexable": true, "report_reasons": null, "author": "noisescience", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c2ftl/some_data_scientists_write_bad_python_code_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c2ftl/some_data_scientists_write_bad_python_code_and/", "subreddit_subscribers": 154500, "created_utc": 1705840279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I hopped on board with this new company last month, and turns out they're on a bit of a staff exodus spree. Come next month, it's just gonna be me and two junior engineers left on the engineering team -  not just data engineering but the whole engineering team!! \ud83d\ude2c\n\nThinking of pulling the plug and bouncing to a new gig. As a data engineer, I'll be dealing with numerous data-related questions, but the challenge lies in not having someone to ask why the data is structured in a particular way.\n\nAny of you been in a situation like this? What did you do, and what should I be considering before making my exit?", "author_fullname": "t2_mbbdv7y98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of Bailing on My New Job - Need Some Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19brn6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705800529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I hopped on board with this new company last month, and turns out they&amp;#39;re on a bit of a staff exodus spree. Come next month, it&amp;#39;s just gonna be me and two junior engineers left on the engineering team -  not just data engineering but the whole engineering team!! \ud83d\ude2c&lt;/p&gt;\n\n&lt;p&gt;Thinking of pulling the plug and bouncing to a new gig. As a data engineer, I&amp;#39;ll be dealing with numerous data-related questions, but the challenge lies in not having someone to ask why the data is structured in a particular way.&lt;/p&gt;\n\n&lt;p&gt;Any of you been in a situation like this? What did you do, and what should I be considering before making my exit?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19brn6q", "is_robot_indexable": true, "report_reasons": null, "author": "Kindly-Screen-2557", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19brn6q/thinking_of_bailing_on_my_new_job_need_some_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19brn6q/thinking_of_bailing_on_my_new_job_need_some_advice/", "subreddit_subscribers": 154500, "created_utc": 1705800529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a grad student with 2 YOE working with Snaplogic. I'm trying to get some job opportunity with coding, so i can grad with coding experience, I've always believed that it could open doors in future and make me more employable. \nBut now a recruiter reached me out to work in a Snaplogic project for a foreign financial institution that would pay me 3 times what i currently earn. \n\nIs going deeper into such a tool as Snaplogic going to limit my options in future? \n\nShould i keep focusing on getting a job that requires deeper tech skills?\n\nIs low code a dead end? Will i be stuck in low code forever if i keep working on it?", "author_fullname": "t2_2q0ga84g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is working with Low code ETL tools worth it career wise? (Snaplogic)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bznpt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705829144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a grad student with 2 YOE working with Snaplogic. I&amp;#39;m trying to get some job opportunity with coding, so i can grad with coding experience, I&amp;#39;ve always believed that it could open doors in future and make me more employable. \nBut now a recruiter reached me out to work in a Snaplogic project for a foreign financial institution that would pay me 3 times what i currently earn. &lt;/p&gt;\n\n&lt;p&gt;Is going deeper into such a tool as Snaplogic going to limit my options in future? &lt;/p&gt;\n\n&lt;p&gt;Should i keep focusing on getting a job that requires deeper tech skills?&lt;/p&gt;\n\n&lt;p&gt;Is low code a dead end? Will i be stuck in low code forever if i keep working on it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19bznpt", "is_robot_indexable": true, "report_reasons": null, "author": "meioaesmo", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bznpt/is_working_with_low_code_etl_tools_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bznpt/is_working_with_low_code_etl_tools_worth_it/", "subreddit_subscribers": 154500, "created_utc": 1705829144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I need to collect data from people, I\u2019m presented with countless options:\n\nRetrieval:\n\n* Email me the data,\n* Put the data on a shared drive,\n* Drop the data in an S3 bucket,\n* Create a forum,\n* Give people database access,\n* \u2026\n\nThen comes validation:\n\n* Check the data manually,\n* Automate checking of common issues on the backend,\n* Reject incorrect data immediately from the frontend,\n* \u2026\n\nThen how to handle the results of validation:\n\n* Clean it manually,\n* Attempt to automate cleaning of common issues and attempt to re-validate,\n* Have the user fix the data,\n* \u2026\n\nThen after these you should have your data as expected, ready to be integrated into your platform and used for whatever. Until this point, however, there\u2019s a lot of grey area for me.\n\nRuling the decision is considerations like:\n\n* Corporate culture,\n* Engineers Technical Knowledge,\n* End Users Technical Knowledge,\n* Existing Infrastructure Available,\n* What\u2019s quickest?\n* What\u2019s easiest?\n* What\u2019s securest?\n* What\u2019s most robust to changing requirements?\n* \u2026\n\nand not particularly in that order.\n\nLet\u2019s say you\u2019re developing a new platform for a company filled with nontechnical users. They store things in spreadsheets and have for years, manually maintaining integrity like a bunch of humanoid relational database monsters. Now the company is growing on an order of magnitude, they want a culture shift to manage the growth. They want to have a platform that they can rely on just as they\u2019d relied on their HRDBMs for so long.\n\nSo you have studied their workflow, learned how and why things operate the way they do. You\u2019ve built systems to help lift a lot of the load, but now you find that you\u2019re still manually patching data into the system yourself. \n\nIt\u2019s time to develop a data integration standard. What do you do? How do you standardize this part of the pipeline?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Retrieval From Nontechnical Users - How To Standardize?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bnb55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705788470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I need to collect data from people, I\u2019m presented with countless options:&lt;/p&gt;\n\n&lt;p&gt;Retrieval:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Email me the data,&lt;/li&gt;\n&lt;li&gt;Put the data on a shared drive,&lt;/li&gt;\n&lt;li&gt;Drop the data in an S3 bucket,&lt;/li&gt;\n&lt;li&gt;Create a forum,&lt;/li&gt;\n&lt;li&gt;Give people database access,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then comes validation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Check the data manually,&lt;/li&gt;\n&lt;li&gt;Automate checking of common issues on the backend,&lt;/li&gt;\n&lt;li&gt;Reject incorrect data immediately from the frontend,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then how to handle the results of validation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Clean it manually,&lt;/li&gt;\n&lt;li&gt;Attempt to automate cleaning of common issues and attempt to re-validate,&lt;/li&gt;\n&lt;li&gt;Have the user fix the data,&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then after these you should have your data as expected, ready to be integrated into your platform and used for whatever. Until this point, however, there\u2019s a lot of grey area for me.&lt;/p&gt;\n\n&lt;p&gt;Ruling the decision is considerations like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Corporate culture,&lt;/li&gt;\n&lt;li&gt;Engineers Technical Knowledge,&lt;/li&gt;\n&lt;li&gt;End Users Technical Knowledge,&lt;/li&gt;\n&lt;li&gt;Existing Infrastructure Available,&lt;/li&gt;\n&lt;li&gt;What\u2019s quickest?&lt;/li&gt;\n&lt;li&gt;What\u2019s easiest?&lt;/li&gt;\n&lt;li&gt;What\u2019s securest?&lt;/li&gt;\n&lt;li&gt;What\u2019s most robust to changing requirements?&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;and not particularly in that order.&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say you\u2019re developing a new platform for a company filled with nontechnical users. They store things in spreadsheets and have for years, manually maintaining integrity like a bunch of humanoid relational database monsters. Now the company is growing on an order of magnitude, they want a culture shift to manage the growth. They want to have a platform that they can rely on just as they\u2019d relied on their HRDBMs for so long.&lt;/p&gt;\n\n&lt;p&gt;So you have studied their workflow, learned how and why things operate the way they do. You\u2019ve built systems to help lift a lot of the load, but now you find that you\u2019re still manually patching data into the system yourself. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s time to develop a data integration standard. What do you do? How do you standardize this part of the pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bnb55", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bnb55/data_retrieval_from_nontechnical_users_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bnb55/data_retrieval_from_nontechnical_users_how_to/", "subreddit_subscribers": 154500, "created_utc": 1705788470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys\n\nI've been googling lots of different unit tests/automated testing for ADF pipelines and databricks notebooks (ran in ADF) and I've got a basic idea lined up, but it's got me curious what other professionals in the industry use for testing and what's generally considered best practice for you guys.", "author_fullname": "t2_56o0g58i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you guys prefer to Unit test/automate test ADF pipelines/databricks notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bi0pn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705774669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been googling lots of different unit tests/automated testing for ADF pipelines and databricks notebooks (ran in ADF) and I&amp;#39;ve got a basic idea lined up, but it&amp;#39;s got me curious what other professionals in the industry use for testing and what&amp;#39;s generally considered best practice for you guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bi0pn", "is_robot_indexable": true, "report_reasons": null, "author": "IG-55", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bi0pn/how_do_you_guys_prefer_to_unit_testautomate_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bi0pn/how_do_you_guys_prefer_to_unit_testautomate_test/", "subreddit_subscribers": 154500, "created_utc": 1705774669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Jailer is a tool for database subsetting and relational data browsing](https://github.com/Wisser/Jailer).\n\nIt  creates small slices from your database and lets you navigate through  your database following the relationships.Ideal for creating small  samples of test data or for local problem analysis with relevant  production data.\n\n* The  Subsetter creates small slices from your database (consistent and  referentially intact) as SQL (topologically sorted), DbUnit records or  XML.Ideal for creating small samples of test data or for local problem  analysis with relevant production data.\n* The  Data Browser lets you navigate through your database  following the  relationships (foreign key-based or user-defined) between  tables.\n\nFeatures\n\n* Exports  consistent and referentially intact row-sets from your productive  database and imports the data into your development and test  environment.\n* Improves database performance by removing and archiving obsolete data without violating integrity.\n* Generates topologically sorted SQL-DML, hierarchically structured XML and DbUnit datasets.\n* Data Browsing. Navigate bidirectionally through the database by following foreign-key-based or user-defined relationships.\n* SQL Console with code completion, syntax highlighting and database metadata visualization.\n* A demo database is included with which you can get a first impression without any configuration effort.", "author_fullname": "t2_9om3w9rn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Subsetting and Relational Data Browsing Tool.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bz1je", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705826580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/Wisser/Jailer\"&gt;Jailer is a tool for database subsetting and relational data browsing&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It  creates small slices from your database and lets you navigate through  your database following the relationships.Ideal for creating small  samples of test data or for local problem analysis with relevant  production data.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The  Subsetter creates small slices from your database (consistent and  referentially intact) as SQL (topologically sorted), DbUnit records or  XML.Ideal for creating small samples of test data or for local problem  analysis with relevant production data.&lt;/li&gt;\n&lt;li&gt;The  Data Browser lets you navigate through your database  following the  relationships (foreign key-based or user-defined) between  tables.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Features&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Exports  consistent and referentially intact row-sets from your productive  database and imports the data into your development and test  environment.&lt;/li&gt;\n&lt;li&gt;Improves database performance by removing and archiving obsolete data without violating integrity.&lt;/li&gt;\n&lt;li&gt;Generates topologically sorted SQL-DML, hierarchically structured XML and DbUnit datasets.&lt;/li&gt;\n&lt;li&gt;Data Browsing. Navigate bidirectionally through the database by following foreign-key-based or user-defined relationships.&lt;/li&gt;\n&lt;li&gt;SQL Console with code completion, syntax highlighting and database metadata visualization.&lt;/li&gt;\n&lt;li&gt;A demo database is included with which you can get a first impression without any configuration effort.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?auto=webp&amp;s=7d91f911921103d21536574e4c7377773af0a670", "width": 1071, "height": 877}, "resolutions": [{"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e51c380ca288d5df077a3a384d83f1283af1dfad", "width": 108, "height": 88}, {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=edfda93cb422d3efad77e36b313c8486384fed39", "width": 216, "height": 176}, {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=768bea441c2ed39a7ea1ca358fc0acc1070e7011", "width": 320, "height": 262}, {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5305979fe027b9e970b26afc10bee2b020853c4f", "width": 640, "height": 524}, {"url": "https://external-preview.redd.it/ZP9HnTzK4SCMYpnQ5YwHOo9lycDK6DAhju5S70eqUEw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c8ea989da1ef3be0e3fc570a45fe1e946088ba8", "width": 960, "height": 786}], "variants": {}, "id": "RG-fODuBFpjyJxP9IX0wg2hg36dqvEa-gISyg1_JD2k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "19bz1je", "is_robot_indexable": true, "report_reasons": null, "author": "Apprehensive-Fix-996", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bz1je/database_subsetting_and_relational_data_browsing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bz1je/database_subsetting_and_relational_data_browsing/", "subreddit_subscribers": 154500, "created_utc": 1705826580.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nBased on the current data engineering landscape, I believe most of the data engineering tools that is used by us are outside of the SAP realm. However, I would like to test and understand if this is true. \n\nAre there any data engineers lurking here familiar with tools like SAP Data Services, SAP HANA, SAP BW/4HANA, SAP Data Sphere and SAP Analytics Cloud. Some can argue that these are not standard data engineering tools but it still very capable tools to process and serve the data for their intended purpose. \n\nAlso, is it desirable to get into the SAP ecosystem and work on SAP specific data projects?", "author_fullname": "t2_5b8k9nl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone here working on data engineering roles using SAP tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19byhep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705824283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;Based on the current data engineering landscape, I believe most of the data engineering tools that is used by us are outside of the SAP realm. However, I would like to test and understand if this is true. &lt;/p&gt;\n\n&lt;p&gt;Are there any data engineers lurking here familiar with tools like SAP Data Services, SAP HANA, SAP BW/4HANA, SAP Data Sphere and SAP Analytics Cloud. Some can argue that these are not standard data engineering tools but it still very capable tools to process and serve the data for their intended purpose. &lt;/p&gt;\n\n&lt;p&gt;Also, is it desirable to get into the SAP ecosystem and work on SAP specific data projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19byhep", "is_robot_indexable": true, "report_reasons": null, "author": "scht1980", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19byhep/anyone_here_working_on_data_engineering_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19byhep/anyone_here_working_on_data_engineering_roles/", "subreddit_subscribers": 154500, "created_utc": 1705824283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically the title, if it can be done with Postgres\u2026 is something like rabbitmq worthwhile?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any real benefit to a queue service over a makeshift queue with Postgres for small scale stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19btc8i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705805719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title, if it can be done with Postgres\u2026 is something like rabbitmq worthwhile?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19btc8i", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19btc8i/any_real_benefit_to_a_queue_service_over_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19btc8i/any_real_benefit_to_a_queue_service_over_a/", "subreddit_subscribers": 154500, "created_utc": 1705805719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I need some career advice, please: \n\nI'm currently employed as a Data Analyst for an IT consulting company. However, my recent project involves tasks unrelated to data analytics, focusing more on process mapping and ERP adjustments. Despite expressing my concerns to my manager, they've mentioned that reassignment to a different project is unlikely until 2025.\n\nI've received an offer from a small AIaaS company to work as a Data Analyst within the Data Engineering team, and the role seems very exciting. My ultimate goal is to transition into a Data Engineering role by the end of the year.\n\nThe dilemma is that my current job offers a great salary, extra vacation days, and access to diverse future projects. On the other hand, the startup offer involves a roughly 30% salary cut and no additional vacation days. While I can manage the pay cut since I live with my parents, it's a significant downgrade.\n\nSo, what would you advise? Should I stick with my current job, even though I'm not enjoying it at all, but enjoying the perks while independently learning Data Engineering? Or should I accept the startup offer, taking a pay cut but gaining experience under the Data Engineering team?\n\nThanks in advance for your perspectives. I truly appreciate it.", "author_fullname": "t2_4iz2pipg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice: More interesting job for less money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bqqbe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705797834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I need some career advice, please: &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently employed as a Data Analyst for an IT consulting company. However, my recent project involves tasks unrelated to data analytics, focusing more on process mapping and ERP adjustments. Despite expressing my concerns to my manager, they&amp;#39;ve mentioned that reassignment to a different project is unlikely until 2025.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve received an offer from a small AIaaS company to work as a Data Analyst within the Data Engineering team, and the role seems very exciting. My ultimate goal is to transition into a Data Engineering role by the end of the year.&lt;/p&gt;\n\n&lt;p&gt;The dilemma is that my current job offers a great salary, extra vacation days, and access to diverse future projects. On the other hand, the startup offer involves a roughly 30% salary cut and no additional vacation days. While I can manage the pay cut since I live with my parents, it&amp;#39;s a significant downgrade.&lt;/p&gt;\n\n&lt;p&gt;So, what would you advise? Should I stick with my current job, even though I&amp;#39;m not enjoying it at all, but enjoying the perks while independently learning Data Engineering? Or should I accept the startup offer, taking a pay cut but gaining experience under the Data Engineering team?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your perspectives. I truly appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19bqqbe", "is_robot_indexable": true, "report_reasons": null, "author": "_Lavender_Brown_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bqqbe/career_advice_more_interesting_job_for_less_money/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bqqbe/career_advice_more_interesting_job_for_less_money/", "subreddit_subscribers": 154500, "created_utc": 1705797834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. As is typical (for me at least), I\u2019m looking to garner some insights on approches for a common kind of application before I built one.\n\nI\u2019m going to build an email notification system. Its first set of requirements will be to send out notices a few weeks before some documents expire, unless those documents have been renewed already.\n\nThe source data lives in an excel spreadsheet stored in a shared SharePoint drive. It gets updated at regular intervals by some kind of ghost entity that magically knows when/how to update the data.\n\nMy first thoughts are that I\u2019m going to need to store the document names and their expiration date, as well as a recipient list somewhere that can be polled daily. If the poll finds any records matching the conditions I\u2019ve described, send an email to the documents recipient list. \n\nHowever, I started to wonder if there might be a better approach. For example, maybe the polling service can simply update a `status` column based on how close a document is to expiration. If `status` gets set to `soon to expire`, then a [postgres] `NOTIFY` can get sent to a `LISTEN`ing channel. On the `LISTEN`ing channel, there can be an application that handles these \u201cevent based\u201d emails. This decouples the polling service from the email service, and theoretically the email service can get used for any email.\n\nAfter this, I started to wonder Postgres actually has some built in method to automatically `NOTIFY` if a records `date` column approaches less than X days from current time. I\u2019m doubtful about this, as it just sounds like a built in polling service, or maybe a nasty looking trigger function, but who knows.\n\nFor reference I use Postgres for storage, Prefect for orchestration, Python for the nooks and crannies, \u2026 I want a solution that\u2019s generally applicable though and can get reused for future projects. \n\nWhat\u2019s the typical \u201cgenerally applicable\u201d approach for email notifications? Thanks!", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Common Architectures for Event &amp; Schedule Based Email Notifications System?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bm0w0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705786231.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705785073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. As is typical (for me at least), I\u2019m looking to garner some insights on approches for a common kind of application before I built one.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m going to build an email notification system. Its first set of requirements will be to send out notices a few weeks before some documents expire, unless those documents have been renewed already.&lt;/p&gt;\n\n&lt;p&gt;The source data lives in an excel spreadsheet stored in a shared SharePoint drive. It gets updated at regular intervals by some kind of ghost entity that magically knows when/how to update the data.&lt;/p&gt;\n\n&lt;p&gt;My first thoughts are that I\u2019m going to need to store the document names and their expiration date, as well as a recipient list somewhere that can be polled daily. If the poll finds any records matching the conditions I\u2019ve described, send an email to the documents recipient list. &lt;/p&gt;\n\n&lt;p&gt;However, I started to wonder if there might be a better approach. For example, maybe the polling service can simply update a &lt;code&gt;status&lt;/code&gt; column based on how close a document is to expiration. If &lt;code&gt;status&lt;/code&gt; gets set to &lt;code&gt;soon to expire&lt;/code&gt;, then a [postgres] &lt;code&gt;NOTIFY&lt;/code&gt; can get sent to a &lt;code&gt;LISTEN&lt;/code&gt;ing channel. On the &lt;code&gt;LISTEN&lt;/code&gt;ing channel, there can be an application that handles these \u201cevent based\u201d emails. This decouples the polling service from the email service, and theoretically the email service can get used for any email.&lt;/p&gt;\n\n&lt;p&gt;After this, I started to wonder Postgres actually has some built in method to automatically &lt;code&gt;NOTIFY&lt;/code&gt; if a records &lt;code&gt;date&lt;/code&gt; column approaches less than X days from current time. I\u2019m doubtful about this, as it just sounds like a built in polling service, or maybe a nasty looking trigger function, but who knows.&lt;/p&gt;\n\n&lt;p&gt;For reference I use Postgres for storage, Prefect for orchestration, Python for the nooks and crannies, \u2026 I want a solution that\u2019s generally applicable though and can get reused for future projects. &lt;/p&gt;\n\n&lt;p&gt;What\u2019s the typical \u201cgenerally applicable\u201d approach for email notifications? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bm0w0", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bm0w0/common_architectures_for_event_schedule_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bm0w0/common_architectures_for_event_schedule_based/", "subreddit_subscribers": 154500, "created_utc": 1705785073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(The reason I put urgent is because the deadline for me to choose courses is in 2 days \ud83e\udd72 i know not the best)\n\nHello, I\u2019m a fourth year undergrad student majoring in Statistics and minoring in GIS and Human Geography at a university in Canada and I\u2019m looking to become a data engineer after graduating but I\u2019ll likely start as a data analyst first before transitioning into a DE. \n\nI\u2019m wondering if it would be worth it to take CS courses for an extra 2 semesters to change my Human Geography minor into a CS minor. \n\nThe thing is, CS at my school can be pretty theoretical, and 2 required courses focus on making projects in Java and C which I\u2019m not sure how relevant those languages are for DEs. However, I do have the option of choosing an SQL course and machine learning courses after I complete those required courses so it\u2019s something I\u2019m considering as I assume it is relevant to the data science industry. \n\nHowever, if I\u2019m not gonna really use a lot of things I learn such as math proofs, Java and C  during work then I honestly think those courses might be overkill, but if CS will overall teach me skills that are fundamental to the engineering aspect of DE then I\u2019m willing to just push through and finish the CS minor. I know for a fact that I learn better in classroom settings than on my own so that is also something to consider. \n\nFor those who work as a data engineer, what are the most important languages/technical skills to learn in order to start a career as a DE? I know Python is very important and I\u2019m currently using it a lot in one of my upper year stats courses, but how about languages such as Java or C? I\u2019m already familiar with R and will learn SQL on my own. \n\nIf anyone can provide me insight on the current industry and tips on how to get hired in Canada or the US it would be much appreciated!", "author_fullname": "t2_89iqzb4b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Urgent: Taking 2 extra semesters for a CS Minor as a Stats major?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bhkx4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705784300.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705773551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(The reason I put urgent is because the deadline for me to choose courses is in 2 days \ud83e\udd72 i know not the best)&lt;/p&gt;\n\n&lt;p&gt;Hello, I\u2019m a fourth year undergrad student majoring in Statistics and minoring in GIS and Human Geography at a university in Canada and I\u2019m looking to become a data engineer after graduating but I\u2019ll likely start as a data analyst first before transitioning into a DE. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering if it would be worth it to take CS courses for an extra 2 semesters to change my Human Geography minor into a CS minor. &lt;/p&gt;\n\n&lt;p&gt;The thing is, CS at my school can be pretty theoretical, and 2 required courses focus on making projects in Java and C which I\u2019m not sure how relevant those languages are for DEs. However, I do have the option of choosing an SQL course and machine learning courses after I complete those required courses so it\u2019s something I\u2019m considering as I assume it is relevant to the data science industry. &lt;/p&gt;\n\n&lt;p&gt;However, if I\u2019m not gonna really use a lot of things I learn such as math proofs, Java and C  during work then I honestly think those courses might be overkill, but if CS will overall teach me skills that are fundamental to the engineering aspect of DE then I\u2019m willing to just push through and finish the CS minor. I know for a fact that I learn better in classroom settings than on my own so that is also something to consider. &lt;/p&gt;\n\n&lt;p&gt;For those who work as a data engineer, what are the most important languages/technical skills to learn in order to start a career as a DE? I know Python is very important and I\u2019m currently using it a lot in one of my upper year stats courses, but how about languages such as Java or C? I\u2019m already familiar with R and will learn SQL on my own. &lt;/p&gt;\n\n&lt;p&gt;If anyone can provide me insight on the current industry and tips on how to get hired in Canada or the US it would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19bhkx4", "is_robot_indexable": true, "report_reasons": null, "author": "smol_llama", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bhkx4/urgent_taking_2_extra_semesters_for_a_cs_minor_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bhkx4/urgent_taking_2_extra_semesters_for_a_cs_minor_as/", "subreddit_subscribers": 154500, "created_utc": 1705773551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Diagram as Code](https://i.redd.it/lnjhr11ctsdc1.gif)\n\n&gt;Creating architectural diagrams with traditional graphical tools can be a hassle. Drag-and-drop interfaces are frustrating, achieving perfect alignment is a challenge, and versioning becomes a nightmare. Diagram as Code offers a solution, allowing diagrams to be written with coding precision, versioned like code, and generated effortlessly. This approach simplifies diagramming tasks and brings order to the chaos.\n\nHow to create Diagram using code: [Youtube Video](https://www.youtube.com/watch?v=jCy3jUgN3GQ&amp;t=4s)", "author_fullname": "t2_jjbftfcy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build cloud Architecture Diagrams in 1 Minute (This Tool is Crazy Fast!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "media_metadata": {"lnjhr11ctsdc1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/lnjhr11ctsdc1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=099c32b2c9f2735a41aa419366243ff8ac20a2d4"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/lnjhr11ctsdc1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=720a4fd3f7eb40f69c10141f980eaa95f6020056"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/lnjhr11ctsdc1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=cba64b743218baab3e50696273edff14d288d752"}, {"y": 640, "x": 640, "u": "https://preview.redd.it/lnjhr11ctsdc1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=45bdfb030e158db7b9416de705b67b1bd5ae918e"}], "s": {"y": 900, "gif": "https://i.redd.it/lnjhr11ctsdc1.gif", "mp4": "https://preview.redd.it/lnjhr11ctsdc1.gif?format=mp4&amp;s=703705fb9a3c95c03bd82e0665f1d8e0e47e11a8", "x": 900}, "id": "lnjhr11ctsdc1"}}, "name": "t3_19c3vs0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jCy3jUgN3GQ?start=4&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jCy3jUgN3GQ?start=4&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )\"&gt;&lt;/iframe&gt;", "author_name": "Bitwise learning", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jCy3jUgN3GQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@naveenkumarmurugan1962"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jCy3jUgN3GQ?start=4&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/19c3vs0", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_dwsOCuWDwZNQLjtvvtSvHRz6Gn9JwNfGWb5bbHEB4I.jpg", "edited": 1705845745.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1705845217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/lnjhr11ctsdc1.gif\"&gt;Diagram as Code&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Creating architectural diagrams with traditional graphical tools can be a hassle. Drag-and-drop interfaces are frustrating, achieving perfect alignment is a challenge, and versioning becomes a nightmare. Diagram as Code offers a solution, allowing diagrams to be written with coding precision, versioned like code, and generated effortlessly. This approach simplifies diagramming tasks and brings order to the chaos.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;How to create Diagram using code: &lt;a href=\"https://www.youtube.com/watch?v=jCy3jUgN3GQ&amp;amp;t=4s\"&gt;Youtube Video&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/k2M6UKltaKJ6wL7S__B7keppLO8YDSmwxoscO31p8Y8.jpg?auto=webp&amp;s=e33dc4771e13b4095c3735cd07b83bab85c39662", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/k2M6UKltaKJ6wL7S__B7keppLO8YDSmwxoscO31p8Y8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b41c85a18c622c350b303a5e60ae47983d346a64", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/k2M6UKltaKJ6wL7S__B7keppLO8YDSmwxoscO31p8Y8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7798c962fe38ffcc68ccc3f5c2a950439c5a4119", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/k2M6UKltaKJ6wL7S__B7keppLO8YDSmwxoscO31p8Y8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=22f5339ac5c27b80c3cd6bcc4899fd30bf7c8e5b", "width": 320, "height": 240}], "variants": {}, "id": "1-UvaHhiYPAXq_n4Xu3SwJuFT_taoKGhBzHesfyNP9c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "19c3vs0", "is_robot_indexable": true, "report_reasons": null, "author": "BigNo3623", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c3vs0/build_cloud_architecture_diagrams_in_1_minute/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c3vs0/build_cloud_architecture_diagrams_in_1_minute/", "subreddit_subscribers": 154500, "created_utc": 1705845217.0, "num_crossposts": 2, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jCy3jUgN3GQ?start=4&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Ditch the Drag-and-Drop! Create Perfect Architectural Diagrams with Code ( AI and Diagrams Python )\"&gt;&lt;/iframe&gt;", "author_name": "Bitwise learning", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jCy3jUgN3GQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@naveenkumarmurugan1962"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have the Databricks ML / DE Professional Certifications.\n\nI'm currently a DE wanting to move to a better (higher paying) DE position or an MLE position. How are the certifications regarded by the companies, especially at FAANG? If they are not that well regarded, what else should I be focusing on to transition to an MLE position?", "author_fullname": "t2_sd4utrozl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How valuable are Certifications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19c3sst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705844965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have the Databricks ML / DE Professional Certifications.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a DE wanting to move to a better (higher paying) DE position or an MLE position. How are the certifications regarded by the companies, especially at FAANG? If they are not that well regarded, what else should I be focusing on to transition to an MLE position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "19c3sst", "is_robot_indexable": true, "report_reasons": null, "author": "asozers", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c3sst/how_valuable_are_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19c3sst/how_valuable_are_certifications/", "subreddit_subscribers": 154500, "created_utc": 1705844965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vbapbjo8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kedro Projects and Iris Dataset Starter example", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_19c1op1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/tG9Ksv5s50k?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Kedro Projects and Iris Dataset Starter example\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Kedro Projects and Iris Dataset Starter example", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/tG9Ksv5s50k?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Kedro Projects and Iris Dataset Starter example\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/tG9Ksv5s50k/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/tG9Ksv5s50k?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Kedro Projects and Iris Dataset Starter example\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/19c1op1", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7QaN0QrhB-T5oQ-H3Zqi5Z7LmNjSbblYKQjKwnloDjA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705837449.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/tG9Ksv5s50k?si=QfudwxhB2wn9ud8T", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PVUKEL-2idyxm_vl252xQml8TfxOUzLPXmmzxA5Vuuc.jpg?auto=webp&amp;s=1ead3f4f34e605fb7f01260fd5b48d24b5168226", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/PVUKEL-2idyxm_vl252xQml8TfxOUzLPXmmzxA5Vuuc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8f4129690ca06078d8ace6c76b2981bb9de3643f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/PVUKEL-2idyxm_vl252xQml8TfxOUzLPXmmzxA5Vuuc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dea94267e2882dd052e8e91eb50484b20c8fa877", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/PVUKEL-2idyxm_vl252xQml8TfxOUzLPXmmzxA5Vuuc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5fc6a97118ae8bd399fc50855bb5d94fc721f26b", "width": 320, "height": 240}], "variants": {}, "id": "JKTBtUe5PSZ-URCxdz3wwm-xLuNhjGbUL-TsD_8e_Ck"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19c1op1", "is_robot_indexable": true, "report_reasons": null, "author": "dnulcon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19c1op1/kedro_projects_and_iris_dataset_starter_example/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/tG9Ksv5s50k?si=QfudwxhB2wn9ud8T", "subreddit_subscribers": 154500, "created_utc": 1705837449.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Kedro Projects and Iris Dataset Starter example", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/tG9Ksv5s50k?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Kedro Projects and Iris Dataset Starter example\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/tG9Ksv5s50k/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the data space there is this new movement of ZeroETL (started by AWS) that advocates the replacement of traditional data movement pipelines (generally implemented using Spark and Airflow) with real-time CDC replication. What is your take on it ? Did anyone fully implemented it ?", "author_fullname": "t2_5efs1s7d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZeroETL vs. Pipelines, Jobs, Schedules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bx9w9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705819472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the data space there is this new movement of ZeroETL (started by AWS) that advocates the replacement of traditional data movement pipelines (generally implemented using Spark and Airflow) with real-time CDC replication. What is your take on it ? Did anyone fully implemented it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bx9w9", "is_robot_indexable": true, "report_reasons": null, "author": "matteopelati76", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bx9w9/zeroetl_vs_pipelines_jobs_schedules/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bx9w9/zeroetl_vs_pipelines_jobs_schedules/", "subreddit_subscribers": 154500, "created_utc": 1705819472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, \nLong story short-  I am trying to switch companies as i think i am going to be put into PIP at a FAANG. I have 2 years of experience as a data engineer. What other good companies that i can apply to? I know the market is pretty bad now a days but i wanna target and try applying to some good companies as well. I work in India. \n1. I always wanted to work in European companies. Is there a chance now given current market? If yes how do i do it. Just go to company\u2019s career site and apply or is there someother way?\n2. I also know that trying to work elsewhere is not very optimal rn . Even in India i would like to get some good data engineer companies.\nPlease let me know if anyone has any ideas or suggestions.", "author_fullname": "t2_nusmz3fhp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with companies shortlisting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bvcjk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705812532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, \nLong story short-  I am trying to switch companies as i think i am going to be put into PIP at a FAANG. I have 2 years of experience as a data engineer. What other good companies that i can apply to? I know the market is pretty bad now a days but i wanna target and try applying to some good companies as well. I work in India. \n1. I always wanted to work in European companies. Is there a chance now given current market? If yes how do i do it. Just go to company\u2019s career site and apply or is there someother way?\n2. I also know that trying to work elsewhere is not very optimal rn . Even in India i would like to get some good data engineer companies.\nPlease let me know if anyone has any ideas or suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19bvcjk", "is_robot_indexable": true, "report_reasons": null, "author": "mad_peace", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bvcjk/need_help_with_companies_shortlisting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bvcjk/need_help_with_companies_shortlisting/", "subreddit_subscribers": 154500, "created_utc": 1705812532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company wants to organize our data in Databricks and I have been looking at some documentation on best practices for directory structures. \n\nOne of the documentations suggested: \u201cCatalogs often mirror organizational units or software development lifecycle scopes. You may choose, for example, to have a catalog for production data and a catalog for development data\u201d \n\nI\u2019ve read in many articles that there should be a catalog for dev, prod, stage, etc\u2026 and one schema for each of the Bronze, Silver, and Gold medallion structures.\n\nHere\u2019s what my company has in place at the moment:\n\n* We have different workspaces for test, dev, and prod (for example, dev\\_us\\_west, prod\\_us\\_west, test\\_us\\_east, test\\_uk,...) \n* In our current setup, catalogs within each workspace represent individual projects. For example, demand\\_forecast, sales\\_prediction,... \n* The schemas group related tables. For example, inside the demand\\_forecast catalog, there are the following schemas: \u2018customers\u2019, and \u2018products\u2019. The \u2018customers\u2019 schema contains tables like churn (raw, untransformed) and customer\\_preference (transformed). And the \u2018products\u2019 schema contains tables like prices (raw), reviews (raw)\n* The way it works right now is if someone has a project that only needs some analysis and doesn't involve pushing codes into production, they will go into the test workspace. There, they can create a catalog for that project, and create the necessary schemas and tables. If someone needs to create a model that will be used in production, they will use the prod workspace and create a catalog for their project there. \n* I\u2019ve read that \u201c*Databricks no longer recommends mounting external data locations to Databricks Filesystem\u201d.* Right now, the way that we load files into Databricks is by using DBFS S3 bucket mount points. In the future, we would want to switch to using volumes to store unstructured data. Right now, each sub-directory in our S3 bucket contains files related to a project. \n\nI\u2019m not from a Data Engineering background and am not very experienced with Unity Catalog. Could you recommend best practices for isolating and organizing data using workspaces, catalogs, schemas, and volumes? \n\nThank you in advance!", "author_fullname": "t2_8rwu4pz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing data and setting up directory structures for Databricks Unity Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bnqyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705789663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company wants to organize our data in Databricks and I have been looking at some documentation on best practices for directory structures. &lt;/p&gt;\n\n&lt;p&gt;One of the documentations suggested: \u201cCatalogs often mirror organizational units or software development lifecycle scopes. You may choose, for example, to have a catalog for production data and a catalog for development data\u201d &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve read in many articles that there should be a catalog for dev, prod, stage, etc\u2026 and one schema for each of the Bronze, Silver, and Gold medallion structures.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s what my company has in place at the moment:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We have different workspaces for test, dev, and prod (for example, dev_us_west, prod_us_west, test_us_east, test_uk,...) &lt;/li&gt;\n&lt;li&gt;In our current setup, catalogs within each workspace represent individual projects. For example, demand_forecast, sales_prediction,... &lt;/li&gt;\n&lt;li&gt;The schemas group related tables. For example, inside the demand_forecast catalog, there are the following schemas: \u2018customers\u2019, and \u2018products\u2019. The \u2018customers\u2019 schema contains tables like churn (raw, untransformed) and customer_preference (transformed). And the \u2018products\u2019 schema contains tables like prices (raw), reviews (raw)&lt;/li&gt;\n&lt;li&gt;The way it works right now is if someone has a project that only needs some analysis and doesn&amp;#39;t involve pushing codes into production, they will go into the test workspace. There, they can create a catalog for that project, and create the necessary schemas and tables. If someone needs to create a model that will be used in production, they will use the prod workspace and create a catalog for their project there. &lt;/li&gt;\n&lt;li&gt;I\u2019ve read that \u201c&lt;em&gt;Databricks no longer recommends mounting external data locations to Databricks Filesystem\u201d.&lt;/em&gt; Right now, the way that we load files into Databricks is by using DBFS S3 bucket mount points. In the future, we would want to switch to using volumes to store unstructured data. Right now, each sub-directory in our S3 bucket contains files related to a project. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m not from a Data Engineering background and am not very experienced with Unity Catalog. Could you recommend best practices for isolating and organizing data using workspaces, catalogs, schemas, and volumes? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19bnqyq", "is_robot_indexable": true, "report_reasons": null, "author": "lunalita_99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bnqyq/organizing_data_and_setting_up_directory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bnqyq/organizing_data_and_setting_up_directory/", "subreddit_subscribers": 154500, "created_utc": 1705789663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI'm currently working on a project that involves creating a searchable database. As the database is expected to grow into millions of records with titles, description and others, I'm looking for an efficient and scalable search engine solution.\n\nHere's a brief overview of my requirements:\n\n* **Data Size**: The database will contain millions of records.\n* **Functionality**: I need to aggregate and deduplicate search results from multiple queries. Each user can have multiple favorite search queries, and I want to provide a personalized feed based on these queries.\n* **Challenges**:\n   * Some queries might return thousands of results.\n   * The aggregated results need to be sorted globally (e.g., by date or relevance).\n   * The aggregated results should possibly be filtered by columns like filestypes\\[\\] and is\\_free\n   * The solution needs to be efficient and scalable to handle the increasing data size and query load.\n   * The solution needs to be selfhosted.\n\n**Current Approach**: I'm currently considering using Typesense for its simplicity and speed, but I'm open to other solutions that might better suit my needs, especially considering the need for efficient multi-query aggregation and global sorting of results.\n\nI would appreciate any suggestions or insights on:\n\n* Which search engines you would recommend for this use case.\n* Strategies for efficiently aggregating and deduplicating results from multiple queries.\n* Any other considerations or tips for managing large-scale search operations.\n\nThank you in advance for your help!\n\nBtw. if there are subreddits that are more suitable for my question please let me know.", "author_fullname": "t2_xfhxx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for a Scalable Search Engine for Aggregating Results from Multiple Queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bghjl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705770638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on a project that involves creating a searchable database. As the database is expected to grow into millions of records with titles, description and others, I&amp;#39;m looking for an efficient and scalable search engine solution.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a brief overview of my requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data Size&lt;/strong&gt;: The database will contain millions of records.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Functionality&lt;/strong&gt;: I need to aggregate and deduplicate search results from multiple queries. Each user can have multiple favorite search queries, and I want to provide a personalized feed based on these queries.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Challenges&lt;/strong&gt;:\n\n&lt;ul&gt;\n&lt;li&gt;Some queries might return thousands of results.&lt;/li&gt;\n&lt;li&gt;The aggregated results need to be sorted globally (e.g., by date or relevance).&lt;/li&gt;\n&lt;li&gt;The aggregated results should possibly be filtered by columns like filestypes[] and is_free&lt;/li&gt;\n&lt;li&gt;The solution needs to be efficient and scalable to handle the increasing data size and query load.&lt;/li&gt;\n&lt;li&gt;The solution needs to be selfhosted.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Current Approach&lt;/strong&gt;: I&amp;#39;m currently considering using Typesense for its simplicity and speed, but I&amp;#39;m open to other solutions that might better suit my needs, especially considering the need for efficient multi-query aggregation and global sorting of results.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any suggestions or insights on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Which search engines you would recommend for this use case.&lt;/li&gt;\n&lt;li&gt;Strategies for efficiently aggregating and deduplicating results from multiple queries.&lt;/li&gt;\n&lt;li&gt;Any other considerations or tips for managing large-scale search operations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n\n&lt;p&gt;Btw. if there are subreddits that are more suitable for my question please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "19bghjl", "is_robot_indexable": true, "report_reasons": null, "author": "LarsSorensen", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bghjl/suggestions_for_a_scalable_search_engine_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bghjl/suggestions_for_a_scalable_search_engine_for/", "subreddit_subscribers": 154500, "created_utc": 1705770638.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you\u2026\n\n- currently use a data lakehouse\n\n- if so, do you like it?\n\n- if not, do you want to?\n\n- if not, why not?\n\n(Data lakehouse = doing more analytics from your data lake using table formats like iceberg/delta/hudi to use the lake more like a traditional warehouse)", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you data lakehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bcijh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.47, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705759623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you\u2026&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;currently use a data lakehouse&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;if so, do you like it?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;if not, do you want to?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;if not, why not?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;(Data lakehouse = doing more analytics from your data lake using table formats like iceberg/delta/hudi to use the lake more like a traditional warehouse)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "19bcijh", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/19bcijh/do_you_data_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/19bcijh/do_you_data_lakehouse/", "subreddit_subscribers": 154500, "created_utc": 1705759623.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}