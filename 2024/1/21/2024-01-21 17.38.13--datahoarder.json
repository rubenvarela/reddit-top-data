{"kind": "Listing", "data": {"after": "t3_19bkwhg", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a group of friends who are into the Soulseek thing, Hi-Fi rips and scans of obscure music. I would like to host a media server to hold all of their great digitizations, for downloading and/or streaming.I don\u2019t know exactly how much they have, but probably more than 3TB. I have amassed a lot of hardware from the ewaste recycling center I used to work at once we liquidated. The attached picture is most of my horde of storage devices. I have:\n- Four Lenovo Thinkcentres. Two have a 256GB SSD and two have a 512GB SSD. All four also have a 16GB intel optane drive.\n- Five 128GB SATA m.2 SSDs\n- Four 256Gb SATA m.2 SSDs\n- Two 2.5\u201d 320GB HDDs\n- Two 2.5\u201d 240GB HDDs\n- Three 3.5\u201d 1TB HDDs\n- One 1TB m.2 NVMe SSD\n- Some other small SSDs and HDDs that are &lt;100GB\n\nI also have many laptops and a spare desktop. A Lenovo Thinkcentre M83, which only has room for one 3.5\u201d drive. and the thinkpads I have only have one 2.5\u201d bay, an mSATA port inside, and the SATA slot where the DVD drive goes that I could cram another drive into if I wanted.\n\nIf it\u2019s not clear already, most of this stuff is varying levels of used. And a majority of the drives are small capacities. I don\u2019t really know what to do with all of these, how to bring them together into a formation that can store terabytes of data with either redundancy or backups. I could just go buy a couple new 4TB hard drives and a PC to throw them into, but then I\u2019m just spending more money and buying more hardware, which you can understand I would like to avoid. I want to use what I have. I have a couple network switches and routers too, by the way. I appreciate any advice you have to give a technomaniac like me.", "author_fullname": "t2_n1wnr2p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardware hoarder looking to make a robust storage server from what I have around", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_19bk69d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 138, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 138, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PCR_2CwSp0flQdK7VCHbo8shvhtlCA2Tb3w8IYeJxIc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705780232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a group of friends who are into the Soulseek thing, Hi-Fi rips and scans of obscure music. I would like to host a media server to hold all of their great digitizations, for downloading and/or streaming.I don\u2019t know exactly how much they have, but probably more than 3TB. I have amassed a lot of hardware from the ewaste recycling center I used to work at once we liquidated. The attached picture is most of my horde of storage devices. I have:\n- Four Lenovo Thinkcentres. Two have a 256GB SSD and two have a 512GB SSD. All four also have a 16GB intel optane drive.\n- Five 128GB SATA m.2 SSDs\n- Four 256Gb SATA m.2 SSDs\n- Two 2.5\u201d 320GB HDDs\n- Two 2.5\u201d 240GB HDDs\n- Three 3.5\u201d 1TB HDDs\n- One 1TB m.2 NVMe SSD\n- Some other small SSDs and HDDs that are &amp;lt;100GB&lt;/p&gt;\n\n&lt;p&gt;I also have many laptops and a spare desktop. A Lenovo Thinkcentre M83, which only has room for one 3.5\u201d drive. and the thinkpads I have only have one 2.5\u201d bay, an mSATA port inside, and the SATA slot where the DVD drive goes that I could cram another drive into if I wanted.&lt;/p&gt;\n\n&lt;p&gt;If it\u2019s not clear already, most of this stuff is varying levels of used. And a majority of the drives are small capacities. I don\u2019t really know what to do with all of these, how to bring them together into a formation that can store terabytes of data with either redundancy or backups. I could just go buy a couple new 4TB hard drives and a PC to throw them into, but then I\u2019m just spending more money and buying more hardware, which you can understand I would like to avoid. I want to use what I have. I have a couple network switches and routers too, by the way. I appreciate any advice you have to give a technomaniac like me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/avx3ujpegndc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?auto=webp&amp;s=5fa37619b117ebeb79b52b8f83e96a59e41bd434", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2fea6e24b6ab60246566fbb50b9f519c7376f6b7", "width": 108, "height": 81}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e672da4d220447a83464a1d88d8035801a62c2b", "width": 216, "height": 162}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4d4a06a8a825e31eeaeef137db8f92cab388b1d5", "width": 320, "height": 240}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=52d6fac7cdac93908c196c8dff2f574e982eeafb", "width": 640, "height": 480}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e647135c4239e0ddf4562e7ce3a987a1542bed35", "width": 960, "height": 720}, {"url": "https://preview.redd.it/avx3ujpegndc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1c77438dae9a12b88523525bfb27dfed8fecdd6", "width": 1080, "height": 810}], "variants": {}, "id": "S1IeJhkO7Ij_BryvFsi45XRxKAoDWm3X0ou9HCDgBZA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bk69d", "is_robot_indexable": true, "report_reasons": null, "author": "type9freak", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bk69d/hardware_hoarder_looking_to_make_a_robust_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/avx3ujpegndc1.jpeg", "subreddit_subscribers": 726927, "created_utc": 1705780232.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_poc45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody know of a resource explaining the differences between these checksum algorithms at a fairly basic level (pros, cons, etc)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_19c1i83", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pgaxQYNaszskmUFYuj8pN7AKq_qQSMuaVFDeUQKq4Ws.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705836721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rvosn91b4sdc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rvosn91b4sdc1.png?auto=webp&amp;s=210dd504440e5659069f03f6ac07b97d7a9e880a", "width": 978, "height": 657}, "resolutions": [{"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=93631ac6ed38c35554d2812b1ad097e19f3f697a", "width": 108, "height": 72}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=da02ebe634c43acf9800f9bbaeadc7d22501ce0a", "width": 216, "height": 145}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fb03d6e74e89a408d7dbf4a2b6140877ea9f9f22", "width": 320, "height": 214}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5aee88d10b3efc41876da9f802ae6ebaca63c6c", "width": 640, "height": 429}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=06e3d410e75b4ccc402b66068b75503f7f444580", "width": 960, "height": 644}], "variants": {}, "id": "aNxWOGfGK9il-LQFREbw-rVJ_dUzpvkQiVEhK9Jd5ho"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c1i83", "is_robot_indexable": true, "report_reasons": null, "author": "danielrosehill", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c1i83/anybody_know_of_a_resource_explaining_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rvosn91b4sdc1.png", "subreddit_subscribers": 726927, "created_utc": 1705836721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to share one of my backup drives with a friend. He told me it needs to be encrypted to store it in his house. I do trust him but he wants the data encrypted. I said fine with me. It's just medical and financial records as well as families movies like Christmas mornings. \n\nThe problem is that while my Linux desktop could always decrypt the drives with my gpg key or password. I'm trying to plan on a situation where something bad happens and I can't access the computer. Maybe I forget the password or something like that. \n\nI thought about buying a cheap waterproof USB drive and just burying it someplace.", "author_fullname": "t2_dui3ih3xt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for backing up keys and passwords of backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19brvds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705801182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to share one of my backup drives with a friend. He told me it needs to be encrypted to store it in his house. I do trust him but he wants the data encrypted. I said fine with me. It&amp;#39;s just medical and financial records as well as families movies like Christmas mornings. &lt;/p&gt;\n\n&lt;p&gt;The problem is that while my Linux desktop could always decrypt the drives with my gpg key or password. I&amp;#39;m trying to plan on a situation where something bad happens and I can&amp;#39;t access the computer. Maybe I forget the password or something like that. &lt;/p&gt;\n\n&lt;p&gt;I thought about buying a cheap waterproof USB drive and just burying it someplace.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19brvds", "is_robot_indexable": true, "report_reasons": null, "author": "sir_topham_biff", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19brvds/ideas_for_backing_up_keys_and_passwords_of_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19brvds/ideas_for_backing_up_keys_and_passwords_of_backups/", "subreddit_subscribers": 726927, "created_utc": 1705801182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello.\n\nI recently got a set of new SSDs for my NAS to replace my current HDDs. I got a bit overanxious about write cycles for flash storage. For example, I bought Kingston DC600M which have a pretty high TBW rating.\n\nYet, I am still worried. The thing that currently worries me is that the filesystem or some usage pattern might bombard the same flash cell over and over again by rewriting the same block. I even wrote a small test suite that records the pattern of used blocks when executing some IO benchmarks.\n\nAfter reading a bit more online, I figured that all the testing might have been irrelevant. The SSD controller will remap logical blocks (as addressed by the host system) to physical blocks. It might even move data around to other blocks. All this happens hidden from the host system. The only indicator it needs, is which blocks are currently unused, so it can move data there. This happens via trim/discard which all modern systems seem to support.\n\nIs my understanding correct and unequal flash wear is basically not an issue with SSDs? Even if rewriting the same logical block over and over again, it will not hit the same flash cell, but the controlle will move it to different physical blocks to make sure they all get the same write cycles?\n\nThank you!", "author_fullname": "t2_6b78jyrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do SSD controllers move blocks around to equalize flash wear?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bigol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705775808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I recently got a set of new SSDs for my NAS to replace my current HDDs. I got a bit overanxious about write cycles for flash storage. For example, I bought Kingston DC600M which have a pretty high TBW rating.&lt;/p&gt;\n\n&lt;p&gt;Yet, I am still worried. The thing that currently worries me is that the filesystem or some usage pattern might bombard the same flash cell over and over again by rewriting the same block. I even wrote a small test suite that records the pattern of used blocks when executing some IO benchmarks.&lt;/p&gt;\n\n&lt;p&gt;After reading a bit more online, I figured that all the testing might have been irrelevant. The SSD controller will remap logical blocks (as addressed by the host system) to physical blocks. It might even move data around to other blocks. All this happens hidden from the host system. The only indicator it needs, is which blocks are currently unused, so it can move data there. This happens via trim/discard which all modern systems seem to support.&lt;/p&gt;\n\n&lt;p&gt;Is my understanding correct and unequal flash wear is basically not an issue with SSDs? Even if rewriting the same logical block over and over again, it will not hit the same flash cell, but the controlle will move it to different physical blocks to make sure they all get the same write cycles?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bigol", "is_robot_indexable": true, "report_reasons": null, "author": "thomas001le", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bigol/do_ssd_controllers_move_blocks_around_to_equalize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bigol/do_ssd_controllers_move_blocks_around_to_equalize/", "subreddit_subscribers": 726927, "created_utc": 1705775808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nWanted to seek some advice. I am scanning all the documents I have / will get and saving them locally and on the cloud. (Redundancy.)  But all the scanners are always so slow, I have a HUGE pile, and the printer/scanner I have now takes about 30 seconds for 1 side of a single paper. (Please come and save me) I currently have an HP DeskJet 2734e, which I no longer print so stopped paying for the service. Little did I know that would make me unable to print NOR use the scanner....\n\n&amp;#x200B;\n\nWhat am I looking for?\n\n* A scanner. \n   * It can be an all-in-one printer but if it requires a paid service, I will ignore it lol.\n* Preferably quick but maintains the quality.\n* Can be saved as PDF or JPG.\n* Does not cost an arm and a leg.\n* Highly prefer to be connected to Wi-Fi (or Bluetooth) but if it costs less to use cable, I will deal with it.\n\nAdditional Information\n\n* Some are one-sided, and some are double-sided.\n* Some have mutliple pages.\n* Some have multiple pages. that are one-sided and double-sided. -\\_-\n\n&amp;#x200B;\n\nThank you in advance for any suggestions!!!", "author_fullname": "t2_o4hbhngt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast Scanner W/O Printer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19blxon", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705784844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Wanted to seek some advice. I am scanning all the documents I have / will get and saving them locally and on the cloud. (Redundancy.)  But all the scanners are always so slow, I have a HUGE pile, and the printer/scanner I have now takes about 30 seconds for 1 side of a single paper. (Please come and save me) I currently have an HP DeskJet 2734e, which I no longer print so stopped paying for the service. Little did I know that would make me unable to print NOR use the scanner....&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What am I looking for?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A scanner. \n\n&lt;ul&gt;\n&lt;li&gt;It can be an all-in-one printer but if it requires a paid service, I will ignore it lol.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Preferably quick but maintains the quality.&lt;/li&gt;\n&lt;li&gt;Can be saved as PDF or JPG.&lt;/li&gt;\n&lt;li&gt;Does not cost an arm and a leg.&lt;/li&gt;\n&lt;li&gt;Highly prefer to be connected to Wi-Fi (or Bluetooth) but if it costs less to use cable, I will deal with it.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Additional Information&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Some are one-sided, and some are double-sided.&lt;/li&gt;\n&lt;li&gt;Some have mutliple pages.&lt;/li&gt;\n&lt;li&gt;Some have multiple pages. that are one-sided and double-sided. -_-&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any suggestions!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19blxon", "is_robot_indexable": true, "report_reasons": null, "author": "Jordanbr25", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19blxon/fast_scanner_wo_printer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19blxon/fast_scanner_wo_printer/", "subreddit_subscribers": 726927, "created_utc": 1705784844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Do you physically destroy them at home and toss the pieces into trash? Go to a place that have drive shredders (can't find many around my location)?\n\nThank you for reading and hopefully answering soon. :)", "author_fullname": "t2_4a27h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do with your personal home dead/broken storage drives (e.g., old HDDs) that you want to get rid of?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19c6x2a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705853900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you physically destroy them at home and toss the pieces into trash? Go to a place that have drive shredders (can&amp;#39;t find many around my location)?&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading and hopefully answering soon. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Where's the big floppy disk(ette) flair? :P", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c6x2a", "is_robot_indexable": true, "report_reasons": null, "author": "antdude", "discussion_type": null, "num_comments": 13, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19c6x2a/what_do_you_do_with_your_personal_home_deadbroken/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c6x2a/what_do_you_do_with_your_personal_home_deadbroken/", "subreddit_subscribers": 726927, "created_utc": 1705853900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello.\nI've been trying to manage my library for years without success.\nI have photos, backups of these photos, copies with different names, some of them with fucked date metadata...\n\nI wonder if there is a software that finds duplicates, and keep ALL metadata merged, picking the oldest date available for example.\n\nCan you guide me to start organizing this mess?\nI would be happy renaming all files with it's date\n\nIm talking about 500.000 files aprox.\n\nI'm using Windows 10\n\nThank you!", "author_fullname": "t2_b969b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need photo/video management help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c29y2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705840492.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705839687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.\nI&amp;#39;ve been trying to manage my library for years without success.\nI have photos, backups of these photos, copies with different names, some of them with fucked date metadata...&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is a software that finds duplicates, and keep ALL metadata merged, picking the oldest date available for example.&lt;/p&gt;\n\n&lt;p&gt;Can you guide me to start organizing this mess?\nI would be happy renaming all files with it&amp;#39;s date&lt;/p&gt;\n\n&lt;p&gt;Im talking about 500.000 files aprox.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Windows 10&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c29y2", "is_robot_indexable": true, "report_reasons": null, "author": "smaiderman", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c29y2/i_need_photovideo_management_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c29y2/i_need_photovideo_management_help/", "subreddit_subscribers": 726927, "created_utc": 1705839687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been archiving data onto BD-R discs since summer 2010 and placing the discs in standard CD binders in a cabinet.  Personally I have not noticed any corruption anytime I've had to pull data off these discs.   I have been using PlexDisc 633-214's since 2016, before that Memorex 98499 and 97854's and Rosewill SB-25I.\n\nI'm wondering what your experience has been.\n\nI agree that HDDs are cheap but I don't think they're that cheap, plus having everything on spinning rust is a bad idea, and the cloud isn't really suitable in my case.", "author_fullname": "t2_xjkyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What has your experience been with long-term data reliability on Blu-Ray discs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bkppo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705781635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been archiving data onto BD-R discs since summer 2010 and placing the discs in standard CD binders in a cabinet.  Personally I have not noticed any corruption anytime I&amp;#39;ve had to pull data off these discs.   I have been using PlexDisc 633-214&amp;#39;s since 2016, before that Memorex 98499 and 97854&amp;#39;s and Rosewill SB-25I.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what your experience has been.&lt;/p&gt;\n\n&lt;p&gt;I agree that HDDs are cheap but I don&amp;#39;t think they&amp;#39;re that cheap, plus having everything on spinning rust is a bad idea, and the cloud isn&amp;#39;t really suitable in my case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "19bkppo", "is_robot_indexable": true, "report_reasons": null, "author": "AnthillOmbudsman", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bkppo/what_has_your_experience_been_with_longterm_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bkppo/what_has_your_experience_been_with_longterm_data/", "subreddit_subscribers": 726927, "created_utc": 1705781635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://www.techradar.com/pro/seagate-launches-biggest-hard-drive-ever-30tb-exos-mozaic-3-hdd-can-store-more-than-1000-blu-ray-movies-and-yes-everyone-will-be-able-to-buy-them", "author_fullname": "t2_x843n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "30Tb HDD, what you think about this SMR+HAMR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bh7v5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705772594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.techradar.com/pro/seagate-launches-biggest-hard-drive-ever-30tb-exos-mozaic-3-hdd-can-store-more-than-1000-blu-ray-movies-and-yes-everyone-will-be-able-to-buy-them\"&gt;https://www.techradar.com/pro/seagate-launches-biggest-hard-drive-ever-30tb-exos-mozaic-3-hdd-can-store-more-than-1000-blu-ray-movies-and-yes-everyone-will-be-able-to-buy-them&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/N9TGcJ82SXeRy7o7lqpuOkFQcCmmxpG7-SwnmNWX4qI.jpg?auto=webp&amp;s=bb080b1615a14d810da3df814e653ee8952cca33", "width": 1062, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/N9TGcJ82SXeRy7o7lqpuOkFQcCmmxpG7-SwnmNWX4qI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7bb4d1479edaffc981ccf654212f12439b6d3d6b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/N9TGcJ82SXeRy7o7lqpuOkFQcCmmxpG7-SwnmNWX4qI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=76c702fd3af7931aea505df00026045f319a07d8", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/N9TGcJ82SXeRy7o7lqpuOkFQcCmmxpG7-SwnmNWX4qI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6047168a7499b4a922abd3ecc6e7626fbfee7232", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/N9TGcJ82SXeRy7o7lqpuOkFQcCmmxpG7-SwnmNWX4qI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eaf3c3c891a049783b6c0e2da6314ea0d411fd71", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/N9TGcJ82SXeRy7o7lqpuOkFQcCmmxpG7-SwnmNWX4qI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ea12d1fea108308a11c08e54a2ae98beec3cb964", "width": 960, "height": 540}], "variants": {}, "id": "LgXYL2gu0ZFIAdFJXhnWW9eF1vfgGxhJSslel--Ny2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bh7v5", "is_robot_indexable": true, "report_reasons": null, "author": "838Joel", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bh7v5/30tb_hdd_what_you_think_about_this_smrhamr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bh7v5/30tb_hdd_what_you_think_about_this_smrhamr/", "subreddit_subscribers": 726927, "created_utc": 1705772594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_13ryag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will this feature help you with organizing your notes? - Tag Suggestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_19c7kmb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/9s6d82c3hrdc1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/9s6d82c3hrdc1/DASH_96.mp4", "dash_url": "https://v.redd.it/9s6d82c3hrdc1/DASHPlaylist.mpd?a=1708450693%2CMzJiYzhmMjdmNmFjM2NjZWQxMjkwNDM2MDY3ZjRmYTY2NGUzMDg4Yjk2YmU0ZGQzNTJjMzEzMjQ1OTc1NThhNg%3D%3D&amp;v=1&amp;f=sd", "duration": 3, "hls_url": "https://v.redd.it/9s6d82c3hrdc1/HLSPlaylist.m3u8?a=1708450693%2CYmJkZGNiY2JkNTM0NzY3ZWNjMmZhNTY5NmFmYWI0NzVkOTMyM2JhYjU1OGVlNTdjYmNlZmQ1NjdlMDM4ZjE4Mw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2ce806b5d8375d560cb3f86288caf8cec06bf417", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705855625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/9s6d82c3hrdc1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_.png?format=pjpg&amp;auto=webp&amp;s=b39a1cc406115ef69e617f5184f60f81ba5dd74d", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6a4f4c7e651fc009d8eabf506684b29e0740b449", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=1621ffb5715497d2a4b72be36fb72e93bbcc6e3f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=753aca1293569b5000619781543a3036ee7b8df1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=390482e158c33309b439c51fcbb7e9242a308bc9", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=d12729a091458ff0431d79737e226de9482acb4d", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b8bce4e61c4ce9be6207142a98f6fee2e62af928", "width": 1080, "height": 607}], "variants": {}, "id": "bTJxcnFzZGVvdGRjMd8bmiKwLUPl4HLQkbIT3uMwHwe1oVWLSjBJq_8Mt6h_"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "19c7kmb", "is_robot_indexable": true, "report_reasons": null, "author": "anh690136", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c7kmb/will_this_feature_help_you_with_organizing_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/9s6d82c3hrdc1", "subreddit_subscribers": 726927, "created_utc": 1705855625.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/9s6d82c3hrdc1/DASH_1080.mp4?source=fallback", "has_audio": true, "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/9s6d82c3hrdc1/DASH_96.mp4", "dash_url": "https://v.redd.it/9s6d82c3hrdc1/DASHPlaylist.mpd?a=1708450693%2CMzJiYzhmMjdmNmFjM2NjZWQxMjkwNDM2MDY3ZjRmYTY2NGUzMDg4Yjk2YmU0ZGQzNTJjMzEzMjQ1OTc1NThhNg%3D%3D&amp;v=1&amp;f=sd", "duration": 3, "hls_url": "https://v.redd.it/9s6d82c3hrdc1/HLSPlaylist.m3u8?a=1708450693%2CYmJkZGNiY2JkNTM0NzY3ZWNjMmZhNTY5NmFmYWI0NzVkOTMyM2JhYjU1OGVlNTdjYmNlZmQ1NjdlMDM4ZjE4Mw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone.  I upgraded my 12TB (2x6TB) PR2100 with two 10TB WD Red drives.  Everything seemed to go well, but I'm running into problem that I cant figure out a solution to.  I'm trying to transfer a video file to a folder on the drive and I'm getting an error that says:\n\n \"There is not enough space on videos\n\n 0 bytes is needed to copy this item. Delete or move files so you have enough space\"\n\nThere is plenty of space on the drives so this is throwing me for a loop.  Does anyone have a recommendation as to how I can fix this.\n\nThanks in advance for any help.", "author_fullname": "t2_wk1uv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PR2100 Drive Upgrade Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bpxak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705795543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone.  I upgraded my 12TB (2x6TB) PR2100 with two 10TB WD Red drives.  Everything seemed to go well, but I&amp;#39;m running into problem that I cant figure out a solution to.  I&amp;#39;m trying to transfer a video file to a folder on the drive and I&amp;#39;m getting an error that says:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;There is not enough space on videos&lt;/p&gt;\n\n&lt;p&gt;0 bytes is needed to copy this item. Delete or move files so you have enough space&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;There is plenty of space on the drives so this is throwing me for a loop.  Does anyone have a recommendation as to how I can fix this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bpxak", "is_robot_indexable": true, "report_reasons": null, "author": "JohnnyDanger79", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bpxak/pr2100_drive_upgrade_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bpxak/pr2100_drive_upgrade_problem/", "subreddit_subscribers": 726927, "created_utc": 1705795543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a folder of images (around 7k) which i messed up the exif data of by moving them from android phone's own memory to the sd card with the file manager app.\n\nIt reset all of the images' dates to the current date.\n\nI was using an android app called \"Image &amp; Video Date Fixer\" to fix them. First i categorized the images that need to be in order/next to each other into the same folders, then i renamed them on Windows with 1 second differences (like 20231122\\_11223\\*\\*3\\*\\* and 20231122\\_11223\\*\\*4\\*\\* and so on) then i used this app to set the EXIF dates into the names of pictures. \n\nBut i realized that gallery on my android app doesn't respect one second differences and still mixes the images around their seconds' range. I want to space around those images for 5 seconds but i don't want to repeat this process manually, i am already tired, i was so happy that it was finally over, then i got this problem. it was very time consuming and most people would not bother with what i am doing to be honest.\n\nIs there any reliable software / or a process to automate this? I heard Exiftool but i don't know how to use write codes for it. \n\n&amp;#x200B;\n\nNot a definite goal of course, but maybe it could be something like this: I'd like detection for exif dates with 1 second differences, group those together, and then extend them based on the selected one image's date in the group.", "author_fullname": "t2_nv30o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk images metadata / EXIF editing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bmkcr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705786504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a folder of images (around 7k) which i messed up the exif data of by moving them from android phone&amp;#39;s own memory to the sd card with the file manager app.&lt;/p&gt;\n\n&lt;p&gt;It reset all of the images&amp;#39; dates to the current date.&lt;/p&gt;\n\n&lt;p&gt;I was using an android app called &amp;quot;Image &amp;amp; Video Date Fixer&amp;quot; to fix them. First i categorized the images that need to be in order/next to each other into the same folders, then i renamed them on Windows with 1 second differences (like 20231122_11223**3** and 20231122_11223**4** and so on) then i used this app to set the EXIF dates into the names of pictures. &lt;/p&gt;\n\n&lt;p&gt;But i realized that gallery on my android app doesn&amp;#39;t respect one second differences and still mixes the images around their seconds&amp;#39; range. I want to space around those images for 5 seconds but i don&amp;#39;t want to repeat this process manually, i am already tired, i was so happy that it was finally over, then i got this problem. it was very time consuming and most people would not bother with what i am doing to be honest.&lt;/p&gt;\n\n&lt;p&gt;Is there any reliable software / or a process to automate this? I heard Exiftool but i don&amp;#39;t know how to use write codes for it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Not a definite goal of course, but maybe it could be something like this: I&amp;#39;d like detection for exif dates with 1 second differences, group those together, and then extend them based on the selected one image&amp;#39;s date in the group.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bmkcr", "is_robot_indexable": true, "report_reasons": null, "author": "RiusGoneMad", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bmkcr/bulk_images_metadata_exif_editing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bmkcr/bulk_images_metadata_exif_editing/", "subreddit_subscribers": 726927, "created_utc": 1705786504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How can i check if a usb flash drive reports a fake capacity? My brother got a 128 gb drive from amazon and its incredibly slow and hangs after writing ~200 mb to it.\n\nEdit: maybe its just a bad drive in general, it doesnt even show up in disk management anymore", "author_fullname": "t2_9kqgspet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Check if USB stick reports fake capacity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bh44j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705784051.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705772315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can i check if a usb flash drive reports a fake capacity? My brother got a 128 gb drive from amazon and its incredibly slow and hangs after writing ~200 mb to it.&lt;/p&gt;\n\n&lt;p&gt;Edit: maybe its just a bad drive in general, it doesnt even show up in disk management anymore&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bh44j", "is_robot_indexable": true, "report_reasons": null, "author": "BlincxYT", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bh44j/check_if_usb_stick_reports_fake_capacity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bh44j/check_if_usb_stick_reports_fake_capacity/", "subreddit_subscribers": 726927, "created_utc": 1705772315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can't seem to find a recent answer.\n\nI know about the big purge from May 2023 but I'm curious about now. If I upload a picture without an account how long will it stay up? Does it need at least one view every so often?", "author_fullname": "t2_8ebac8il", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long do pics stay up on Imgur now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19c7lve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705855712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can&amp;#39;t seem to find a recent answer.&lt;/p&gt;\n\n&lt;p&gt;I know about the big purge from May 2023 but I&amp;#39;m curious about now. If I upload a picture without an account how long will it stay up? Does it need at least one view every so often?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c7lve", "is_robot_indexable": true, "report_reasons": null, "author": "itsarace1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c7lve/how_long_do_pics_stay_up_on_imgur_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c7lve/how_long_do_pics_stay_up_on_imgur_now/", "subreddit_subscribers": 726927, "created_utc": 1705855712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am fairly new to this and just recently in the past 6 months or so (June 2023) started to organize my life and data to have better control and archiving. I've got 4 kids, a few businesses, wife, and as everyone can imagine - countless data, docs and files that I should save and stop paying cloud providers for.\n\nI'm now about 8 TB deep into my system. I see how this will get out of control quickly, and my issue that I didn't consider is retrieval.\n\n**How does everyone organize or index their data?** \n\nI don't mean like file name conventions, tag or folder systems. I am curious if you build a database to store key information such as:\n\n* Backup Archives\n   * File Name | Archiving Date | File Summary | Etc. \n* Directory MOC\n   * Directory Name | File Types/Rules | Dates and Source Locations | etc... \n\n&amp;#x200B;\n\nI want to avoid the pitfall of when I need to find that one set of PDFs or photos from that one period I think was maybe between August 2016 and March 2017... for example. \n\n&amp;#x200B;\n\nJust curious of the process some bigger hoarders have taken to help me avoid a nightmare. ", "author_fullname": "t2_aikbtreq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Documenting and Indexing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19c70r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705854163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am fairly new to this and just recently in the past 6 months or so (June 2023) started to organize my life and data to have better control and archiving. I&amp;#39;ve got 4 kids, a few businesses, wife, and as everyone can imagine - countless data, docs and files that I should save and stop paying cloud providers for.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m now about 8 TB deep into my system. I see how this will get out of control quickly, and my issue that I didn&amp;#39;t consider is retrieval.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How does everyone organize or index their data?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t mean like file name conventions, tag or folder systems. I am curious if you build a database to store key information such as:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Backup Archives\n\n&lt;ul&gt;\n&lt;li&gt;File Name | Archiving Date | File Summary | Etc. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Directory MOC\n\n&lt;ul&gt;\n&lt;li&gt;Directory Name | File Types/Rules | Dates and Source Locations | etc... &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to avoid the pitfall of when I need to find that one set of PDFs or photos from that one period I think was maybe between August 2016 and March 2017... for example. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Just curious of the process some bigger hoarders have taken to help me avoid a nightmare. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "8TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c70r5", "is_robot_indexable": true, "report_reasons": null, "author": "HisNameWasShagbark", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19c70r5/documenting_and_indexing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c70r5/documenting_and_indexing/", "subreddit_subscribers": 726927, "created_utc": 1705854163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am digitizing a bunch of old family photos 1976-1978 onwards some even date to 1970s , and it is also our family tree, so apart from giving relevant file names how can i make a comment or note in the photo as to who are the people in the photo. I am scanning photos in our flatbed scanner as jpg file.  \n\nI am thinking of using image editor and add a text line below the photo or wherever there is empty space in photo, but is this a good method of tagging or recording comments about photos? ", "author_fullname": "t2_ogj32tug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to tag people in photos - scanned old ones", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bxual", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705821672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am digitizing a bunch of old family photos 1976-1978 onwards some even date to 1970s , and it is also our family tree, so apart from giving relevant file names how can i make a comment or note in the photo as to who are the people in the photo. I am scanning photos in our flatbed scanner as jpg file.  &lt;/p&gt;\n\n&lt;p&gt;I am thinking of using image editor and add a text line below the photo or wherever there is empty space in photo, but is this a good method of tagging or recording comments about photos? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bxual", "is_robot_indexable": true, "report_reasons": null, "author": "Sudden-Air-243", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bxual/how_to_tag_people_in_photos_scanned_old_ones/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bxual/how_to_tag_people_in_photos_scanned_old_ones/", "subreddit_subscribers": 726927, "created_utc": 1705821672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My wife passed away years ago. She left behind a sizable collection of pre-digital prints and negatives, which is being scanned, and a big collection in Google Photos.\n\nI like that Google Photos shows me my old pictures daily, and it would be nice to see her pics too. It would also be nice for other family members to be able to browse the pictures.\n\nShould I move her Google Photo pictures to my account? Leave them in hers? Should I put them in my Google Drive account? Somewhere else?\n\nBonus question: the scanned pictures are going to have the scanning date as the EXIF date. What's the done thing here? Should I update the EXIF date with the actual picture date? Put the actual date somewhere else? How can I make sure that Google Photos, for example, will show the pictures in correct chronological order?", "author_fullname": "t2_mwhfv38o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do with my deceased wife's photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bvqos", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705813870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My wife passed away years ago. She left behind a sizable collection of pre-digital prints and negatives, which is being scanned, and a big collection in Google Photos.&lt;/p&gt;\n\n&lt;p&gt;I like that Google Photos shows me my old pictures daily, and it would be nice to see her pics too. It would also be nice for other family members to be able to browse the pictures.&lt;/p&gt;\n\n&lt;p&gt;Should I move her Google Photo pictures to my account? Leave them in hers? Should I put them in my Google Drive account? Somewhere else?&lt;/p&gt;\n\n&lt;p&gt;Bonus question: the scanned pictures are going to have the scanning date as the EXIF date. What&amp;#39;s the done thing here? Should I update the EXIF date with the actual picture date? Put the actual date somewhere else? How can I make sure that Google Photos, for example, will show the pictures in correct chronological order?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bvqos", "is_robot_indexable": true, "report_reasons": null, "author": "optimisticlemur", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bvqos/what_to_do_with_my_deceased_wifes_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bvqos/what_to_do_with_my_deceased_wifes_photos/", "subreddit_subscribers": 726927, "created_utc": 1705813870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, \n\n&amp;#x200B;\n\nI'm looking for a tool that would allow me to backup:\n\n\\- All my tweets, retweets, liked and bookmarked tweets with the associated media\n\n\\- My followers list\n\n\\- My lists\n\n&amp;#x200B;\n\nIf this tool does not exist, is there a way for me to have programmatical access to my data without using Twitter official API (100USD/Month)? I could write a script or a browser extension.", "author_fullname": "t2_at77r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download an extensive backup of my own twitter account", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19butmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705810692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a tool that would allow me to backup:&lt;/p&gt;\n\n&lt;p&gt;- All my tweets, retweets, liked and bookmarked tweets with the associated media&lt;/p&gt;\n\n&lt;p&gt;- My followers list&lt;/p&gt;\n\n&lt;p&gt;- My lists&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If this tool does not exist, is there a way for me to have programmatical access to my data without using Twitter official API (100USD/Month)? I could write a script or a browser extension.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19butmc", "is_robot_indexable": true, "report_reasons": null, "author": "bobberkarl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19butmc/download_an_extensive_backup_of_my_own_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19butmc/download_an_extensive_backup_of_my_own_twitter/", "subreddit_subscribers": 726927, "created_utc": 1705810692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to preserve a very long RPG play-by-post game written on a discord server. It's about 1.5 million words of text. All the other posts I've seen asking about preserving things from discord are concerned with saving photos/attachments or reactions, but I want literally just the text people have written and to specifically *exclude* things like usernames, dates, and reactions so that it reads like a book. It seems like there should be an easy way to have a program grab just the text and export it to a text file, but I haven't found anything.\n\nWant to keep: The responses people write, formatting if possible (e.g. italics)\n\nDon't want to keep: Usernames, dates, reactions, images, attachments\n\nAny suggestions? I can get admin access to the server as well if that affects what can be done.", "author_fullname": "t2_boege", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to archive ONLY text from a discord server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bthfz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705806171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to preserve a very long RPG play-by-post game written on a discord server. It&amp;#39;s about 1.5 million words of text. All the other posts I&amp;#39;ve seen asking about preserving things from discord are concerned with saving photos/attachments or reactions, but I want literally just the text people have written and to specifically &lt;em&gt;exclude&lt;/em&gt; things like usernames, dates, and reactions so that it reads like a book. It seems like there should be an easy way to have a program grab just the text and export it to a text file, but I haven&amp;#39;t found anything.&lt;/p&gt;\n\n&lt;p&gt;Want to keep: The responses people write, formatting if possible (e.g. italics)&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t want to keep: Usernames, dates, reactions, images, attachments&lt;/p&gt;\n\n&lt;p&gt;Any suggestions? I can get admin access to the server as well if that affects what can be done.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bthfz", "is_robot_indexable": true, "report_reasons": null, "author": "Lycanthrotree", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bthfz/best_way_to_archive_only_text_from_a_discord/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bthfz/best_way_to_archive_only_text_from_a_discord/", "subreddit_subscribers": 726927, "created_utc": 1705806171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Moving into DAS and was recommended that Toshiba\u2019s are pretty solid for DAS? Anyone uses them and can vouch for it? I just got a Thunderbay 8 from OWC and im planning to use 10tb wd red\u2019s or the Exos but now checking if I should just go with Toshiba\u2019s since its what OWC recommends.", "author_fullname": "t2_4ma0eche", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toshiba? Best HDD for OWC DAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bq7cz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705796323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Moving into DAS and was recommended that Toshiba\u2019s are pretty solid for DAS? Anyone uses them and can vouch for it? I just got a Thunderbay 8 from OWC and im planning to use 10tb wd red\u2019s or the Exos but now checking if I should just go with Toshiba\u2019s since its what OWC recommends.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bq7cz", "is_robot_indexable": true, "report_reasons": null, "author": "Arjay188", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bq7cz/toshiba_best_hdd_for_owc_das/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bq7cz/toshiba_best_hdd_for_owc_das/", "subreddit_subscribers": 726927, "created_utc": 1705796323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased three external hard drives, all 2 TB. I am backing up my Macbook on all three external hard drives using Time Machine. I am just wondering if this is a solid back-up plan. I am aware of the 3-2-1 rule. Hence the three external hard drives. I know that the Rule says I am supposed to have at least 2 different methods for backing up. In which case, for one of my back-ups instead of Time Machine I could use the software that the external hard drives come with. However Time Machine has turned out to be so simple, and these softwares that accompany the external hard drives are a bit more complex to set up. So I'm thinking to just keep things simple by using Time Machine for all three of my external hard drives. \n\nIs there anything wrong with that? ", "author_fullname": "t2_4u6autkj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time Machine as my Back-Up Method on all three of my external hard drives \u2013 is this a solid back-up plan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bptve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705795285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased three external hard drives, all 2 TB. I am backing up my Macbook on all three external hard drives using Time Machine. I am just wondering if this is a solid back-up plan. I am aware of the 3-2-1 rule. Hence the three external hard drives. I know that the Rule says I am supposed to have at least 2 different methods for backing up. In which case, for one of my back-ups instead of Time Machine I could use the software that the external hard drives come with. However Time Machine has turned out to be so simple, and these softwares that accompany the external hard drives are a bit more complex to set up. So I&amp;#39;m thinking to just keep things simple by using Time Machine for all three of my external hard drives. &lt;/p&gt;\n\n&lt;p&gt;Is there anything wrong with that? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bptve", "is_robot_indexable": true, "report_reasons": null, "author": "OrvilleSpencer34", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bptve/time_machine_as_my_backup_method_on_all_three_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bptve/time_machine_as_my_backup_method_on_all_three_of/", "subreddit_subscribers": 726927, "created_utc": 1705795285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I am a wannabe data hoarder lmao  \n\n\nI have a spare pc that I don't use, it's an old 1155 gigabyte ga-b75n motherboard with an intel i7 2600k and 16gb ddr3. I also have a box with x14 500gb laptop hard drives that check good on crystaldisk info. That motherboard just has 4 sata ports. I need one of them for the ssd, another one for a wd red 3tb nas drive, and then the other 2 for 2 of these 2.5\" drives that I have.  \n\n\nI've seen cards that can output sata ports from pci express, but that was a long time ago, when I started searching on here I saw so many types of cards, I kind of got lost.  \n\n\nThe main purpose of this build is to have a server I can use for torrent and jellyfin and basically everything I use my raspberry pi 3b+ for (plus nextcloud which my old pi can't do), but because I have no money to buy a decent modern SBC (like the ODRIOD H3 which could handle nextcloud and some other stuff although no more than 2 sata drives)  \n\n\nFor what I've seen, a normal ammount of sata ports in one of those cards seems to be 8 ports. Anything above that, looks like it's bad quality pci-e 2x.  \n\n\nBut no idea of what card to buy, I saw this one on [ebay](https://www.ebay.es/itm/144210451235?hash=item21939cdb23:g:WuEAAOSwHWRhSJ8y&amp;amdata=enc%3AAQAIAAAAwC%2BiXEwAVaYAyphYHkqdN5rMEpTESXfX3t59m298SgH1Nx0xcBQcR2Yz2cuxQQw46yz%2B1sEBqiv6iXHk%2FFHM2ctv6Vdy73jMCNfBeihXR96ZCciO6hbU%2FDl6LLRB0%2BVwaBifJbDef3iy0xI5Cjspgmi2j3woRAkFTKS8bW9wbBJw9RmGIow9aChikNhzxMAwxfSGvu%2B89kG0U169pMPu5ngunBOKmzxiNkXEif8NaEvg0xDkk4z%2F0u6lGM0FehzlrQ%3D%3D%7Ctkp%3ABk9SR8ri_Y-lYw) . 26\u20ac for it seems cheap, also comes from china so no idea if it's good.  \n\n\nAlso, my drives are sata, and don't know what does that card have but I guess I need an adapter.  \n\n\nSince I guess people here are expert on this matter, I would appreciate some help! Thanks and sorry for the wall of text!", "author_fullname": "t2_q87sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to connect ~10 hdd to my pc, unsure how. Help is appreciated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bo7v4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1705790925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am a wannabe data hoarder lmao  &lt;/p&gt;\n\n&lt;p&gt;I have a spare pc that I don&amp;#39;t use, it&amp;#39;s an old 1155 gigabyte ga-b75n motherboard with an intel i7 2600k and 16gb ddr3. I also have a box with x14 500gb laptop hard drives that check good on crystaldisk info. That motherboard just has 4 sata ports. I need one of them for the ssd, another one for a wd red 3tb nas drive, and then the other 2 for 2 of these 2.5&amp;quot; drives that I have.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen cards that can output sata ports from pci express, but that was a long time ago, when I started searching on here I saw so many types of cards, I kind of got lost.  &lt;/p&gt;\n\n&lt;p&gt;The main purpose of this build is to have a server I can use for torrent and jellyfin and basically everything I use my raspberry pi 3b+ for (plus nextcloud which my old pi can&amp;#39;t do), but because I have no money to buy a decent modern SBC (like the ODRIOD H3 which could handle nextcloud and some other stuff although no more than 2 sata drives)  &lt;/p&gt;\n\n&lt;p&gt;For what I&amp;#39;ve seen, a normal ammount of sata ports in one of those cards seems to be 8 ports. Anything above that, looks like it&amp;#39;s bad quality pci-e 2x.  &lt;/p&gt;\n\n&lt;p&gt;But no idea of what card to buy, I saw this one on &lt;a href=\"https://www.ebay.es/itm/144210451235?hash=item21939cdb23:g:WuEAAOSwHWRhSJ8y&amp;amp;amdata=enc%3AAQAIAAAAwC%2BiXEwAVaYAyphYHkqdN5rMEpTESXfX3t59m298SgH1Nx0xcBQcR2Yz2cuxQQw46yz%2B1sEBqiv6iXHk%2FFHM2ctv6Vdy73jMCNfBeihXR96ZCciO6hbU%2FDl6LLRB0%2BVwaBifJbDef3iy0xI5Cjspgmi2j3woRAkFTKS8bW9wbBJw9RmGIow9aChikNhzxMAwxfSGvu%2B89kG0U169pMPu5ngunBOKmzxiNkXEif8NaEvg0xDkk4z%2F0u6lGM0FehzlrQ%3D%3D%7Ctkp%3ABk9SR8ri_Y-lYw\"&gt;ebay&lt;/a&gt; . 26\u20ac for it seems cheap, also comes from china so no idea if it&amp;#39;s good.  &lt;/p&gt;\n\n&lt;p&gt;Also, my drives are sata, and don&amp;#39;t know what does that card have but I guess I need an adapter.  &lt;/p&gt;\n\n&lt;p&gt;Since I guess people here are expert on this matter, I would appreciate some help! Thanks and sorry for the wall of text!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?auto=webp&amp;s=ecb8019d97a50921834f2592a9af64513eca9f5d", "width": 400, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=36d785f27544862c20cb5d15eca758e4dc4a8ef1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2521cd5aacef09fab648c925746b167ce962a011", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/d6Zn5ygscUwX88ffyvCfBSwGS80aX1HEzgNNbl88ma4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6163d552292c2244476550f52a0aaa7bd2b8eb33", "width": 320, "height": 240}], "variants": {}, "id": "4SNq5slnQHY5ukuvhQh51R7fc-UIue5XnqAfNqEw6iI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bo7v4", "is_robot_indexable": true, "report_reasons": null, "author": "LanguageManiac", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bo7v4/want_to_connect_10_hdd_to_my_pc_unsure_how_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bo7v4/want_to_connect_10_hdd_to_my_pc_unsure_how_help/", "subreddit_subscribers": 726927, "created_utc": 1705790925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI need help connecting my old Buffalo TerraStation Model HS-DH0.0TGL/R5. Buffalo no longer offers the NAS server software. When I try to use the IP address, it doesn't recognize the user and password I provided. I'm using a MAC Studio with Sonoma 14.2.1.\u00a0\n\nAny assistance would be greatly appreciated!", "author_fullname": "t2_ftg55infz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with an old Buffalo TerraStation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bmg89", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705786209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I need help connecting my old Buffalo TerraStation Model HS-DH0.0TGL/R5. Buffalo no longer offers the NAS server software. When I try to use the IP address, it doesn&amp;#39;t recognize the user and password I provided. I&amp;#39;m using a MAC Studio with Sonoma 14.2.1.\u00a0&lt;/p&gt;\n\n&lt;p&gt;Any assistance would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bmg89", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Week-6906", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bmg89/help_with_an_old_buffalo_terrastation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bmg89/help_with_an_old_buffalo_terrastation/", "subreddit_subscribers": 726927, "created_utc": 1705786209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,\n\nI have gotten some sweet deals on ebay that may be turning sour, and I really need your insight to assert where my problem lays; I got myself an MSL4048 without drives which seems to work fine and is running firmware version 9.60/3.02e which I believe is the last one from a cursory search on HP's site.\n\nI separately got myself an LTO-6 drive, HP branded and with a few IDs on it \"spare no. 721592-001\", \"AQ288D#103\", \"C5F90A\".\n\nNow, when trying out the tape drive in the library, I get a note that \"Drive 1: Disabled - Exception 48\", and there's a log entry saying \"Wrong drive fitted\".\n\nThere isn't too much information about that from my googling around, though it seems that this error stems from using a drive on a library that was factory prepared to operate on a different brand library, though it seems odd this would bear the HP brand and be for another library.\n\nI do not have any other tape drive to test the operation of the library and I am waiting on the seller to tell me what method they used to test this to advertise it as \"tested working\". But, in the mean time, since I don't have any prior knowledge with tapes and such, I wanted to ask if there's anything I can do to further test this, as well as maybe force update the tape firmware. Right now it won't let me update the drive as it is disabled, and nothing comes up in the SAS interface, not the tape nor the library which I guess is expected as the drive is powered off once it failed to be initialize.\n\nI generated a support ticket and while it seems to be mostly binary data, the plain text part does read \"HP      Ultrium 6-SCSI  HUJ42813R2      33HW    018.421\" and I find no mention to any other brand.\n\nFinally, there are some other errors that show up in that support ticket, though I don't see these in the event log I downloaded:\n\nHE: drive communication error\n\nHUJ42813R2              HE: drive communication error\n\nHUJ42813R2              HE: drive logged out\n\nHE: invalid rotation range\n\nLTC015065               HE: slider blocked\n\n&amp;#x200B;\n\nSo, yeah, any help would be greatly appreciated :)", "author_fullname": "t2_ci6bx6c6l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSL4048 with LTO6 6250 - wrong drive type", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bl6yf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705793105.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705782897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I have gotten some sweet deals on ebay that may be turning sour, and I really need your insight to assert where my problem lays; I got myself an MSL4048 without drives which seems to work fine and is running firmware version 9.60/3.02e which I believe is the last one from a cursory search on HP&amp;#39;s site.&lt;/p&gt;\n\n&lt;p&gt;I separately got myself an LTO-6 drive, HP branded and with a few IDs on it &amp;quot;spare no. 721592-001&amp;quot;, &amp;quot;AQ288D#103&amp;quot;, &amp;quot;C5F90A&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Now, when trying out the tape drive in the library, I get a note that &amp;quot;Drive 1: Disabled - Exception 48&amp;quot;, and there&amp;#39;s a log entry saying &amp;quot;Wrong drive fitted&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;There isn&amp;#39;t too much information about that from my googling around, though it seems that this error stems from using a drive on a library that was factory prepared to operate on a different brand library, though it seems odd this would bear the HP brand and be for another library.&lt;/p&gt;\n\n&lt;p&gt;I do not have any other tape drive to test the operation of the library and I am waiting on the seller to tell me what method they used to test this to advertise it as &amp;quot;tested working&amp;quot;. But, in the mean time, since I don&amp;#39;t have any prior knowledge with tapes and such, I wanted to ask if there&amp;#39;s anything I can do to further test this, as well as maybe force update the tape firmware. Right now it won&amp;#39;t let me update the drive as it is disabled, and nothing comes up in the SAS interface, not the tape nor the library which I guess is expected as the drive is powered off once it failed to be initialize.&lt;/p&gt;\n\n&lt;p&gt;I generated a support ticket and while it seems to be mostly binary data, the plain text part does read &amp;quot;HP      Ultrium 6-SCSI  HUJ42813R2      33HW    018.421&amp;quot; and I find no mention to any other brand.&lt;/p&gt;\n\n&lt;p&gt;Finally, there are some other errors that show up in that support ticket, though I don&amp;#39;t see these in the event log I downloaded:&lt;/p&gt;\n\n&lt;p&gt;HE: drive communication error&lt;/p&gt;\n\n&lt;p&gt;HUJ42813R2              HE: drive communication error&lt;/p&gt;\n\n&lt;p&gt;HUJ42813R2              HE: drive logged out&lt;/p&gt;\n\n&lt;p&gt;HE: invalid rotation range&lt;/p&gt;\n\n&lt;p&gt;LTC015065               HE: slider blocked&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So, yeah, any help would be greatly appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bl6yf", "is_robot_indexable": true, "report_reasons": null, "author": "nutsoh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bl6yf/msl4048_with_lto6_6250_wrong_drive_type/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bl6yf/msl4048_with_lto6_6250_wrong_drive_type/", "subreddit_subscribers": 726927, "created_utc": 1705782897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a very large 8+ tb hdd and I want to connect it to a NAS for backups. I don't need multi-bays or anything. Does it need to be fully enclosed? It'll be connected 24/7. Also, how much do you need a fan? I was thinking about [this one](https://www.amazon.com/dp/B013WODZH0), but found complaints that it corrupted data? I would have thought that enclosures were literally just boxes with sata to USB plugs. How could it possibly corrupt drives?\n\nIdeally, I'd not want to spend too much cash on this because, if I spend a lot, I might as well just buy another NAS to back up the big one?", "author_fullname": "t2_itdbynwt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what's the best way to connect a large internal hdd to a nas for hyperbackup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bkwhg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705782123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very large 8+ tb hdd and I want to connect it to a NAS for backups. I don&amp;#39;t need multi-bays or anything. Does it need to be fully enclosed? It&amp;#39;ll be connected 24/7. Also, how much do you need a fan? I was thinking about &lt;a href=\"https://www.amazon.com/dp/B013WODZH0\"&gt;this one&lt;/a&gt;, but found complaints that it corrupted data? I would have thought that enclosures were literally just boxes with sata to USB plugs. How could it possibly corrupt drives?&lt;/p&gt;\n\n&lt;p&gt;Ideally, I&amp;#39;d not want to spend too much cash on this because, if I spend a lot, I might as well just buy another NAS to back up the big one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bkwhg", "is_robot_indexable": true, "report_reasons": null, "author": "Leading_Release_4344", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bkwhg/whats_the_best_way_to_connect_a_large_internal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bkwhg/whats_the_best_way_to_connect_a_large_internal/", "subreddit_subscribers": 726927, "created_utc": 1705782123.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}