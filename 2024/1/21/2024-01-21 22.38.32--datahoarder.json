{"kind": "Listing", "data": {"after": "t3_19butmc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_poc45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody know of a resource explaining the differences between these checksum algorithms at a fairly basic level (pros, cons, etc)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_19c1i83", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pgaxQYNaszskmUFYuj8pN7AKq_qQSMuaVFDeUQKq4Ws.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1705836721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rvosn91b4sdc1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rvosn91b4sdc1.png?auto=webp&amp;s=210dd504440e5659069f03f6ac07b97d7a9e880a", "width": 978, "height": 657}, "resolutions": [{"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=93631ac6ed38c35554d2812b1ad097e19f3f697a", "width": 108, "height": 72}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=da02ebe634c43acf9800f9bbaeadc7d22501ce0a", "width": 216, "height": 145}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fb03d6e74e89a408d7dbf4a2b6140877ea9f9f22", "width": 320, "height": 214}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5aee88d10b3efc41876da9f802ae6ebaca63c6c", "width": 640, "height": 429}, {"url": "https://preview.redd.it/rvosn91b4sdc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=06e3d410e75b4ccc402b66068b75503f7f444580", "width": 960, "height": 644}], "variants": {}, "id": "aNxWOGfGK9il-LQFREbw-rVJ_dUzpvkQiVEhK9Jd5ho"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c1i83", "is_robot_indexable": true, "report_reasons": null, "author": "danielrosehill", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c1i83/anybody_know_of_a_resource_explaining_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rvosn91b4sdc1.png", "subreddit_subscribers": 726988, "created_utc": 1705836721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We've come a long way", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_19ccxmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_7ndf2", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interesting", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2d0bfed1a6d3cd366e4e91f627f5dee320de89fe", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Damnthatsinteresting", "selftext": "", "author_fullname": "t2_41eoq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store data in 1982", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Damnthatsinteresting", "hidden": false, "pwls": 6, "link_flair_css_class": "video", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_19c7ls1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3485, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/i2iwtohtotdc1/DASH_720.mp4?source=fallback", "has_audio": true, "height": 740, "width": 720, "scrubber_media_url": "https://v.redd.it/i2iwtohtotdc1/DASH_96.mp4", "dash_url": "https://v.redd.it/i2iwtohtotdc1/DASHPlaylist.mpd?a=1708468712%2CMTRlNGJlZmViNzM4ZjQ3OTZmZDFjOWY0MzVhODRmMTc5NTFhMzEwOTM4YjE5NzBkODgzYjYyNGZhOTBmOWYxMw%3D%3D&amp;v=1&amp;f=sd", "duration": 190, "hls_url": "https://v.redd.it/i2iwtohtotdc1/HLSPlaylist.m3u8?a=1708468712%2CZmVjMTRjNWU0ZDE5ZDUxY2U2NmJjMDYzNGQ0YmQ2ZTFjMGUwNDg1Y2QyYzJkZGY5MDZjZGVhOTVmY2ExMTM5OA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Video", "can_mod_post": false, "score": 3485, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2d0bfed1a6d3cd366e4e91f627f5dee320de89fe", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "mod_note": null, "created": 1705855705.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/i2iwtohtotdc1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?format=pjpg&amp;auto=webp&amp;s=d258c7ecb446ee667bde33ed5225b67732a69c85", "width": 720, "height": 740}, "resolutions": [{"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6d9e111712b71a001a35bdec47864e4a4d3c2159", "width": 108, "height": 110}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0e5ada3d49e57fca7a38e4391834772f49b5570e", "width": 216, "height": 221}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b53629eed6e8abcb010e6ce452a1e00230e3e5bf", "width": 320, "height": 328}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=fdfe3204d5a62a16c5d0c74af28f0b4c3147b04c", "width": 640, "height": 657}], "variants": {}, "id": "Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2xxyj", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "19c7ls1", "is_robot_indexable": true, "report_reasons": null, "author": "Pasargad", "discussion_type": null, "num_comments": 160, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Damnthatsinteresting/comments/19c7ls1/how_to_store_data_in_1982/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/i2iwtohtotdc1", "subreddit_subscribers": 13435464, "created_utc": 1705855705.0, "num_crossposts": 2, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/i2iwtohtotdc1/DASH_720.mp4?source=fallback", "has_audio": true, "height": 740, "width": 720, "scrubber_media_url": "https://v.redd.it/i2iwtohtotdc1/DASH_96.mp4", "dash_url": "https://v.redd.it/i2iwtohtotdc1/DASHPlaylist.mpd?a=1708468712%2CMTRlNGJlZmViNzM4ZjQ3OTZmZDFjOWY0MzVhODRmMTc5NTFhMzEwOTM4YjE5NzBkODgzYjYyNGZhOTBmOWYxMw%3D%3D&amp;v=1&amp;f=sd", "duration": 190, "hls_url": "https://v.redd.it/i2iwtohtotdc1/HLSPlaylist.m3u8?a=1708468712%2CZmVjMTRjNWU0ZDE5ZDUxY2U2NmJjMDYzNGQ0YmQ2ZTFjMGUwNDg1Y2QyYzJkZGY5MDZjZGVhOTVmY2ExMTM5OA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}], "created": 1705869038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/i2iwtohtotdc1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?auto=webp&amp;s=f652d1331011773e19ecc12146ed2e77bec997ac", "width": 720, "height": 740}, "resolutions": [{"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=387509397e8677ccf617a86f7fe675c1c5799275", "width": 108, "height": 110}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=471739abfdabb307f58048bb1f4aa2707a906e98", "width": 216, "height": 221}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a73735793ef0516c74bc7778c7011d341351508f", "width": 320, "height": 328}, {"url": "https://external-preview.redd.it/Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=91948c148ec5e24b6cdb75428e76d8ad493c0347", "width": 640, "height": 657}], "variants": {}, "id": "Nm5pMGE0c3RvdGRjMb-GArsp9BQ88GlECmbS7T3-aln33afgxTk8KKV2vt1Z"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "19ccxmc", "is_robot_indexable": true, "report_reasons": null, "author": "pelosnecios", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_19c7ls1", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccxmc/weve_come_a_long_way/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/i2iwtohtotdc1", "subreddit_subscribers": 726988, "created_utc": 1705869038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to share one of my backup drives with a friend. He told me it needs to be encrypted to store it in his house. I do trust him but he wants the data encrypted. I said fine with me. It's just medical and financial records as well as families movies like Christmas mornings. \n\nThe problem is that while my Linux desktop could always decrypt the drives with my gpg key or password. I'm trying to plan on a situation where something bad happens and I can't access the computer. Maybe I forget the password or something like that. \n\nI thought about buying a cheap waterproof USB drive and just burying it someplace.", "author_fullname": "t2_dui3ih3xt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for backing up keys and passwords of backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19brvds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705801182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to share one of my backup drives with a friend. He told me it needs to be encrypted to store it in his house. I do trust him but he wants the data encrypted. I said fine with me. It&amp;#39;s just medical and financial records as well as families movies like Christmas mornings. &lt;/p&gt;\n\n&lt;p&gt;The problem is that while my Linux desktop could always decrypt the drives with my gpg key or password. I&amp;#39;m trying to plan on a situation where something bad happens and I can&amp;#39;t access the computer. Maybe I forget the password or something like that. &lt;/p&gt;\n\n&lt;p&gt;I thought about buying a cheap waterproof USB drive and just burying it someplace.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19brvds", "is_robot_indexable": true, "report_reasons": null, "author": "sir_topham_biff", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19brvds/ideas_for_backing_up_keys_and_passwords_of_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19brvds/ideas_for_backing_up_keys_and_passwords_of_backups/", "subreddit_subscribers": 726988, "created_utc": 1705801182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Do you physically destroy them at home and toss the pieces into trash? Go to a place that have drive shredders (can't find many around my location)?\n\nThank you for reading and hopefully answering soon. :)", "author_fullname": "t2_4a27h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do with your personal home dead/broken storage drives (e.g., old HDDs) that you want to get rid of?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c6x2a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705853900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you physically destroy them at home and toss the pieces into trash? Go to a place that have drive shredders (can&amp;#39;t find many around my location)?&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading and hopefully answering soon. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Where's the big floppy disk(ette) flair? :P", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c6x2a", "is_robot_indexable": true, "report_reasons": null, "author": "antdude", "discussion_type": null, "num_comments": 43, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19c6x2a/what_do_you_do_with_your_personal_home_deadbroken/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c6x2a/what_do_you_do_with_your_personal_home_deadbroken/", "subreddit_subscribers": 726988, "created_utc": 1705853900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My wife passed away years ago. She left behind a sizable collection of pre-digital prints and negatives, which is being scanned, and a big collection in Google Photos.\n\nI like that Google Photos shows me my old pictures daily, and it would be nice to see her pics too. It would also be nice for other family members to be able to browse the pictures.\n\nShould I move her Google Photo pictures to my account? Leave them in hers? Should I put them in my Google Drive account? Somewhere else?\n\nBonus question: the scanned pictures are going to have the scanning date as the EXIF date. What's the done thing here? Should I update the EXIF date with the actual picture date? Put the actual date somewhere else? How can I make sure that Google Photos, for example, will show the pictures in correct chronological order?", "author_fullname": "t2_mwhfv38o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do with my deceased wife's photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bvqos", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705813870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My wife passed away years ago. She left behind a sizable collection of pre-digital prints and negatives, which is being scanned, and a big collection in Google Photos.&lt;/p&gt;\n\n&lt;p&gt;I like that Google Photos shows me my old pictures daily, and it would be nice to see her pics too. It would also be nice for other family members to be able to browse the pictures.&lt;/p&gt;\n\n&lt;p&gt;Should I move her Google Photo pictures to my account? Leave them in hers? Should I put them in my Google Drive account? Somewhere else?&lt;/p&gt;\n\n&lt;p&gt;Bonus question: the scanned pictures are going to have the scanning date as the EXIF date. What&amp;#39;s the done thing here? Should I update the EXIF date with the actual picture date? Put the actual date somewhere else? How can I make sure that Google Photos, for example, will show the pictures in correct chronological order?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bvqos", "is_robot_indexable": true, "report_reasons": null, "author": "optimisticlemur", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bvqos/what_to_do_with_my_deceased_wifes_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bvqos/what_to_do_with_my_deceased_wifes_photos/", "subreddit_subscribers": 726988, "created_utc": 1705813870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am fairly new to this and just recently in the past 6 months or so (June 2023) started to organize my life and data to have better control and archiving. I've got 4 kids, a few businesses, wife, and as everyone can imagine - countless data, docs and files that I should save and stop paying cloud providers for.\n\nI'm now about 8 TB deep into my system. I see how this will get out of control quickly, and my issue that I didn't consider is retrieval.\n\n**How does everyone organize or index their data?** \n\nI don't mean like file name conventions, tag or folder systems. I am curious if you build a database to store key information such as:\n\n* Backup Archives\n   * File Name | Archiving Date | File Summary | Etc. \n* Directory MOC\n   * Directory Name | File Types/Rules | Dates and Source Locations | etc... \n\n&amp;#x200B;\n\nI want to avoid the pitfall of when I need to find that one set of PDFs or photos from that one period I think was maybe between August 2016 and March 2017... for example. \n\n&amp;#x200B;\n\nJust curious of the process some bigger hoarders have taken to help me avoid a nightmare. ", "author_fullname": "t2_aikbtreq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Documenting and Indexing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c70r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705854163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am fairly new to this and just recently in the past 6 months or so (June 2023) started to organize my life and data to have better control and archiving. I&amp;#39;ve got 4 kids, a few businesses, wife, and as everyone can imagine - countless data, docs and files that I should save and stop paying cloud providers for.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m now about 8 TB deep into my system. I see how this will get out of control quickly, and my issue that I didn&amp;#39;t consider is retrieval.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How does everyone organize or index their data?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t mean like file name conventions, tag or folder systems. I am curious if you build a database to store key information such as:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Backup Archives\n\n&lt;ul&gt;\n&lt;li&gt;File Name | Archiving Date | File Summary | Etc. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Directory MOC\n\n&lt;ul&gt;\n&lt;li&gt;Directory Name | File Types/Rules | Dates and Source Locations | etc... &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to avoid the pitfall of when I need to find that one set of PDFs or photos from that one period I think was maybe between August 2016 and March 2017... for example. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Just curious of the process some bigger hoarders have taken to help me avoid a nightmare. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "8TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c70r5", "is_robot_indexable": true, "report_reasons": null, "author": "HisNameWasShagbark", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19c70r5/documenting_and_indexing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c70r5/documenting_and_indexing/", "subreddit_subscribers": 726988, "created_utc": 1705854163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello.\nI've been trying to manage my library for years without success.\nI have photos, backups of these photos, copies with different names, some of them with fucked date metadata...\n\nI wonder if there is a software that finds duplicates, and keep ALL metadata merged, picking the oldest date available for example.\n\nCan you guide me to start organizing this mess?\nI would be happy renaming all files with it's date\n\nIm talking about 500.000 files aprox.\n\nI'm using Windows 10\n\nThank you!", "author_fullname": "t2_b969b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need photo/video management help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c29y2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705840492.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705839687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.\nI&amp;#39;ve been trying to manage my library for years without success.\nI have photos, backups of these photos, copies with different names, some of them with fucked date metadata...&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is a software that finds duplicates, and keep ALL metadata merged, picking the oldest date available for example.&lt;/p&gt;\n\n&lt;p&gt;Can you guide me to start organizing this mess?\nI would be happy renaming all files with it&amp;#39;s date&lt;/p&gt;\n\n&lt;p&gt;Im talking about 500.000 files aprox.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Windows 10&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c29y2", "is_robot_indexable": true, "report_reasons": null, "author": "smaiderman", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c29y2/i_need_photovideo_management_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c29y2/i_need_photovideo_management_help/", "subreddit_subscribers": 726988, "created_utc": 1705839687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "G\u2019day - title may have been weird if so apologies, and I did a search but couldn\u2019t find what I was after\n\nI have a few hundred hard drives - both in servers and also externals \n\nIs there a program \u2018anywhere\u2019 that would allow me to scan these drives , and list the contents, and alert me when there are dupes ?\n\nKinda like a big database ?\n\nBe even more helpful if once the scanning process was done, that \u2018this program\u2019 would add new downloads to the database etc\n\nI keep finding that I have multiple copies of various things which is not only a waste of bandwidth but more importantly hard drive space , and the system I\u2019m currently using is obviously really bad\n\nSo I figure that there has to be a decent way or organization out there right ??", "author_fullname": "t2_dak0xorw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Program to scan drives for content to list dupes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ccac2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705867433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;G\u2019day - title may have been weird if so apologies, and I did a search but couldn\u2019t find what I was after&lt;/p&gt;\n\n&lt;p&gt;I have a few hundred hard drives - both in servers and also externals &lt;/p&gt;\n\n&lt;p&gt;Is there a program \u2018anywhere\u2019 that would allow me to scan these drives , and list the contents, and alert me when there are dupes ?&lt;/p&gt;\n\n&lt;p&gt;Kinda like a big database ?&lt;/p&gt;\n\n&lt;p&gt;Be even more helpful if once the scanning process was done, that \u2018this program\u2019 would add new downloads to the database etc&lt;/p&gt;\n\n&lt;p&gt;I keep finding that I have multiple copies of various things which is not only a waste of bandwidth but more importantly hard drive space , and the system I\u2019m currently using is obviously really bad&lt;/p&gt;\n\n&lt;p&gt;So I figure that there has to be a decent way or organization out there right ??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19ccac2", "is_robot_indexable": true, "report_reasons": null, "author": "ectoplasmic-warrior", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccac2/program_to_scan_drives_for_content_to_list_dupes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ccac2/program_to_scan_drives_for_content_to_list_dupes/", "subreddit_subscribers": 726988, "created_utc": 1705867433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\n# \n\nI accidentally deleted my documents on my laptop(windows os) and I need them in two days. Any tools for recovery that are easy to use?", "author_fullname": "t2_k1mgo7uwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data recovery softwares", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cbtmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705866277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I accidentally deleted my documents on my laptop(windows os) and I need them in two days. Any tools for recovery that are easy to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19cbtmn", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent_Eye1248", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19cbtmn/data_recovery_softwares/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19cbtmn/data_recovery_softwares/", "subreddit_subscribers": 726988, "created_utc": 1705866277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hard drives, as I understand it, often exhibit warning symptoms before they fail. And SSDs, maybe not so much. But still, I'm certain there must be some software out that to notify you if your drive health is showing anything concerning.\n\nIs there a good light-weight system tray app that can run in the background and run daily checks or something?\n\nI have a Windows desktop machine in my office with 14 GB of storage, and a Windows desktop acting as a server in the living room with 20 GB storage.", "author_fullname": "t2_4uv8kp1km", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best software for monitoring hard drive health status? (Windows)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19caacs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705862425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hard drives, as I understand it, often exhibit warning symptoms before they fail. And SSDs, maybe not so much. But still, I&amp;#39;m certain there must be some software out that to notify you if your drive health is showing anything concerning.&lt;/p&gt;\n\n&lt;p&gt;Is there a good light-weight system tray app that can run in the background and run daily checks or something?&lt;/p&gt;\n\n&lt;p&gt;I have a Windows desktop machine in my office with 14 GB of storage, and a Windows desktop acting as a server in the living room with 20 GB storage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "30TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19caacs", "is_robot_indexable": true, "report_reasons": null, "author": "raging_pastafarian", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/19caacs/best_software_for_monitoring_hard_drive_health/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19caacs/best_software_for_monitoring_hard_drive_health/", "subreddit_subscribers": 726988, "created_utc": 1705862425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to preserve a very long RPG play-by-post game written on a discord server. It's about 1.5 million words of text. All the other posts I've seen asking about preserving things from discord are concerned with saving photos/attachments or reactions, but I want literally just the text people have written and to specifically *exclude* things like usernames, dates, and reactions so that it reads like a book. It seems like there should be an easy way to have a program grab just the text and export it to a text file, but I haven't found anything.\n\nWant to keep: The responses people write, formatting if possible (e.g. italics)\n\nDon't want to keep: Usernames, dates, reactions, images, attachments\n\nAny suggestions? I can get admin access to the server as well if that affects what can be done.", "author_fullname": "t2_boege", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to archive ONLY text from a discord server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bthfz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705806171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to preserve a very long RPG play-by-post game written on a discord server. It&amp;#39;s about 1.5 million words of text. All the other posts I&amp;#39;ve seen asking about preserving things from discord are concerned with saving photos/attachments or reactions, but I want literally just the text people have written and to specifically &lt;em&gt;exclude&lt;/em&gt; things like usernames, dates, and reactions so that it reads like a book. It seems like there should be an easy way to have a program grab just the text and export it to a text file, but I haven&amp;#39;t found anything.&lt;/p&gt;\n\n&lt;p&gt;Want to keep: The responses people write, formatting if possible (e.g. italics)&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t want to keep: Usernames, dates, reactions, images, attachments&lt;/p&gt;\n\n&lt;p&gt;Any suggestions? I can get admin access to the server as well if that affects what can be done.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bthfz", "is_robot_indexable": true, "report_reasons": null, "author": "Lycanthrotree", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bthfz/best_way_to_archive_only_text_from_a_discord/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bthfz/best_way_to_archive_only_text_from_a_discord/", "subreddit_subscribers": 726988, "created_utc": 1705806171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone.  I upgraded my 12TB (2x6TB) PR2100 with two 10TB WD Red drives.  Everything seemed to go well, but I'm running into problem that I cant figure out a solution to.  I'm trying to transfer a video file to a folder on the drive and I'm getting an error that says:\n\n \"There is not enough space on videos\n\n 0 bytes is needed to copy this item. Delete or move files so you have enough space\"\n\nThere is plenty of space on the drives so this is throwing me for a loop.  Does anyone have a recommendation as to how I can fix this.\n\nThanks in advance for any help.", "author_fullname": "t2_wk1uv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PR2100 Drive Upgrade Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bpxak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705795543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone.  I upgraded my 12TB (2x6TB) PR2100 with two 10TB WD Red drives.  Everything seemed to go well, but I&amp;#39;m running into problem that I cant figure out a solution to.  I&amp;#39;m trying to transfer a video file to a folder on the drive and I&amp;#39;m getting an error that says:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;There is not enough space on videos&lt;/p&gt;\n\n&lt;p&gt;0 bytes is needed to copy this item. Delete or move files so you have enough space&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;There is plenty of space on the drives so this is throwing me for a loop.  Does anyone have a recommendation as to how I can fix this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bpxak", "is_robot_indexable": true, "report_reasons": null, "author": "JohnnyDanger79", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bpxak/pr2100_drive_upgrade_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bpxak/pr2100_drive_upgrade_problem/", "subreddit_subscribers": 726988, "created_utc": 1705795543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am not sure if this is the right sub-reddit to ask, so please tell me if this post is off topic.\n\nRecently all educational accounts' (Google, o365) storages got limited. Those accounts used to give large amount of cloud storage, but now they have limited to 100gb or 20gb.\n\nAs I'm moving all my stuff to an external hdd, I was wondering what do you guys use for cloud storage? There must be some files that are convenient to be in the cloud for any paper work.\n\nFurthermore, I've had personal experience with hdd just suddenly dying, so I prefer ssd, but then again the cost difference is unmissable. Are recent hdd's less fragile? ", "author_fullname": "t2_nd0c54c7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Education Accounts No Longer Gives Large Cloud Storage: Suggestions for the Future", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19ceejz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705872687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not sure if this is the right sub-reddit to ask, so please tell me if this post is off topic.&lt;/p&gt;\n\n&lt;p&gt;Recently all educational accounts&amp;#39; (Google, o365) storages got limited. Those accounts used to give large amount of cloud storage, but now they have limited to 100gb or 20gb.&lt;/p&gt;\n\n&lt;p&gt;As I&amp;#39;m moving all my stuff to an external hdd, I was wondering what do you guys use for cloud storage? There must be some files that are convenient to be in the cloud for any paper work.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, I&amp;#39;ve had personal experience with hdd just suddenly dying, so I prefer ssd, but then again the cost difference is unmissable. Are recent hdd&amp;#39;s less fragile? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19ceejz", "is_robot_indexable": true, "report_reasons": null, "author": "Known_Alternative565", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ceejz/education_accounts_no_longer_gives_large_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ceejz/education_accounts_no_longer_gives_large_cloud/", "subreddit_subscribers": 726988, "created_utc": 1705872687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have quite a few older HDD ranging in sizes from 500GB to 3TB. I'm thinking about using as cold storage backups for my main NAS. Looking for what people doing for the same and what their strategies are. \n\nMy NAS is a 36TB (23tb used) raidz2 pool with automated snapshots and unencrypted volumes for each category of data. (Linux ISO's, homedirs, music, roms, personal photos, etc).  I automated backup of the important/irreplacable stuff to a 3tb disk elsewhere on a rpi4. (warm backup). I do have a 2 bay USB/Sata dock for quickly popping disks in and out, and another single disk sata/usb adapter.\n\nMy initial idea is use pairs of matching sized disks. First run badblocks and validate each disks is healthy. On each of them make a small vfat volume with a README and other details about what the disks contains and how to access it should someone in the distant future who isn't me try to read the disks on a windows box. On the remaining space make a mirrored ZFS pool with both disks. For volumes that can easily fit entirely on one set of disks (like my /home is only 600GB) use zfs send/recv and add encryption on the receiving end. On sets too large to fit, instead create new encrypted volumes and rsync the data over, splitting the volumes up alphabetically and fitting as much as I can. The README will contain information on where to find the decryption keys. Afterwards catalog and name each disk with post-it notes (coldbackup-1a and 1b).  Keep a running copy of what is on each pair of disks and when it was last scrubbed in a central document.  Then store the drives in static bags with silica packets in my basement (cool, steady temperature, and relatively dry). And make calendar events so every 2 to 3 years I go through and scrub all the disks and replace as needed. On super irreplacable stuff (family photos and the like) maybe I even use a 3-way mirror using another sata-usb cable i have.\n\nThoughts? What would you do differently?  Is encrypting backups a bad idea even if I make sure that Key's are recoverable (i may even print out QR codes on paper in addition to KeePass). Is there a benefit to settings copies=2 in a 2way mirror for this use case?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_53838", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do for cold backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_19cdt01", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705871221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have quite a few older HDD ranging in sizes from 500GB to 3TB. I&amp;#39;m thinking about using as cold storage backups for my main NAS. Looking for what people doing for the same and what their strategies are. &lt;/p&gt;\n\n&lt;p&gt;My NAS is a 36TB (23tb used) raidz2 pool with automated snapshots and unencrypted volumes for each category of data. (Linux ISO&amp;#39;s, homedirs, music, roms, personal photos, etc).  I automated backup of the important/irreplacable stuff to a 3tb disk elsewhere on a rpi4. (warm backup). I do have a 2 bay USB/Sata dock for quickly popping disks in and out, and another single disk sata/usb adapter.&lt;/p&gt;\n\n&lt;p&gt;My initial idea is use pairs of matching sized disks. First run badblocks and validate each disks is healthy. On each of them make a small vfat volume with a README and other details about what the disks contains and how to access it should someone in the distant future who isn&amp;#39;t me try to read the disks on a windows box. On the remaining space make a mirrored ZFS pool with both disks. For volumes that can easily fit entirely on one set of disks (like my /home is only 600GB) use zfs send/recv and add encryption on the receiving end. On sets too large to fit, instead create new encrypted volumes and rsync the data over, splitting the volumes up alphabetically and fitting as much as I can. The README will contain information on where to find the decryption keys. Afterwards catalog and name each disk with post-it notes (coldbackup-1a and 1b).  Keep a running copy of what is on each pair of disks and when it was last scrubbed in a central document.  Then store the drives in static bags with silica packets in my basement (cool, steady temperature, and relatively dry). And make calendar events so every 2 to 3 years I go through and scrub all the disks and replace as needed. On super irreplacable stuff (family photos and the like) maybe I even use a 3-way mirror using another sata-usb cable i have.&lt;/p&gt;\n\n&lt;p&gt;Thoughts? What would you do differently?  Is encrypting backups a bad idea even if I make sure that Key&amp;#39;s are recoverable (i may even print out QR codes on paper in addition to KeePass). Is there a benefit to settings copies=2 in a 2way mirror for this use case?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19cdt01", "is_robot_indexable": true, "report_reasons": null, "author": "skreak", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19cdt01/what_do_you_do_for_cold_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19cdt01/what_do_you_do_for_cold_backups/", "subreddit_subscribers": 726988, "created_utc": 1705871221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to move my backups to different location, since in the case of fire or theft I could lose all data.\n\nI was thinking to copy everything on external 2.5\" HDDs and store them far away from my apartment.\n\nI have:\n\n* Maxtor M3 Portable External Hard Drive (**4TB**)\n* Seagate Basic Portable Drive (**5TB**)\n* and plan to buy WD Elements Portable Black 2.5 (**5TB**)  \n\n\nAll drives are new and not used much. I have a house in a countryside and that is where I plan to keep my offsite backup. No one lives there and temperature can go from -20\u00b0C to 40\u00b0C.   \nI was wondering do you have any suggestions on how to store these drives? I guess I need to keep them in shade and keep them dry. Do I need to buy some protective materials to isolate them better? \n\nI would like to keep them in a good health for 10 years and to replace them after. Not sure if these ones are able to live that long (even when not used), since they are the cheapest I could find.  \n", "author_fullname": "t2_26c1b19v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store external HDD as an offsite backup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ccz2t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705869140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to move my backups to different location, since in the case of fire or theft I could lose all data.&lt;/p&gt;\n\n&lt;p&gt;I was thinking to copy everything on external 2.5&amp;quot; HDDs and store them far away from my apartment.&lt;/p&gt;\n\n&lt;p&gt;I have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Maxtor M3 Portable External Hard Drive (&lt;strong&gt;4TB&lt;/strong&gt;)&lt;/li&gt;\n&lt;li&gt;Seagate Basic Portable Drive (&lt;strong&gt;5TB&lt;/strong&gt;)&lt;/li&gt;\n&lt;li&gt;and plan to buy WD Elements Portable Black 2.5 (&lt;strong&gt;5TB&lt;/strong&gt;)&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All drives are new and not used much. I have a house in a countryside and that is where I plan to keep my offsite backup. No one lives there and temperature can go from -20\u00b0C to 40\u00b0C.&lt;br/&gt;\nI was wondering do you have any suggestions on how to store these drives? I guess I need to keep them in shade and keep them dry. Do I need to buy some protective materials to isolate them better? &lt;/p&gt;\n\n&lt;p&gt;I would like to keep them in a good health for 10 years and to replace them after. Not sure if these ones are able to live that long (even when not used), since they are the cheapest I could find.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19ccz2t", "is_robot_indexable": true, "report_reasons": null, "author": "zp-87", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccz2t/how_to_store_external_hdd_as_an_offsite_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ccz2t/how_to_store_external_hdd_as_an_offsite_backup/", "subreddit_subscribers": 726988, "created_utc": 1705869140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have 12 16TB HDDs, I plan to buy another 6, I have them mounted in a simple plastic that I bought, could you recommend a case to mount in?", "author_fullname": "t2_jtdjzpua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hdd cage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ccoir", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705868413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have 12 16TB HDDs, I plan to buy another 6, I have them mounted in a simple plastic that I bought, could you recommend a case to mount in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19ccoir", "is_robot_indexable": true, "report_reasons": null, "author": "Silent_Bus_8510", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccoir/hdd_cage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ccoir/hdd_cage/", "subreddit_subscribers": 726988, "created_utc": 1705868413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know that there is individual that share storage between themselves and I know that there is FileCoin\n\nBut no fren and FIL is actually just a currency to give to classic providers\n\nI search for a way to share my storage P2P on a network with random people and get the same transfer/storage amount in return, no money\n\nOnly problem being availability as I don't have a server, so I can't be online all the time. And my data is metered so I want to share really few data because basically it'll cost me 4 times the data amount I want to save (like backup 1 GB of data means one upload of me, one of the other one, one download per person too, multiply it by wanted backups)", "author_fullname": "t2_5slsu5xg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mutual storage sharing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19ccgq2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Serious answer only", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705867870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that there is individual that share storage between themselves and I know that there is FileCoin&lt;/p&gt;\n\n&lt;p&gt;But no fren and FIL is actually just a currency to give to classic providers&lt;/p&gt;\n\n&lt;p&gt;I search for a way to share my storage P2P on a network with random people and get the same transfer/storage amount in return, no money&lt;/p&gt;\n\n&lt;p&gt;Only problem being availability as I don&amp;#39;t have a server, so I can&amp;#39;t be online all the time. And my data is metered so I want to share really few data because basically it&amp;#39;ll cost me 4 times the data amount I want to save (like backup 1 GB of data means one upload of me, one of the other one, one download per person too, multiply it by wanted backups)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "19ccgq2", "is_robot_indexable": true, "report_reasons": null, "author": "xqoe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19ccgq2/mutual_storage_sharing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19ccgq2/mutual_storage_sharing/", "subreddit_subscribers": 726988, "created_utc": 1705867870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to find a good capture card for digitizing tapes.\nHaulage pvr2 is my go to for capture but I understand stand it doesn't work with VirtualDub and it has built in compression.\n\nTried a cheap 5 dollar capture card I bought online and it works with VDub but so far it seems to have Jpg artifacts in the recording, haven't determined if it's the tape or the card but I see compression in VDubs control panel and assume its hardware since I can't turn it off.\n\nI also have a Diamond VC500 that I haven't tried.\nPc is running latest Windows.", "author_fullname": "t2_fk8e08x1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need personal recommendations on capture cards.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19cb7gl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705864724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to find a good capture card for digitizing tapes.\nHaulage pvr2 is my go to for capture but I understand stand it doesn&amp;#39;t work with VirtualDub and it has built in compression.&lt;/p&gt;\n\n&lt;p&gt;Tried a cheap 5 dollar capture card I bought online and it works with VDub but so far it seems to have Jpg artifacts in the recording, haven&amp;#39;t determined if it&amp;#39;s the tape or the card but I see compression in VDubs control panel and assume its hardware since I can&amp;#39;t turn it off.&lt;/p&gt;\n\n&lt;p&gt;I also have a Diamond VC500 that I haven&amp;#39;t tried.\nPc is running latest Windows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19cb7gl", "is_robot_indexable": true, "report_reasons": null, "author": "KWalthersArt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19cb7gl/need_personal_recommendations_on_capture_cards/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19cb7gl/need_personal_recommendations_on_capture_cards/", "subreddit_subscribers": 726988, "created_utc": 1705864724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nI understand why WD Blue and Barracuda HDD shouldn't be used for NAS or 24/7 surveillance, I find why it's not recommended to use WD Red or an Ironwolf hd for basic computing? \\*   \n\n\nspecifically a 4tb SG Ironwolfis $79.99 and SG Barracuda $78.99.  same rpm and same cache size.   \n\n\nI was just looking for a 4tb non-smr drive, Ironwolf is the cheapest option locally.    \n\n\n\\*I'm using it to back pictures, movies, and on occasion installing steam games that are too big to go onto my OS's SSD (just a that need150gb+)", "author_fullname": "t2_4d5wxcdi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downsides using IronWolf for basic daily computing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c9h1s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705860403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I understand why WD Blue and Barracuda HDD shouldn&amp;#39;t be used for NAS or 24/7 surveillance, I find why it&amp;#39;s not recommended to use WD Red or an Ironwolf hd for basic computing? *   &lt;/p&gt;\n\n&lt;p&gt;specifically a 4tb SG Ironwolfis $79.99 and SG Barracuda $78.99.  same rpm and same cache size.   &lt;/p&gt;\n\n&lt;p&gt;I was just looking for a 4tb non-smr drive, Ironwolf is the cheapest option locally.    &lt;/p&gt;\n\n&lt;p&gt;*I&amp;#39;m using it to back pictures, movies, and on occasion installing steam games that are too big to go onto my OS&amp;#39;s SSD (just a that need150gb+)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c9h1s", "is_robot_indexable": true, "report_reasons": null, "author": "WalterMelon81", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c9h1s/downsides_using_ironwolf_for_basic_daily_computing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c9h1s/downsides_using_ironwolf_for_basic_daily_computing/", "subreddit_subscribers": 726988, "created_utc": 1705860403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Reddit,\n\nI am trying (and failing) to download all of the PDFs from the following [LINK](https://archive.org/details/zines?tab=collection&amp;and%5B%5D=subject%3A%22punk%22&amp;and%5B%5D=subject%3A%22fanzine%22&amp;and%5B%5D=year%3A%221980%22&amp;and%5B%5D=year%3A%221981%22&amp;and%5B%5D=year%3A%221982%22&amp;and%5B%5D=year%3A%221983%22&amp;and%5B%5D=year%3A%221984%22&amp;and%5B%5D=year%3A%221985%22&amp;and%5B%5D=year%3A%221986%22&amp;and%5B%5D=year%3A%221987%22&amp;and%5B%5D=year%3A%221988%22&amp;and%5B%5D=year%3A%221989%22) from Internet Archive. None of the Chrome add-ons I have tried recognize the files and I would be very grateful for any help.\n\nThanks!", "author_fullname": "t2_11nvlg47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "INTERNET ARCHIVE: Downloading Multiple PDFs Simultaneously (MAC)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c9c11", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "internet archive, downloading, mass downloads", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705860065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Reddit,&lt;/p&gt;\n\n&lt;p&gt;I am trying (and failing) to download all of the PDFs from the following &lt;a href=\"https://archive.org/details/zines?tab=collection&amp;amp;and%5B%5D=subject%3A%22punk%22&amp;amp;and%5B%5D=subject%3A%22fanzine%22&amp;amp;and%5B%5D=year%3A%221980%22&amp;amp;and%5B%5D=year%3A%221981%22&amp;amp;and%5B%5D=year%3A%221982%22&amp;amp;and%5B%5D=year%3A%221983%22&amp;amp;and%5B%5D=year%3A%221984%22&amp;amp;and%5B%5D=year%3A%221985%22&amp;amp;and%5B%5D=year%3A%221986%22&amp;amp;and%5B%5D=year%3A%221987%22&amp;amp;and%5B%5D=year%3A%221988%22&amp;amp;and%5B%5D=year%3A%221989%22\"&gt;LINK&lt;/a&gt; from Internet Archive. None of the Chrome add-ons I have tried recognize the files and I would be very grateful for any help.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "19c9c11", "is_robot_indexable": true, "report_reasons": null, "author": "HasTheEdgeGoneDull", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c9c11/internet_archive_downloading_multiple_pdfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c9c11/internet_archive_downloading_multiple_pdfs/", "subreddit_subscribers": 726988, "created_utc": 1705860065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First of all, sorry if this is kind of a newbie-ish question.\n\nNow, been looking on Google and so far I've only seen a bunch of options:\n\n- Google cloud backups (up to 15GB free, with 100 or so being paid/subscription based)\n- Cloud backup via jailbreak apps, which are not feasible for me\n- Or a PC, HDD, SSD, or any physical storage media.\n\nMy idea for this is to use a PC I have, but I wanted to know if there's a better way, since this is pretty much my first time doing this sort of stuff, and Google mostly led me to somewhat older posts and websites, so things may have changed.\n\nI also wanted to know: if I go by making a backup on PC/external storage, would there be a loss of quality on media files, and if so, is there a way to prevent or minimize it? Some of my files are FLAC audios, 4K images and the like, and I really want to keep them at the best quality possible.", "author_fullname": "t2_37k7e5yu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to/Best way to backup an Android device?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c8o7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705858409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, sorry if this is kind of a newbie-ish question.&lt;/p&gt;\n\n&lt;p&gt;Now, been looking on Google and so far I&amp;#39;ve only seen a bunch of options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Google cloud backups (up to 15GB free, with 100 or so being paid/subscription based)&lt;/li&gt;\n&lt;li&gt;Cloud backup via jailbreak apps, which are not feasible for me&lt;/li&gt;\n&lt;li&gt;Or a PC, HDD, SSD, or any physical storage media.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My idea for this is to use a PC I have, but I wanted to know if there&amp;#39;s a better way, since this is pretty much my first time doing this sort of stuff, and Google mostly led me to somewhat older posts and websites, so things may have changed.&lt;/p&gt;\n\n&lt;p&gt;I also wanted to know: if I go by making a backup on PC/external storage, would there be a loss of quality on media files, and if so, is there a way to prevent or minimize it? Some of my files are FLAC audios, 4K images and the like, and I really want to keep them at the best quality possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c8o7y", "is_robot_indexable": true, "report_reasons": null, "author": "Hemlock_Deci", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c8o7y/how_tobest_way_to_backup_an_android_device/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c8o7y/how_tobest_way_to_backup_an_android_device/", "subreddit_subscribers": 726988, "created_utc": 1705858409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm thinking of buying a portable ssd enclosure but where I live they are pretty expensive so I'm wondering could I buy a 10\u20ac one from aliexpress or are they just complete garbage and I should just pay 12\u20ac more for a better know quality one.", "author_fullname": "t2_g46z0sj7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on portable ssd enclosures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19c07oi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1705831859.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705831458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of buying a portable ssd enclosure but where I live they are pretty expensive so I&amp;#39;m wondering could I buy a 10\u20ac one from aliexpress or are they just complete garbage and I should just pay 12\u20ac more for a better know quality one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19c07oi", "is_robot_indexable": true, "report_reasons": null, "author": "kalameespeeter", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19c07oi/advice_on_portable_ssd_enclosures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19c07oi/advice_on_portable_ssd_enclosures/", "subreddit_subscribers": 726988, "created_utc": 1705831458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am digitizing a bunch of old family photos 1976-1978 onwards some even date to 1970s , and it is also our family tree, so apart from giving relevant file names how can i make a comment or note in the photo as to who are the people in the photo. I am scanning photos in our flatbed scanner as jpg file.  \n\nI am thinking of using image editor and add a text line below the photo or wherever there is empty space in photo, but is this a good method of tagging or recording comments about photos? ", "author_fullname": "t2_ogj32tug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to tag people in photos - scanned old ones", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bxual", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705821672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am digitizing a bunch of old family photos 1976-1978 onwards some even date to 1970s , and it is also our family tree, so apart from giving relevant file names how can i make a comment or note in the photo as to who are the people in the photo. I am scanning photos in our flatbed scanner as jpg file.  &lt;/p&gt;\n\n&lt;p&gt;I am thinking of using image editor and add a text line below the photo or wherever there is empty space in photo, but is this a good method of tagging or recording comments about photos? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bxual", "is_robot_indexable": true, "report_reasons": null, "author": "Sudden-Air-243", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bxual/how_to_tag_people_in_photos_scanned_old_ones/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bxual/how_to_tag_people_in_photos_scanned_old_ones/", "subreddit_subscribers": 726988, "created_utc": 1705821672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Say I export a channel's content using Discord Chat Exporter, and then the channel I exported from gets deleted\n\nWill the export disappear? If yes, how can I keep the logs after its deletion? Is there a way to make a hard save in my pc?", "author_fullname": "t2_ejv9g8yek", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will Discord Chat Exporter files stay available after a channel gets deleted?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19bxsn2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705821498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I export a channel&amp;#39;s content using Discord Chat Exporter, and then the channel I exported from gets deleted&lt;/p&gt;\n\n&lt;p&gt;Will the export disappear? If yes, how can I keep the logs after its deletion? Is there a way to make a hard save in my pc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19bxsn2", "is_robot_indexable": true, "report_reasons": null, "author": "DeenDre", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19bxsn2/will_discord_chat_exporter_files_stay_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19bxsn2/will_discord_chat_exporter_files_stay_available/", "subreddit_subscribers": 726988, "created_utc": 1705821498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, \n\n&amp;#x200B;\n\nI'm looking for a tool that would allow me to backup:\n\n\\- All my tweets, retweets, liked and bookmarked tweets with the associated media\n\n\\- My followers list\n\n\\- My lists\n\n&amp;#x200B;\n\nIf this tool does not exist, is there a way for me to have programmatical access to my data without using Twitter official API (100USD/Month)? I could write a script or a browser extension.", "author_fullname": "t2_at77r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download an extensive backup of my own twitter account", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19butmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1705810692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a tool that would allow me to backup:&lt;/p&gt;\n\n&lt;p&gt;- All my tweets, retweets, liked and bookmarked tweets with the associated media&lt;/p&gt;\n\n&lt;p&gt;- My followers list&lt;/p&gt;\n\n&lt;p&gt;- My lists&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If this tool does not exist, is there a way for me to have programmatical access to my data without using Twitter official API (100USD/Month)? I could write a script or a browser extension.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19butmc", "is_robot_indexable": true, "report_reasons": null, "author": "bobberkarl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19butmc/download_an_extensive_backup_of_my_own_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19butmc/download_an_extensive_backup_of_my_own_twitter/", "subreddit_subscribers": 726988, "created_utc": 1705810692.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}