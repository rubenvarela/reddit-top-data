{"kind": "Listing", "data": {"after": "t3_1aeufvx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I\u2019m a Jr data engineer which is facing a challenge and I would love to know your opinions and expertise in this topic:\n\nI\u2019m currently handling allots of data in SQL, we receive at a high frequency JSONs with raw data in it (in a single json there could be more than 10k raws) \n\nThe thing is that we need to make some statistics with this JSONS \nWe need to concatenate several Jsons and then apply the statistics (calculate outliers, calculate avgs, calculate percentages, stds, frequency, etc\u2026) \n\nAnd after calculating it we need to insert it in a new table which handles summarizes data. \nAll of this in a SQL stored procedure, the hole process lasts more than 3hours to complete, is there any advice for this kind of stuff, some literature I can read, videos or something to optimize the solution? \nI\u2019m also open to other robust pipelines besides only using SQL!", "author_fullname": "t2_gcej0pe8b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Processing high amount of data with SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aepsld", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706625257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I\u2019m a Jr data engineer which is facing a challenge and I would love to know your opinions and expertise in this topic:&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently handling allots of data in SQL, we receive at a high frequency JSONs with raw data in it (in a single json there could be more than 10k raws) &lt;/p&gt;\n\n&lt;p&gt;The thing is that we need to make some statistics with this JSONS \nWe need to concatenate several Jsons and then apply the statistics (calculate outliers, calculate avgs, calculate percentages, stds, frequency, etc\u2026) &lt;/p&gt;\n\n&lt;p&gt;And after calculating it we need to insert it in a new table which handles summarizes data. \nAll of this in a SQL stored procedure, the hole process lasts more than 3hours to complete, is there any advice for this kind of stuff, some literature I can read, videos or something to optimize the solution? \nI\u2019m also open to other robust pipelines besides only using SQL!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aepsld", "is_robot_indexable": true, "report_reasons": null, "author": "Alex_Alca_", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aepsld/processing_high_amount_of_data_with_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aepsld/processing_high_amount_of_data_with_sql/", "subreddit_subscribers": 157155, "created_utc": 1706625257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to hear stories of data pipelines running on prem. A lot of the tools now are from cloud, but there are industries that are not comfortable using cloud. I have some clients in manufacturing that have stable electricity but not stable internet since they are located at the outskirts of the city. Also, had a gig working in healthcare that requires all data processing to be on prem. I managed to do them with simple python scripts running on local machines. Mostly processing large amounts of csv and text logs from a NAS drive into an OLAP database. Interested to know if there are better implementations.", "author_fullname": "t2_a0i580op", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern data pipeline for on premise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af8ts7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706674252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to hear stories of data pipelines running on prem. A lot of the tools now are from cloud, but there are industries that are not comfortable using cloud. I have some clients in manufacturing that have stable electricity but not stable internet since they are located at the outskirts of the city. Also, had a gig working in healthcare that requires all data processing to be on prem. I managed to do them with simple python scripts running on local machines. Mostly processing large amounts of csv and text logs from a NAS drive into an OLAP database. Interested to know if there are better implementations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1af8ts7", "is_robot_indexable": true, "report_reasons": null, "author": "lezzgooooo", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af8ts7/modern_data_pipeline_for_on_premise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af8ts7/modern_data_pipeline_for_on_premise/", "subreddit_subscribers": 157155, "created_utc": 1706674252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Comp Sci, Data Analytics, Information Systems, stats, math etc  \n\n\nYour thoughts?", "author_fullname": "t2_hiu1pyq6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the ideal masters for data engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af15s3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706653128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Comp Sci, Data Analytics, Information Systems, stats, math etc  &lt;/p&gt;\n\n&lt;p&gt;Your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1af15s3", "is_robot_indexable": true, "report_reasons": null, "author": "PureLavishness8654", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af15s3/what_is_the_ideal_masters_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af15s3/what_is_the_ideal_masters_for_data_engineers/", "subreddit_subscribers": 157155, "created_utc": 1706653128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been working with a handful of higher ed institutions on data modernization. Cloud warehouses (Snowflake, Redshift), moving from ETL to ELT, dbt for the \u201cT\u201d, and dimensional modeling. Most are just moving from on-premises to cloud, have never heard of dbt, and don\u2019t do much in the way of dimensional modelling. The term \u201cData Engineer\u201d is almost never used.\n\nIs there anybody out there? I\u2019d love to hear where people in this community are at, perhaps collaborate or share some stories of what\u2019s working, not working, etc.", "author_fullname": "t2_j8v7zu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Data Stack in Higher Education?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aeulzm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706637307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been working with a handful of higher ed institutions on data modernization. Cloud warehouses (Snowflake, Redshift), moving from ETL to ELT, dbt for the \u201cT\u201d, and dimensional modeling. Most are just moving from on-premises to cloud, have never heard of dbt, and don\u2019t do much in the way of dimensional modelling. The term \u201cData Engineer\u201d is almost never used.&lt;/p&gt;\n\n&lt;p&gt;Is there anybody out there? I\u2019d love to hear where people in this community are at, perhaps collaborate or share some stories of what\u2019s working, not working, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aeulzm", "is_robot_indexable": true, "report_reasons": null, "author": "BIntelligent", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aeulzm/modern_data_stack_in_higher_education/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aeulzm/modern_data_stack_in_higher_education/", "subreddit_subscribers": 157155, "created_utc": 1706637307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. What do you think of the data mesh concept?\n2. Have you implemented or used a data mesh?\n3. If so, what was the experience? What did you learn?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you implemented or used a data mesh?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aeqowi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706627670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;What do you think of the data mesh concept?&lt;/li&gt;\n&lt;li&gt;Have you implemented or used a data mesh?&lt;/li&gt;\n&lt;li&gt;If so, what was the experience? What did you learn?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aeqowi", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aeqowi/have_you_implemented_or_used_a_data_mesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aeqowi/have_you_implemented_or_used_a_data_mesh/", "subreddit_subscribers": 157155, "created_utc": 1706627670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 3 certifications (Snowpro Core, AWS SAA, and Databricks DEA). I am aiming to specialize in Azure and Databricks, and currently working as a data engineering consultant. I am still new to data engineering and have a ton of things to improve and learn.  \n\nWondering if the community can advise me 1 or 2 solid resource(s) for learning Azure, starting from fundamental concepts in Azure. \n\nThanks in advance!", "author_fullname": "t2_7qz1v7vg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best learning path and resources for Azure from a data engineering perspective", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aeu4ry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706636128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3 certifications (Snowpro Core, AWS SAA, and Databricks DEA). I am aiming to specialize in Azure and Databricks, and currently working as a data engineering consultant. I am still new to data engineering and have a ton of things to improve and learn.  &lt;/p&gt;\n\n&lt;p&gt;Wondering if the community can advise me 1 or 2 solid resource(s) for learning Azure, starting from fundamental concepts in Azure. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aeu4ry", "is_robot_indexable": true, "report_reasons": null, "author": "sajiDsarkaR12321", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aeu4ry/best_learning_path_and_resources_for_azure_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aeu4ry/best_learning_path_and_resources_for_azure_from_a/", "subreddit_subscribers": 157155, "created_utc": 1706636128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lw1vuj1gg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "6 Things Data Consulting Clients Absolutely Hate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_1aen5t7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.61, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/O0jx9r0F8PJm7ckhQLiBQqDNcA8zRlzNAsz1k3-Ivo8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706617296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arch.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arch.dev/blog/6-things-data-consulting-clients-absolutely-hate/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bnf25_oUIPNiLb-crkVTAKO3aqLVOhTrdQVSVTQQTjc.jpg?auto=webp&amp;s=8b86994c2f69b95b57e1c4dac243605c5ee3e5a5", "width": 1792, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/bnf25_oUIPNiLb-crkVTAKO3aqLVOhTrdQVSVTQQTjc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b230520895ff2aed8deb78df1a1e8cce655a7bb", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/bnf25_oUIPNiLb-crkVTAKO3aqLVOhTrdQVSVTQQTjc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8094d9413e68a56bfb087cffcb372bab7299e5f8", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/bnf25_oUIPNiLb-crkVTAKO3aqLVOhTrdQVSVTQQTjc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb00dbece4019b1772068b1854ed84fdea198835", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/bnf25_oUIPNiLb-crkVTAKO3aqLVOhTrdQVSVTQQTjc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=274870ffbf4102b8f2c3313354f6a94e232a4dbf", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/bnf25_oUIPNiLb-crkVTAKO3aqLVOhTrdQVSVTQQTjc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e1332e876938e87b03510feed48a4e0748858140", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/bnf25_oUIPNiLb-crkVTAKO3aqLVOhTrdQVSVTQQTjc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=194f45e91b4884dcbb348d587cc7bfa5d690697f", "width": 1080, "height": 617}], "variants": {}, "id": "1jE9dc2gAnTAQGWvyOZUUSlh1-b8h_HZjfgyLv41uUQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aen5t7", "is_robot_indexable": true, "report_reasons": null, "author": "Distinct-Economics24", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aen5t7/6_things_data_consulting_clients_absolutely_hate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arch.dev/blog/6-things-data-consulting-clients-absolutely-hate/", "subreddit_subscribers": 157155, "created_utc": 1706617296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wrote a blog post which looks in depth at Snowflakes new feature for streaming ingestion. The analysis focuses on the Java SDK implementation.\n\nhttps://blog.yuvalitzchakov.com/snowpipe-streaming-deep-dive/", "author_fullname": "t2_elarh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowpipe Streaming Deep Dive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aevqet", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706639988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wrote a blog post which looks in depth at Snowflakes new feature for streaming ingestion. The analysis focuses on the Java SDK implementation.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.yuvalitzchakov.com/snowpipe-streaming-deep-dive/\"&gt;https://blog.yuvalitzchakov.com/snowpipe-streaming-deep-dive/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?auto=webp&amp;s=835bf926ff136d72eca4f99033cf536e142609ce", "width": 6016, "height": 4016}, "resolutions": [{"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8cf704b3753dd8c194fa9453ffc4b2e338680d7f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f9fee6336318e224b5835f1f2780cc86d8a6ace", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a333dea35887c936e1a5ba9b6219ea21a839549b", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d4776d6ae3f8dea3cecfe13d180edee2e57cd92", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e1113e1d5204fefa84386086a413a386c9e63b87", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=387d88e8557da6e22ceee2995cb5d5bc4e554b67", "width": 1080, "height": 720}], "variants": {}, "id": "cTIg0FsOyrYpaGVwlPjUJEFLNjW7rE9BO4u1GNe4fi0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aevqet", "is_robot_indexable": true, "report_reasons": null, "author": "yuvalos", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aevqet/snowpipe_streaming_deep_dive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aevqet/snowpipe_streaming_deep_dive/", "subreddit_subscribers": 157155, "created_utc": 1706639988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I took the self taught route to get into teck, I started with learning sql and python by solving leetcode problems every day for a couple months, then from their learned about the data engineering lifecycle and then the cloud all while working a full time job, I started my job hunt in November when my baby was born, and since then I took my foot off the gas on learning and just been applying and adjusting to being a new father, I figured I learned enough to be able to get a junior position somewhere and get experience, however 60 applications later and not a single interview, I seen people talk about the key is to send hundreds and hundreds of applications but It\u2019s not as easy as it sounds, 9 out of 10 job posting ask for tons of exprience so I don\u2019t waist my time on those and I look for anything less than 3 years of experience but they are not many of them, I feel like I waisted tons of time job hunting and my last project was in November, so now I have the pressure of pumping another project out so their isn\u2019t a gap of inactivity in my resume but I don\u2019t have the time for both applying and doing another project, these last couple weeks I been slacking cause I\u2019m really discouraged, any advice for me?", "author_fullname": "t2_ab7jqmfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats keeping me from getting hired ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1afbpix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n5O49wao8YbGv0VphaheZ5UjcrmlDyBIfKKJEc9DswU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706683840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I took the self taught route to get into teck, I started with learning sql and python by solving leetcode problems every day for a couple months, then from their learned about the data engineering lifecycle and then the cloud all while working a full time job, I started my job hunt in November when my baby was born, and since then I took my foot off the gas on learning and just been applying and adjusting to being a new father, I figured I learned enough to be able to get a junior position somewhere and get experience, however 60 applications later and not a single interview, I seen people talk about the key is to send hundreds and hundreds of applications but It\u2019s not as easy as it sounds, 9 out of 10 job posting ask for tons of exprience so I don\u2019t waist my time on those and I look for anything less than 3 years of experience but they are not many of them, I feel like I waisted tons of time job hunting and my last project was in November, so now I have the pressure of pumping another project out so their isn\u2019t a gap of inactivity in my resume but I don\u2019t have the time for both applying and doing another project, these last couple weeks I been slacking cause I\u2019m really discouraged, any advice for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/47huwwna3qfc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/47huwwna3qfc1.jpeg?auto=webp&amp;s=f32f6159f1e64b44dcad44b1c4a4cecd8b5d3be7", "width": 1242, "height": 2208}, "resolutions": [{"url": "https://preview.redd.it/47huwwna3qfc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85790805a2cbae3160b3bb5b9d28e6c7662149d6", "width": 108, "height": 192}, {"url": "https://preview.redd.it/47huwwna3qfc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7ebf576b3bf0160413c4f5b86236c30ab5aeca7d", "width": 216, "height": 384}, {"url": "https://preview.redd.it/47huwwna3qfc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=65e67b3f5a2106fbe3679c66e8aa7f333dc7c63e", "width": 320, "height": 568}, {"url": "https://preview.redd.it/47huwwna3qfc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=578883775ddd00ab6b173f4a65f5373ccddb8aa6", "width": 640, "height": 1137}, {"url": "https://preview.redd.it/47huwwna3qfc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa9f6a480b1e0eaeae69fab8c8ad375001efb797", "width": 960, "height": 1706}, {"url": "https://preview.redd.it/47huwwna3qfc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=43645cd82ccf9e1c5e2564b45c99ea4badf7a777", "width": 1080, "height": 1920}], "variants": {}, "id": "wxJ1trXliCjNaElPFindLEncoBYGPpskJlhMiTI2BK8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1afbpix", "is_robot_indexable": true, "report_reasons": null, "author": "Mother-Finance-8431", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afbpix/whats_keeping_me_from_getting_hired/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/47huwwna3qfc1.jpeg", "subreddit_subscribers": 157155, "created_utc": 1706683840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wanted to try writing a blogpost for a while, finally got the motivation and time to write it. Would appreciate any constructive feedback on it.\n\n[Link](https://rr43.net/posts/2024/1/Dremel/)", "author_fullname": "t2_dbozei2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My first blog about DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1afakqy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706679855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to try writing a blogpost for a while, finally got the motivation and time to write it. Would appreciate any constructive feedback on it.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://rr43.net/posts/2024/1/Dremel/\"&gt;Link&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1afakqy", "is_robot_indexable": true, "report_reasons": null, "author": "InstitutionalizedSon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afakqy/my_first_blog_about_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1afakqy/my_first_blog_about_de/", "subreddit_subscribers": 157155, "created_utc": 1706679855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nWe've been using ADF in our team, purely ADF. With AI especially my development is so much faster with SP's and scripts, but theres a push to do everything in a dataflow. Obviously its worse off for us if something takes 5-10x longer to develop when I can't use a SP for everything, happy to orchestrate runs in ADF but the actual ETL logic I feel should be done using SQL or python databricks.\n\nHe tried to solely use an ADF to run an API, and when he couldn't he said we can't use the API anymore, insanity. He then blamed the company itself when it wouldn't work.\n\nI'm going to see if I can do a cost comparison in my own time and show everyone how wrong he is, but does anyone else have any information or knowledge on this? I'm actually new to azure and adf so I can't say.", "author_fullname": "t2_4nomabkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost of ADF using Stored Procedures vs pure ADF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aephtl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706624397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve been using ADF in our team, purely ADF. With AI especially my development is so much faster with SP&amp;#39;s and scripts, but theres a push to do everything in a dataflow. Obviously its worse off for us if something takes 5-10x longer to develop when I can&amp;#39;t use a SP for everything, happy to orchestrate runs in ADF but the actual ETL logic I feel should be done using SQL or python databricks.&lt;/p&gt;\n\n&lt;p&gt;He tried to solely use an ADF to run an API, and when he couldn&amp;#39;t he said we can&amp;#39;t use the API anymore, insanity. He then blamed the company itself when it wouldn&amp;#39;t work.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m going to see if I can do a cost comparison in my own time and show everyone how wrong he is, but does anyone else have any information or knowledge on this? I&amp;#39;m actually new to azure and adf so I can&amp;#39;t say.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aephtl", "is_robot_indexable": true, "report_reasons": null, "author": "cantseemelol", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aephtl/cost_of_adf_using_stored_procedures_vs_pure_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aephtl/cost_of_adf_using_stored_procedures_vs_pure_adf/", "subreddit_subscribers": 157155, "created_utc": 1706624397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Blog post about how DuckDB WASM can be used to create data-driven applications in the browser, and how a browser-based SQL Playground can be used to quickly create and share SQL queries and Data Visualizations.\n\n[https://tobilg.com/using-duckdb-wasm-for-in-browser-data-engineering](https://tobilg.com/using-duckdb-wasm-for-in-browser-data-engineering) ", "author_fullname": "t2_cl6jnq23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using DuckDB WASM for in-browser Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af2fab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706656222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Blog post about how DuckDB WASM can be used to create data-driven applications in the browser, and how a browser-based SQL Playground can be used to quickly create and share SQL queries and Data Visualizations.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://tobilg.com/using-duckdb-wasm-for-in-browser-data-engineering\"&gt;https://tobilg.com/using-duckdb-wasm-for-in-browser-data-engineering&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?auto=webp&amp;s=9a55dca929112fb172874385c98d45ae7c113825", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=18da77dcba1e674544d372c7b2f193e89b795ebe", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e63a7f2e770e42f6269f7f310e71b36fbaf5e39c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb4391846b77a474ea272ef9be631adb2aa1b63c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aea9616ec6f138a1edb318393885db37b7e37436", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=069886e8690cd22fdd91e4a08a33c1ce4dd38a80", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b706f763ea19b6f93ba54b12e245f8a0be07430", "width": 1080, "height": 567}], "variants": {}, "id": "UL9SB4dYPLFNRVOq3radBxIFFdc9g8fh0FyEjIetobE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1af2fab", "is_robot_indexable": true, "report_reasons": null, "author": "migh_t", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af2fab/using_duckdb_wasm_for_inbrowser_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af2fab/using_duckdb_wasm_for_inbrowser_data_engineering/", "subreddit_subscribers": 157155, "created_utc": 1706656222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently have a &gt;1TB table containing billions of rows (updated via a data loader from a third party). This data is updated three times a day, and rows are added to the table. We currently use a materialized view to generate a subset of the data that we actually care about. However, we wanted to get real-time data refreshes without waiting for the materialized view to update. We were exploring Airbyte, but their CDC approach requires replicating the table, and we were looking to avoid having 2 copies of a 1 TB table. ", "author_fullname": "t2_vos56utz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for suggestions for real-time data refreshes with large tables (&gt;1TB) in Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1afacpu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706679112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently have a &amp;gt;1TB table containing billions of rows (updated via a data loader from a third party). This data is updated three times a day, and rows are added to the table. We currently use a materialized view to generate a subset of the data that we actually care about. However, we wanted to get real-time data refreshes without waiting for the materialized view to update. We were exploring Airbyte, but their CDC approach requires replicating the table, and we were looking to avoid having 2 copies of a 1 TB table. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1afacpu", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Accountant9659", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afacpu/looking_for_suggestions_for_realtime_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1afacpu/looking_for_suggestions_for_realtime_data/", "subreddit_subscribers": 157155, "created_utc": 1706679112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI\u2019m looking for suggestions on a solution that can help me orchestrate the corporate infrastructure of **30 private VM servers and baremetal servers with GPU**. I\u2019m hoping to find a solution that can help me **spin up a dynamic instance like ECS**, **spin dev and prod Jupyter Lab notebooks**, have a MLflow and dagster setup on these instances and **manage an execution queue for GPU-based servers**.\n\nwe dont have a very large team to manage and support kubernetees installation, but I'm open to discuss if this is the only way. \n\nIf anyone has any experience with similar requirements or can suggest a solution, I\u2019d really appreciate it.\n\nThank you in advance!\n\nI hope this helps! Let me know if you have any other questions.", "author_fullname": "t2_4uziix4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for suggestions on a solution to orchestrate corporate infrastructure of 30 private VM servers and baremetal servers with GPU", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af6zgk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706668736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for suggestions on a solution that can help me orchestrate the corporate infrastructure of &lt;strong&gt;30 private VM servers and baremetal servers with GPU&lt;/strong&gt;. I\u2019m hoping to find a solution that can help me &lt;strong&gt;spin up a dynamic instance like ECS&lt;/strong&gt;, &lt;strong&gt;spin dev and prod Jupyter Lab notebooks&lt;/strong&gt;, have a MLflow and dagster setup on these instances and &lt;strong&gt;manage an execution queue for GPU-based servers&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;we dont have a very large team to manage and support kubernetees installation, but I&amp;#39;m open to discuss if this is the only way. &lt;/p&gt;\n\n&lt;p&gt;If anyone has any experience with similar requirements or can suggest a solution, I\u2019d really appreciate it.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n\n&lt;p&gt;I hope this helps! Let me know if you have any other questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1af6zgk", "is_robot_indexable": true, "report_reasons": null, "author": "mvishruth", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af6zgk/looking_for_suggestions_on_a_solution_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af6zgk/looking_for_suggestions_on_a_solution_to/", "subreddit_subscribers": 157155, "created_utc": 1706668736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nI am a newbie in DE and want to tryout what I've learned with Astronomer Airflow 1:1 course. My ambition is to build another pet project for portfolio.\n\nThe idea is to build a simple pipeline via Airflow (deployed in Managed Workers) that pulls the data from Spotify API, loads it into S3, then performs basic wrangling and loads it into reporting view in Snowflake for further visualization.\n\nKey phases:\n\n1. Create VENV and test/deploy all connection\n2. Containerize the solution with Docker\n3. Deploy the solution in the cloud\n\nDo you mind put some of your thoughts/critique/advice?\n\nThank you!", "author_fullname": "t2_16bfjc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please provide suggestions to my pet project on building Airflow pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af3uuo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706659940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I am a newbie in DE and want to tryout what I&amp;#39;ve learned with Astronomer Airflow 1:1 course. My ambition is to build another pet project for portfolio.&lt;/p&gt;\n\n&lt;p&gt;The idea is to build a simple pipeline via Airflow (deployed in Managed Workers) that pulls the data from Spotify API, loads it into S3, then performs basic wrangling and loads it into reporting view in Snowflake for further visualization.&lt;/p&gt;\n\n&lt;p&gt;Key phases:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create VENV and test/deploy all connection&lt;/li&gt;\n&lt;li&gt;Containerize the solution with Docker&lt;/li&gt;\n&lt;li&gt;Deploy the solution in the cloud&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Do you mind put some of your thoughts/critique/advice?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1af3uuo", "is_robot_indexable": true, "report_reasons": null, "author": "gikis1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af3uuo/please_provide_suggestions_to_my_pet_project_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af3uuo/please_provide_suggestions_to_my_pet_project_on/", "subreddit_subscribers": 157155, "created_utc": 1706659940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generative AI: An introduction to prompt engineering and LangChain for data practitioners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1af0utx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1LlBRyGH7Ruu7iq-whgK92xtlGcmsPFF1fpc6RNrraw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706652381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/teradata/generative-ai-part-1-an-introduction-to-prompt-engineering-and-langchain-742987f2d9c1?source=friends_link&amp;sk=e62cbac26db2d6ed662b6d08c2469504", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?auto=webp&amp;s=792aaa2459236bcca3a62b5897ccb2fa52cda2dc", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f39363f82738e33360409f712d703329008b84eb", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af1879dd02eff4b1f44467912c11dd84b6f9fb5e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=391f964d027ef7a94b467cc31c39d321c8f5586d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7c481fe23e7de5dfc232c1a7c9405821d73033a2", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e82e37157f489c7f5aa8648ee5b996f084b7b5ae", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e77d5093f573cc3157b395821860e00960f2ee41", "width": 1080, "height": 567}], "variants": {}, "id": "J1m4rmgFumu25yh6TpxE1seywkLq5EsdLh_mIIK-4gg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1af0utx", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af0utx/generative_ai_an_introduction_to_prompt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/teradata/generative-ai-part-1-an-introduction-to-prompt-engineering-and-langchain-742987f2d9c1?source=friends_link&amp;sk=e62cbac26db2d6ed662b6d08c2469504", "subreddit_subscribers": 157155, "created_utc": 1706652381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Disney Hotstar Captures One Billion Emojis!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1aev0l4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UN1kW5AHid4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How Disney Hotstar Captures One Billion Emojis!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How Disney Hotstar Captures One Billion Emojis!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UN1kW5AHid4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How Disney Hotstar Captures One Billion Emojis!\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UN1kW5AHid4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UN1kW5AHid4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How Disney Hotstar Captures One Billion Emojis!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1aev0l4", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fgu0-vc156RFpuWdsuUURMAzfYG3czuh6pmQzZ_QMuo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706638288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=UN1kW5AHid4", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mIHuYvDYQbfQRLOny2EI4sH32JUAWGpMGlwwr3ZqjOQ.jpg?auto=webp&amp;s=9e1823e21dd040c84a0d92a629583897608c8b3a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/mIHuYvDYQbfQRLOny2EI4sH32JUAWGpMGlwwr3ZqjOQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=213ad23bed5dceed758188cb1a390f51614166a1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/mIHuYvDYQbfQRLOny2EI4sH32JUAWGpMGlwwr3ZqjOQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b64681ca8e03c58910d4959185d2dbbd335eb12", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/mIHuYvDYQbfQRLOny2EI4sH32JUAWGpMGlwwr3ZqjOQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d033c897cf066d4f2d1e9aa4a7225b7b2291c5d5", "width": 320, "height": 240}], "variants": {}, "id": "GMU0CgoG92Xc4dyKC7706W9SAKFbpBUPbuiqgBfhfQY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aev0l4", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aev0l4/how_disney_hotstar_captures_one_billion_emojis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=UN1kW5AHid4", "subreddit_subscribers": 157155, "created_utc": 1706638288.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How Disney Hotstar Captures One Billion Emojis!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UN1kW5AHid4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How Disney Hotstar Captures One Billion Emojis!\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UN1kW5AHid4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Redshift Enthusiasts,\n\nI'm encountering a puzzling situation with the Redshift COPY command and could really use some insights from the community.\n\nHere's the scenario: I'm in the midst of copying a substantial 2 GB CSV file from S3 into Redshift as part of a full load operation. Naturally, given the size of the file, it's taking quite a bit of time to complete.\n\nIn an effort to expedite the process, I decided to scale up my Redshift cluster. Initially, I was operating on a single dc2.xlarge node, and I thought increasing it to a cluster with two dc2.xlarge nodes would significantly improve the load time.\n\nHowever, to my surprise, the two-node cluster seems to be taking even longer compared to the single-node setup. This unexpected turn has left me scratching my head, wondering what could be causing this slowdown.\n\nI've pondered potential reasons behind this counterintuitive outcome. Could it be an issue with the distribution keys, data skew, or perhaps something else entirely?\n\nI'd greatly appreciate any insights, tips, or experiences you've had with similar situations. What could be causing the two-node cluster to lag behind its single-node counterpart in terms of load times?\n\nLooking forward to your thoughts and expertise!\n\nCheers!", "author_fullname": "t2_7nvr4m4i4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Troubleshooting Redshift COPY Command Performance: Need Help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af8onh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706673814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Redshift Enthusiasts,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m encountering a puzzling situation with the Redshift COPY command and could really use some insights from the community.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the scenario: I&amp;#39;m in the midst of copying a substantial 2 GB CSV file from S3 into Redshift as part of a full load operation. Naturally, given the size of the file, it&amp;#39;s taking quite a bit of time to complete.&lt;/p&gt;\n\n&lt;p&gt;In an effort to expedite the process, I decided to scale up my Redshift cluster. Initially, I was operating on a single dc2.xlarge node, and I thought increasing it to a cluster with two dc2.xlarge nodes would significantly improve the load time.&lt;/p&gt;\n\n&lt;p&gt;However, to my surprise, the two-node cluster seems to be taking even longer compared to the single-node setup. This unexpected turn has left me scratching my head, wondering what could be causing this slowdown.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve pondered potential reasons behind this counterintuitive outcome. Could it be an issue with the distribution keys, data skew, or perhaps something else entirely?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d greatly appreciate any insights, tips, or experiences you&amp;#39;ve had with similar situations. What could be causing the two-node cluster to lag behind its single-node counterpart in terms of load times?&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your thoughts and expertise!&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1af8onh", "is_robot_indexable": true, "report_reasons": null, "author": "Flimsy-Mirror974", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af8onh/troubleshooting_redshift_copy_command_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af8onh/troubleshooting_redshift_copy_command_performance/", "subreddit_subscribers": 157155, "created_utc": 1706673814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Folks aren't too happy with Synapse for multiple reasons; one is that we can't get it running on a private endpoint, so port 1433 sits on the internet for the Serverless SQL Pool.  Apparently, this is also the case with Fabric, although Fabric uses managed identities whereas Synapse has a SQL Auth method turned on by default.\n\nThis is our data flow  Dataverse --&gt; Synapse Link --- &gt; Datalake Storage Gen 2 ---&gt; Synapse Analytics serverless SQL Endpoint ----&gt; Synapse Pipelines -----&gt; Upsert data and schema evolution to Azure SQL Server -----&gt; Snaplogic ------&gt; AWS Redshift.\n\nI am the build owner for the architecture up to Azure SQL Server and want to come up with a secure alternative (no open port 1433 to the internet).  The solution needs to do schema evolution from the D365 Rest endpoint as well as update all changed data every 5 to 10 minutes. The current system does all that with minimal issues.  I've tried pursuing a private endpoint for the Synapse SQL endpoint and was told by Microsoft it's not supported.\n\nAny suggestions are much appreciated. I have VMS on premise at my current disposal and will eventually get them in Azure when we finish a hardened image. For what it's worth we also use BigTable and VErtex at GCP and Snaplogic and Redshift on AWS.", "author_fullname": "t2_5yj82gi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Platform suggestions to migrate off of Azure Synapse Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af70gd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706668813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Folks aren&amp;#39;t too happy with Synapse for multiple reasons; one is that we can&amp;#39;t get it running on a private endpoint, so port 1433 sits on the internet for the Serverless SQL Pool.  Apparently, this is also the case with Fabric, although Fabric uses managed identities whereas Synapse has a SQL Auth method turned on by default.&lt;/p&gt;\n\n&lt;p&gt;This is our data flow  Dataverse --&amp;gt; Synapse Link --- &amp;gt; Datalake Storage Gen 2 ---&amp;gt; Synapse Analytics serverless SQL Endpoint ----&amp;gt; Synapse Pipelines -----&amp;gt; Upsert data and schema evolution to Azure SQL Server -----&amp;gt; Snaplogic ------&amp;gt; AWS Redshift.&lt;/p&gt;\n\n&lt;p&gt;I am the build owner for the architecture up to Azure SQL Server and want to come up with a secure alternative (no open port 1433 to the internet).  The solution needs to do schema evolution from the D365 Rest endpoint as well as update all changed data every 5 to 10 minutes. The current system does all that with minimal issues.  I&amp;#39;ve tried pursuing a private endpoint for the Synapse SQL endpoint and was told by Microsoft it&amp;#39;s not supported.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions are much appreciated. I have VMS on premise at my current disposal and will eventually get them in Azure when we finish a hardened image. For what it&amp;#39;s worth we also use BigTable and VErtex at GCP and Snaplogic and Redshift on AWS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1af70gd", "is_robot_indexable": true, "report_reasons": null, "author": "Swimming_Cry_6841", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af70gd/looking_for_platform_suggestions_to_migrate_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af70gd/looking_for_platform_suggestions_to_migrate_off/", "subreddit_subscribers": 157155, "created_utc": 1706668813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I feel like I need to learn cloud infrastructure. I have about 8 years of experience as a data analyst. Here is my program/language stack:\n\n* Python\n* VBA (lol)\n* Power BI/Power Query\n* SQL\n* Alteryx\n\nI'm pretty comfortable/experienced with general programming/automation/ETL/visualization but I've never worked with big data/cloud stuff. Just wondering what a data engineering hiring manager would want to see.", "author_fullname": "t2_1ad62ux7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do I need to add to my stack to break into data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af3rg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706659697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel like I need to learn cloud infrastructure. I have about 8 years of experience as a data analyst. Here is my program/language stack:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;VBA (lol)&lt;/li&gt;\n&lt;li&gt;Power BI/Power Query&lt;/li&gt;\n&lt;li&gt;SQL&lt;/li&gt;\n&lt;li&gt;Alteryx&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m pretty comfortable/experienced with general programming/automation/ETL/visualization but I&amp;#39;ve never worked with big data/cloud stuff. Just wondering what a data engineering hiring manager would want to see.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1af3rg5", "is_robot_indexable": true, "report_reasons": null, "author": "VegaGT-VZ", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af3rg5/what_do_i_need_to_add_to_my_stack_to_break_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af3rg5/what_do_i_need_to_add_to_my_stack_to_break_into/", "subreddit_subscribers": 157155, "created_utc": 1706659697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here goes our latest blog on Data Types and their impact on Database Replication - [https://blog.peerdb.io/role-of-data-type-mapping-in-database-replication](https://blog.peerdb.io/role-of-data-type-mapping-in-database-replication)\n\nDid you know that carefully designing data type mapping during database replication can?  \n\n\n1. **Save Costs:** Replicating to native data types in the Warehouse avoids additional transformations and typecasting from apps such as [dbt Labs](https://www.linkedin.com/company/dbtlabs/), thus saving on compute costs.\n2. **Enable Advanced Analytics:** Replicating to native data types in the Warehouse enables consumer apps to use advanced functions and operators, facilitating advanced querying and analytics.\n3. **Reduce Tech Debt:** Your data engineers don't need to write additional code to convert strings to native data types, thereby reducing technical debt.\n\nThe blog also talks about how [PeerDB](https://www.peerdb.io/)\u00a0handles data type mapping, with practical examples.", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Types and their impact on Database Replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af0woe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706652508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here goes our latest blog on Data Types and their impact on Database Replication - &lt;a href=\"https://blog.peerdb.io/role-of-data-type-mapping-in-database-replication\"&gt;https://blog.peerdb.io/role-of-data-type-mapping-in-database-replication&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Did you know that carefully designing data type mapping during database replication can?  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Save Costs:&lt;/strong&gt; Replicating to native data types in the Warehouse avoids additional transformations and typecasting from apps such as &lt;a href=\"https://www.linkedin.com/company/dbtlabs/\"&gt;dbt Labs&lt;/a&gt;, thus saving on compute costs.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enable Advanced Analytics:&lt;/strong&gt; Replicating to native data types in the Warehouse enables consumer apps to use advanced functions and operators, facilitating advanced querying and analytics.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Reduce Tech Debt:&lt;/strong&gt; Your data engineers don&amp;#39;t need to write additional code to convert strings to native data types, thereby reducing technical debt.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The blog also talks about how &lt;a href=\"https://www.peerdb.io/\"&gt;PeerDB&lt;/a&gt;\u00a0handles data type mapping, with practical examples.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?auto=webp&amp;s=3d7d36799bd51f98de4b9353f2e78017c7679558", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cb37b2ff5f6bc1dbedb12c7d71a2aafd8716f0be", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a6c011458b3e6fd2ea7c273a9218fbcaa1d8cd6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc82869bd56aa6f98d5a6f517977a41e3c679a3b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fdcf68b083a1ec1a62991f6114a742e6a31dfa13", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0c8c5bbe8d974c8a8a3cfecf2bf494deeb905833", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14f0975bd04e16ab1af2688fca84519217c0372f", "width": 1080, "height": 567}], "variants": {}, "id": "L3mxAd9-4u7t5R_5a5u44x49ddQcP6mlPm3L75SeZsQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1af0woe", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af0woe/data_types_and_their_impact_on_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af0woe/data_types_and_their_impact_on_database/", "subreddit_subscribers": 157155, "created_utc": 1706652508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_un9ertyb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4 simple software engineering habits that transformed my productivity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_1afe5ug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/4kP-FUOwxhBUYC9OE08WdSJCvzdPdX92Eb4bizlVL74.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706693946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "read.engineerscodex.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://read.engineerscodex.com/p/simple-software-engineering-habits?utm_source=%252Fbrowse%252Ftechnology&amp;utm_medium=reader2&amp;ref=dailydev", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?auto=webp&amp;s=5871f0d7487438c46b01eebb7041b2f5a2ba7527", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bdec1cf8f05f2821e71a81d57b8b1b702bc44ebf", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=23e5627d5bdcdcaa244366390da0a789cad4ee8c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7ebe3ed6fb441eabc7f8c3f2481e9ead91151a20", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03a92ae3e201c4437dc18cbe46538d166170fc37", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=371233137e9fb0406471aba4201351f9bf459b61", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=32f7bba1c8cf00ab2b15dfe0088d3570c3d8f56c", "width": 1080, "height": 540}], "variants": {}, "id": "jv2y0q2UCecenbfBaCYYmlJZojw4Z73RqFv9jW4FMmA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1afe5ug", "is_robot_indexable": true, "report_reasons": null, "author": "boyrot37", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afe5ug/4_simple_software_engineering_habits_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://read.engineerscodex.com/p/simple-software-engineering-habits?utm_source=%252Fbrowse%252Ftechnology&amp;utm_medium=reader2&amp;ref=dailydev", "subreddit_subscribers": 157155, "created_utc": 1706693946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \nI am SQL Developer with 5 YOE, working\nCurrently (2 yrs): Snowflake, Snaplogic (simple pipelines) &amp; Datastage (migrating out of it)\n[Very less development, so switching]\n\nPrev Exp: T-SQL, Sql Server &amp; some Power BI\nEducation: from Non-IT, learnt Sql for job\n\nExp level: Good at SQL, can understand ETL workflows, self-learning python [learnt all req for pyspark - but since no prior coding exp feeling difficult] &amp; completed 1 hands-on Azure Data Factory pipeline course.\n\nQUESTION: (considering Long-term)\nImprove python &amp; Snowflake and switch ?\nOR  \nImprove python &amp; do atleast 1 pyspark project (in Azure) and switch ?\n\nMy doubts: \nI heard MS Stack (ADF, ADB) is not consistent and really difficult for big projects.\nAlso, Snowflake cost is high &amp; very less companies use SF+python as main stack.\nAny other suggestion, welcome.\n\nPls consider all points.\nNote: I was not lucky enuf to work on Python or advance Data Engg stack, so requesting for genuine practical suggestions instead of trolling \ud83d\ude4f\ud83c\udffb", "author_fullname": "t2_cw3fmfvos", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling STUCK, Need Career Advice in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af9ycw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706677805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nI am SQL Developer with 5 YOE, working\nCurrently (2 yrs): Snowflake, Snaplogic (simple pipelines) &amp;amp; Datastage (migrating out of it)\n[Very less development, so switching]&lt;/p&gt;\n\n&lt;p&gt;Prev Exp: T-SQL, Sql Server &amp;amp; some Power BI\nEducation: from Non-IT, learnt Sql for job&lt;/p&gt;\n\n&lt;p&gt;Exp level: Good at SQL, can understand ETL workflows, self-learning python [learnt all req for pyspark - but since no prior coding exp feeling difficult] &amp;amp; completed 1 hands-on Azure Data Factory pipeline course.&lt;/p&gt;\n\n&lt;p&gt;QUESTION: (considering Long-term)\nImprove python &amp;amp; Snowflake and switch ?\nOR&lt;br/&gt;\nImprove python &amp;amp; do atleast 1 pyspark project (in Azure) and switch ?&lt;/p&gt;\n\n&lt;p&gt;My doubts: \nI heard MS Stack (ADF, ADB) is not consistent and really difficult for big projects.\nAlso, Snowflake cost is high &amp;amp; very less companies use SF+python as main stack.\nAny other suggestion, welcome.&lt;/p&gt;\n\n&lt;p&gt;Pls consider all points.\nNote: I was not lucky enuf to work on Python or advance Data Engg stack, so requesting for genuine practical suggestions instead of trolling \ud83d\ude4f\ud83c\udffb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1af9ycw", "is_robot_indexable": true, "report_reasons": null, "author": "raj_gd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af9ycw/feeling_stuck_need_career_advice_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af9ycw/feeling_stuck_need_career_advice_in_de/", "subreddit_subscribers": 157155, "created_utc": 1706677805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\njust looking for some clarification on best practices for dimensional and fact tables. At my work, we have a number of dimensional tables. Say we are looking at the dimCustomers table. I have 'dimCustomerId', 'CustomerId', 'CustomerName' as fields. The 'dimCustomerId' is an auto incrementing ID. The dimCustomerId is what is used in my fact table. \n\n  \nWhat is the point in having this dimCustomerId? Everywhere else in our business including our lakehouse, we simply use 'CustomerId'. When we load data to our fact table, we read in the dimCustomers table, use CustomerId to find the dimCustomerId, and then store dimCustomerId in the fact table. It seems like an unnecessary, round about way since we get the dimCustomerId using CustomerId, so why not just use CustomerId? \n\nWould it be suitable to have a dimCustomer table with 'CustomerId' as the PK and 'CustomerName' as the field, removing the dimCustomerId altogether? I'm not looking to actually do this, just for my own learning. ", "author_fullname": "t2_1yo0xaq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dimensional table ids", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af7s1s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706671079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;just looking for some clarification on best practices for dimensional and fact tables. At my work, we have a number of dimensional tables. Say we are looking at the dimCustomers table. I have &amp;#39;dimCustomerId&amp;#39;, &amp;#39;CustomerId&amp;#39;, &amp;#39;CustomerName&amp;#39; as fields. The &amp;#39;dimCustomerId&amp;#39; is an auto incrementing ID. The dimCustomerId is what is used in my fact table. &lt;/p&gt;\n\n&lt;p&gt;What is the point in having this dimCustomerId? Everywhere else in our business including our lakehouse, we simply use &amp;#39;CustomerId&amp;#39;. When we load data to our fact table, we read in the dimCustomers table, use CustomerId to find the dimCustomerId, and then store dimCustomerId in the fact table. It seems like an unnecessary, round about way since we get the dimCustomerId using CustomerId, so why not just use CustomerId? &lt;/p&gt;\n\n&lt;p&gt;Would it be suitable to have a dimCustomer table with &amp;#39;CustomerId&amp;#39; as the PK and &amp;#39;CustomerName&amp;#39; as the field, removing the dimCustomerId altogether? I&amp;#39;m not looking to actually do this, just for my own learning. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1af7s1s", "is_robot_indexable": true, "report_reasons": null, "author": "justanator101", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af7s1s/dimensional_table_ids/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af7s1s/dimensional_table_ids/", "subreddit_subscribers": 157155, "created_utc": 1706671079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Okay so, here goes. I'm not a Data Engineer so please forgive me if I get a few things wrong. \n\nWe use azure as an organisation and we have a large (to us!) amount of data in a collection in MongoDB (around 40 Million documents). It includes a ton of nested fields and we would like to be able to aggregate this data, group on certain fields and output sum amounts (likely to be under 1.5M documents) - nothing too crazy. It is all indexed and I have tried grouping in python and extracting but it takes forever to run. This leads me to my next point, ideally we would like to run this monthly or quarterly (and adhoc too). We report in Power BI so it would be great if we could have some sort of connection there but I'm lost as to what tools or \"pipeline\" (for lack of a better word) to suggest. \n\nIn my mind I would use a tool like airflow to transform this data and then upload back into the MongoDB into a new collection? So the grouped data can be indexed and therefore it will be able to be retrieved faster? Is that correct? Or am I better off uploading it to an azure data factory rather than MongoDB as it has better connections in Power BI? \n\nI'm open to learning new tech but we are quite a small team and would prefer a low cost solution and staying within either Mongo or Azure (I don't mind learning open source stuff like airflow). Ideally as well I would like someone else to be able to run this (in the event that I'm off), whether that be pulling from github or something else. Am open to suggestions! Thanks in advance for reading my garbled explanation lol. \n\nTLDR: We have a lot of data in MongoDB, and we report in Power BI - we want to transform this data and upload to either MongoDB or a low cost Azure hosted service but need advice on what tools to best approach this with.", "author_fullname": "t2_tcnjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with an ETL process and MongoDB (Am not a Data Engineer)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aeufvx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706636897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay so, here goes. I&amp;#39;m not a Data Engineer so please forgive me if I get a few things wrong. &lt;/p&gt;\n\n&lt;p&gt;We use azure as an organisation and we have a large (to us!) amount of data in a collection in MongoDB (around 40 Million documents). It includes a ton of nested fields and we would like to be able to aggregate this data, group on certain fields and output sum amounts (likely to be under 1.5M documents) - nothing too crazy. It is all indexed and I have tried grouping in python and extracting but it takes forever to run. This leads me to my next point, ideally we would like to run this monthly or quarterly (and adhoc too). We report in Power BI so it would be great if we could have some sort of connection there but I&amp;#39;m lost as to what tools or &amp;quot;pipeline&amp;quot; (for lack of a better word) to suggest. &lt;/p&gt;\n\n&lt;p&gt;In my mind I would use a tool like airflow to transform this data and then upload back into the MongoDB into a new collection? So the grouped data can be indexed and therefore it will be able to be retrieved faster? Is that correct? Or am I better off uploading it to an azure data factory rather than MongoDB as it has better connections in Power BI? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m open to learning new tech but we are quite a small team and would prefer a low cost solution and staying within either Mongo or Azure (I don&amp;#39;t mind learning open source stuff like airflow). Ideally as well I would like someone else to be able to run this (in the event that I&amp;#39;m off), whether that be pulling from github or something else. Am open to suggestions! Thanks in advance for reading my garbled explanation lol. &lt;/p&gt;\n\n&lt;p&gt;TLDR: We have a lot of data in MongoDB, and we report in Power BI - we want to transform this data and upload to either MongoDB or a low cost Azure hosted service but need advice on what tools to best approach this with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aeufvx", "is_robot_indexable": true, "report_reasons": null, "author": "Zulowie", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aeufvx/need_help_with_an_etl_process_and_mongodb_am_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aeufvx/need_help_with_an_etl_process_and_mongodb_am_not/", "subreddit_subscribers": 157155, "created_utc": 1706636897.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}