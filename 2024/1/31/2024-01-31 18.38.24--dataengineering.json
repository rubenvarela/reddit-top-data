{"kind": "Listing", "data": {"after": "t3_1aex15l", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to hear stories of data pipelines running on prem. A lot of the tools now are from cloud, but there are industries that are not comfortable using cloud. I have some clients in manufacturing that have stable electricity but not stable internet since they are located at the outskirts of the city. Also, had a gig working in healthcare that requires all data processing to be on prem. I managed to do them with simple python scripts running on local machines. Mostly processing large amounts of csv and text logs from a NAS drive into an OLAP database. Interested to know if there are better implementations.", "author_fullname": "t2_a0i580op", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern data pipeline for on premise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af8ts7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706674252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to hear stories of data pipelines running on prem. A lot of the tools now are from cloud, but there are industries that are not comfortable using cloud. I have some clients in manufacturing that have stable electricity but not stable internet since they are located at the outskirts of the city. Also, had a gig working in healthcare that requires all data processing to be on prem. I managed to do them with simple python scripts running on local machines. Mostly processing large amounts of csv and text logs from a NAS drive into an OLAP database. Interested to know if there are better implementations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1af8ts7", "is_robot_indexable": true, "report_reasons": null, "author": "lezzgooooo", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af8ts7/modern_data_pipeline_for_on_premise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af8ts7/modern_data_pipeline_for_on_premise/", "subreddit_subscribers": 157231, "created_utc": 1706674252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Comp Sci, Data Analytics, Information Systems, stats, math etc  \n\n\nYour thoughts?", "author_fullname": "t2_hiu1pyq6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the ideal masters for data engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af15s3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706653128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Comp Sci, Data Analytics, Information Systems, stats, math etc  &lt;/p&gt;\n\n&lt;p&gt;Your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1af15s3", "is_robot_indexable": true, "report_reasons": null, "author": "PureLavishness8654", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af15s3/what_is_the_ideal_masters_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af15s3/what_is_the_ideal_masters_for_data_engineers/", "subreddit_subscribers": 157231, "created_utc": 1706653128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Edit : Thank you guys, you're all awesome and helpful.\n\nMy manager at work told me to focus on these two, I have some low level experience with Python but never heard about Spark Scala, do they work together, I will be working on big data shortly with no experience.\n\nSorry for this stupid question, I am still flabbergasted by this stack that got thrown onto me, did some internet search and all I see is advanced and complex guides.\n\n&amp;#x200B;\n\nThank you so much.", "author_fullname": "t2_43bjqfmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python and Spark Scala", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aff8gu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706716375.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706698474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit : Thank you guys, you&amp;#39;re all awesome and helpful.&lt;/p&gt;\n\n&lt;p&gt;My manager at work told me to focus on these two, I have some low level experience with Python but never heard about Spark Scala, do they work together, I will be working on big data shortly with no experience.&lt;/p&gt;\n\n&lt;p&gt;Sorry for this stupid question, I am still flabbergasted by this stack that got thrown onto me, did some internet search and all I see is advanced and complex guides.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you so much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aff8gu", "is_robot_indexable": true, "report_reasons": null, "author": "WadieXkiller", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aff8gu/python_and_spark_scala/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aff8gu/python_and_spark_scala/", "subreddit_subscribers": 157231, "created_utc": 1706698474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wanted to try writing a blogpost for a while, finally got the motivation and time to write it. Would appreciate any constructive feedback on it.\n\n[Link](https://rr43.net/posts/2024/1/Dremel/)", "author_fullname": "t2_dbozei2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My first blog about DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1afakqy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706679855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to try writing a blogpost for a while, finally got the motivation and time to write it. Would appreciate any constructive feedback on it.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://rr43.net/posts/2024/1/Dremel/\"&gt;Link&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1afakqy", "is_robot_indexable": true, "report_reasons": null, "author": "InstitutionalizedSon", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afakqy/my_first_blog_about_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1afakqy/my_first_blog_about_de/", "subreddit_subscribers": 157231, "created_utc": 1706679855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Dagster Believes About Data Platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_1afnd1d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/1HfcUuzrMpvBBY94JElFNYso1NQQ4RrLwGz_rUBvKb8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706722293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/what-dagster-believes-about-data-platforms", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lSg3RztVkw9k9cNY0mz5t02hS4bQaxvuRFQqCKWbYfU.jpg?auto=webp&amp;s=94dcf8ce7019ce3e221a84088531c82d39c59478", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/lSg3RztVkw9k9cNY0mz5t02hS4bQaxvuRFQqCKWbYfU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eea7cd5c0c3002c13b2398269a37e06cf911e3ae", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lSg3RztVkw9k9cNY0mz5t02hS4bQaxvuRFQqCKWbYfU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6982f3cf54d8a8754e64ee7e2c4bc544d1a5422c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lSg3RztVkw9k9cNY0mz5t02hS4bQaxvuRFQqCKWbYfU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=74ed1228f650dddfb6ed29eb136a6b8f73ada0ac", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/lSg3RztVkw9k9cNY0mz5t02hS4bQaxvuRFQqCKWbYfU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=80a10915705eaf3527c7d89450431f653a590f8d", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/lSg3RztVkw9k9cNY0mz5t02hS4bQaxvuRFQqCKWbYfU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9fbe788ae92611b87791c735d2d71eb2e00e28b5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/lSg3RztVkw9k9cNY0mz5t02hS4bQaxvuRFQqCKWbYfU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=006b1460ef750708d063f2e3c7670fde92270524", "width": 1080, "height": 567}], "variants": {}, "id": "9BPh1HBe8dpb9hwolf4ivC5UxBl9ds4I31wiMA6yM0E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1afnd1d", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afnd1d/what_dagster_believes_about_data_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/what-dagster-believes-about-data-platforms", "subreddit_subscribers": 157231, "created_utc": 1706722293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wrote a blog post which looks in depth at Snowflakes new feature for streaming ingestion. The analysis focuses on the Java SDK implementation.\n\nhttps://blog.yuvalitzchakov.com/snowpipe-streaming-deep-dive/", "author_fullname": "t2_elarh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowpipe Streaming Deep Dive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aevqet", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706639988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wrote a blog post which looks in depth at Snowflakes new feature for streaming ingestion. The analysis focuses on the Java SDK implementation.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.yuvalitzchakov.com/snowpipe-streaming-deep-dive/\"&gt;https://blog.yuvalitzchakov.com/snowpipe-streaming-deep-dive/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?auto=webp&amp;s=835bf926ff136d72eca4f99033cf536e142609ce", "width": 6016, "height": 4016}, "resolutions": [{"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8cf704b3753dd8c194fa9453ffc4b2e338680d7f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f9fee6336318e224b5835f1f2780cc86d8a6ace", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a333dea35887c936e1a5ba9b6219ea21a839549b", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d4776d6ae3f8dea3cecfe13d180edee2e57cd92", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e1113e1d5204fefa84386086a413a386c9e63b87", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/BQMlr5BJcPBzGFInNQyS7tVGM5l1Jje1QykaIHqVfOw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=387d88e8557da6e22ceee2995cb5d5bc4e554b67", "width": 1080, "height": 720}], "variants": {}, "id": "cTIg0FsOyrYpaGVwlPjUJEFLNjW7rE9BO4u1GNe4fi0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aevqet", "is_robot_indexable": true, "report_reasons": null, "author": "yuvalos", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aevqet/snowpipe_streaming_deep_dive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aevqet/snowpipe_streaming_deep_dive/", "subreddit_subscribers": 157231, "created_utc": 1706639988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_un9ertyb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4 simple software engineering habits that transformed my productivity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1afe5ug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/4kP-FUOwxhBUYC9OE08WdSJCvzdPdX92Eb4bizlVL74.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706693946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "read.engineerscodex.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://read.engineerscodex.com/p/simple-software-engineering-habits?utm_source=%252Fbrowse%252Ftechnology&amp;utm_medium=reader2&amp;ref=dailydev", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?auto=webp&amp;s=5871f0d7487438c46b01eebb7041b2f5a2ba7527", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bdec1cf8f05f2821e71a81d57b8b1b702bc44ebf", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=23e5627d5bdcdcaa244366390da0a789cad4ee8c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7ebe3ed6fb441eabc7f8c3f2481e9ead91151a20", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03a92ae3e201c4437dc18cbe46538d166170fc37", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=371233137e9fb0406471aba4201351f9bf459b61", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/jFIuUEXCUZiN4K05QzfG924liJb35SyGDZ9cYW5k8T0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=32f7bba1c8cf00ab2b15dfe0088d3570c3d8f56c", "width": 1080, "height": 540}], "variants": {}, "id": "jv2y0q2UCecenbfBaCYYmlJZojw4Z73RqFv9jW4FMmA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1afe5ug", "is_robot_indexable": true, "report_reasons": null, "author": "boyrot37", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afe5ug/4_simple_software_engineering_habits_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://read.engineerscodex.com/p/simple-software-engineering-habits?utm_source=%252Fbrowse%252Ftechnology&amp;utm_medium=reader2&amp;ref=dailydev", "subreddit_subscribers": 157231, "created_utc": 1706693946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently have a &gt;1TB table containing billions of rows (updated via a data loader from a third party). This data is updated three times a day, and rows are added to the table. We currently use a materialized view to generate a subset of the data that we actually care about. However, we wanted to get real-time data refreshes without waiting for the materialized view to update. We were exploring Airbyte, but their CDC approach requires replicating the table, and we were looking to avoid having 2 copies of a 1 TB table. ", "author_fullname": "t2_vos56utz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for suggestions for real-time data refreshes with large tables (&gt;1TB) in Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1afacpu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706679112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently have a &amp;gt;1TB table containing billions of rows (updated via a data loader from a third party). This data is updated three times a day, and rows are added to the table. We currently use a materialized view to generate a subset of the data that we actually care about. However, we wanted to get real-time data refreshes without waiting for the materialized view to update. We were exploring Airbyte, but their CDC approach requires replicating the table, and we were looking to avoid having 2 copies of a 1 TB table. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1afacpu", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Accountant9659", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afacpu/looking_for_suggestions_for_realtime_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1afacpu/looking_for_suggestions_for_realtime_data/", "subreddit_subscribers": 157231, "created_utc": 1706679112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Blog post about how DuckDB WASM can be used to create data-driven applications in the browser, and how a browser-based SQL Playground can be used to quickly create and share SQL queries and Data Visualizations.\n\n[https://tobilg.com/using-duckdb-wasm-for-in-browser-data-engineering](https://tobilg.com/using-duckdb-wasm-for-in-browser-data-engineering) ", "author_fullname": "t2_cl6jnq23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using DuckDB WASM for in-browser Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af2fab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706656222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Blog post about how DuckDB WASM can be used to create data-driven applications in the browser, and how a browser-based SQL Playground can be used to quickly create and share SQL queries and Data Visualizations.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://tobilg.com/using-duckdb-wasm-for-in-browser-data-engineering\"&gt;https://tobilg.com/using-duckdb-wasm-for-in-browser-data-engineering&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?auto=webp&amp;s=9a55dca929112fb172874385c98d45ae7c113825", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=18da77dcba1e674544d372c7b2f193e89b795ebe", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e63a7f2e770e42f6269f7f310e71b36fbaf5e39c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb4391846b77a474ea272ef9be631adb2aa1b63c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aea9616ec6f138a1edb318393885db37b7e37436", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=069886e8690cd22fdd91e4a08a33c1ce4dd38a80", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/EzFH0p7EBUBzumH4rR0JEatagGuFhXEHmGPJpQGZxGQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b706f763ea19b6f93ba54b12e245f8a0be07430", "width": 1080, "height": 567}], "variants": {}, "id": "UL9SB4dYPLFNRVOq3radBxIFFdc9g8fh0FyEjIetobE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1af2fab", "is_robot_indexable": true, "report_reasons": null, "author": "migh_t", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af2fab/using_duckdb_wasm_for_inbrowser_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af2fab/using_duckdb_wasm_for_inbrowser_data_engineering/", "subreddit_subscribers": 157231, "created_utc": 1706656222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What libraries do use most when writing ad-hoc data scripts, why? Any lesser known libraries you found very useful?", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite Python Data Processing Libraries? (PyArrow, Pandas, Polars, DuckDB, etc.)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aflut4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706718628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What libraries do use most when writing ad-hoc data scripts, why? Any lesser known libraries you found very useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1aflut4", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aflut4/favorite_python_data_processing_libraries_pyarrow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aflut4/favorite_python_data_processing_libraries_pyarrow/", "subreddit_subscribers": 157231, "created_utc": 1706718628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI\u2019m looking for suggestions on a solution that can help me orchestrate the corporate infrastructure of **30 private VM servers and baremetal servers with GPU**. I\u2019m hoping to find a solution that can help me **spin up a dynamic instance like ECS**, **spin dev and prod Jupyter Lab notebooks**, have a MLflow and dagster setup on these instances and **manage an execution queue for GPU-based servers**.\n\nwe dont have a very large team to manage and support kubernetees installation, but I'm open to discuss if this is the only way. \n\nIf anyone has any experience with similar requirements or can suggest a solution, I\u2019d really appreciate it.\n\nThank you in advance!\n\nI hope this helps! Let me know if you have any other questions.", "author_fullname": "t2_4uziix4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for suggestions on a solution to orchestrate corporate infrastructure of 30 private VM servers and baremetal servers with GPU", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af6zgk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706668736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for suggestions on a solution that can help me orchestrate the corporate infrastructure of &lt;strong&gt;30 private VM servers and baremetal servers with GPU&lt;/strong&gt;. I\u2019m hoping to find a solution that can help me &lt;strong&gt;spin up a dynamic instance like ECS&lt;/strong&gt;, &lt;strong&gt;spin dev and prod Jupyter Lab notebooks&lt;/strong&gt;, have a MLflow and dagster setup on these instances and &lt;strong&gt;manage an execution queue for GPU-based servers&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;we dont have a very large team to manage and support kubernetees installation, but I&amp;#39;m open to discuss if this is the only way. &lt;/p&gt;\n\n&lt;p&gt;If anyone has any experience with similar requirements or can suggest a solution, I\u2019d really appreciate it.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n\n&lt;p&gt;I hope this helps! Let me know if you have any other questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1af6zgk", "is_robot_indexable": true, "report_reasons": null, "author": "mvishruth", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af6zgk/looking_for_suggestions_on_a_solution_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af6zgk/looking_for_suggestions_on_a_solution_to/", "subreddit_subscribers": 157231, "created_utc": 1706668736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Disney Hotstar Captures One Billion Emojis!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1aev0l4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UN1kW5AHid4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How Disney Hotstar Captures One Billion Emojis!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How Disney Hotstar Captures One Billion Emojis!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UN1kW5AHid4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How Disney Hotstar Captures One Billion Emojis!\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UN1kW5AHid4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UN1kW5AHid4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How Disney Hotstar Captures One Billion Emojis!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1aev0l4", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fgu0-vc156RFpuWdsuUURMAzfYG3czuh6pmQzZ_QMuo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706638288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=UN1kW5AHid4", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mIHuYvDYQbfQRLOny2EI4sH32JUAWGpMGlwwr3ZqjOQ.jpg?auto=webp&amp;s=9e1823e21dd040c84a0d92a629583897608c8b3a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/mIHuYvDYQbfQRLOny2EI4sH32JUAWGpMGlwwr3ZqjOQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=213ad23bed5dceed758188cb1a390f51614166a1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/mIHuYvDYQbfQRLOny2EI4sH32JUAWGpMGlwwr3ZqjOQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b64681ca8e03c58910d4959185d2dbbd335eb12", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/mIHuYvDYQbfQRLOny2EI4sH32JUAWGpMGlwwr3ZqjOQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d033c897cf066d4f2d1e9aa4a7225b7b2291c5d5", "width": 320, "height": 240}], "variants": {}, "id": "GMU0CgoG92Xc4dyKC7706W9SAKFbpBUPbuiqgBfhfQY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1aev0l4", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aev0l4/how_disney_hotstar_captures_one_billion_emojis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=UN1kW5AHid4", "subreddit_subscribers": 157231, "created_utc": 1706638288.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How Disney Hotstar Captures One Billion Emojis!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UN1kW5AHid4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How Disney Hotstar Captures One Billion Emojis!\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UN1kW5AHid4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are converting a database load based to DBT. The old value chain was often like this:\n\n1. Insert new base data into table X \n2. Run multiple update statement or insert statement on table X\n\nThis was done at regular intervals each year by the means of stored procedures. All these updates and inserts have to be replaced with models that increases the number of models/tables compared with the old data base (which only have the final tables). \n\nI feel that this is becoming messy very fast. Even if DBT keeps track of the linage, the DAG have become so large that it is difficult to get a good overview. Much scrolling in the DAG html view is needed.\n\nDo you try to organize models in folders in such a way that make that closely related models are kept together? \n\nIs a stupid idea to put numbers on folders/models in order to get a idea of the relative order between models?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_7hbs1ihu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organize code in DBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1afj9o0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706711826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are converting a database load based to DBT. The old value chain was often like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Insert new base data into table X &lt;/li&gt;\n&lt;li&gt;Run multiple update statement or insert statement on table X&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This was done at regular intervals each year by the means of stored procedures. All these updates and inserts have to be replaced with models that increases the number of models/tables compared with the old data base (which only have the final tables). &lt;/p&gt;\n\n&lt;p&gt;I feel that this is becoming messy very fast. Even if DBT keeps track of the linage, the DAG have become so large that it is difficult to get a good overview. Much scrolling in the DAG html view is needed.&lt;/p&gt;\n\n&lt;p&gt;Do you try to organize models in folders in such a way that make that closely related models are kept together? &lt;/p&gt;\n\n&lt;p&gt;Is a stupid idea to put numbers on folders/models in order to get a idea of the relative order between models?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1afj9o0", "is_robot_indexable": true, "report_reasons": null, "author": "Wise-Ad-7492", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afj9o0/organize_code_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1afj9o0/organize_code_in_dbt/", "subreddit_subscribers": 157231, "created_utc": 1706711826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working with a massive 14 billion row dataset in Redshift for sales analytics reporting: I've managed to optimize query times using sort keys and distribution keys, but as the dataset is continuously growing and currently spans three years of data, what are other effective strategies or methods you would recommend for further optimizing read performance on such a large and expanding dataset?", "author_fullname": "t2_hae00nzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift performance optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1afcicb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706686938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working with a massive 14 billion row dataset in Redshift for sales analytics reporting: I&amp;#39;ve managed to optimize query times using sort keys and distribution keys, but as the dataset is continuously growing and currently spans three years of data, what are other effective strategies or methods you would recommend for further optimizing read performance on such a large and expanding dataset?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1afcicb", "is_robot_indexable": true, "report_reasons": null, "author": "New-Statistician-155", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afcicb/redshift_performance_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1afcicb/redshift_performance_optimization/", "subreddit_subscribers": 157231, "created_utc": 1706686938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Redshift Enthusiasts,\n\nI'm encountering a puzzling situation with the Redshift COPY command and could really use some insights from the community.\n\nHere's the scenario: I'm in the midst of copying a substantial 2 GB CSV file from S3 into Redshift as part of a full load operation. Naturally, given the size of the file, it's taking quite a bit of time to complete.\n\nIn an effort to expedite the process, I decided to scale up my Redshift cluster. Initially, I was operating on a single dc2.xlarge node, and I thought increasing it to a cluster with two dc2.xlarge nodes would significantly improve the load time.\n\nHowever, to my surprise, the two-node cluster seems to be taking even longer compared to the single-node setup. This unexpected turn has left me scratching my head, wondering what could be causing this slowdown.\n\nI've pondered potential reasons behind this counterintuitive outcome. Could it be an issue with the distribution keys, data skew, or perhaps something else entirely?\n\nI'd greatly appreciate any insights, tips, or experiences you've had with similar situations. What could be causing the two-node cluster to lag behind its single-node counterpart in terms of load times?\n\nLooking forward to your thoughts and expertise!\n\nCheers!", "author_fullname": "t2_7nvr4m4i4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Troubleshooting Redshift COPY Command Performance: Need Help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af8onh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706673814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Redshift Enthusiasts,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m encountering a puzzling situation with the Redshift COPY command and could really use some insights from the community.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the scenario: I&amp;#39;m in the midst of copying a substantial 2 GB CSV file from S3 into Redshift as part of a full load operation. Naturally, given the size of the file, it&amp;#39;s taking quite a bit of time to complete.&lt;/p&gt;\n\n&lt;p&gt;In an effort to expedite the process, I decided to scale up my Redshift cluster. Initially, I was operating on a single dc2.xlarge node, and I thought increasing it to a cluster with two dc2.xlarge nodes would significantly improve the load time.&lt;/p&gt;\n\n&lt;p&gt;However, to my surprise, the two-node cluster seems to be taking even longer compared to the single-node setup. This unexpected turn has left me scratching my head, wondering what could be causing this slowdown.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve pondered potential reasons behind this counterintuitive outcome. Could it be an issue with the distribution keys, data skew, or perhaps something else entirely?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d greatly appreciate any insights, tips, or experiences you&amp;#39;ve had with similar situations. What could be causing the two-node cluster to lag behind its single-node counterpart in terms of load times?&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your thoughts and expertise!&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1af8onh", "is_robot_indexable": true, "report_reasons": null, "author": "Flimsy-Mirror974", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af8onh/troubleshooting_redshift_copy_command_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af8onh/troubleshooting_redshift_copy_command_performance/", "subreddit_subscribers": 157231, "created_utc": 1706673814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\njust looking for some clarification on best practices for dimensional and fact tables. At my work, we have a number of dimensional tables. Say we are looking at the dimCustomers table. I have 'dimCustomerId', 'CustomerId', 'CustomerName' as fields. The 'dimCustomerId' is an auto incrementing ID. The dimCustomerId is what is used in my fact table. \n\n  \nWhat is the point in having this dimCustomerId? Everywhere else in our business including our lakehouse, we simply use 'CustomerId'. When we load data to our fact table, we read in the dimCustomers table, use CustomerId to find the dimCustomerId, and then store dimCustomerId in the fact table. It seems like an unnecessary, round about way since we get the dimCustomerId using CustomerId, so why not just use CustomerId? \n\nWould it be suitable to have a dimCustomer table with 'CustomerId' as the PK and 'CustomerName' as the field, removing the dimCustomerId altogether? I'm not looking to actually do this, just for my own learning. ", "author_fullname": "t2_1yo0xaq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dimensional table ids", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af7s1s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706671079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;just looking for some clarification on best practices for dimensional and fact tables. At my work, we have a number of dimensional tables. Say we are looking at the dimCustomers table. I have &amp;#39;dimCustomerId&amp;#39;, &amp;#39;CustomerId&amp;#39;, &amp;#39;CustomerName&amp;#39; as fields. The &amp;#39;dimCustomerId&amp;#39; is an auto incrementing ID. The dimCustomerId is what is used in my fact table. &lt;/p&gt;\n\n&lt;p&gt;What is the point in having this dimCustomerId? Everywhere else in our business including our lakehouse, we simply use &amp;#39;CustomerId&amp;#39;. When we load data to our fact table, we read in the dimCustomers table, use CustomerId to find the dimCustomerId, and then store dimCustomerId in the fact table. It seems like an unnecessary, round about way since we get the dimCustomerId using CustomerId, so why not just use CustomerId? &lt;/p&gt;\n\n&lt;p&gt;Would it be suitable to have a dimCustomer table with &amp;#39;CustomerId&amp;#39; as the PK and &amp;#39;CustomerName&amp;#39; as the field, removing the dimCustomerId altogether? I&amp;#39;m not looking to actually do this, just for my own learning. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1af7s1s", "is_robot_indexable": true, "report_reasons": null, "author": "justanator101", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af7s1s/dimensional_table_ids/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af7s1s/dimensional_table_ids/", "subreddit_subscribers": 157231, "created_utc": 1706671079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nI am a newbie in DE and want to tryout what I've learned with Astronomer Airflow 1:1 course. My ambition is to build another pet project for portfolio.\n\nThe idea is to build a simple pipeline via Airflow (deployed in Managed Workers) that pulls the data from Spotify API, loads it into S3, then performs basic wrangling and loads it into reporting view in Snowflake for further visualization.\n\nKey phases:\n\n1. Create VENV and test/deploy all connection\n2. Containerize the solution with Docker\n3. Deploy the solution in the cloud\n\nDo you mind put some of your thoughts/critique/advice?\n\nThank you!", "author_fullname": "t2_16bfjc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please provide suggestions to my pet project on building Airflow pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af3uuo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706659940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I am a newbie in DE and want to tryout what I&amp;#39;ve learned with Astronomer Airflow 1:1 course. My ambition is to build another pet project for portfolio.&lt;/p&gt;\n\n&lt;p&gt;The idea is to build a simple pipeline via Airflow (deployed in Managed Workers) that pulls the data from Spotify API, loads it into S3, then performs basic wrangling and loads it into reporting view in Snowflake for further visualization.&lt;/p&gt;\n\n&lt;p&gt;Key phases:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create VENV and test/deploy all connection&lt;/li&gt;\n&lt;li&gt;Containerize the solution with Docker&lt;/li&gt;\n&lt;li&gt;Deploy the solution in the cloud&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Do you mind put some of your thoughts/critique/advice?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1af3uuo", "is_robot_indexable": true, "report_reasons": null, "author": "gikis1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af3uuo/please_provide_suggestions_to_my_pet_project_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af3uuo/please_provide_suggestions_to_my_pet_project_on/", "subreddit_subscribers": 157231, "created_utc": 1706659940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generative AI: An introduction to prompt engineering and LangChain for data practitioners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1af0utx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1LlBRyGH7Ruu7iq-whgK92xtlGcmsPFF1fpc6RNrraw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706652381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/teradata/generative-ai-part-1-an-introduction-to-prompt-engineering-and-langchain-742987f2d9c1?source=friends_link&amp;sk=e62cbac26db2d6ed662b6d08c2469504", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?auto=webp&amp;s=792aaa2459236bcca3a62b5897ccb2fa52cda2dc", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f39363f82738e33360409f712d703329008b84eb", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af1879dd02eff4b1f44467912c11dd84b6f9fb5e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=391f964d027ef7a94b467cc31c39d321c8f5586d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7c481fe23e7de5dfc232c1a7c9405821d73033a2", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e82e37157f489c7f5aa8648ee5b996f084b7b5ae", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/sNZLb38iNgJDN3K4aSZBNRRDgCuA9cxUZmu00W-YOM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e77d5093f573cc3157b395821860e00960f2ee41", "width": 1080, "height": 567}], "variants": {}, "id": "J1m4rmgFumu25yh6TpxE1seywkLq5EsdLh_mIIK-4gg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1af0utx", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af0utx/generative_ai_an_introduction_to_prompt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/teradata/generative-ai-part-1-an-introduction-to-prompt-engineering-and-langchain-742987f2d9c1?source=friends_link&amp;sk=e62cbac26db2d6ed662b6d08c2469504", "subreddit_subscribers": 157231, "created_utc": 1706652381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Folks aren't too happy with Synapse for multiple reasons; one is that we can't get it running on a private endpoint, so port 1433 sits on the internet for the Serverless SQL Pool.  Apparently, this is also the case with Fabric, although Fabric uses managed identities whereas Synapse has a SQL Auth method turned on by default.\n\nThis is our data flow  Dataverse --&gt; Synapse Link --- &gt; Datalake Storage Gen 2 ---&gt; Synapse Analytics serverless SQL Endpoint ----&gt; Synapse Pipelines -----&gt; Upsert data and schema evolution to Azure SQL Server -----&gt; Snaplogic ------&gt; AWS Redshift.\n\nI am the build owner for the architecture up to Azure SQL Server and want to come up with a secure alternative (no open port 1433 to the internet).  The solution needs to do schema evolution from the D365 Rest endpoint as well as update all changed data every 5 to 10 minutes. The current system does all that with minimal issues.  I've tried pursuing a private endpoint for the Synapse SQL endpoint and was told by Microsoft it's not supported.\n\nAny suggestions are much appreciated. I have VMS on premise at my current disposal and will eventually get them in Azure when we finish a hardened image. For what it's worth we also use BigTable and VErtex at GCP and Snaplogic and Redshift on AWS.", "author_fullname": "t2_5yj82gi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Platform suggestions to migrate off of Azure Synapse Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af70gd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706668813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Folks aren&amp;#39;t too happy with Synapse for multiple reasons; one is that we can&amp;#39;t get it running on a private endpoint, so port 1433 sits on the internet for the Serverless SQL Pool.  Apparently, this is also the case with Fabric, although Fabric uses managed identities whereas Synapse has a SQL Auth method turned on by default.&lt;/p&gt;\n\n&lt;p&gt;This is our data flow  Dataverse --&amp;gt; Synapse Link --- &amp;gt; Datalake Storage Gen 2 ---&amp;gt; Synapse Analytics serverless SQL Endpoint ----&amp;gt; Synapse Pipelines -----&amp;gt; Upsert data and schema evolution to Azure SQL Server -----&amp;gt; Snaplogic ------&amp;gt; AWS Redshift.&lt;/p&gt;\n\n&lt;p&gt;I am the build owner for the architecture up to Azure SQL Server and want to come up with a secure alternative (no open port 1433 to the internet).  The solution needs to do schema evolution from the D365 Rest endpoint as well as update all changed data every 5 to 10 minutes. The current system does all that with minimal issues.  I&amp;#39;ve tried pursuing a private endpoint for the Synapse SQL endpoint and was told by Microsoft it&amp;#39;s not supported.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions are much appreciated. I have VMS on premise at my current disposal and will eventually get them in Azure when we finish a hardened image. For what it&amp;#39;s worth we also use BigTable and VErtex at GCP and Snaplogic and Redshift on AWS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1af70gd", "is_robot_indexable": true, "report_reasons": null, "author": "Swimming_Cry_6841", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af70gd/looking_for_platform_suggestions_to_migrate_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af70gd/looking_for_platform_suggestions_to_migrate_off/", "subreddit_subscribers": 157231, "created_utc": 1706668813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here goes our latest blog on Data Types and their impact on Database Replication - [https://blog.peerdb.io/role-of-data-type-mapping-in-database-replication](https://blog.peerdb.io/role-of-data-type-mapping-in-database-replication)\n\nDid you know that carefully designing data type mapping during database replication can?  \n\n\n1. **Save Costs:** Replicating to native data types in the Warehouse avoids additional transformations and typecasting from apps such as [dbt Labs](https://www.linkedin.com/company/dbtlabs/), thus saving on compute costs.\n2. **Enable Advanced Analytics:** Replicating to native data types in the Warehouse enables consumer apps to use advanced functions and operators, facilitating advanced querying and analytics.\n3. **Reduce Tech Debt:** Your data engineers don't need to write additional code to convert strings to native data types, thereby reducing technical debt.\n\nThe blog also talks about how [PeerDB](https://www.peerdb.io/)\u00a0handles data type mapping, with practical examples.", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Types and their impact on Database Replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af0woe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1706652508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here goes our latest blog on Data Types and their impact on Database Replication - &lt;a href=\"https://blog.peerdb.io/role-of-data-type-mapping-in-database-replication\"&gt;https://blog.peerdb.io/role-of-data-type-mapping-in-database-replication&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Did you know that carefully designing data type mapping during database replication can?  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Save Costs:&lt;/strong&gt; Replicating to native data types in the Warehouse avoids additional transformations and typecasting from apps such as &lt;a href=\"https://www.linkedin.com/company/dbtlabs/\"&gt;dbt Labs&lt;/a&gt;, thus saving on compute costs.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enable Advanced Analytics:&lt;/strong&gt; Replicating to native data types in the Warehouse enables consumer apps to use advanced functions and operators, facilitating advanced querying and analytics.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Reduce Tech Debt:&lt;/strong&gt; Your data engineers don&amp;#39;t need to write additional code to convert strings to native data types, thereby reducing technical debt.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The blog also talks about how &lt;a href=\"https://www.peerdb.io/\"&gt;PeerDB&lt;/a&gt;\u00a0handles data type mapping, with practical examples.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?auto=webp&amp;s=3d7d36799bd51f98de4b9353f2e78017c7679558", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cb37b2ff5f6bc1dbedb12c7d71a2aafd8716f0be", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a6c011458b3e6fd2ea7c273a9218fbcaa1d8cd6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc82869bd56aa6f98d5a6f517977a41e3c679a3b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fdcf68b083a1ec1a62991f6114a742e6a31dfa13", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0c8c5bbe8d974c8a8a3cfecf2bf494deeb905833", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fjDeiWYd7B8nKeVueq6M5VvWSFHJik8v4izOH1FOmLM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14f0975bd04e16ab1af2688fca84519217c0372f", "width": 1080, "height": 567}], "variants": {}, "id": "L3mxAd9-4u7t5R_5a5u44x49ddQcP6mlPm3L75SeZsQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1af0woe", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af0woe/data_types_and_their_impact_on_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af0woe/data_types_and_their_impact_on_database/", "subreddit_subscribers": 157231, "created_utc": 1706652508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Crossposting in some of my favorite forums.\n\nFirst year out of college, just started working my first data analytics job at a huge company. It's not my end goal, but it's a great starting point. Actually, flip that. It's great if you're looking for a cushy place to retire at. But I think it's not where a college grad should be for a high pace, growth environment. Luckily, I use good tools, my manager supports my desire to write code (mostly ETL scripts), mid-level management is reasonable. But part of me wants the experience of working hybrid in the city, being alongside people my age in the office, networking through work events, etc.\n\nAll I think about is job hopping 1 yr later. Right now I'm taking courses that would help me\nmove up (either data engineering or ML modeling). I'm set to finish to my Master's degree in analytics by August. I hope to study and earn some cloud provider's data engineer certification. I want to do so much. So much that I forget I'm unproven in my current role and I have basically no accomplishments besides being able to say \"I worked at ______\". \n\nI envy my friends who work in the city, but they say the city is draining and they're always tired. I'm truly very grateful for my job. But I'm experiencing severe \"grass is greener\" syndrome + FOMO, I sometimes daydream too much and fail to focus on my current tasks.\n\nHow can you make the most of your current situation and grow, but also embrace the work that you do now without getting caught up in the desire for something more?", "author_fullname": "t2_lfyfd0fn2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with the constsnt desire for more?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1afmpv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706720740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Crossposting in some of my favorite forums.&lt;/p&gt;\n\n&lt;p&gt;First year out of college, just started working my first data analytics job at a huge company. It&amp;#39;s not my end goal, but it&amp;#39;s a great starting point. Actually, flip that. It&amp;#39;s great if you&amp;#39;re looking for a cushy place to retire at. But I think it&amp;#39;s not where a college grad should be for a high pace, growth environment. Luckily, I use good tools, my manager supports my desire to write code (mostly ETL scripts), mid-level management is reasonable. But part of me wants the experience of working hybrid in the city, being alongside people my age in the office, networking through work events, etc.&lt;/p&gt;\n\n&lt;p&gt;All I think about is job hopping 1 yr later. Right now I&amp;#39;m taking courses that would help me\nmove up (either data engineering or ML modeling). I&amp;#39;m set to finish to my Master&amp;#39;s degree in analytics by August. I hope to study and earn some cloud provider&amp;#39;s data engineer certification. I want to do so much. So much that I forget I&amp;#39;m unproven in my current role and I have basically no accomplishments besides being able to say &amp;quot;I worked at ______&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;I envy my friends who work in the city, but they say the city is draining and they&amp;#39;re always tired. I&amp;#39;m truly very grateful for my job. But I&amp;#39;m experiencing severe &amp;quot;grass is greener&amp;quot; syndrome + FOMO, I sometimes daydream too much and fail to focus on my current tasks.&lt;/p&gt;\n\n&lt;p&gt;How can you make the most of your current situation and grow, but also embrace the work that you do now without getting caught up in the desire for something more?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1afmpv5", "is_robot_indexable": true, "report_reasons": null, "author": "velimino", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1afmpv5/how_do_you_deal_with_the_constsnt_desire_for_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1afmpv5/how_do_you_deal_with_the_constsnt_desire_for_more/", "subreddit_subscribers": 157231, "created_utc": 1706720740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For me this month, 12 initial interviews, 5 technical, 1 final round, no offers\n\n3.5 years exp. Wanna leave my current job asap.", "author_fullname": "t2_p9gvk8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How's the job search going for you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aflkig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706717890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me this month, 12 initial interviews, 5 technical, 1 final round, no offers&lt;/p&gt;\n\n&lt;p&gt;3.5 years exp. Wanna leave my current job asap.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aflkig", "is_robot_indexable": true, "report_reasons": null, "author": "marcelorojas56", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aflkig/hows_the_job_search_going_for_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aflkig/hows_the_job_search_going_for_you/", "subreddit_subscribers": 157231, "created_utc": 1706717890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I usually develop data platforms that periodically update using ADF for copying data from the source system to a data lake or data warehouse, and dbt for building the models. I have a client that wants near realtime refreshes. I think with ADF this would create a lot of costs, and in general I don't really see the point of using this extensive paid tool for basically doing just simple API and database calls. \n\nIs there a better tool/method for automating and managing a copy activity easily? (in Azure)", "author_fullname": "t2_u2p974i5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Near realtime copy ELT with other tool than ADF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aflaae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706717177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I usually develop data platforms that periodically update using ADF for copying data from the source system to a data lake or data warehouse, and dbt for building the models. I have a client that wants near realtime refreshes. I think with ADF this would create a lot of costs, and in general I don&amp;#39;t really see the point of using this extensive paid tool for basically doing just simple API and database calls. &lt;/p&gt;\n\n&lt;p&gt;Is there a better tool/method for automating and managing a copy activity easily? (in Azure)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aflaae", "is_robot_indexable": true, "report_reasons": null, "author": "MarcScripts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aflaae/near_realtime_copy_elt_with_other_tool_than_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aflaae/near_realtime_copy_elt_with_other_tool_than_adf/", "subreddit_subscribers": 157231, "created_utc": 1706717177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I feel like I need to learn cloud infrastructure. I have about 8 years of experience as a data analyst. Here is my program/language stack:\n\n* Python\n* VBA (lol)\n* Power BI/Power Query\n* SQL\n* Alteryx\n\nI'm pretty comfortable/experienced with general programming/automation/ETL/visualization but I've never worked with big data/cloud stuff. Just wondering what a data engineering hiring manager would want to see.", "author_fullname": "t2_1ad62ux7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do I need to add to my stack to break into data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1af3rg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706659697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel like I need to learn cloud infrastructure. I have about 8 years of experience as a data analyst. Here is my program/language stack:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;VBA (lol)&lt;/li&gt;\n&lt;li&gt;Power BI/Power Query&lt;/li&gt;\n&lt;li&gt;SQL&lt;/li&gt;\n&lt;li&gt;Alteryx&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m pretty comfortable/experienced with general programming/automation/ETL/visualization but I&amp;#39;ve never worked with big data/cloud stuff. Just wondering what a data engineering hiring manager would want to see.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1af3rg5", "is_robot_indexable": true, "report_reasons": null, "author": "VegaGT-VZ", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1af3rg5/what_do_i_need_to_add_to_my_stack_to_break_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1af3rg5/what_do_i_need_to_add_to_my_stack_to_break_into/", "subreddit_subscribers": 157231, "created_utc": 1706659697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \nI was about to start reading 'The Data Warehouse Toolkit' by Ralph Kimball and Margy Ross. However, I understand that it has become somewhat outdated.\n\nI would like to know what resources I could use to learn about modern architectures and dimensional modeling.\n\nThank you very much!", "author_fullname": "t2_6kkepa9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books and Resources for Analytics Engineering and Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aex15l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706643063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;br/&gt;\nI was about to start reading &amp;#39;The Data Warehouse Toolkit&amp;#39; by Ralph Kimball and Margy Ross. However, I understand that it has become somewhat outdated.&lt;/p&gt;\n\n&lt;p&gt;I would like to know what resources I could use to learn about modern architectures and dimensional modeling.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1aex15l", "is_robot_indexable": true, "report_reasons": null, "author": "hypnotize9", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aex15l/books_and_resources_for_analytics_engineering_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aex15l/books_and_resources_for_analytics_engineering_and/", "subreddit_subscribers": 157231, "created_utc": 1706643063.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}