{"kind": "Listing", "data": {"after": "t3_191hlw3", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a junior Data Analyst/Scientist consultant, mostly doing analytics and BI, but I also work with machine learning.\n\n\nI want to move into Data Engineering. I've started learning on my own and I'm curious about how others have done it and would recommend doing it.\n\n\nMy plan is to learn the basics on my own, replicate 3 full projects from the web, then do my own project on something I like. \n\n\nDoes this sound good? What do you think? Do you know some end to end project that you would consider worth learning from?", "author_fullname": "t2_tyzkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "People who transitioned to DE, how did you study?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191m6ke", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704723368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a junior Data Analyst/Scientist consultant, mostly doing analytics and BI, but I also work with machine learning.&lt;/p&gt;\n\n&lt;p&gt;I want to move into Data Engineering. I&amp;#39;ve started learning on my own and I&amp;#39;m curious about how others have done it and would recommend doing it.&lt;/p&gt;\n\n&lt;p&gt;My plan is to learn the basics on my own, replicate 3 full projects from the web, then do my own project on something I like. &lt;/p&gt;\n\n&lt;p&gt;Does this sound good? What do you think? Do you know some end to end project that you would consider worth learning from?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "191m6ke", "is_robot_indexable": true, "report_reasons": null, "author": "Deiice", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191m6ke/people_who_transitioned_to_de_how_did_you_study/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191m6ke/people_who_transitioned_to_de_how_did_you_study/", "subreddit_subscribers": 151323, "created_utc": 1704723368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was a technical/data PM that switched to the data/analytics engineering space because I got tired of talking to all teams and people ata company every day and actually enjoyed the peace and quiet of running queries, updating data models, using Looker, getting fresh (as we call it at my place lol instead of raw) to usable data for the data science team etc. What I don\u2019t like about it, is that sometimes an ad hoc request from sales or an incompetent mba grad will be top priority for leadership, and I have to export the results in google sheets or something. Like isn\u2019t that something for an analyst to do??\n\nWhat about you?", "author_fullname": "t2_lh8s5ycdc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you like and not like about being a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191cpwm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704688902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was a technical/data PM that switched to the data/analytics engineering space because I got tired of talking to all teams and people ata company every day and actually enjoyed the peace and quiet of running queries, updating data models, using Looker, getting fresh (as we call it at my place lol instead of raw) to usable data for the data science team etc. What I don\u2019t like about it, is that sometimes an ad hoc request from sales or an incompetent mba grad will be top priority for leadership, and I have to export the results in google sheets or something. Like isn\u2019t that something for an analyst to do??&lt;/p&gt;\n\n&lt;p&gt;What about you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "191cpwm", "is_robot_indexable": true, "report_reasons": null, "author": "imjusthereforPMstuff", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191cpwm/what_do_you_like_and_not_like_about_being_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191cpwm/what_do_you_like_and_not_like_about_being_a_data/", "subreddit_subscribers": 151323, "created_utc": 1704688902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of the companies I have seen use Confluence or Google Docs to document their releases or how to setup codebase, software architecture or how things work in general.  \nOne of the problems I personally face is that these documentations never get updated or are just too cumbersome to search and read.\n\nWhat are the problems you face? What software does your company use for this purpose? Would you or your company be willing to pay for software that solves these problems?", "author_fullname": "t2_6ihvp7sd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What problems do you face with the documentation software in your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1919pch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704679809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the companies I have seen use Confluence or Google Docs to document their releases or how to setup codebase, software architecture or how things work in general.&lt;br/&gt;\nOne of the problems I personally face is that these documentations never get updated or are just too cumbersome to search and read.&lt;/p&gt;\n\n&lt;p&gt;What are the problems you face? What software does your company use for this purpose? Would you or your company be willing to pay for software that solves these problems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1919pch", "is_robot_indexable": true, "report_reasons": null, "author": "brequinn89", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1919pch/what_problems_do_you_face_with_the_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1919pch/what_problems_do_you_face_with_the_documentation/", "subreddit_subscribers": 151323, "created_utc": 1704679809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I had this discussion recently with somebody on LinkedIn, but I believe we can have a much better discussion here.\n\nI believe we are more consumers than producers of data.\n\n\\- You depend on the data the developers write in PostgreSQL.  \n\\- You depend on the data salespeople input in Salesforce.  \n\\- You depend on the data accountants add to Xero.\n\nIf these people produce low-quality data, there\u2019s almost no chance for you to build high-quality data products.\n\nTrying to build trustworthy dashboards, models, and insights is like relying on a crappy third-party API to build an outstanding app.\n\nYou need to communicate that idea clearly with stakeholders. They need to understand how their actions affect the results you produce.\n\nI'm not saying data engineers are not producers for analysts, but I think we are primarily consumers.\n\nWhat's your opinion?", "author_fullname": "t2_1c6f704", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the data team a data producer or a consumer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191s99i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704738951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had this discussion recently with somebody on LinkedIn, but I believe we can have a much better discussion here.&lt;/p&gt;\n\n&lt;p&gt;I believe we are more consumers than producers of data.&lt;/p&gt;\n\n&lt;p&gt;- You depend on the data the developers write in PostgreSQL.&lt;br/&gt;\n- You depend on the data salespeople input in Salesforce.&lt;br/&gt;\n- You depend on the data accountants add to Xero.&lt;/p&gt;\n\n&lt;p&gt;If these people produce low-quality data, there\u2019s almost no chance for you to build high-quality data products.&lt;/p&gt;\n\n&lt;p&gt;Trying to build trustworthy dashboards, models, and insights is like relying on a crappy third-party API to build an outstanding app.&lt;/p&gt;\n\n&lt;p&gt;You need to communicate that idea clearly with stakeholders. They need to understand how their actions affect the results you produce.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not saying data engineers are not producers for analysts, but I think we are primarily consumers.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your opinion?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "191s99i", "is_robot_indexable": true, "report_reasons": null, "author": "ivanovyordan", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/191s99i/is_the_data_team_a_data_producer_or_a_consumer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191s99i/is_the_data_team_a_data_producer_or_a_consumer/", "subreddit_subscribers": 151323, "created_utc": 1704738951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a data engineering project with specific demands for ensuring and validating data consistency. My database is structured into three tiers: a schema with raw data tables, a schema with intermediate tables, and a schema with tables that are 'ready to query'. Therefore, validations need to be performed between these levels, considering various values and conditions.\n\nI attempted to create some expectations using Great Expectations (GE), but I encountered several complexities specific to my use case. For instance, I need to verify whether the sum of the revenue from orders with status equals to \"approved\" in my orders table matches the sum in the approved revenue column of my revenue table. This is a basic example for which I couldn't find any solution using GE.\n\nMy question is: should I create a simplified version of Great Expectations to address all my use cases deeply? I feel that I'm going to amount of Toil in either scenario, possibly even more if I choose to implement it using Great Expectations in its entirety.", "author_fullname": "t2_qb9fcc1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use Great Expectations or build it myself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191y5xq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704753336.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704753073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a data engineering project with specific demands for ensuring and validating data consistency. My database is structured into three tiers: a schema with raw data tables, a schema with intermediate tables, and a schema with tables that are &amp;#39;ready to query&amp;#39;. Therefore, validations need to be performed between these levels, considering various values and conditions.&lt;/p&gt;\n\n&lt;p&gt;I attempted to create some expectations using Great Expectations (GE), but I encountered several complexities specific to my use case. For instance, I need to verify whether the sum of the revenue from orders with status equals to &amp;quot;approved&amp;quot; in my orders table matches the sum in the approved revenue column of my revenue table. This is a basic example for which I couldn&amp;#39;t find any solution using GE.&lt;/p&gt;\n\n&lt;p&gt;My question is: should I create a simplified version of Great Expectations to address all my use cases deeply? I feel that I&amp;#39;m going to amount of Toil in either scenario, possibly even more if I choose to implement it using Great Expectations in its entirety.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "191y5xq", "is_robot_indexable": true, "report_reasons": null, "author": "Feisty_Albatross_893", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191y5xq/should_i_use_great_expectations_or_build_it_myself/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191y5xq/should_i_use_great_expectations_or_build_it_myself/", "subreddit_subscribers": 151323, "created_utc": 1704753073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data engineering can mean a lot of things depending on what company you work at. At all of the companies I've worked at, all data engineering disciplines had the title of data engineer.\n\n\n\n\n\nFor example, I see data engineering as falling under the following areas: software engineer - data, data pipeline development, ML engineering, database admin.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you make it clear on your resume what area of data engineering you work in?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191rwwx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704738111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data engineering can mean a lot of things depending on what company you work at. At all of the companies I&amp;#39;ve worked at, all data engineering disciplines had the title of data engineer.&lt;/p&gt;\n\n&lt;p&gt;For example, I see data engineering as falling under the following areas: software engineer - data, data pipeline development, ML engineering, database admin.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "191rwwx", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/191rwwx/how_do_you_make_it_clear_on_your_resume_what_area/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191rwwx/how_do_you_make_it_clear_on_your_resume_what_area/", "subreddit_subscribers": 151323, "created_utc": 1704738111.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking to experiment with various big data tooling like Databricks and Microsoft Fabric. What would be good datasets to play with to build out projects with? \n\nI think Kaggle is likely too small scale. I\u2019d like to be able to flesh out ETLs all the way through to Analytics and ETLs. So looking for large scale freely available data sets that could be interesting to work with. \n\nThanks!", "author_fullname": "t2_srabrhe6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good datasets for personal learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191snt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704739951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to experiment with various big data tooling like Databricks and Microsoft Fabric. What would be good datasets to play with to build out projects with? &lt;/p&gt;\n\n&lt;p&gt;I think Kaggle is likely too small scale. I\u2019d like to be able to flesh out ETLs all the way through to Analytics and ETLs. So looking for large scale freely available data sets that could be interesting to work with. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "191snt1", "is_robot_indexable": true, "report_reasons": null, "author": "i-kn0w-n0thing", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191snt1/good_datasets_for_personal_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191snt1/good_datasets_for_personal_learning/", "subreddit_subscribers": 151323, "created_utc": 1704739951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w6hkluod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Core Principles of Scikit Learn - Gael Varoquaux creator of Scikit Learn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_191irxm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/NvqcJrCh5KE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Core Principles of Scikit Learn - Gael Varoquaux creator of Scikit Learn\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Core Principles of Scikit Learn - Gael Varoquaux creator of Scikit Learn", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/NvqcJrCh5KE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Core Principles of Scikit Learn - Gael Varoquaux creator of Scikit Learn\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/NvqcJrCh5KE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/NvqcJrCh5KE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Core Principles of Scikit Learn - Gael Varoquaux creator of Scikit Learn\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/191irxm", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/S8GB40eCwMDr0-dKe3_wvzR6RDjR59LebaYMtd4NH3M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704711932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/NvqcJrCh5KE?si=mKWWU1biapj7UPmS", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iZLlO3Xi_VC4PUeEQuIFHmJ38fbvB7Sv1SAnj9Co4AE.jpg?auto=webp&amp;s=cbce3834c26c53418251094a84bc66b7f205da3d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/iZLlO3Xi_VC4PUeEQuIFHmJ38fbvB7Sv1SAnj9Co4AE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f913b8849ff93640f85e2efad7fc6b5a57bdbc2e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/iZLlO3Xi_VC4PUeEQuIFHmJ38fbvB7Sv1SAnj9Co4AE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=73a7ddbcb77775efbac4bf816364a987c10636bc", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/iZLlO3Xi_VC4PUeEQuIFHmJ38fbvB7Sv1SAnj9Co4AE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=88df0acb3bf7c506eda7b0ec2313eee5a773b470", "width": 320, "height": 240}], "variants": {}, "id": "DDjFBscc8fz4PdFw0MYf9ssvISGa2PIanU_R9xTfdGI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "191irxm", "is_robot_indexable": true, "report_reasons": null, "author": "danipudani", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191irxm/core_principles_of_scikit_learn_gael_varoquaux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/NvqcJrCh5KE?si=mKWWU1biapj7UPmS", "subreddit_subscribers": 151323, "created_utc": 1704711932.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Core Principles of Scikit Learn - Gael Varoquaux creator of Scikit Learn", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/NvqcJrCh5KE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Core Principles of Scikit Learn - Gael Varoquaux creator of Scikit Learn\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/NvqcJrCh5KE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just quit without anything lined up due to extreme burnout and being pushed in a management direction on a very small team that doesn\u2019t want or need it, when my career interests at this point are technical. \n\nMy manager came back asking if I\u2019d be interested in contract work to help finish out the project set to span Q1 &amp; Q2 of this year. With my departure, they\u2019re now planning on using in-house consultants of our 1-2 main vendors and asked if I would either assist with the technical component or managing the relationship with the consultant(s). \n\nHonestly, I would definitely be interested if it meant I could focus on just the scope given and didn\u2019t have to be included in other meetings or pulled into the side quests that were pushing me over 40h a week, but trying to figure out a reasonable proposal. The main thing I care about is keeping my hours below 20 (ideally 12-16) as I try to heal this burnout. \n\nIs it as simple as a multiplier of current hourly rate? Or should I factor in my own experience, proprietary knowledge, education, etc? Should I propose hourly or estimate the hours and lump sum for the project? \n\nIn case it\u2019s relevant, my role is possibly more closely aligned with Analytics Engineering (heavy in dbt, I\u2019m only one who knows the tool/our project well) and BI development (implementing dbt for end users), but feel this community has good insight. Anyone have experience here? Thanks in advance!", "author_fullname": "t2_spwsseep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Employer asked me to contract after I gave my notice. Best way to calculate rate for proposal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191t6ed", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704741458.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704741157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just quit without anything lined up due to extreme burnout and being pushed in a management direction on a very small team that doesn\u2019t want or need it, when my career interests at this point are technical. &lt;/p&gt;\n\n&lt;p&gt;My manager came back asking if I\u2019d be interested in contract work to help finish out the project set to span Q1 &amp;amp; Q2 of this year. With my departure, they\u2019re now planning on using in-house consultants of our 1-2 main vendors and asked if I would either assist with the technical component or managing the relationship with the consultant(s). &lt;/p&gt;\n\n&lt;p&gt;Honestly, I would definitely be interested if it meant I could focus on just the scope given and didn\u2019t have to be included in other meetings or pulled into the side quests that were pushing me over 40h a week, but trying to figure out a reasonable proposal. The main thing I care about is keeping my hours below 20 (ideally 12-16) as I try to heal this burnout. &lt;/p&gt;\n\n&lt;p&gt;Is it as simple as a multiplier of current hourly rate? Or should I factor in my own experience, proprietary knowledge, education, etc? Should I propose hourly or estimate the hours and lump sum for the project? &lt;/p&gt;\n\n&lt;p&gt;In case it\u2019s relevant, my role is possibly more closely aligned with Analytics Engineering (heavy in dbt, I\u2019m only one who knows the tool/our project well) and BI development (implementing dbt for end users), but feel this community has good insight. Anyone have experience here? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "191t6ed", "is_robot_indexable": true, "report_reasons": null, "author": "hairc-ut", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191t6ed/employer_asked_me_to_contract_after_i_gave_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191t6ed/employer_asked_me_to_contract_after_i_gave_my/", "subreddit_subscribers": 151323, "created_utc": 1704741157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,   \n\n\n[dlt](https://dlthub.com/docs/intro) is the python library for data loading with schema evolution. Our contributors recently created 2 very interesting articles on event ingestion which I wanted to share.  \n1. [Event ingestion on AWS](https://dlthub.com/docs/blog/dlt-aws-taktile-blog) with Lambda; Cost of 7.5 USD/1m events.  \n2. [Event ingestion on GCP](https://dlthub.com/docs/blog/streaming-pubsub-json-gcp) via PubSub; Cost of 16usd/month for 2 workers that can process 1400 events/second.  \n\n\nWe are also working on doing our own similar pipeline on gcp and will share it when ready.\n\n&amp;#x200B;\n\ndlt library added an early release of [data contracts](https://dlthub.com/docs/general-usage/schema-contracts) with the following options for handling bad events:  \n\\- evolve schema  \n\\- reject load package   \n\\- truncate columns and ingest (discard columns)  \n\\- discard event (discard row)  \nWe will next add bad data handling so if you have requirements how you would like that to work please comment [here](https://github.com/dlt-hub/dlt/issues/780).  \n\n\nThanks all! and let 2024 be a year with more open source data solutions :)", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event ingestion for cheap on AWS and GCP: 2 demos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191lf3o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704721119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dlthub.com/docs/intro\"&gt;dlt&lt;/a&gt; is the python library for data loading with schema evolution. Our contributors recently created 2 very interesting articles on event ingestion which I wanted to share.&lt;br/&gt;\n1. &lt;a href=\"https://dlthub.com/docs/blog/dlt-aws-taktile-blog\"&gt;Event ingestion on AWS&lt;/a&gt; with Lambda; Cost of 7.5 USD/1m events.&lt;br/&gt;\n2. &lt;a href=\"https://dlthub.com/docs/blog/streaming-pubsub-json-gcp\"&gt;Event ingestion on GCP&lt;/a&gt; via PubSub; Cost of 16usd/month for 2 workers that can process 1400 events/second.  &lt;/p&gt;\n\n&lt;p&gt;We are also working on doing our own similar pipeline on gcp and will share it when ready.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;dlt library added an early release of &lt;a href=\"https://dlthub.com/docs/general-usage/schema-contracts\"&gt;data contracts&lt;/a&gt; with the following options for handling bad events:&lt;br/&gt;\n- evolve schema&lt;br/&gt;\n- reject load package&lt;br/&gt;\n- truncate columns and ingest (discard columns)&lt;br/&gt;\n- discard event (discard row)&lt;br/&gt;\nWe will next add bad data handling so if you have requirements how you would like that to work please comment &lt;a href=\"https://github.com/dlt-hub/dlt/issues/780\"&gt;here&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;Thanks all! and let 2024 be a year with more open source data solutions :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "191lf3o", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191lf3o/event_ingestion_for_cheap_on_aws_and_gcp_2_demos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191lf3o/event_ingestion_for_cheap_on_aws_and_gcp_2_demos/", "subreddit_subscribers": 151323, "created_utc": 1704721119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nWe have an interesting problem and wanted to get reddit's take on it. I am keeping it intentionally vague for privacy, but will add relevant details and can answer questions in the comments. \n\nWe are building an application that segments consumers based on whether they have or have not done activities. Ultimately the application supports combinations of boolean logic and whether they have or have not done something to arrive at a list of IDs and a count of consumers. It also supports non-dynamic date ranges, whether they have done it in the last 30 days, 1 year, or all time. One example request would be \"Get me all the people who have done ((activity X AND activity Y) OR activity Z) in the last 30 days\", another could be \"Get me all the people who have done activity X AND NOT activity Y\". We delivered this functionality though our architecture has some issues. \n\nPrimary issue is that the we are using event tables, and as a result we have records of consumers who HAVE participated in an activity but we don't maintain people who HAVE NOT done the activity, thus we cannot query consumers who have done an activity 0 times. To achieve the NOT logic, we exclude people who have done the activity to get the final result set. If we were to run a query that has activity X OR NOT activity Y, we would get unintended results. \n\nSecondary issue is that we have preset date ranges, which is useful at times but not very flexible or dynamic. Ideally a user could input a custom date range in the application to be applied to the backend queries. \n\nThis is a very large data set. The total possible consumers is \\~3B and they all participate in (some) activity. We 1) want to maintain a pool of consumers such that our NOT logic can query for records where participation count = 0 and 2) want to provide a flexible date range option (or mimic that functionality) \n\nFirst thought is to join a datedim table to our table of consumers to have one record for each combination of consumer and date. However this results in an ever increasing amount of data, for 2 years we would have \\~2Trillion records and counting. Then we have to apply boolean logic to filter down the records and in some cases join subsets of records, which simply gets expensive and is computationally intensive for a user facing application. \n\nWe are using **snowflake** for data storage and **python** for custom query generation, I am trying to think of creative ways to add a flexible date range and support potentially massive computation without requests from the application being too slow. For a user application, does it make more sense to compute dynamic date ranges on the fly after a request has been submitted, or precompute a massive dataset and filter it down after the fact? Or a mix of both? \n\nIf anyone has any wisdom or similar experience please let me know, I am also happy to answer any questions in the comments. ", "author_fullname": "t2_60ux6m11", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Really big data set, combining pool of consumers with datedim", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191x2nj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704750442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;We have an interesting problem and wanted to get reddit&amp;#39;s take on it. I am keeping it intentionally vague for privacy, but will add relevant details and can answer questions in the comments. &lt;/p&gt;\n\n&lt;p&gt;We are building an application that segments consumers based on whether they have or have not done activities. Ultimately the application supports combinations of boolean logic and whether they have or have not done something to arrive at a list of IDs and a count of consumers. It also supports non-dynamic date ranges, whether they have done it in the last 30 days, 1 year, or all time. One example request would be &amp;quot;Get me all the people who have done ((activity X AND activity Y) OR activity Z) in the last 30 days&amp;quot;, another could be &amp;quot;Get me all the people who have done activity X AND NOT activity Y&amp;quot;. We delivered this functionality though our architecture has some issues. &lt;/p&gt;\n\n&lt;p&gt;Primary issue is that the we are using event tables, and as a result we have records of consumers who HAVE participated in an activity but we don&amp;#39;t maintain people who HAVE NOT done the activity, thus we cannot query consumers who have done an activity 0 times. To achieve the NOT logic, we exclude people who have done the activity to get the final result set. If we were to run a query that has activity X OR NOT activity Y, we would get unintended results. &lt;/p&gt;\n\n&lt;p&gt;Secondary issue is that we have preset date ranges, which is useful at times but not very flexible or dynamic. Ideally a user could input a custom date range in the application to be applied to the backend queries. &lt;/p&gt;\n\n&lt;p&gt;This is a very large data set. The total possible consumers is ~3B and they all participate in (some) activity. We 1) want to maintain a pool of consumers such that our NOT logic can query for records where participation count = 0 and 2) want to provide a flexible date range option (or mimic that functionality) &lt;/p&gt;\n\n&lt;p&gt;First thought is to join a datedim table to our table of consumers to have one record for each combination of consumer and date. However this results in an ever increasing amount of data, for 2 years we would have ~2Trillion records and counting. Then we have to apply boolean logic to filter down the records and in some cases join subsets of records, which simply gets expensive and is computationally intensive for a user facing application. &lt;/p&gt;\n\n&lt;p&gt;We are using &lt;strong&gt;snowflake&lt;/strong&gt; for data storage and &lt;strong&gt;python&lt;/strong&gt; for custom query generation, I am trying to think of creative ways to add a flexible date range and support potentially massive computation without requests from the application being too slow. For a user application, does it make more sense to compute dynamic date ranges on the fly after a request has been submitted, or precompute a massive dataset and filter it down after the fact? Or a mix of both? &lt;/p&gt;\n\n&lt;p&gt;If anyone has any wisdom or similar experience please let me know, I am also happy to answer any questions in the comments. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "191x2nj", "is_robot_indexable": true, "report_reasons": null, "author": "lt-96", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191x2nj/really_big_data_set_combining_pool_of_consumers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191x2nj/really_big_data_set_combining_pool_of_consumers/", "subreddit_subscribers": 151323, "created_utc": 1704750442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have heard great things and wanted to give it a shot. Currently have a Postgres database handling data aggregations and ETL. I wanted to pick a separate technology for the warehouse so that down the road migrating to something like Snowflake would be less painful (no shortcuts, lazy coding, etc) and to keep end users from accidentally stalling out the resources of the ETL pipelines. Snowflake and anything similar would be overkill for my current data volume, and trying to avoid cloud for simplifying security environment.\n\nI was curious how DuckDB could work in this scenario with multiple end users. The data in Postgres will be properly transformed into gold level and star schema before landing in the warehouse. I\u2019m really wanting the warehouse to be a ready to consume analytics layer rather than a mess of transformations and staging tables (already using DBT in ETL pipelines).\n\nWould I surface a common .db file on a local network for end users with read only access? Or is there another configuration to consider/another tool completely that would be better suited for the job.", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB as a data warehouse for multiple users?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1922n89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704764802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have heard great things and wanted to give it a shot. Currently have a Postgres database handling data aggregations and ETL. I wanted to pick a separate technology for the warehouse so that down the road migrating to something like Snowflake would be less painful (no shortcuts, lazy coding, etc) and to keep end users from accidentally stalling out the resources of the ETL pipelines. Snowflake and anything similar would be overkill for my current data volume, and trying to avoid cloud for simplifying security environment.&lt;/p&gt;\n\n&lt;p&gt;I was curious how DuckDB could work in this scenario with multiple end users. The data in Postgres will be properly transformed into gold level and star schema before landing in the warehouse. I\u2019m really wanting the warehouse to be a ready to consume analytics layer rather than a mess of transformations and staging tables (already using DBT in ETL pipelines).&lt;/p&gt;\n\n&lt;p&gt;Would I surface a common .db file on a local network for end users with read only access? Or is there another configuration to consider/another tool completely that would be better suited for the job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1922n89", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1922n89/duckdb_as_a_data_warehouse_for_multiple_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1922n89/duckdb_as_a_data_warehouse_for_multiple_users/", "subreddit_subscribers": 151323, "created_utc": 1704764802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am trying to think of ways to approximate the count of records returned on a series of queries without processing the query. \n\nI am using snowflake, and we create a number of temporary tables that are either inner or outer joined together to support AND / OR logic. \n\nFor example, say we have Temp Table A, Temp Table B, Temp Table C and we want a count of records for ids that appear in ((A AND B) OR C). Is it remotely possible to approximate a count without running a query? My first thought is to use **HyperLogLog** algorithm ([https://redis.io/docs/data-types/probabilistic/hyperloglogs/#:\\~:text=HyperLogLog%20is%20a%20probabilistic%20data,accuracy%20for%20efficient%20space%20utilization](https://redis.io/docs/data-types/probabilistic/hyperloglogs/#:~:text=HyperLogLog%20is%20a%20probabilistic%20data,accuracy%20for%20efficient%20space%20utilization)), however this seems to be more applicable for interacting with 2 tables and finding the approximate intersection. \n\nWe don't need to be very precise, just a ballpark count. Any ideas out there to estimate the count of multiple tables being joined together?\n\n&amp;#x200B;", "author_fullname": "t2_60ux6m11", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get multi-table join results without running the query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191x6w3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704750724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am trying to think of ways to approximate the count of records returned on a series of queries without processing the query. &lt;/p&gt;\n\n&lt;p&gt;I am using snowflake, and we create a number of temporary tables that are either inner or outer joined together to support AND / OR logic. &lt;/p&gt;\n\n&lt;p&gt;For example, say we have Temp Table A, Temp Table B, Temp Table C and we want a count of records for ids that appear in ((A AND B) OR C). Is it remotely possible to approximate a count without running a query? My first thought is to use &lt;strong&gt;HyperLogLog&lt;/strong&gt; algorithm (&lt;a href=\"https://redis.io/docs/data-types/probabilistic/hyperloglogs/#:%7E:text=HyperLogLog%20is%20a%20probabilistic%20data,accuracy%20for%20efficient%20space%20utilization\"&gt;https://redis.io/docs/data-types/probabilistic/hyperloglogs/#:~:text=HyperLogLog%20is%20a%20probabilistic%20data,accuracy%20for%20efficient%20space%20utilization&lt;/a&gt;), however this seems to be more applicable for interacting with 2 tables and finding the approximate intersection. &lt;/p&gt;\n\n&lt;p&gt;We don&amp;#39;t need to be very precise, just a ballpark count. Any ideas out there to estimate the count of multiple tables being joined together?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "191x6w3", "is_robot_indexable": true, "report_reasons": null, "author": "lt-96", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191x6w3/get_multitable_join_results_without_running_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191x6w3/get_multitable_join_results_without_running_the/", "subreddit_subscribers": 151323, "created_utc": 1704750724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The [project](https://github.com/JawaharRamis/PL-Football-ETL-with-Airflow-AWS) orchestrated using Airflow retrieve raw data from an api saving into an S3 bucket which is then transformed using a glue job and then stored onto another S3 bucket. The processed data is fed into Quicksight for visualizations. \n\nI have been trying to build up my DE portfolio hoping to land a job in this field. You can find more of my projects in my [Github](https://github.com/JawaharRamis). Most of these projects helped familiarize myself with the tools. My goal is to develop a really good DE project within the next few months which could help me really stand out. \n\nShare me your advices/suggestions on my project and also how I could build up my portfolio further.", "author_fullname": "t2_67og6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Premier League football data pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191jbc9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704713923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The &lt;a href=\"https://github.com/JawaharRamis/PL-Football-ETL-with-Airflow-AWS\"&gt;project&lt;/a&gt; orchestrated using Airflow retrieve raw data from an api saving into an S3 bucket which is then transformed using a glue job and then stored onto another S3 bucket. The processed data is fed into Quicksight for visualizations. &lt;/p&gt;\n\n&lt;p&gt;I have been trying to build up my DE portfolio hoping to land a job in this field. You can find more of my projects in my &lt;a href=\"https://github.com/JawaharRamis\"&gt;Github&lt;/a&gt;. Most of these projects helped familiarize myself with the tools. My goal is to develop a really good DE project within the next few months which could help me really stand out. &lt;/p&gt;\n\n&lt;p&gt;Share me your advices/suggestions on my project and also how I could build up my portfolio further.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1Ij6NXV0VmqGQbreihbdbU2WYEnc12GrQAqjtLmC4mw.jpg?auto=webp&amp;s=347d9668cc8c2ec7a8c04fee6e77cba3a4afc79d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1Ij6NXV0VmqGQbreihbdbU2WYEnc12GrQAqjtLmC4mw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2ad3e33471e7a8bb581236afaed67a1bbab4303b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1Ij6NXV0VmqGQbreihbdbU2WYEnc12GrQAqjtLmC4mw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86777486d7455d06995fbd5614f91dacfb14f5fb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1Ij6NXV0VmqGQbreihbdbU2WYEnc12GrQAqjtLmC4mw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6940e9a9e525dcefada6b5a37dec973eeb2ae372", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1Ij6NXV0VmqGQbreihbdbU2WYEnc12GrQAqjtLmC4mw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f72576fe2aecfc199f7eb58c169264038fd0666d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1Ij6NXV0VmqGQbreihbdbU2WYEnc12GrQAqjtLmC4mw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a1da77c69cd2bd166ec975ae5f545204aff8ec91", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1Ij6NXV0VmqGQbreihbdbU2WYEnc12GrQAqjtLmC4mw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c6a017189e1a21c9ae88c5767560b118c9b055e", "width": 1080, "height": 540}], "variants": {}, "id": "IDYD8vpVUNEhiFy6td-x6vZG_MLHzaQ1ccBksElAl60"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "191jbc9", "is_robot_indexable": true, "report_reasons": null, "author": "jawz96", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191jbc9/premier_league_football_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191jbc9/premier_league_football_data_pipeline/", "subreddit_subscribers": 151323, "created_utc": 1704713923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, so I'm wondering if there are any major differences between the two roles and what they might look like from others with similar experience around them.  I know data engineers are more implementation and data architect is design, but I was wondering how they relate within the field and what possible career trajectory there might be for each", "author_fullname": "t2_egr49q43v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Architect vs Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1922w0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704765474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, so I&amp;#39;m wondering if there are any major differences between the two roles and what they might look like from others with similar experience around them.  I know data engineers are more implementation and data architect is design, but I was wondering how they relate within the field and what possible career trajectory there might be for each&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1922w0r", "is_robot_indexable": true, "report_reasons": null, "author": "morkborkus", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1922w0r/data_architect_vs_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1922w0r/data_architect_vs_data_engineer/", "subreddit_subscribers": 151323, "created_utc": 1704765474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Probably only one thing that is more painful than working with legacy ETL stored procedures/DMLs is migrating them.\n\nNew data teams normally start with a data analyst or data scientist come up with a number of SQLs, then setting up cron jobs materializing views into tables. Over time, it becomes a pile of mess. Data leanage exists nowhere but in their minds. Tables being updated by god-knows DMLs.\n\nI have seen a lot of efforts in migrating existing SQL codes and DML to DAG-based solution like DBT. But doing so manually is extremely tedious. I wonder there must be automation service for this already.\n\nHas anyone come across this problem?", "author_fullname": "t2_oqbpxpulm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrate legacy database ETL to newer DAG-based", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1922oee", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704764890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Probably only one thing that is more painful than working with legacy ETL stored procedures/DMLs is migrating them.&lt;/p&gt;\n\n&lt;p&gt;New data teams normally start with a data analyst or data scientist come up with a number of SQLs, then setting up cron jobs materializing views into tables. Over time, it becomes a pile of mess. Data leanage exists nowhere but in their minds. Tables being updated by god-knows DMLs.&lt;/p&gt;\n\n&lt;p&gt;I have seen a lot of efforts in migrating existing SQL codes and DML to DAG-based solution like DBT. But doing so manually is extremely tedious. I wonder there must be automation service for this already.&lt;/p&gt;\n\n&lt;p&gt;Has anyone come across this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1922oee", "is_robot_indexable": true, "report_reasons": null, "author": "JayDoDr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1922oee/migrate_legacy_database_etl_to_newer_dagbased/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1922oee/migrate_legacy_database_etl_to_newer_dagbased/", "subreddit_subscribers": 151323, "created_utc": 1704764890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say I have normalised a table to create my database schema. However, how would new data coming in via the original denormalised format be appended to the normalised version of the table?", "author_fullname": "t2_d9jl5vn6o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data appending task help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191m9g1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704723595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I have normalised a table to create my database schema. However, how would new data coming in via the original denormalised format be appended to the normalised version of the table?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "191m9g1", "is_robot_indexable": true, "report_reasons": null, "author": "No-Pineapple7188", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191m9g1/data_appending_task_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191m9g1/data_appending_task_help/", "subreddit_subscribers": 151323, "created_utc": 1704723595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i have learned that creating a separate database for development is better than using the live database -- for which i was doing for a while, so i am applying in my database this practice that i learned. Now, whenever there are changes in my development database, I just perform exactly the same (changes in columns, create new table, alter procedure, etc) to the live database.  \nIt is somehow tedious, so I think, there might be a better way than what I was doing right now. Can you share how do you do it? I am using postgre", "author_fullname": "t2_de0trs4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to apply same changes from dev database to prod?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191lomk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704721934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have learned that creating a separate database for development is better than using the live database -- for which i was doing for a while, so i am applying in my database this practice that i learned. Now, whenever there are changes in my development database, I just perform exactly the same (changes in columns, create new table, alter procedure, etc) to the live database.&lt;br/&gt;\nIt is somehow tedious, so I think, there might be a better way than what I was doing right now. Can you share how do you do it? I am using postgre&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "191lomk", "is_robot_indexable": true, "report_reasons": null, "author": "WildNumber7303", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191lomk/how_to_apply_same_changes_from_dev_database_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191lomk/how_to_apply_same_changes_from_dev_database_to/", "subreddit_subscribers": 151323, "created_utc": 1704721934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi i am helping somome design a DE system , hoping to get some ideas here.\n\n1. Ecommerce system like amazon with various 'shops' ( vendors)\n2. We get hourly batch of clickstream like data&lt;Shop\\_id, visitor\\_user\\_id&gt;\n3. We need to put out records in a pub/sub type system when shops reach a specific lifetime audience&lt;shop\\_id, 100k unique lifetime visitors&gt;\n4. Based on the pub/sub tier level for the shop is upgraded in the backend system. This is out of scope for this post but adding it as an additional context.\n5. One thing to note is that 'hourly\\_batch' in step 2 is sometimes backfilled if there were errors in the upstream system. We are notified  if a particular hourly batch was backfilled with newer corrected data. Its very rare but our system should be able to handle this scenario. \n\n&amp;#x200B;", "author_fullname": "t2_m3j3hg1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Metrics Notification Design.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191kyfh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704719659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi i am helping somome design a DE system , hoping to get some ideas here.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ecommerce system like amazon with various &amp;#39;shops&amp;#39; ( vendors)&lt;/li&gt;\n&lt;li&gt;We get hourly batch of clickstream like data&amp;lt;Shop\\_id, visitor\\_user\\_id&amp;gt;&lt;/li&gt;\n&lt;li&gt;We need to put out records in a pub/sub type system when shops reach a specific lifetime audience&amp;lt;shop\\_id, 100k unique lifetime visitors&amp;gt;&lt;/li&gt;\n&lt;li&gt;Based on the pub/sub tier level for the shop is upgraded in the backend system. This is out of scope for this post but adding it as an additional context.&lt;/li&gt;\n&lt;li&gt;One thing to note is that &amp;#39;hourly_batch&amp;#39; in step 2 is sometimes backfilled if there were errors in the upstream system. We are notified  if a particular hourly batch was backfilled with newer corrected data. Its very rare but our system should be able to handle this scenario. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "191kyfh", "is_robot_indexable": true, "report_reasons": null, "author": "Electrical-Ask847", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191kyfh/metrics_notification_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191kyfh/metrics_notification_design/", "subreddit_subscribers": 151323, "created_utc": 1704719659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, community! \ud83d\ude80 I'm eager to kickstart my journey into Apache Airflow and looking for suggestions on beginner-friendly projects. Any insights, recommendations, or hands-on learning ideas that can help me grasp the ropes of Airflow effectively? Thanks in advance for your valuable input!", "author_fullname": "t2_3fyuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice: Beginner-Friendly Projects to Dive into Apache Airflow Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191k13k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704716546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, community! \ud83d\ude80 I&amp;#39;m eager to kickstart my journey into Apache Airflow and looking for suggestions on beginner-friendly projects. Any insights, recommendations, or hands-on learning ideas that can help me grasp the ropes of Airflow effectively? Thanks in advance for your valuable input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "191k13k", "is_robot_indexable": true, "report_reasons": null, "author": "ramesh4f", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191k13k/seeking_advice_beginnerfriendly_projects_to_dive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191k13k/seeking_advice_beginnerfriendly_projects_to_dive/", "subreddit_subscribers": 151323, "created_utc": 1704716546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI have been working on data connector app, so for that I need to store my unstructed data (image) inside snowflake workspace ! Similar to databricks where we can store it in volumes  within db workspace.\nIs there any similar way in snowflake, or I can only store a data with structured format with reference to public urls of image ? \nAny similar blogs or reference would be helpful ? \nTIA", "author_fullname": "t2_ksfsegu4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unstructured data in snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191jzqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704716416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI have been working on data connector app, so for that I need to store my unstructed data (image) inside snowflake workspace ! Similar to databricks where we can store it in volumes  within db workspace.\nIs there any similar way in snowflake, or I can only store a data with structured format with reference to public urls of image ? \nAny similar blogs or reference would be helpful ? \nTIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "191jzqt", "is_robot_indexable": true, "report_reasons": null, "author": "MelodicHyena5029", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191jzqt/unstructured_data_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191jzqt/unstructured_data_in_snowflake/", "subreddit_subscribers": 151323, "created_utc": 1704716416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you use Airbyte cloud or self hosted on EC2 for production data integration pipelines? Mainly looking for only data ingestion tool.", "author_fullname": "t2_eozceps7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte Cloud or self hosted on EC2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191j9iy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704713727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you use Airbyte cloud or self hosted on EC2 for production data integration pipelines? Mainly looking for only data ingestion tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "191j9iy", "is_robot_indexable": true, "report_reasons": null, "author": "Liily_07", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191j9iy/airbyte_cloud_or_self_hosted_on_ec2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191j9iy/airbyte_cloud_or_self_hosted_on_ec2/", "subreddit_subscribers": 151323, "created_utc": 1704713727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a Data Engineer having most of the experience in GCP cloud. I see more Data Engineer job postings on AWS cloud comparatively than GCP. How do companies look at a candidate resume when their tech stack doesn\u2019t match but has the relevant experience.", "author_fullname": "t2_5gknig7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP Data Engineering Jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191a1k3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704680749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a Data Engineer having most of the experience in GCP cloud. I see more Data Engineer job postings on AWS cloud comparatively than GCP. How do companies look at a candidate resume when their tech stack doesn\u2019t match but has the relevant experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "191a1k3", "is_robot_indexable": true, "report_reasons": null, "author": "PurpleCurrent3576", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191a1k3/gcp_data_engineering_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191a1k3/gcp_data_engineering_jobs/", "subreddit_subscribers": 151323, "created_utc": 1704680749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wonder if there are dbt altnernatives, even in development phase, that do not use yml, but code. I think what [pulumi](https://www.pulumi.com/) is for terraform, no more yml, only code that you run. I wonder if there is the equivalent in sql transformation", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for dbt alternatives in development, with less yml \ud83d\ude2c", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191ittr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704712131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wonder if there are dbt altnernatives, even in development phase, that do not use yml, but code. I think what &lt;a href=\"https://www.pulumi.com/\"&gt;pulumi&lt;/a&gt; is for terraform, no more yml, only code that you run. I wonder if there is the equivalent in sql transformation&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fU2gtaPQJIVKR2jnWz-bxfBqnhuM7vTYFEGfpqcFCs0.jpg?auto=webp&amp;s=f254a1588f7a3ace6e64595bc2432a26dc3e1470", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fU2gtaPQJIVKR2jnWz-bxfBqnhuM7vTYFEGfpqcFCs0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3c8bba3c6168a39493a90f561e8e919696a15d2", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fU2gtaPQJIVKR2jnWz-bxfBqnhuM7vTYFEGfpqcFCs0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa642407b0c895619b18b576969160863a17a4f5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fU2gtaPQJIVKR2jnWz-bxfBqnhuM7vTYFEGfpqcFCs0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a7dfdc30320ee4e3340caa228efe5756dea1d904", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fU2gtaPQJIVKR2jnWz-bxfBqnhuM7vTYFEGfpqcFCs0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=845297c16d2cc5b28c20fc07f5674af16bfc7bba", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fU2gtaPQJIVKR2jnWz-bxfBqnhuM7vTYFEGfpqcFCs0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d28315a58f7e1babc5f9cca33e2da70cbacc84a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fU2gtaPQJIVKR2jnWz-bxfBqnhuM7vTYFEGfpqcFCs0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b7bbb5e843c8eebca4506630b6b422e919a17e3", "width": 1080, "height": 567}], "variants": {}, "id": "cQEFWWqJNyaGgwDq3eMFY8skU1wDtz3knCMTN9_XTBo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "191ittr", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191ittr/looking_for_dbt_alternatives_in_development_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191ittr/looking_for_dbt_alternatives_in_development_with/", "subreddit_subscribers": 151323, "created_utc": 1704712131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI\u2019d like to know what you think are the needs for distributed processing (which focuses more precisely on MapReduce treatments, Spark/Hadoop frameworks, etc.) in the industry atm.\n\nI\u2019m currently working for key accounts customers and I don\u2019t see any need really. Still, that\u2019s the career I\u2019d like to pursue.\n\nIs it outdated already? Too niche?\n\nDo you have any advices on:\n- Kinds of structures I could aim for,\n- Most relevant companies and/or\n- City hubs to work in/for?", "author_fullname": "t2_ssgrrnis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Needs for Distributed Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_191hlw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704707228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to know what you think are the needs for distributed processing (which focuses more precisely on MapReduce treatments, Spark/Hadoop frameworks, etc.) in the industry atm.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently working for key accounts customers and I don\u2019t see any need really. Still, that\u2019s the career I\u2019d like to pursue.&lt;/p&gt;\n\n&lt;p&gt;Is it outdated already? Too niche?&lt;/p&gt;\n\n&lt;p&gt;Do you have any advices on:\n- Kinds of structures I could aim for,\n- Most relevant companies and/or\n- City hubs to work in/for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "191hlw3", "is_robot_indexable": true, "report_reasons": null, "author": "Cultural_Guarantee69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/191hlw3/needs_for_distributed_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/191hlw3/needs_for_distributed_processing/", "subreddit_subscribers": 151323, "created_utc": 1704707228.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}