{"kind": "Listing", "data": {"after": "t3_1acu35b", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do amateurs usually not do well?", "author_fullname": "t2_e7studq8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What distinguishes production-grade data pipelines from amateur setups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1addsj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706477671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do amateurs usually not do well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1addsj4", "is_robot_indexable": true, "report_reasons": null, "author": "CupcakeFun4746", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1addsj4/what_distinguishes_productiongrade_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1addsj4/what_distinguishes_productiongrade_data_pipelines/", "subreddit_subscribers": 156549, "created_utc": 1706477671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some context : I'm working on a predictive maintenance prototype on Azure. Essentially, the sensors send in readings periodically every 30s (Temperature, Vibrations, Pressure, Noice, etc.). The data is added into an event hub. The data is then processed and dumped into ADLS V2. The readings are passed into an ML model and run against some basic checks(If temp exceeds, send an email notification to the asset owner, etc...) The notifications (for now) are processed via logic apps(When a blob is created within the datalake)\n\nCan these events directly be processed via an event driven architecture instead of using Kafka? Or processing the data through serverless functions? \n\nAlso, what are some good visualization tools that can let me monotor this data in near real time?\n\nI've just started learning to use Kafka, and would appreciate any answers. ", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the purpose of using Kafka, when the same can be processed though an Event Driven Architecuture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ad1xqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706446067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some context : I&amp;#39;m working on a predictive maintenance prototype on Azure. Essentially, the sensors send in readings periodically every 30s (Temperature, Vibrations, Pressure, Noice, etc.). The data is added into an event hub. The data is then processed and dumped into ADLS V2. The readings are passed into an ML model and run against some basic checks(If temp exceeds, send an email notification to the asset owner, etc...) The notifications (for now) are processed via logic apps(When a blob is created within the datalake)&lt;/p&gt;\n\n&lt;p&gt;Can these events directly be processed via an event driven architecture instead of using Kafka? Or processing the data through serverless functions? &lt;/p&gt;\n\n&lt;p&gt;Also, what are some good visualization tools that can let me monotor this data in near real time?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just started learning to use Kafka, and would appreciate any answers. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ad1xqt", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ad1xqt/whats_the_purpose_of_using_kafka_when_the_same/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ad1xqt/whats_the_purpose_of_using_kafka_when_the_same/", "subreddit_subscribers": 156549, "created_utc": 1706446067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is by far the hardest course I ever took.\n\nMost of the things don't work I am constantly on Slack and running around on the net and harrasing gpt.\n\nI can't even figure out how to do the homework.\n\nSome questions are trivial, but there are others that require knowledge of data ingestion and docker compose.\n\nI have such a headache these last few days as I haven't moved an inch. The project for certification is copy paste, but the homework is basically knowing advanced knowledge for the thing you are supposed to be learning.  \nEDIT: I was wrong, I must have been somewhere else.  \nFortunately there exists a template for creating personal projects.  \nSo if I manage to get there that is a big plus.\n\nIt can't just be me who has the issue with the structure?\n\n&amp;#x200B;", "author_fullname": "t2_yn7uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else struggle in DE zoomcamp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ad7pcc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1706471070.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706462510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is by far the hardest course I ever took.&lt;/p&gt;\n\n&lt;p&gt;Most of the things don&amp;#39;t work I am constantly on Slack and running around on the net and harrasing gpt.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t even figure out how to do the homework.&lt;/p&gt;\n\n&lt;p&gt;Some questions are trivial, but there are others that require knowledge of data ingestion and docker compose.&lt;/p&gt;\n\n&lt;p&gt;I have such a headache these last few days as I haven&amp;#39;t moved an inch. The project for certification is copy paste, but the homework is basically knowing advanced knowledge for the thing you are supposed to be learning.&lt;br/&gt;\nEDIT: I was wrong, I must have been somewhere else.&lt;br/&gt;\nFortunately there exists a template for creating personal projects.&lt;br/&gt;\nSo if I manage to get there that is a big plus.&lt;/p&gt;\n\n&lt;p&gt;It can&amp;#39;t just be me who has the issue with the structure?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ad7pcc", "is_robot_indexable": true, "report_reasons": null, "author": "SemperPistos", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ad7pcc/does_anyone_else_struggle_in_de_zoomcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ad7pcc/does_anyone_else_struggle_in_de_zoomcamp/", "subreddit_subscribers": 156549, "created_utc": 1706462510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to learn even more about data engineering and would really like to connect to enthusiastic data folks. Does anybody has recommendations for good data related conference across europe in 2024?", "author_fullname": "t2_lj5pjrd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best data conferences in Europe - 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ad0vkk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706442110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn even more about data engineering and would really like to connect to enthusiastic data folks. Does anybody has recommendations for good data related conference across europe in 2024?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1ad0vkk", "is_robot_indexable": true, "report_reasons": null, "author": "HolidayCritical3665", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ad0vkk/best_data_conferences_in_europe_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ad0vkk/best_data_conferences_in_europe_2024/", "subreddit_subscribers": 156549, "created_utc": 1706442110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm considering a data Engineer job in Stockholm and wondering what salary one might expect. I have around 3-4 years of experience in the area. I don't want to get lowballed and there is not a lot of information on the sites that I have checked.", "author_fullname": "t2_16rehat2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer salary in sweden", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1aczxgc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706438262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m considering a data Engineer job in Stockholm and wondering what salary one might expect. I have around 3-4 years of experience in the area. I don&amp;#39;t want to get lowballed and there is not a lot of information on the sites that I have checked.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1aczxgc", "is_robot_indexable": true, "report_reasons": null, "author": "fjurgo", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1aczxgc/data_engineer_salary_in_sweden/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1aczxgc/data_engineer_salary_in_sweden/", "subreddit_subscribers": 156549, "created_utc": 1706438262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lets say I have source team that can write data to Kafka for the data team\u2019s consumption so data team can build a DW. What approach from the below approaches would be the best approxh for long term success and why?\n\nSource\u2014&gt; Kafka\u2014&gt;Redshift (DW)\n\nSource \u2014&gt; Kafka \u2014&gt; S3 \u2014&gt; Redshift?\n\n\nI like storing data in S3 first and  then copy it into Redshift. This way your S3 can be your Data Lake and the DL data can be used bu other tools. \n\nI am trying to see what are some other benefits of storing data on S3 or should we just write data to Redshift?", "author_fullname": "t2_5cjr5v2c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lake preferred approach.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acvcqo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706420119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have source team that can write data to Kafka for the data team\u2019s consumption so data team can build a DW. What approach from the below approaches would be the best approxh for long term success and why?&lt;/p&gt;\n\n&lt;p&gt;Source\u2014&amp;gt; Kafka\u2014&amp;gt;Redshift (DW)&lt;/p&gt;\n\n&lt;p&gt;Source \u2014&amp;gt; Kafka \u2014&amp;gt; S3 \u2014&amp;gt; Redshift?&lt;/p&gt;\n\n&lt;p&gt;I like storing data in S3 first and  then copy it into Redshift. This way your S3 can be your Data Lake and the DL data can be used bu other tools. &lt;/p&gt;\n\n&lt;p&gt;I am trying to see what are some other benefits of storing data on S3 or should we just write data to Redshift?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1acvcqo", "is_robot_indexable": true, "report_reasons": null, "author": "captut", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acvcqo/data_lake_preferred_approach/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acvcqo/data_lake_preferred_approach/", "subreddit_subscribers": 156549, "created_utc": 1706420119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, software engineer in the trading space here. Currently, we dump a load of very useful data into Kdb and never look at it again, q is designed for Kx consultants, not for the lay-person. Took some time over Christmas to make a simple system that goes:\n\nRaw JSON events in Kdb -[Java]-&gt; ClickHouse Raw -[Materialised View]-&gt; ClickHouse Facts -&gt; Superset\n\nDemo reactions were similar to how I imagine cavemen reacted to seeing fire for the first time, and news of this shiny new tool has flown up the chain of command. Needless to say we're now very keen on building out a SQL-based OLAP system. As we move towards a proper POC, I've refined the setup slightly to:\n\n* dbt for building the facts table from the raw table. \n  * Materialised views felt too magic, at least how I was using them - lots of JSON parsing and self joins to build up order summaries, etc. Feel they're more suited for simple running aggregations?\n* Jenkins for running the Kdb ingest and dbt transforms every 10m.\n  * Don't shoot me, had it already and I'm familiar with it as a developer.\n\nSome key goals/facts:\n\n* Must be low maintenance.\n  * We're turning our backs on the corporate data strategy. No dedicated DE staff, just developers with lots of other things to be doing.\n* Cost is secondary.\n  * Insights from this data are worth $$$.\n* Keep everything, forever (ELT &gt; ETL). \n  * It's unacceptable to say \"we don't have this piece of data anymore\" or \"we forgot to parse that new field\" in 2024.\n* Full Prod volumes are c.10bn rows a day, 99.9% of which is market data.\n  * Raw JSON market data events can reside in Kdb per previous tenet, but we'll still need to store every tick (under a proper schema) for order analysis.\n\nImagine the final production deployment will be managed Superset/ClickHouse, then self hosted orchestration/dbt. Things I'm particularly interested in hearing your thoughts on are (but not exclusively):\n\n* Is ClickHouse a suitable database choice? Simple deployment was a driving factor for my toy project; could Snowflake, StarRocks, Pinot/Druid, etc etc be a better option as we move towards production?\n* What orchestration tool should I use? Airflow/Dagster/Prefect seem to be the big 3, any distinguishing features? Do forsee needing to run more complicated transformations than just dbt SQL (eg. the quants will probably want to get involved running ML models etc).\n* Any other useful tools I'm missing (although more tools = more things to maintain).\n* What should we watch out for as we scale this up from a toy to a POC and finally to production? \n\nThanks!!", "author_fullname": "t2_snsq45lm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a greenfield OLAP system for finance/trading", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ad00tv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706438633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, software engineer in the trading space here. Currently, we dump a load of very useful data into Kdb and never look at it again, q is designed for Kx consultants, not for the lay-person. Took some time over Christmas to make a simple system that goes:&lt;/p&gt;\n\n&lt;p&gt;Raw JSON events in Kdb -[Java]-&amp;gt; ClickHouse Raw -[Materialised View]-&amp;gt; ClickHouse Facts -&amp;gt; Superset&lt;/p&gt;\n\n&lt;p&gt;Demo reactions were similar to how I imagine cavemen reacted to seeing fire for the first time, and news of this shiny new tool has flown up the chain of command. Needless to say we&amp;#39;re now very keen on building out a SQL-based OLAP system. As we move towards a proper POC, I&amp;#39;ve refined the setup slightly to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;dbt for building the facts table from the raw table. \n\n&lt;ul&gt;\n&lt;li&gt;Materialised views felt too magic, at least how I was using them - lots of JSON parsing and self joins to build up order summaries, etc. Feel they&amp;#39;re more suited for simple running aggregations?&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Jenkins for running the Kdb ingest and dbt transforms every 10m.\n\n&lt;ul&gt;\n&lt;li&gt;Don&amp;#39;t shoot me, had it already and I&amp;#39;m familiar with it as a developer.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Some key goals/facts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Must be low maintenance.\n\n&lt;ul&gt;\n&lt;li&gt;We&amp;#39;re turning our backs on the corporate data strategy. No dedicated DE staff, just developers with lots of other things to be doing.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Cost is secondary.\n\n&lt;ul&gt;\n&lt;li&gt;Insights from this data are worth $$$.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Keep everything, forever (ELT &amp;gt; ETL). \n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s unacceptable to say &amp;quot;we don&amp;#39;t have this piece of data anymore&amp;quot; or &amp;quot;we forgot to parse that new field&amp;quot; in 2024.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Full Prod volumes are c.10bn rows a day, 99.9% of which is market data.\n\n&lt;ul&gt;\n&lt;li&gt;Raw JSON market data events can reside in Kdb per previous tenet, but we&amp;#39;ll still need to store every tick (under a proper schema) for order analysis.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Imagine the final production deployment will be managed Superset/ClickHouse, then self hosted orchestration/dbt. Things I&amp;#39;m particularly interested in hearing your thoughts on are (but not exclusively):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is ClickHouse a suitable database choice? Simple deployment was a driving factor for my toy project; could Snowflake, StarRocks, Pinot/Druid, etc etc be a better option as we move towards production?&lt;/li&gt;\n&lt;li&gt;What orchestration tool should I use? Airflow/Dagster/Prefect seem to be the big 3, any distinguishing features? Do forsee needing to run more complicated transformations than just dbt SQL (eg. the quants will probably want to get involved running ML models etc).&lt;/li&gt;\n&lt;li&gt;Any other useful tools I&amp;#39;m missing (although more tools = more things to maintain).&lt;/li&gt;\n&lt;li&gt;What should we watch out for as we scale this up from a toy to a POC and finally to production? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ad00tv", "is_robot_indexable": true, "report_reasons": null, "author": "Alternative_Push_948", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ad00tv/building_a_greenfield_olap_system_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ad00tv/building_a_greenfield_olap_system_for/", "subreddit_subscribers": 156549, "created_utc": 1706438633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have converted some domain-specific name vectors into embeddings, with a dataset size of 200k words. All the embeddings were generated using OpenAI's embedding model 3 (3072 dim per embedding) . Now I am planning to implement semantic search similarity. Given a domain keyword, I want to find the top 5 most similar matches. After embedding all 280k words, the size of the JSON file containing the embeddings is around 30GB.\n\nI am new to this domain and evaluating the best options.\n\n1. Should I use a cloud vector database like Pinecone or Typsense, or host locally on DigitalOcean?\n2. If I go with a cloud option like Typsense, what configuration (RAM, etc.) would I need for 280k embeddings (30GB in size)? And how much would it likely cost?\n\nI have been confused for the past few days and unable to find useful resources. Any help or advice you could provide would be greatly appreciated.", "author_fullname": "t2_kgr7e5qng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices for Semantic Search on 200k vectors (30GB) Worth of Embeddings?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acxy0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706430039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have converted some domain-specific name vectors into embeddings, with a dataset size of 200k words. All the embeddings were generated using OpenAI&amp;#39;s embedding model 3 (3072 dim per embedding) . Now I am planning to implement semantic search similarity. Given a domain keyword, I want to find the top 5 most similar matches. After embedding all 280k words, the size of the JSON file containing the embeddings is around 30GB.&lt;/p&gt;\n\n&lt;p&gt;I am new to this domain and evaluating the best options.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Should I use a cloud vector database like Pinecone or Typsense, or host locally on DigitalOcean?&lt;/li&gt;\n&lt;li&gt;If I go with a cloud option like Typsense, what configuration (RAM, etc.) would I need for 280k embeddings (30GB in size)? And how much would it likely cost?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I have been confused for the past few days and unable to find useful resources. Any help or advice you could provide would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1acxy0q", "is_robot_indexable": true, "report_reasons": null, "author": "stoicbats_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acxy0q/best_practices_for_semantic_search_on_200k/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acxy0q/best_practices_for_semantic_search_on_200k/", "subreddit_subscribers": 156549, "created_utc": 1706430039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was discussing professional certifications with my sister, she just completed 3 years of experience. \nThe place where she works at, just got established and the business is in its early stages.. however, she wants to start building the business intelligence centre with them and hopefully can lead the team in a year or two. \nWhat professional certifications will help her? and what skills she should develop? \n\nPersonally I think PMP and Data+ can help but she kinda hesitant.", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What professional certifications will help to lead BI/Analytics team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ada7r0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706468743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was discussing professional certifications with my sister, she just completed 3 years of experience. \nThe place where she works at, just got established and the business is in its early stages.. however, she wants to start building the business intelligence centre with them and hopefully can lead the team in a year or two. \nWhat professional certifications will help her? and what skills she should develop? &lt;/p&gt;\n\n&lt;p&gt;Personally I think PMP and Data+ can help but she kinda hesitant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ada7r0", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ada7r0/what_professional_certifications_will_help_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ada7r0/what_professional_certifications_will_help_to/", "subreddit_subscribers": 156549, "created_utc": 1706468743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, fellow data enthusiasts!\n\nI'm back with my second post, and I want to thank you for the incredible insights and support you all provided on my first one. This community is truly a goldmine of collective wisdom!\n\nNow, onto my current conundrum. The use cases at my day job are less than inspiring. I've tried to shake things up, suggesting new ideas and approaches I've discovered online, but the company is sticking to the old ways due to budget constraints.\n\nI firmly believe in the power of side projects to keep skills sharp and stay competitive in the tech market. I'm hitting a roadblock when finding side projects that could add some weight to my skills.\n\nSo, I'm reaching out to you, my fellow data engineers, for some advice on how you go about finding side projects that are not only meaningful but also enhance your skills\n\nAny advice, resources, or personal experiences you can share would be greatly appreciated", "author_fullname": "t2_vncr806l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Navigating Uninspiring Work Use Cases &amp; Finding Valuable Side Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ad7y3l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706463116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, fellow data enthusiasts!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m back with my second post, and I want to thank you for the incredible insights and support you all provided on my first one. This community is truly a goldmine of collective wisdom!&lt;/p&gt;\n\n&lt;p&gt;Now, onto my current conundrum. The use cases at my day job are less than inspiring. I&amp;#39;ve tried to shake things up, suggesting new ideas and approaches I&amp;#39;ve discovered online, but the company is sticking to the old ways due to budget constraints.&lt;/p&gt;\n\n&lt;p&gt;I firmly believe in the power of side projects to keep skills sharp and stay competitive in the tech market. I&amp;#39;m hitting a roadblock when finding side projects that could add some weight to my skills.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m reaching out to you, my fellow data engineers, for some advice on how you go about finding side projects that are not only meaningful but also enhance your skills&lt;/p&gt;\n\n&lt;p&gt;Any advice, resources, or personal experiences you can share would be greatly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1ad7y3l", "is_robot_indexable": true, "report_reasons": null, "author": "SpiritedSparrow8314", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ad7y3l/navigating_uninspiring_work_use_cases_finding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ad7y3l/navigating_uninspiring_work_use_cases_finding/", "subreddit_subscribers": 156549, "created_utc": 1706463116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I read the Designing Data-Intensive Applications book by Martin Kleppmann a few years ago. It is an accessible encyclopedia-like book about databases and distributed systems. The big plus of this book is that it has a lot of references for further reading.\n\nNow I'm looking for something similar in terms of content, but with a focus on the modern data engineering stack that covers technologies like Flink, Kafka, Pulsar, Pinot, Spark, Iceberg, Clickhouse, and others. The use cases behind using them, their advantages and disadvantages, and how they all integrate.\n\nIn other words, something that covers the whole modern landscape of data engineering tools.\n\nIt would be good if it wouldn't be an in-depth 1000+ pages read. Something that an experienced backend engineer (not a data engineer) could grasp in a few weekends. It may be a book, a set of articles, or a series of videos. The form is not important.\n\nWhat would you recommend?", "author_fullname": "t2_15hg9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comprehensive recommendations on the modern data engineering tools ecosystem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1adckj2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706474655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read the Designing Data-Intensive Applications book by Martin Kleppmann a few years ago. It is an accessible encyclopedia-like book about databases and distributed systems. The big plus of this book is that it has a lot of references for further reading.&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m looking for something similar in terms of content, but with a focus on the modern data engineering stack that covers technologies like Flink, Kafka, Pulsar, Pinot, Spark, Iceberg, Clickhouse, and others. The use cases behind using them, their advantages and disadvantages, and how they all integrate.&lt;/p&gt;\n\n&lt;p&gt;In other words, something that covers the whole modern landscape of data engineering tools.&lt;/p&gt;\n\n&lt;p&gt;It would be good if it wouldn&amp;#39;t be an in-depth 1000+ pages read. Something that an experienced backend engineer (not a data engineer) could grasp in a few weekends. It may be a book, a set of articles, or a series of videos. The form is not important.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1adckj2", "is_robot_indexable": true, "report_reasons": null, "author": "visortelle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adckj2/comprehensive_recommendations_on_the_modern_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adckj2/comprehensive_recommendations_on_the_modern_data/", "subreddit_subscribers": 156549, "created_utc": 1706474655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After seeing a few people on this subreddit respond to [Gunnar Morling's 1BRC](https://www.morling.dev/blog/one-billion-row-challenge/) with unofficial SQL solutions, we decided to give it a try, and after a few rounds of optimizing our parsing code, Pansynchro's performance is equivalent to the top 20% of 1BRC contest entrants.  Not bad for a general-purpose data integration framework that's not able to apply many of the hyper-specific optimization tricks used by top-performing entries!\n\n[https://pansynchro.tech/the-one-billion-row-challenge-optimizing-csv-performance/](https://pansynchro.tech/the-one-billion-row-challenge-optimizing-csv-performance/)", "author_fullname": "t2_otqnx9sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One Billion Row Challenge - Pansynchro", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acuj21", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706417290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After seeing a few people on this subreddit respond to &lt;a href=\"https://www.morling.dev/blog/one-billion-row-challenge/\"&gt;Gunnar Morling&amp;#39;s 1BRC&lt;/a&gt; with unofficial SQL solutions, we decided to give it a try, and after a few rounds of optimizing our parsing code, Pansynchro&amp;#39;s performance is equivalent to the top 20% of 1BRC contest entrants.  Not bad for a general-purpose data integration framework that&amp;#39;s not able to apply many of the hyper-specific optimization tricks used by top-performing entries!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pansynchro.tech/the-one-billion-row-challenge-optimizing-csv-performance/\"&gt;https://pansynchro.tech/the-one-billion-row-challenge-optimizing-csv-performance/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1acuj21", "is_robot_indexable": true, "report_reasons": null, "author": "Pansynchro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acuj21/one_billion_row_challenge_pansynchro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acuj21/one_billion_row_challenge_pansynchro/", "subreddit_subscribers": 156549, "created_utc": 1706417290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6ygc9fu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for new projects. I had some replies. Any tips for my CV? TiA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1adfduo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WDbDlTiWDFHlQzIjg3srmK1wVx496lgHzkDEZw7MwBo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1706481673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/up5xald5e9fc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/up5xald5e9fc1.jpeg?auto=webp&amp;s=ce6c8ab6a2805436ead157277bf8e2248c4d6767", "width": 1080, "height": 2340}, "resolutions": [{"url": "https://preview.redd.it/up5xald5e9fc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8341a662dc160bdcde93858fee3ce87aabb3c07b", "width": 108, "height": 216}, {"url": "https://preview.redd.it/up5xald5e9fc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=80aaece61ac3959bdff87d7b2686dd1650844670", "width": 216, "height": 432}, {"url": "https://preview.redd.it/up5xald5e9fc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b8ca26c94547276a35a17c4192f953d8e2842b0b", "width": 320, "height": 640}, {"url": "https://preview.redd.it/up5xald5e9fc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2e56843ea6d27eab579d35adf731994947823240", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/up5xald5e9fc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9ef9c36e82d61fa107e278cb4ff00e9851d5767", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/up5xald5e9fc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7900835bb0efb8b1d5ff35b7cb02881042778ac7", "width": 1080, "height": 2160}], "variants": {}, "id": "Ysev3tEqXXlsBIdGnf00C-AuVljgjuzCc4dK_kk9_Zs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1adfduo", "is_robot_indexable": true, "report_reasons": null, "author": "StovetopAtol4", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adfduo/looking_for_new_projects_i_had_some_replies_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/up5xald5e9fc1.jpeg", "subreddit_subscribers": 156549, "created_utc": 1706481673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For our dimensional tables we use SCD 2 and cut a new record every time there is a change in any one of the fields. We use SSIS's SCD component which does it nicely.\n\nWe will be now moving the DWH to snowflake. Not sure if we want to keep SSIS as the tool for it.\n\nWhat do you use with snowflake for SCD?", "author_fullname": "t2_5epqry7a5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slowly changing dimension in DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ad986k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706466292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For our dimensional tables we use SCD 2 and cut a new record every time there is a change in any one of the fields. We use SSIS&amp;#39;s SCD component which does it nicely.&lt;/p&gt;\n\n&lt;p&gt;We will be now moving the DWH to snowflake. Not sure if we want to keep SSIS as the tool for it.&lt;/p&gt;\n\n&lt;p&gt;What do you use with snowflake for SCD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ad986k", "is_robot_indexable": true, "report_reasons": null, "author": "liskeeksil", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ad986k/slowly_changing_dimension_in_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ad986k/slowly_changing_dimension_in_dwh/", "subreddit_subscribers": 156549, "created_utc": 1706466292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have the first round of interviews coming up in a week. The interviewer asked to solve HackerRank hard SQL and Medium Python. Have gone through the SQL questions but I would like to have some more practice. Any tips on where to find more relevant SQL exercises for this role? \n\nAlso, would highly appreciate if anyone with experience of going through this interview or with experience of working in this role leave any comments/tips for the interview. Thanks in advance!", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips for the technical round prep (SQL, Python) for Amazon Sr. BIE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ad3mxb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706451522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have the first round of interviews coming up in a week. The interviewer asked to solve HackerRank hard SQL and Medium Python. Have gone through the SQL questions but I would like to have some more practice. Any tips on where to find more relevant SQL exercises for this role? &lt;/p&gt;\n\n&lt;p&gt;Also, would highly appreciate if anyone with experience of going through this interview or with experience of working in this role leave any comments/tips for the interview. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1ad3mxb", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ad3mxb/any_tips_for_the_technical_round_prep_sql_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ad3mxb/any_tips_for_the_technical_round_prep_sql_python/", "subreddit_subscribers": 156549, "created_utc": 1706451522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHi all, coming for QA background, wanted to switch to data engineering field, I'm curious to know - what are the differences between a data engineer and a cloud engineer in terms of job roles and skills sets? Which one is better accordingly? \n\nSpoke to cloud engineer and he told that DE skills also comes in his field, so refered me to consider Cloud engineering. What's your take ont his\n\nThanks for any helpful responses!", "author_fullname": "t2_bpk9d5w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering vs Cloud Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acwxnp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706425963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, coming for QA background, wanted to switch to data engineering field, I&amp;#39;m curious to know - what are the differences between a data engineer and a cloud engineer in terms of job roles and skills sets? Which one is better accordingly? &lt;/p&gt;\n\n&lt;p&gt;Spoke to cloud engineer and he told that DE skills also comes in his field, so refered me to consider Cloud engineering. What&amp;#39;s your take ont his&lt;/p&gt;\n\n&lt;p&gt;Thanks for any helpful responses!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1acwxnp", "is_robot_indexable": true, "report_reasons": null, "author": "Zestyclose_Web_6331", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acwxnp/data_engineering_vs_cloud_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acwxnp/data_engineering_vs_cloud_engineering/", "subreddit_subscribers": 156549, "created_utc": 1706425963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm reviewing new systems and one key component that they reference is the usage of complex transformations. \n\nI know that generally, people will say \"Lots of joins, aggregations etc\". But that is a little too general for my level of experience (which is low). \n\nCan you please give me some sort of guideline, heuristic, rule of thumb, or scoring guide that will allow me to more objectively determine if I have complex transformations in my data environment? \n\nAny and all tips and greatly appreciated. ", "author_fullname": "t2_y8ebf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you determine if you have 'Complex Transformations'?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1adiie2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706490177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m reviewing new systems and one key component that they reference is the usage of complex transformations. &lt;/p&gt;\n\n&lt;p&gt;I know that generally, people will say &amp;quot;Lots of joins, aggregations etc&amp;quot;. But that is a little too general for my level of experience (which is low). &lt;/p&gt;\n\n&lt;p&gt;Can you please give me some sort of guideline, heuristic, rule of thumb, or scoring guide that will allow me to more objectively determine if I have complex transformations in my data environment? &lt;/p&gt;\n\n&lt;p&gt;Any and all tips and greatly appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1adiie2", "is_robot_indexable": true, "report_reasons": null, "author": "Raging-Loner", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adiie2/how_do_you_determine_if_you_have_complex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adiie2/how_do_you_determine_if_you_have_complex/", "subreddit_subscribers": 156549, "created_utc": 1706490177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let\u2019s say you have an application that communicates with your database. You scaled out your frontend so that it\u2019s highly available. However, a process that occurs from your frontend is very noisy and results in too much chatter going from your database back to that one instance.\n\nMaybe the question is fundamentally flawed, but does it make technical sense in any manner to scale out the requests your server receives from its backend? How would you do that? Would it require proxying the complex request through a backend service and awaiting the result at the instance that needs it? Are there any algorithms that do this without requiring changes to the underlying application?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you horizontally scale for incoming requests?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acx6je", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706426958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say you have an application that communicates with your database. You scaled out your frontend so that it\u2019s highly available. However, a process that occurs from your frontend is very noisy and results in too much chatter going from your database back to that one instance.&lt;/p&gt;\n\n&lt;p&gt;Maybe the question is fundamentally flawed, but does it make technical sense in any manner to scale out the requests your server receives from its backend? How would you do that? Would it require proxying the complex request through a backend service and awaiting the result at the instance that needs it? Are there any algorithms that do this without requiring changes to the underlying application?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1acx6je", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acx6je/how_do_you_horizontally_scale_for_incoming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acx6je/how_do_you_horizontally_scale_for_incoming/", "subreddit_subscribers": 156549, "created_utc": 1706426958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically, I have a macro that dynamically parses a json. This is advantageous bc upstream we find that databases change occasionally. However, I\u2019m having a hell of time figuring out how to type floats, dates, integers, etc in the downstream model without explicitly casting each column. Many tables per database are 150+ columns. \n\nAnd while Snowflake will interpret fairly well as consumers query either the string or variant it gets messy when data consumers are using Jupyter or SAS (can\u2019t change it, nothing to do there). \n\nSo, how do I cast these data types cleanly through a macro that also parses a json field. \n\nAny help or insight is greatly appreciated.\n\nEdit: more info \u2014 Kafka as upstream, DBT for transformation, Snowflake as db. ", "author_fullname": "t2_j2qne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Frustrated with DBT and Kafka, how are you supposed to type data as opposed to parsing all of it dynamically into a string or a variant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1adjbud", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706492597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically, I have a macro that dynamically parses a json. This is advantageous bc upstream we find that databases change occasionally. However, I\u2019m having a hell of time figuring out how to type floats, dates, integers, etc in the downstream model without explicitly casting each column. Many tables per database are 150+ columns. &lt;/p&gt;\n\n&lt;p&gt;And while Snowflake will interpret fairly well as consumers query either the string or variant it gets messy when data consumers are using Jupyter or SAS (can\u2019t change it, nothing to do there). &lt;/p&gt;\n\n&lt;p&gt;So, how do I cast these data types cleanly through a macro that also parses a json field. &lt;/p&gt;\n\n&lt;p&gt;Any help or insight is greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Edit: more info \u2014 Kafka as upstream, DBT for transformation, Snowflake as db. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1adjbud", "is_robot_indexable": true, "report_reasons": null, "author": "r0ck13r4c00n", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adjbud/frustrated_with_dbt_and_kafka_how_are_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adjbud/frustrated_with_dbt_and_kafka_how_are_you/", "subreddit_subscribers": 156549, "created_utc": 1706492597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started at a small company (the whole data team is myself and three other self-taught guys doing SQL development, dashboarding, and basic DBA work) whose whole stack is in MSSQL, and they\u2019ve got no dev/test environment. All of their queries are tested right there in their production database that feeds all of their reporting solutions, which is really concerning me.\n\nI\u2019m coming from a major firm where they had a full sandbox with regularly snapshotted copies of the production DBs that you could develop and test on, but that\u2019s waaaaayyy too big for this company, so I\u2019m trying to figure out what the best practice for creating at least a development environment for them would be. Something that also has their linked server connections that the main DB has, ideally.\n\nIs the best option a replicated copy of the prod DB, taken every morning after the overnight ETL run, that we all just develop on? They\u2019re still all on SQL Agent and SSIS (old school, but it works for now), so can we migrate any jobs/packages we develop on the dev environment over to prod?\n\nWould it be best to entirely separate prod and dev, running on separate VMs, rather than having multiple DBs on the same server? We\u2019ll soon have a two more SQL devs joining us, so we could get pretty full up some people are in prod and others are in dev, all on the same server simultaneously.", "author_fullname": "t2_bnb6qfsd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a prod/dev(/test?) SQL environment split for a small company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1adix2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706491392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started at a small company (the whole data team is myself and three other self-taught guys doing SQL development, dashboarding, and basic DBA work) whose whole stack is in MSSQL, and they\u2019ve got no dev/test environment. All of their queries are tested right there in their production database that feeds all of their reporting solutions, which is really concerning me.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m coming from a major firm where they had a full sandbox with regularly snapshotted copies of the production DBs that you could develop and test on, but that\u2019s waaaaayyy too big for this company, so I\u2019m trying to figure out what the best practice for creating at least a development environment for them would be. Something that also has their linked server connections that the main DB has, ideally.&lt;/p&gt;\n\n&lt;p&gt;Is the best option a replicated copy of the prod DB, taken every morning after the overnight ETL run, that we all just develop on? They\u2019re still all on SQL Agent and SSIS (old school, but it works for now), so can we migrate any jobs/packages we develop on the dev environment over to prod?&lt;/p&gt;\n\n&lt;p&gt;Would it be best to entirely separate prod and dev, running on separate VMs, rather than having multiple DBs on the same server? We\u2019ll soon have a two more SQL devs joining us, so we could get pretty full up some people are in prod and others are in dev, all on the same server simultaneously.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1adix2j", "is_robot_indexable": true, "report_reasons": null, "author": "Seth_Littrells_alt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adix2j/creating_a_proddevtest_sql_environment_split_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adix2j/creating_a_proddevtest_sql_environment_split_for/", "subreddit_subscribers": 156549, "created_utc": 1706491392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I have an interview for a software consultancy firm in the UK. \n\nI have a group based problem solving activity around data modelling for a hypothetical system.\n\nI'm a software dev, what's this and how do I prep for it?\n\nThanks guys", "author_fullname": "t2_k7i48uo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me prep for a software consultancy firm - data modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1adby0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706473061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I have an interview for a software consultancy firm in the UK. &lt;/p&gt;\n\n&lt;p&gt;I have a group based problem solving activity around data modelling for a hypothetical system.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a software dev, what&amp;#39;s this and how do I prep for it?&lt;/p&gt;\n\n&lt;p&gt;Thanks guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1adby0v", "is_robot_indexable": true, "report_reasons": null, "author": "13aoul", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adby0v/help_me_prep_for_a_software_consultancy_firm_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adby0v/help_me_prep_for_a_software_consultancy_firm_data/", "subreddit_subscribers": 156549, "created_utc": 1706473061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm curious to hear about your personal experiences with Kafka.\n\nKafka has become a cornerstone for real-time data processing and streaming, but like any technology, it comes with its own set of challenges and limitations.\n\n1. What are the most significant challenges you've encountered while working with Kafka? And how did you overcome them?\n2. Every tool has its limitations. What limitations have you encountered with Kafka? And how did you manage them?\n3. What do you wish Kafka had that it currently doesn't? What tool did you use to add these missing features?\n4. What aspects of Kafka do you think could be enhanced or improved?\n\nLooking forward to your stories and insights!", "author_fullname": "t2_legj2pv6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your experiences, wishes, and challenges with Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1adbfb6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706471732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to hear about your personal experiences with Kafka.&lt;/p&gt;\n\n&lt;p&gt;Kafka has become a cornerstone for real-time data processing and streaming, but like any technology, it comes with its own set of challenges and limitations.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What are the most significant challenges you&amp;#39;ve encountered while working with Kafka? And how did you overcome them?&lt;/li&gt;\n&lt;li&gt;Every tool has its limitations. What limitations have you encountered with Kafka? And how did you manage them?&lt;/li&gt;\n&lt;li&gt;What do you wish Kafka had that it currently doesn&amp;#39;t? What tool did you use to add these missing features?&lt;/li&gt;\n&lt;li&gt;What aspects of Kafka do you think could be enhanced or improved?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Looking forward to your stories and insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1adbfb6", "is_robot_indexable": true, "report_reasons": null, "author": "jak7878", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1adbfb6/your_experiences_wishes_and_challenges_with_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1adbfb6/your_experiences_wishes_and_challenges_with_kafka/", "subreddit_subscribers": 156549, "created_utc": 1706471732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I tend to think personal projects don\u2019t deserve formal project management and planning, but\u2026 perhaps I\u2019m wrong, especially for a project that spans longer than one weekend. It seems like it could pay dividends in terms of focus and organization. \n\nIf you have a process, what does it look like? For example, do you use Excel, or an SaaS subscription?  Do you organize in terms of epics/features/user stories, or something else?\n\nI\u2019m curious what you do, especially when it\u2019s just *you* working on the project, with no collaboration.", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal projects \u2014 if you use a process or tools for structuring/organizing/planning your personal projects, what do you use? Excel? Subscriptions? Scrum?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1ad9027", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706465722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tend to think personal projects don\u2019t deserve formal project management and planning, but\u2026 perhaps I\u2019m wrong, especially for a project that spans longer than one weekend. It seems like it could pay dividends in terms of focus and organization. &lt;/p&gt;\n\n&lt;p&gt;If you have a process, what does it look like? For example, do you use Excel, or an SaaS subscription?  Do you organize in terms of epics/features/user stories, or something else?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what you do, especially when it\u2019s just &lt;em&gt;you&lt;/em&gt; working on the project, with no collaboration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1ad9027", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1ad9027/personal_projects_if_you_use_a_process_or_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1ad9027/personal_projects_if_you_use_a_process_or_tools/", "subreddit_subscribers": 156549, "created_utc": 1706465722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! Does anyone have experience with using Confluent Cloud\u2019s fully-managed S3 Sink Connector to move data from Kafka topics to AWS S3? Currently I am struggling to simulate whether its scheduled rotations (through rotate.schedule.interval.ms config parameter) actually leads to duplicate records in the records uploaded to S3, as the documentation says **\u201cUsing the rotate.schedule.interval.ms property results in a non-deterministic environment and invalidates exactly-once guarantees.\u201d** \n\nIn my attempt to simulate a scenario that produces duplicates, I am referencing the example in this article ([Confluent S3 Sink Connector EOS (declarativesystems.com)](https://www.declarativesystems.com/2023/08/18/confluent-s3-sink-connector-eos.html) which illustrates that duplicates can occur when the producer writes to the Kafka topic at the same time as when the connector is scheduled to upload. So what I did was schedule a confluent\\_kafka Producer (in Python) to produce records every 10 minutes, while my S3 Sink Connector is configured to also upload every 10 minutes. So far I have tried this with 1,500 records and 6,000 records. However, I have yet to see any duplicate records when I try to parse the output stored in S3. One thing I did forget until now was the flush.size is still set to 1000 (default) meaning an upload should trigger once a kafka partition reaches 1000 records, but I have not seen any early uploads so I think it has not affected my simulation so far, but sharing it in case my understanding is wrong.", "author_fullname": "t2_3j4k9pzb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Confluent Cloud's fully managed S3 Sink Connector, do duplicates still occur?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acur5b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706418063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Does anyone have experience with using Confluent Cloud\u2019s fully-managed S3 Sink Connector to move data from Kafka topics to AWS S3? Currently I am struggling to simulate whether its scheduled rotations (through rotate.schedule.interval.ms config parameter) actually leads to duplicate records in the records uploaded to S3, as the documentation says &lt;strong&gt;\u201cUsing the rotate.schedule.interval.ms property results in a non-deterministic environment and invalidates exactly-once guarantees.\u201d&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;In my attempt to simulate a scenario that produces duplicates, I am referencing the example in this article (&lt;a href=\"https://www.declarativesystems.com/2023/08/18/confluent-s3-sink-connector-eos.html\"&gt;Confluent S3 Sink Connector EOS (declarativesystems.com)&lt;/a&gt; which illustrates that duplicates can occur when the producer writes to the Kafka topic at the same time as when the connector is scheduled to upload. So what I did was schedule a confluent_kafka Producer (in Python) to produce records every 10 minutes, while my S3 Sink Connector is configured to also upload every 10 minutes. So far I have tried this with 1,500 records and 6,000 records. However, I have yet to see any duplicate records when I try to parse the output stored in S3. One thing I did forget until now was the flush.size is still set to 1000 (default) meaning an upload should trigger once a kafka partition reaches 1000 records, but I have not seen any early uploads so I think it has not affected my simulation so far, but sharing it in case my understanding is wrong.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1acur5b", "is_robot_indexable": true, "report_reasons": null, "author": "Nagusameta", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acur5b/using_confluent_clouds_fully_managed_s3_sink/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acur5b/using_confluent_clouds_fully_managed_s3_sink/", "subreddit_subscribers": 156549, "created_utc": 1706418063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could anyone recommend university-affiliated certifications for a budding data analyst? Looking for options beyond Coursera.\n\nThanks!", "author_fullname": "t2_82djul76", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "University Data Analyst Certification Recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1acu35b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1706415774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could anyone recommend university-affiliated certifications for a budding data analyst? Looking for options beyond Coursera.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1acu35b", "is_robot_indexable": true, "report_reasons": null, "author": "ledangkhoa1220", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1acu35b/university_data_analyst_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1acu35b/university_data_analyst_certification/", "subreddit_subscribers": 156549, "created_utc": 1706415774.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}