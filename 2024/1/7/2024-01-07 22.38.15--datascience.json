{"kind": "Listing", "data": {"after": null, "dist": 3, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI've got a pretty good handle on machine learning and how those LLMs are trained. People often say LLMs predict the next word based on what came before, using a transformer network. But I'm wondering, how can a model that predicts the next word also understand requests like 'fix the spelling in this essay,' 'debug my code,' or 'tell me the sentiment of this comment'? It seems like they're doing more than just guessing the next word.\n\nI also know that big LLMs like GPT can't do these things right out of the box \u2013 they need some fine-tuning. Can someone break this down in a way that's easier for me to wrap my head around? I've tried reading a bunch of articles, but I'm still a bit puzzled", "author_fullname": "t2_5fbmh3va", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please provide an explanation of how large language models interpret prompts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190ww63", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704647515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a pretty good handle on machine learning and how those LLMs are trained. People often say LLMs predict the next word based on what came before, using a transformer network. But I&amp;#39;m wondering, how can a model that predicts the next word also understand requests like &amp;#39;fix the spelling in this essay,&amp;#39; &amp;#39;debug my code,&amp;#39; or &amp;#39;tell me the sentiment of this comment&amp;#39;? It seems like they&amp;#39;re doing more than just guessing the next word.&lt;/p&gt;\n\n&lt;p&gt;I also know that big LLMs like GPT can&amp;#39;t do these things right out of the box \u2013 they need some fine-tuning. Can someone break this down in a way that&amp;#39;s easier for me to wrap my head around? I&amp;#39;ve tried reading a bunch of articles, but I&amp;#39;m still a bit puzzled&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "190ww63", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent_Cost170", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/190ww63/please_provide_an_explanation_of_how_large/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/190ww63/please_provide_an_explanation_of_how_large/", "subreddit_subscribers": 1232424, "created_utc": 1704647515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Warning:** *I am an analytics engineer who lurks on this sub, pretends to know what they're are talking about, and am fascinated with \"scientific thinking\". I may write something stupid or incorrect, so please bear with me. There's essentially three sets of questions/scenarios below as it relates to domain knowledge.*\n\nI'm under the impression that building domain knowledge comes from working in these roles and supporting business functions, but it also seems there's risk in that domain knowledge isn't being properly developed in an incremental fashion over time if many of these said activities are in support of the business users (who are the ones in the throes of the domain knowledge).\n\nFor example, if you're a data scientist who supports sales forecasting, you may employ a modified version of linear regression and the output is essentially a heuristic specific to the business (I'm using my background from FP&amp;A as an example where everything is a SWAG). Along the way, you're working with sales management, and likely sales or revenue operations, and then someone in a GTM/product role. Each of the aforementioned functions is where the domain knowledge truly resides, so in this example, are you building domain knowledge from the interaction with these teams?\n\nAdditionally, let's say you're in a role that's supporting the revenue organization for a manufacturing company that makes auto parts, but you're more interested in education, especially online education technology (so think like Coursera, Udemy, EdX, Pluralsight to name a few). How do you identify what domain knowledge to seek that would be effective in transitioning to a new industry? Does that lead to a situation where you're almost starting over in a way?\n\nLastly, how do you know you have enough depth to say you have domain knowledge? If a data scientist has worked in a reporting dominant role supporting a payments facilitator team (payfac), how would they know they have \"enough\" domain knowledge to allow being included on a resume and not made a fool during an interview?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do \"know\" if your daily work is contributing to building domain knowledge? And, how do you identify and seek domain knowledge?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190rsmb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704632905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; &lt;em&gt;I am an analytics engineer who lurks on this sub, pretends to know what they&amp;#39;re are talking about, and am fascinated with &amp;quot;scientific thinking&amp;quot;. I may write something stupid or incorrect, so please bear with me. There&amp;#39;s essentially three sets of questions/scenarios below as it relates to domain knowledge.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m under the impression that building domain knowledge comes from working in these roles and supporting business functions, but it also seems there&amp;#39;s risk in that domain knowledge isn&amp;#39;t being properly developed in an incremental fashion over time if many of these said activities are in support of the business users (who are the ones in the throes of the domain knowledge).&lt;/p&gt;\n\n&lt;p&gt;For example, if you&amp;#39;re a data scientist who supports sales forecasting, you may employ a modified version of linear regression and the output is essentially a heuristic specific to the business (I&amp;#39;m using my background from FP&amp;amp;A as an example where everything is a SWAG). Along the way, you&amp;#39;re working with sales management, and likely sales or revenue operations, and then someone in a GTM/product role. Each of the aforementioned functions is where the domain knowledge truly resides, so in this example, are you building domain knowledge from the interaction with these teams?&lt;/p&gt;\n\n&lt;p&gt;Additionally, let&amp;#39;s say you&amp;#39;re in a role that&amp;#39;s supporting the revenue organization for a manufacturing company that makes auto parts, but you&amp;#39;re more interested in education, especially online education technology (so think like Coursera, Udemy, EdX, Pluralsight to name a few). How do you identify what domain knowledge to seek that would be effective in transitioning to a new industry? Does that lead to a situation where you&amp;#39;re almost starting over in a way?&lt;/p&gt;\n\n&lt;p&gt;Lastly, how do you know you have enough depth to say you have domain knowledge? If a data scientist has worked in a reporting dominant role supporting a payments facilitator team (payfac), how would they know they have &amp;quot;enough&amp;quot; domain knowledge to allow being included on a resume and not made a fool during an interview?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "190rsmb", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/190rsmb/how_to_do_know_if_your_daily_work_is_contributing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/190rsmb/how_to_do_know_if_your_daily_work_is_contributing/", "subreddit_subscribers": 1232424, "created_utc": 1704632905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!!\n\nI recently ran a bunch of models before I discovered that the dataset I was working with was incredibly imbalanced.\n\nI do not have a formal data science background (I have a background in Economics), but I have a data science job right now. I was wondering if someone could let me know what are some important datasets characteristics I should know about a dataset before I do what I just did in the future.", "author_fullname": "t2_17ir90", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Steps to understanding your dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190y2j8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704650462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!!&lt;/p&gt;\n\n&lt;p&gt;I recently ran a bunch of models before I discovered that the dataset I was working with was incredibly imbalanced.&lt;/p&gt;\n\n&lt;p&gt;I do not have a formal data science background (I have a background in Economics), but I have a data science job right now. I was wondering if someone could let me know what are some important datasets characteristics I should know about a dataset before I do what I just did in the future.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "190y2j8", "is_robot_indexable": true, "report_reasons": null, "author": "EmilyEmlz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/190y2j8/steps_to_understanding_your_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/190y2j8/steps_to_understanding_your_dataset/", "subreddit_subscribers": 1232424, "created_utc": 1704650462.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}