{"kind": "Listing", "data": {"after": "t3_190ooqr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Lately I have been archiving more media for my Plex library. I decided to download the entire One Piece show that's 1.3 tb. I started it a bit ago and it says it'll take over 3-5 days. I did download all of the Saturday Night Live seasons 2 years ago that took a week or less that was 1.68tbs.", "author_fullname": "t2_4trjihkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the biggest thing you've downloaded in your time being a Datahoarder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1908up8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 181, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 181, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704571797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lately I have been archiving more media for my Plex library. I decided to download the entire One Piece show that&amp;#39;s 1.3 tb. I started it a bit ago and it says it&amp;#39;ll take over 3-5 days. I did download all of the Saturday Night Live seasons 2 years ago that took a week or less that was 1.68tbs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "52TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1908up8", "is_robot_indexable": true, "report_reasons": null, "author": "Eskel5", "discussion_type": null, "num_comments": 166, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1908up8/whats_the_biggest_thing_youve_downloaded_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1908up8/whats_the_biggest_thing_youve_downloaded_in_your/", "subreddit_subscribers": 723540, "created_utc": 1704571797.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_78n2t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Meme] Average DigitalFAQ Forum Thread", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 59, "top_awarded_type": null, "hide_score": false, "name": "t3_1907rwb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/k2z32uelevac1/DASH_720.mp4?source=fallback", "has_audio": true, "height": 544, "width": 1280, "scrubber_media_url": "https://v.redd.it/k2z32uelevac1/DASH_96.mp4", "dash_url": "https://v.redd.it/k2z32uelevac1/DASHPlaylist.mpd?a=1707233896%2CYTdmODZhYzRhMzlmNWRkNDJmZTk0ZDU5ZGM4ZWY5NTEzZTVmYTIwNmRkNmNhMWJiYTVlNjVlZTJjZDRmMDNhZg%3D%3D&amp;v=1&amp;f=sd", "duration": 65, "hls_url": "https://v.redd.it/k2z32uelevac1/HLSPlaylist.m3u8?a=1707233896%2CYjI1ODAxZDZhZjM2ZjA2NGRmYWQ5MDM0N2E2OGZmOWY0NDY1NWQxNGZhYTI4MDdmMTNiYjExNDhjODNiNWVkNA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY.png?width=140&amp;height=59&amp;crop=140:59,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=c413aa68682d0d4c97f88b82728982ffb9e05f5d", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704569038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/k2z32uelevac1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY.png?format=pjpg&amp;auto=webp&amp;s=bce44850f07342b55770e49b9dc74229ca1c0776", "width": 1920, "height": 816}, "resolutions": [{"url": "https://external-preview.redd.it/bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=30edb531f0cf4a76e3d8fa5f083fac24e5f0b4d6", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=356a8f1356e0283ef130b7fc656c3d746826b129", "width": 216, "height": 91}, {"url": "https://external-preview.redd.it/bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=235550b017ec21d5aae3e494b27c05a6e8129a79", "width": 320, "height": 136}, {"url": "https://external-preview.redd.it/bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=1bf5a4fbda2d77e7cf10d8dc47df1b53719ab764", "width": 640, "height": 272}, {"url": "https://external-preview.redd.it/bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f6fb1360a21b12d868b1702a34c70cef96f944a4", "width": 960, "height": 408}, {"url": "https://external-preview.redd.it/bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=119168848e82be396df3a14fd9be234106477d4a", "width": 1080, "height": 459}], "variants": {}, "id": "bnA2M3N5ZXdldmFjMZoWtHTUYQ8HmcDa3x7MlwMAKZ70Qm2G5Gu-Wnq4rOgY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1907rwb", "is_robot_indexable": true, "report_reasons": null, "author": "Nightowl3090", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1907rwb/meme_average_digitalfaq_forum_thread/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/k2z32uelevac1", "subreddit_subscribers": 723540, "created_utc": 1704569038.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/k2z32uelevac1/DASH_720.mp4?source=fallback", "has_audio": true, "height": 544, "width": 1280, "scrubber_media_url": "https://v.redd.it/k2z32uelevac1/DASH_96.mp4", "dash_url": "https://v.redd.it/k2z32uelevac1/DASHPlaylist.mpd?a=1707233896%2CYTdmODZhYzRhMzlmNWRkNDJmZTk0ZDU5ZGM4ZWY5NTEzZTVmYTIwNmRkNmNhMWJiYTVlNjVlZTJjZDRmMDNhZg%3D%3D&amp;v=1&amp;f=sd", "duration": 65, "hls_url": "https://v.redd.it/k2z32uelevac1/HLSPlaylist.m3u8?a=1707233896%2CYjI1ODAxZDZhZjM2ZjA2NGRmYWQ5MDM0N2E2OGZmOWY0NDY1NWQxNGZhYTI4MDdmMTNiYjExNDhjODNiNWVkNA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_crd2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There comes a point where MEGA becomes unfeasible for a certain level of datahoarders :(", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "name": "t3_190hram", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ngwEo0bklrcZGim7cSMSgsLKghi-NCbOMUWyeThGkyI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704595960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/xfv0obghmxac1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/xfv0obghmxac1.png?auto=webp&amp;s=98e4bf632faec59a928397462a40f684b2a86910", "width": 1037, "height": 562}, "resolutions": [{"url": "https://preview.redd.it/xfv0obghmxac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=41d193dac7fed1e96be4a68ceed4cd47f82a0e85", "width": 108, "height": 58}, {"url": "https://preview.redd.it/xfv0obghmxac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=693fd298104a73bbe09aaf0742081bb25c49945c", "width": 216, "height": 117}, {"url": "https://preview.redd.it/xfv0obghmxac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bda9ed080b9934c2aa64a8bb684a27ba225d361d", "width": 320, "height": 173}, {"url": "https://preview.redd.it/xfv0obghmxac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=27d292b33e645b9ab93aee14eb3534ab574d7ce3", "width": 640, "height": 346}, {"url": "https://preview.redd.it/xfv0obghmxac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e62e7cd79d06ce2653222f363ea59235a0b9155", "width": 960, "height": 520}], "variants": {}, "id": "CCE8PnQ9w705IN7Kiaq56e5QB9EfV4iPOtnTX6jZQ28"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "190hram", "is_robot_indexable": true, "report_reasons": null, "author": "TheInzaneGamer", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190hram/there_comes_a_point_where_mega_becomes_unfeasible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/xfv0obghmxac1.png", "subreddit_subscribers": 723540, "created_utc": 1704595960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a PC to encrypt and she has a Mac on her end. I do have access to a MacBook Air too. ", "author_fullname": "t2_119ak5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to password protect/encrypt an external drive with 500GB of photos and videos for shipping?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1902mpo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704555641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a PC to encrypt and she has a Mac on her end. I do have access to a MacBook Air too. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1902mpo", "is_robot_indexable": true, "report_reasons": null, "author": "nakkai", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1902mpo/best_way_to_password_protectencrypt_an_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1902mpo/best_way_to_password_protectencrypt_an_external/", "subreddit_subscribers": 723540, "created_utc": 1704555641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The Western Digital website is having a sale right now, you can get two WD Red Pro 14TB NAS drives for $439.98 (free shipping) if anyone is in the market for some. Looks like the discount ends 1/7/2024.", "author_fullname": "t2_xagsn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bundle discount on WD Pro Red 14TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1904a1m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/3zQXU-3S4jeh3SEwSQaSwboZJNti_8jiS7D1cMUm3O0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704560131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The Western Digital website is having a sale right now, you can get two WD Red Pro 14TB NAS drives for $439.98 (free shipping) if anyone is in the market for some. Looks like the discount ends 1/7/2024.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/34b9fq5fouac1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/34b9fq5fouac1.png?auto=webp&amp;s=c5a705840ad9031c5446de7f34aae1fc07448581", "width": 1080, "height": 2412}, "resolutions": [{"url": "https://preview.redd.it/34b9fq5fouac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab2416aca78843be6d4abd7f127fab9e112589a0", "width": 108, "height": 216}, {"url": "https://preview.redd.it/34b9fq5fouac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=734c47d6961c2ba9f4ee48ef1149226e67662e30", "width": 216, "height": 432}, {"url": "https://preview.redd.it/34b9fq5fouac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4599776d3b396f0f1c7a7870b05a1d9251dc20bf", "width": 320, "height": 640}, {"url": "https://preview.redd.it/34b9fq5fouac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a7889b19d691644110378448897150e57443325e", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/34b9fq5fouac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a1b1fd88c0cd58a80c6ae415ad9839e461de0b54", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/34b9fq5fouac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9123b5e52fa6831e1022e50d10f74819c7b051ff", "width": 1080, "height": 2160}], "variants": {}, "id": "2QqZ8gspdCb_mQ3lJxXBq0x0SDA6WfocGaGqIT6sf_A"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1904a1m", "is_robot_indexable": true, "report_reasons": null, "author": "pillowserious", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1904a1m/bundle_discount_on_wd_pro_red_14tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/34b9fq5fouac1.png", "subreddit_subscribers": 723540, "created_utc": 1704560131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "All of my collections have been deleted and I can't login anymore. It's ridiculous that I never even got an email as to why I got banned. I had some deleted YouTube channel content on there. So glad I got some stuff backed up locally. Why would the Internet Archive of all people delete ALL content that a user has uploaded? And why the hell didn't I get an email??", "author_fullname": "t2_vnru8wzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Banned from Internet Archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190kfw0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704604359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All of my collections have been deleted and I can&amp;#39;t login anymore. It&amp;#39;s ridiculous that I never even got an email as to why I got banned. I had some deleted YouTube channel content on there. So glad I got some stuff backed up locally. Why would the Internet Archive of all people delete ALL content that a user has uploaded? And why the hell didn&amp;#39;t I get an email??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "52TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190kfw0", "is_robot_indexable": true, "report_reasons": null, "author": "funny_b0t2", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/190kfw0/banned_from_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190kfw0/banned_from_internet_archive/", "subreddit_subscribers": 723540, "created_utc": 1704604359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I find one problem with being a DataHoarder is having multiple versions of the same video clips. I've used programs such as DupeGuru to weed out identical videos, but the problem is when you have the same video, but different sizes. One possibility is that the video was popular and re-encoded by someone else at some point. \n\nMy goal is to only keep the best quality version of each video. \n\nSo I first thought I could just sort by video length, and then take out the smaller sized files. But I'm finding that some of the reencoded vids are larger than the original, so that doesn't always help. Right now I'm going through each potential dupe video, screenshotting a random frame, zooming in and comparing them manually. It works, but not the most efficient process.\n\nAre there any thoughts on a better way to do this? Thanks!", "author_fullname": "t2_h3tsi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video quality advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1907qbg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704568921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I find one problem with being a DataHoarder is having multiple versions of the same video clips. I&amp;#39;ve used programs such as DupeGuru to weed out identical videos, but the problem is when you have the same video, but different sizes. One possibility is that the video was popular and re-encoded by someone else at some point. &lt;/p&gt;\n\n&lt;p&gt;My goal is to only keep the best quality version of each video. &lt;/p&gt;\n\n&lt;p&gt;So I first thought I could just sort by video length, and then take out the smaller sized files. But I&amp;#39;m finding that some of the reencoded vids are larger than the original, so that doesn&amp;#39;t always help. Right now I&amp;#39;m going through each potential dupe video, screenshotting a random frame, zooming in and comparing them manually. It works, but not the most efficient process.&lt;/p&gt;\n\n&lt;p&gt;Are there any thoughts on a better way to do this? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1907qbg", "is_robot_indexable": true, "report_reasons": null, "author": "1doughnut", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1907qbg/video_quality_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1907qbg/video_quality_advice/", "subreddit_subscribers": 723540, "created_utc": 1704568921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible if so how?", "author_fullname": "t2_8zpe3mjoq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting 3d models from 2gis.ru", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1908wle", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704571925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible if so how?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1908wle", "is_robot_indexable": true, "report_reasons": null, "author": "3dPrintMyThingi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1908wle/extracting_3d_models_from_2gisru/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1908wle/extracting_3d_models_from_2gisru/", "subreddit_subscribers": 723540, "created_utc": 1704571925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There a few courses that I would like to download from Linkedin Learning. I want to ask if anyone can suggest a program that currently works? What is the easiest method to download full courses?\n\nI would appreciate any suggestions. Thank you. ", "author_fullname": "t2_gte3r2430", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can you download full courses from Linkedin Learning? What method currently works?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190ozjv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704621863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There a few courses that I would like to download from Linkedin Learning. I want to ask if anyone can suggest a program that currently works? What is the easiest method to download full courses?&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any suggestions. Thank you. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190ozjv", "is_robot_indexable": true, "report_reasons": null, "author": "bigbellybomac", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190ozjv/how_can_you_download_full_courses_from_linkedin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190ozjv/how_can_you_download_full_courses_from_linkedin/", "subreddit_subscribers": 723540, "created_utc": 1704621863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sorry, I know it's partially on topic at best, but I figure you guys are likely the ones to chat to.\n\nI'm having issues with the playback of some of my, err hoarded data and what I really need is a variety of 'test files' so I can just spot a problem instantly, without having to question my eyes.\n\nI need some 30 and 24hz videos which specifically do panning, that kind of thing, just a general 'plex test' of content. Variety of frame rates and situations to spot if my playback is working flawlessly at resolutions / frame rates, with trancoding and so on.\n\n&amp;#x200B;\n\nAnyone seen anything like this that they've hoarded?", "author_fullname": "t2_vhliwffj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need some test files, this seems the most likely place to find them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190of8d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704619483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry, I know it&amp;#39;s partially on topic at best, but I figure you guys are likely the ones to chat to.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having issues with the playback of some of my, err hoarded data and what I really need is a variety of &amp;#39;test files&amp;#39; so I can just spot a problem instantly, without having to question my eyes.&lt;/p&gt;\n\n&lt;p&gt;I need some 30 and 24hz videos which specifically do panning, that kind of thing, just a general &amp;#39;plex test&amp;#39; of content. Variety of frame rates and situations to spot if my playback is working flawlessly at resolutions / frame rates, with trancoding and so on.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyone seen anything like this that they&amp;#39;ve hoarded?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190of8d", "is_robot_indexable": true, "report_reasons": null, "author": "ChumpyCarvings", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190of8d/i_need_some_test_files_this_seems_the_most_likely/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190of8d/i_need_some_test_files_this_seems_the_most_likely/", "subreddit_subscribers": 723540, "created_utc": 1704619483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What's the point of buying the latest version of a hard drive?  What is the difference between a new 4tb hard drive that came out in 2023 and a new 4tb hard drive that came out a long time ago?  (5, 10, 12 years, no idea, just as an example)\nAre there any bigger differences in terms of safety, longevity and reliability? \nOr is it just possible that even more data can fit in and some small upgrades? \n\nWill there be revolutions in the near future (next 5-10 years) related to data storage?", "author_fullname": "t2_9odcnu9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why should I buy the latest version of hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190glwh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704592482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the point of buying the latest version of a hard drive?  What is the difference between a new 4tb hard drive that came out in 2023 and a new 4tb hard drive that came out a long time ago?  (5, 10, 12 years, no idea, just as an example)\nAre there any bigger differences in terms of safety, longevity and reliability? \nOr is it just possible that even more data can fit in and some small upgrades? &lt;/p&gt;\n\n&lt;p&gt;Will there be revolutions in the near future (next 5-10 years) related to data storage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "20TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190glwh", "is_robot_indexable": true, "report_reasons": null, "author": "ServiceOk9043", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/190glwh/why_should_i_buy_the_latest_version_of_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190glwh/why_should_i_buy_the_latest_version_of_hard_drive/", "subreddit_subscribers": 723540, "created_utc": 1704592482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, \n\nI\u2019m looking into buying my first DAS. Most of you are probably going to recommend going for a NAS, and Ideally I would like a NAS but the sort of thing I would want is out of my price range right now so my plan is to get a DAS for now then buy a NAS later down the line and use this DAS as a backup for that. (I would need a large capacity backup at some point anyway)\n\nMy question is, is it worth me buying an enclosure with 10gbps capability or will I not notice any difference in speed compared to a 5gbps enclosure, seeing as I\u2019ll be using 5400rpm drives, which max out at around 150MBps. I\u2019m planning on having 3 x 8-12tb seagate ironwolf or exos drives in a raid 5 configuration to begin, then add more drives as I need them later for a total of 6. So with the combined speed I presume the max speed I will ever get is roughly 725MBps? (5 x 150MBps, 1 x drive for parity). But realistically I won\u2019t need those extra drives for a long time so will be running off 3 or 4 drives for a while. So let\u2019s say 450MBps total with 4 drives, which the 5gbps enclosure can handle right? I had my eye on the terramaster D6-320 for the 10gbps enclosure, until i realised the transfer speeds would be restricted by the speed of the actual drives and i could get something for half the price if i go with a 5gbps enclosure. Is there anything I\u2019m missing here though?\n\nI have a 2017 iMac with thunderbolt 3 ports and I want to use this DAS to edit music and 4k video files from and also to have somewhere to put all my files in one place. My current setup is just a bunch of old external hard drives I\u2019ve collected over the years. I used to export the footage from my sd cards directly onto my Mac and edit from there, then back the files up to an external drive once I was finished, but my Mac is getting full and now I edit in 4k so I don\u2019t have the space for that anymore. Plus it\u2019s just a mess having multiple hdds, some of which have old footage on which I want to use for future edits and that means moving my files off those slow drives to do so. I haven\u2019t done much editing over the past few years but recently decided to get back into it and one of my external drives is struggling to boot so I need to pull my data off it and figured it\u2019s time to sort this mess out once and for all, rather than buying another external hdd and adding to the mess!\n\nI\u2019m also looking into what raid software is best to use with a DAS but not sure if that requires a new post? Softraid seems to be the best but it costs a fortune, then I can\u2019t see hardly any other options. I\u2019m not really keen on the look of terramaster\u2019s software, have any of you used it and what\u2019s it like? The main thing I need is the ability to clearly monitor the condition of my drives and the option to add more drives to a raid 5 when required. \n\nI think I have a good idea of what I need now but just wanted to run it past people who actually know what they\u2019re talking about before I drop a tonne of money on it. Any advise or recommendations would be appreciated. \n\nThanks", "author_fullname": "t2_5o6x09iy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "5gbps vs 10gbps DAS with 5400rpm drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1909biz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704572993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking into buying my first DAS. Most of you are probably going to recommend going for a NAS, and Ideally I would like a NAS but the sort of thing I would want is out of my price range right now so my plan is to get a DAS for now then buy a NAS later down the line and use this DAS as a backup for that. (I would need a large capacity backup at some point anyway)&lt;/p&gt;\n\n&lt;p&gt;My question is, is it worth me buying an enclosure with 10gbps capability or will I not notice any difference in speed compared to a 5gbps enclosure, seeing as I\u2019ll be using 5400rpm drives, which max out at around 150MBps. I\u2019m planning on having 3 x 8-12tb seagate ironwolf or exos drives in a raid 5 configuration to begin, then add more drives as I need them later for a total of 6. So with the combined speed I presume the max speed I will ever get is roughly 725MBps? (5 x 150MBps, 1 x drive for parity). But realistically I won\u2019t need those extra drives for a long time so will be running off 3 or 4 drives for a while. So let\u2019s say 450MBps total with 4 drives, which the 5gbps enclosure can handle right? I had my eye on the terramaster D6-320 for the 10gbps enclosure, until i realised the transfer speeds would be restricted by the speed of the actual drives and i could get something for half the price if i go with a 5gbps enclosure. Is there anything I\u2019m missing here though?&lt;/p&gt;\n\n&lt;p&gt;I have a 2017 iMac with thunderbolt 3 ports and I want to use this DAS to edit music and 4k video files from and also to have somewhere to put all my files in one place. My current setup is just a bunch of old external hard drives I\u2019ve collected over the years. I used to export the footage from my sd cards directly onto my Mac and edit from there, then back the files up to an external drive once I was finished, but my Mac is getting full and now I edit in 4k so I don\u2019t have the space for that anymore. Plus it\u2019s just a mess having multiple hdds, some of which have old footage on which I want to use for future edits and that means moving my files off those slow drives to do so. I haven\u2019t done much editing over the past few years but recently decided to get back into it and one of my external drives is struggling to boot so I need to pull my data off it and figured it\u2019s time to sort this mess out once and for all, rather than buying another external hdd and adding to the mess!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m also looking into what raid software is best to use with a DAS but not sure if that requires a new post? Softraid seems to be the best but it costs a fortune, then I can\u2019t see hardly any other options. I\u2019m not really keen on the look of terramaster\u2019s software, have any of you used it and what\u2019s it like? The main thing I need is the ability to clearly monitor the condition of my drives and the option to add more drives to a raid 5 when required. &lt;/p&gt;\n\n&lt;p&gt;I think I have a good idea of what I need now but just wanted to run it past people who actually know what they\u2019re talking about before I drop a tonne of money on it. Any advise or recommendations would be appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1909biz", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Fox8080", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1909biz/5gbps_vs_10gbps_das_with_5400rpm_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1909biz/5gbps_vs_10gbps_das_with_5400rpm_drives/", "subreddit_subscribers": 723540, "created_utc": 1704572993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My main internal drive is a 4TB WD Black. (don't laugh) I want to upgrade to 8TB, so I bought an 8TB Seagate Barracuda from B&amp;H. I installed it into a Sabrent drive dock I've had a few years, but IS rated for 8TB. Formatted as Z, copied a couple TB from the internal drive, and about 600MB from an external drive of my wife's. The plan was to leave it in action for some weeks before swapping into the PC, to make sure it was working OK.\n\nStarted getting errors from Windows (W10) that the drive needed scanned and repaired. It would repeatedly hang about 30% through the scan, and the drive would disappear. Downloaded **Seatools**, the 2 minute self test would fail. But I did see some folders of data that I had copied. I have **HD Sentinel**, ran the short self-test and the conveyance self test (whatever that is) successfully with that. Disk surface test showed no bad or damaged sectors, but I was also left with 1000 \"found.nnn\" folders.\n\nQuestions: Could this be a problem with the dock or it's USB cable? I've already bought a new one with it's own USB 3.2 cable (which my PC supports). Is it worth installing it in the new dock, reformatting, and starting over? You can view screenshots of the [various test results at Imgur](https://imgur.com/a/4A7HZSP). Or should I RMA this drive? Thanks.", "author_fullname": "t2_fwy7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I trust this drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1907hg5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1704568307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My main internal drive is a 4TB WD Black. (don&amp;#39;t laugh) I want to upgrade to 8TB, so I bought an 8TB Seagate Barracuda from B&amp;amp;H. I installed it into a Sabrent drive dock I&amp;#39;ve had a few years, but IS rated for 8TB. Formatted as Z, copied a couple TB from the internal drive, and about 600MB from an external drive of my wife&amp;#39;s. The plan was to leave it in action for some weeks before swapping into the PC, to make sure it was working OK.&lt;/p&gt;\n\n&lt;p&gt;Started getting errors from Windows (W10) that the drive needed scanned and repaired. It would repeatedly hang about 30% through the scan, and the drive would disappear. Downloaded &lt;strong&gt;Seatools&lt;/strong&gt;, the 2 minute self test would fail. But I did see some folders of data that I had copied. I have &lt;strong&gt;HD Sentinel&lt;/strong&gt;, ran the short self-test and the conveyance self test (whatever that is) successfully with that. Disk surface test showed no bad or damaged sectors, but I was also left with 1000 &amp;quot;found.nnn&amp;quot; folders.&lt;/p&gt;\n\n&lt;p&gt;Questions: Could this be a problem with the dock or it&amp;#39;s USB cable? I&amp;#39;ve already bought a new one with it&amp;#39;s own USB 3.2 cable (which my PC supports). Is it worth installing it in the new dock, reformatting, and starting over? You can view screenshots of the &lt;a href=\"https://imgur.com/a/4A7HZSP\"&gt;various test results at Imgur&lt;/a&gt;. Or should I RMA this drive? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aBdOe6upL_qzL8ZjcG7kXs1CRC_FD97QElI73GoKldQ.jpg?auto=webp&amp;s=bab6394dd8a233277e287d0b8817296aa6fac59c", "width": 566, "height": 573}, "resolutions": [{"url": "https://external-preview.redd.it/aBdOe6upL_qzL8ZjcG7kXs1CRC_FD97QElI73GoKldQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=28c234971dc8891add6528a783cf3c370b38e4d5", "width": 108, "height": 109}, {"url": "https://external-preview.redd.it/aBdOe6upL_qzL8ZjcG7kXs1CRC_FD97QElI73GoKldQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e46399bdd3ab8a4224db150e857404ec6a2e542", "width": 216, "height": 218}, {"url": "https://external-preview.redd.it/aBdOe6upL_qzL8ZjcG7kXs1CRC_FD97QElI73GoKldQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b5203b7783399d90b405f626f125f89f14af7b4", "width": 320, "height": 323}], "variants": {}, "id": "7HP71TV1dsuSeRkrcBo3iGMG7MffI_6vRYgs4-z3LgU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1907hg5", "is_robot_indexable": true, "report_reasons": null, "author": "evildad53", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1907hg5/can_i_trust_this_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1907hg5/can_i_trust_this_drive/", "subreddit_subscribers": 723540, "created_utc": 1704568307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have searched around and so far nothing I find actually works. I have a video set I've paid for that I log in on their website and there is an embedded Vimeo playlist of the videos I want to download. I use the inspector in my web browser and look at the network tab while playing the video and just see a bunch of segment-number.m4s links. I try to copy that address into YTDL but it never works. What am I doing wrong?", "author_fullname": "t2_qbrku9p6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download Embedded Vimeo Playlist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1904xed", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704561810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have searched around and so far nothing I find actually works. I have a video set I&amp;#39;ve paid for that I log in on their website and there is an embedded Vimeo playlist of the videos I want to download. I use the inspector in my web browser and look at the network tab while playing the video and just see a bunch of segment-number.m4s links. I try to copy that address into YTDL but it never works. What am I doing wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1904xed", "is_robot_indexable": true, "report_reasons": null, "author": "Tumnus1337", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1904xed/download_embedded_vimeo_playlist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1904xed/download_embedded_vimeo_playlist/", "subreddit_subscribers": 723540, "created_utc": 1704561810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to figure out my options here for a basic and budget 4 bay NAS setup. At present I have an old WD 2 bay NAS with two 6TB drives in a Raid0 (I know, I know) that is running out of space and am looking to replace. Separately, I have a Lenovo M93P Tiny that is running Ubuntu as a headless server doing the usual home server stuff that is barely stressed the majority of the time.\n\nWas originally thinking of just getting a 4 bay DAS, throw in 4 8tb drives in a Raid5, and attach it via USB3.0. Problem one, any recommendations on a DAS? problem two, any recommendations on software that would run on Ubuntu to manage it?\n\nWould it be easier to just get a RaspberryPi and run TrueNAS on it?", "author_fullname": "t2_48p5okg0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best homebrew NAS setup using DAS? Already have mini pc (no drive bays) running Ubuntu.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190jwgn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704602658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to figure out my options here for a basic and budget 4 bay NAS setup. At present I have an old WD 2 bay NAS with two 6TB drives in a Raid0 (I know, I know) that is running out of space and am looking to replace. Separately, I have a Lenovo M93P Tiny that is running Ubuntu as a headless server doing the usual home server stuff that is barely stressed the majority of the time.&lt;/p&gt;\n\n&lt;p&gt;Was originally thinking of just getting a 4 bay DAS, throw in 4 8tb drives in a Raid5, and attach it via USB3.0. Problem one, any recommendations on a DAS? problem two, any recommendations on software that would run on Ubuntu to manage it?&lt;/p&gt;\n\n&lt;p&gt;Would it be easier to just get a RaspberryPi and run TrueNAS on it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190jwgn", "is_robot_indexable": true, "report_reasons": null, "author": "GiggityYay", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190jwgn/best_homebrew_nas_setup_using_das_already_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190jwgn/best_homebrew_nas_setup_using_das_already_have/", "subreddit_subscribers": 723540, "created_utc": 1704602658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, i have many years of my family's videos on both of these. What would be the best way to convert each of these to digital? I will buy whatever products are required to get good output. Thank you.", "author_fullname": "t2_2v5p7f69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to convert VHS and DV to Digital, help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_190gjpe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Co2WmKcgN6jf_BMH1Y8_4PsZ6XmJu1rn1JnJA6p5yHM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1704592292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i have many years of my family&amp;#39;s videos on both of these. What would be the best way to convert each of these to digital? I will buy whatever products are required to get good output. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/2sxwexs1cxac1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/2sxwexs1cxac1.png?auto=webp&amp;s=965cd6df8131754112cbb10a55cafbe056bda637", "width": 1080, "height": 810}, "resolutions": [{"url": "https://preview.redd.it/2sxwexs1cxac1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=29b93b89ad64ab8c7c2b7d06b7289e61d5cea612", "width": 108, "height": 81}, {"url": "https://preview.redd.it/2sxwexs1cxac1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=262e257432da8a00d582e2d937d820c94cb63dcd", "width": 216, "height": 162}, {"url": "https://preview.redd.it/2sxwexs1cxac1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1a7711c7becb3f692d5814fd7451646742b28bc1", "width": 320, "height": 240}, {"url": "https://preview.redd.it/2sxwexs1cxac1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0379f297d720fd76ad630f06af017cdbaa109d4e", "width": 640, "height": 480}, {"url": "https://preview.redd.it/2sxwexs1cxac1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fbb5b14972f730890c0d843b6ef30bd2a34645b2", "width": 960, "height": 720}, {"url": "https://preview.redd.it/2sxwexs1cxac1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=82e88f9a9ffe83e389308263ea5989f00cd293f2", "width": 1080, "height": 810}], "variants": {}, "id": "a7JXjFFfk1yUsU-bn34R0dOfkSWpip6dzlw-xuIUD9c"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190gjpe", "is_robot_indexable": true, "report_reasons": null, "author": "Xcedia", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190gjpe/need_to_convert_vhs_and_dv_to_digital_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/2sxwexs1cxac1.png", "subreddit_subscribers": 723540, "created_utc": 1704592292.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible to have rsync check the content of a file before synch? Like a go ahead to ensure that the directory is not encrypted by ransomware", "author_fullname": "t2_hrtc9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ransomware verification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190dlnm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704584043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to have rsync check the content of a file before synch? Like a go ahead to ensure that the directory is not encrypted by ransomware&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190dlnm", "is_robot_indexable": true, "report_reasons": null, "author": "py2gb", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190dlnm/ransomware_verification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190dlnm/ransomware_verification/", "subreddit_subscribers": 723540, "created_utc": 1704584043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am using MAkeMKV program. Here is the plan I have decided to do:\n\n(1) When it comes to fitness DVDs I plan to make them a iso and keep all the menus and such and just store the iso on my \"Anime\" External Hard Drive for now until I can get a second External Hard Drive this month or next. \n\n(2) Movies I plan to keep the main movie and Trailer for the main movie and the Subtitles for \"English\" just in case I do need the subtitles after all. But I can always turn them off or on. With the VLC Media Player that I use. \n\n(3) TV Shows I will be just keeping the \"Episodes\" so I plan to use makemkv to turn them into mkv files and then just keep them as is maybe it all depends on the screen size and such. I guess I could always fix the black square background with the screen size on VLC media player. \n\n&amp;#x200B;\n\nBut for now this is the easiest way I have found to keep the \"Fitness/Exercise\" videos without getting there names messed up and this way I can still customize the workouts. \n\n&amp;#x200B;\n\nBut the only issue I have is where I read that VLC will not play iso. The thing is I just played around with the iso and opened it in VLC fine without issue. I even took the iso and placed it inside a folder I just made on my secondary external hard drive I call \"Anime\" since the \"Anime\" hard drive has over 367GB left before full. I do have a bunch of random stuff on there for \"Anime\" I do still plan to delete since its gone from \"Subtitled\" only to \"Dubbed\" now for some of the \"Anime\". \n\n&amp;#x200B;\n\nSo I plan to go through the hard drive and remove some random stuff later. But for now I plan to \"Backup\" all the \"Fitness/Exercise\" DVDs to my windows 10 laptop 1 at a time and then move to the iso folder on the hard drive and then remove them from the computer once there moved to the hard drive. Then once I get my new hard drive I will move all the \"Fitness/Exercise\" to the new hard drive and keep them all as iso. But I will make a new folder for each DVD and rename each folder the title of the DVD and the year released. I know plex and such programs wont play iso. But that is fine I will use iso for only the fitness/exercise DVDs and then the Movies and TV Shows I will use with Kodi once I have all the DVDs copied. \n\n&amp;#x200B;\n\nSo for now that is the plan. \n\n&amp;#x200B;\n\nThis way I can still use my fitness DVDs on my PC while the PC is connect to my older 32\" TV and then play my fitness videos on there with customization and so on. But movies and TV Shows will be put on a different hard drive called \"Movies &amp; TV Shows\" and those will be used on Kodi for the same PC. \n\n&amp;#x200B;\n\nIf this sound like it might not work please comment below where I am going wrong. Thank You! ", "author_fullname": "t2_8gvbu38t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change of plan for fitness DVD vs Main Movie DVDs and TV Show DVDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1907m3t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704568634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using MAkeMKV program. Here is the plan I have decided to do:&lt;/p&gt;\n\n&lt;p&gt;(1) When it comes to fitness DVDs I plan to make them a iso and keep all the menus and such and just store the iso on my &amp;quot;Anime&amp;quot; External Hard Drive for now until I can get a second External Hard Drive this month or next. &lt;/p&gt;\n\n&lt;p&gt;(2) Movies I plan to keep the main movie and Trailer for the main movie and the Subtitles for &amp;quot;English&amp;quot; just in case I do need the subtitles after all. But I can always turn them off or on. With the VLC Media Player that I use. &lt;/p&gt;\n\n&lt;p&gt;(3) TV Shows I will be just keeping the &amp;quot;Episodes&amp;quot; so I plan to use makemkv to turn them into mkv files and then just keep them as is maybe it all depends on the screen size and such. I guess I could always fix the black square background with the screen size on VLC media player. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But for now this is the easiest way I have found to keep the &amp;quot;Fitness/Exercise&amp;quot; videos without getting there names messed up and this way I can still customize the workouts. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But the only issue I have is where I read that VLC will not play iso. The thing is I just played around with the iso and opened it in VLC fine without issue. I even took the iso and placed it inside a folder I just made on my secondary external hard drive I call &amp;quot;Anime&amp;quot; since the &amp;quot;Anime&amp;quot; hard drive has over 367GB left before full. I do have a bunch of random stuff on there for &amp;quot;Anime&amp;quot; I do still plan to delete since its gone from &amp;quot;Subtitled&amp;quot; only to &amp;quot;Dubbed&amp;quot; now for some of the &amp;quot;Anime&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I plan to go through the hard drive and remove some random stuff later. But for now I plan to &amp;quot;Backup&amp;quot; all the &amp;quot;Fitness/Exercise&amp;quot; DVDs to my windows 10 laptop 1 at a time and then move to the iso folder on the hard drive and then remove them from the computer once there moved to the hard drive. Then once I get my new hard drive I will move all the &amp;quot;Fitness/Exercise&amp;quot; to the new hard drive and keep them all as iso. But I will make a new folder for each DVD and rename each folder the title of the DVD and the year released. I know plex and such programs wont play iso. But that is fine I will use iso for only the fitness/exercise DVDs and then the Movies and TV Shows I will use with Kodi once I have all the DVDs copied. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So for now that is the plan. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This way I can still use my fitness DVDs on my PC while the PC is connect to my older 32&amp;quot; TV and then play my fitness videos on there with customization and so on. But movies and TV Shows will be put on a different hard drive called &amp;quot;Movies &amp;amp; TV Shows&amp;quot; and those will be used on Kodi for the same PC. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If this sound like it might not work please comment below where I am going wrong. Thank You! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1907m3t", "is_robot_indexable": true, "report_reasons": null, "author": "DawnRenee1988", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1907m3t/change_of_plan_for_fitness_dvd_vs_main_movie_dvds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1907m3t/change_of_plan_for_fitness_dvd_vs_main_movie_dvds/", "subreddit_subscribers": 723540, "created_utc": 1704568634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On the PC that will perform the operation, the encrypted HDD is unlocked.", "author_fullname": "t2_b65ub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi! Will converting an external HDD from MBR to GPT make it lose BitLocker encryption? Thank you", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1904v17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704561643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On the PC that will perform the operation, the encrypted HDD is unlocked.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1904v17", "is_robot_indexable": true, "report_reasons": null, "author": "Salberyon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1904v17/hi_will_converting_an_external_hdd_from_mbr_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1904v17/hi_will_converting_an_external_hdd_from_mbr_to/", "subreddit_subscribers": 723540, "created_utc": 1704561643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Thinking about archiving all my music cds into FLAC(uncompressed), DVDs and Blu-Rays into iso files. Also ripping said movies into H265 mp4 files to stream. What are the thoughts on sheer size?\n500-ish CDs\n1000 movie and TV shows on DVD and Blu-Ray.", "author_fullname": "t2_11bc9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving DVDs and Blu-Ray movies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1902v05", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704556306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thinking about archiving all my music cds into FLAC(uncompressed), DVDs and Blu-Rays into iso files. Also ripping said movies into H265 mp4 files to stream. What are the thoughts on sheer size?\n500-ish CDs\n1000 movie and TV shows on DVD and Blu-Ray.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1902v05", "is_robot_indexable": true, "report_reasons": null, "author": "Lmiller0810", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1902v05/archiving_dvds_and_bluray_movies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1902v05/archiving_dvds_and_bluray_movies/", "subreddit_subscribers": 723540, "created_utc": 1704556306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Please help!! I\u2019ve got a WD My Passport 4tb which is not mounting on my  MacBook Pro 13 (mid 2014) running on Big Sur 11.7.10. When I plug it in, it shows on the disk utility, but fails to mount (disk management dis enter error 0). I\u2019ve run the first aid, first section says no problems, second says File Ststem verify or repair failed (-64895). I am at a loss on how to force mount this thing.\n\n I will say, the passport is full, and if I can mount the drive I can then delete some files, but I have files on this drive I need for a project. I\u2019ve been trying to mount this for a week, and I need to get this project finished. Any advice?", "author_fullname": "t2_3jlwq21j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD My Passport not mounting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_190tlgw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704638600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please help!! I\u2019ve got a WD My Passport 4tb which is not mounting on my  MacBook Pro 13 (mid 2014) running on Big Sur 11.7.10. When I plug it in, it shows on the disk utility, but fails to mount (disk management dis enter error 0). I\u2019ve run the first aid, first section says no problems, second says File Ststem verify or repair failed (-64895). I am at a loss on how to force mount this thing.&lt;/p&gt;\n\n&lt;p&gt;I will say, the passport is full, and if I can mount the drive I can then delete some files, but I have files on this drive I need for a project. I\u2019ve been trying to mount this for a week, and I need to get this project finished. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190tlgw", "is_robot_indexable": true, "report_reasons": null, "author": "templetondean", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190tlgw/wd_my_passport_not_mounting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190tlgw/wd_my_passport_not_mounting/", "subreddit_subscribers": 723540, "created_utc": 1704638600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nI have been using OpenMediaVault on my setup for some time now, started with an oDroid XU4, now ended up using my old desktop.\n\n\nI noticed a strange issue that I initially blamed it on a few power outages. I am using the latest available OMV 6 with the latest Proxmox kernel 6.2.16-11-bpo11-pve. The HDD in question is new, it was purchased last year with another one. I know that the issues shown in dmesg should mean that the HDD turned bad and today I booted into GParted Live and Seatools Bootable to check all HDDs. None of the tools are showing any errors with the HDD in question, I let it run the Short Generic Test. SMART information is clean and I cannot see any dmesg errors in GParted Live, Seatools Bootable or Ubuntu 22.04 Live. I even tried changing the SATA port. I don't know when the issue appeared, but I noticed sometime at the end of last year that my snapraid sync and scrub jobs were hung for a long time and that the snapraid.content on the affected drive is different than the ones on the other content drives.\n\nCould this be related to the installation or the kernel? I have not tried booting into the mainline OMV kernel or any other older kernels. I also realized I didn't change the SATA cable with a new one to rule out a bad cable. What puzzles me the most is that booting into anything else but OMV shows no error on the affected drive. One strange behavior of the affected drive is that it appeared as not mounted at some point - mountpoint was completely empty. All data on it was visible after a reboot - that scared me the most and then I started doing some basic checks that led me to running Seatools Bootable and checking it in a Live CD environment. I can read and write on it now without any issues. I fear that if I were to send it for warranty I would just get it back as functional.\n\nLogs are available HERE.\n\nI booted with the non Proxmox kernel 6.1.0-0.deb11.13-amd64 and I cannot see any issue with any disks. I ran snapraid and I also copied a large file to the affected disk for testing. I need to be able to use OpenCL, that is why I want to use Proxmox kernel.", "author_fullname": "t2_gdcr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strange issue with new HDD and OpenMediaVault", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190pgvk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1704623929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "logpaste.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using OpenMediaVault on my setup for some time now, started with an oDroid XU4, now ended up using my old desktop.&lt;/p&gt;\n\n&lt;p&gt;I noticed a strange issue that I initially blamed it on a few power outages. I am using the latest available OMV 6 with the latest Proxmox kernel 6.2.16-11-bpo11-pve. The HDD in question is new, it was purchased last year with another one. I know that the issues shown in dmesg should mean that the HDD turned bad and today I booted into GParted Live and Seatools Bootable to check all HDDs. None of the tools are showing any errors with the HDD in question, I let it run the Short Generic Test. SMART information is clean and I cannot see any dmesg errors in GParted Live, Seatools Bootable or Ubuntu 22.04 Live. I even tried changing the SATA port. I don&amp;#39;t know when the issue appeared, but I noticed sometime at the end of last year that my snapraid sync and scrub jobs were hung for a long time and that the snapraid.content on the affected drive is different than the ones on the other content drives.&lt;/p&gt;\n\n&lt;p&gt;Could this be related to the installation or the kernel? I have not tried booting into the mainline OMV kernel or any other older kernels. I also realized I didn&amp;#39;t change the SATA cable with a new one to rule out a bad cable. What puzzles me the most is that booting into anything else but OMV shows no error on the affected drive. One strange behavior of the affected drive is that it appeared as not mounted at some point - mountpoint was completely empty. All data on it was visible after a reboot - that scared me the most and then I started doing some basic checks that led me to running Seatools Bootable and checking it in a Live CD environment. I can read and write on it now without any issues. I fear that if I were to send it for warranty I would just get it back as functional.&lt;/p&gt;\n\n&lt;p&gt;Logs are available HERE.&lt;/p&gt;\n\n&lt;p&gt;I booted with the non Proxmox kernel 6.1.0-0.deb11.13-amd64 and I cannot see any issue with any disks. I ran snapraid and I also copied a large file to the affected disk for testing. I need to be able to use OpenCL, that is why I want to use Proxmox kernel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://logpaste.com/7o5YYWO5", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB OMV NAS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190pgvk", "is_robot_indexable": true, "report_reasons": null, "author": "tmihai20", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/190pgvk/strange_issue_with_new_hdd_and_openmediavault/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://logpaste.com/7o5YYWO5", "subreddit_subscribers": 723540, "created_utc": 1704623929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible to migrate a local backup from one application to another (in this case from Perfect-Backup to VEAM?) I'm hoping I can somehow make a new job with VEAM agent without having to re-copy all of my files again. Is there a way to do this? I'm just doing a standard backup to an external drive. Thanks for your help!", "author_fullname": "t2_jmi91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to migrate a local backup from one application to another (in this case from Perfect-Backup to VEAM?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190p7qz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704622837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to migrate a local backup from one application to another (in this case from Perfect-Backup to VEAM?) I&amp;#39;m hoping I can somehow make a new job with VEAM agent without having to re-copy all of my files again. Is there a way to do this? I&amp;#39;m just doing a standard backup to an external drive. Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190p7qz", "is_robot_indexable": true, "report_reasons": null, "author": "owenbenson", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190p7qz/is_it_possible_to_migrate_a_local_backup_from_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190p7qz/is_it_possible_to_migrate_a_local_backup_from_one/", "subreddit_subscribers": 723540, "created_utc": 1704622837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "edit: i think it would be much easier to just use raid for the main drives. so that's what i'll do\n\n&amp;#x200B;\n\n~~I asked if RAID was necessary for me here earlier and most people were saying that unless you care about downtime (I don't) then as long as you have a backup you're fine.~~\n\n~~But someone raised a good point saying that whatever you had put on your NAS between the last backup sync and the point where your HDD failed would be completely lost without RAID. Is there a way to prevent this? Maybe something where you have two SSDs in RAID (which I'm already considering getting to put regular software on) and then having files stay there until they're ready to be synced?~~", "author_fullname": "t2_mqskseq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to prevent recently downloaded data loss without using RAID?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_19077rq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1704596545.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704567635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;edit: i think it would be much easier to just use raid for the main drives. so that&amp;#39;s what i&amp;#39;ll do&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;del&gt;I asked if RAID was necessary for me here earlier and most people were saying that unless you care about downtime (I don&amp;#39;t) then as long as you have a backup you&amp;#39;re fine.&lt;/del&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;del&gt;But someone raised a good point saying that whatever you had put on your NAS between the last backup sync and the point where your HDD failed would be completely lost without RAID. Is there a way to prevent this? Maybe something where you have two SSDs in RAID (which I&amp;#39;m already considering getting to put regular software on) and then having files stay there until they&amp;#39;re ready to be synced?&lt;/del&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "19077rq", "is_robot_indexable": true, "report_reasons": null, "author": "OneSteelTank", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/19077rq/is_there_a_way_to_prevent_recently_downloaded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/19077rq/is_there_a_way_to_prevent_recently_downloaded/", "subreddit_subscribers": 723540, "created_utc": 1704567635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "(This is bootleg-crossposted from [this post](https://www.reddit.com/r/datarecovery/comments/190oajn/do_any_disk_copying_programs_for_windows_10_allow/) I made to r/datarecovery, moved here as I thought this community may be a better fit, in turn partially continued off of [this post](https://www.reddit.com/r/datarecovery/comments/18xtmi8/what_software_for_windows_10_supporting/) I made on January 3^(rd).)\n\nSo, for context, I had wanted to make a backup image of the drives of three of my (or associated) devices:\n\n1. My laptop, as mentioned in the previous post. Specifically, a sector-by-sector image. (\\~475 GiB, \\~30 GiB free)\n2. A brother of mine's laptop (the one I'm using at this moment), largely as he's sending it into repair and they make no promises on data integrity. He prefers a sector-by-sector copy, too. (\\~475 GiB, \\~40 GiB free)\n3. An external hard drive that, while internally fine, has a *really* unreliable connection and is probably best to transition away from. (That, in fact, was the external drive I was referring to transferring my laptop's disk image to, which I talked myself out of.) *And for consistency's sake...* (2 TB; \\~1.81 TiB, \\~1 TiB free)\n\nThe big problem is, *I only have a 2 TB SSD to back those up to* (I, uhh, don't have much resources and was given it rather than having purchased it myself), and while that would be sufficient conventionally, AFAIK it's not sufficient if I want a sector-by-sector copy, which would be identically sized to the full space of the drive.\n\nSo, is there any way (with a program on Windows 10) to reduce the size of these while still containing *all information* on the drive? I'd assume something as simple as run-length compression could suffice. It would effectively have to be done dynamically, as otherwise the external hard drive will have to be entirely filled to transfer Image #3 uncompressed first, and the time constraints of tasks #1 and #2 massively advise against that.", "author_fullname": "t2_12oi4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do any disk copying programs (for Windows 10) allow the (dynamic) compression of a sector-by-sector disk image/copy as it is being saved? If so, which ones?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_190ooqr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1704620562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(This is bootleg-crossposted from &lt;a href=\"https://www.reddit.com/r/datarecovery/comments/190oajn/do_any_disk_copying_programs_for_windows_10_allow/\"&gt;this post&lt;/a&gt; I made to &lt;a href=\"/r/datarecovery\"&gt;r/datarecovery&lt;/a&gt;, moved here as I thought this community may be a better fit, in turn partially continued off of &lt;a href=\"https://www.reddit.com/r/datarecovery/comments/18xtmi8/what_software_for_windows_10_supporting/\"&gt;this post&lt;/a&gt; I made on January 3&lt;sup&gt;rd&lt;/sup&gt;.)&lt;/p&gt;\n\n&lt;p&gt;So, for context, I had wanted to make a backup image of the drives of three of my (or associated) devices:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My laptop, as mentioned in the previous post. Specifically, a sector-by-sector image. (~475 GiB, ~30 GiB free)&lt;/li&gt;\n&lt;li&gt;A brother of mine&amp;#39;s laptop (the one I&amp;#39;m using at this moment), largely as he&amp;#39;s sending it into repair and they make no promises on data integrity. He prefers a sector-by-sector copy, too. (~475 GiB, ~40 GiB free)&lt;/li&gt;\n&lt;li&gt;An external hard drive that, while internally fine, has a &lt;em&gt;really&lt;/em&gt; unreliable connection and is probably best to transition away from. (That, in fact, was the external drive I was referring to transferring my laptop&amp;#39;s disk image to, which I talked myself out of.) &lt;em&gt;And for consistency&amp;#39;s sake...&lt;/em&gt; (2 TB; ~1.81 TiB, ~1 TiB free)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The big problem is, &lt;em&gt;I only have a 2 TB SSD to back those up to&lt;/em&gt; (I, uhh, don&amp;#39;t have much resources and was given it rather than having purchased it myself), and while that would be sufficient conventionally, AFAIK it&amp;#39;s not sufficient if I want a sector-by-sector copy, which would be identically sized to the full space of the drive.&lt;/p&gt;\n\n&lt;p&gt;So, is there any way (with a program on Windows 10) to reduce the size of these while still containing &lt;em&gt;all information&lt;/em&gt; on the drive? I&amp;#39;d assume something as simple as run-length compression could suffice. It would effectively have to be done dynamically, as otherwise the external hard drive will have to be entirely filled to transfer Image #3 uncompressed first, and the time constraints of tasks #1 and #2 massively advise against that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "190ooqr", "is_robot_indexable": true, "report_reasons": null, "author": "GrantExploit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/190ooqr/do_any_disk_copying_programs_for_windows_10_allow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/190ooqr/do_any_disk_copying_programs_for_windows_10_allow/", "subreddit_subscribers": 723540, "created_utc": 1704620562.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}