{"kind": "Listing", "data": {"after": "t3_1bjq03j", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This comes up a lot in random posts. Snowflake is a data warehouse. BigQuery is a data warehouse. PostgreSQL, MySQL, and SQL Server are not. We have let companies like Snowflake, Oracle, etc. redefine data warehouse from it's data-centric meaning, to a platform-centric one. \n\nA data warehouse is a collection of disparate sources modeled to provide efficient querying. Just about any DB system can be part a data warehouse solution, but the platform itself is not the data warehouse. Snowflake is a great solution for larger use cases where it saves significant engineering resources. For some tiny DW with rows in the low millions, it is probably going to be very expensive compared to other platforms. \n\nI know this sounds pedantic, but as data engineers, we should be precise with our terms. Doing anything else leads to confusion and misunderstandings. In the end, we should perform analysis and choose the best tool for the job. It very well might be one of the advertised \"data warehouses\". It may be Postgres. It may be something else. It's our job to find the right solution with hard data, not marketing hype.", "author_fullname": "t2_8ov8i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can We Stop Using Marketing Terms to Define Data Warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjcybi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 134, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 134, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710939902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This comes up a lot in random posts. Snowflake is a data warehouse. BigQuery is a data warehouse. PostgreSQL, MySQL, and SQL Server are not. We have let companies like Snowflake, Oracle, etc. redefine data warehouse from it&amp;#39;s data-centric meaning, to a platform-centric one. &lt;/p&gt;\n\n&lt;p&gt;A data warehouse is a collection of disparate sources modeled to provide efficient querying. Just about any DB system can be part a data warehouse solution, but the platform itself is not the data warehouse. Snowflake is a great solution for larger use cases where it saves significant engineering resources. For some tiny DW with rows in the low millions, it is probably going to be very expensive compared to other platforms. &lt;/p&gt;\n\n&lt;p&gt;I know this sounds pedantic, but as data engineers, we should be precise with our terms. Doing anything else leads to confusion and misunderstandings. In the end, we should perform analysis and choose the best tool for the job. It very well might be one of the advertised &amp;quot;data warehouses&amp;quot;. It may be Postgres. It may be something else. It&amp;#39;s our job to find the right solution with hard data, not marketing hype.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjcybi", "is_robot_indexable": true, "report_reasons": null, "author": "leogodin217", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjcybi/can_we_stop_using_marketing_terms_to_define_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjcybi/can_we_stop_using_marketing_terms_to_define_data/", "subreddit_subscribers": 170537, "created_utc": 1710939902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have recently started working as a data analyst in a start-up company. We have a web-based application. Currently, we have only Google Analytics and Zoho CRM connected to our website. We are planning to add more connections to our website and we are going to need a data warehouse (I suppose). So, our data is very small due to our business model. We are never going to have hundreds of users. 1 month's worth of Zoho CRM data is around 100k rows. I think using bigquery or snowflake is an overkill for us. What should I do?", "author_fullname": "t2_7y78l90c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am planning to use Postgre as a data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjbdv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710934829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have recently started working as a data analyst in a start-up company. We have a web-based application. Currently, we have only Google Analytics and Zoho CRM connected to our website. We are planning to add more connections to our website and we are going to need a data warehouse (I suppose). So, our data is very small due to our business model. We are never going to have hundreds of users. 1 month&amp;#39;s worth of Zoho CRM data is around 100k rows. I think using bigquery or snowflake is an overkill for us. What should I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bjbdv3", "is_robot_indexable": true, "report_reasons": null, "author": "Dodomeki16", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjbdv3/i_am_planning_to_use_postgre_as_a_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjbdv3/i_am_planning_to_use_postgre_as_a_data_warehouse/", "subreddit_subscribers": 170537, "created_utc": 1710934829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context : \n\n* Completed my bachelors in CSE (November 2023)\n* No prior experience with cloud computing and Azure\n* Did not write DP-900 or AZ-900 or any other certification exam before this one\n\nMost of the people on this subreddit have cleared this exam with some prior experience on cloud computing,I was unemployed(LOL ,I still am but I will start working from April onwards) and couldn't get placed from my college,so one of my uncle told that they  had a vacancy for a 'Azure Data Engineer Associate' and so I decided to **clear DP - 203 and ended up scoring 900/1000** \n\n**I feel this post will help people like me who have no prior experience with Azure or Cloud or SQL**\n\nI found the exam to be moderately difficult started studying on approximately 17th January and gave my exam on 17th March (If you study daily for around 2-3 hours daily,**consistently** it might take you around 40 - 45 days)\n\nFirst things first : You must have some theoretical and practical on SQL because the exam will test your knowledge on Transact-SQL (if you understand SQL it will not take time) \n\nSo I researched and many people suggested that I start preparing from Alan Rodrigues's course (Bought it for just 449 INR) [https://www.udemy.com/share/104Rwq3@bLDvpnwu7U80WdvU1d3esdKYQotX82fguZgUCnKLTqK1bcWrGF8DyKzLxo1R9tFBWQ==/](https://www.udemy.com/share/104Rwq3@bLDvpnwu7U80WdvU1d3esdKYQotX82fguZgUCnKLTqK1bcWrGF8DyKzLxo1R9tFBWQ==/) , **initially found the course overwhelming** (because I did not study for DP - 900) so I spent a lot of time on ChatGPT understanding the basics like *Batch Processing,ETL,ELT,Stream and Reference Data,Telemetry Data,Power BI,Polybase,HADOOP,Apache Spark,Azure Data Lake Storage,Parquet,JSON etc.* (while preparing for this exam I took a look at DP - 900's syllabus and found a youtuber that explained the basics clearly,**according to me you don't have to clear DP-900 to clear this exam but atleast understand the basics**,watched some videos from his playlist on 1.5X [https://www.youtube.com/playlist?list=PLhLKc18P9YODENOj4F2nHbNXeYwY1zYGb](https://www.youtube.com/playlist?list=PLhLKc18P9YODENOj4F2nHbNXeYwY1zYGb) ) \n\nSo after I completed Alan's course,took a practice test and ended up scoring around 20% (I would still recommend his course to understand *T-SQL queries,Synpase,DataFactory,Databricks,Pipelines,Data Flows,Azure Monitor etc.*)the overall explanation was good **but the mistake I made was** : focused too much on how to execute the services and getting hands on experience with the platform rather than getting an overall understanding of the concepts,but a little bit hands on experience will be helpful. \n\nSo I started to understand  the paper pattern and the type of questions that frequently come on the exam,around 60 - 70 % of the questions came from this playlist [https://www.youtube.com/watch?v=mbo43UgIkYc&amp;list=PL0AYtrUw-NRQu89sbJNXPEo0dkBVTujY5&amp;index=3](https://www.youtube.com/watch?v=mbo43UgIkYc&amp;list=PL0AYtrUw-NRQu89sbJNXPEo0dkBVTujY5&amp;index=3) \n\nI would also recommend this youtuber as he explains all the questions clearly [https://www.youtube.com/@studyingasyouwere/playlists](https://www.youtube.com/@studyingasyouwere/playlists) \n\nI would also recommend these 2 channels to revise your preparation \n\n[https://www.youtube.com/watch?v=RTlZZMDA7qw&amp;list=PLG3ClUcNEYt5Fmrx1hnhquUpLStdItu-y](https://www.youtube.com/watch?v=RTlZZMDA7qw&amp;list=PLG3ClUcNEYt5Fmrx1hnhquUpLStdItu-y) \n\n[https://www.youtube.com/watch?v=6deS7pKBEGM](https://www.youtube.com/watch?v=6deS7pKBEGM) \n\nAnd towards the end I bought a course that had 6 question papers for 449 INR,but some answers were wrong so just google the question or read about the question on Microsoft Documentation\n\n[https://www.udemy.com/share/109Ko43@oymPlhQbt8fnnMSk\\_8khpWLUGJ8D7mSrFUvTFPMwj7rOI8n9gYK3xBO434pV4z3dWg==/](https://www.udemy.com/share/109Ko43@oymPlhQbt8fnnMSk_8khpWLUGJ8D7mSrFUvTFPMwj7rOI8n9gYK3xBO434pV4z3dWg==/) \n\n**A tip I would recommend**,if you don't understand any topic refer to Microsoft Documentation and still if you don't understand use ChatGPT\n\n**And finally my exam experience** : Had a total of 43 questions (I thought the total number of questions were 65,I guess it changed recently) , had to answer a Case Study intially,then had Multiple choice single answer,Multiple choice Multiple answer,Drop down menus , **not a single question consisted of rearranging the sequence ,** total exam time : 140 minutes,completed mine in around 100 minutes \n\nI hope someone on this subreddit finds this information valuable,study well and all the best", "author_fullname": "t2_29svvuid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Passed DP-203 on 17th March 2024,without any prior cloud experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjb4f1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710940020.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710933858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Completed my bachelors in CSE (November 2023)&lt;/li&gt;\n&lt;li&gt;No prior experience with cloud computing and Azure&lt;/li&gt;\n&lt;li&gt;Did not write DP-900 or AZ-900 or any other certification exam before this one&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Most of the people on this subreddit have cleared this exam with some prior experience on cloud computing,I was unemployed(LOL ,I still am but I will start working from April onwards) and couldn&amp;#39;t get placed from my college,so one of my uncle told that they  had a vacancy for a &amp;#39;Azure Data Engineer Associate&amp;#39; and so I decided to &lt;strong&gt;clear DP - 203 and ended up scoring 900/1000&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I feel this post will help people like me who have no prior experience with Azure or Cloud or SQL&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I found the exam to be moderately difficult started studying on approximately 17th January and gave my exam on 17th March (If you study daily for around 2-3 hours daily,&lt;strong&gt;consistently&lt;/strong&gt; it might take you around 40 - 45 days)&lt;/p&gt;\n\n&lt;p&gt;First things first : You must have some theoretical and practical on SQL because the exam will test your knowledge on Transact-SQL (if you understand SQL it will not take time) &lt;/p&gt;\n\n&lt;p&gt;So I researched and many people suggested that I start preparing from Alan Rodrigues&amp;#39;s course (Bought it for just 449 INR) &lt;a href=\"https://www.udemy.com/share/104Rwq3@bLDvpnwu7U80WdvU1d3esdKYQotX82fguZgUCnKLTqK1bcWrGF8DyKzLxo1R9tFBWQ==/\"&gt;https://www.udemy.com/share/104Rwq3@bLDvpnwu7U80WdvU1d3esdKYQotX82fguZgUCnKLTqK1bcWrGF8DyKzLxo1R9tFBWQ==/&lt;/a&gt; , &lt;strong&gt;initially found the course overwhelming&lt;/strong&gt; (because I did not study for DP - 900) so I spent a lot of time on ChatGPT understanding the basics like &lt;em&gt;Batch Processing,ETL,ELT,Stream and Reference Data,Telemetry Data,Power BI,Polybase,HADOOP,Apache Spark,Azure Data Lake Storage,Parquet,JSON etc.&lt;/em&gt; (while preparing for this exam I took a look at DP - 900&amp;#39;s syllabus and found a youtuber that explained the basics clearly,&lt;strong&gt;according to me you don&amp;#39;t have to clear DP-900 to clear this exam but atleast understand the basics&lt;/strong&gt;,watched some videos from his playlist on 1.5X &lt;a href=\"https://www.youtube.com/playlist?list=PLhLKc18P9YODENOj4F2nHbNXeYwY1zYGb\"&gt;https://www.youtube.com/playlist?list=PLhLKc18P9YODENOj4F2nHbNXeYwY1zYGb&lt;/a&gt; ) &lt;/p&gt;\n\n&lt;p&gt;So after I completed Alan&amp;#39;s course,took a practice test and ended up scoring around 20% (I would still recommend his course to understand &lt;em&gt;T-SQL queries,Synpase,DataFactory,Databricks,Pipelines,Data Flows,Azure Monitor etc.&lt;/em&gt;)the overall explanation was good &lt;strong&gt;but the mistake I made was&lt;/strong&gt; : focused too much on how to execute the services and getting hands on experience with the platform rather than getting an overall understanding of the concepts,but a little bit hands on experience will be helpful. &lt;/p&gt;\n\n&lt;p&gt;So I started to understand  the paper pattern and the type of questions that frequently come on the exam,around 60 - 70 % of the questions came from this playlist &lt;a href=\"https://www.youtube.com/watch?v=mbo43UgIkYc&amp;amp;list=PL0AYtrUw-NRQu89sbJNXPEo0dkBVTujY5&amp;amp;index=3\"&gt;https://www.youtube.com/watch?v=mbo43UgIkYc&amp;amp;list=PL0AYtrUw-NRQu89sbJNXPEo0dkBVTujY5&amp;amp;index=3&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;I would also recommend this youtuber as he explains all the questions clearly &lt;a href=\"https://www.youtube.com/@studyingasyouwere/playlists\"&gt;https://www.youtube.com/@studyingasyouwere/playlists&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;I would also recommend these 2 channels to revise your preparation &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=RTlZZMDA7qw&amp;amp;list=PLG3ClUcNEYt5Fmrx1hnhquUpLStdItu-y\"&gt;https://www.youtube.com/watch?v=RTlZZMDA7qw&amp;amp;list=PLG3ClUcNEYt5Fmrx1hnhquUpLStdItu-y&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=6deS7pKBEGM\"&gt;https://www.youtube.com/watch?v=6deS7pKBEGM&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;And towards the end I bought a course that had 6 question papers for 449 INR,but some answers were wrong so just google the question or read about the question on Microsoft Documentation&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/share/109Ko43@oymPlhQbt8fnnMSk_8khpWLUGJ8D7mSrFUvTFPMwj7rOI8n9gYK3xBO434pV4z3dWg==/\"&gt;https://www.udemy.com/share/109Ko43@oymPlhQbt8fnnMSk_8khpWLUGJ8D7mSrFUvTFPMwj7rOI8n9gYK3xBO434pV4z3dWg==/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;A tip I would recommend&lt;/strong&gt;,if you don&amp;#39;t understand any topic refer to Microsoft Documentation and still if you don&amp;#39;t understand use ChatGPT&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;And finally my exam experience&lt;/strong&gt; : Had a total of 43 questions (I thought the total number of questions were 65,I guess it changed recently) , had to answer a Case Study intially,then had Multiple choice single answer,Multiple choice Multiple answer,Drop down menus , &lt;strong&gt;not a single question consisted of rearranging the sequence ,&lt;/strong&gt; total exam time : 140 minutes,completed mine in around 100 minutes &lt;/p&gt;\n\n&lt;p&gt;I hope someone on this subreddit finds this information valuable,study well and all the best&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bjb4f1", "is_robot_indexable": true, "report_reasons": null, "author": "re8r0", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjb4f1/passed_dp203_on_17th_march_2024without_any_prior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjb4f1/passed_dp203_on_17th_march_2024without_any_prior/", "subreddit_subscribers": 170537, "created_utc": 1710933858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Airflow is so darn heavy, has so much unnecessary over engineering and it makes it so necessary to adapt your scripts to it rather than the other way around \u2014 which in my opinion should be how it should work.\n\nTo be honest, maybe Im using Airflow wrong but no one on my team seems to be privy to more knowledge nor can I find much online. \n\nIs there a lightweight orchestrator that\u2019s out there? Something simple, that does everything like Airflow minus the endless configuration. Something simple like CRON with a web ui for task status?", "author_fullname": "t2_2l4y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lightweight Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjfvir", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710947715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Airflow is so darn heavy, has so much unnecessary over engineering and it makes it so necessary to adapt your scripts to it rather than the other way around \u2014 which in my opinion should be how it should work.&lt;/p&gt;\n\n&lt;p&gt;To be honest, maybe Im using Airflow wrong but no one on my team seems to be privy to more knowledge nor can I find much online. &lt;/p&gt;\n\n&lt;p&gt;Is there a lightweight orchestrator that\u2019s out there? Something simple, that does everything like Airflow minus the endless configuration. Something simple like CRON with a web ui for task status?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjfvir", "is_robot_indexable": true, "report_reasons": null, "author": "5678", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjfvir/lightweight_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjfvir/lightweight_airflow/", "subreddit_subscribers": 170537, "created_utc": 1710947715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don't know if these kind of posts are allowed or not, but I truly want to admire how this community is very helpful and feels like home, whenever I am stuck in something I just come here and search for a special topic.\n\nMany posts and comments have been helpful to my starting career in Data Engineering, at first I was lost and overwhelmed, but things got clearer once I joined r/dataengineering.\n\nI am still learning day by day, and looking forward to becoming a data engineer, good luck to everybody who's chasing a dream.\n", "author_fullname": "t2_43bjqfmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Appreciation Post - Thank you guys!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjpg6d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710971248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know if these kind of posts are allowed or not, but I truly want to admire how this community is very helpful and feels like home, whenever I am stuck in something I just come here and search for a special topic.&lt;/p&gt;\n\n&lt;p&gt;Many posts and comments have been helpful to my starting career in Data Engineering, at first I was lost and overwhelmed, but things got clearer once I joined &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I am still learning day by day, and looking forward to becoming a data engineer, good luck to everybody who&amp;#39;s chasing a dream.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjpg6d", "is_robot_indexable": true, "report_reasons": null, "author": "WadieXkiller", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjpg6d/appreciation_post_thank_you_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjpg6d/appreciation_post_thank_you_guys/", "subreddit_subscribers": 170537, "created_utc": 1710971248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on an email course for Analytics team leads on product management. But since I'm super slow, I could release what I got so far for free.\n\nThe idea is this: I've seen that the most challenging part for analytics PMs is discovery, and not really the prototyping or the solution finding, but really digging into who the internal customers for their team really are, and what they really want. \n\n&amp;#x200B;\n\nSo that's what those five short emails are about.   \n\n\n1. Figuring out that users of BI systems are not the only internal customers, and likely not the most important ones\n2. Finding key decision makers inside the company that your team doesn't serve yet  \n\n3. Finding key decision makers for whom you've previously only had an indirect relation (e.g. through an analyst using the BI systems)  \n\n4. Finding a good line of questioning to get to the bottom of the requirements.  \n\n\nFiguring out that users of BI systems are not the only internal customers and likely not the most important ones. Here's my outline for questions I ask in discovery calls with internal customers:   \n***Problem-Centric Questions***\n\n* *Walk me through how you use this X.*\n* *What do you do with it then? (Export?)*\n* *How does this data help you make better decisions?*  \n\n   * *A less aggressive version: How does this data help you area to make better decisions?*  \n*Or: How does your area make decisions with data? Tell me all the steps.* \n* *If it is not you who makes better decisions, who is it? (also pretty aggressive, best used as follow-up with context)*\n* *Can you give me an example?*\n* *How does this help you move towards our company strategy?*\n* *How do you get this data right now? Manually? CSV, some other tool?*\n* *What does your workflow look like when preparing for X (sales meeting)?*\n\n*I\u2019ll follow up most of these questions by adapting them, extending them, letting them provide me with an example, or asking about one I have in mind that already exists. I\u2019ll often make sure I cover, at the very least, half of the meeting with problem-centric questions.*\n\n*Then, I move on to solution-centric questions.*\n\n**Solution-centric Questions**\n\n*I will always open the discussion of solutions by saying, \u201cNothing is set in stone; I\u2019ll come back to you once I discussed everything with the team, but what I can say is we have different ways of implementing this, and I\u2019m not the expert on it, the team is.\u201d*\n\n* *What would you do if we cannot build X? (literally) Both regarding the impact on your work, and what would you do to find a workaround?*\n* *If not an X (your product feature), how would it best be delivered to you? Explain how you\u2019d integrate X into your work to make/help make decisions.*\n* *If we build this as X, how would your workflow change?*\n* *Describe to me how this would change the impact on decision-making.*\n* *If you could only get one of the features described, what\u2019s the one that would have the most impact on decision-making?*\n\n  \nIf that makes sense, please take a look at it here: [https://www.theanalyticspm.com/discovery-course](https://www.theanalyticspm.com/discovery-course) and don't forget to give me some feedback! ", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Course On Analytics Product Management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bj8kvh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710923136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on an email course for Analytics team leads on product management. But since I&amp;#39;m super slow, I could release what I got so far for free.&lt;/p&gt;\n\n&lt;p&gt;The idea is this: I&amp;#39;ve seen that the most challenging part for analytics PMs is discovery, and not really the prototyping or the solution finding, but really digging into who the internal customers for their team really are, and what they really want. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So that&amp;#39;s what those five short emails are about.   &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Figuring out that users of BI systems are not the only internal customers, and likely not the most important ones&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Finding key decision makers inside the company that your team doesn&amp;#39;t serve yet  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Finding key decision makers for whom you&amp;#39;ve previously only had an indirect relation (e.g. through an analyst using the BI systems)  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Finding a good line of questioning to get to the bottom of the requirements.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Figuring out that users of BI systems are not the only internal customers and likely not the most important ones. Here&amp;#39;s my outline for questions I ask in discovery calls with internal customers:&lt;br/&gt;\n&lt;strong&gt;&lt;em&gt;Problem-Centric Questions&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;em&gt;Walk me through how you use this X.&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;What do you do with it then? (Export?)&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;em&gt;How does this data help you make better decisions?&lt;/em&gt;  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;em&gt;A less aggressive version: How does this data help you area to make better decisions?&lt;/em&gt;&lt;br/&gt;\n&lt;em&gt;Or: How does your area make decisions with data? Tell me all the steps.&lt;/em&gt; &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;em&gt;If it is not you who makes better decisions, who is it? (also pretty aggressive, best used as follow-up with context)&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;em&gt;Can you give me an example?&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;em&gt;How does this help you move towards our company strategy?&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;em&gt;How do you get this data right now? Manually? CSV, some other tool?&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;em&gt;What does your workflow look like when preparing for X (sales meeting)?&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;em&gt;I\u2019ll follow up most of these questions by adapting them, extending them, letting them provide me with an example, or asking about one I have in mind that already exists. I\u2019ll often make sure I cover, at the very least, half of the meeting with problem-centric questions.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Then, I move on to solution-centric questions.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Solution-centric Questions&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I will always open the discussion of solutions by saying, \u201cNothing is set in stone; I\u2019ll come back to you once I discussed everything with the team, but what I can say is we have different ways of implementing this, and I\u2019m not the expert on it, the team is.\u201d&lt;/em&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;em&gt;What would you do if we cannot build X? (literally) Both regarding the impact on your work, and what would you do to find a workaround?&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;If not an X (your product feature), how would it best be delivered to you? Explain how you\u2019d integrate X into your work to make/help make decisions.&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;If we build this as X, how would your workflow change?&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Describe to me how this would change the impact on decision-making.&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;If you could only get one of the features described, what\u2019s the one that would have the most impact on decision-making?&lt;/em&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If that makes sense, please take a look at it here: &lt;a href=\"https://www.theanalyticspm.com/discovery-course\"&gt;https://www.theanalyticspm.com/discovery-course&lt;/a&gt; and don&amp;#39;t forget to give me some feedback! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pegH9_UZOiP5FF6R6Dlp02VMvzGpDzbmsSCOxbTFgmo.jpg?auto=webp&amp;s=9e298d81e5cfb8892539f2b4a9d80e67bba1f638", "width": 5184, "height": 3456}, "resolutions": [{"url": "https://external-preview.redd.it/pegH9_UZOiP5FF6R6Dlp02VMvzGpDzbmsSCOxbTFgmo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8999d61beadcfd59df649167decacac81b728732", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/pegH9_UZOiP5FF6R6Dlp02VMvzGpDzbmsSCOxbTFgmo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=431bf58be79cbeaf374fb8157de7bd2eea38541e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/pegH9_UZOiP5FF6R6Dlp02VMvzGpDzbmsSCOxbTFgmo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=455354eb7e0821d15efd1cbc65e9ba05707e2990", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/pegH9_UZOiP5FF6R6Dlp02VMvzGpDzbmsSCOxbTFgmo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=325d94e6972ebfe522e9d0f625c884fcb5edd4fd", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/pegH9_UZOiP5FF6R6Dlp02VMvzGpDzbmsSCOxbTFgmo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=78393cbba7b7882ecbcff0bf2ffb87b4c89fdd9a", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/pegH9_UZOiP5FF6R6Dlp02VMvzGpDzbmsSCOxbTFgmo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b2c8033d391a40a46d9f4bef31f68ca55b03e87f", "width": 1080, "height": 720}], "variants": {}, "id": "8p3XRmkWno4hl8QimLdtm6LAjl1MrJJVHZO-E8POKOI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bj8kvh", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bj8kvh/free_course_on_analytics_product_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bj8kvh/free_course_on_analytics_product_management/", "subreddit_subscribers": 170537, "created_utc": 1710923136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apologies if this is not the right sub, but I feel like this is relevant.\n\nWhat, in your opinion, should be the responsibilities of a \u2018Head of Data\u2019 position? \n\nWhat does an ideal Head of Data do, and more importantly, what do they not do?\n\nI understand that the responsibilities can vary between industries and organisations but still want to get an idea since it\u2019s such a vague title. \n\nThanks. ", "author_fullname": "t2_v97o8gu4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the responsibilities of a \u2018Head of Data\u2019?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjss49", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710979618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this is not the right sub, but I feel like this is relevant.&lt;/p&gt;\n\n&lt;p&gt;What, in your opinion, should be the responsibilities of a \u2018Head of Data\u2019 position? &lt;/p&gt;\n\n&lt;p&gt;What does an ideal Head of Data do, and more importantly, what do they not do?&lt;/p&gt;\n\n&lt;p&gt;I understand that the responsibilities can vary between industries and organisations but still want to get an idea since it\u2019s such a vague title. &lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjss49", "is_robot_indexable": true, "report_reasons": null, "author": "Useful_Foundation_42", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjss49/what_are_the_responsibilities_of_a_head_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjss49/what_are_the_responsibilities_of_a_head_of_data/", "subreddit_subscribers": 170537, "created_utc": 1710979618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Timeline of Data Processing technologies covering from MapReduce to Polars. \n\nCovering distributed frameworks to single node libraries, mature and recent development. Let me know which one missed in the comments.\n\nLet me know which one have you used, and which one I have missed.\n\nhttps://www.junaideffendi.com/p/data-processing-in-21st-century", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Processing in 21st Century ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjvuwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JyozGBzlmGkva3MRNrUE-hnzDJCmJhknEDEVyqwwsZg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710988172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Timeline of Data Processing technologies covering from MapReduce to Polars. &lt;/p&gt;\n\n&lt;p&gt;Covering distributed frameworks to single node libraries, mature and recent development. Let me know which one missed in the comments.&lt;/p&gt;\n\n&lt;p&gt;Let me know which one have you used, and which one I have missed.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.junaideffendi.com/p/data-processing-in-21st-century\"&gt;https://www.junaideffendi.com/p/data-processing-in-21st-century&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ag83iybamlpc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?auto=webp&amp;s=86c285f10bb21c51ebbf0a2cfffc9e1cd6636fe3", "width": 2547, "height": 1477}, "resolutions": [{"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8aae14f5c119a9071dc67bf24cb7452b6a65fdf7", "width": 108, "height": 62}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35ab572b3d5c5808c1d852308a4db13acdeb2be4", "width": 216, "height": 125}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b326ad7c2d2e9b7e917aa8ef58a38138bd83432c", "width": 320, "height": 185}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=25be2f9e5eb4dc6f1b8a770956260205c88910bc", "width": 640, "height": 371}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad213d983db97d5ebcfb4aa1c27eb94bb8061dbd", "width": 960, "height": 556}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3ae6044dd61a8fbf06f018222045cebaa8e42635", "width": 1080, "height": 626}], "variants": {}, "id": "wMCVW7pNwdjso_SPpqGoYlWbq9hyerFR9s1pPw4Nr58"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bjvuwy", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjvuwy/data_processing_in_21st_century/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ag83iybamlpc1.jpeg", "subreddit_subscribers": 170537, "created_utc": 1710988172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a DE, and the Devops engineer supporting my team is leaving for a new job. My manager asked me if I would be interested in skilling up for that role. The Devops engineer would be supporting my team and 2 other teams.\n\nThis is my exp so far: \n\n* Previous job - BI work for 3 yrs \n* Current job - DE(70%) and BI (30%) for the last 5 yrs\n\nMy DE work is building and maintaining pipelines in AWS. Working on DB enhancements, ETL etc. We don't have any Big Data, I would call it small/medium data.\n\nIdeally I would like to upskill next with Databricks, pyspark etc. But my company has no need of any Big Data tools. And the option to upskill in Devops is open now.\n\nI'm somewhat familiar with the IAC and CICD tools my team uses, but there will be a lot to learn, especially to support other teams. I'm not sure if this is a good career move.\n\nOther option I'm considering is to look for other jobs in the Big Data space, so I can continue to gain more deep DE expertise.", "author_fullname": "t2_tcw9022g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opportunity to switch to DevOps at my workplace. Should I take it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjv3fk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710986367.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710985972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a DE, and the Devops engineer supporting my team is leaving for a new job. My manager asked me if I would be interested in skilling up for that role. The Devops engineer would be supporting my team and 2 other teams.&lt;/p&gt;\n\n&lt;p&gt;This is my exp so far: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Previous job - BI work for 3 yrs &lt;/li&gt;\n&lt;li&gt;Current job - DE(70%) and BI (30%) for the last 5 yrs&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My DE work is building and maintaining pipelines in AWS. Working on DB enhancements, ETL etc. We don&amp;#39;t have any Big Data, I would call it small/medium data.&lt;/p&gt;\n\n&lt;p&gt;Ideally I would like to upskill next with Databricks, pyspark etc. But my company has no need of any Big Data tools. And the option to upskill in Devops is open now.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m somewhat familiar with the IAC and CICD tools my team uses, but there will be a lot to learn, especially to support other teams. I&amp;#39;m not sure if this is a good career move.&lt;/p&gt;\n\n&lt;p&gt;Other option I&amp;#39;m considering is to look for other jobs in the Big Data space, so I can continue to gain more deep DE expertise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bjv3fk", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Conversation48", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjv3fk/opportunity_to_switch_to_devops_at_my_workplace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjv3fk/opportunity_to_switch_to_devops_at_my_workplace/", "subreddit_subscribers": 170537, "created_utc": 1710985972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019ve been looking for passion as 8 years ago when I started to program in Java for a bank company, during this time I\u2019ve realized I always had been involved in projects of the same kind, you know a monolithic application with lasa\u00f1a pattern to fetch data or insert data or update in a multiple tables on the database. Since 4 years micro services appeared as the revolutionary vision to build business applications and well we now have to be proficient troubleshooting issues on kubernetes. But in the core is the same, a vast set of microservices with its databases and patterns just doing a CRUD operations.\n\nI\u2019m a software engineer working with Java, and I\u2019ve been working with Java version 8 for the last 5 years. Yes I am here to capitulate that too less companies are migrating to Java 17 for example.\n\nNowadays I started to be interested in C# and Dotnet, when I tasted some C# elegant code I felt excited again, because the new features of the language and how it is curated the ecosystem around dotnet.\n\nWhen I was a teenager I was a Linux fan boy terrorizing hard disks with Windows and formatting them with a Linux distro, the perfect anti-Microsoft guy. But when you start to work in the real world and you\u2019re enough mature, you start to see things in a pragmatic way. \n\nMy questions here is:\n\n1.- how do you keep interested despite mostly of the projects that you\u2019re involved are not necessarily exciting things that implies you have to learn new cool stuff? Such as cloud services, new tools or new versions of the framework and programming language!\n\n2.- I\u2019m thinking in doing a horizontal movement and try to get a position as dotnet developer or maybe data engineer with Python to challenge myself or c++ templates or Scala to be a functional ninja, do you believe am I being biased with my own opinions?\n", "author_fullname": "t2_t2gmvsvk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m tired of the same kind of projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjprcv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710971996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019ve been looking for passion as 8 years ago when I started to program in Java for a bank company, during this time I\u2019ve realized I always had been involved in projects of the same kind, you know a monolithic application with lasa\u00f1a pattern to fetch data or insert data or update in a multiple tables on the database. Since 4 years micro services appeared as the revolutionary vision to build business applications and well we now have to be proficient troubleshooting issues on kubernetes. But in the core is the same, a vast set of microservices with its databases and patterns just doing a CRUD operations.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a software engineer working with Java, and I\u2019ve been working with Java version 8 for the last 5 years. Yes I am here to capitulate that too less companies are migrating to Java 17 for example.&lt;/p&gt;\n\n&lt;p&gt;Nowadays I started to be interested in C# and Dotnet, when I tasted some C# elegant code I felt excited again, because the new features of the language and how it is curated the ecosystem around dotnet.&lt;/p&gt;\n\n&lt;p&gt;When I was a teenager I was a Linux fan boy terrorizing hard disks with Windows and formatting them with a Linux distro, the perfect anti-Microsoft guy. But when you start to work in the real world and you\u2019re enough mature, you start to see things in a pragmatic way. &lt;/p&gt;\n\n&lt;p&gt;My questions here is:&lt;/p&gt;\n\n&lt;p&gt;1.- how do you keep interested despite mostly of the projects that you\u2019re involved are not necessarily exciting things that implies you have to learn new cool stuff? Such as cloud services, new tools or new versions of the framework and programming language!&lt;/p&gt;\n\n&lt;p&gt;2.- I\u2019m thinking in doing a horizontal movement and try to get a position as dotnet developer or maybe data engineer with Python to challenge myself or c++ templates or Scala to be a functional ninja, do you believe am I being biased with my own opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bjprcv", "is_robot_indexable": true, "report_reasons": null, "author": "Swimming-Ad-9848", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjprcv/im_tired_of_the_same_kind_of_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjprcv/im_tired_of_the_same_kind_of_projects/", "subreddit_subscribers": 170537, "created_utc": 1710971996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has a mix of GCP/on-prem architecture : \n\n\\- for all our streaming jobs on GCP we use Apache Beam (Java/Python) + Dataflow\n\n\\- for on-prem streaming jobs we implemented custom python consumers\n\nAs part of the revamp of these consumer jobs, we want to harmonize the technologies in the data and software engineering teams.  \n\n\nWe are a bit frustrated with Beam, as a lot of features are only available in Java, and it is sometimes overkill for some use cases (just tasks doing simple transformations). Also, running Beam on-premise is not the simplest task (we need Apache Flink for that).  \n\n\nWe tried looking at alternatives, and we wondered if there were some limitations using python consumers instead of using a tool like Spark/Beam/Flink ?  \n\n\n[https://www.benthos.dev/](https://www.benthos.dev/) is really interesting to us, are there similar interesting alternatives out there ? Is anyone running this in production ?", "author_fullname": "t2_6eywks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lightweight alternative to Spark/Flink/Apache Beam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjjdqc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710956386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has a mix of GCP/on-prem architecture : &lt;/p&gt;\n\n&lt;p&gt;- for all our streaming jobs on GCP we use Apache Beam (Java/Python) + Dataflow&lt;/p&gt;\n\n&lt;p&gt;- for on-prem streaming jobs we implemented custom python consumers&lt;/p&gt;\n\n&lt;p&gt;As part of the revamp of these consumer jobs, we want to harmonize the technologies in the data and software engineering teams.  &lt;/p&gt;\n\n&lt;p&gt;We are a bit frustrated with Beam, as a lot of features are only available in Java, and it is sometimes overkill for some use cases (just tasks doing simple transformations). Also, running Beam on-premise is not the simplest task (we need Apache Flink for that).  &lt;/p&gt;\n\n&lt;p&gt;We tried looking at alternatives, and we wondered if there were some limitations using python consumers instead of using a tool like Spark/Beam/Flink ?  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.benthos.dev/\"&gt;https://www.benthos.dev/&lt;/a&gt; is really interesting to us, are there similar interesting alternatives out there ? Is anyone running this in production ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?auto=webp&amp;s=dbd4e50acf2c42d60ce3d39f04de3a52639fb9ce", "width": 640, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4225757574c6f331afa17e7c5589f1b146d7932c", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b36b2bb69cda53273dd799d4f7a2b64508879881", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=125d1a6e1ce47ec1981961520cca43f3e73c952d", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa98a2bdb1c50316ebd0a1ec5426977f9a6e9ed8", "width": 640, "height": 400}], "variants": {}, "id": "8HIkF3M3-DIhSHVbfFusVy2WXvxdYkTp7e1P1xwBbhk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjjdqc", "is_robot_indexable": true, "report_reasons": null, "author": "gfalcone", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bjjdqc/lightweight_alternative_to_sparkflinkapache_beam/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjjdqc/lightweight_alternative_to_sparkflinkapache_beam/", "subreddit_subscribers": 170537, "created_utc": 1710956386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking out for any website/platform which allows users to interact and users will be able to work together on the project. If it's not present, I'm proposing following:\n\nA platform or website which have functionality to support following workflow: \n\n  \n**1**. **Ideation Pitch In** \\- Anyone can come and add their project/task ideas in the posts. For ex. Need to build a dashboard from this [dataset](https://voaratinglists.blob.core.windows.net/html/rlidata.htm). \n\n**2**. **Peer Gathering:** People gonna see the post and gonna add the enhancement that can be done on this. ex. in dashboard, can we add this feature?\n\n**3**. **Task Division:** OP can divide the tasks initially once the project is finalized (ofc they can add enhacements in between).\n\n**4**. **Task Ownership:** Peers who wanna pitch in can take these tasks and own them (if that owner drops off, someone else from community can pick that up)\n\n*Advantage*: They can show up these projects in their portfolio as they are openly available in public Github, Also if some ideas are really useful to everyone, they can easily showcase them. \n\nLet me know what you guys think of it. Any feedback is appreciated.  \n\n\n&amp;#x200B;", "author_fullname": "t2_c4kloony", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Peer Driven Projects for Experience and Learning Purpose", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjd57h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710940459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking out for any website/platform which allows users to interact and users will be able to work together on the project. If it&amp;#39;s not present, I&amp;#39;m proposing following:&lt;/p&gt;\n\n&lt;p&gt;A platform or website which have functionality to support following workflow: &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;. &lt;strong&gt;Ideation Pitch In&lt;/strong&gt; - Anyone can come and add their project/task ideas in the posts. For ex. Need to build a dashboard from this &lt;a href=\"https://voaratinglists.blob.core.windows.net/html/rlidata.htm\"&gt;dataset&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;. &lt;strong&gt;Peer Gathering:&lt;/strong&gt; People gonna see the post and gonna add the enhancement that can be done on this. ex. in dashboard, can we add this feature?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;3&lt;/strong&gt;. &lt;strong&gt;Task Division:&lt;/strong&gt; OP can divide the tasks initially once the project is finalized (ofc they can add enhacements in between).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt;. &lt;strong&gt;Task Ownership:&lt;/strong&gt; Peers who wanna pitch in can take these tasks and own them (if that owner drops off, someone else from community can pick that up)&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Advantage&lt;/em&gt;: They can show up these projects in their portfolio as they are openly available in public Github, Also if some ideas are really useful to everyone, they can easily showcase them. &lt;/p&gt;\n\n&lt;p&gt;Let me know what you guys think of it. Any feedback is appreciated.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjd57h", "is_robot_indexable": true, "report_reasons": null, "author": "triesegment", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bjd57h/peer_driven_projects_for_experience_and_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjd57h/peer_driven_projects_for_experience_and_learning/", "subreddit_subscribers": 170537, "created_utc": 1710940459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working as a Analytics Engineer/Data Engineer for a year and been solving Leetcode problems lately (to prepare for new opportunities). The following questions just came up in my mind regarding Leetcode and how to approach solving technical problems in general.\n\n**1. About intellectual capability to program:** I was able to crack some Easy level LC problems, but this one (https://leetcode.com/problems/subsets/) made me doubt my ability. I came up with a general solution (pseudo-code) and a runnable program (using recursion) for that problem within an afternoon, but only until the next day did I find a way to write it without using recursion. I do not have a CS background, but I know that interviews are very time-intensive and my colleagues with CS background can solve this kind of problem in minutes. With my age approaching 30, am I screwed with regards to my ability to program well and effectively? I'm really afraid that I'm not intellectually capable of programming *effectively* (i.e., coming up with efficient and smart solutions to problems).\n\n**2. About approaching technical problems:** For me, it takes quite some time to solve LC problems and lots of tweaking/debugging to pass all test cases. I feel like if I come back to those problems, I won't produce the exact answers. How would you organize the ideas that you learned from solving technical problems like LC? Do you recommend remembering all the details/edge cases of the code or just remember the general approach to each problem or the kind of the problem? Should I read algorithm textbooks as well to invigorate the ideas learnt?\n\nThank you for reading.", "author_fullname": "t2_ksuox3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leetcode, programming capability and approaching technical problems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bj6pp2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710915052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a Analytics Engineer/Data Engineer for a year and been solving Leetcode problems lately (to prepare for new opportunities). The following questions just came up in my mind regarding Leetcode and how to approach solving technical problems in general.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1. About intellectual capability to program:&lt;/strong&gt; I was able to crack some Easy level LC problems, but this one (&lt;a href=\"https://leetcode.com/problems/subsets/\"&gt;https://leetcode.com/problems/subsets/&lt;/a&gt;) made me doubt my ability. I came up with a general solution (pseudo-code) and a runnable program (using recursion) for that problem within an afternoon, but only until the next day did I find a way to write it without using recursion. I do not have a CS background, but I know that interviews are very time-intensive and my colleagues with CS background can solve this kind of problem in minutes. With my age approaching 30, am I screwed with regards to my ability to program well and effectively? I&amp;#39;m really afraid that I&amp;#39;m not intellectually capable of programming &lt;em&gt;effectively&lt;/em&gt; (i.e., coming up with efficient and smart solutions to problems).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. About approaching technical problems:&lt;/strong&gt; For me, it takes quite some time to solve LC problems and lots of tweaking/debugging to pass all test cases. I feel like if I come back to those problems, I won&amp;#39;t produce the exact answers. How would you organize the ideas that you learned from solving technical problems like LC? Do you recommend remembering all the details/edge cases of the code or just remember the general approach to each problem or the kind of the problem? Should I read algorithm textbooks as well to invigorate the ideas learnt?&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bj6pp2", "is_robot_indexable": true, "report_reasons": null, "author": "vietzerg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bj6pp2/leetcode_programming_capability_and_approaching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bj6pp2/leetcode_programming_capability_and_approaching/", "subreddit_subscribers": 170537, "created_utc": 1710915052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cv0bgwia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The \"pip install data stack\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjocci", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pphqVCmxbqn1pMnDKrbb2nYf-sxcLUVfKLcu8QNu3A8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710968603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "juhache.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://juhache.substack.com/p/pip-install-data-stack?utm_source=profile&amp;utm_medium=reader2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?auto=webp&amp;s=15736a469b20e0fafd0c66c92e66155a3d7eef23", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5b8d32487b2952672e8aec024faffa293d007f3c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=870810e83dfb54b3568a08c9505310fd11e984d5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1aeea72fbcb0b0ee3eb48c170e73818a359898d7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a29a2f6f395e438549df7e225b92cbbd70f2016", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d01b9c2261e6b5055cf4c63534fd0ea8fbd9b244", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=52a12844b751038786595eb4cd9450a280bc301e", "width": 1080, "height": 540}], "variants": {}, "id": "HgYkgiKoJ3K5IxWmSmkKBeQvq9pr8QAtn3nH0djST3I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bjocci", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant_Type_4547", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjocci/the_pip_install_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://juhache.substack.com/p/pip-install-data-stack?utm_source=profile&amp;utm_medium=reader2", "subreddit_subscribers": 170537, "created_utc": 1710968603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my current position (and for personal projects) I find myself doing a lot of bespoke problem solving as team of 1 or 2. Examples:\n\n\\- Scrape and munge some amount (&lt;10GB) of historical data from this website. Have it in a format where we can calculate \\[potential metrics\\] if we want to write about it in the future.\n\n\\- The metrics on this government website don't give us what we need -- monitor the site for updates and trigger a pipeline that downloads the data, calculates our metrics, creates charts, and emails a summary.\n\nThere's no online application, no warehouse, not much technical expertise on the team. The objective is to get the task done in a reliable, maintainable manner while minimizing cost.\n\nI have found myself often favoring a data lake (S3 + medallion architecture) + serverless functions (AWS Lambda). Email alerts when things break, Cloudwatch for monitoring. Feels so ethereal not worrying about servers and databases while still delivering valuable data.\n\nWho else does \"small data engineer\" work and what architecture(s) do you typically use to get the job done?", "author_fullname": "t2_cqvp4nt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small Data Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjjte9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710957457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my current position (and for personal projects) I find myself doing a lot of bespoke problem solving as team of 1 or 2. Examples:&lt;/p&gt;\n\n&lt;p&gt;- Scrape and munge some amount (&amp;lt;10GB) of historical data from this website. Have it in a format where we can calculate [potential metrics] if we want to write about it in the future.&lt;/p&gt;\n\n&lt;p&gt;- The metrics on this government website don&amp;#39;t give us what we need -- monitor the site for updates and trigger a pipeline that downloads the data, calculates our metrics, creates charts, and emails a summary.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s no online application, no warehouse, not much technical expertise on the team. The objective is to get the task done in a reliable, maintainable manner while minimizing cost.&lt;/p&gt;\n\n&lt;p&gt;I have found myself often favoring a data lake (S3 + medallion architecture) + serverless functions (AWS Lambda). Email alerts when things break, Cloudwatch for monitoring. Feels so ethereal not worrying about servers and databases while still delivering valuable data.&lt;/p&gt;\n\n&lt;p&gt;Who else does &amp;quot;small data engineer&amp;quot; work and what architecture(s) do you typically use to get the job done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjjte9", "is_robot_indexable": true, "report_reasons": null, "author": "udonthave2call", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjjte9/small_data_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjjte9/small_data_architecture/", "subreddit_subscribers": 170537, "created_utc": 1710957457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Howdy folks. The team I\u2019m currently on has a plethora of Informatica processes built up that are being considered for divestment out of Informatica. Currently those processes use a hashing function in Informatica that creates a hash off predefined attributes, checks that hash against the current table, and if there isn\u2019t a match: load the record.\n\nThe problem: the hash function is a black box. Attempting to recreate the hash, even by the namesake of the hashing algorithm (think MD5 and other hashing algos), the same result is not reproduced. There seems to be some baked in logic to the Informatica logic that modifies the algo one way or another.\n\nSo with that in mind, divesting from Informatica will cause every row to be new. The compute and storage of an entirely new dataset across all of the processes is out of scope.\n\nIf anyone\u2019s been down a similar road, curious on the solution you used. One thought is SCDM2 and indicate the columns being used as the hash input today as the changing dimensions for SCDM2. In theory, simply scanning those columns and timestamping changes ought to provide a solution that mirrors the legacy dataset and not cause an entirely new dataset. ", "author_fullname": "t2_708ooj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Divesting from Informatica &amp; Hashing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjbsqu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710936231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy folks. The team I\u2019m currently on has a plethora of Informatica processes built up that are being considered for divestment out of Informatica. Currently those processes use a hashing function in Informatica that creates a hash off predefined attributes, checks that hash against the current table, and if there isn\u2019t a match: load the record.&lt;/p&gt;\n\n&lt;p&gt;The problem: the hash function is a black box. Attempting to recreate the hash, even by the namesake of the hashing algorithm (think MD5 and other hashing algos), the same result is not reproduced. There seems to be some baked in logic to the Informatica logic that modifies the algo one way or another.&lt;/p&gt;\n\n&lt;p&gt;So with that in mind, divesting from Informatica will cause every row to be new. The compute and storage of an entirely new dataset across all of the processes is out of scope.&lt;/p&gt;\n\n&lt;p&gt;If anyone\u2019s been down a similar road, curious on the solution you used. One thought is SCDM2 and indicate the columns being used as the hash input today as the changing dimensions for SCDM2. In theory, simply scanning those columns and timestamping changes ought to provide a solution that mirrors the legacy dataset and not cause an entirely new dataset. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjbsqu", "is_robot_indexable": true, "report_reasons": null, "author": "ExistentialFajitas", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bjbsqu/divesting_from_informatica_hashing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjbsqu/divesting_from_informatica_hashing/", "subreddit_subscribers": 170537, "created_utc": 1710936231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are some commonly used tools for integrating and transforming data with different GTM SaaS?   \nFor instance, I built a SaaS product that helps to construct PnL for B2B SaaS. I want to extract data from Stripe and Hubspot, perform some metric calculations across two systems, and then send it back to the original systems; what tools should I use? I considered using Airbyte for ETL, DBT for transformation, and some API wrapped to communicate the results back to the systems. \n\nDoes this approach sound reasonable or I'm looking in the wrong direction? ", "author_fullname": "t2_evy8q46", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL setup for the backend for the data products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjbmk7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710935667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some commonly used tools for integrating and transforming data with different GTM SaaS?&lt;br/&gt;\nFor instance, I built a SaaS product that helps to construct PnL for B2B SaaS. I want to extract data from Stripe and Hubspot, perform some metric calculations across two systems, and then send it back to the original systems; what tools should I use? I considered using Airbyte for ETL, DBT for transformation, and some API wrapped to communicate the results back to the systems. &lt;/p&gt;\n\n&lt;p&gt;Does this approach sound reasonable or I&amp;#39;m looking in the wrong direction? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bjbmk7", "is_robot_indexable": true, "report_reasons": null, "author": "zkid18", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjbmk7/etl_setup_for_the_backend_for_the_data_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjbmk7/etl_setup_for_the_backend_for_the_data_products/", "subreddit_subscribers": 170537, "created_utc": 1710935667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is more of a Data Science problem, but I found surprisingly little information on it and I thought it would be a good idea to ask the epxerts.\n\nI have a large dataset of strings and corresponding embeddings (fixed-size torch tensors). I would like to save them in some kind of tabular format, to be re-used when experimenting with hyperparameters, model architectures, etc. If possible I would like to avoid signing up for cloud vector DBs or setting up DB servers (like Postgres).\n\nThe solutions I see now:\n\n- store as `.npy`, `.pt` or `.hd5`: straightforward &amp; efficient. Cons: not so straightforward retrieval without link to the corresponding string, no built-in appending / batching solutions.\n- PyArrow has a `FixedShapeTensorArray` extension format which you can save into Parquet. Con: it does not seem to be interoperable with tools I would use to retrieve embeddings for a particular set of strings, like Polars or DuckDB.\n- DuckDB &amp; Parquet have a 1D fixed-length array type. Con: would require reshaping before saving and after retrieval.\n- Finally, Parquet could also store a serialized bytes column. Con: again, requires (de)serialization on read and write.\n\nI would appreciate any insights.", "author_fullname": "t2_59m5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File storage format for tensors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bj9ua8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710928904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is more of a Data Science problem, but I found surprisingly little information on it and I thought it would be a good idea to ask the epxerts.&lt;/p&gt;\n\n&lt;p&gt;I have a large dataset of strings and corresponding embeddings (fixed-size torch tensors). I would like to save them in some kind of tabular format, to be re-used when experimenting with hyperparameters, model architectures, etc. If possible I would like to avoid signing up for cloud vector DBs or setting up DB servers (like Postgres).&lt;/p&gt;\n\n&lt;p&gt;The solutions I see now:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;store as &lt;code&gt;.npy&lt;/code&gt;, &lt;code&gt;.pt&lt;/code&gt; or &lt;code&gt;.hd5&lt;/code&gt;: straightforward &amp;amp; efficient. Cons: not so straightforward retrieval without link to the corresponding string, no built-in appending / batching solutions.&lt;/li&gt;\n&lt;li&gt;PyArrow has a &lt;code&gt;FixedShapeTensorArray&lt;/code&gt; extension format which you can save into Parquet. Con: it does not seem to be interoperable with tools I would use to retrieve embeddings for a particular set of strings, like Polars or DuckDB.&lt;/li&gt;\n&lt;li&gt;DuckDB &amp;amp; Parquet have a 1D fixed-length array type. Con: would require reshaping before saving and after retrieval.&lt;/li&gt;\n&lt;li&gt;Finally, Parquet could also store a serialized bytes column. Con: again, requires (de)serialization on read and write.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would appreciate any insights.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bj9ua8", "is_robot_indexable": true, "report_reasons": null, "author": "satyrmode", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bj9ua8/file_storage_format_for_tensors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bj9ua8/file_storage_format_for_tensors/", "subreddit_subscribers": 170537, "created_utc": 1710928904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in an org which has a 80 node cluster and run lot of data pipelines (pyspark jobs) at different times. \n\nRecently we have been having lot of issues effectively managing the jobs. There are lot of adhoc analysis which goes on and because of this resource usage reaches more than 80-90%, this results in everything running slow. \n\nI'm trying to come up with a mechanism to notify high resource users.\n\nMy current solution is to run periodic script which check the YRAN resource manager and picks jobs which cross certain threshold, Ex: Cluster usage &gt; 30%, elapsed time &gt; 5hrs etc. \n\nhttps://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html\n\nIs there any better way to do it?", "author_fullname": "t2_bnruv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage/notify usage in the cluster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bjxqc2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710993897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in an org which has a 80 node cluster and run lot of data pipelines (pyspark jobs) at different times. &lt;/p&gt;\n\n&lt;p&gt;Recently we have been having lot of issues effectively managing the jobs. There are lot of adhoc analysis which goes on and because of this resource usage reaches more than 80-90%, this results in everything running slow. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to come up with a mechanism to notify high resource users.&lt;/p&gt;\n\n&lt;p&gt;My current solution is to run periodic script which check the YRAN resource manager and picks jobs which cross certain threshold, Ex: Cluster usage &amp;gt; 30%, elapsed time &amp;gt; 5hrs etc. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html\"&gt;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there any better way to do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bjxqc2", "is_robot_indexable": true, "report_reasons": null, "author": "lazygeek", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjxqc2/how_do_you_managenotify_usage_in_the_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjxqc2/how_do_you_managenotify_usage_in_the_cluster/", "subreddit_subscribers": 170537, "created_utc": 1710993897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I\u2019m in my final year of engineering in a uni in Canada and as a part of our program they make us do 6 internships. Most of my internships have been backend but my current internship and my final one next semester are Data engineering roles. Chances are I\u2019ll return back to this company full time as a data engineer for new grad. I\u2019m not too sure if DE is for me so I\u2019d appreciate any input here.\n\n1) I\u2019ve been doing my internships at faang adjacent companies. I keep reading that DEs get paid lower than SWEs in big tech. Compensation is a huge factor for me and I don\u2019t wanna fall behind my SWE peers. Is this problem overblown or is there some truth to it?\n\n2) I\u2019m very comfortable with software development as I\u2019ve been doing it since high school. However, I\u2019m not familiar with most of the technologies in the data engineering tech stack since it\u2019s so niche. Will this mean slower promotions than SWE due to the learning curve?\n\n3) I\u2019m working remote right now and would love to work remote in the future as the city I live in doesn\u2019t have a tech industry. Hence, the ability to find remote jobs is important to me. Is it reasonable to expect DE jobs to be easier to secure as it\u2019s very niche, hence less competition?\n\n4) Is DE a good idea as a new grad or should I start off as a general backend engineer and specialize later on if I want to?\n\n5) Is it easy to move from DE to SWE in the future if I wanted to?\n\nAlso to give some context surrounding the data engineering role at my current company, it\u2019s pretty coding heavy. A lot of scala, pyspark, go, airflow, dagster, etc. It\u2019s not just writing sql queries ", "author_fullname": "t2_jhrem0eu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SWE vs DE for new grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjt82m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710980760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I\u2019m in my final year of engineering in a uni in Canada and as a part of our program they make us do 6 internships. Most of my internships have been backend but my current internship and my final one next semester are Data engineering roles. Chances are I\u2019ll return back to this company full time as a data engineer for new grad. I\u2019m not too sure if DE is for me so I\u2019d appreciate any input here.&lt;/p&gt;\n\n&lt;p&gt;1) I\u2019ve been doing my internships at faang adjacent companies. I keep reading that DEs get paid lower than SWEs in big tech. Compensation is a huge factor for me and I don\u2019t wanna fall behind my SWE peers. Is this problem overblown or is there some truth to it?&lt;/p&gt;\n\n&lt;p&gt;2) I\u2019m very comfortable with software development as I\u2019ve been doing it since high school. However, I\u2019m not familiar with most of the technologies in the data engineering tech stack since it\u2019s so niche. Will this mean slower promotions than SWE due to the learning curve?&lt;/p&gt;\n\n&lt;p&gt;3) I\u2019m working remote right now and would love to work remote in the future as the city I live in doesn\u2019t have a tech industry. Hence, the ability to find remote jobs is important to me. Is it reasonable to expect DE jobs to be easier to secure as it\u2019s very niche, hence less competition?&lt;/p&gt;\n\n&lt;p&gt;4) Is DE a good idea as a new grad or should I start off as a general backend engineer and specialize later on if I want to?&lt;/p&gt;\n\n&lt;p&gt;5) Is it easy to move from DE to SWE in the future if I wanted to?&lt;/p&gt;\n\n&lt;p&gt;Also to give some context surrounding the data engineering role at my current company, it\u2019s pretty coding heavy. A lot of scala, pyspark, go, airflow, dagster, etc. It\u2019s not just writing sql queries &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bjt82m", "is_robot_indexable": true, "report_reasons": null, "author": "PrizeProper2670", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjt82m/swe_vs_de_for_new_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjt82m/swe_vs_de_for_new_grad/", "subreddit_subscribers": 170537, "created_utc": 1710980760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://blog.peerdb.io/enterprise-grade-replication-from-postgres-to-azure-event-hubs](https://blog.peerdb.io/enterprise-grade-replication-from-postgres-to-azure-event-hubs)", "author_fullname": "t2_ecjs7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Native Debezium alternative for replication from Postgres to Azure Event Hubs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjmmox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710964422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://blog.peerdb.io/enterprise-grade-replication-from-postgres-to-azure-event-hubs\"&gt;https://blog.peerdb.io/enterprise-grade-replication-from-postgres-to-azure-event-hubs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5xRKf2sV4B85oLGn3djxEAR_x1UrA0g0qhmpUXkXH2c.jpg?auto=webp&amp;s=22269b35c490ce2585397b554fba6db6f7fd4395", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/5xRKf2sV4B85oLGn3djxEAR_x1UrA0g0qhmpUXkXH2c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12de3b05dae947aa6a4a41bd41652a653ce0ba9b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5xRKf2sV4B85oLGn3djxEAR_x1UrA0g0qhmpUXkXH2c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f461bd39cbac36d8e2bd4aa4d04ee5b10c156df2", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5xRKf2sV4B85oLGn3djxEAR_x1UrA0g0qhmpUXkXH2c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1e256ac25c0efb263f50c7170a1efe72185a102", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/5xRKf2sV4B85oLGn3djxEAR_x1UrA0g0qhmpUXkXH2c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03bb385efbea675c69f0c7ee2ea9a457163003c1", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/5xRKf2sV4B85oLGn3djxEAR_x1UrA0g0qhmpUXkXH2c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f725969402048abd200eed54970278111540b82a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/5xRKf2sV4B85oLGn3djxEAR_x1UrA0g0qhmpUXkXH2c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8572fbeb409d650725f9d22f96c4f38f63f0a9de", "width": 1080, "height": 567}], "variants": {}, "id": "1I9RWZJ9CUgq9_6AQ3Rr3gvJJsnWwnIAgHQ0rKh-BuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bjmmox", "is_robot_indexable": true, "report_reasons": null, "author": "cauchyk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjmmox/native_debezium_alternative_for_replication_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjmmox/native_debezium_alternative_for_replication_from/", "subreddit_subscribers": 170537, "created_utc": 1710964422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I receive a CSV in s3, glue ETL grabs it and transforms the schema and to parquet and drops it back into another bucket and registers the data in the catalog (Athena). Fine.\n\nBut I noticed columns marked for transformation into int data type will get written entirely as nulls if just one row has a null value in that column. If it transforms to float, this is not a problem. Everything is being converted from string, but the csv will have just a blank cell not \u201cnull\u201d or whatever.\n\nAm I missing something here? Is this expected behavior?", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue + Athena Data Catalog, int column all nulls if one row in source data was null but float is fine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjl4fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710960712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I receive a CSV in s3, glue ETL grabs it and transforms the schema and to parquet and drops it back into another bucket and registers the data in the catalog (Athena). Fine.&lt;/p&gt;\n\n&lt;p&gt;But I noticed columns marked for transformation into int data type will get written entirely as nulls if just one row has a null value in that column. If it transforms to float, this is not a problem. Everything is being converted from string, but the csv will have just a blank cell not \u201cnull\u201d or whatever.&lt;/p&gt;\n\n&lt;p&gt;Am I missing something here? Is this expected behavior?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bjl4fq", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjl4fq/aws_glue_athena_data_catalog_int_column_all_nulls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjl4fq/aws_glue_athena_data_catalog_int_column_all_nulls/", "subreddit_subscribers": 170537, "created_utc": 1710960712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know if MFA can be setup for the Cloud IDE?  I am not meaning dbt core, but the cloud instance.  I am also not meaning mfa to source data - just the cloud env where you manage projects, connections etc", "author_fullname": "t2_90kfz8w4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Cloud - MFA/2FA support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bjxiay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710993208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know if MFA can be setup for the Cloud IDE?  I am not meaning dbt core, but the cloud instance.  I am also not meaning mfa to source data - just the cloud env where you manage projects, connections etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bjxiay", "is_robot_indexable": true, "report_reasons": null, "author": "Additional-Maize3980", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjxiay/dbt_cloud_mfa2fa_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjxiay/dbt_cloud_mfa2fa_support/", "subreddit_subscribers": 170537, "created_utc": 1710993208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gxesw7ji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u2699\ufe0f Automating Database Schema Change workflow Using GitHub Actions \ud83d\udc19", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjvp4z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/G8pdBlOnmES4fNu-lFT6w3eKe7eWxI_szGmlYoGWgxg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710987703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bytebase.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.bytebase.com/docs/tutorials/github-ci/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PrpDCNZ5dLHLyLUgbkc9r3g4okSK0kN6um4fkbTcDhM.jpg?auto=webp&amp;s=4ee9291eeea359f87e371ad2b60f36cc015e0deb", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PrpDCNZ5dLHLyLUgbkc9r3g4okSK0kN6um4fkbTcDhM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6dc3af82f9d57e18cc1e39bad1e49c43bfa5f4d6", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PrpDCNZ5dLHLyLUgbkc9r3g4okSK0kN6um4fkbTcDhM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b37bf07fcf134c5c3c89a9cf0a5f1d7871c47829", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PrpDCNZ5dLHLyLUgbkc9r3g4okSK0kN6um4fkbTcDhM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f404fb30e9f6f55e01b974f32cd376b72a2989cc", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PrpDCNZ5dLHLyLUgbkc9r3g4okSK0kN6um4fkbTcDhM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=27d41f18e0795ac766cb303af4c9e5190c5fe660", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PrpDCNZ5dLHLyLUgbkc9r3g4okSK0kN6um4fkbTcDhM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=11d914ffdb4267d9fe84b0c9fee38a00fdb99ec0", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PrpDCNZ5dLHLyLUgbkc9r3g4okSK0kN6um4fkbTcDhM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fc1a9af4f4d0046d299db13cab3e24958ee7311c", "width": 1080, "height": 567}], "variants": {}, "id": "RhCyZwp_UbLN7zKPSBXTU3o_RwNpfCS-ZmS42mHZjdI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bjvp4z", "is_robot_indexable": true, "report_reasons": null, "author": "Adela_freedom", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjvp4z/automating_database_schema_change_workflow_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.bytebase.com/docs/tutorials/github-ci/", "subreddit_subscribers": 170537, "created_utc": 1710987703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Organizations worldwide are beginning to adopt cloud services. As a result, the painstaking task of moving data from on-premises to the cloud has been on the rise for most data professionals. Using the best platform and technique for moving data is more crucial than ever.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dynamically Copy Data from SQL Server to Azure SQL Database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjq03j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XPU6bmXFj3dIwCRltaJZpzyh75rfsjMpXhIbZTcGl8o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710972576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mssqltips.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Organizations worldwide are beginning to adopt cloud services. As a result, the painstaking task of moving data from on-premises to the cloud has been on the rise for most data professionals. Using the best platform and technique for moving data is more crucial than ever.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.mssqltips.com/sqlservertip/7930/dynamically-copy-data-from-sql-server-to-azure-sql-database/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4as0vR77w12xHGdca3bTZ4ZKQ7QoIn87pOQTI6MP8ZY.jpg?auto=webp&amp;s=bb6ab315d6ad8d448475682631933776c28fcbd5", "width": 350, "height": 175}, "resolutions": [{"url": "https://external-preview.redd.it/4as0vR77w12xHGdca3bTZ4ZKQ7QoIn87pOQTI6MP8ZY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fcf3745a310ac962912e3d90f2edc6939be21be4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4as0vR77w12xHGdca3bTZ4ZKQ7QoIn87pOQTI6MP8ZY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=406646b3ad9401edf23c99ae9a528889bdf96dad", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4as0vR77w12xHGdca3bTZ4ZKQ7QoIn87pOQTI6MP8ZY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=69e715c17629dabdcb0b3e28a8eca949264248ee", "width": 320, "height": 160}], "variants": {}, "id": "0l7rPyIzKjdetiT4rFGw_8krHMvwF9TjI_6syfoZzTg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bjq03j", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjq03j/dynamically_copy_data_from_sql_server_to_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.mssqltips.com/sqlservertip/7930/dynamically-copy-data-from-sql-server-to-azure-sql-database/", "subreddit_subscribers": 170537, "created_utc": 1710972576.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}