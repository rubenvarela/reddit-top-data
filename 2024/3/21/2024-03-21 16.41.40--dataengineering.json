{"kind": "Listing", "data": {"after": "t3_1bk36hb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Timeline of Data Processing technologies covering from MapReduce to Polars. \n\nCovering distributed frameworks to single node libraries, mature and recent development. Let me know which one missed in the comments.\n\nLet me know which one have you used, and which one I have missed.\n\nhttps://www.junaideffendi.com/p/data-processing-in-21st-century", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Processing in 21st Century ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjvuwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JyozGBzlmGkva3MRNrUE-hnzDJCmJhknEDEVyqwwsZg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710988172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Timeline of Data Processing technologies covering from MapReduce to Polars. &lt;/p&gt;\n\n&lt;p&gt;Covering distributed frameworks to single node libraries, mature and recent development. Let me know which one missed in the comments.&lt;/p&gt;\n\n&lt;p&gt;Let me know which one have you used, and which one I have missed.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.junaideffendi.com/p/data-processing-in-21st-century\"&gt;https://www.junaideffendi.com/p/data-processing-in-21st-century&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ag83iybamlpc1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?auto=webp&amp;s=86c285f10bb21c51ebbf0a2cfffc9e1cd6636fe3", "width": 2547, "height": 1477}, "resolutions": [{"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8aae14f5c119a9071dc67bf24cb7452b6a65fdf7", "width": 108, "height": 62}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35ab572b3d5c5808c1d852308a4db13acdeb2be4", "width": 216, "height": 125}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b326ad7c2d2e9b7e917aa8ef58a38138bd83432c", "width": 320, "height": 185}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=25be2f9e5eb4dc6f1b8a770956260205c88910bc", "width": 640, "height": 371}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad213d983db97d5ebcfb4aa1c27eb94bb8061dbd", "width": 960, "height": 556}, {"url": "https://preview.redd.it/ag83iybamlpc1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3ae6044dd61a8fbf06f018222045cebaa8e42635", "width": 1080, "height": 626}], "variants": {}, "id": "wMCVW7pNwdjso_SPpqGoYlWbq9hyerFR9s1pPw4Nr58"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bjvuwy", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjvuwy/data_processing_in_21st_century/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ag83iybamlpc1.jpeg", "subreddit_subscribers": 170661, "created_utc": 1710988172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm 27(F) and I've been working in data engineering for a good 5 years now. I recently started working for a Canadian company where I already knew my boss from another place we worked together. When we were discussing the opportunity he had told me that the salary would be around 7500 dollars a month, but after a conversation with the founders of the company I received the offer with a salary of 5800, but I managed to cry for 6500. From what my boss said, it was because Canadians think I'm too young, but I'm sure part of it was because I'm a woman too.\n\nNow that I've been with the company for a year, I've made some great deliveries and I give a lot of support to other people whose technical level is well below mine, but who earn more, I'd like to ask for a decent raise. I've already talked to my boss, but he tells me to be patient because HR is working on a career plan, but that should take another 6 months at least.\n\nI'd like some help in approaching my boss more firmly, but without sounding like an ultimatum. I'd like him to talk directly to the founders, as I think this would make it easier to get a raise (the founders are aware of the work I've been doing).\n\nI wouldn't want to change jobs now, because I like the company, I'd just like a fair salary on a par with that of my colleagues.", "author_fullname": "t2_mjzy4r5fx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to ask for a salary increase that I deserve", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk5tkj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711025592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m 27(F) and I&amp;#39;ve been working in data engineering for a good 5 years now. I recently started working for a Canadian company where I already knew my boss from another place we worked together. When we were discussing the opportunity he had told me that the salary would be around 7500 dollars a month, but after a conversation with the founders of the company I received the offer with a salary of 5800, but I managed to cry for 6500. From what my boss said, it was because Canadians think I&amp;#39;m too young, but I&amp;#39;m sure part of it was because I&amp;#39;m a woman too.&lt;/p&gt;\n\n&lt;p&gt;Now that I&amp;#39;ve been with the company for a year, I&amp;#39;ve made some great deliveries and I give a lot of support to other people whose technical level is well below mine, but who earn more, I&amp;#39;d like to ask for a decent raise. I&amp;#39;ve already talked to my boss, but he tells me to be patient because HR is working on a career plan, but that should take another 6 months at least.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like some help in approaching my boss more firmly, but without sounding like an ultimatum. I&amp;#39;d like him to talk directly to the founders, as I think this would make it easier to get a raise (the founders are aware of the work I&amp;#39;ve been doing).&lt;/p&gt;\n\n&lt;p&gt;I wouldn&amp;#39;t want to change jobs now, because I like the company, I&amp;#39;d just like a fair salary on a par with that of my colleagues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bk5tkj", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Engineering-5752", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk5tkj/how_to_ask_for_a_salary_increase_that_i_deserve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk5tkj/how_to_ask_for_a_salary_increase_that_i_deserve/", "subreddit_subscribers": 170661, "created_utc": 1711025592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apologies if this is not the right sub, but I feel like this is relevant.\n\nWhat, in your opinion, should be the responsibilities of a \u2018Head of Data\u2019 position? \n\nWhat does an ideal Head of Data do, and more importantly, what do they not do?\n\nI understand that the responsibilities can vary between industries and organisations but still want to get an idea since it\u2019s such a vague title. \n\nThanks. ", "author_fullname": "t2_v97o8gu4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the responsibilities of a \u2018Head of Data\u2019?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjss49", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710979618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this is not the right sub, but I feel like this is relevant.&lt;/p&gt;\n\n&lt;p&gt;What, in your opinion, should be the responsibilities of a \u2018Head of Data\u2019 position? &lt;/p&gt;\n\n&lt;p&gt;What does an ideal Head of Data do, and more importantly, what do they not do?&lt;/p&gt;\n\n&lt;p&gt;I understand that the responsibilities can vary between industries and organisations but still want to get an idea since it\u2019s such a vague title. &lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjss49", "is_robot_indexable": true, "report_reasons": null, "author": "Useful_Foundation_42", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjss49/what_are_the_responsibilities_of_a_head_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjss49/what_are_the_responsibilities_of_a_head_of_data/", "subreddit_subscribers": 170661, "created_utc": 1710979618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a DE, and the Devops engineer supporting my team is leaving for a new job. My manager asked me if I would be interested in skilling up for that role. The Devops engineer would be supporting my team and 2 other teams.\n\nThis is my exp so far: \n\n* Previous job - BI work for 3 yrs \n* Current job - DE(70%) and BI (30%) for the last 5 yrs\n\nMy DE work is building and maintaining pipelines in AWS. Working on DB enhancements, ETL etc. We don't have any Big Data, I would call it small/medium data.\n\nIdeally I would like to upskill next with Databricks, pyspark etc. But my company has no need of any Big Data tools. And the option to upskill in Devops is open now.\n\nI'm somewhat familiar with the IAC and CICD tools my team uses, but there will be a lot to learn, especially to support other teams. I'm not sure if this is a good career move.\n\nOther option I'm considering is to look for other jobs in the Big Data space, so I can continue to gain more deep DE expertise.", "author_fullname": "t2_tcw9022g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opportunity to switch to DevOps at my workplace. Should I take it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjv3fk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710986367.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710985972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a DE, and the Devops engineer supporting my team is leaving for a new job. My manager asked me if I would be interested in skilling up for that role. The Devops engineer would be supporting my team and 2 other teams.&lt;/p&gt;\n\n&lt;p&gt;This is my exp so far: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Previous job - BI work for 3 yrs &lt;/li&gt;\n&lt;li&gt;Current job - DE(70%) and BI (30%) for the last 5 yrs&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My DE work is building and maintaining pipelines in AWS. Working on DB enhancements, ETL etc. We don&amp;#39;t have any Big Data, I would call it small/medium data.&lt;/p&gt;\n\n&lt;p&gt;Ideally I would like to upskill next with Databricks, pyspark etc. But my company has no need of any Big Data tools. And the option to upskill in Devops is open now.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m somewhat familiar with the IAC and CICD tools my team uses, but there will be a lot to learn, especially to support other teams. I&amp;#39;m not sure if this is a good career move.&lt;/p&gt;\n\n&lt;p&gt;Other option I&amp;#39;m considering is to look for other jobs in the Big Data space, so I can continue to gain more deep DE expertise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bjv3fk", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Conversation48", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjv3fk/opportunity_to_switch_to_devops_at_my_workplace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjv3fk/opportunity_to_switch_to_devops_at_my_workplace/", "subreddit_subscribers": 170661, "created_utc": 1710985972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to get opinions on what I could've done better here.\n\nI am mid level data consultant. A little over a year ago a client approached us, I was the most senior person on this one and was kinda left on my own.\n\nBasically his company was launching a new subsidiary (brand) and app to go with it. He wanted proper dashboards and reporting in place from day 1, so no exports and spreadsheets.\n\nHe had the app running on flutter, MS SQL DB, an ERP system and at some stage was going to get a CRM system.\n\nWith limited funds he needed a proof of concept, that would form the basis of Enterprise reporting in future.\n\nWe started with reporting for the app database. So new users, products, revenue, etc.\n\nI proposed migrating the SQL DB to AWS S3 and using Athena for queries and connecting to Tableau for dashboards. Granted we could have just plugged Tableau into the DB but the idea was that in future we would migrate data from the other sources to S3 and then we could start running queries across data sets.\n\nI recently found out he has decommissioned all of this and is getting the app dev team to build dashboards directly into the admin portal.\n\nWas my solution bad?\n\nIn hindsight maybe I could've used a virtualization tool like Denodo or Azure Data fabric to achieve the same result. Or gone with a smaller POC and just plugged in Tableau.\n\n\n", "author_fullname": "t2_jvfyd0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Client replaced my solution, want opinions on what I could've changed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk1870", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711007616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to get opinions on what I could&amp;#39;ve done better here.&lt;/p&gt;\n\n&lt;p&gt;I am mid level data consultant. A little over a year ago a client approached us, I was the most senior person on this one and was kinda left on my own.&lt;/p&gt;\n\n&lt;p&gt;Basically his company was launching a new subsidiary (brand) and app to go with it. He wanted proper dashboards and reporting in place from day 1, so no exports and spreadsheets.&lt;/p&gt;\n\n&lt;p&gt;He had the app running on flutter, MS SQL DB, an ERP system and at some stage was going to get a CRM system.&lt;/p&gt;\n\n&lt;p&gt;With limited funds he needed a proof of concept, that would form the basis of Enterprise reporting in future.&lt;/p&gt;\n\n&lt;p&gt;We started with reporting for the app database. So new users, products, revenue, etc.&lt;/p&gt;\n\n&lt;p&gt;I proposed migrating the SQL DB to AWS S3 and using Athena for queries and connecting to Tableau for dashboards. Granted we could have just plugged Tableau into the DB but the idea was that in future we would migrate data from the other sources to S3 and then we could start running queries across data sets.&lt;/p&gt;\n\n&lt;p&gt;I recently found out he has decommissioned all of this and is getting the app dev team to build dashboards directly into the admin portal.&lt;/p&gt;\n\n&lt;p&gt;Was my solution bad?&lt;/p&gt;\n\n&lt;p&gt;In hindsight maybe I could&amp;#39;ve used a virtualization tool like Denodo or Azure Data fabric to achieve the same result. Or gone with a smaller POC and just plugged in Tableau.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk1870", "is_robot_indexable": true, "report_reasons": null, "author": "FlyContrapuntist", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk1870/client_replaced_my_solution_want_opinions_on_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk1870/client_replaced_my_solution_want_opinions_on_what/", "subreddit_subscribers": 170661, "created_utc": 1711007616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don't know if these kind of posts are allowed or not, but I truly want to admire how this community is very helpful and feels like home, whenever I am stuck in something I just come here and search for a special topic.\n\nMany posts and comments have been helpful to my starting career in Data Engineering, at first I was lost and overwhelmed, but things got clearer once I joined r/dataengineering.\n\nI am still learning day by day, and looking forward to becoming a data engineer, good luck to everybody who's chasing a dream.\n", "author_fullname": "t2_43bjqfmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Appreciation Post - Thank you guys!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjpg6d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710971248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know if these kind of posts are allowed or not, but I truly want to admire how this community is very helpful and feels like home, whenever I am stuck in something I just come here and search for a special topic.&lt;/p&gt;\n\n&lt;p&gt;Many posts and comments have been helpful to my starting career in Data Engineering, at first I was lost and overwhelmed, but things got clearer once I joined &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I am still learning day by day, and looking forward to becoming a data engineer, good luck to everybody who&amp;#39;s chasing a dream.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjpg6d", "is_robot_indexable": true, "report_reasons": null, "author": "WadieXkiller", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjpg6d/appreciation_post_thank_you_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjpg6d/appreciation_post_thank_you_guys/", "subreddit_subscribers": 170661, "created_utc": 1710971248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019ve been looking for passion as 8 years ago when I started to program in Java for a bank company, during this time I\u2019ve realized I always had been involved in projects of the same kind, you know a monolithic application with lasa\u00f1a pattern to fetch data or insert data or update in a multiple tables on the database. Since 4 years micro services appeared as the revolutionary vision to build business applications and well we now have to be proficient troubleshooting issues on kubernetes. But in the core is the same, a vast set of microservices with its databases and patterns just doing a CRUD operations.\n\nI\u2019m a software engineer working with Java, and I\u2019ve been working with Java version 8 for the last 5 years. Yes I am here to capitulate that too less companies are migrating to Java 17 for example.\n\nNowadays I started to be interested in C# and Dotnet, when I tasted some C# elegant code I felt excited again, because the new features of the language and how it is curated the ecosystem around dotnet.\n\nWhen I was a teenager I was a Linux fan boy terrorizing hard disks with Windows and formatting them with a Linux distro, the perfect anti-Microsoft guy. But when you start to work in the real world and you\u2019re enough mature, you start to see things in a pragmatic way. \n\nMy questions here is:\n\n1.- how do you keep interested despite mostly of the projects that you\u2019re involved are not necessarily exciting things that implies you have to learn new cool stuff? Such as cloud services, new tools or new versions of the framework and programming language!\n\n2.- I\u2019m thinking in doing a horizontal movement and try to get a position as dotnet developer or maybe data engineer with Python to challenge myself or c++ templates or Scala to be a functional ninja, do you believe am I being biased with my own opinions?\n", "author_fullname": "t2_t2gmvsvk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m tired of the same kind of projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjprcv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710971996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019ve been looking for passion as 8 years ago when I started to program in Java for a bank company, during this time I\u2019ve realized I always had been involved in projects of the same kind, you know a monolithic application with lasa\u00f1a pattern to fetch data or insert data or update in a multiple tables on the database. Since 4 years micro services appeared as the revolutionary vision to build business applications and well we now have to be proficient troubleshooting issues on kubernetes. But in the core is the same, a vast set of microservices with its databases and patterns just doing a CRUD operations.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a software engineer working with Java, and I\u2019ve been working with Java version 8 for the last 5 years. Yes I am here to capitulate that too less companies are migrating to Java 17 for example.&lt;/p&gt;\n\n&lt;p&gt;Nowadays I started to be interested in C# and Dotnet, when I tasted some C# elegant code I felt excited again, because the new features of the language and how it is curated the ecosystem around dotnet.&lt;/p&gt;\n\n&lt;p&gt;When I was a teenager I was a Linux fan boy terrorizing hard disks with Windows and formatting them with a Linux distro, the perfect anti-Microsoft guy. But when you start to work in the real world and you\u2019re enough mature, you start to see things in a pragmatic way. &lt;/p&gt;\n\n&lt;p&gt;My questions here is:&lt;/p&gt;\n\n&lt;p&gt;1.- how do you keep interested despite mostly of the projects that you\u2019re involved are not necessarily exciting things that implies you have to learn new cool stuff? Such as cloud services, new tools or new versions of the framework and programming language!&lt;/p&gt;\n\n&lt;p&gt;2.- I\u2019m thinking in doing a horizontal movement and try to get a position as dotnet developer or maybe data engineer with Python to challenge myself or c++ templates or Scala to be a functional ninja, do you believe am I being biased with my own opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bjprcv", "is_robot_indexable": true, "report_reasons": null, "author": "Swimming-Ad-9848", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjprcv/im_tired_of_the_same_kind_of_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjprcv/im_tired_of_the_same_kind_of_projects/", "subreddit_subscribers": 170661, "created_utc": 1710971996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, this question might be a bit out of context for this sub but I'm really confused and don't know what to do :\n\nSo im a 4th Year software engineering student(out of 5 years in total) and up until this point I've been focusing only on software development and all the projects internships I did consisted mainly of web, mobile development and recently I started to get introduced to data engineering and data analysis as they added some new subjects to the curriculum and I sort of liked them but I don't know if it would be a better career path If I shift my focus to data engineering instead of focusing solely on software develoment, \nPlease help me I need advices and opinions.\n", "author_fullname": "t2_kjvbhqyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SWE vs Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk5yyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711026058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, this question might be a bit out of context for this sub but I&amp;#39;m really confused and don&amp;#39;t know what to do :&lt;/p&gt;\n\n&lt;p&gt;So im a 4th Year software engineering student(out of 5 years in total) and up until this point I&amp;#39;ve been focusing only on software development and all the projects internships I did consisted mainly of web, mobile development and recently I started to get introduced to data engineering and data analysis as they added some new subjects to the curriculum and I sort of liked them but I don&amp;#39;t know if it would be a better career path If I shift my focus to data engineering instead of focusing solely on software develoment, \nPlease help me I need advices and opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bk5yyi", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic_Battle876", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk5yyi/swe_vs_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk5yyi/swe_vs_data_engineer/", "subreddit_subscribers": 170661, "created_utc": 1711026058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I currently new in this field and want to ask for some advice on this problem.\n\n  \nGiven N items (N \\~ 10\\^8), each item has a list of unique items that is \"related\" to it. The average size of the \"related\" list of an item is about 10^3. The problem is, each time, a list of items is given with size \\~ 10\\^3 items, we have to return the number of unique items in the concatenated list of all the \"related\" items of at least 1 item in the given list.\n\n* Input: Each line is the item id and its \"related\" items. So the input matrix is around 10\\^8 \\* 10\\^3. \n* Output:\n   * When given a list of X (X \\~ 10\\^3) items, we have to concatenate the lists of \"related\" items of X items, and return the number of unique items.\n   * For each query, the inference time is &lt;= 1s.\n\nExample:\n\nInput: \n\n1 2 3 4\n\n2 1 3 5\n\n3 1 2\n\n4 2 5\n\n5 1 4\n\nSo the item 1 is related to 2, 3, 4. item 2 is related to 1, 3, 5. item 3 is related to 1, 2 and so on.  \nIf the query is (1, 4), then the answer is 4. (the list is (2, 3, 4, 5) = (2, 3, 4) + (2, 5)).\n\n&amp;#x200B;\n\nRequirements:\n\n* Exact solution with inference time &lt;= 1s\n* Cannot use cloud computing (must run with my own hardwares)\n\nPriority (top to bottom is most prioritized to least)\n\n* Inference time\n* Use the least memory\n* Simplicity\n* Scalability...\n\nWhat might be the most probable solutions for this? Thanks in advance.  \n", "author_fullname": "t2_mnodayhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help on a data problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk10ch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711019029.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711006646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I currently new in this field and want to ask for some advice on this problem.&lt;/p&gt;\n\n&lt;p&gt;Given N items (N ~ 10^8), each item has a list of unique items that is &amp;quot;related&amp;quot; to it. The average size of the &amp;quot;related&amp;quot; list of an item is about 10&lt;sup&gt;3.&lt;/sup&gt; The problem is, each time, a list of items is given with size ~ 10^3 items, we have to return the number of unique items in the concatenated list of all the &amp;quot;related&amp;quot; items of at least 1 item in the given list.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Input: Each line is the item id and its &amp;quot;related&amp;quot; items. So the input matrix is around 10^8 * 10^3. &lt;/li&gt;\n&lt;li&gt;Output:\n\n&lt;ul&gt;\n&lt;li&gt;When given a list of X (X ~ 10^3) items, we have to concatenate the lists of &amp;quot;related&amp;quot; items of X items, and return the number of unique items.&lt;/li&gt;\n&lt;li&gt;For each query, the inference time is &amp;lt;= 1s.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;p&gt;Input: &lt;/p&gt;\n\n&lt;p&gt;1 2 3 4&lt;/p&gt;\n\n&lt;p&gt;2 1 3 5&lt;/p&gt;\n\n&lt;p&gt;3 1 2&lt;/p&gt;\n\n&lt;p&gt;4 2 5&lt;/p&gt;\n\n&lt;p&gt;5 1 4&lt;/p&gt;\n\n&lt;p&gt;So the item 1 is related to 2, 3, 4. item 2 is related to 1, 3, 5. item 3 is related to 1, 2 and so on.&lt;br/&gt;\nIf the query is (1, 4), then the answer is 4. (the list is (2, 3, 4, 5) = (2, 3, 4) + (2, 5)).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Exact solution with inference time &amp;lt;= 1s&lt;/li&gt;\n&lt;li&gt;Cannot use cloud computing (must run with my own hardwares)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Priority (top to bottom is most prioritized to least)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Inference time&lt;/li&gt;\n&lt;li&gt;Use the least memory&lt;/li&gt;\n&lt;li&gt;Simplicity&lt;/li&gt;\n&lt;li&gt;Scalability...&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What might be the most probable solutions for this? Thanks in advance.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk10ch", "is_robot_indexable": true, "report_reasons": null, "author": "HynDuf", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk10ch/need_help_on_a_data_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk10ch/need_help_on_a_data_problem/", "subreddit_subscribers": 170661, "created_utc": 1711006646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cv0bgwia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The \"pip install data stack\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjocci", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pphqVCmxbqn1pMnDKrbb2nYf-sxcLUVfKLcu8QNu3A8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710968603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "juhache.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://juhache.substack.com/p/pip-install-data-stack?utm_source=profile&amp;utm_medium=reader2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?auto=webp&amp;s=15736a469b20e0fafd0c66c92e66155a3d7eef23", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5b8d32487b2952672e8aec024faffa293d007f3c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=870810e83dfb54b3568a08c9505310fd11e984d5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1aeea72fbcb0b0ee3eb48c170e73818a359898d7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a29a2f6f395e438549df7e225b92cbbd70f2016", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d01b9c2261e6b5055cf4c63534fd0ea8fbd9b244", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/BKWOY3ALoHTW5hyBvPWvV57AYYlgDhzZpppkt5z4zr0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=52a12844b751038786595eb4cd9450a280bc301e", "width": 1080, "height": 540}], "variants": {}, "id": "HgYkgiKoJ3K5IxWmSmkKBeQvq9pr8QAtn3nH0djST3I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bjocci", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant_Type_4547", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjocci/the_pip_install_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://juhache.substack.com/p/pip-install-data-stack?utm_source=profile&amp;utm_medium=reader2", "subreddit_subscribers": 170661, "created_utc": 1710968603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has a mix of GCP/on-prem architecture : \n\n\\- for all our streaming jobs on GCP we use Apache Beam (Java/Python) + Dataflow\n\n\\- for on-prem streaming jobs we implemented custom python consumers\n\nAs part of the revamp of these consumer jobs, we want to harmonize the technologies in the data and software engineering teams.  \n\n\nWe are a bit frustrated with Beam, as a lot of features are only available in Java, and it is sometimes overkill for some use cases (just tasks doing simple transformations). Also, running Beam on-premise is not the simplest task (we need Apache Flink for that).  \n\n\nWe tried looking at alternatives, and we wondered if there were some limitations using python consumers instead of using a tool like Spark/Beam/Flink ?  \n\n\n[https://www.benthos.dev/](https://www.benthos.dev/) is really interesting to us, are there similar interesting alternatives out there ? Is anyone running this in production ?", "author_fullname": "t2_6eywks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lightweight alternative to Spark/Flink/Apache Beam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjjdqc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710956386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has a mix of GCP/on-prem architecture : &lt;/p&gt;\n\n&lt;p&gt;- for all our streaming jobs on GCP we use Apache Beam (Java/Python) + Dataflow&lt;/p&gt;\n\n&lt;p&gt;- for on-prem streaming jobs we implemented custom python consumers&lt;/p&gt;\n\n&lt;p&gt;As part of the revamp of these consumer jobs, we want to harmonize the technologies in the data and software engineering teams.  &lt;/p&gt;\n\n&lt;p&gt;We are a bit frustrated with Beam, as a lot of features are only available in Java, and it is sometimes overkill for some use cases (just tasks doing simple transformations). Also, running Beam on-premise is not the simplest task (we need Apache Flink for that).  &lt;/p&gt;\n\n&lt;p&gt;We tried looking at alternatives, and we wondered if there were some limitations using python consumers instead of using a tool like Spark/Beam/Flink ?  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.benthos.dev/\"&gt;https://www.benthos.dev/&lt;/a&gt; is really interesting to us, are there similar interesting alternatives out there ? Is anyone running this in production ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?auto=webp&amp;s=dbd4e50acf2c42d60ce3d39f04de3a52639fb9ce", "width": 640, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4225757574c6f331afa17e7c5589f1b146d7932c", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b36b2bb69cda53273dd799d4f7a2b64508879881", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=125d1a6e1ce47ec1981961520cca43f3e73c952d", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/rm37_L98P0m6DxDXw6QAcV7yqkCHMp7rLIGU2vfEWTw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa98a2bdb1c50316ebd0a1ec5426977f9a6e9ed8", "width": 640, "height": 400}], "variants": {}, "id": "8HIkF3M3-DIhSHVbfFusVy2WXvxdYkTp7e1P1xwBbhk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjjdqc", "is_robot_indexable": true, "report_reasons": null, "author": "gfalcone", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bjjdqc/lightweight_alternative_to_sparkflinkapache_beam/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjjdqc/lightweight_alternative_to_sparkflinkapache_beam/", "subreddit_subscribers": 170661, "created_utc": 1710956386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in an org which has a 80 node cluster and run lot of data pipelines (pyspark jobs) at different times. \n\nRecently we have been having lot of issues effectively managing the jobs. There are lot of adhoc analysis which goes on and because of this resource usage reaches more than 80-90%, this results in everything running slow. \n\nI'm trying to come up with a mechanism to notify high resource users.\n\nMy current solution is to run periodic script which check the YRAN resource manager and picks jobs which cross certain threshold, Ex: Cluster usage &gt; 30%, elapsed time &gt; 5hrs etc. \n\nhttps://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html\n\nIs there any better way to do it?", "author_fullname": "t2_bnruv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage/notify usage in the cluster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjxqc2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710993897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in an org which has a 80 node cluster and run lot of data pipelines (pyspark jobs) at different times. &lt;/p&gt;\n\n&lt;p&gt;Recently we have been having lot of issues effectively managing the jobs. There are lot of adhoc analysis which goes on and because of this resource usage reaches more than 80-90%, this results in everything running slow. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to come up with a mechanism to notify high resource users.&lt;/p&gt;\n\n&lt;p&gt;My current solution is to run periodic script which check the YRAN resource manager and picks jobs which cross certain threshold, Ex: Cluster usage &amp;gt; 30%, elapsed time &amp;gt; 5hrs etc. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html\"&gt;https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there any better way to do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bjxqc2", "is_robot_indexable": true, "report_reasons": null, "author": "lazygeek", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjxqc2/how_do_you_managenotify_usage_in_the_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjxqc2/how_do_you_managenotify_usage_in_the_cluster/", "subreddit_subscribers": 170661, "created_utc": 1710993897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my current position (and for personal projects) I find myself doing a lot of bespoke problem solving as team of 1 or 2. Examples:\n\n\\- Scrape and munge some amount (&lt;10GB) of historical data from this website. Have it in a format where we can calculate \\[potential metrics\\] if we want to write about it in the future.\n\n\\- The metrics on this government website don't give us what we need -- monitor the site for updates and trigger a pipeline that downloads the data, calculates our metrics, creates charts, and emails a summary.\n\nThere's no online application, no warehouse, not much technical expertise on the team. The objective is to get the task done in a reliable, maintainable manner while minimizing cost.\n\nI have found myself often favoring a data lake (S3 + medallion architecture) + serverless functions (AWS Lambda). Email alerts when things break, Cloudwatch for monitoring. Feels so ethereal not worrying about servers and databases while still delivering valuable data.\n\nWho else does \"small data engineer\" work and what architecture(s) do you typically use to get the job done?", "author_fullname": "t2_cqvp4nt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small Data Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjjte9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710957457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my current position (and for personal projects) I find myself doing a lot of bespoke problem solving as team of 1 or 2. Examples:&lt;/p&gt;\n\n&lt;p&gt;- Scrape and munge some amount (&amp;lt;10GB) of historical data from this website. Have it in a format where we can calculate [potential metrics] if we want to write about it in the future.&lt;/p&gt;\n\n&lt;p&gt;- The metrics on this government website don&amp;#39;t give us what we need -- monitor the site for updates and trigger a pipeline that downloads the data, calculates our metrics, creates charts, and emails a summary.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s no online application, no warehouse, not much technical expertise on the team. The objective is to get the task done in a reliable, maintainable manner while minimizing cost.&lt;/p&gt;\n\n&lt;p&gt;I have found myself often favoring a data lake (S3 + medallion architecture) + serverless functions (AWS Lambda). Email alerts when things break, Cloudwatch for monitoring. Feels so ethereal not worrying about servers and databases while still delivering valuable data.&lt;/p&gt;\n\n&lt;p&gt;Who else does &amp;quot;small data engineer&amp;quot; work and what architecture(s) do you typically use to get the job done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bjjte9", "is_robot_indexable": true, "report_reasons": null, "author": "udonthave2call", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjjte9/small_data_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjjte9/small_data_architecture/", "subreddit_subscribers": 170661, "created_utc": 1710957457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Note: This isn't about Extract/Load data in delta mode but rather the Transform part.\n\nLet's say I'm loading orders and I'm joining the header and detail together.\n\nI'm trying to figure out how to handle scenarios where either table gets a change.\n\nLet's say the Order header changes, I'd want to reload the entire Order by joining the header/detail but, only the order currently has delta data.\n\nThere's also the scenario where a new order line appears and I need to reload the entire order because, let's say I'm performing window functions or any similar workload.\n\n&amp;#x200B;\n\nI also have scenarios where more than 2 tables get joined together and all of them are deltas.\n\n&amp;#x200B;\n\nI'm currently using SSIS with most of the workload being pure SQL or Stored Procedures.\n\nI'm aware the tool is old and we are looking into new tools but I still need to develop new stuff right now, plus I assume the issue would remain in other tools.\n\n&amp;#x200B;\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_6293r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performing delta/incremental loads with header/detail relationships", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bk8637", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711032214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Note: This isn&amp;#39;t about Extract/Load data in delta mode but rather the Transform part.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I&amp;#39;m loading orders and I&amp;#39;m joining the header and detail together.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out how to handle scenarios where either table gets a change.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say the Order header changes, I&amp;#39;d want to reload the entire Order by joining the header/detail but, only the order currently has delta data.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s also the scenario where a new order line appears and I need to reload the entire order because, let&amp;#39;s say I&amp;#39;m performing window functions or any similar workload.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I also have scenarios where more than 2 tables get joined together and all of them are deltas.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using SSIS with most of the workload being pure SQL or Stored Procedures.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware the tool is old and we are looking into new tools but I still need to develop new stuff right now, plus I assume the issue would remain in other tools.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk8637", "is_robot_indexable": true, "report_reasons": null, "author": "meatmick", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk8637/performing_deltaincremental_loads_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk8637/performing_deltaincremental_loads_with/", "subreddit_subscribers": 170661, "created_utc": 1711032214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I receive a CSV in s3, glue ETL grabs it and transforms the schema and to parquet and drops it back into another bucket and registers the data in the catalog (Athena). Fine.\n\nBut I noticed columns marked for transformation into int data type will get written entirely as nulls if just one row has a null value in that column. If it transforms to float, this is not a problem. Everything is being converted from string, but the csv will have just a blank cell not \u201cnull\u201d or whatever.\n\nAm I missing something here? Is this expected behavior?", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue + Athena Data Catalog, int column all nulls if one row in source data was null but float is fine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjl4fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710960712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I receive a CSV in s3, glue ETL grabs it and transforms the schema and to parquet and drops it back into another bucket and registers the data in the catalog (Athena). Fine.&lt;/p&gt;\n\n&lt;p&gt;But I noticed columns marked for transformation into int data type will get written entirely as nulls if just one row has a null value in that column. If it transforms to float, this is not a problem. Everything is being converted from string, but the csv will have just a blank cell not \u201cnull\u201d or whatever.&lt;/p&gt;\n\n&lt;p&gt;Am I missing something here? Is this expected behavior?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bjl4fq", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjl4fq/aws_glue_athena_data_catalog_int_column_all_nulls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bjl4fq/aws_glue_athena_data_catalog_int_column_all_nulls/", "subreddit_subscribers": 170661, "created_utc": 1710960712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "    FROM python:3.10.6-slim-buster\n    \n    WORKDIR /orchestration\n    \n    COPY . /orchestration\n    \n    RUN apt-get update \\\n        &amp;&amp; apt-get -y install libpq-dev gcc \\\n        &amp;&amp; pip install psycopg2 \\\n        &amp;&amp; pip install --no-cache-dir -r requirements.txt\n    \n    EXPOSE 4200\n    \n    # Run the Python application\n    ENTRYPOINT [\"python\", \"data_orchestration/staging_workloads/main.py\"]\n    RUN prefect server start\n\nI can't build the docker image because it gets stuck in the \"prefect server start\" endlessly. I've seen other repos and I think there is nothing wrong with my code.\n\n&amp;#x200B;\n\nCan you please help me?", "author_fullname": "t2_a9360hkx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help deploying prefect to EC2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk78d2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711029686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;FROM python:3.10.6-slim-buster\n\nWORKDIR /orchestration\n\nCOPY . /orchestration\n\nRUN apt-get update \\\n    &amp;amp;&amp;amp; apt-get -y install libpq-dev gcc \\\n    &amp;amp;&amp;amp; pip install psycopg2 \\\n    &amp;amp;&amp;amp; pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 4200\n\n# Run the Python application\nENTRYPOINT [&amp;quot;python&amp;quot;, &amp;quot;data_orchestration/staging_workloads/main.py&amp;quot;]\nRUN prefect server start\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I can&amp;#39;t build the docker image because it gets stuck in the &amp;quot;prefect server start&amp;quot; endlessly. I&amp;#39;ve seen other repos and I think there is nothing wrong with my code.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can you please help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk78d2", "is_robot_indexable": true, "report_reasons": null, "author": "Different_Fee6785", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk78d2/help_deploying_prefect_to_ec2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk78d2/help_deploying_prefect_to_ec2/", "subreddit_subscribers": 170661, "created_utc": 1711029686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, maybe you have faced this. I have to send some data to an endpoint where the batch size limit is 10k, we were doing ok using python on airflow (single core) but now the data size increased to 10M so it\u2019s taking too long because of the 1000s requests\n\nWe could use spark but I would like to avoid it (as 10M fits in one worker perfectly) but not sure how, not really used to python multi threading or how to implement on airflow ", "author_fullname": "t2_79l5nq82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paralelize requests to insert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk57gv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711023575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, maybe you have faced this. I have to send some data to an endpoint where the batch size limit is 10k, we were doing ok using python on airflow (single core) but now the data size increased to 10M so it\u2019s taking too long because of the 1000s requests&lt;/p&gt;\n\n&lt;p&gt;We could use spark but I would like to avoid it (as 10M fits in one worker perfectly) but not sure how, not really used to python multi threading or how to implement on airflow &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bk57gv", "is_robot_indexable": true, "report_reasons": null, "author": "Obvious-Phrase-657", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk57gv/paralelize_requests_to_insert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk57gv/paralelize_requests_to_insert/", "subreddit_subscribers": 170661, "created_utc": 1711023575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am the only data engineer at a small company with not too much experience, and I have to figure out a system to supply the data for our BI platform and other reports, from various sources (APIs, csv files, SQL databases, etc.).\n\nI looked around and I found Apache NiFi (which has already been recommended by other people on this sub). I've already played around with it a little bit and it seems to be what I'm looking for. It was also important that I can run python scripts with any dependencies, and it seems to be allowing it through the ExecuteStreamCommand processor, but what I don't know is how I should organize these scripts and where to store them.\n\nWe will run NiFi in Kubernetes, and according to our DevOps guy, it would be very bad practice if we just kept adding these python scripts / virtual environments (in case we really need that complexity) to the container of NiFi. \n\nWhat would be the best practice here? We want to keep the python scripts version controlled, so it would be pushed to our own gitlab. Of course we don't want to deploy each python script individually and create a bunch of pods either, but we're struggling to find our way.\n\nThank you in advance!", "author_fullname": "t2_bcsbesiv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing scripts in Apache NiFi", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk45ct", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711019860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am the only data engineer at a small company with not too much experience, and I have to figure out a system to supply the data for our BI platform and other reports, from various sources (APIs, csv files, SQL databases, etc.).&lt;/p&gt;\n\n&lt;p&gt;I looked around and I found Apache NiFi (which has already been recommended by other people on this sub). I&amp;#39;ve already played around with it a little bit and it seems to be what I&amp;#39;m looking for. It was also important that I can run python scripts with any dependencies, and it seems to be allowing it through the ExecuteStreamCommand processor, but what I don&amp;#39;t know is how I should organize these scripts and where to store them.&lt;/p&gt;\n\n&lt;p&gt;We will run NiFi in Kubernetes, and according to our DevOps guy, it would be very bad practice if we just kept adding these python scripts / virtual environments (in case we really need that complexity) to the container of NiFi. &lt;/p&gt;\n\n&lt;p&gt;What would be the best practice here? We want to keep the python scripts version controlled, so it would be pushed to our own gitlab. Of course we don&amp;#39;t want to deploy each python script individually and create a bunch of pods either, but we&amp;#39;re struggling to find our way.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk45ct", "is_robot_indexable": true, "report_reasons": null, "author": "csicskagyasz00", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk45ct/organizing_scripts_in_apache_nifi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk45ct/organizing_scripts_in_apache_nifi/", "subreddit_subscribers": 170661, "created_utc": 1711019860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is general best practice to store additional data related to devices etc.\n\nFor example  \nA customer has an asset (A factory building) where many temperature sensors are installed.  \nAlong with time series for each sensor, we need to store additional data about devices and asset,  \nfor example\n\n* Device Id (generated when device was provisioned), device description, manufacturer, installation date etc\n* Device location coordinates\n* Factory building related meta data\n\nDo ppl use another relational db togather with timeseries db to store this kind of data ?  \nWhat is general best practice, how others do it ?", "author_fullname": "t2_mpnco", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for storing additional data for timeseries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk3m6f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711017867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is general best practice to store additional data related to devices etc.&lt;/p&gt;\n\n&lt;p&gt;For example&lt;br/&gt;\nA customer has an asset (A factory building) where many temperature sensors are installed.&lt;br/&gt;\nAlong with time series for each sensor, we need to store additional data about devices and asset,&lt;br/&gt;\nfor example&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Device Id (generated when device was provisioned), device description, manufacturer, installation date etc&lt;/li&gt;\n&lt;li&gt;Device location coordinates&lt;/li&gt;\n&lt;li&gt;Factory building related meta data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Do ppl use another relational db togather with timeseries db to store this kind of data ?&lt;br/&gt;\nWhat is general best practice, how others do it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk3m6f", "is_robot_indexable": true, "report_reasons": null, "author": "snimavat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk3m6f/best_practices_for_storing_additional_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk3m6f/best_practices_for_storing_additional_data_for/", "subreddit_subscribers": 170661, "created_utc": 1711017867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \nI am currently trying to run Spark through Docker as part of my learning journey. It's giving me a bit of a headache though. Therefore, here I am, asking for some knowledge I know I'm missing.\n\nThe goal: Get Spark UI to work in order to analyze how tasks are handled  \nPurpose: Get Spark to work as part of a larger Apache Airflow setup.\n\nProblems:\n\n* Not sure I understand the difference between a Spark Master and a standalone Spark Cluster that has access to Spark UI. Is the Spark Master UI a 1:1 functionality match for Spark UI? Is it something different altogether?\n* Not sure if using the bitnami version of the docker image is the best way forward. How do you set it up usually (or do you go for another version)?\n* What is not right in the way I set up my spark?\n* Is there a need for a Spark UI dedicated container?\n\nBonus round:\n\n* While exploring worker tasks I get hit with web addresses I can't access (either localhost/172.x.x.x type of networks or docker internal links). How can I work my way around that?  \nKubernetes seems to be a suggested solution but I am still unsure if I should go ahead and sink into that.\n\nIf anyone sees this and answers, it would make my day. Thank you very much! :)\n\nFor reference, this is a snippet under services of how I set it up:\n\n \n\n`spark-ui:`  \n `image: bitnami/spark:latest`  \n `environment:`  \n `# needs to be updated whenever I relocate the raspberry pi`  \n `SPARK_DRIVER_HOST: \"0.0.0.0\"`  \n `SPARK_DRIVER_BINDADDRESS: \"0.0.0.0\"`  \n `SPARK_MASTER: spark://spark-master:7077`  \n `MAIN_CLASS: Main`  \n `ports:`  \n`- \"4040:4040\"`  \n`- \"4041:8080\"`  \n `networks:`  \n`- spark-network`  \n   \n `spark-master:`  \n `image: bitnami/spark:latest`  \n `ports:`  \n`- \"9092:8080\"`  \n`- \"7077:7077\"`  \n`- \"4043:4040\"`  \n`- \"8998:8998\"`  \n`- \"8887:8888\"`  \n `networks:`  \n`- spark-network`  \n `spark-worker-1:`  \n `image: bitnami/spark:latest`  \n `depends_on:`  \n`- spark-master`  \n `environment:`  \n `SPARK_MODE: worker`  \n `SPARK_WORKER_CORES: 1`  \n `SPARK_WORKER_MEMORY: 4g`  \n `SPARK_MASTER_URL: spark://spark-master:7077`  \n `ports:`  \n`- \"8081:8081\"`  \n`- \"4042:4040\"`  \n `networks:`  \n`- spark-network`  \n `# # spark-worker-2:`  \n `# # \u00a0 \u00a0 image: apache/spark-py:latest`  \n `# # \u00a0 \u00a0 depends_on:`  \n `# # \u00a0 \u00a0 \u00a0 - spark-master`  \n `# # \u00a0 \u00a0 environment:`  \n `# # \u00a0 \u00a0 \u00a0 SPARK_MODE: worker`  \n `# # \u00a0 \u00a0 \u00a0 SPARK_WORKER_CORES: 1`  \n `# # \u00a0 \u00a0 \u00a0 SPARK_WORKER_MEMORY: 4g`  \n `# # \u00a0 \u00a0 \u00a0 SPARK_MASTER_URL: spark://spark-master:7077`  \n `# # \u00a0 \u00a0 networks:`  \n `# # \u00a0 \u00a0 \u00a0 - spark-network`  \n `# # \u00a0 \u00a0 ports:`  \n `# # \u00a0 \u00a0 \u00a0 - \"8082:8081\"`  \n `# # \u00a0 \u00a0 \u00a0 - \"4043:4040\"`  \n`volumes:`  \n `spark-data:`  \n `name: spark-data`  \n`networks:`  \n `spark-network:`  \n `name: spark-network`", "author_fullname": "t2_n75h7s91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark docker-compose questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk11x5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711006845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;br/&gt;\nI am currently trying to run Spark through Docker as part of my learning journey. It&amp;#39;s giving me a bit of a headache though. Therefore, here I am, asking for some knowledge I know I&amp;#39;m missing.&lt;/p&gt;\n\n&lt;p&gt;The goal: Get Spark UI to work in order to analyze how tasks are handled&lt;br/&gt;\nPurpose: Get Spark to work as part of a larger Apache Airflow setup.&lt;/p&gt;\n\n&lt;p&gt;Problems:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Not sure I understand the difference between a Spark Master and a standalone Spark Cluster that has access to Spark UI. Is the Spark Master UI a 1:1 functionality match for Spark UI? Is it something different altogether?&lt;/li&gt;\n&lt;li&gt;Not sure if using the bitnami version of the docker image is the best way forward. How do you set it up usually (or do you go for another version)?&lt;/li&gt;\n&lt;li&gt;What is not right in the way I set up my spark?&lt;/li&gt;\n&lt;li&gt;Is there a need for a Spark UI dedicated container?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Bonus round:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;While exploring worker tasks I get hit with web addresses I can&amp;#39;t access (either localhost/172.x.x.x type of networks or docker internal links). How can I work my way around that?&lt;br/&gt;\nKubernetes seems to be a suggested solution but I am still unsure if I should go ahead and sink into that.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If anyone sees this and answers, it would make my day. Thank you very much! :)&lt;/p&gt;\n\n&lt;p&gt;For reference, this is a snippet under services of how I set it up:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;spark-ui:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;image: bitnami/spark:latest&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;environment:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# needs to be updated whenever I relocate the raspberry pi&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_DRIVER_HOST: &amp;quot;0.0.0.0&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_DRIVER_BINDADDRESS: &amp;quot;0.0.0.0&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_MASTER: spark://spark-master:7077&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;MAIN_CLASS: Main&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;ports:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;4040:4040&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;4041:8080&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;networks:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- spark-network&lt;/code&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;spark-master:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;image: bitnami/spark:latest&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;ports:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;9092:8080&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;7077:7077&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;4043:4040&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;8998:8998&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;8887:8888&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;networks:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- spark-network&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;spark-worker-1:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;image: bitnami/spark:latest&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;depends_on:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- spark-master&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;environment:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_MODE: worker&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_WORKER_CORES: 1&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_WORKER_MEMORY: 4g&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;SPARK_MASTER_URL: spark://spark-master:7077&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;ports:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;8081:8081&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- &amp;quot;4042:4040&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;networks:&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;- spark-network&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # spark-worker-2:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 image: apache/spark-py:latest&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 depends_on:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 - spark-master&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 environment:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 SPARK_MODE: worker&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 SPARK_WORKER_CORES: 1&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 SPARK_WORKER_MEMORY: 4g&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 SPARK_MASTER_URL: spark://spark-master:7077&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 networks:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 - spark-network&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 ports:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 - &amp;quot;8082:8081&amp;quot;&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;# # \u00a0 \u00a0 \u00a0 - &amp;quot;4043:4040&amp;quot;&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;volumes:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;spark-data:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;name: spark-data&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;networks:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;spark-network:&lt;/code&gt;&lt;br/&gt;\n &lt;code&gt;name: spark-network&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk11x5", "is_robot_indexable": true, "report_reasons": null, "author": "Cheeky-owlet", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk11x5/spark_dockercompose_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk11x5/spark_dockercompose_questions/", "subreddit_subscribers": 170661, "created_utc": 1711006845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Organizations worldwide are beginning to adopt cloud services. As a result, the painstaking task of moving data from on-premises to the cloud has been on the rise for most data professionals. Using the best platform and technique for moving data is more crucial than ever.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dynamically Copy Data from SQL Server to Azure SQL Database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1bjq03j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XPU6bmXFj3dIwCRltaJZpzyh75rfsjMpXhIbZTcGl8o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710972576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mssqltips.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Organizations worldwide are beginning to adopt cloud services. As a result, the painstaking task of moving data from on-premises to the cloud has been on the rise for most data professionals. Using the best platform and technique for moving data is more crucial than ever.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.mssqltips.com/sqlservertip/7930/dynamically-copy-data-from-sql-server-to-azure-sql-database/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4as0vR77w12xHGdca3bTZ4ZKQ7QoIn87pOQTI6MP8ZY.jpg?auto=webp&amp;s=bb6ab315d6ad8d448475682631933776c28fcbd5", "width": 350, "height": 175}, "resolutions": [{"url": "https://external-preview.redd.it/4as0vR77w12xHGdca3bTZ4ZKQ7QoIn87pOQTI6MP8ZY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fcf3745a310ac962912e3d90f2edc6939be21be4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4as0vR77w12xHGdca3bTZ4ZKQ7QoIn87pOQTI6MP8ZY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=406646b3ad9401edf23c99ae9a528889bdf96dad", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4as0vR77w12xHGdca3bTZ4ZKQ7QoIn87pOQTI6MP8ZY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=69e715c17629dabdcb0b3e28a8eca949264248ee", "width": 320, "height": 160}], "variants": {}, "id": "0l7rPyIzKjdetiT4rFGw_8krHMvwF9TjI_6syfoZzTg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1bjq03j", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bjq03j/dynamically_copy_data_from_sql_server_to_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.mssqltips.com/sqlservertip/7930/dynamically-copy-data-from-sql-server-to-azure-sql-database/", "subreddit_subscribers": 170661, "created_utc": 1710972576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, we're currently in the process of pushing structured data into a Data Lake, as it currently resides on Azure SQL Server and, at present, is using around 250gb. This would be in a blob storage on Azure.  \n\n\nThe plan is to opt for parquet files, with the data pulling from one database and approx 15 tables. On average, each table has approx 200k rows, none of them are very wide.  \n\n\nI have a couple of questions.  \n\n\nA) Would I be better pulling the data every 15minutes, creating a larger quantity of parquet files, or would I be better doing 1 file for each table, at the end of the day.\n\nB) We'd like to introduce an analytics tool to allow users to query the data, what would be the best tool to run queries directly against the blob storage (therefore avoiding hitting the current SQL instance).  \n\n\n&amp;#x200B;", "author_fullname": "t2_117uqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lake Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk5c9b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711024011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, we&amp;#39;re currently in the process of pushing structured data into a Data Lake, as it currently resides on Azure SQL Server and, at present, is using around 250gb. This would be in a blob storage on Azure.  &lt;/p&gt;\n\n&lt;p&gt;The plan is to opt for parquet files, with the data pulling from one database and approx 15 tables. On average, each table has approx 200k rows, none of them are very wide.  &lt;/p&gt;\n\n&lt;p&gt;I have a couple of questions.  &lt;/p&gt;\n\n&lt;p&gt;A) Would I be better pulling the data every 15minutes, creating a larger quantity of parquet files, or would I be better doing 1 file for each table, at the end of the day.&lt;/p&gt;\n\n&lt;p&gt;B) We&amp;#39;d like to introduce an analytics tool to allow users to query the data, what would be the best tool to run queries directly against the blob storage (therefore avoiding hitting the current SQL instance).  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk5c9b", "is_robot_indexable": true, "report_reasons": null, "author": "iamdawsonz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk5c9b/data_lake_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk5c9b/data_lake_questions/", "subreddit_subscribers": 170661, "created_utc": 1711024011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for information, documentation plus videos preferable in English Apache Doris. This is an upcoming field I am venturing to and would like to have as much info. as possible on the subject matter. ", "author_fullname": "t2_cxzdcift", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk50f2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711022912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for information, documentation plus videos preferable in English Apache Doris. This is an upcoming field I am venturing to and would like to have as much info. as possible on the subject matter. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bk50f2", "is_robot_indexable": true, "report_reasons": null, "author": "Lazy_Secret8626", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk50f2/apache_doris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk50f2/apache_doris/", "subreddit_subscribers": 170661, "created_utc": 1711022912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What topics are interested in hearing about in a podcast, talk, webinar, blog, etc.", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What topic would you like to see a webinar on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk4ixa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711021225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What topics are interested in hearing about in a podcast, talk, webinar, blog, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bk4ixa", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk4ixa/what_topic_would_you_like_to_see_a_webinar_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk4ixa/what_topic_would_you_like_to_see_a_webinar_on/", "subreddit_subscribers": 170661, "created_utc": 1711021225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been preparing for Microsoft's DP-203 certification exam with the modules provided in Microsoft Learn. I came across a specialization (by Microsoft) in coursera, here's the link for it: [https://www.coursera.org/programs/learning-program-for-family-iwira/professional-certificates/microsoft-azure-dp-203-data-engineering](https://www.coursera.org/programs/learning-program-for-family-iwira/professional-certificates/microsoft-azure-dp-203-data-engineering) . \n\nBut the specialization's videos seem a little old. I'm just wondering, is this specialization still relevant for the exam? Has anyone finished it? ", "author_fullname": "t2_lxre77x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this coursera specialization still relevant for DP-203?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bk36hb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711016127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been preparing for Microsoft&amp;#39;s DP-203 certification exam with the modules provided in Microsoft Learn. I came across a specialization (by Microsoft) in coursera, here&amp;#39;s the link for it: &lt;a href=\"https://www.coursera.org/programs/learning-program-for-family-iwira/professional-certificates/microsoft-azure-dp-203-data-engineering\"&gt;https://www.coursera.org/programs/learning-program-for-family-iwira/professional-certificates/microsoft-azure-dp-203-data-engineering&lt;/a&gt; . &lt;/p&gt;\n\n&lt;p&gt;But the specialization&amp;#39;s videos seem a little old. I&amp;#39;m just wondering, is this specialization still relevant for the exam? Has anyone finished it? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nV7A5_FsMAHQvw20NKtxvc_IsTPWnRXa9OqIYeTQrPA.jpg?auto=webp&amp;s=920f7833e299bf4046c7a504d5bea7ff9f2cc80f", "width": 1772, "height": 928}, "resolutions": [{"url": "https://external-preview.redd.it/nV7A5_FsMAHQvw20NKtxvc_IsTPWnRXa9OqIYeTQrPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0933823a8c1fe5ed858cfee0e5b35f535698a0c5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/nV7A5_FsMAHQvw20NKtxvc_IsTPWnRXa9OqIYeTQrPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=411302164a7392cd1e048f9aa2e5dcb918eb0041", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/nV7A5_FsMAHQvw20NKtxvc_IsTPWnRXa9OqIYeTQrPA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8be2978ad9fbf3ea9d12067634993539954ab95a", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/nV7A5_FsMAHQvw20NKtxvc_IsTPWnRXa9OqIYeTQrPA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7df86d0c4c802a3333b7e5a3154e66d7543e9530", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/nV7A5_FsMAHQvw20NKtxvc_IsTPWnRXa9OqIYeTQrPA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87beb89587a2345263acee9fa57bd872964a6cac", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/nV7A5_FsMAHQvw20NKtxvc_IsTPWnRXa9OqIYeTQrPA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f5d1384ac54d4c886a931910a2ba157da06ff67b", "width": 1080, "height": 565}], "variants": {}, "id": "K6_tf2eymuEYVDrxr0Bbnh6G1_3qc-H4clCGf9Gbkls"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bk36hb", "is_robot_indexable": true, "report_reasons": null, "author": "RyanTahnikoyev", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bk36hb/is_this_coursera_specialization_still_relevant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bk36hb/is_this_coursera_specialization_still_relevant/", "subreddit_subscribers": 170661, "created_utc": 1711016127.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}