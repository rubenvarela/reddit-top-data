{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit! I'm a former engineer at FAANG who decided to take the leap and start my own venture. I'm now building Quary, a startup in Y Combinator's Winter 2024 batch. The journey from a mere concept to securing a $500k investment from YC has been filled with a rollercoaster of emotions, countless challenges, and a steep learning curve. I'm here to share my experiences, insights, and the realities of transitioning from an engineering role to entrepreneurship.\n\nFeel free to ask me anything about the journey, the lessons I've learned, or any advice you might need for your own career or startup aspirations!\n\n(And hey, if you happen to check out Quary and find it interesting, [a star on my GitHub repo would be a nice way to show support. No pressure, though](https://github.com/quarylabs/quary)!)", "author_fullname": "t2_dr38sa99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[AMA] From FAANG Data/Software Engineer to YC-Backed Startup Founder - Ask Me Anything!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5986w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709443106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit! I&amp;#39;m a former engineer at FAANG who decided to take the leap and start my own venture. I&amp;#39;m now building Quary, a startup in Y Combinator&amp;#39;s Winter 2024 batch. The journey from a mere concept to securing a $500k investment from YC has been filled with a rollercoaster of emotions, countless challenges, and a steep learning curve. I&amp;#39;m here to share my experiences, insights, and the realities of transitioning from an engineering role to entrepreneurship.&lt;/p&gt;\n\n&lt;p&gt;Feel free to ask me anything about the journey, the lessons I&amp;#39;ve learned, or any advice you might need for your own career or startup aspirations!&lt;/p&gt;\n\n&lt;p&gt;(And hey, if you happen to check out Quary and find it interesting, &lt;a href=\"https://github.com/quarylabs/quary\"&gt;a star on my GitHub repo would be a nice way to show support. No pressure, though&lt;/a&gt;!)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z3I5umYVZc4VFp2I7NWGK4KswTOrEjRG9SLiCiSx0AM.jpg?auto=webp&amp;s=4d97fc1b834dc8f4fe9d77775fcb0d0527251d30", "width": 3942, "height": 1860}, "resolutions": [{"url": "https://external-preview.redd.it/Z3I5umYVZc4VFp2I7NWGK4KswTOrEjRG9SLiCiSx0AM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8ab04d777ec5325e0dbd6f3f03ef3f70edde513", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/Z3I5umYVZc4VFp2I7NWGK4KswTOrEjRG9SLiCiSx0AM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb830e7738dfe5b7f49199ba443f6b2b76baa6b8", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/Z3I5umYVZc4VFp2I7NWGK4KswTOrEjRG9SLiCiSx0AM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=de46e12822c1f9ef4d36efcfbfb7e0173213d1b2", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/Z3I5umYVZc4VFp2I7NWGK4KswTOrEjRG9SLiCiSx0AM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad046cf6ac0917f53429fc322a2830d62328c6d6", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/Z3I5umYVZc4VFp2I7NWGK4KswTOrEjRG9SLiCiSx0AM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=75288aea7cab7ff0831bfa01e0691ccf01b32f65", "width": 960, "height": 452}, {"url": "https://external-preview.redd.it/Z3I5umYVZc4VFp2I7NWGK4KswTOrEjRG9SLiCiSx0AM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c8a8b076a8d355cd22c2694178469bd1dba93b48", "width": 1080, "height": 509}], "variants": {}, "id": "nhZw20xKrHzWoNLPzQEjk1mOth6Y9i2oRMvrwBaoT6Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b5986w", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Call6280", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5986w/ama_from_faang_datasoftware_engineer_to_ycbacked/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5986w/ama_from_faang_datasoftware_engineer_to_ycbacked/", "subreddit_subscribers": 165483, "created_utc": 1709443106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This though suddenly came up when I saw job postings for experienced individuals paying $25 an hour. This is not the norm, but still scary that companies even have such low expectations. Compared to most jobs out there, although the type of work may be fulfilling, And more often employers slap the \"Analyst\" title and get these people for a bargain. I feel that people in this industry are often underpaid compared to the work/skills they bring to the table. What do you all think?", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are Data Engineers underpaid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4v030", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709404052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This though suddenly came up when I saw job postings for experienced individuals paying $25 an hour. This is not the norm, but still scary that companies even have such low expectations. Compared to most jobs out there, although the type of work may be fulfilling, And more often employers slap the &amp;quot;Analyst&amp;quot; title and get these people for a bargain. I feel that people in this industry are often underpaid compared to the work/skills they bring to the table. What do you all think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b4v030", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4v030/are_data_engineers_underpaid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4v030/are_data_engineers_underpaid/", "subreddit_subscribers": 165483, "created_utc": 1709404052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company we are In a Databricks Azure environnement with most of the jobs are ETL jobs curently in python / pyspark", "author_fullname": "t2_uhw0wx8az", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is scala worth to learn as a spark data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b506um", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709417224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company we are In a Databricks Azure environnement with most of the jobs are ETL jobs curently in python / pyspark&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b506um", "is_robot_indexable": true, "report_reasons": null, "author": "randomWasabiEnjoyer", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b506um/is_scala_worth_to_learn_as_a_spark_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b506um/is_scala_worth_to_learn_as_a_spark_data_engineer/", "subreddit_subscribers": 165483, "created_utc": 1709417224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To all data enthusiasts here - a confession from a data engineer - my estimation of data platform setup time failed 100% of the time.\n\nWhat's your experience in building a new data platform? Specifically interested in learning about the time spent in setting up &amp; integrating the essential layers and making it production-ready - warehouse, ingestion, transformation, orchestration, and visualization.\n\nThis might be subjective given the requirements, love to hear about your experiences.", "author_fullname": "t2_6odriz9z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time needed to build a data platform from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b510m2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709419349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To all data enthusiasts here - a confession from a data engineer - my estimation of data platform setup time failed 100% of the time.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your experience in building a new data platform? Specifically interested in learning about the time spent in setting up &amp;amp; integrating the essential layers and making it production-ready - warehouse, ingestion, transformation, orchestration, and visualization.&lt;/p&gt;\n\n&lt;p&gt;This might be subjective given the requirements, love to hear about your experiences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b510m2", "is_robot_indexable": true, "report_reasons": null, "author": "prasadus", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b510m2/time_needed_to_build_a_data_platform_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b510m2/time_needed_to_build_a_data_platform_from_scratch/", "subreddit_subscribers": 165483, "created_utc": 1709419349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Guys,\n\nI am trying to read a .xlsx file in my local mac. I have tried pandas (takes 10 minutes), polars (take 5+ minutes and all the columns get \u201csting\u201d dtype), pyspark won\u2019t let me use pyspark.pandas.read_excel without giving me a type error of \u201csqueeze\u201d.\n\nI also tried data bricks, but Microsoft data bricks has restricted my account to only use 100,000,000 bytes when my file requires 550,000,000 bytes.\n\nPlease give me your suggestion. \n\nThe reason I\u2019m doing this is,  I have 300+ files like this and want to convert all my .xlsx into a data lakehouse, so any senior engineers here please advice me!", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you read .xlsx in general where the file\u2019s shape is (120000,110)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b559ap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709430786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys,&lt;/p&gt;\n\n&lt;p&gt;I am trying to read a .xlsx file in my local mac. I have tried pandas (takes 10 minutes), polars (take 5+ minutes and all the columns get \u201csting\u201d dtype), pyspark won\u2019t let me use pyspark.pandas.read_excel without giving me a type error of \u201csqueeze\u201d.&lt;/p&gt;\n\n&lt;p&gt;I also tried data bricks, but Microsoft data bricks has restricted my account to only use 100,000,000 bytes when my file requires 550,000,000 bytes.&lt;/p&gt;\n\n&lt;p&gt;Please give me your suggestion. &lt;/p&gt;\n\n&lt;p&gt;The reason I\u2019m doing this is,  I have 300+ files like this and want to convert all my .xlsx into a data lakehouse, so any senior engineers here please advice me!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b559ap", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b559ap/how_do_you_read_xlsx_in_general_where_the_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b559ap/how_do_you_read_xlsx_in_general_where_the_files/", "subreddit_subscribers": 165483, "created_utc": 1709430786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We receive a large amount of ad-hoc data from customers that needs to be matched up to authoritative data. Oftentimes, the ad-hoc data doesn\u2019t contain any IDs, and we end up matching via first and last name. I cringe just thinking about it, but we can afford an incorrect match if two people have the same name or to throw out some unmatched data because it\u2019s all aggregated and used for reporting general trends. But I still hate that we do this.\n\nHow have you guys dealt with data where the only keys are people\u2019s names? We can\u2019t fix the source data and populate IDs, as it\u2019s not our data, it\u2019s exported and sent to us. And we process so many files, it\u2019s not feasible to manually handle mismatched names or name conflicts.", "author_fullname": "t2_m0ki4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle data where first and last names are the only \u201ckeys\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5664g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709433446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We receive a large amount of ad-hoc data from customers that needs to be matched up to authoritative data. Oftentimes, the ad-hoc data doesn\u2019t contain any IDs, and we end up matching via first and last name. I cringe just thinking about it, but we can afford an incorrect match if two people have the same name or to throw out some unmatched data because it\u2019s all aggregated and used for reporting general trends. But I still hate that we do this.&lt;/p&gt;\n\n&lt;p&gt;How have you guys dealt with data where the only keys are people\u2019s names? We can\u2019t fix the source data and populate IDs, as it\u2019s not our data, it\u2019s exported and sent to us. And we process so many files, it\u2019s not feasible to manually handle mismatched names or name conflicts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b5664g", "is_robot_indexable": true, "report_reasons": null, "author": "phonyfakeorreal", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5664g/how_to_handle_data_where_first_and_last_names_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5664g/how_to_handle_data_where_first_and_last_names_are/", "subreddit_subscribers": 165483, "created_utc": 1709433446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I'm looking for a great spark course for a data engineer with basic base knowledge who want to go deeper on spark concept, optimization, best practice,...", "author_fullname": "t2_uhw0wx8az", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Spark course in 2024 for medium level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b50a0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709417450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I&amp;#39;m looking for a great spark course for a data engineer with basic base knowledge who want to go deeper on spark concept, optimization, best practice,...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b50a0f", "is_robot_indexable": true, "report_reasons": null, "author": "randomWasabiEnjoyer", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b50a0f/best_spark_course_in_2024_for_medium_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b50a0f/best_spark_course_in_2024_for_medium_level/", "subreddit_subscribers": 165483, "created_utc": 1709417450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks currently I am working as a data migration engineer for the past 1.8 years.This is my first job too.My main job is to analyse different database technologies and maintain SQL script codebase according to business logic.The rest is automated and is just a button click.The pay is decent and I have a great WLB.But the thing is I am not learning anything rather than some business logic which ain't any use to me personally.I am getting guilt that I am wasting my initial years of career cuz that's where all the learning happens.So I have been thinking of job switch,but the problem is I haven't learned anything properly except for a little bit of SQL and c# (noob level mainly chatgpt)for automation tool development.Either way I need to grind to switch, so my question is whether I need to grind on data engineering and switch to data field, but I have been hearing the field is routine mundane and it gets boring after a time and the payment won't build up after certain years.(Is it true?)The switch to data field would be easier path for me as I need to put more effort in learning coding.So experienced people should I switch to data field or transition to a developer role(longer and harder route).What do you all suggest", "author_fullname": "t2_bbadtp3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career decision", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5bclz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709450810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks currently I am working as a data migration engineer for the past 1.8 years.This is my first job too.My main job is to analyse different database technologies and maintain SQL script codebase according to business logic.The rest is automated and is just a button click.The pay is decent and I have a great WLB.But the thing is I am not learning anything rather than some business logic which ain&amp;#39;t any use to me personally.I am getting guilt that I am wasting my initial years of career cuz that&amp;#39;s where all the learning happens.So I have been thinking of job switch,but the problem is I haven&amp;#39;t learned anything properly except for a little bit of SQL and c# (noob level mainly chatgpt)for automation tool development.Either way I need to grind to switch, so my question is whether I need to grind on data engineering and switch to data field, but I have been hearing the field is routine mundane and it gets boring after a time and the payment won&amp;#39;t build up after certain years.(Is it true?)The switch to data field would be easier path for me as I need to put more effort in learning coding.So experienced people should I switch to data field or transition to a developer role(longer and harder route).What do you all suggest&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b5bclz", "is_robot_indexable": true, "report_reasons": null, "author": "Wrong-Oven1077", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5bclz/career_decision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5bclz/career_decision/", "subreddit_subscribers": 165483, "created_utc": 1709450810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want a service which provides an sdk i can through my node js app and it ingests the data in to postgresql. The files will be csv, my current implementations crush the node.js server because they can't fit into memory", "author_fullname": "t2_5nctfhe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a paid service that can ingest csv files, then they get uploaded to my database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5i9t0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709475645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want a service which provides an sdk i can through my node js app and it ingests the data in to postgresql. The files will be csv, my current implementations crush the node.js server because they can&amp;#39;t fit into memory&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b5i9t0", "is_robot_indexable": true, "report_reasons": null, "author": "ZealousidealRich7460", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5i9t0/is_there_a_paid_service_that_can_ingest_csv_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5i9t0/is_there_a_paid_service_that_can_ingest_csv_files/", "subreddit_subscribers": 165483, "created_utc": 1709475645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don't get much technical growth out of my day job; everything is very cookie cutter, and I've decided to build out some personal projects to upskill in some latest technologies and tools. However, the challenge I'm finding is that DE projects are pretty expensive to build and host compared to say web app development or something... \n\nOne real-world example, I'm interested in both hosting and building ELT projects with Dagster. Ideally, I want to actually make use of Dagster as an orchestrator which means hosting it long-term so I can ingest a sufficiently large volume of data, however, my back-of-the-napkin math shows this to be almost $60 per month in AWS! And this is just for my orchestration layer. I know I can host and run all of these locally, but I feel like I miss out on the experience of building in the cloud (i.e. IaC) and the tools themselves (e.g. an orchestrator running locally that's off half the time is a lousy orchestrator).\n\nHow does everyone else approach personal projects? DO you just do everything locally? Do you use a company-owned cloud account? Am I overengineering personal projects?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to cheaply build/host DE personal projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b5mw89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709487627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t get much technical growth out of my day job; everything is very cookie cutter, and I&amp;#39;ve decided to build out some personal projects to upskill in some latest technologies and tools. However, the challenge I&amp;#39;m finding is that DE projects are pretty expensive to build and host compared to say web app development or something... &lt;/p&gt;\n\n&lt;p&gt;One real-world example, I&amp;#39;m interested in both hosting and building ELT projects with Dagster. Ideally, I want to actually make use of Dagster as an orchestrator which means hosting it long-term so I can ingest a sufficiently large volume of data, however, my back-of-the-napkin math shows this to be almost $60 per month in AWS! And this is just for my orchestration layer. I know I can host and run all of these locally, but I feel like I miss out on the experience of building in the cloud (i.e. IaC) and the tools themselves (e.g. an orchestrator running locally that&amp;#39;s off half the time is a lousy orchestrator).&lt;/p&gt;\n\n&lt;p&gt;How does everyone else approach personal projects? DO you just do everything locally? Do you use a company-owned cloud account? Am I overengineering personal projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b5mw89", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5mw89/how_to_cheaply_buildhost_de_personal_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5mw89/how_to_cheaply_buildhost_de_personal_projects/", "subreddit_subscribers": 165483, "created_utc": 1709487627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I came across Sling and was wondering if anyone has experience with it. Any pros/cons?\n\nhttps://slingdata.io/", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with Sling for data ingestion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5k1kf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709480386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across Sling and was wondering if anyone has experience with it. Any pros/cons?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://slingdata.io/\"&gt;https://slingdata.io/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A6JFpWVX0dSmfMWxpg1D1H-2FkyEO9pr9pmRqxtfxcw.jpg?auto=webp&amp;s=4fd86079b0bccccb80b333fcf6cf07055b074cbc", "width": 1400, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/A6JFpWVX0dSmfMWxpg1D1H-2FkyEO9pr9pmRqxtfxcw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e41e03d4918b9269364e5482cd9c7d7d4bdbc5a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/A6JFpWVX0dSmfMWxpg1D1H-2FkyEO9pr9pmRqxtfxcw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=081103f6882e3719eaf2581f7836446dbf03deb1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/A6JFpWVX0dSmfMWxpg1D1H-2FkyEO9pr9pmRqxtfxcw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=104683949a85398dadad8f57da651e6b4390d869", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/A6JFpWVX0dSmfMWxpg1D1H-2FkyEO9pr9pmRqxtfxcw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fef43b90a198db19c60f2457ad085a570e5a69a4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/A6JFpWVX0dSmfMWxpg1D1H-2FkyEO9pr9pmRqxtfxcw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=11fd386ce8a1c13917621b6f7b1a7006ab1b9c53", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/A6JFpWVX0dSmfMWxpg1D1H-2FkyEO9pr9pmRqxtfxcw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5f077dda68d1ce16709dbce8b0b309a007bed1b8", "width": 1080, "height": 540}], "variants": {}, "id": "Vb3c0eiOMA_329cW1MyIi4yFfzrp0Jzx8XuJC5r99Js"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b5k1kf", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5k1kf/experience_with_sling_for_data_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5k1kf/experience_with_sling_for_data_ingestion/", "subreddit_subscribers": 165483, "created_utc": 1709480386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A bit of clarity. In my company we use the Infosphere suite for all the major ETL pipelines. I hate it with a burning passion, all the advantages it provides are mostly circumstantial, and I especially hate dragging icons on a screen when the same task could be done ten times faster by using code. Luckily, it gives you the option to export and import jobs via xml, so I built myself a script that makes what I need by taking in input an excel spreadsheet with some parameters.\n\nDo most tools give you the option to import/export stuff in a human-readable format? I was thinking about improving the script so that it does the same work for other tools. Also, and this is a long shot, is there some open-source software that does the same thing, so that I can study it?", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common is it for low-code drag &amp; drop tools to provide the option to work with code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b533il", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709424666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A bit of clarity. In my company we use the Infosphere suite for all the major ETL pipelines. I hate it with a burning passion, all the advantages it provides are mostly circumstantial, and I especially hate dragging icons on a screen when the same task could be done ten times faster by using code. Luckily, it gives you the option to export and import jobs via xml, so I built myself a script that makes what I need by taking in input an excel spreadsheet with some parameters.&lt;/p&gt;\n\n&lt;p&gt;Do most tools give you the option to import/export stuff in a human-readable format? I was thinking about improving the script so that it does the same work for other tools. Also, and this is a long shot, is there some open-source software that does the same thing, so that I can study it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b533il", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b533il/how_common_is_it_for_lowcode_drag_drop_tools_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b533il/how_common_is_it_for_lowcode_drag_drop_tools_to/", "subreddit_subscribers": 165483, "created_utc": 1709424666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a project for stock analysis, attempt to get 10 years of data from stock historical data source to store in data warehouse, then update the latest daily stock price after system go-live.\n\nI'm using Postgres as database which I'm familiar with, the overall data ingestion pipeline looks like this:  \n`data source -&gt; raw_table (Postgres)-&gt; staging table (Postgres)`  \n\n\nThe significance of raw table is that when I gather data from stock data source, it may get duplicate data that have already captured before. \n\nI plan to gather data to a raw\\_table, then insert into staging table which removed all duplicates\n\n&amp;#x200B;\n\nThe problem here is that there are too many rows in raw\\_table and whenever I want to do the insertion to staging table, I run this:\n\n    insert into stagin_Table\n    select * from stock_raw_table sr\n    where sr.stock_code not in (select stock_code from stock_raw_table);\n\nwhere stock\\_code is the unique key for single daily stock price.\n\nThe above insertion cost too much time, and I'm wondering if my pipeline is inefficient.\n\nAny advice for this scenario?\n\nThanks for any advice!", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "May I ask for suggestions for the data pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5ee2p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709462772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project for stock analysis, attempt to get 10 years of data from stock historical data source to store in data warehouse, then update the latest daily stock price after system go-live.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Postgres as database which I&amp;#39;m familiar with, the overall data ingestion pipeline looks like this:&lt;br/&gt;\n&lt;code&gt;data source -&amp;gt; raw_table (Postgres)-&amp;gt; staging table (Postgres)&lt;/code&gt;  &lt;/p&gt;\n\n&lt;p&gt;The significance of raw table is that when I gather data from stock data source, it may get duplicate data that have already captured before. &lt;/p&gt;\n\n&lt;p&gt;I plan to gather data to a raw_table, then insert into staging table which removed all duplicates&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The problem here is that there are too many rows in raw_table and whenever I want to do the insertion to staging table, I run this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;insert into stagin_Table\nselect * from stock_raw_table sr\nwhere sr.stock_code not in (select stock_code from stock_raw_table);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;where stock_code is the unique key for single daily stock price.&lt;/p&gt;\n\n&lt;p&gt;The above insertion cost too much time, and I&amp;#39;m wondering if my pipeline is inefficient.&lt;/p&gt;\n\n&lt;p&gt;Any advice for this scenario?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b5ee2p", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5ee2p/may_i_ask_for_suggestions_for_the_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5ee2p/may_i_ask_for_suggestions_for_the_data_pipeline/", "subreddit_subscribers": 165483, "created_utc": 1709462772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm reading that in Delta Lake the deltas are periodically cleaned up. One of the reasons we're looking at Delta Lake or Iceberg as a technology is so we can retain all versions of our data forever. Is there a way to do this in Delta Lake, or any disadvantage performance wise? I see Iceberg has a tagging feature we could run on every change. Since Delta Lake doesn't seemingly offer a way to turn this feature off there's a tonne of concerns I need to address:\n\n* How does running \\`VACUUM\\` affect the ability to time travel back to versions older than the retention period? It deletes them.\n* Does Delta Lake trigger the data retention process automatically, and if so, under what circumstances? It claims not to run VACUUM, but it does look like it will clean up the log automatically, which will prevent time travel.\n* What are the performance implications of not running \\`VACUUM\\`, and should these be considered in schema design decisions?\n* How can the risk of table vacuuming for older versions of data be mitigated, such as through backing up the version history prior to compaction?\n* How does the retention period setting affect versioning strategies, once we VACUUM do we reset the version back to 1 or does it keep going?\n* Once set, how robust is a retention period, and what impact does it have on data management?\n* Is there a concept of version pinning we can use, e.g. a version 'tag' that gets kept forever.\n\nThanks in advance.", "author_fullname": "t2_duii2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retaining Delta Table (like) Versions Forever", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b538qj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709428473.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709425061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reading that in Delta Lake the deltas are periodically cleaned up. One of the reasons we&amp;#39;re looking at Delta Lake or Iceberg as a technology is so we can retain all versions of our data forever. Is there a way to do this in Delta Lake, or any disadvantage performance wise? I see Iceberg has a tagging feature we could run on every change. Since Delta Lake doesn&amp;#39;t seemingly offer a way to turn this feature off there&amp;#39;s a tonne of concerns I need to address:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How does running `VACUUM` affect the ability to time travel back to versions older than the retention period? It deletes them.&lt;/li&gt;\n&lt;li&gt;Does Delta Lake trigger the data retention process automatically, and if so, under what circumstances? It claims not to run VACUUM, but it does look like it will clean up the log automatically, which will prevent time travel.&lt;/li&gt;\n&lt;li&gt;What are the performance implications of not running `VACUUM`, and should these be considered in schema design decisions?&lt;/li&gt;\n&lt;li&gt;How can the risk of table vacuuming for older versions of data be mitigated, such as through backing up the version history prior to compaction?&lt;/li&gt;\n&lt;li&gt;How does the retention period setting affect versioning strategies, once we VACUUM do we reset the version back to 1 or does it keep going?&lt;/li&gt;\n&lt;li&gt;Once set, how robust is a retention period, and what impact does it have on data management?&lt;/li&gt;\n&lt;li&gt;Is there a concept of version pinning we can use, e.g. a version &amp;#39;tag&amp;#39; that gets kept forever.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b538qj", "is_robot_indexable": true, "report_reasons": null, "author": "MMACheerpuppy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b538qj/retaining_delta_table_like_versions_forever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b538qj/retaining_delta_table_like_versions_forever/", "subreddit_subscribers": 165483, "created_utc": 1709425061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any suggestions for online resources and/or books explaining \"all-start\" software architecture design? I can use Lucid to make clean flowcharts, but I'm interested in learning key attributes and industry standards", "author_fullname": "t2_6cc9wqbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Best Practices in Software Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b50byv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709417586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any suggestions for online resources and/or books explaining &amp;quot;all-start&amp;quot; software architecture design? I can use Lucid to make clean flowcharts, but I&amp;#39;m interested in learning key attributes and industry standards&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b50byv", "is_robot_indexable": true, "report_reasons": null, "author": "Cultured_dude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b50byv/resources_for_best_practices_in_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b50byv/resources_for_best_practices_in_software/", "subreddit_subscribers": 165483, "created_utc": 1709417586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team,\n\nI want to let my Spark partitions write to CSV or JSON as usual. As we know, this means that each partition writes its own file.\n\nI've got the challenge of writing a statement for each customer. That means, 1 customer gets 1 file with their info in it.\n\nI want to avoid bringing all the data to the driver node and getting python to write the file, but I also have to manage these multiple partition files. Even if I \\`coalesce\\` the name is not correct. For this case, let's pretend the data is so large that coalescing would be a bad idea anyway.\n\nQuestion is: what is the best practice for combining + renaming these partition files?\n\nWe have airflow in the works, so perhaps a step in a DAG? Or maybe a CRON to catch the files and do the work?\n\nAny ideas? Please and thank you.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combine Spark's output files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5bfh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709451107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team,&lt;/p&gt;\n\n&lt;p&gt;I want to let my Spark partitions write to CSV or JSON as usual. As we know, this means that each partition writes its own file.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got the challenge of writing a statement for each customer. That means, 1 customer gets 1 file with their info in it.&lt;/p&gt;\n\n&lt;p&gt;I want to avoid bringing all the data to the driver node and getting python to write the file, but I also have to manage these multiple partition files. Even if I `coalesce` the name is not correct. For this case, let&amp;#39;s pretend the data is so large that coalescing would be a bad idea anyway.&lt;/p&gt;\n\n&lt;p&gt;Question is: what is the best practice for combining + renaming these partition files?&lt;/p&gt;\n\n&lt;p&gt;We have airflow in the works, so perhaps a step in a DAG? Or maybe a CRON to catch the files and do the work?&lt;/p&gt;\n\n&lt;p&gt;Any ideas? Please and thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b5bfh9", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5bfh9/combine_sparks_output_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5bfh9/combine_sparks_output_files/", "subreddit_subscribers": 165483, "created_utc": 1709451107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This platform here:\n\nhttps://docs.lowcoder.cloud/lowcoder-documentation/\n\nI constantly find that I\u2019m needing to build some kind of frontend for various purposes. Usually because I need data that can only be collected from a human. Like a date value, an integer, a whole file, a CSV with validation, \u2026\n\nI build the database, the backend logic, provision the servers, set up the network, deploy the code, back it up to code storage, \u2026 i just don\u2019t do web development. I don\u2019t know their frameworks, I don\u2019t have a firm grasp on their models like MVC. Every time I try sometimes starts screaming at me about some kind of cross-domain origin error. I hate website stuff,\n\nI kind of just want an easy tool that can build quick front ends and I can move on with my day. In a perfect world it would be version controlled but that one requirement seems to make a world of difference by complexity. \n\nHowever, lowcode too quickly becomes unmaintainable monstrosities of which I also want no part in\u2026 Ive tried, they are notoriously bad. Too rigid and not at all professional, resulting in strange tools.\n\nThis platform says it\u2019s different and more modern. I think I want to trust it because it\u2019s new and open source. However, I also think I know better\u2026\n\nHas anyone tried this specific platform? I\u2019d love to hear about your experience.", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used that \u201cLowcoder\u201d platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b5a9fr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709447054.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1709446759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This platform here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.lowcoder.cloud/lowcoder-documentation/\"&gt;https://docs.lowcoder.cloud/lowcoder-documentation/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I constantly find that I\u2019m needing to build some kind of frontend for various purposes. Usually because I need data that can only be collected from a human. Like a date value, an integer, a whole file, a CSV with validation, \u2026&lt;/p&gt;\n\n&lt;p&gt;I build the database, the backend logic, provision the servers, set up the network, deploy the code, back it up to code storage, \u2026 i just don\u2019t do web development. I don\u2019t know their frameworks, I don\u2019t have a firm grasp on their models like MVC. Every time I try sometimes starts screaming at me about some kind of cross-domain origin error. I hate website stuff,&lt;/p&gt;\n\n&lt;p&gt;I kind of just want an easy tool that can build quick front ends and I can move on with my day. In a perfect world it would be version controlled but that one requirement seems to make a world of difference by complexity. &lt;/p&gt;\n\n&lt;p&gt;However, lowcode too quickly becomes unmaintainable monstrosities of which I also want no part in\u2026 Ive tried, they are notoriously bad. Too rigid and not at all professional, resulting in strange tools.&lt;/p&gt;\n\n&lt;p&gt;This platform says it\u2019s different and more modern. I think I want to trust it because it\u2019s new and open source. However, I also think I know better\u2026&lt;/p&gt;\n\n&lt;p&gt;Has anyone tried this specific platform? I\u2019d love to hear about your experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NLHIMPQo8Kk9U8lY_KKVv-dqMoTFTZ79ZCsFrLtRs0Q.jpg?auto=webp&amp;s=ad06c1fc1672dcf031f0fbb0d1a5ebce1a2e1ff8", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/NLHIMPQo8Kk9U8lY_KKVv-dqMoTFTZ79ZCsFrLtRs0Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ac43a556f4cce711675cc749fc9ebcae0cf6c87", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/NLHIMPQo8Kk9U8lY_KKVv-dqMoTFTZ79ZCsFrLtRs0Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69c93ab4b87887cfd9c375dba832d60518c1031f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/NLHIMPQo8Kk9U8lY_KKVv-dqMoTFTZ79ZCsFrLtRs0Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b372214c81ed4c9410e82aa98e92f4ed6da5c21", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/NLHIMPQo8Kk9U8lY_KKVv-dqMoTFTZ79ZCsFrLtRs0Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a5362b1ed17277eab1070735afde793e05b3f6d7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/NLHIMPQo8Kk9U8lY_KKVv-dqMoTFTZ79ZCsFrLtRs0Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=06e917647c589e4da59407581e7b6d2d95c4f9c6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/NLHIMPQo8Kk9U8lY_KKVv-dqMoTFTZ79ZCsFrLtRs0Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1768910eb2e938bb73b86171b91daf86dd5b976d", "width": 1080, "height": 567}], "variants": {}, "id": "L6RSJWfOguQjDafRRKkpD4sQ5D6ddai9mcwQRsY2nxk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b5a9fr", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b5a9fr/has_anyone_used_that_lowcoder_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b5a9fr/has_anyone_used_that_lowcoder_platform/", "subreddit_subscribers": 165483, "created_utc": 1709446759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \nDoes anyone has Experience which one of those options for a upsert (based on id) streaming pipeline from kafka to iceberg (which also has to do schema evolution, e.g. automatically adding new cols if some appear) has the best performance:\n\n- Spark Structured Streaming \n- Flink Streaming \n- Tabulars Sink Connector\n\nWhich do you prefer? \n\nI am currently building one pretty flexible pipeline with spark structured streaming, multi-table support (based on column value in data) and upsert per default, running locally on my Mac M1pro Ram limited to 8gb. Current Throughput at around 7k msg/seconds. Was wondering if flink or kafka-connect might be faster and worth a try", "author_fullname": "t2_q4hy00qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg Upsert Streaming Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b53dkg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709425418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nDoes anyone has Experience which one of those options for a upsert (based on id) streaming pipeline from kafka to iceberg (which also has to do schema evolution, e.g. automatically adding new cols if some appear) has the best performance:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Spark Structured Streaming &lt;/li&gt;\n&lt;li&gt;Flink Streaming &lt;/li&gt;\n&lt;li&gt;Tabulars Sink Connector&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Which do you prefer? &lt;/p&gt;\n\n&lt;p&gt;I am currently building one pretty flexible pipeline with spark structured streaming, multi-table support (based on column value in data) and upsert per default, running locally on my Mac M1pro Ram limited to 8gb. Current Throughput at around 7k msg/seconds. Was wondering if flink or kafka-connect might be faster and worth a try&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b53dkg", "is_robot_indexable": true, "report_reasons": null, "author": "ShipWild9022", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b53dkg/iceberg_upsert_streaming_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b53dkg/iceberg_upsert_streaming_pipelines/", "subreddit_subscribers": 165483, "created_utc": 1709425418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am trying to read from Mongo using spark mongo connector trying to load 10M rows\n\nAnyone know how I can ignore rows if there is datatype mismatch using my predefined schema. There are some date field which are timestamp but someone inserted String type. There are similar issues with other field. \n\nI want to know how we can handle datatype mismatch, The DROPMALFORMED functionality is not available in Spark Mongo Connector.\n\nAny advice or pointer will be helpful.", "author_fullname": "t2_6klazicf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with Spark and Mongo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4w7pv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709407109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am trying to read from Mongo using spark mongo connector trying to load 10M rows&lt;/p&gt;\n\n&lt;p&gt;Anyone know how I can ignore rows if there is datatype mismatch using my predefined schema. There are some date field which are timestamp but someone inserted String type. There are similar issues with other field. &lt;/p&gt;\n\n&lt;p&gt;I want to know how we can handle datatype mismatch, The DROPMALFORMED functionality is not available in Spark Mongo Connector.&lt;/p&gt;\n\n&lt;p&gt;Any advice or pointer will be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4w7pv", "is_robot_indexable": true, "report_reasons": null, "author": "asfifa14", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4w7pv/need_help_with_spark_and_mongo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4w7pv/need_help_with_spark_and_mongo/", "subreddit_subscribers": 165483, "created_utc": 1709407109.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}