{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This though suddenly came up when I saw job postings for experienced individuals paying $25 an hour. This is not the norm, but still scary that companies even have such low expectations. Compared to most jobs out there, although the type of work may be fulfilling, And more often employers slap the \"Analyst\" title and get these people for a bargain. I feel that people in this industry are often underpaid compared to the work/skills they bring to the table. What do you all think?", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are Data Engineers underpaid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4v030", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709404052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This though suddenly came up when I saw job postings for experienced individuals paying $25 an hour. This is not the norm, but still scary that companies even have such low expectations. Compared to most jobs out there, although the type of work may be fulfilling, And more often employers slap the &amp;quot;Analyst&amp;quot; title and get these people for a bargain. I feel that people in this industry are often underpaid compared to the work/skills they bring to the table. What do you all think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b4v030", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4v030/are_data_engineers_underpaid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4v030/are_data_engineers_underpaid/", "subreddit_subscribers": 165290, "created_utc": 1709404052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To all data enthusiasts here - a confession from a data engineer - my estimation of data platform setup time failed 100% of the time.\n\nWhat's your experience in building a new data platform? Specifically interested in learning about the time spent in setting up &amp; integrating the essential layers and making it production-ready - warehouse, ingestion, transformation, orchestration, and visualization.\n\nThis might be subjective given the requirements, love to hear about your experiences.", "author_fullname": "t2_6odriz9z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time needed to build a data platform from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b510m2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709419349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To all data enthusiasts here - a confession from a data engineer - my estimation of data platform setup time failed 100% of the time.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your experience in building a new data platform? Specifically interested in learning about the time spent in setting up &amp;amp; integrating the essential layers and making it production-ready - warehouse, ingestion, transformation, orchestration, and visualization.&lt;/p&gt;\n\n&lt;p&gt;This might be subjective given the requirements, love to hear about your experiences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b510m2", "is_robot_indexable": true, "report_reasons": null, "author": "prasadus", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b510m2/time_needed_to_build_a_data_platform_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b510m2/time_needed_to_build_a_data_platform_from_scratch/", "subreddit_subscribers": 165290, "created_utc": 1709419349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company we are In a Databricks Azure environnement with most of the jobs are ETL jobs curently in python / pyspark", "author_fullname": "t2_uhw0wx8az", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is scala worth to learn as a spark data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b506um", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709417224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company we are In a Databricks Azure environnement with most of the jobs are ETL jobs curently in python / pyspark&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b506um", "is_robot_indexable": true, "report_reasons": null, "author": "randomWasabiEnjoyer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b506um/is_scala_worth_to_learn_as_a_spark_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b506um/is_scala_worth_to_learn_as_a_spark_data_engineer/", "subreddit_subscribers": 165290, "created_utc": 1709417224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has two separate main business functions. One involving distribution of food products, and the other being the selling of custom merchandise and apparel. There\u2019s been some discussion on if in the future it would be beneficial to have one single data warehouse that is shared by both companies or having two separate systems for both. \n\nThe companies currently operate separately now, as one company was acquired and never entirely brought under the same umbrella as the parent from a technology standpoint. Both currently have separate systems and databases, but will be upgraded over the course of the next few years (one before the other).\n\nDoes it make sense to design a warehouse that can accommodate both under one roof? Or would it be wiser to keep these two divisions separate from a data warehouse perspective?", "author_fullname": "t2_3sghijoz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One data warehouse or two for different divisions of the same company ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4pxjb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709390903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has two separate main business functions. One involving distribution of food products, and the other being the selling of custom merchandise and apparel. There\u2019s been some discussion on if in the future it would be beneficial to have one single data warehouse that is shared by both companies or having two separate systems for both. &lt;/p&gt;\n\n&lt;p&gt;The companies currently operate separately now, as one company was acquired and never entirely brought under the same umbrella as the parent from a technology standpoint. Both currently have separate systems and databases, but will be upgraded over the course of the next few years (one before the other).&lt;/p&gt;\n\n&lt;p&gt;Does it make sense to design a warehouse that can accommodate both under one roof? Or would it be wiser to keep these two divisions separate from a data warehouse perspective?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4pxjb", "is_robot_indexable": true, "report_reasons": null, "author": "ManiaMcG33_", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4pxjb/one_data_warehouse_or_two_for_different_divisions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4pxjb/one_data_warehouse_or_two_for_different_divisions/", "subreddit_subscribers": 165290, "created_utc": 1709390903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I'm looking for a great spark course for a data engineer with basic base knowledge who want to go deeper on spark concept, optimization, best practice,...", "author_fullname": "t2_uhw0wx8az", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Spark course in 2024 for medium level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b50a0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709417450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I&amp;#39;m looking for a great spark course for a data engineer with basic base knowledge who want to go deeper on spark concept, optimization, best practice,...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b50a0f", "is_robot_indexable": true, "report_reasons": null, "author": "randomWasabiEnjoyer", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b50a0f/best_spark_course_in_2024_for_medium_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b50a0f/best_spark_course_in_2024_for_medium_level/", "subreddit_subscribers": 165290, "created_utc": 1709417450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i have being giving interviews for azure data engg. Most of them ask me scenario based questions. The problem of scenario based questions is there may be multiple ways of achieving the solution. \n\nBelow are some scenarios. Please do share your insiggts if you might have came across in your work\n\n#1. You have multiple csv files in adls. You want to apply transformation on them and generate a single file. How would you acheive it.\n\nSol 1 - using adf mapping dataflows can take multiple source, do  the transformation and generate one file with one partition using sink transformation\n\nSol2 - using metadata activity to get the list of files and then using copy activity to get all the files from source and sink as one file by setting copy behaviour to merge\n\n\n\n#2. You have to store data on adls. How do you store the data in optimised way. Like partitioning indexing etc\n(Dont know about this. Please provide your input here)\n\n\n#3. How will you incrementally load data from file in adls.\nSol - probably using a metadata activity by getting all the last modified date \n\n\n#4. How will you copy data from onprem sql server to adls\nSol-  setup a Self hosted IR and then using a copy activity. But what if i dont want to copy all the data and just a section of data how do i do that ??\n\n\n#5. How do you Transform data without using a dataflow. \nSol - probably copy activity. But as far as i know it can only map source and dest cols and cant do any complex transformations\n\n\n#6- how do you connect to a on pem SQL server from a synaspse notebook without using adf pipeline\n-i dont have any idea abt this\n\n\nWould be great if experts of ADF share their insights", "author_fullname": "t2_e2e7dtpv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you solve these adf scenarios ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4ti4e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709400291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i have being giving interviews for azure data engg. Most of them ask me scenario based questions. The problem of scenario based questions is there may be multiple ways of achieving the solution. &lt;/p&gt;\n\n&lt;p&gt;Below are some scenarios. Please do share your insiggts if you might have came across in your work&lt;/p&gt;\n\n&lt;h1&gt;1. You have multiple csv files in adls. You want to apply transformation on them and generate a single file. How would you acheive it.&lt;/h1&gt;\n\n&lt;p&gt;Sol 1 - using adf mapping dataflows can take multiple source, do  the transformation and generate one file with one partition using sink transformation&lt;/p&gt;\n\n&lt;p&gt;Sol2 - using metadata activity to get the list of files and then using copy activity to get all the files from source and sink as one file by setting copy behaviour to merge&lt;/p&gt;\n\n&lt;h1&gt;2. You have to store data on adls. How do you store the data in optimised way. Like partitioning indexing etc&lt;/h1&gt;\n\n&lt;p&gt;(Dont know about this. Please provide your input here)&lt;/p&gt;\n\n&lt;h1&gt;3. How will you incrementally load data from file in adls.&lt;/h1&gt;\n\n&lt;p&gt;Sol - probably using a metadata activity by getting all the last modified date &lt;/p&gt;\n\n&lt;h1&gt;4. How will you copy data from onprem sql server to adls&lt;/h1&gt;\n\n&lt;p&gt;Sol-  setup a Self hosted IR and then using a copy activity. But what if i dont want to copy all the data and just a section of data how do i do that ??&lt;/p&gt;\n\n&lt;h1&gt;5. How do you Transform data without using a dataflow.&lt;/h1&gt;\n\n&lt;p&gt;Sol - probably copy activity. But as far as i know it can only map source and dest cols and cant do any complex transformations&lt;/p&gt;\n\n&lt;h1&gt;6- how do you connect to a on pem SQL server from a synaspse notebook without using adf pipeline&lt;/h1&gt;\n\n&lt;p&gt;-i dont have any idea abt this&lt;/p&gt;\n\n&lt;p&gt;Would be great if experts of ADF share their insights&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4ti4e", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult_Ad_426", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4ti4e/how_do_you_solve_these_adf_scenarios/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4ti4e/how_do_you_solve_these_adf_scenarios/", "subreddit_subscribers": 165290, "created_utc": 1709400291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I wanted to ask how important it would be to learn (theoretically / practically) the following topics with in mind a data engineering future career:\n\nDistributed framework Apache Spark.\n\nClustering for data analysis and summarization.\n\nAnalysis of data streams.\n\nSimilarity search.\n\nAssociation Analysis.\n\n\nThanks!!", "author_fullname": "t2_a43b8wju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big Data Computing in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4p1t1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709388370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I wanted to ask how important it would be to learn (theoretically / practically) the following topics with in mind a data engineering future career:&lt;/p&gt;\n\n&lt;p&gt;Distributed framework Apache Spark.&lt;/p&gt;\n\n&lt;p&gt;Clustering for data analysis and summarization.&lt;/p&gt;\n\n&lt;p&gt;Analysis of data streams.&lt;/p&gt;\n\n&lt;p&gt;Similarity search.&lt;/p&gt;\n\n&lt;p&gt;Association Analysis.&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4p1t1", "is_robot_indexable": true, "report_reasons": null, "author": "Aiecco", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4p1t1/big_data_computing_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4p1t1/big_data_computing_in_data_engineering/", "subreddit_subscribers": 165290, "created_utc": 1709388370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3qpsfp70", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mistral AI, Klarna AI customer support agent, extract and load still unsolved", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4n50k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WEJPt2FzuFZnoXNluIHC-2TMSyaaGkmUB4VJd8cZGvI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1709382380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blef.fr", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.blef.fr/data-news-week-24-09/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?auto=webp&amp;s=2c582ffb719685be75072e2ad3165658a96e0e7c", "width": 2500, "height": 1667}, "resolutions": [{"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff3a6beeb29af9738698f43405c5ef7c03630cb3", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f48117d3f5966230ea0f1006394aad85b2551e4", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bbdd4e39c0c3ca26d2e72aa2c67fb44231f12b68", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=332c5b5d7e8f6cc6dec5cd676adb963f3aee3efb", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7985ea0e8108b3f58c869fc531dbf572b6cebc69", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/QcyJ4wO9_WFnEQEVrN7WrWq5xYKvhng7duKs7-45k38.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=823626cdd2dd3679a122dbc651c511446ea8cd5d", "width": 1080, "height": 720}], "variants": {}, "id": "_8UH2w59fyHSlLr2L65k-Njp35XnnrWQYTWT62hAk2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1b4n50k", "is_robot_indexable": true, "report_reasons": null, "author": "mrocral", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4n50k/mistral_ai_klarna_ai_customer_support_agent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.blef.fr/data-news-week-24-09/", "subreddit_subscribers": 165290, "created_utc": 1709382380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \nDoes anyone has Experience which one of those options for a upsert (based on id) streaming pipeline from kafka to iceberg (which also has to do schema evolution, e.g. automatically adding new cols if some appear) has the best performance:\n\n- Spark Structured Streaming \n- Flink Streaming \n- Tabulars Sink Connector\n\nWhich do you prefer? \n\nI am currently building one pretty flexible pipeline with spark structured streaming, multi-table support (based on column value in data) and upsert per default, running locally on my Mac M1pro Ram limited to 8gb. Current Throughput at around 7k msg/seconds. Was wondering if flink or kafka-connect might be faster and worth a try", "author_fullname": "t2_q4hy00qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg Upsert Streaming Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b53dkg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709425418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nDoes anyone has Experience which one of those options for a upsert (based on id) streaming pipeline from kafka to iceberg (which also has to do schema evolution, e.g. automatically adding new cols if some appear) has the best performance:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Spark Structured Streaming &lt;/li&gt;\n&lt;li&gt;Flink Streaming &lt;/li&gt;\n&lt;li&gt;Tabulars Sink Connector&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Which do you prefer? &lt;/p&gt;\n\n&lt;p&gt;I am currently building one pretty flexible pipeline with spark structured streaming, multi-table support (based on column value in data) and upsert per default, running locally on my Mac M1pro Ram limited to 8gb. Current Throughput at around 7k msg/seconds. Was wondering if flink or kafka-connect might be faster and worth a try&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b53dkg", "is_robot_indexable": true, "report_reasons": null, "author": "ShipWild9022", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b53dkg/iceberg_upsert_streaming_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b53dkg/iceberg_upsert_streaming_pipelines/", "subreddit_subscribers": 165290, "created_utc": 1709425418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm reading that in Delta Lake the deltas are periodically cleaned up. One of the reasons we're looking at Delta Lake or Iceberg as a technology is so we can retain all versions of our data forever. Is there a way to do this in Delta Lake, or any disadvantage performance wise? I see Iceberg has a tagging feature we could run on every change. Since Delta Lake doesn't seemingly offer a way to turn this feature off there's a tonne of concerns I need to address:\n\n* How does running \\`VACUUM\\` affect the ability to time travel back to versions older than the retention period? It deletes them.\n* Does Delta Lake trigger the data retention process automatically, and if so, under what circumstances? It claims not to run VACUUM, but it does look like it will clean up the log automatically, which will prevent time travel.\n* What are the performance implications of not running \\`VACUUM\\`, and should these be considered in schema design decisions?\n* How can the risk of table vacuuming for older versions of data be mitigated, such as through backing up the version history prior to compaction?\n* How does the retention period setting affect versioning strategies, once we VACUUM do we reset the version back to 1 or does it keep going?\n* Once set, how robust is a retention period, and what impact does it have on data management?\n* Is there a concept of version pinning we can use, e.g. a version 'tag' that gets kept forever.\n\nThanks in advance.", "author_fullname": "t2_duii2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retaining Delta Table (like) Versions Forever", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b538qj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709428473.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709425061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reading that in Delta Lake the deltas are periodically cleaned up. One of the reasons we&amp;#39;re looking at Delta Lake or Iceberg as a technology is so we can retain all versions of our data forever. Is there a way to do this in Delta Lake, or any disadvantage performance wise? I see Iceberg has a tagging feature we could run on every change. Since Delta Lake doesn&amp;#39;t seemingly offer a way to turn this feature off there&amp;#39;s a tonne of concerns I need to address:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How does running `VACUUM` affect the ability to time travel back to versions older than the retention period? It deletes them.&lt;/li&gt;\n&lt;li&gt;Does Delta Lake trigger the data retention process automatically, and if so, under what circumstances? It claims not to run VACUUM, but it does look like it will clean up the log automatically, which will prevent time travel.&lt;/li&gt;\n&lt;li&gt;What are the performance implications of not running `VACUUM`, and should these be considered in schema design decisions?&lt;/li&gt;\n&lt;li&gt;How can the risk of table vacuuming for older versions of data be mitigated, such as through backing up the version history prior to compaction?&lt;/li&gt;\n&lt;li&gt;How does the retention period setting affect versioning strategies, once we VACUUM do we reset the version back to 1 or does it keep going?&lt;/li&gt;\n&lt;li&gt;Once set, how robust is a retention period, and what impact does it have on data management?&lt;/li&gt;\n&lt;li&gt;Is there a concept of version pinning we can use, e.g. a version &amp;#39;tag&amp;#39; that gets kept forever.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b538qj", "is_robot_indexable": true, "report_reasons": null, "author": "MMACheerpuppy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b538qj/retaining_delta_table_like_versions_forever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b538qj/retaining_delta_table_like_versions_forever/", "subreddit_subscribers": 165290, "created_utc": 1709425061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A bit of clarity. In my company we use the Infosphere suite for all the major ETL pipelines. I hate it with a burning passion, all the advantages it provides are mostly circumstantial, and I especially hate dragging icons on a screen when the same task could be done ten times faster by using code. Luckily, it gives you the option to export and import jobs via xml, so I built myself a script that makes what I need by taking in input an excel spreadsheet with some parameters.\n\nDo most tools give you the option to import/export stuff in a human-readable format? I was thinking about improving the script so that it does the same work for other tools. Also, and this is a long shot, is there some open-source software that does the same thing, so that I can study it?", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common is it for low-code drag &amp; drop tools to provide the option to work with code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1b533il", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709424666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A bit of clarity. In my company we use the Infosphere suite for all the major ETL pipelines. I hate it with a burning passion, all the advantages it provides are mostly circumstantial, and I especially hate dragging icons on a screen when the same task could be done ten times faster by using code. Luckily, it gives you the option to export and import jobs via xml, so I built myself a script that makes what I need by taking in input an excel spreadsheet with some parameters.&lt;/p&gt;\n\n&lt;p&gt;Do most tools give you the option to import/export stuff in a human-readable format? I was thinking about improving the script so that it does the same work for other tools. Also, and this is a long shot, is there some open-source software that does the same thing, so that I can study it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b533il", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b533il/how_common_is_it_for_lowcode_drag_drop_tools_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b533il/how_common_is_it_for_lowcode_drag_drop_tools_to/", "subreddit_subscribers": 165290, "created_utc": 1709424666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any suggestions for online resources and/or books explaining \"all-start\" software architecture design? I can use Lucid to make clean flowcharts, but I'm interested in learning key attributes and industry standards", "author_fullname": "t2_6cc9wqbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Best Practices in Software Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b50byv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709417586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any suggestions for online resources and/or books explaining &amp;quot;all-start&amp;quot; software architecture design? I can use Lucid to make clean flowcharts, but I&amp;#39;m interested in learning key attributes and industry standards&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b50byv", "is_robot_indexable": true, "report_reasons": null, "author": "Cultured_dude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b50byv/resources_for_best_practices_in_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b50byv/resources_for_best_practices_in_software/", "subreddit_subscribers": 165290, "created_utc": 1709417586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've inherited a large data warehouse that has many different SQL Server Databases.\n\nI'm trying to understand the structure and relationships of the objects, but there isn't a data model I can refer to.  The system has grown over many years and has inconsistent names etc. which makes it more difficult to follow.\n\nThe largest issue, is that there are an abundance of nested views which, in turn, reference objects in other databases.  When you dig down through the views, you may even end up back in your original database.\n\nI'm thinking that I need to reverse engineer it in to a data model so I can see the dependencies and work out what is/isnt required when implementing its replacement.\n\nHas anyone worked with data modelling tools that handle multi-database dependencies?  I briefly looked at ER/Studio, but it seems to only handle dependencies within the same database when reverse engineering objects.  Even when adding the objects manually, I couldn't see how the database could be specified for an object, as it didn't seem to go above schema level.\n\nAnyone worked with a modelling tool that can reverse engineer dependencies like this?\n\n&amp;#x200B;", "author_fullname": "t2_2z1ud2z1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse Engineering a multi-database model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4pj29", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709389751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve inherited a large data warehouse that has many different SQL Server Databases.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to understand the structure and relationships of the objects, but there isn&amp;#39;t a data model I can refer to.  The system has grown over many years and has inconsistent names etc. which makes it more difficult to follow.&lt;/p&gt;\n\n&lt;p&gt;The largest issue, is that there are an abundance of nested views which, in turn, reference objects in other databases.  When you dig down through the views, you may even end up back in your original database.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking that I need to reverse engineer it in to a data model so I can see the dependencies and work out what is/isnt required when implementing its replacement.&lt;/p&gt;\n\n&lt;p&gt;Has anyone worked with data modelling tools that handle multi-database dependencies?  I briefly looked at ER/Studio, but it seems to only handle dependencies within the same database when reverse engineering objects.  Even when adding the objects manually, I couldn&amp;#39;t see how the database could be specified for an object, as it didn&amp;#39;t seem to go above schema level.&lt;/p&gt;\n\n&lt;p&gt;Anyone worked with a modelling tool that can reverse engineer dependencies like this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4pj29", "is_robot_indexable": true, "report_reasons": null, "author": "TeflonJacket", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4pj29/reverse_engineering_a_multidatabase_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4pj29/reverse_engineering_a_multidatabase_model/", "subreddit_subscribers": 165290, "created_utc": 1709389751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,  \nSoon I will be joining a new project, seen the board and there is an user story of \"Verify and test spark connectivity\", with no further description. It will take place on Synapse. How would you approach this task? I know I can ask but I've just passed client technical review and wont necessarily go with such question day 1 what did he meant or so. I mean I'll probably go but after doing something on my own and then report that I did this and that and what else he except of me in regards of this user story but I have no idea what to do.. The admin most likely will deploy Synapse spark pool and what, should I just create a notebook in development tab and see if I can execute dataframe creation, read and write using pyspark? This user story has at least 2 story points if I remember correctly which is 1 day, so It cannot be that quick, can it? Thank you in advance for your help!\n\n  \nTL;DR: How to you make sure you have good connectivity of spark in Synapse, how do you test and verify that?", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Verify and test spark connectivity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4mxaf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709384265.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709381640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nSoon I will be joining a new project, seen the board and there is an user story of &amp;quot;Verify and test spark connectivity&amp;quot;, with no further description. It will take place on Synapse. How would you approach this task? I know I can ask but I&amp;#39;ve just passed client technical review and wont necessarily go with such question day 1 what did he meant or so. I mean I&amp;#39;ll probably go but after doing something on my own and then report that I did this and that and what else he except of me in regards of this user story but I have no idea what to do.. The admin most likely will deploy Synapse spark pool and what, should I just create a notebook in development tab and see if I can execute dataframe creation, read and write using pyspark? This user story has at least 2 story points if I remember correctly which is 1 day, so It cannot be that quick, can it? Thank you in advance for your help!&lt;/p&gt;\n\n&lt;p&gt;TL;DR: How to you make sure you have good connectivity of spark in Synapse, how do you test and verify that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4mxaf", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4mxaf/verify_and_test_spark_connectivity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4mxaf/verify_and_test_spark_connectivity/", "subreddit_subscribers": 165290, "created_utc": 1709381640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone share their experience and tech stacks used dealing with these three above. Automation experience will be a plus! Really interested to know what\u2019s the workaround ppl are using to streamline the ETL process to BI reporting / dashboards.", "author_fullname": "t2_vp3nqhfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAP ECC, S/4 HANA and ARIBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4k4hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709370691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone share their experience and tech stacks used dealing with these three above. Automation experience will be a plus! Really interested to know what\u2019s the workaround ppl are using to streamline the ETL process to BI reporting / dashboards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4k4hr", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway-765431", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4k4hr/sap_ecc_s4_hana_and_ariba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4k4hr/sap_ecc_s4_hana_and_ariba/", "subreddit_subscribers": 165290, "created_utc": 1709370691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any recommendations for materials, e.g., blog/textbook, to help with resource planning and design/architecture for cloud migration?", "author_fullname": "t2_6cc9wqbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recs for materials to help with cloud migration resource planning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4gdam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709356620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any recommendations for materials, e.g., blog/textbook, to help with resource planning and design/architecture for cloud migration?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4gdam", "is_robot_indexable": true, "report_reasons": null, "author": "Cultured_dude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4gdam/recs_for_materials_to_help_with_cloud_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4gdam/recs_for_materials_to_help_with_cloud_migration/", "subreddit_subscribers": 165290, "created_utc": 1709356620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Better yet, what am I actually looking for here?\n\nI\u2019m designing a system that handles schedules in a novel way that, based on our review, isn\u2019t offered elsewhere. Honestly the magic boils down to just a handful of presentation choices and feature integrations.\n\nI\u2019m using a relational database and the data, for the most part, fits the model well. One thing that stands out is tasks though\u2026 The tasks have a serial order to them meaning that one gets started only after the prior finishes.\n\nI need to support a query that, given a task and a location, the response is the number of incomplete upstream tasks. This is done by getting all incomplete tasks with an expected start date of less than the given task, within the given location, and returning the count of records.\n\nHowever, tasks are global\u2026 Every single space has the same tasks. Therefore, the serial order for tasks is also global. It\u2019s wasted effort to slice to tasks within the given location, recalculating which are upstream every time as based on a date column. \n\nI could just artificially maintain a serial order column within a tasks table. Values would just count upward, and I as the user would just insert them this way. This is an implicitly maintained rule that\u2019s critical for the system\u2019s functionality though\u2026 I think not.\n\nThen there are trigger functions which likely can be used very effectively. However, they carry a negative connotation due to undesired side effects. It can be difficult to reason about the synergic behavior of relational and functional capabilities at large scale, and humans bite the bullet here eventually. I\u2019d like to avoid triggers if possible.\n\nAre there data models that support this kind of precedence between entities more naturally? \n\nAre there data models that blur the line between relational and what I\u2019m looking for, potentially solving both needs at the same time?", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do relational databases offer a way to require serial order from manually entered data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4e5fn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709349550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Better yet, what am I actually looking for here?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m designing a system that handles schedules in a novel way that, based on our review, isn\u2019t offered elsewhere. Honestly the magic boils down to just a handful of presentation choices and feature integrations.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m using a relational database and the data, for the most part, fits the model well. One thing that stands out is tasks though\u2026 The tasks have a serial order to them meaning that one gets started only after the prior finishes.&lt;/p&gt;\n\n&lt;p&gt;I need to support a query that, given a task and a location, the response is the number of incomplete upstream tasks. This is done by getting all incomplete tasks with an expected start date of less than the given task, within the given location, and returning the count of records.&lt;/p&gt;\n\n&lt;p&gt;However, tasks are global\u2026 Every single space has the same tasks. Therefore, the serial order for tasks is also global. It\u2019s wasted effort to slice to tasks within the given location, recalculating which are upstream every time as based on a date column. &lt;/p&gt;\n\n&lt;p&gt;I could just artificially maintain a serial order column within a tasks table. Values would just count upward, and I as the user would just insert them this way. This is an implicitly maintained rule that\u2019s critical for the system\u2019s functionality though\u2026 I think not.&lt;/p&gt;\n\n&lt;p&gt;Then there are trigger functions which likely can be used very effectively. However, they carry a negative connotation due to undesired side effects. It can be difficult to reason about the synergic behavior of relational and functional capabilities at large scale, and humans bite the bullet here eventually. I\u2019d like to avoid triggers if possible.&lt;/p&gt;\n\n&lt;p&gt;Are there data models that support this kind of precedence between entities more naturally? &lt;/p&gt;\n\n&lt;p&gt;Are there data models that blur the line between relational and what I\u2019m looking for, potentially solving both needs at the same time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4e5fn", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4e5fn/do_relational_databases_offer_a_way_to_require/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4e5fn/do_relational_databases_offer_a_way_to_require/", "subreddit_subscribers": 165290, "created_utc": 1709349550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My client in healthcare uses a hardware device that generates data and saves it into the VM of the hardware manufacturer. The generated data is about 10gb per file. Is there a way to automatically move these files to my own computer? The next step would be to monitor a folder in my computer to upload the file to S3 using multipart upload, but first, the files need to be there in the first place. Any advice would be appreciated. \n", "author_fullname": "t2_tln2vge3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automate data extraction from external VM to my computer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4dnze", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709348099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My client in healthcare uses a hardware device that generates data and saves it into the VM of the hardware manufacturer. The generated data is about 10gb per file. Is there a way to automatically move these files to my own computer? The next step would be to monitor a folder in my computer to upload the file to S3 using multipart upload, but first, the files need to be there in the first place. Any advice would be appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4dnze", "is_robot_indexable": true, "report_reasons": null, "author": "TheQuiteMind", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4dnze/how_to_automate_data_extraction_from_external_vm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4dnze/how_to_automate_data_extraction_from_external_vm/", "subreddit_subscribers": 165290, "created_utc": 1709348099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am trying to read from Mongo using spark mongo connector trying to load 10M rows\n\nAnyone know how I can ignore rows if there is datatype mismatch using my predefined schema. There are some date field which are timestamp but someone inserted String type. There are similar issues with other field. \n\nI want to know how we can handle datatype mismatch, The DROPMALFORMED functionality is not available in Spark Mongo Connector.\n\nAny advice or pointer will be helpful.", "author_fullname": "t2_6klazicf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with Spark and Mongo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4w7pv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709407109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am trying to read from Mongo using spark mongo connector trying to load 10M rows&lt;/p&gt;\n\n&lt;p&gt;Anyone know how I can ignore rows if there is datatype mismatch using my predefined schema. There are some date field which are timestamp but someone inserted String type. There are similar issues with other field. &lt;/p&gt;\n\n&lt;p&gt;I want to know how we can handle datatype mismatch, The DROPMALFORMED functionality is not available in Spark Mongo Connector.&lt;/p&gt;\n\n&lt;p&gt;Any advice or pointer will be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1b4w7pv", "is_robot_indexable": true, "report_reasons": null, "author": "asfifa14", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4w7pv/need_help_with_spark_and_mongo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4w7pv/need_help_with_spark_and_mongo/", "subreddit_subscribers": 165290, "created_utc": 1709407109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can you all please suggest what are some good sources to understand salary trends for data scientist, engineering or even data analysts? - preferably with over the years data as well.\n\nMany thanks for all your suggestions.", "author_fullname": "t2_143jjw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4fngj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709354301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you all please suggest what are some good sources to understand salary trends for data scientist, engineering or even data analysts? - preferably with over the years data as well.&lt;/p&gt;\n\n&lt;p&gt;Many thanks for all your suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1b4fngj", "is_robot_indexable": true, "report_reasons": null, "author": "Jay12a", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4fngj/salary_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4fngj/salary_reports/", "subreddit_subscribers": 165290, "created_utc": 1709354301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context: I have some work experience and have freelanced in this field - Built data pipelines(data engineeiring) and BI dashboards. Mostly inclined towards Azure. I have some other clients as well that are related to that of a software architect. I am considering my options to see if a masters can give me a significant jump. \n\nDoes it necessarily give me an edge? Alternatively, what's the next best thing to do if not a Masters? Would it be working on projects and building my portfolio?", "author_fullname": "t2_rr6r6b8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth Getting going for a Masters in Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4r198", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.48, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1709394218.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709393906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I have some work experience and have freelanced in this field - Built data pipelines(data engineeiring) and BI dashboards. Mostly inclined towards Azure. I have some other clients as well that are related to that of a software architect. I am considering my options to see if a masters can give me a significant jump. &lt;/p&gt;\n\n&lt;p&gt;Does it necessarily give me an edge? Alternatively, what&amp;#39;s the next best thing to do if not a Masters? Would it be working on projects and building my portfolio?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4r198", "is_robot_indexable": true, "report_reasons": null, "author": "_areebpasha", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4r198/is_it_worth_getting_going_for_a_masters_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4r198/is_it_worth_getting_going_for_a_masters_in_data/", "subreddit_subscribers": 165290, "created_utc": 1709393906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would love to create content about data engineering but do not know what you would like or miss. :) ", "author_fullname": "t2_uuylu9emi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data engineering content do you miss on social media?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1b4kxs0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.21, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1709373966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would love to create content about data engineering but do not know what you would like or miss. :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1b4kxs0", "is_robot_indexable": true, "report_reasons": null, "author": "LinasData", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1b4kxs0/what_data_engineering_content_do_you_miss_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1b4kxs0/what_data_engineering_content_do_you_miss_on/", "subreddit_subscribers": 165290, "created_utc": 1709373966.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}