{"kind": "Listing", "data": {"after": "t3_1blps4n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I live in Canada and I\u2019m going to be 27 soon. I studied mechanical engineering and working in auto for a few years before getting a job in the tech industry as a product analyst. My role is has a analytics component to it but it\u2019s a small team so it\u2019s harder to learn when you\u2019ve failed and how you can improve your queries.\n\nI completed a data engineering bootcamp last year and I\u2019m struggling to land a role, the market is abysmal. I\u2019ve had 3 interviews so far and some of them I failed the technical and others I was rejected. \n\nI\u2019m kinda just looking at where my life is going and it\u2019s just embarrassing - 27 and you still don\u2019t have your life figured out and ur basically entry level.\n\nIdk why in posting this it\u2019s basically just a rant.", "author_fullname": "t2_89to7nqdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel like an absolute loser", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bly2h0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711215831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I live in Canada and I\u2019m going to be 27 soon. I studied mechanical engineering and working in auto for a few years before getting a job in the tech industry as a product analyst. My role is has a analytics component to it but it\u2019s a small team so it\u2019s harder to learn when you\u2019ve failed and how you can improve your queries.&lt;/p&gt;\n\n&lt;p&gt;I completed a data engineering bootcamp last year and I\u2019m struggling to land a role, the market is abysmal. I\u2019ve had 3 interviews so far and some of them I failed the technical and others I was rejected. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m kinda just looking at where my life is going and it\u2019s just embarrassing - 27 and you still don\u2019t have your life figured out and ur basically entry level.&lt;/p&gt;\n\n&lt;p&gt;Idk why in posting this it\u2019s basically just a rant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bly2h0", "is_robot_indexable": true, "report_reasons": null, "author": "seikoalpinist197", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bly2h0/feel_like_an_absolute_loser/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bly2h0/feel_like_an_absolute_loser/", "subreddit_subscribers": 171325, "created_utc": 1711215831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your approach to this: you have a bunch of tables, need to do somewhat complex transformations to create new columns based on some business logic. To get from point A to point B will likely take several queries, a bunch of inner, left, and self joins, aggregation, possibly temp tables, etc.\n\nDo you plan it and think about the steps, or do you just launch into the code? For example I paste table snippets of 50 rows into Excel, manually fill in the new columns I need (to help visualize it), think, start coding it, and write down the steps as I go (to keep it straight in my head, otherwise I get lost).\n\nIs there a name for this process - how to plan and envision the steps? FYI, I have enough experience using the SQL other people might call \"advanced\", like window functions, CTEs, regex, etc. \n\nWhere does one learn how to get better at this process?", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you organize and plan complex SQL transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blx4lh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711213439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your approach to this: you have a bunch of tables, need to do somewhat complex transformations to create new columns based on some business logic. To get from point A to point B will likely take several queries, a bunch of inner, left, and self joins, aggregation, possibly temp tables, etc.&lt;/p&gt;\n\n&lt;p&gt;Do you plan it and think about the steps, or do you just launch into the code? For example I paste table snippets of 50 rows into Excel, manually fill in the new columns I need (to help visualize it), think, start coding it, and write down the steps as I go (to keep it straight in my head, otherwise I get lost).&lt;/p&gt;\n\n&lt;p&gt;Is there a name for this process - how to plan and envision the steps? FYI, I have enough experience using the SQL other people might call &amp;quot;advanced&amp;quot;, like window functions, CTEs, regex, etc. &lt;/p&gt;\n\n&lt;p&gt;Where does one learn how to get better at this process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blx4lh", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blx4lh/how_do_you_organize_and_plan_complex_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blx4lh/how_do_you_organize_and_plan_complex_sql/", "subreddit_subscribers": 171325, "created_utc": 1711213439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.\n\nNow I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. ", "author_fullname": "t2_4geyh6db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering with inefficient practices: What is your perspective on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blnf39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711182938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.&lt;/p&gt;\n\n&lt;p&gt;Now I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blnf39", "is_robot_indexable": true, "report_reasons": null, "author": "bloatedboat", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "subreddit_subscribers": 171325, "created_utc": 1711182938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Certain topics, like the shifting and competitive job market and how automation affects employment, often not talked about that much... Even though data engineering positions are expected to remain, the skills required for the roles are likely to change. As the job market grows more competitive, I'm interested in gathering tips to assist data engineers or data scientists. ", "author_fullname": "t2_dxtbgbxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some under-discussed topics within the data engineering community that deserve more focus?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm0v2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711222809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Certain topics, like the shifting and competitive job market and how automation affects employment, often not talked about that much... Even though data engineering positions are expected to remain, the skills required for the roles are likely to change. As the job market grows more competitive, I&amp;#39;m interested in gathering tips to assist data engineers or data scientists. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm0v2c", "is_robot_indexable": true, "report_reasons": null, "author": "jessedata", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm0v2c/what_are_some_underdiscussed_topics_within_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm0v2c/what_are_some_underdiscussed_topics_within_the/", "subreddit_subscribers": 171325, "created_utc": 1711222809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI recently attended the Gartner Data &amp; Analytics Summit held at the Disney Dolphin and Swan hotels in Orlando, FL, and I wanted to share my experience, especially since I run a solo data and analytics boutique focusing on data management, data strategy, data engineering, and data modeling. \n\nThe summit was an excellent opportunity for networking with professionals in the field. It offered a variety of sessions, including roundtables (intimate discussions capped at around 30 participants), vendor sessions (focused on sales pitches for their data governance, mesh, or AI tools), and, most importantly for me, sessions led by Gartner analysts. \n\nMost of the sessions I attended dived into data governance and data product development within organizations, offering high-level frameworks and insights into the organizational change needed for these initiatives. They were incredibly informative, and great for me staying up to date on the latest trends and providing actionable takeaways. I definitely have some more reading to do on my part.\n\nOne of the highlights was chatting with other attendees. One highlight for me, was meeting a seasoned professional who shared his journey from the early days of loading data into tables with COBOL to attending one of Kimball's first seminars on dimensional modeling\u2014I thought this was interesting because I learned dimensional modeling through Kimball's work. \n\nWhile the summit was broadly beneficial, offering insights into industry practices for managing and deriving value from data, it was also an invaluable networking event. However, I wish I could have gotten into one of the roundtable discussions. They can be particularly valuable because they are deep dive sessions into one area that is facilitated by Gartner analysts alongside industry leaders.\n\nThis year\u2019s focus was on Generative AI, almost to the point of overshadowing other discussions. Despite this, I'm excited to attend next year's summit to stay updated on the latest trends and best practices.\n\nIf you have any questions or need more details about the conference, feel free to ask. I'd be happy to share more about my experience.", "author_fullname": "t2_rdorl0euo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gartner Data &amp; Analytics Summit 2024 - My Experience &amp; Key Takeaways", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blwtyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711212706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently attended the Gartner Data &amp;amp; Analytics Summit held at the Disney Dolphin and Swan hotels in Orlando, FL, and I wanted to share my experience, especially since I run a solo data and analytics boutique focusing on data management, data strategy, data engineering, and data modeling. &lt;/p&gt;\n\n&lt;p&gt;The summit was an excellent opportunity for networking with professionals in the field. It offered a variety of sessions, including roundtables (intimate discussions capped at around 30 participants), vendor sessions (focused on sales pitches for their data governance, mesh, or AI tools), and, most importantly for me, sessions led by Gartner analysts. &lt;/p&gt;\n\n&lt;p&gt;Most of the sessions I attended dived into data governance and data product development within organizations, offering high-level frameworks and insights into the organizational change needed for these initiatives. They were incredibly informative, and great for me staying up to date on the latest trends and providing actionable takeaways. I definitely have some more reading to do on my part.&lt;/p&gt;\n\n&lt;p&gt;One of the highlights was chatting with other attendees. One highlight for me, was meeting a seasoned professional who shared his journey from the early days of loading data into tables with COBOL to attending one of Kimball&amp;#39;s first seminars on dimensional modeling\u2014I thought this was interesting because I learned dimensional modeling through Kimball&amp;#39;s work. &lt;/p&gt;\n\n&lt;p&gt;While the summit was broadly beneficial, offering insights into industry practices for managing and deriving value from data, it was also an invaluable networking event. However, I wish I could have gotten into one of the roundtable discussions. They can be particularly valuable because they are deep dive sessions into one area that is facilitated by Gartner analysts alongside industry leaders.&lt;/p&gt;\n\n&lt;p&gt;This year\u2019s focus was on Generative AI, almost to the point of overshadowing other discussions. Despite this, I&amp;#39;m excited to attend next year&amp;#39;s summit to stay updated on the latest trends and best practices.&lt;/p&gt;\n\n&lt;p&gt;If you have any questions or need more details about the conference, feel free to ask. I&amp;#39;d be happy to share more about my experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blwtyr", "is_robot_indexable": true, "report_reasons": null, "author": "data-pro-wizard", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blwtyr/gartner_data_analytics_summit_2024_my_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blwtyr/gartner_data_analytics_summit_2024_my_experience/", "subreddit_subscribers": 171325, "created_utc": 1711212706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any resources for learning of Databricks besides their online materials? Need to get up to speed on it quickly for a new initiative my company is looking to invest in.  I want to understand the common use cases, particularly in healthcare and life sciences, and how companies typically architect/use Databricks.  If you\u2019re in this space already, I appreciate any recommendations or pro-tips. Thanks!", "author_fullname": "t2_8phjzgjz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Databricks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blyr09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711217558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any resources for learning of Databricks besides their online materials? Need to get up to speed on it quickly for a new initiative my company is looking to invest in.  I want to understand the common use cases, particularly in healthcare and life sciences, and how companies typically architect/use Databricks.  If you\u2019re in this space already, I appreciate any recommendations or pro-tips. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blyr09", "is_robot_indexable": true, "report_reasons": null, "author": "spoonorfork1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blyr09/learning_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blyr09/learning_databricks/", "subreddit_subscribers": 171325, "created_utc": 1711217558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings,\n\nWe have a department which has been allowed to build reporting using PowerBI from raw SFDC and NetSuite data which does a significant amount of data transformation in order to create the analytics.  This was built as a quick/dirty solution to financial analytics reporting.  The data is not transformed in any sort of data warehouse infrastructure (ETL or ELT solution) before PowerBI.   Is it common for companies to use PowerBI to do significant transformations instead of using traditional ETL/ELT to prepare the data (like a DW) before being accessed by PowerBI?   The team doing the PowerBI are not analytics  or data engineering professionals and seem to have been doing this as a 'side of desk' solution to side-step a properly engineered DW/ETL solution.   Just wondering.\n\nThanks", "author_fullname": "t2_cymxj8xi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should PowerBI be used to extensively transform incoming data ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bmdd6b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711258577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings,&lt;/p&gt;\n\n&lt;p&gt;We have a department which has been allowed to build reporting using PowerBI from raw SFDC and NetSuite data which does a significant amount of data transformation in order to create the analytics.  This was built as a quick/dirty solution to financial analytics reporting.  The data is not transformed in any sort of data warehouse infrastructure (ETL or ELT solution) before PowerBI.   Is it common for companies to use PowerBI to do significant transformations instead of using traditional ETL/ELT to prepare the data (like a DW) before being accessed by PowerBI?   The team doing the PowerBI are not analytics  or data engineering professionals and seem to have been doing this as a &amp;#39;side of desk&amp;#39; solution to side-step a properly engineered DW/ETL solution.   Just wondering.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bmdd6b", "is_robot_indexable": true, "report_reasons": null, "author": "GreyHairedDWGuy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bmdd6b/should_powerbi_be_used_to_extensively_transform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bmdd6b/should_powerbi_be_used_to_extensively_transform/", "subreddit_subscribers": 171325, "created_utc": 1711258577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm new to this community so apologies in advance if this isn't allowed and I will remove. I'm kind of on my own at work so I thought I'd see what you all think because I've been noodling on this for a few days.\n\nOne of my recent projects ended with me writing a number of SQL queries that are used in tasks. They add or delete rows from a production table meant to show near-real-time analytics to customers. Depending on the trigger my queries do some transformation and add or remove rows from the table, which determines what is visible to the customer. \n\nIf the task that is removing some rows runs at the same time as a task adding rows, the table obviously deadlocks. \n\nI think the best thing to do would be for the tasks to queue up and only run when the previous task is finished, but that's not my jurisdiction. The stopgap my colleagues put in is a fallback that basically reruns the tasks if there's a failure. \n\nFor me to be able to fix it I'd have to do it within SQL, stored procedures, or adjusting the data model. I've been trying to think of a way to maybe queue up all the adds and deletes in one place and apply them every few minutes but that doesn't seem scalable. If anyone has any input I'd love to hear it!", "author_fullname": "t2_avhxmqxxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Queueing\" table inserts and deletes to avoid deadlocking?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm7g5n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711239725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to this community so apologies in advance if this isn&amp;#39;t allowed and I will remove. I&amp;#39;m kind of on my own at work so I thought I&amp;#39;d see what you all think because I&amp;#39;ve been noodling on this for a few days.&lt;/p&gt;\n\n&lt;p&gt;One of my recent projects ended with me writing a number of SQL queries that are used in tasks. They add or delete rows from a production table meant to show near-real-time analytics to customers. Depending on the trigger my queries do some transformation and add or remove rows from the table, which determines what is visible to the customer. &lt;/p&gt;\n\n&lt;p&gt;If the task that is removing some rows runs at the same time as a task adding rows, the table obviously deadlocks. &lt;/p&gt;\n\n&lt;p&gt;I think the best thing to do would be for the tasks to queue up and only run when the previous task is finished, but that&amp;#39;s not my jurisdiction. The stopgap my colleagues put in is a fallback that basically reruns the tasks if there&amp;#39;s a failure. &lt;/p&gt;\n\n&lt;p&gt;For me to be able to fix it I&amp;#39;d have to do it within SQL, stored procedures, or adjusting the data model. I&amp;#39;ve been trying to think of a way to maybe queue up all the adds and deletes in one place and apply them every few minutes but that doesn&amp;#39;t seem scalable. If anyone has any input I&amp;#39;d love to hear it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm7g5n", "is_robot_indexable": true, "report_reasons": null, "author": "APodofFlumphs", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm7g5n/queueing_table_inserts_and_deletes_to_avoid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm7g5n/queueing_table_inserts_and_deletes_to_avoid/", "subreddit_subscribers": 171325, "created_utc": 1711239725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone I joined a mid sized company working on a Machine Learning team. Our team is only 2 years old so we have relatively immature data infrastructure. We recently released a new ML product. Data is sent via a request to our API we return predictions and have another endpoint to collect feedback. Our ML service is hosted on k8s with triton inference server and MongoDB to store user feedback for improving predictions. \n\nOur next initiative is to create a data platform - we chose to use Databricks Lakehouse as the underlying technology. The API is writing the mongodb documents as JSON files to blob storage. These documents contain a lot of fact and dimensional data and we are using autoloader to ingest into databricks. My question is should I be building/updating these dimension tables from the json files? Or should the json artifacts only have fact data and we build the dimension model using cdc from our main application SqlServer db (which I don\u2019t even have access to because it\u2019s maintained by a different team and has an existing sub-par snowflake model).\n\nPlease let me know if you need any clarification and I really appreciate the support. At my previous role, I always had access to the main application db where the dimensional model was already built so I just had to maintain it. Never designed one from scratch.  Thank you!", "author_fullname": "t2_aszk65qa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Dimensional Modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blt82x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711203415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone I joined a mid sized company working on a Machine Learning team. Our team is only 2 years old so we have relatively immature data infrastructure. We recently released a new ML product. Data is sent via a request to our API we return predictions and have another endpoint to collect feedback. Our ML service is hosted on k8s with triton inference server and MongoDB to store user feedback for improving predictions. &lt;/p&gt;\n\n&lt;p&gt;Our next initiative is to create a data platform - we chose to use Databricks Lakehouse as the underlying technology. The API is writing the mongodb documents as JSON files to blob storage. These documents contain a lot of fact and dimensional data and we are using autoloader to ingest into databricks. My question is should I be building/updating these dimension tables from the json files? Or should the json artifacts only have fact data and we build the dimension model using cdc from our main application SqlServer db (which I don\u2019t even have access to because it\u2019s maintained by a different team and has an existing sub-par snowflake model).&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you need any clarification and I really appreciate the support. At my previous role, I always had access to the main application db where the dimensional model was already built so I just had to maintain it. Never designed one from scratch.  Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blt82x", "is_robot_indexable": true, "report_reasons": null, "author": "No_Promotion_729", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blt82x/databricks_dimensional_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blt82x/databricks_dimensional_modeling/", "subreddit_subscribers": 171325, "created_utc": 1711203415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello fellow data engineers! \n\nI recently switched companies and I'm diving into cloud services more extensively than ever before. Previously, I've worked with AWS but approach was waaay different, also I worked in a company that used Snowflake and BigQuery + GCS at another. This new role introduces me to a range of AWS services like Lambda, EC2, Kinesis Data Stream, Kinesis Firehose, Glue, Redshift, DMS, EMR, and more.\n\nIn my previous experiences, we always had code versioning and CI/CD processes using tools like Jenkins or GitLab. Usually, I would create a feature branch from the development branch, commit changes, and push them. After a review, the CI/CD system would handle the deployment to the development environment, and later to production. Production was managed solely through CI/CD pipelines.\n\nHowever, in my current role, the approach is different. Instead of uusing CI/CD for deployments, my team directly writes and tests code on AWS, starting with development tables (code testing), then moving to a staging tables (data validation I guess?!) before deploying to production. This methodology seems to bypass the traditional CI/CD pipeline approach (hands OFF the PROD).\n\nI'm grappling with the concept of having only one AWS environment (production) and testing everything there directly. It raises questions about the necessity of CI/CD. If the Lambda function works in the development environment, does that mean it will work in production without any additional checks or safeguards?\n\nIn my previous experience with Airflow, we maintained separate development and production environments. Changes were tested in the development environment, and upon approval, they were merged into the production branch triggering builds, tests, and deployments automatically and DAGs would be present on Prod without me ever laying a hand on it.\n\nI'm curious to hear about your experiences with implementing code versioning and CI/CD on AWS using GitLab or GitHub. How does your company handle these processes? Thank you for sharing your insights!", "author_fullname": "t2_2jtk54zi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD and Code Versioning on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm3wsz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711230429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data engineers! &lt;/p&gt;\n\n&lt;p&gt;I recently switched companies and I&amp;#39;m diving into cloud services more extensively than ever before. Previously, I&amp;#39;ve worked with AWS but approach was waaay different, also I worked in a company that used Snowflake and BigQuery + GCS at another. This new role introduces me to a range of AWS services like Lambda, EC2, Kinesis Data Stream, Kinesis Firehose, Glue, Redshift, DMS, EMR, and more.&lt;/p&gt;\n\n&lt;p&gt;In my previous experiences, we always had code versioning and CI/CD processes using tools like Jenkins or GitLab. Usually, I would create a feature branch from the development branch, commit changes, and push them. After a review, the CI/CD system would handle the deployment to the development environment, and later to production. Production was managed solely through CI/CD pipelines.&lt;/p&gt;\n\n&lt;p&gt;However, in my current role, the approach is different. Instead of uusing CI/CD for deployments, my team directly writes and tests code on AWS, starting with development tables (code testing), then moving to a staging tables (data validation I guess?!) before deploying to production. This methodology seems to bypass the traditional CI/CD pipeline approach (hands OFF the PROD).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m grappling with the concept of having only one AWS environment (production) and testing everything there directly. It raises questions about the necessity of CI/CD. If the Lambda function works in the development environment, does that mean it will work in production without any additional checks or safeguards?&lt;/p&gt;\n\n&lt;p&gt;In my previous experience with Airflow, we maintained separate development and production environments. Changes were tested in the development environment, and upon approval, they were merged into the production branch triggering builds, tests, and deployments automatically and DAGs would be present on Prod without me ever laying a hand on it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to hear about your experiences with implementing code versioning and CI/CD on AWS using GitLab or GitHub. How does your company handle these processes? Thank you for sharing your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm3wsz", "is_robot_indexable": true, "report_reasons": null, "author": "d_underdog", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bm3wsz/cicd_and_code_versioning_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm3wsz/cicd_and_code_versioning_on_aws/", "subreddit_subscribers": 171325, "created_utc": 1711230429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am checking out DuckDB but it seems like DataFusion can do everything DuckDB can do except some built in extensions provided by DuckDB like postgres.\n\nWhat are some cases for preferring DuckDB over DataFusion? Any experiences to share?", "author_fullname": "t2_20n43h6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When should I prefer DuckDB over DataFusion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm27px", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711226135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am checking out DuckDB but it seems like DataFusion can do everything DuckDB can do except some built in extensions provided by DuckDB like postgres.&lt;/p&gt;\n\n&lt;p&gt;What are some cases for preferring DuckDB over DataFusion? Any experiences to share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm27px", "is_robot_indexable": true, "report_reasons": null, "author": "gibriyagi", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm27px/when_should_i_prefer_duckdb_over_datafusion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm27px/when_should_i_prefer_duckdb_over_datafusion/", "subreddit_subscribers": 171325, "created_utc": 1711226135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Data flow](https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;format=png&amp;auto=webp&amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc)\n\nHi,\n\n&amp;#x200B;\n\nI am trying to setup a pipeline for processing images which will be running OnPrem. I have added a data flow diagram above. There will be 4 docker containers for individual processes. The first container (preprocessing) will fetch images from external API every 5 minutes, process them and then send them to S3 storage. I am thinking of using Airflow here. The problems that I am struggling with are:\n\n1) how do I notify the next container(s) that the images have been processed and ready for transfer? \n\n2) how do I transfer the images for further processing between the containers? \n\nI am open to any and all suggestions but the tools/tech need to be free to use.", "author_fullname": "t2_bmxda7ioc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on how to efficiently create a pipeline for images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "media_metadata": {"85qi28f2n4qc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc6bf22cdd9ee210f26981146b90037c6a8f312f"}, {"y": 134, "x": 216, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=05da27ad865391a874ce7e66a439af7db06c1fe8"}, {"y": 198, "x": 320, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac853bedb09e7b6de92f353cba5479ae88bd713e"}, {"y": 397, "x": 640, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d1f10e5a1791c9891025c20e3740b1651addacc5"}], "s": {"y": 471, "x": 759, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;format=png&amp;auto=webp&amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc"}, "id": "85qi28f2n4qc1"}}, "name": "t3_1blzcx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a31C2UUcyPPK-DQYONOvSz6oNMlzbV00yDZL1QZENWw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711219085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc\"&gt;Data flow&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am trying to setup a pipeline for processing images which will be running OnPrem. I have added a data flow diagram above. There will be 4 docker containers for individual processes. The first container (preprocessing) will fetch images from external API every 5 minutes, process them and then send them to S3 storage. I am thinking of using Airflow here. The problems that I am struggling with are:&lt;/p&gt;\n\n&lt;p&gt;1) how do I notify the next container(s) that the images have been processed and ready for transfer? &lt;/p&gt;\n\n&lt;p&gt;2) how do I transfer the images for further processing between the containers? &lt;/p&gt;\n\n&lt;p&gt;I am open to any and all suggestions but the tools/tech need to be free to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blzcx2", "is_robot_indexable": true, "report_reasons": null, "author": "Even_Work_7995", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blzcx2/looking_for_advice_on_how_to_efficiently_create_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blzcx2/looking_for_advice_on_how_to_efficiently_create_a/", "subreddit_subscribers": 171325, "created_utc": 1711219085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_58s0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built a tool to run classification directly on a database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_1blz3t4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/et58xk3um4qc1/DASH_1080.mp4?source=fallback", "has_audio": false, "height": 1080, "width": 1592, "scrubber_media_url": "https://v.redd.it/et58xk3um4qc1/DASH_96.mp4", "dash_url": "https://v.redd.it/et58xk3um4qc1/DASHPlaylist.mpd?a=1713861488%2CNTlkMjQ4MzczNTI4NWM4MzkwMWU4NTU1NTAxNDk2MDNmZTcxMDJiMmRkNWNhNGY0NzY1NTEzODI4Yzg0YTIzMw%3D%3D&amp;v=1&amp;f=sd", "duration": 23, "hls_url": "https://v.redd.it/et58xk3um4qc1/HLSPlaylist.m3u8?a=1713861488%2COWM0MmU3YzYzM2QwYzdjOWVkZTZhNzMzNTU2ZGU1MjRlMjczM2JmZjVmNTU1ZDAxZTliZDMwNzA4YzBkMDliOA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=140&amp;height=94&amp;crop=140:94,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2d719b9ba6a6729a031d95dd0818e175959675a1", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711218453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/et58xk3um4qc1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?format=pjpg&amp;auto=webp&amp;s=744d369b4b92d8aad1b50a0097cf2f36f32fc2e9", "width": 1592, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2f0a11fcd4a3f4cbe68554a5c3f3ce9a84dbc3f0", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9030be02b75e305f96099b52f581240703373ef0", "width": 216, "height": 146}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0fc2a544f4ee9fdb87c4dbd4b9a83551297a65a1", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9706fb48dbab31f4da91c2cb8afd30ea9b65b224", "width": 640, "height": 434}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=25862ffa68335478a0425d41756ea4c430dcac7f", "width": 960, "height": 651}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8809e081cc61b4526c196ef22cce1a52cc65025b", "width": 1080, "height": 732}], "variants": {}, "id": "MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1blz3t4", "is_robot_indexable": true, "report_reasons": null, "author": "Tylernator", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blz3t4/i_built_a_tool_to_run_classification_directly_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/et58xk3um4qc1", "subreddit_subscribers": 171325, "created_utc": 1711218453.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/et58xk3um4qc1/DASH_1080.mp4?source=fallback", "has_audio": false, "height": 1080, "width": 1592, "scrubber_media_url": "https://v.redd.it/et58xk3um4qc1/DASH_96.mp4", "dash_url": "https://v.redd.it/et58xk3um4qc1/DASHPlaylist.mpd?a=1713861488%2CNTlkMjQ4MzczNTI4NWM4MzkwMWU4NTU1NTAxNDk2MDNmZTcxMDJiMmRkNWNhNGY0NzY1NTEzODI4Yzg0YTIzMw%3D%3D&amp;v=1&amp;f=sd", "duration": 23, "hls_url": "https://v.redd.it/et58xk3um4qc1/HLSPlaylist.m3u8?a=1713861488%2COWM0MmU3YzYzM2QwYzdjOWVkZTZhNzMzNTU2ZGU1MjRlMjczM2JmZjVmNTU1ZDAxZTliZDMwNzA4YzBkMDliOA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was hoping someone could give me a realistic perspective of how far I need to go to get my foot in the door as a Jr. Data Engineer. I am hoping to make a career change out of consulting - I am currently a Senior Product Analyst. Prior to this I was a mechanical engineer for five years. I've found I still don't want anything to do with the political world of business execs, I want to get back in the weeds where I belong and build glorious elegant solutions to weird problems. Efficiency makes me happy.\n\nWhere I am currently:\n\n* I have built a few full-stack applications and am very familiar with React and Postgres.\n* At work I use Python (often starting with a first pass generated by ChatGPT to save time, then refining from there -- everything has to happen fast, and everyone thinks we should just use Excel for everything) to automate a lot of my tasks and try to build leave-behind tools to help others process data. \n   * While I may skimp on the implementation step since I am cheating with AI, I do have to understand:\n      * What is possible\n      * What's the specific set of steps I want to take to achieve this\n      * What data structures will be useful in getting me there\n      * What edge cases and other issues do I need to account for to make this generally applicable\n   * These have included Powerpoint slide generators that take data from an Excel file and populate pre-defined templates to save time in re-spins, an automatic Pareto analyzer for spend data, a variant tree generator for product portfolios, and a bill of materials re-formatter to transform various formats to a consistent hierarchical pattern, enabling further downstream analysis\n* I also use Alteryx a lot at work for a wide variety of tasks, usually for quickly parsing and getting insights from large datasets, and setting up repeatable transformations. \n\n&amp;#x200B;\n\nI understand most of this is Analysis and not Engineering, but I'm wondering if I may be close enough that I could get into a job and learn on the fly after spending a few months doing some self-learning and practice with the basic concepts of data engineering. \n\n**Would appreciate any and all feedback -- don't hold back!**\n\n&amp;#x200B;", "author_fullname": "t2_5i451", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How far do I have to go to become a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bltvss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711205156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was hoping someone could give me a realistic perspective of how far I need to go to get my foot in the door as a Jr. Data Engineer. I am hoping to make a career change out of consulting - I am currently a Senior Product Analyst. Prior to this I was a mechanical engineer for five years. I&amp;#39;ve found I still don&amp;#39;t want anything to do with the political world of business execs, I want to get back in the weeds where I belong and build glorious elegant solutions to weird problems. Efficiency makes me happy.&lt;/p&gt;\n\n&lt;p&gt;Where I am currently:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I have built a few full-stack applications and am very familiar with React and Postgres.&lt;/li&gt;\n&lt;li&gt;At work I use Python (often starting with a first pass generated by ChatGPT to save time, then refining from there -- everything has to happen fast, and everyone thinks we should just use Excel for everything) to automate a lot of my tasks and try to build leave-behind tools to help others process data. \n\n&lt;ul&gt;\n&lt;li&gt;While I may skimp on the implementation step since I am cheating with AI, I do have to understand:\n\n&lt;ul&gt;\n&lt;li&gt;What is possible&lt;/li&gt;\n&lt;li&gt;What&amp;#39;s the specific set of steps I want to take to achieve this&lt;/li&gt;\n&lt;li&gt;What data structures will be useful in getting me there&lt;/li&gt;\n&lt;li&gt;What edge cases and other issues do I need to account for to make this generally applicable&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;These have included Powerpoint slide generators that take data from an Excel file and populate pre-defined templates to save time in re-spins, an automatic Pareto analyzer for spend data, a variant tree generator for product portfolios, and a bill of materials re-formatter to transform various formats to a consistent hierarchical pattern, enabling further downstream analysis&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;I also use Alteryx a lot at work for a wide variety of tasks, usually for quickly parsing and getting insights from large datasets, and setting up repeatable transformations. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I understand most of this is Analysis and not Engineering, but I&amp;#39;m wondering if I may be close enough that I could get into a job and learn on the fly after spending a few months doing some self-learning and practice with the basic concepts of data engineering. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Would appreciate any and all feedback -- don&amp;#39;t hold back!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bltvss", "is_robot_indexable": true, "report_reasons": null, "author": "Pawtang", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bltvss/how_far_do_i_have_to_go_to_become_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bltvss/how_far_do_i_have_to_go_to_become_a_data_engineer/", "subreddit_subscribers": 171325, "created_utc": 1711205156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I'm interested in pursuing a career at Netflix, Can anyone shed some light on what level of experience they usually expect for L4 roles? I know for L5, they typically seek at least 5 years of experience, but I'm curious about what's expected for L4. Thanks in advance for any insights! #Netflix", "author_fullname": "t2_plab96e4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Netflix L4.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bmajc0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711248891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m interested in pursuing a career at Netflix, Can anyone shed some light on what level of experience they usually expect for L4 roles? I know for L5, they typically seek at least 5 years of experience, but I&amp;#39;m curious about what&amp;#39;s expected for L4. Thanks in advance for any insights! #Netflix&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bmajc0", "is_robot_indexable": true, "report_reasons": null, "author": "BalanceOdd144", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bmajc0/netflix_l4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bmajc0/netflix_l4/", "subreddit_subscribers": 171325, "created_utc": 1711248891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe are going to start on a new project where we will be provided data for 9 different clients in csv formats. Data will then need to go through a fairly normal dataflow\n\n1. Data passed to us via the clients' \"drop boxes\"\n2. Data validation and ETL stuff\n3. Stored in Azure SQL\n4. A fairly complex calculation will be applied to the data\n5. Results of calculation stored back in to Azure SQL\n6. Various reporting etc\n7. Process repeated periodically (say twice a month)\n\nOther than being different datasets, the logical steps will be the same for each client. It is likely that throughout the life of the project there will need to be changes to the methodology in step 2 and step 4, when that happens any changes will apply to all clients simultaneously.\n\nLastly, it is critical that there is never a mix up between the 9 clients' data.\n\nThe most robust would seem to be to have completely separate instances of everything, but conversely having 9 copies of python / Spark ETL and calculation code doesn't seem like a good way to do things when it gets updated.\n\nAppreciate any thoughts or any reading I could do.", "author_fullname": "t2_76xailgf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Maintaining separation of data for different clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm2fm9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711226697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We are going to start on a new project where we will be provided data for 9 different clients in csv formats. Data will then need to go through a fairly normal dataflow&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data passed to us via the clients&amp;#39; &amp;quot;drop boxes&amp;quot;&lt;/li&gt;\n&lt;li&gt;Data validation and ETL stuff&lt;/li&gt;\n&lt;li&gt;Stored in Azure SQL&lt;/li&gt;\n&lt;li&gt;A fairly complex calculation will be applied to the data&lt;/li&gt;\n&lt;li&gt;Results of calculation stored back in to Azure SQL&lt;/li&gt;\n&lt;li&gt;Various reporting etc&lt;/li&gt;\n&lt;li&gt;Process repeated periodically (say twice a month)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Other than being different datasets, the logical steps will be the same for each client. It is likely that throughout the life of the project there will need to be changes to the methodology in step 2 and step 4, when that happens any changes will apply to all clients simultaneously.&lt;/p&gt;\n\n&lt;p&gt;Lastly, it is critical that there is never a mix up between the 9 clients&amp;#39; data.&lt;/p&gt;\n\n&lt;p&gt;The most robust would seem to be to have completely separate instances of everything, but conversely having 9 copies of python / Spark ETL and calculation code doesn&amp;#39;t seem like a good way to do things when it gets updated.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any thoughts or any reading I could do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm2fm9", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Isopod4493", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm2fm9/maintaining_separation_of_data_for_different/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm2fm9/maintaining_separation_of_data_for_different/", "subreddit_subscribers": 171325, "created_utc": 1711226697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of the work is done on Epic systems like Cogito, Caboodle and Clarity using SQL to source data.\nTeams are transitioning to Snowflake and dbt but also mainly focused on Epic suite.", "author_fullname": "t2_ryxoz6of4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there good scope in data engineering in a non profit healthcare company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bly2lq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711215842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the work is done on Epic systems like Cogito, Caboodle and Clarity using SQL to source data.\nTeams are transitioning to Snowflake and dbt but also mainly focused on Epic suite.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bly2lq", "is_robot_indexable": true, "report_reasons": null, "author": "UnfairDiscount8331", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bly2lq/is_there_good_scope_in_data_engineering_in_a_non/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bly2lq/is_there_good_scope_in_data_engineering_in_a_non/", "subreddit_subscribers": 171325, "created_utc": 1711215842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So at work I was handed a spring boot application to do some minor changes to inject a service to manipulate and load  some kstream data into a topic and load some data to postgres.\nI only use python and HiveQL otherwise for the past 5 years.\nWill learning kotlin be of any use or should I just not bother too much with it.", "author_fullname": "t2_5y5mt5wer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will learning kotlin be beneficial in my data engineering career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blsz6g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711202763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So at work I was handed a spring boot application to do some minor changes to inject a service to manipulate and load  some kstream data into a topic and load some data to postgres.\nI only use python and HiveQL otherwise for the past 5 years.\nWill learning kotlin be of any use or should I just not bother too much with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blsz6g", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient_Example30", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blsz6g/will_learning_kotlin_be_beneficial_in_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blsz6g/will_learning_kotlin_be_beneficial_in_my_data/", "subreddit_subscribers": 171325, "created_utc": 1711202763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an use case where I have to create STM document(Source to Target Mapping). \n\nI want to get the business logic which is being applied on a column, along with the column lineage.\n\nUsing databricks api, I got all the required lineage info of each column, but I want to get the business rule as well. For example, Col A from table-A is an union of Col B and Col C of table-B, I want to document this business logic which is union. \nCan that be done in Databricks? \nI wonder Alation/Prophecy would be able to do that? Any thoughts or help on this? Thank you", "author_fullname": "t2_4njp7ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Column level Business rule along with Lineage in Databricks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bls2gy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711200191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an use case where I have to create STM document(Source to Target Mapping). &lt;/p&gt;\n\n&lt;p&gt;I want to get the business logic which is being applied on a column, along with the column lineage.&lt;/p&gt;\n\n&lt;p&gt;Using databricks api, I got all the required lineage info of each column, but I want to get the business rule as well. For example, Col A from table-A is an union of Col B and Col C of table-B, I want to document this business logic which is union. \nCan that be done in Databricks? \nI wonder Alation/Prophecy would be able to do that? Any thoughts or help on this? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bls2gy", "is_robot_indexable": true, "report_reasons": null, "author": "ravitejasurla", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bls2gy/column_level_business_rule_along_with_lineage_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bls2gy/column_level_business_rule_along_with_lineage_in/", "subreddit_subscribers": 171325, "created_utc": 1711200191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am looking to provide chargeable mentorship/career counseling in data field. Please recommend some platform to register. I am from India.", "author_fullname": "t2_uwpususkt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paid Mentoring platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bme8ck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711262026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am looking to provide chargeable mentorship/career counseling in data field. Please recommend some platform to register. I am from India.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bme8ck", "is_robot_indexable": true, "report_reasons": null, "author": "pyare-p13", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bme8ck/paid_mentoring_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bme8ck/paid_mentoring_platforms/", "subreddit_subscribers": 171325, "created_utc": 1711262026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, i am searching for ways to implement complex event processing, my use case is i have a bunch of systems sending events in kafka, i want to process and correlate these events to gain insights and alerts.\nThe problem is that i need to allow the user to change the rules and templates through some kind of ui based on their changing needs.\nI looked into Apache Flink but it doesn't seem to support user defined querys and rules.\nDoes anyone know a way of achieving this?\nI attached a presentation by Uber that covers exactly my use case however it is from 2017 and seems a bit outdated", "author_fullname": "t2_re31tw67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dynamic rules and templates for Complex Event Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1blt70j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nncxYGD6m7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nncxYGD6m7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017\"&gt;&lt;/iframe&gt;", "author_name": "WSO2", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/nncxYGD6m7E/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WSO2official"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nncxYGD6m7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1blt70j", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/unwgbLes0IOaLE_BBjsfe6cfCIF1QIrbrdzYPphfEw4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711203338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i am searching for ways to implement complex event processing, my use case is i have a bunch of systems sending events in kafka, i want to process and correlate these events to gain insights and alerts.\nThe problem is that i need to allow the user to change the rules and templates through some kind of ui based on their changing needs.\nI looked into Apache Flink but it doesn&amp;#39;t seem to support user defined querys and rules.\nDoes anyone know a way of achieving this?\nI attached a presentation by Uber that covers exactly my use case however it is from 2017 and seems a bit outdated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/nncxYGD6m7E?si=HkvADsHJIQ8ZmF2O", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yheLXINMWSHycWMhfNt7TwGa95_dV5IwJ99FXkC8ps8.jpg?auto=webp&amp;s=ccdc89eea4cdd22210e90e2da960a7e579f7b35a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/yheLXINMWSHycWMhfNt7TwGa95_dV5IwJ99FXkC8ps8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d4fb3b162872036fb58be69480985712ccd3e8f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/yheLXINMWSHycWMhfNt7TwGa95_dV5IwJ99FXkC8ps8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dffc8d76a77acb4e09beddc4f15f2302b3e522be", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/yheLXINMWSHycWMhfNt7TwGa95_dV5IwJ99FXkC8ps8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e0f3779d4079f6425ea88a75e094b4845b81cf12", "width": 320, "height": 240}], "variants": {}, "id": "xDgdhPdPXUACgx8OrY9WY6BPTtmQuyomJ9w0b07m90c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blt70j", "is_robot_indexable": true, "report_reasons": null, "author": "shaiiii5", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blt70j/dynamic_rules_and_templates_for_complex_event/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/nncxYGD6m7E?si=HkvADsHJIQ8ZmF2O", "subreddit_subscribers": 171325, "created_utc": 1711203338.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nncxYGD6m7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017\"&gt;&lt;/iframe&gt;", "author_name": "WSO2", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/nncxYGD6m7E/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WSO2official"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your take on AI plug-ins for Databases ? Do you use it regularly and has it improved productivity? \n", "author_fullname": "t2_aryc45smm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI plugins for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blph0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711191346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your take on AI plug-ins for Databases ? Do you use it regularly and has it improved productivity? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blph0c", "is_robot_indexable": true, "report_reasons": null, "author": "Paperplaneflyr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blph0c/ai_plugins_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blph0c/ai_plugins_for_de/", "subreddit_subscribers": 171325, "created_utc": 1711191346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to consume some data from an API. One of the endpoint will return a list of regions in the UK. The data returned from this API will likely be the same 99.999% of the time given that these won't change very often. However that being said, I need to check this daily to ensure any changes are picked up.\n\nWhen consuming this data into the raw layer of the medallion architecture, what's best practice? Do I save the data every time the API is called, meaning having daily copies of the same data?", "author_fullname": "t2_wrxuebqcg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consuming API data into Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bloqle", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711188441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to consume some data from an API. One of the endpoint will return a list of regions in the UK. The data returned from this API will likely be the same 99.999% of the time given that these won&amp;#39;t change very often. However that being said, I need to check this daily to ensure any changes are picked up.&lt;/p&gt;\n\n&lt;p&gt;When consuming this data into the raw layer of the medallion architecture, what&amp;#39;s best practice? Do I save the data every time the API is called, meaning having daily copies of the same data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bloqle", "is_robot_indexable": true, "report_reasons": null, "author": "Sad-Entrepreneur1027", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bloqle/consuming_api_data_into_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bloqle/consuming_api_data_into_spark/", "subreddit_subscribers": 171325, "created_utc": 1711188441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nWe are working on a project where the architecture will be like:\n\nADF --&gt; Dabtabricks(ETL) --&gt; Synapse(BI layer)\n\nAnd everything is stored in ADLS gen2.\n\nThe reason we chose Synapse was because our BI team wanted something similar to SQL as they have reports datasets written in SQL and wanted a platform to access databases same way they do now.\n\n&amp;#x200B;\n\nAnd now we have dedicated SQL pools for them and they would access data stored in silver and gold layer. \n\n&amp;#x200B;\n\nSo either we copy the data every day and do duplication of data. ( more development effort to upsert the data and since we copying data, more time taken to finish the whole process.)\n\nOR\n\nwrite external tables for each table. ( less development effort but network latency and not as optimized as internal tables)\n\nWe process close to 4-5 million records in a day to give you estimate on the volume.\n\n&amp;#x200B;\n\nOr if there is another solution I am overlooking?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_kz99f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Copy data into dedicated SQL pool from Databricks or create External tables in Synapse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm2imt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711226908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;We are working on a project where the architecture will be like:&lt;/p&gt;\n\n&lt;p&gt;ADF --&amp;gt; Dabtabricks(ETL) --&amp;gt; Synapse(BI layer)&lt;/p&gt;\n\n&lt;p&gt;And everything is stored in ADLS gen2.&lt;/p&gt;\n\n&lt;p&gt;The reason we chose Synapse was because our BI team wanted something similar to SQL as they have reports datasets written in SQL and wanted a platform to access databases same way they do now.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;And now we have dedicated SQL pools for them and they would access data stored in silver and gold layer. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So either we copy the data every day and do duplication of data. ( more development effort to upsert the data and since we copying data, more time taken to finish the whole process.)&lt;/p&gt;\n\n&lt;p&gt;OR&lt;/p&gt;\n\n&lt;p&gt;write external tables for each table. ( less development effort but network latency and not as optimized as internal tables)&lt;/p&gt;\n\n&lt;p&gt;We process close to 4-5 million records in a day to give you estimate on the volume.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or if there is another solution I am overlooking?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm2imt", "is_robot_indexable": true, "report_reasons": null, "author": "jerrie86", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm2imt/copy_data_into_dedicated_sql_pool_from_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm2imt/copy_data_into_dedicated_sql_pool_from_databricks/", "subreddit_subscribers": 171325, "created_utc": 1711226908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Talking about [this one](https://careerbootcamps.tlcenter.wustl.edu/programs/data-engineering/), also found in [Springboard](https://www.springboard.com/courses/data-engineering-career-track/). They seem to provide a lot more career coaching/mentoring which I think I need, let you fast-track to complete in less time, and make you do portfolio projects. Their mantra is that portfolio projects (involving AWS, Azure, Hadoop, Spark, etc) will set me apart.\n\n[dataengineercamp.com](https://dataengineercamp.com/) seems like a similar one but I haven't talked to them yet.\n\nAbout me: I'm a May 2024 grad experienced in Data Science, ML, Python, SQL, etc, but not much else. I did have 1 DE internship involving Kafka/Confluent though. Didn't have success in the market even after several interviews, so I'm looking into DE bootcamps + certifications to expand my skillsets. I have the funds and I want coaching, so I'm just trying to choose the right program.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_1likqpjn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on WashU St. Louis DE bootcamp (shown in Springboard)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blps4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711192824.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711192493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talking about &lt;a href=\"https://careerbootcamps.tlcenter.wustl.edu/programs/data-engineering/\"&gt;this one&lt;/a&gt;, also found in &lt;a href=\"https://www.springboard.com/courses/data-engineering-career-track/\"&gt;Springboard&lt;/a&gt;. They seem to provide a lot more career coaching/mentoring which I think I need, let you fast-track to complete in less time, and make you do portfolio projects. Their mantra is that portfolio projects (involving AWS, Azure, Hadoop, Spark, etc) will set me apart.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dataengineercamp.com/\"&gt;dataengineercamp.com&lt;/a&gt; seems like a similar one but I haven&amp;#39;t talked to them yet.&lt;/p&gt;\n\n&lt;p&gt;About me: I&amp;#39;m a May 2024 grad experienced in Data Science, ML, Python, SQL, etc, but not much else. I did have 1 DE internship involving Kafka/Confluent though. Didn&amp;#39;t have success in the market even after several interviews, so I&amp;#39;m looking into DE bootcamps + certifications to expand my skillsets. I have the funds and I want coaching, so I&amp;#39;m just trying to choose the right program.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FnGEU5CoOCD9so2ksNzVCeQQs-OuVgArdxvP0bJiLtQ.jpg?auto=webp&amp;s=36c1bd6b2462692c4e32cb95d99c65b2f660ba54", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/FnGEU5CoOCD9so2ksNzVCeQQs-OuVgArdxvP0bJiLtQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0158e8a0bfac3578e30a2e4b5ac54322ac9a930", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/FnGEU5CoOCD9so2ksNzVCeQQs-OuVgArdxvP0bJiLtQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=760d44aaff5a6ae53afe2ba71e65f69ecdd9a3fa", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/FnGEU5CoOCD9so2ksNzVCeQQs-OuVgArdxvP0bJiLtQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=84bb68b11de33cb820f6b24892990cc8007a341f", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/FnGEU5CoOCD9so2ksNzVCeQQs-OuVgArdxvP0bJiLtQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b45b7e6e9d43d42b5debefb3f4bd6b7707717a76", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/FnGEU5CoOCD9so2ksNzVCeQQs-OuVgArdxvP0bJiLtQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c37dc7ff7a56f2695728f4a60ea7ab11cb948263", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/FnGEU5CoOCD9so2ksNzVCeQQs-OuVgArdxvP0bJiLtQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77e489125f5f695bd8340d8f07fc03d920779c46", "width": 1080, "height": 564}], "variants": {}, "id": "9HqplvvkH4m2W1R5clcUvNqPLh_F1hWEvexVbf_G8lQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1blps4n", "is_robot_indexable": true, "report_reasons": null, "author": "Unusuala1l2e3x4", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blps4n/thoughts_on_washu_st_louis_de_bootcamp_shown_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blps4n/thoughts_on_washu_st_louis_de_bootcamp_shown_in/", "subreddit_subscribers": 171325, "created_utc": 1711192493.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}