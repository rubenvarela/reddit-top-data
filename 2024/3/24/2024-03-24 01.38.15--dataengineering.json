{"kind": "Listing", "data": {"after": "t3_1blt70j", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I live in Canada and I\u2019m going to be 27 soon. I studied mechanical engineering and working in auto for a few years before getting a job in the tech industry as a product analyst. My role is has a analytics component to it but it\u2019s a small team so it\u2019s harder to learn when you\u2019ve failed and how you can improve your queries.\n\nI completed a data engineering bootcamp last year and I\u2019m struggling to land a role, the market is abysmal. I\u2019ve had 3 interviews so far and some of them I failed the technical and others I was rejected. \n\nI\u2019m kinda just looking at where my life is going and it\u2019s just embarrassing - 27 and you still don\u2019t have your life figured out and ur basically entry level.\n\nIdk why in posting this it\u2019s basically just a rant.", "author_fullname": "t2_89to7nqdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel like an absolute loser", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bly2h0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711215831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I live in Canada and I\u2019m going to be 27 soon. I studied mechanical engineering and working in auto for a few years before getting a job in the tech industry as a product analyst. My role is has a analytics component to it but it\u2019s a small team so it\u2019s harder to learn when you\u2019ve failed and how you can improve your queries.&lt;/p&gt;\n\n&lt;p&gt;I completed a data engineering bootcamp last year and I\u2019m struggling to land a role, the market is abysmal. I\u2019ve had 3 interviews so far and some of them I failed the technical and others I was rejected. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m kinda just looking at where my life is going and it\u2019s just embarrassing - 27 and you still don\u2019t have your life figured out and ur basically entry level.&lt;/p&gt;\n\n&lt;p&gt;Idk why in posting this it\u2019s basically just a rant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bly2h0", "is_robot_indexable": true, "report_reasons": null, "author": "seikoalpinist197", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bly2h0/feel_like_an_absolute_loser/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bly2h0/feel_like_an_absolute_loser/", "subreddit_subscribers": 171260, "created_utc": 1711215831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically title. I\u2019m a Jr Data Engineer in a big four company, I work mostly on the cloud with GCP and sometimes I work with Python to automate my daily schedule lol. Recently a manager quitted and he was the owner of some important processes that were used for some BI dashboards and all that, they gave everything to me, what it\u2019s bothering me is that all the scripts are modeled in R, I don\u2019t really care about it because they\u2019re easy to run, but I live with the constant fear of what will happen when they need to change the logic of some column or need to merge some new fields, since I do not know shit about R, and his scripts are huge and pretty complex, so studying and understanding the logic of all of them have been a pain in the ass for me, I want to migrate the logic of the scripts to Python but I know it\u2019s not gonna be easy and will probably take me more than what I want to spend doing it. Any suggestions or advices?", "author_fullname": "t2_wksnouv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you when your organization gives you scripts or tasks from exemployees in a language you don\u2019t really understand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blke3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711175205.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711170679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically title. I\u2019m a Jr Data Engineer in a big four company, I work mostly on the cloud with GCP and sometimes I work with Python to automate my daily schedule lol. Recently a manager quitted and he was the owner of some important processes that were used for some BI dashboards and all that, they gave everything to me, what it\u2019s bothering me is that all the scripts are modeled in R, I don\u2019t really care about it because they\u2019re easy to run, but I live with the constant fear of what will happen when they need to change the logic of some column or need to merge some new fields, since I do not know shit about R, and his scripts are huge and pretty complex, so studying and understanding the logic of all of them have been a pain in the ass for me, I want to migrate the logic of the scripts to Python but I know it\u2019s not gonna be easy and will probably take me more than what I want to spend doing it. Any suggestions or advices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blke3g", "is_robot_indexable": true, "report_reasons": null, "author": "Ivan_GL7", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blke3g/what_do_you_when_your_organization_gives_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blke3g/what_do_you_when_your_organization_gives_you/", "subreddit_subscribers": 171260, "created_utc": 1711170679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.\n\nNow I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. ", "author_fullname": "t2_4geyh6db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering with inefficient practices: What is your perspective on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blnf39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711182938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we all know, data engineering has a lot of shortcuts where when you start out that you can do inefficient data practices i.e. have your tables denormalised and do on top full table upsert that the ROI cost part is negligent to the business outcome values and less manpower need it in comparison to accomplish the same things efficiently which will take longer time and cost more at start.&lt;/p&gt;\n\n&lt;p&gt;Now I see a lot of data topics that \u201cthis is too expensive\u201d and \u201chow to reduce costs\u201d popping up here and there meaning that many in our career did not put the homework or want to figure or understand how the cost will scale as they use these tool. Most treat them as black box and thank the AI lords that everything will be automated with a big magic button. Correct me if I am wrong, but won\u2019t all this SaaS and cloud vendors go bankrupt or their stock will take a huge dive if they give all their black box services out of the box efficiently as possible that will charge customers less in the first place? I always feel those data cloud providers and vendors are like a free to play gacha game. If you know how to use these tools properly, you have to grind a lot to get most of the stuff to be almost free. Otherwise if you don\u2019t have the time to do that, you have to pay a hefty amount. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blnf39", "is_robot_indexable": true, "report_reasons": null, "author": "bloatedboat", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blnf39/data_engineering_with_inefficient_practices_what/", "subreddit_subscribers": 171260, "created_utc": 1711182938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So basically we have 50+ employees who use google sheets to update daily data. Like how many customers were seen, the why, and where. This data goes through a process from checking the data, posting it and then sending to be billed and finally billing it. All of this is done in google sheets by updating designated column. Multiple employees come to this sheet, do their job and leave it for the next employee.\n\nOn the other hand I use PowerBI to build weekly dashboards. First I started to copy paste data from 50 sheets, transform in excel, clean, and load in powerBi and build my report. This turned nightmare when my manager asked for an update of the same report ( coz not all customers are billed the same day/week and we want to see how many where billed vs not billed and why there were nt billed or whre in the process of billing are we for that particular customer). I had to copy paste values again from google sheet, clean and transform and then send report again. Now imagine having to do this every week. Workload only builds up. \n\nI started connecting google sheets directly to powerbI and refresh it before sending an update and to my surprise all the data was updated and accurate. But I still get overload error which has to do with api overload I believe. Hence, looking for another system to do most of the cleaning and transformation and storing. \n\nAnother problem Im trying to solve is if my manager asks for report on quarterly basis, I need to spend a week gathering data and this cannot be done linking google sheets to powerBi coz im sure powerbi is simply gonna shut down which all those spreadsheets and individual sheets inside those soreadsheets \n\nWe do not have a database system. And sometimes powerbi throws overload error when I have so many sheets connected. \n\nIm expecting a system that lies between google sheet and powerBI. This system should should be connected to google sheets, and constanly be refreshing data (like streaming data or batch processing atleast 1 refresh every hour) so that we can have a clear number of how many customers were billed in the start of the day vs end. And while this system should transform, clean and store data in a way I would do in powerBI. And then I want powerBI to link to this system to do my analytics without spending much time in transforming while also be able to do quaterly analysis\n\nIhv asked this question a few times here but because I have limited knowledge of databases, im confused. Ihv been researching alot abt big query, azure and snowflake. But still nt sure which one is perfect for this case. \n", "author_fullname": "t2_83gq3oxts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google sheets \u2014-&gt; ???? \u2014\u2014-&gt; PowerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bliedv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711166291.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711164059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically we have 50+ employees who use google sheets to update daily data. Like how many customers were seen, the why, and where. This data goes through a process from checking the data, posting it and then sending to be billed and finally billing it. All of this is done in google sheets by updating designated column. Multiple employees come to this sheet, do their job and leave it for the next employee.&lt;/p&gt;\n\n&lt;p&gt;On the other hand I use PowerBI to build weekly dashboards. First I started to copy paste data from 50 sheets, transform in excel, clean, and load in powerBi and build my report. This turned nightmare when my manager asked for an update of the same report ( coz not all customers are billed the same day/week and we want to see how many where billed vs not billed and why there were nt billed or whre in the process of billing are we for that particular customer). I had to copy paste values again from google sheet, clean and transform and then send report again. Now imagine having to do this every week. Workload only builds up. &lt;/p&gt;\n\n&lt;p&gt;I started connecting google sheets directly to powerbI and refresh it before sending an update and to my surprise all the data was updated and accurate. But I still get overload error which has to do with api overload I believe. Hence, looking for another system to do most of the cleaning and transformation and storing. &lt;/p&gt;\n\n&lt;p&gt;Another problem Im trying to solve is if my manager asks for report on quarterly basis, I need to spend a week gathering data and this cannot be done linking google sheets to powerBi coz im sure powerbi is simply gonna shut down which all those spreadsheets and individual sheets inside those soreadsheets &lt;/p&gt;\n\n&lt;p&gt;We do not have a database system. And sometimes powerbi throws overload error when I have so many sheets connected. &lt;/p&gt;\n\n&lt;p&gt;Im expecting a system that lies between google sheet and powerBI. This system should should be connected to google sheets, and constanly be refreshing data (like streaming data or batch processing atleast 1 refresh every hour) so that we can have a clear number of how many customers were billed in the start of the day vs end. And while this system should transform, clean and store data in a way I would do in powerBI. And then I want powerBI to link to this system to do my analytics without spending much time in transforming while also be able to do quaterly analysis&lt;/p&gt;\n\n&lt;p&gt;Ihv asked this question a few times here but because I have limited knowledge of databases, im confused. Ihv been researching alot abt big query, azure and snowflake. But still nt sure which one is perfect for this case. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bliedv", "is_robot_indexable": true, "report_reasons": null, "author": "FigTraditional1201", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bliedv/google_sheets_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bliedv/google_sheets_powerbi/", "subreddit_subscribers": 171260, "created_utc": 1711164059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is your approach to this: you have a bunch of tables, need to do somewhat complex transformations to create new columns based on some business logic. To get from point A to point B will likely take several queries, a bunch of inner, left, and self joins, aggregation, possibly temp tables, etc.\n\nDo you plan it and think about the steps, or do you just launch into the code? For example I paste table snippets of 50 rows into Excel, manually fill in the new columns I need (to help visualize it), think, start coding it, and write down the steps as I go (to keep it straight in my head, otherwise I get lost).\n\nIs there a name for this process - how to plan and envision the steps? FYI, I have enough experience using the SQL other people might call \"advanced\", like window functions, CTEs, regex, etc. \n\nWhere does one learn how to get better at this process?", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you organize and plan complex SQL transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blx4lh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711213439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is your approach to this: you have a bunch of tables, need to do somewhat complex transformations to create new columns based on some business logic. To get from point A to point B will likely take several queries, a bunch of inner, left, and self joins, aggregation, possibly temp tables, etc.&lt;/p&gt;\n\n&lt;p&gt;Do you plan it and think about the steps, or do you just launch into the code? For example I paste table snippets of 50 rows into Excel, manually fill in the new columns I need (to help visualize it), think, start coding it, and write down the steps as I go (to keep it straight in my head, otherwise I get lost).&lt;/p&gt;\n\n&lt;p&gt;Is there a name for this process - how to plan and envision the steps? FYI, I have enough experience using the SQL other people might call &amp;quot;advanced&amp;quot;, like window functions, CTEs, regex, etc. &lt;/p&gt;\n\n&lt;p&gt;Where does one learn how to get better at this process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blx4lh", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blx4lh/how_do_you_organize_and_plan_complex_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blx4lh/how_do_you_organize_and_plan_complex_sql/", "subreddit_subscribers": 171260, "created_utc": 1711213439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone I joined a mid sized company working on a Machine Learning team. Our team is only 2 years old so we have relatively immature data infrastructure. We recently released a new ML product. Data is sent via a request to our API we return predictions and have another endpoint to collect feedback. Our ML service is hosted on k8s with triton inference server and MongoDB to store user feedback for improving predictions. \n\nOur next initiative is to create a data platform - we chose to use Databricks Lakehouse as the underlying technology. The API is writing the mongodb documents as JSON files to blob storage. These documents contain a lot of fact and dimensional data and we are using autoloader to ingest into databricks. My question is should I be building/updating these dimension tables from the json files? Or should the json artifacts only have fact data and we build the dimension model using cdc from our main application SqlServer db (which I don\u2019t even have access to because it\u2019s maintained by a different team and has an existing sub-par snowflake model).\n\nPlease let me know if you need any clarification and I really appreciate the support. At my previous role, I always had access to the main application db where the dimensional model was already built so I just had to maintain it. Never designed one from scratch.  Thank you!", "author_fullname": "t2_aszk65qa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Dimensional Modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blt82x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711203415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone I joined a mid sized company working on a Machine Learning team. Our team is only 2 years old so we have relatively immature data infrastructure. We recently released a new ML product. Data is sent via a request to our API we return predictions and have another endpoint to collect feedback. Our ML service is hosted on k8s with triton inference server and MongoDB to store user feedback for improving predictions. &lt;/p&gt;\n\n&lt;p&gt;Our next initiative is to create a data platform - we chose to use Databricks Lakehouse as the underlying technology. The API is writing the mongodb documents as JSON files to blob storage. These documents contain a lot of fact and dimensional data and we are using autoloader to ingest into databricks. My question is should I be building/updating these dimension tables from the json files? Or should the json artifacts only have fact data and we build the dimension model using cdc from our main application SqlServer db (which I don\u2019t even have access to because it\u2019s maintained by a different team and has an existing sub-par snowflake model).&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you need any clarification and I really appreciate the support. At my previous role, I always had access to the main application db where the dimensional model was already built so I just had to maintain it. Never designed one from scratch.  Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blt82x", "is_robot_indexable": true, "report_reasons": null, "author": "No_Promotion_729", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blt82x/databricks_dimensional_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blt82x/databricks_dimensional_modeling/", "subreddit_subscribers": 171260, "created_utc": 1711203415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Certain topics, like the shifting and competitive job market and how automation affects employment, often not talked about that much... Even though data engineering positions are expected to remain, the skills required for the roles are likely to change. As the job market grows more competitive, I'm interested in gathering tips to assist data engineers or data scientists. ", "author_fullname": "t2_dxtbgbxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some under-discussed topics within the data engineering community that deserve more focus?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm0v2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711222809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Certain topics, like the shifting and competitive job market and how automation affects employment, often not talked about that much... Even though data engineering positions are expected to remain, the skills required for the roles are likely to change. As the job market grows more competitive, I&amp;#39;m interested in gathering tips to assist data engineers or data scientists. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm0v2c", "is_robot_indexable": true, "report_reasons": null, "author": "jessedata", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm0v2c/what_are_some_underdiscussed_topics_within_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm0v2c/what_are_some_underdiscussed_topics_within_the/", "subreddit_subscribers": 171260, "created_utc": 1711222809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI recently attended the Gartner Data &amp; Analytics Summit held at the Disney Dolphin and Swan hotels in Orlando, FL, and I wanted to share my experience, especially since I run a solo data and analytics boutique focusing on data management, data strategy, data engineering, and data modeling. \n\nThe summit was an excellent opportunity for networking with professionals in the field. It offered a variety of sessions, including roundtables (intimate discussions capped at around 30 participants), vendor sessions (focused on sales pitches for their data governance, mesh, or AI tools), and, most importantly for me, sessions led by Gartner analysts. \n\nMost of the sessions I attended dived into data governance and data product development within organizations, offering high-level frameworks and insights into the organizational change needed for these initiatives. They were incredibly informative, and great for me staying up to date on the latest trends and providing actionable takeaways. I definitely have some more reading to do on my part.\n\nOne of the highlights was chatting with other attendees. One highlight for me, was meeting a seasoned professional who shared his journey from the early days of loading data into tables with COBOL to attending one of Kimball's first seminars on dimensional modeling\u2014I thought this was interesting because I learned dimensional modeling through Kimball's work. \n\nWhile the summit was broadly beneficial, offering insights into industry practices for managing and deriving value from data, it was also an invaluable networking event. However, I wish I could have gotten into one of the roundtable discussions. They can be particularly valuable because they are deep dive sessions into one area that is facilitated by Gartner analysts alongside industry leaders.\n\nThis year\u2019s focus was on Generative AI, almost to the point of overshadowing other discussions. Despite this, I'm excited to attend next year's summit to stay updated on the latest trends and best practices.\n\nIf you have any questions or need more details about the conference, feel free to ask. I'd be happy to share more about my experience.", "author_fullname": "t2_rdorl0euo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gartner Data &amp; Analytics Summit 2024 - My Experience &amp; Key Takeaways", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blwtyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711212706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently attended the Gartner Data &amp;amp; Analytics Summit held at the Disney Dolphin and Swan hotels in Orlando, FL, and I wanted to share my experience, especially since I run a solo data and analytics boutique focusing on data management, data strategy, data engineering, and data modeling. &lt;/p&gt;\n\n&lt;p&gt;The summit was an excellent opportunity for networking with professionals in the field. It offered a variety of sessions, including roundtables (intimate discussions capped at around 30 participants), vendor sessions (focused on sales pitches for their data governance, mesh, or AI tools), and, most importantly for me, sessions led by Gartner analysts. &lt;/p&gt;\n\n&lt;p&gt;Most of the sessions I attended dived into data governance and data product development within organizations, offering high-level frameworks and insights into the organizational change needed for these initiatives. They were incredibly informative, and great for me staying up to date on the latest trends and providing actionable takeaways. I definitely have some more reading to do on my part.&lt;/p&gt;\n\n&lt;p&gt;One of the highlights was chatting with other attendees. One highlight for me, was meeting a seasoned professional who shared his journey from the early days of loading data into tables with COBOL to attending one of Kimball&amp;#39;s first seminars on dimensional modeling\u2014I thought this was interesting because I learned dimensional modeling through Kimball&amp;#39;s work. &lt;/p&gt;\n\n&lt;p&gt;While the summit was broadly beneficial, offering insights into industry practices for managing and deriving value from data, it was also an invaluable networking event. However, I wish I could have gotten into one of the roundtable discussions. They can be particularly valuable because they are deep dive sessions into one area that is facilitated by Gartner analysts alongside industry leaders.&lt;/p&gt;\n\n&lt;p&gt;This year\u2019s focus was on Generative AI, almost to the point of overshadowing other discussions. Despite this, I&amp;#39;m excited to attend next year&amp;#39;s summit to stay updated on the latest trends and best practices.&lt;/p&gt;\n\n&lt;p&gt;If you have any questions or need more details about the conference, feel free to ask. I&amp;#39;d be happy to share more about my experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blwtyr", "is_robot_indexable": true, "report_reasons": null, "author": "data-pro-wizard", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blwtyr/gartner_data_analytics_summit_2024_my_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blwtyr/gartner_data_analytics_summit_2024_my_experience/", "subreddit_subscribers": 171260, "created_utc": 1711212706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_58s0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built a tool to run classification directly on a database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_1blz3t4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/et58xk3um4qc1/DASH_1080.mp4?source=fallback", "has_audio": false, "height": 1080, "width": 1592, "scrubber_media_url": "https://v.redd.it/et58xk3um4qc1/DASH_96.mp4", "dash_url": "https://v.redd.it/et58xk3um4qc1/DASHPlaylist.mpd?a=1713836295%2CMGQwOGY4MTdiMmE0NGVlN2ZjNDI1YzY0NzEzOWY5ODhkM2E4NTkxMzRjYzE4M2RhYjNiNjUyYTljMTI3ZmYzNA%3D%3D&amp;v=1&amp;f=sd", "duration": 23, "hls_url": "https://v.redd.it/et58xk3um4qc1/HLSPlaylist.m3u8?a=1713836295%2COWNhZDUwNGFlY2ExNTA0N2FlODFmNmIwNjJjNTk3MTY3YWE0N2NhZWM0YzY5NTU1NWE1MWJlZWUyNmQ5NzlmZA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=140&amp;height=94&amp;crop=140:94,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2d719b9ba6a6729a031d95dd0818e175959675a1", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711218453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/et58xk3um4qc1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?format=pjpg&amp;auto=webp&amp;s=744d369b4b92d8aad1b50a0097cf2f36f32fc2e9", "width": 1592, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2f0a11fcd4a3f4cbe68554a5c3f3ce9a84dbc3f0", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9030be02b75e305f96099b52f581240703373ef0", "width": 216, "height": 146}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0fc2a544f4ee9fdb87c4dbd4b9a83551297a65a1", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9706fb48dbab31f4da91c2cb8afd30ea9b65b224", "width": 640, "height": 434}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=25862ffa68335478a0425d41756ea4c430dcac7f", "width": 960, "height": 651}, {"url": "https://external-preview.redd.it/MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8809e081cc61b4526c196ef22cce1a52cc65025b", "width": 1080, "height": 732}], "variants": {}, "id": "MncyODQ1MjFuNHFjMRHeHg_9bTyEqCaYIAjynHR2R3HE7omuhfrnTjlLDeYx"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1blz3t4", "is_robot_indexable": true, "report_reasons": null, "author": "Tylernator", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blz3t4/i_built_a_tool_to_run_classification_directly_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/et58xk3um4qc1", "subreddit_subscribers": 171260, "created_utc": 1711218453.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/et58xk3um4qc1/DASH_1080.mp4?source=fallback", "has_audio": false, "height": 1080, "width": 1592, "scrubber_media_url": "https://v.redd.it/et58xk3um4qc1/DASH_96.mp4", "dash_url": "https://v.redd.it/et58xk3um4qc1/DASHPlaylist.mpd?a=1713836295%2CMGQwOGY4MTdiMmE0NGVlN2ZjNDI1YzY0NzEzOWY5ODhkM2E4NTkxMzRjYzE4M2RhYjNiNjUyYTljMTI3ZmYzNA%3D%3D&amp;v=1&amp;f=sd", "duration": 23, "hls_url": "https://v.redd.it/et58xk3um4qc1/HLSPlaylist.m3u8?a=1713836295%2COWNhZDUwNGFlY2ExNTA0N2FlODFmNmIwNjJjNTk3MTY3YWE0N2NhZWM0YzY5NTU1NWE1MWJlZWUyNmQ5NzlmZA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a professional in automation testing, I've encountered a new requirement in my current project that necessitates learning Apache Airflow. I'm seeking high-quality references or courses that could guide me through this learning process. If you're aware of any resources, I would greatly appreciate your recommendations.", "author_fullname": "t2_3mhkzvqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I find some good resources based on Apache Airflow? ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blglio", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711158625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a professional in automation testing, I&amp;#39;ve encountered a new requirement in my current project that necessitates learning Apache Airflow. I&amp;#39;m seeking high-quality references or courses that could guide me through this learning process. If you&amp;#39;re aware of any resources, I would greatly appreciate your recommendations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blglio", "is_robot_indexable": true, "report_reasons": null, "author": "aatish_tandel", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blglio/where_can_i_find_some_good_resources_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blglio/where_can_i_find_some_good_resources_based_on/", "subreddit_subscribers": 171260, "created_utc": 1711158625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am checking out DuckDB but it seems like DataFusion can do everything DuckDB can do except some built in extensions provided by DuckDB like postgres.\n\nWhat are some cases for preferring DuckDB over DataFusion? Any experiences to share?", "author_fullname": "t2_20n43h6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When should I prefer DuckDB over DataFusion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm27px", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711226135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am checking out DuckDB but it seems like DataFusion can do everything DuckDB can do except some built in extensions provided by DuckDB like postgres.&lt;/p&gt;\n\n&lt;p&gt;What are some cases for preferring DuckDB over DataFusion? Any experiences to share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm27px", "is_robot_indexable": true, "report_reasons": null, "author": "gibriyagi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm27px/when_should_i_prefer_duckdb_over_datafusion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm27px/when_should_i_prefer_duckdb_over_datafusion/", "subreddit_subscribers": 171260, "created_utc": 1711226135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any resources for learning of Databricks besides their online materials? Need to get up to speed on it quickly for a new initiative my company is looking to invest in.  I want to understand the common use cases, particularly in healthcare and life sciences, and how companies typically architect/use Databricks.  If you\u2019re in this space already, I appreciate any recommendations or pro-tips. Thanks!", "author_fullname": "t2_8phjzgjz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Databricks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blyr09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711217558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any resources for learning of Databricks besides their online materials? Need to get up to speed on it quickly for a new initiative my company is looking to invest in.  I want to understand the common use cases, particularly in healthcare and life sciences, and how companies typically architect/use Databricks.  If you\u2019re in this space already, I appreciate any recommendations or pro-tips. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blyr09", "is_robot_indexable": true, "report_reasons": null, "author": "spoonorfork1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blyr09/learning_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blyr09/learning_databricks/", "subreddit_subscribers": 171260, "created_utc": 1711217558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So at work I was handed a spring boot application to do some minor changes to inject a service to manipulate and load  some kstream data into a topic and load some data to postgres.\nI only use python and HiveQL otherwise for the past 5 years.\nWill learning kotlin be of any use or should I just not bother too much with it.", "author_fullname": "t2_5y5mt5wer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will learning kotlin be beneficial in my data engineering career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blsz6g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711202763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So at work I was handed a spring boot application to do some minor changes to inject a service to manipulate and load  some kstream data into a topic and load some data to postgres.\nI only use python and HiveQL otherwise for the past 5 years.\nWill learning kotlin be of any use or should I just not bother too much with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blsz6g", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient_Example30", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blsz6g/will_learning_kotlin_be_beneficial_in_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blsz6g/will_learning_kotlin_be_beneficial_in_my_data/", "subreddit_subscribers": 171260, "created_utc": 1711202763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm new to this community so apologies in advance if this isn't allowed and I will remove. I'm kind of on my own at work so I thought I'd see what you all think because I've been noodling on this for a few days.\n\nOne of my recent projects ended with me writing a number of SQL queries that are used in tasks. They add or delete rows from a production table meant to show near-real-time analytics to customers. Depending on the trigger my queries do some transformation and add or remove rows from the table, which determines what is visible to the customer. \n\nIf the task that is removing some rows runs at the same time as a task adding rows, the table obviously deadlocks. \n\nI think the best thing to do would be for the tasks to queue up and only run when the previous task is finished, but that's not my jurisdiction. The stopgap my colleagues put in is a fallback that basically reruns the tasks if there's a failure. \n\nFor me to be able to fix it I'd have to do it within SQL, stored procedures, or adjusting the data model. I've been trying to think of a way to maybe queue up all the adds and deletes in one place and apply them every few minutes but that doesn't seem scalable. If anyone has any input I'd love to hear it!", "author_fullname": "t2_avhxmqxxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Queueing\" table inserts and deletes to avoid deadlocking?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1bm7g5n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711239725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to this community so apologies in advance if this isn&amp;#39;t allowed and I will remove. I&amp;#39;m kind of on my own at work so I thought I&amp;#39;d see what you all think because I&amp;#39;ve been noodling on this for a few days.&lt;/p&gt;\n\n&lt;p&gt;One of my recent projects ended with me writing a number of SQL queries that are used in tasks. They add or delete rows from a production table meant to show near-real-time analytics to customers. Depending on the trigger my queries do some transformation and add or remove rows from the table, which determines what is visible to the customer. &lt;/p&gt;\n\n&lt;p&gt;If the task that is removing some rows runs at the same time as a task adding rows, the table obviously deadlocks. &lt;/p&gt;\n\n&lt;p&gt;I think the best thing to do would be for the tasks to queue up and only run when the previous task is finished, but that&amp;#39;s not my jurisdiction. The stopgap my colleagues put in is a fallback that basically reruns the tasks if there&amp;#39;s a failure. &lt;/p&gt;\n\n&lt;p&gt;For me to be able to fix it I&amp;#39;d have to do it within SQL, stored procedures, or adjusting the data model. I&amp;#39;ve been trying to think of a way to maybe queue up all the adds and deletes in one place and apply them every few minutes but that doesn&amp;#39;t seem scalable. If anyone has any input I&amp;#39;d love to hear it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm7g5n", "is_robot_indexable": true, "report_reasons": null, "author": "APodofFlumphs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm7g5n/queueing_table_inserts_and_deletes_to_avoid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm7g5n/queueing_table_inserts_and_deletes_to_avoid/", "subreddit_subscribers": 171260, "created_utc": 1711239725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello fellow data engineers! \n\nI recently switched companies and I'm diving into cloud services more extensively than ever before. Previously, I've worked with AWS but approach was waaay different, also I worked in a company that used Snowflake and BigQuery + GCS at another. This new role introduces me to a range of AWS services like Lambda, EC2, Kinesis Data Stream, Kinesis Firehose, Glue, Redshift, DMS, EMR, and more.\n\nIn my previous experiences, we always had code versioning and CI/CD processes using tools like Jenkins or GitLab. Usually, I would create a feature branch from the development branch, commit changes, and push them. After a review, the CI/CD system would handle the deployment to the development environment, and later to production. Production was managed solely through CI/CD pipelines.\n\nHowever, in my current role, the approach is different. Instead of uusing CI/CD for deployments, my team directly writes and tests code on AWS, starting with development tables (code testing), then moving to a staging tables (data validation I guess?!) before deploying to production. This methodology seems to bypass the traditional CI/CD pipeline approach (hands OFF the PROD).\n\nI'm grappling with the concept of having only one AWS environment (production) and testing everything there directly. It raises questions about the necessity of CI/CD. If the Lambda function works in the development environment, does that mean it will work in production without any additional checks or safeguards?\n\nIn my previous experience with Airflow, we maintained separate development and production environments. Changes were tested in the development environment, and upon approval, they were merged into the production branch triggering builds, tests, and deployments automatically and DAGs would be present on Prod without me ever laying a hand on it.\n\nI'm curious to hear about your experiences with implementing code versioning and CI/CD on AWS using GitLab or GitHub. How does your company handle these processes? Thank you for sharing your insights!", "author_fullname": "t2_2jtk54zi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD and Code Versioning on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm3wsz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711230429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data engineers! &lt;/p&gt;\n\n&lt;p&gt;I recently switched companies and I&amp;#39;m diving into cloud services more extensively than ever before. Previously, I&amp;#39;ve worked with AWS but approach was waaay different, also I worked in a company that used Snowflake and BigQuery + GCS at another. This new role introduces me to a range of AWS services like Lambda, EC2, Kinesis Data Stream, Kinesis Firehose, Glue, Redshift, DMS, EMR, and more.&lt;/p&gt;\n\n&lt;p&gt;In my previous experiences, we always had code versioning and CI/CD processes using tools like Jenkins or GitLab. Usually, I would create a feature branch from the development branch, commit changes, and push them. After a review, the CI/CD system would handle the deployment to the development environment, and later to production. Production was managed solely through CI/CD pipelines.&lt;/p&gt;\n\n&lt;p&gt;However, in my current role, the approach is different. Instead of uusing CI/CD for deployments, my team directly writes and tests code on AWS, starting with development tables (code testing), then moving to a staging tables (data validation I guess?!) before deploying to production. This methodology seems to bypass the traditional CI/CD pipeline approach (hands OFF the PROD).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m grappling with the concept of having only one AWS environment (production) and testing everything there directly. It raises questions about the necessity of CI/CD. If the Lambda function works in the development environment, does that mean it will work in production without any additional checks or safeguards?&lt;/p&gt;\n\n&lt;p&gt;In my previous experience with Airflow, we maintained separate development and production environments. Changes were tested in the development environment, and upon approval, they were merged into the production branch triggering builds, tests, and deployments automatically and DAGs would be present on Prod without me ever laying a hand on it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to hear about your experiences with implementing code versioning and CI/CD on AWS using GitLab or GitHub. How does your company handle these processes? Thank you for sharing your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bm3wsz", "is_robot_indexable": true, "report_reasons": null, "author": "d_underdog", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bm3wsz/cicd_and_code_versioning_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm3wsz/cicd_and_code_versioning_on_aws/", "subreddit_subscribers": 171260, "created_utc": 1711230429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Data flow](https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;format=png&amp;auto=webp&amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc)\n\nHi,\n\n&amp;#x200B;\n\nI am trying to setup a pipeline for processing images which will be running OnPrem. I have added a data flow diagram above. There will be 4 docker containers for individual processes. The first container (preprocessing) will fetch images from external API every 5 minutes, process them and then send them to S3 storage. I am thinking of using Airflow here. The problems that I am struggling with are:\n\n1) how do I notify the next container(s) that the images have been processed and ready for transfer? \n\n2) how do I transfer the images for further processing between the containers? \n\nI am open to any and all suggestions but the tools/tech need to be free to use.", "author_fullname": "t2_bmxda7ioc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on how to efficiently create a pipeline for images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "media_metadata": {"85qi28f2n4qc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc6bf22cdd9ee210f26981146b90037c6a8f312f"}, {"y": 134, "x": 216, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=05da27ad865391a874ce7e66a439af7db06c1fe8"}, {"y": 198, "x": 320, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac853bedb09e7b6de92f353cba5479ae88bd713e"}, {"y": 397, "x": 640, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d1f10e5a1791c9891025c20e3740b1651addacc5"}], "s": {"y": 471, "x": 759, "u": "https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;format=png&amp;auto=webp&amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc"}, "id": "85qi28f2n4qc1"}}, "name": "t3_1blzcx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a31C2UUcyPPK-DQYONOvSz6oNMlzbV00yDZL1QZENWw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711219085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/85qi28f2n4qc1.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=678aed4c017509487bfe89da3c2ed92d56aed5dc\"&gt;Data flow&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am trying to setup a pipeline for processing images which will be running OnPrem. I have added a data flow diagram above. There will be 4 docker containers for individual processes. The first container (preprocessing) will fetch images from external API every 5 minutes, process them and then send them to S3 storage. I am thinking of using Airflow here. The problems that I am struggling with are:&lt;/p&gt;\n\n&lt;p&gt;1) how do I notify the next container(s) that the images have been processed and ready for transfer? &lt;/p&gt;\n\n&lt;p&gt;2) how do I transfer the images for further processing between the containers? &lt;/p&gt;\n\n&lt;p&gt;I am open to any and all suggestions but the tools/tech need to be free to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1blzcx2", "is_robot_indexable": true, "report_reasons": null, "author": "Even_Work_7995", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blzcx2/looking_for_advice_on_how_to_efficiently_create_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blzcx2/looking_for_advice_on_how_to_efficiently_create_a/", "subreddit_subscribers": 171260, "created_utc": 1711219085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of the work is done on Epic systems like Cogito, Caboodle and Clarity using SQL to source data.\nTeams are transitioning to Snowflake and dbt but also mainly focused on Epic suite.", "author_fullname": "t2_ryxoz6of4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there good scope in data engineering in a non profit healthcare company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bly2lq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711215842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the work is done on Epic systems like Cogito, Caboodle and Clarity using SQL to source data.\nTeams are transitioning to Snowflake and dbt but also mainly focused on Epic suite.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bly2lq", "is_robot_indexable": true, "report_reasons": null, "author": "UnfairDiscount8331", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bly2lq/is_there_good_scope_in_data_engineering_in_a_non/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bly2lq/is_there_good_scope_in_data_engineering_in_a_non/", "subreddit_subscribers": 171260, "created_utc": 1711215842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There's this local (Southeast Asia) cohort-based 15-week data science bootcamp that I've been considering joining, but I'm wondering if I'd be better off investing that money and time elsewhere. If you wanna check it out, it's at [https://www.eskwelabs.com/data-science-fellowship.](https://www.eskwelabs.com/data-science-fellowship)\n\nThe main advantage with this option are the connections/network opportunities as this is an EdTech startup trusted by the local industry. Many former students go on to be successful data professionals. I know it's not for data engineering, but my hope is that it would at least get my foot in the door because where data analysts and data scientists are, data engineers should be too. I could just study on my own, but I would be forgoing the benefits I just mentioned.\n\nI've been struggling to consistently self-learn because I'm so indecisive about exactly what I want to learn. I'm kind of set on data engineering now because it seems to be the better fit vs. data analysis or data science. I also really need a structured learning environment to motivate me, which is why I'm seriously considering taking up a bootcamp.\n\nAny advice is welcome.\n\nP.S.\n\nFor more context, I'm currently an independent contractor for a small company, working with Machine Learning engineers to create datasets for training their computer vision models. Before this, I graduated with a geology degree but it burnt me the hell out. The one thing I held on to was my skill in GIS. I love GIS, the part I like most about GIS is the technical side, using a myriad of tools and data sources to come up with maps. But I'm not happy about the job market. To move up the ladder, you'd need SWE skills to become a GIS developer. I was going to study full stack development, but the number of available GIS developer roles here is scant. At least with how things are looking, there will always be a need for data engineers.", "author_fullname": "t2_6k8yfl9c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I join this $1000 bootcamp or invest in cloud provider certifications and MOOCs instead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blvxfn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1711210419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s this local (Southeast Asia) cohort-based 15-week data science bootcamp that I&amp;#39;ve been considering joining, but I&amp;#39;m wondering if I&amp;#39;d be better off investing that money and time elsewhere. If you wanna check it out, it&amp;#39;s at &lt;a href=\"https://www.eskwelabs.com/data-science-fellowship\"&gt;https://www.eskwelabs.com/data-science-fellowship.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The main advantage with this option are the connections/network opportunities as this is an EdTech startup trusted by the local industry. Many former students go on to be successful data professionals. I know it&amp;#39;s not for data engineering, but my hope is that it would at least get my foot in the door because where data analysts and data scientists are, data engineers should be too. I could just study on my own, but I would be forgoing the benefits I just mentioned.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been struggling to consistently self-learn because I&amp;#39;m so indecisive about exactly what I want to learn. I&amp;#39;m kind of set on data engineering now because it seems to be the better fit vs. data analysis or data science. I also really need a structured learning environment to motivate me, which is why I&amp;#39;m seriously considering taking up a bootcamp.&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome.&lt;/p&gt;\n\n&lt;p&gt;P.S.&lt;/p&gt;\n\n&lt;p&gt;For more context, I&amp;#39;m currently an independent contractor for a small company, working with Machine Learning engineers to create datasets for training their computer vision models. Before this, I graduated with a geology degree but it burnt me the hell out. The one thing I held on to was my skill in GIS. I love GIS, the part I like most about GIS is the technical side, using a myriad of tools and data sources to come up with maps. But I&amp;#39;m not happy about the job market. To move up the ladder, you&amp;#39;d need SWE skills to become a GIS developer. I was going to study full stack development, but the number of available GIS developer roles here is scant. At least with how things are looking, there will always be a need for data engineers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?auto=webp&amp;s=96aff65dba75c56f1bed0f8f99b250dfcde2ba4c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=49efc40b1d79a0c094b86ce16c84c72235512a95", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7fab185ecc225430bc48b0acda3de550f4e9a41b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=05d8cca46de10ff43ab761403d110861e5d1d5f8", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8b5dcb9aa5509fd95552f64dd0148ea7f33b34b6", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=516628c5208d3a1fd0d86d5c343f7fceac1f2e14", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/pdokBKzW3i3-QdpOih4U_E9U208S66zDcLmYA63qR0Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2dd964e97e162e92278d4de258bf4aa595da83ec", "width": 1080, "height": 567}], "variants": {}, "id": "TsI3dGx42LkLb5P7V4Nov50XsoHJ_KsQetLC-BDcRSE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1blvxfn", "is_robot_indexable": true, "report_reasons": null, "author": "justlikeutoo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blvxfn/should_i_join_this_1000_bootcamp_or_invest_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blvxfn/should_i_join_this_1000_bootcamp_or_invest_in/", "subreddit_subscribers": 171260, "created_utc": 1711210419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an use case where I have to create STM document(Source to Target Mapping). \n\nI want to get the business logic which is being applied on a column, along with the column lineage.\n\nUsing databricks api, I got all the required lineage info of each column, but I want to get the business rule as well. For example, Col A from table-A is an union of Col B and Col C of table-B, I want to document this business logic which is union. \nCan that be done in Databricks? \nI wonder Alation/Prophecy would be able to do that? Any thoughts or help on this? Thank you", "author_fullname": "t2_4njp7ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Column level Business rule along with Lineage in Databricks ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bls2gy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711200191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an use case where I have to create STM document(Source to Target Mapping). &lt;/p&gt;\n\n&lt;p&gt;I want to get the business logic which is being applied on a column, along with the column lineage.&lt;/p&gt;\n\n&lt;p&gt;Using databricks api, I got all the required lineage info of each column, but I want to get the business rule as well. For example, Col A from table-A is an union of Col B and Col C of table-B, I want to document this business logic which is union. \nCan that be done in Databricks? \nI wonder Alation/Prophecy would be able to do that? Any thoughts or help on this? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bls2gy", "is_robot_indexable": true, "report_reasons": null, "author": "ravitejasurla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bls2gy/column_level_business_rule_along_with_lineage_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bls2gy/column_level_business_rule_along_with_lineage_in/", "subreddit_subscribers": 171260, "created_utc": 1711200191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you were to have an agreement with your manager that the organization would support you in your own professional development, and the context bespoken included *courses, seminars, workcenters, associations, conferences, certifications, \u2026* and the like, without any particular budget, where would you start looking?\n\nI\u2019m curious what sort of data engineering, devops, software architecture, events or programs are highly regarded for its value and currency with modern practices. Are there any renowned speakers who you\u2019d look out for at events, or specific events in general you\u2019d want to plan for? How about books, classes, boot camps, etc? \n\nI have such an agreement with my employer. Before asking I had some books and a course in mind, but my bosses response made me feel quite hopeful that they\u2019d support me in much larger endeavors. I\u2019m not sure exactly where to start looking given the broader scope.\n\nFor context on my aptitude for this stuff; I have never managed a data team, though that\u2019s a possibility for the future. My only management experience is years ago in the military. I have always worked in smaller businesses where I wear many hats. My duties include analysis and automations, but I also manage the infrastructure and networking to make that happen. I feel comfortable with things like terraform, docker, Python, sql, vanilla JavaScript, Linux, some pretty advanced webscraping, marketing concepts like customer acquisition and implementing the client side and server side tracking for it, \u2026\n\nMore recently, I\u2019ve grown a liking toward the concepts of engineering distributed systems, devops platforms, data meshes, Kubernetes, react (yes, the JS framework), and streaming. These are all areas that I would like grow in, though I\u2019m not suggesting I need to start there.\n\n\nWhat do you think? Thanks for any input. ", "author_fullname": "t2_uqm6fk35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you allocate an (positively) ambiguously capped professional development budget?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1blhvrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1711163283.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711162450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were to have an agreement with your manager that the organization would support you in your own professional development, and the context bespoken included &lt;em&gt;courses, seminars, workcenters, associations, conferences, certifications, \u2026&lt;/em&gt; and the like, without any particular budget, where would you start looking?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious what sort of data engineering, devops, software architecture, events or programs are highly regarded for its value and currency with modern practices. Are there any renowned speakers who you\u2019d look out for at events, or specific events in general you\u2019d want to plan for? How about books, classes, boot camps, etc? &lt;/p&gt;\n\n&lt;p&gt;I have such an agreement with my employer. Before asking I had some books and a course in mind, but my bosses response made me feel quite hopeful that they\u2019d support me in much larger endeavors. I\u2019m not sure exactly where to start looking given the broader scope.&lt;/p&gt;\n\n&lt;p&gt;For context on my aptitude for this stuff; I have never managed a data team, though that\u2019s a possibility for the future. My only management experience is years ago in the military. I have always worked in smaller businesses where I wear many hats. My duties include analysis and automations, but I also manage the infrastructure and networking to make that happen. I feel comfortable with things like terraform, docker, Python, sql, vanilla JavaScript, Linux, some pretty advanced webscraping, marketing concepts like customer acquisition and implementing the client side and server side tracking for it, \u2026&lt;/p&gt;\n\n&lt;p&gt;More recently, I\u2019ve grown a liking toward the concepts of engineering distributed systems, devops platforms, data meshes, Kubernetes, react (yes, the JS framework), and streaming. These are all areas that I would like grow in, though I\u2019m not suggesting I need to start there.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Thanks for any input. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blhvrx", "is_robot_indexable": true, "report_reasons": null, "author": "DuckDatum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blhvrx/how_would_you_allocate_an_positively_ambiguously/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1blhvrx/how_would_you_allocate_an_positively_ambiguously/", "subreddit_subscribers": 171260, "created_utc": 1711162450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe are going to start on a new project where we will be provided data for 9 different clients in csv formats. Data will then need to go through a fairly normal dataflow\n\n1. Data passed to us via the clients' \"drop boxes\"\n2. Data validation and ETL stuff\n3. Stored in Azure SQL\n4. A fairly complex calculation will be applied to the data\n5. Results of calculation stored back in to Azure SQL\n6. Various reporting etc\n7. Process repeated periodically (say twice a month)\n\nOther than being different datasets, the logical steps will be the same for each client. It is likely that throughout the life of the project there will need to be changes to the methodology in step 2 and step 4, when that happens any changes will apply to all clients simultaneously.\n\nLastly, it is critical that there is never a mix up between the 9 clients' data.\n\nThe most robust would seem to be to have completely separate instances of everything, but conversely having 9 copies of python / Spark ETL and calculation code doesn't seem like a good way to do things when it gets updated.\n\nAppreciate any thoughts or any reading I could do.", "author_fullname": "t2_76xailgf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Maintaining separation of data for different clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm2fm9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711226697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We are going to start on a new project where we will be provided data for 9 different clients in csv formats. Data will then need to go through a fairly normal dataflow&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data passed to us via the clients&amp;#39; &amp;quot;drop boxes&amp;quot;&lt;/li&gt;\n&lt;li&gt;Data validation and ETL stuff&lt;/li&gt;\n&lt;li&gt;Stored in Azure SQL&lt;/li&gt;\n&lt;li&gt;A fairly complex calculation will be applied to the data&lt;/li&gt;\n&lt;li&gt;Results of calculation stored back in to Azure SQL&lt;/li&gt;\n&lt;li&gt;Various reporting etc&lt;/li&gt;\n&lt;li&gt;Process repeated periodically (say twice a month)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Other than being different datasets, the logical steps will be the same for each client. It is likely that throughout the life of the project there will need to be changes to the methodology in step 2 and step 4, when that happens any changes will apply to all clients simultaneously.&lt;/p&gt;\n\n&lt;p&gt;Lastly, it is critical that there is never a mix up between the 9 clients&amp;#39; data.&lt;/p&gt;\n\n&lt;p&gt;The most robust would seem to be to have completely separate instances of everything, but conversely having 9 copies of python / Spark ETL and calculation code doesn&amp;#39;t seem like a good way to do things when it gets updated.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any thoughts or any reading I could do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm2fm9", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Isopod4493", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm2fm9/maintaining_separation_of_data_for_different/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm2fm9/maintaining_separation_of_data_for_different/", "subreddit_subscribers": 171260, "created_utc": 1711226697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I'm an American DE working in France. I regularly find good freelance gigs here (notably through a platform called malt). As I'm moving back to the states soon I'd like to test the freelance market there.\n\nI'm wondering if anyone does that full-time, and what platforms work best? Would Upwork still be the go-to or are there more specialized data or IT-focused platforms?", "author_fullname": "t2_gcq3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best platforms for finding freelance US-based DE gigs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm1kyn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711224580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;m an American DE working in France. I regularly find good freelance gigs here (notably through a platform called malt). As I&amp;#39;m moving back to the states soon I&amp;#39;d like to test the freelance market there.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if anyone does that full-time, and what platforms work best? Would Upwork still be the go-to or are there more specialized data or IT-focused platforms?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm1kyn", "is_robot_indexable": true, "report_reasons": null, "author": "johnsonfrusciante", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm1kyn/best_platforms_for_finding_freelance_usbased_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm1kyn/best_platforms_for_finding_freelance_usbased_de/", "subreddit_subscribers": 171260, "created_utc": 1711224580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I need help solving a problem. I need to convert Solitidy ByteCodes to OpCodes. I have several datasets storing ByteCodes and i'm looking for a way to automate the transformation of these ByteCodes into Opcodes in bulk rather than treating them individually. Any guidance or support you can provide would be greatly appreciated. Thanks!", "author_fullname": "t2_qrqs3bpd7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ByteCodes to OpCodes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bm0cj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711221531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I need help solving a problem. I need to convert Solitidy ByteCodes to OpCodes. I have several datasets storing ByteCodes and i&amp;#39;m looking for a way to automate the transformation of these ByteCodes into Opcodes in bulk rather than treating them individually. Any guidance or support you can provide would be greatly appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bm0cj4", "is_robot_indexable": true, "report_reasons": null, "author": "iwasalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bm0cj4/bytecodes_to_opcodes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bm0cj4/bytecodes_to_opcodes/", "subreddit_subscribers": 171260, "created_utc": 1711221531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was hoping someone could give me a realistic perspective of how far I need to go to get my foot in the door as a Jr. Data Engineer. I am hoping to make a career change out of consulting - I am currently a Senior Product Analyst. Prior to this I was a mechanical engineer for five years. I've found I still don't want anything to do with the political world of business execs, I want to get back in the weeds where I belong and build glorious elegant solutions to weird problems. Efficiency makes me happy.\n\nWhere I am currently:\n\n* I have built a few full-stack applications and am very familiar with React and Postgres.\n* At work I use Python (often starting with a first pass generated by ChatGPT to save time, then refining from there -- everything has to happen fast, and everyone thinks we should just use Excel for everything) to automate a lot of my tasks and try to build leave-behind tools to help others process data. \n   * While I may skimp on the implementation step since I am cheating with AI, I do have to understand:\n      * What is possible\n      * What's the specific set of steps I want to take to achieve this\n      * What data structures will be useful in getting me there\n      * What edge cases and other issues do I need to account for to make this generally applicable\n   * These have included Powerpoint slide generators that take data from an Excel file and populate pre-defined templates to save time in re-spins, an automatic Pareto analyzer for spend data, a variant tree generator for product portfolios, and a bill of materials re-formatter to transform various formats to a consistent hierarchical pattern, enabling further downstream analysis\n* I also use Alteryx a lot at work for a wide variety of tasks, usually for quickly parsing and getting insights from large datasets, and setting up repeatable transformations. \n\n&amp;#x200B;\n\nI understand most of this is Analysis and not Engineering, but I'm wondering if I may be close enough that I could get into a job and learn on the fly after spending a few months doing some self-learning and practice with the basic concepts of data engineering. \n\n**Would appreciate any and all feedback -- don't hold back!**\n\n&amp;#x200B;", "author_fullname": "t2_5i451", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How far do I have to go to become a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bltvss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1711205156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was hoping someone could give me a realistic perspective of how far I need to go to get my foot in the door as a Jr. Data Engineer. I am hoping to make a career change out of consulting - I am currently a Senior Product Analyst. Prior to this I was a mechanical engineer for five years. I&amp;#39;ve found I still don&amp;#39;t want anything to do with the political world of business execs, I want to get back in the weeds where I belong and build glorious elegant solutions to weird problems. Efficiency makes me happy.&lt;/p&gt;\n\n&lt;p&gt;Where I am currently:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I have built a few full-stack applications and am very familiar with React and Postgres.&lt;/li&gt;\n&lt;li&gt;At work I use Python (often starting with a first pass generated by ChatGPT to save time, then refining from there -- everything has to happen fast, and everyone thinks we should just use Excel for everything) to automate a lot of my tasks and try to build leave-behind tools to help others process data. \n\n&lt;ul&gt;\n&lt;li&gt;While I may skimp on the implementation step since I am cheating with AI, I do have to understand:\n\n&lt;ul&gt;\n&lt;li&gt;What is possible&lt;/li&gt;\n&lt;li&gt;What&amp;#39;s the specific set of steps I want to take to achieve this&lt;/li&gt;\n&lt;li&gt;What data structures will be useful in getting me there&lt;/li&gt;\n&lt;li&gt;What edge cases and other issues do I need to account for to make this generally applicable&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;These have included Powerpoint slide generators that take data from an Excel file and populate pre-defined templates to save time in re-spins, an automatic Pareto analyzer for spend data, a variant tree generator for product portfolios, and a bill of materials re-formatter to transform various formats to a consistent hierarchical pattern, enabling further downstream analysis&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;I also use Alteryx a lot at work for a wide variety of tasks, usually for quickly parsing and getting insights from large datasets, and setting up repeatable transformations. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I understand most of this is Analysis and not Engineering, but I&amp;#39;m wondering if I may be close enough that I could get into a job and learn on the fly after spending a few months doing some self-learning and practice with the basic concepts of data engineering. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Would appreciate any and all feedback -- don&amp;#39;t hold back!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bltvss", "is_robot_indexable": true, "report_reasons": null, "author": "Pawtang", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bltvss/how_far_do_i_have_to_go_to_become_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bltvss/how_far_do_i_have_to_go_to_become_a_data_engineer/", "subreddit_subscribers": 171260, "created_utc": 1711205156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, i am searching for ways to implement complex event processing, my use case is i have a bunch of systems sending events in kafka, i want to process and correlate these events to gain insights and alerts.\nThe problem is that i need to allow the user to change the rules and templates through some kind of ui based on their changing needs.\nI looked into Apache Flink but it doesn't seem to support user defined querys and rules.\nDoes anyone know a way of achieving this?\nI attached a presentation by Uber that covers exactly my use case however it is from 2017 and seems a bit outdated", "author_fullname": "t2_re31tw67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dynamic rules and templates for Complex Event Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1blt70j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nncxYGD6m7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nncxYGD6m7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017\"&gt;&lt;/iframe&gt;", "author_name": "WSO2", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/nncxYGD6m7E/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WSO2official"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nncxYGD6m7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1blt70j", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/unwgbLes0IOaLE_BBjsfe6cfCIF1QIrbrdzYPphfEw4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1711203338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i am searching for ways to implement complex event processing, my use case is i have a bunch of systems sending events in kafka, i want to process and correlate these events to gain insights and alerts.\nThe problem is that i need to allow the user to change the rules and templates through some kind of ui based on their changing needs.\nI looked into Apache Flink but it doesn&amp;#39;t seem to support user defined querys and rules.\nDoes anyone know a way of achieving this?\nI attached a presentation by Uber that covers exactly my use case however it is from 2017 and seems a bit outdated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/nncxYGD6m7E?si=HkvADsHJIQ8ZmF2O", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yheLXINMWSHycWMhfNt7TwGa95_dV5IwJ99FXkC8ps8.jpg?auto=webp&amp;s=ccdc89eea4cdd22210e90e2da960a7e579f7b35a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/yheLXINMWSHycWMhfNt7TwGa95_dV5IwJ99FXkC8ps8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d4fb3b162872036fb58be69480985712ccd3e8f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/yheLXINMWSHycWMhfNt7TwGa95_dV5IwJ99FXkC8ps8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dffc8d76a77acb4e09beddc4f15f2302b3e522be", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/yheLXINMWSHycWMhfNt7TwGa95_dV5IwJ99FXkC8ps8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e0f3779d4079f6425ea88a75e094b4845b81cf12", "width": 320, "height": 240}], "variants": {}, "id": "xDgdhPdPXUACgx8OrY9WY6BPTtmQuyomJ9w0b07m90c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1blt70j", "is_robot_indexable": true, "report_reasons": null, "author": "shaiiii5", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1blt70j/dynamic_rules_and_templates_for_complex_event/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/nncxYGD6m7E?si=HkvADsHJIQ8ZmF2O", "subreddit_subscribers": 171260, "created_utc": 1711203338.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nncxYGD6m7E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Scalable Real-time Complex Event Processing at Uber, WSO2Con USA 2017\"&gt;&lt;/iframe&gt;", "author_name": "WSO2", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/nncxYGD6m7E/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WSO2official"}}, "is_video": false}}], "before": null}}