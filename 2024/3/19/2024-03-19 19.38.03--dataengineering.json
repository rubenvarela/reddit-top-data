{"kind": "Listing", "data": {"after": "t3_1big8k5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hope this post is ok, as I don't work for either O'Reilly or Humble Bundle. Given the number of questions on this thread for getting books on the topic, thought maybe some of you might be interested in this too! Personally, I'd been wanting to get, \"Data Algorithms with Spark,\" but had been hesitating due to the price. I was super thrilled seeing this included in the book bundle.\n\nThis is an organization that partners with others to offer books (and games) at a super low price. Part of the proceeds goes to charity. I've been a huge fan of them since discovering them a while ago.\n\n[https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books](https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books)", "author_fullname": "t2_97dp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "O\u2019Reilly data engineering reference books on sale! (Includes reference books on pyspark and scaling up pipelines)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bifhj9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 85, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 85, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710837462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope this post is ok, as I don&amp;#39;t work for either O&amp;#39;Reilly or Humble Bundle. Given the number of questions on this thread for getting books on the topic, thought maybe some of you might be interested in this too! Personally, I&amp;#39;d been wanting to get, &amp;quot;Data Algorithms with Spark,&amp;quot; but had been hesitating due to the price. I was super thrilled seeing this included in the book bundle.&lt;/p&gt;\n\n&lt;p&gt;This is an organization that partners with others to offer books (and games) at a super low price. Part of the proceeds goes to charity. I&amp;#39;ve been a huge fan of them since discovering them a while ago.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books\"&gt;https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?auto=webp&amp;s=b50f3a7282d32dcfa0e059b0b506a19daa6b7df9", "width": 1120, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8df569a17eb586e2b0feb844c8ddd80e2c53523e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc1d0f218d319d03ff9fb045ea5a017098e1c402", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4db0e3979f4fd989e036859dfa1257d15a01f34", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0c5aa5216466749f2ffd89e4f6dda46502974b1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=92b050a7f148a6395bed48099df1cca2307178a1", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=abb37e101932d1c5791c9ad599433a01b56b311e", "width": 1080, "height": 607}], "variants": {}, "id": "FbykrjGMgm2863qufl2xVlkGdUUd4rQbUPblShEhFV4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bifhj9", "is_robot_indexable": true, "report_reasons": null, "author": "truckbot101", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bifhj9/oreilly_data_engineering_reference_books_on_sale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bifhj9/oreilly_data_engineering_reference_books_on_sale/", "subreddit_subscribers": 170174, "created_utc": 1710837462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am sure many others have been in my shoes before. \n\nI have been with my org for about a year, and it\u2019s approach to data management is extremely primitive. I am trying to do some dash boarding of various KPIs, but I\u2019m finding that everywhere I look the approach has been that some random person enters data into an excel sheet somewhere without any documentation.\n\nAgain, there\u2019s no documentation on where this data lives or how it comes to be. Over the course of my role, I\u2019ve discovered that much of this data entry could just be automated by creating some views off our main production database. I\u2019ve resolved about 70% of the necessary data processing by creating a view and loading it to a PowerBi data model, but I\u2019m trying to figure out how to handle the missing ends. \n\nI\u2019ve considered asking our operations manager if we could drive people to host their excel workbooks in share point. That way, I\u2019d have access to the files and could take a periodic snapshot by just reading it to a pandas dataframe before loading it to a history table in a data warehouse. \n\nHow have others managed this issue with undocumented excel workbooks floating all over the place? \n\nIt\u2019s tough because I get the sense that many are refusing to share information because they fear their job being automated. At the same time, it is simply not feasible for me to spend my whole day constantly chasing down spreadsheets everywhere.", "author_fullname": "t2_6hsp2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Excel files sprinkled across organization with no documentation ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bi6dus", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710807128.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710806762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am sure many others have been in my shoes before. &lt;/p&gt;\n\n&lt;p&gt;I have been with my org for about a year, and it\u2019s approach to data management is extremely primitive. I am trying to do some dash boarding of various KPIs, but I\u2019m finding that everywhere I look the approach has been that some random person enters data into an excel sheet somewhere without any documentation.&lt;/p&gt;\n\n&lt;p&gt;Again, there\u2019s no documentation on where this data lives or how it comes to be. Over the course of my role, I\u2019ve discovered that much of this data entry could just be automated by creating some views off our main production database. I\u2019ve resolved about 70% of the necessary data processing by creating a view and loading it to a PowerBi data model, but I\u2019m trying to figure out how to handle the missing ends. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve considered asking our operations manager if we could drive people to host their excel workbooks in share point. That way, I\u2019d have access to the files and could take a periodic snapshot by just reading it to a pandas dataframe before loading it to a history table in a data warehouse. &lt;/p&gt;\n\n&lt;p&gt;How have others managed this issue with undocumented excel workbooks floating all over the place? &lt;/p&gt;\n\n&lt;p&gt;It\u2019s tough because I get the sense that many are refusing to share information because they fear their job being automated. At the same time, it is simply not feasible for me to spend my whole day constantly chasing down spreadsheets everywhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bi6dus", "is_robot_indexable": true, "report_reasons": null, "author": "suitupyo", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bi6dus/excel_files_sprinkled_across_organization_with_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bi6dus/excel_files_sprinkled_across_organization_with_no/", "subreddit_subscribers": 170174, "created_utc": 1710806762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently got my first offer as a Data Engineer coming out of school and wanted to understand the possibilities of moving out of DE into SWE at some point. Has any body made this jump before? Was it hard or easy? What kinds of skills did you have to pick up either on the job or by yourself?\n\nThanks!", "author_fullname": "t2_hfl4w59z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going from DE to SWE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bhzgyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710790126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got my first offer as a Data Engineer coming out of school and wanted to understand the possibilities of moving out of DE into SWE at some point. Has any body made this jump before? Was it hard or easy? What kinds of skills did you have to pick up either on the job or by yourself?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bhzgyi", "is_robot_indexable": true, "report_reasons": null, "author": "digging_for_memories", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bhzgyi/going_from_de_to_swe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bhzgyi/going_from_de_to_swe/", "subreddit_subscribers": 170174, "created_utc": 1710790126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i have a project where basically data needs to be ingested into a big snowflake table from multiple csv files that are sent to AWS SFTP (and forwarded to S3). The project itself is pretty simple tbh. The high level architecture and workflow is as follows: CSV gets send by customer applications into S3 --&gt; loading into snowflake load table --&gt; some small/basic transformations (joins across data of multiple files) --&gt; database with clean data --&gt; some customers will require export jobs like nested json or csv to their own s3 or whatever.\n\nTo be a little bit more specific: the data we are talking about here is very small like 30mb etc. the ingestion is very basic as well maybe some edge cases but overall just parsing CSV.\n\nOur AWS architect made an architecture i will call \"aws first\": Basically whenever anything has to be done he wants me to do it with AWS Lambda and python3. Meaning: Ingestion made with s3 events that triggers lambda that will do simple ingestion. Then the copy process and joins also in a lambda and the export jobs as well.\n\nThe second approach i would call snowflake first is skipping AWS Lambda all together and just using Snowpipe that will listen to s3 events and then some UFD functions or stored procedures. For the Export jobs we can use snowpipe and snowflake tasks as well maybe in some cases we would need external functions and then some kind of AWS lambda service but it's probably unlikely this will be a real use-case. The snowpipes and storage integration i would create with terraform snowflake provider.\n\nSo i would like to ask the community what approach they would choose here. In my opinion both approaches have disadvantages and advantages:\n\nadvantages aws first approach (aws lambda and python)\n\n- most of the project is in aws so aws lambda would integrate very well (IaC) etc.\n\n- patching of software is required anyways since our project has some other tools and apps\n\n- we could implement some additional stuff in the lambda like idempotency\n\n- very easy to understand if the project wants to hire low cost devs in the future for programing integrations\n\n- data is pretty small probably even fits into a python3 dataframe so all the optimisation we would get from focusing on snowflake features probably not worth it\n\nadvantages \"snowflake first\" approach (terraform and snowpipe, tasks, ufd etc.)\n\n- leveraging the tools of a platform we already paying for anyways\n\n- less operational overhead, less changes needed in the future\n\nMaybe i can get some guidance on this topic. It just feels counterintuitive to me to build so many custom lambda functions on the other hand there isn't really a good argument to do most of the workloads in snowflake. What do you think? :) Thanks!\n\n", "author_fullname": "t2_ficwvf44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance: Snowflake first approach vs AWS first approach data ingestion and export jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bi195y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710840028.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710794349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i have a project where basically data needs to be ingested into a big snowflake table from multiple csv files that are sent to AWS SFTP (and forwarded to S3). The project itself is pretty simple tbh. The high level architecture and workflow is as follows: CSV gets send by customer applications into S3 --&amp;gt; loading into snowflake load table --&amp;gt; some small/basic transformations (joins across data of multiple files) --&amp;gt; database with clean data --&amp;gt; some customers will require export jobs like nested json or csv to their own s3 or whatever.&lt;/p&gt;\n\n&lt;p&gt;To be a little bit more specific: the data we are talking about here is very small like 30mb etc. the ingestion is very basic as well maybe some edge cases but overall just parsing CSV.&lt;/p&gt;\n\n&lt;p&gt;Our AWS architect made an architecture i will call &amp;quot;aws first&amp;quot;: Basically whenever anything has to be done he wants me to do it with AWS Lambda and python3. Meaning: Ingestion made with s3 events that triggers lambda that will do simple ingestion. Then the copy process and joins also in a lambda and the export jobs as well.&lt;/p&gt;\n\n&lt;p&gt;The second approach i would call snowflake first is skipping AWS Lambda all together and just using Snowpipe that will listen to s3 events and then some UFD functions or stored procedures. For the Export jobs we can use snowpipe and snowflake tasks as well maybe in some cases we would need external functions and then some kind of AWS lambda service but it&amp;#39;s probably unlikely this will be a real use-case. The snowpipes and storage integration i would create with terraform snowflake provider.&lt;/p&gt;\n\n&lt;p&gt;So i would like to ask the community what approach they would choose here. In my opinion both approaches have disadvantages and advantages:&lt;/p&gt;\n\n&lt;p&gt;advantages aws first approach (aws lambda and python)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;most of the project is in aws so aws lambda would integrate very well (IaC) etc.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;patching of software is required anyways since our project has some other tools and apps&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;we could implement some additional stuff in the lambda like idempotency&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;very easy to understand if the project wants to hire low cost devs in the future for programing integrations&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;data is pretty small probably even fits into a python3 dataframe so all the optimisation we would get from focusing on snowflake features probably not worth it&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;advantages &amp;quot;snowflake first&amp;quot; approach (terraform and snowpipe, tasks, ufd etc.)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;leveraging the tools of a platform we already paying for anyways&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;less operational overhead, less changes needed in the future&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Maybe i can get some guidance on this topic. It just feels counterintuitive to me to build so many custom lambda functions on the other hand there isn&amp;#39;t really a good argument to do most of the workloads in snowflake. What do you think? :) Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bi195y", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Interaction_5701", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bi195y/guidance_snowflake_first_approach_vs_aws_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bi195y/guidance_snowflake_first_approach_vs_aws_first/", "subreddit_subscribers": 170174, "created_utc": 1710794349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is optimized by DBMS: logical or physical plans? or both? If only logical plans, how DBMS can calculate costs without knowing of exact physical operations behind nodes of query tree? I also doubt that only physical plans are optimized.  \nI have this picture (CMU DB group lectures) where given logical plan is optimized but I dunno how this may happen if logical plan is to my knowledge high-level DAG of operators without any physical specifics.\n\nTo me it seems that optimizer should optimize both logical plans (iterate through different query plan trees and choose best plan using *heuristics*) and physical plans (iterate through different options of executing the same query plan tree (different joins, access methods, etc.) and choose best plan using *costs-based approach*) but I'm definitely not sure about that.\n\nUPD. Found docs of specific DB [https://docs.pingcap.com/tidb/stable/sql-optimization-concepts](https://docs.pingcap.com/tidb/stable/sql-optimization-concepts) . In this docs there is point about doing some \"logically equivalent changes to the query\" and they name it \"[Logical Optimization](https://docs.pingcap.com/tidb/stable/sql-logical-optimization)\". Also there is about \"obtaining a final execution plan based on the data distribution and the specific execution cost of an operator\" and they name it \"[Physical Optimization](https://docs.pingcap.com/tidb/stable/sql-physical-optimization)\".   \nSo to me it seems that in modern DB systems there is actually similar process to one I described earlier.\n\nhttps://preview.redd.it/3p9o5illm5pc1.png?width=537&amp;format=png&amp;auto=webp&amp;s=683f91e65fed6d4cc615379eb13cb35997f2578a", "author_fullname": "t2_b3ayn5hsg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When does query optimization in DBMS happen?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3p9o5illm5pc1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/3p9o5illm5pc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f31e57669dba4a7a2b7b285720441bb9fdb4f7f"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/3p9o5illm5pc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c9c84776ba8b8b2e4e94043039331ca3d0a690e"}, {"y": 160, "x": 320, "u": "https://preview.redd.it/3p9o5illm5pc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=631e3dae7cbd3a70a36f697e530ad1d9dcd4185b"}], "s": {"y": 270, "x": 537, "u": "https://preview.redd.it/3p9o5illm5pc1.png?width=537&amp;format=png&amp;auto=webp&amp;s=683f91e65fed6d4cc615379eb13cb35997f2578a"}, "id": "3p9o5illm5pc1"}}, "name": "t3_1bi1et9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/N-7Eb17SVssj45oho_0YGsxARVCoWdtSC2M938LmapM.jpg", "edited": 1710800187.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1710794728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is optimized by DBMS: logical or physical plans? or both? If only logical plans, how DBMS can calculate costs without knowing of exact physical operations behind nodes of query tree? I also doubt that only physical plans are optimized.&lt;br/&gt;\nI have this picture (CMU DB group lectures) where given logical plan is optimized but I dunno how this may happen if logical plan is to my knowledge high-level DAG of operators without any physical specifics.&lt;/p&gt;\n\n&lt;p&gt;To me it seems that optimizer should optimize both logical plans (iterate through different query plan trees and choose best plan using &lt;em&gt;heuristics&lt;/em&gt;) and physical plans (iterate through different options of executing the same query plan tree (different joins, access methods, etc.) and choose best plan using &lt;em&gt;costs-based approach&lt;/em&gt;) but I&amp;#39;m definitely not sure about that.&lt;/p&gt;\n\n&lt;p&gt;UPD. Found docs of specific DB &lt;a href=\"https://docs.pingcap.com/tidb/stable/sql-optimization-concepts\"&gt;https://docs.pingcap.com/tidb/stable/sql-optimization-concepts&lt;/a&gt; . In this docs there is point about doing some &amp;quot;logically equivalent changes to the query&amp;quot; and they name it &amp;quot;&lt;a href=\"https://docs.pingcap.com/tidb/stable/sql-logical-optimization\"&gt;Logical Optimization&lt;/a&gt;&amp;quot;. Also there is about &amp;quot;obtaining a final execution plan based on the data distribution and the specific execution cost of an operator&amp;quot; and they name it &amp;quot;&lt;a href=\"https://docs.pingcap.com/tidb/stable/sql-physical-optimization\"&gt;Physical Optimization&lt;/a&gt;&amp;quot;.&lt;br/&gt;\nSo to me it seems that in modern DB systems there is actually similar process to one I described earlier.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3p9o5illm5pc1.png?width=537&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=683f91e65fed6d4cc615379eb13cb35997f2578a\"&gt;https://preview.redd.it/3p9o5illm5pc1.png?width=537&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=683f91e65fed6d4cc615379eb13cb35997f2578a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qwZv8hypQb7RFYHa3U4CglTUpF0TmfrRn5LGonrSIDg.jpg?auto=webp&amp;s=8150913c159f903cc5577b744799db42db187d9c", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/qwZv8hypQb7RFYHa3U4CglTUpF0TmfrRn5LGonrSIDg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=30824ff14765ae039e3b6d7d2d5ee2dc0f24c652", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/qwZv8hypQb7RFYHa3U4CglTUpF0TmfrRn5LGonrSIDg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=00db47a9520ff588fdf82bcaf30a82abe2c3a3f2", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/qwZv8hypQb7RFYHa3U4CglTUpF0TmfrRn5LGonrSIDg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a231e7f510167f41a4a7f55c51d42ce8b4451acf", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/qwZv8hypQb7RFYHa3U4CglTUpF0TmfrRn5LGonrSIDg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1987b6c83ef844cb83414743dd68ff938f1c110", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/qwZv8hypQb7RFYHa3U4CglTUpF0TmfrRn5LGonrSIDg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5df7f9263b806d2009a7df7ab1303f86671967dc", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/qwZv8hypQb7RFYHa3U4CglTUpF0TmfrRn5LGonrSIDg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c005210e0451b258fbb29ae1ec082d7cd9752d5f", "width": 1080, "height": 1080}], "variants": {}, "id": "ZQDvKgaiNIaaiEfaM14MidCgI9LagV_KOlnvnr_bxa0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bi1et9", "is_robot_indexable": true, "report_reasons": null, "author": "isk14yo", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bi1et9/when_does_query_optimization_in_dbms_happen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bi1et9/when_does_query_optimization_in_dbms_happen/", "subreddit_subscribers": 170174, "created_utc": 1710794728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently working as a mix of DA/DE, and I believe my skills with SQL are not upto the mark to make a move to DE.\nI understand there is just \"normal\" sql that data analysts, BI analysts use which is typically:\n\n&gt; Select xyz from abc where ysd = '123'\n\nYes this can get more complex with joins, ctes, window functions etc.\n\nWhat is the difference between complex SQL that a DE would write, compared to the SQL a data analyst writes?", "author_fullname": "t2_mvubfxcg0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Level of SQL for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bil95m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710857622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working as a mix of DA/DE, and I believe my skills with SQL are not upto the mark to make a move to DE.\nI understand there is just &amp;quot;normal&amp;quot; sql that data analysts, BI analysts use which is typically:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Select xyz from abc where ysd = &amp;#39;123&amp;#39;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yes this can get more complex with joins, ctes, window functions etc.&lt;/p&gt;\n\n&lt;p&gt;What is the difference between complex SQL that a DE would write, compared to the SQL a data analyst writes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bil95m", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous-Kale9545", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bil95m/level_of_sql_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bil95m/level_of_sql_for_de/", "subreddit_subscribers": 170174, "created_utc": 1710857622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to work an enterprise workflow and am trying to think of what the right stack looks like.\n\nCloud at the moment is not a possibility - but the organization will go there one day. It\u2019s just a money thing.\n\nWe have contracts with Microsoft and so my front end is forced to be power apps and power BI. We do have licenses for power automate etc. \n\nWe have a very small allocation of dataverse and a decent sized share point. \n\nMy organization has 0 APIs, but are going to build them.\n\nWe have a few large databases and a gateway.\n\nMy original plan was to do data collection through power apps, power automate into a json, build a rest API with fast API to receive post, route traffic to mongo, store into a Postgres staging area to run Python transforms and into another Postgres as long term structured data, put an API in front of that into an MDM, an API off the MDM into an analytical database, and then an API off of that into the various BI customers and generally run data services.\n\nI\u2019ve recently heard about Apache Cassandra and thought it was interesting. I\u2019ve also heard of people building lakehouses and warehouses with duck DB.\n\nUltimately I\u2019m trying to figure out what the best scalable databases are and the easiest to interact with. Also.. am I doing my flow right?", "author_fullname": "t2_4dovkjca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database choices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bij7z5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710851881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to work an enterprise workflow and am trying to think of what the right stack looks like.&lt;/p&gt;\n\n&lt;p&gt;Cloud at the moment is not a possibility - but the organization will go there one day. It\u2019s just a money thing.&lt;/p&gt;\n\n&lt;p&gt;We have contracts with Microsoft and so my front end is forced to be power apps and power BI. We do have licenses for power automate etc. &lt;/p&gt;\n\n&lt;p&gt;We have a very small allocation of dataverse and a decent sized share point. &lt;/p&gt;\n\n&lt;p&gt;My organization has 0 APIs, but are going to build them.&lt;/p&gt;\n\n&lt;p&gt;We have a few large databases and a gateway.&lt;/p&gt;\n\n&lt;p&gt;My original plan was to do data collection through power apps, power automate into a json, build a rest API with fast API to receive post, route traffic to mongo, store into a Postgres staging area to run Python transforms and into another Postgres as long term structured data, put an API in front of that into an MDM, an API off the MDM into an analytical database, and then an API off of that into the various BI customers and generally run data services.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve recently heard about Apache Cassandra and thought it was interesting. I\u2019ve also heard of people building lakehouses and warehouses with duck DB.&lt;/p&gt;\n\n&lt;p&gt;Ultimately I\u2019m trying to figure out what the best scalable databases are and the easiest to interact with. Also.. am I doing my flow right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bij7z5", "is_robot_indexable": true, "report_reasons": null, "author": "necrohobo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bij7z5/database_choices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bij7z5/database_choices/", "subreddit_subscribers": 170174, "created_utc": 1710851881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, dlt (the data ingestion library) cofounder here,   \n\n\nI want to showcase our event ingestion setup. We put this behind cloudflare, to lower latency in different geographies.\n\nMany of our users use dlt for event ingestion. We were using Segment ourselves as we had free credits, but on credit expiration the bill is not pretty. So we moved to dlt on serverless gcp cloud functions with pub sub.\n\nWe like Segment, but we like 18x cost saving more :)\n\nHere's our setup  \n[https://dlthub.com/docs/blog/dlt-segment-migration](https://dlthub.com/docs/blog/dlt-segment-migration)\n\nMore streaming setups done by our users here: [https://dlthub.com/docs/blog/tags/streaming](https://dlthub.com/docs/blog/tags/streaming)  \n\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event ingestion on GCP terraform template + blog (18x cost saving over Segment)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bigwrv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1710843634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, dlt (the data ingestion library) cofounder here,   &lt;/p&gt;\n\n&lt;p&gt;I want to showcase our event ingestion setup. We put this behind cloudflare, to lower latency in different geographies.&lt;/p&gt;\n\n&lt;p&gt;Many of our users use dlt for event ingestion. We were using Segment ourselves as we had free credits, but on credit expiration the bill is not pretty. So we moved to dlt on serverless gcp cloud functions with pub sub.&lt;/p&gt;\n\n&lt;p&gt;We like Segment, but we like 18x cost saving more :)&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s our setup&lt;br/&gt;\n&lt;a href=\"https://dlthub.com/docs/blog/dlt-segment-migration\"&gt;https://dlthub.com/docs/blog/dlt-segment-migration&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;More streaming setups done by our users here: &lt;a href=\"https://dlthub.com/docs/blog/tags/streaming\"&gt;https://dlthub.com/docs/blog/tags/streaming&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?auto=webp&amp;s=7f542da7e01be864731a87a5966f1da32fb1c0c6", "width": 3483, "height": 1148}, "resolutions": [{"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e43620cee4872bff896e6e91e21a8b05be75fb6c", "width": 108, "height": 35}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e7bf904f616dabb756e6dfc370782f91bb6e0c7", "width": 216, "height": 71}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eeac09672bbbc25f987aaa496dc5565036f1da3b", "width": 320, "height": 105}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea4b58ab320d7d12631b04de23f15a300aecdd7b", "width": 640, "height": 210}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a6fc2854f5627b9b2ff29e9e4745b940c2d8ac7", "width": 960, "height": 316}, {"url": "https://external-preview.redd.it/vvcyd0J-74fslNI97qJpP3Qs5O-jkC6sczFyt1KoXk0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eeb7f45ca1bd06a2122e72974c60807e1bedf33a", "width": 1080, "height": 355}], "variants": {}, "id": "_iRCnnKFUj1iGmaRU1XQdxy12fe92yHsgkY8JGxjpyM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bigwrv", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bigwrv/event_ingestion_on_gcp_terraform_template_blog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bigwrv/event_ingestion_on_gcp_terraform_template_blog/", "subreddit_subscribers": 170174, "created_utc": 1710843634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says I'm looking for any messy datasets that would require some significant transformation for a personal project I'm doing. I have already set the architecture which involves Kafka, RDS Postgres, Docker, Debezium and Pyspark. I specify some tables from which any new-entries are captured and published to Kafka topic(s) through a debezium-postgres-connector. The next step is to ingest these real-time entries in Pyspark, perform some transformation, and publish it to another topic for subsequent processing (I haven't decided what I'm going to do yet \u2014 maybe some visualization/analytics?)\n\n&amp;#x200B;\n\nEverything is working fine and I'm getting the new entries in real time. But the data that is currently present in the database is overall clean and doesn't require any major transformation. Maybe dropping a column or two, or filtering for rows that don't meet a specific criteria but that's it. Neither is the data really huge.\n\n&amp;#x200B;\n\nSo I'm looking for any datasets that can span multiple tables so I can do some meaningful transformation on them. I could upload the datasets to the db and proceed from there. \n\n&amp;#x200B;\n\nI'll also take any suggestions regarding the project itself. Maybe there's a flaw in the architecture I'm missing. Who knows?", "author_fullname": "t2_4w6ebksa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any messy datasets for Pyspark practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bibu4z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710822578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says I&amp;#39;m looking for any messy datasets that would require some significant transformation for a personal project I&amp;#39;m doing. I have already set the architecture which involves Kafka, RDS Postgres, Docker, Debezium and Pyspark. I specify some tables from which any new-entries are captured and published to Kafka topic(s) through a debezium-postgres-connector. The next step is to ingest these real-time entries in Pyspark, perform some transformation, and publish it to another topic for subsequent processing (I haven&amp;#39;t decided what I&amp;#39;m going to do yet \u2014 maybe some visualization/analytics?)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Everything is working fine and I&amp;#39;m getting the new entries in real time. But the data that is currently present in the database is overall clean and doesn&amp;#39;t require any major transformation. Maybe dropping a column or two, or filtering for rows that don&amp;#39;t meet a specific criteria but that&amp;#39;s it. Neither is the data really huge.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for any datasets that can span multiple tables so I can do some meaningful transformation on them. I could upload the datasets to the db and proceed from there. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll also take any suggestions regarding the project itself. Maybe there&amp;#39;s a flaw in the architecture I&amp;#39;m missing. Who knows?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bibu4z", "is_robot_indexable": true, "report_reasons": null, "author": "SAAD_3XK", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bibu4z/any_messy_datasets_for_pyspark_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bibu4z/any_messy_datasets_for_pyspark_practice/", "subreddit_subscribers": 170174, "created_utc": 1710822578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Get the knowledge required to excel in the realms of data engineering, data science, and a host of related in-demand fields with this collection of books from O\u2019Reilly! Deciphering Data Architectures provides a guided tour of today\u2019s most common architectures\u2014from data lakehouses to data meshes\u2014to help you understand the pros and cons of each. Data Science: The Hard Parts is a handy guidebook of techniques and best practices that are generally overlooked when teaching this wide-ranging discipline.\n\n\n", "author_fullname": "t2_6b9o0e5i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Humble Tech Book Bundle: Pipelines and NoSQL by O'Reilly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1bhzg06", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kRC4x_HcbhsgiwleL2XqINxbXymSn_3C1EO3omqF0og.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1710790063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "humblebundle.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Get the knowledge required to excel in the realms of data engineering, data science, and a host of related in-demand fields with this collection of books from O\u2019Reilly! Deciphering Data Architectures provides a guided tour of today\u2019s most common architectures\u2014from data lakehouses to data meshes\u2014to help you understand the pros and cons of each. Data Science: The Hard Parts is a handy guidebook of techniques and best practices that are generally overlooked when teaching this wide-ranging discipline.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books?hmb_source=&amp;hmb_medium=product_tile&amp;hmb_campaign=mosaic_section_1_layout_index_1_layout_type_threes_tile_index_1_c_pipelinesandnosqloreilly_bookbundle", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?auto=webp&amp;s=b50f3a7282d32dcfa0e059b0b506a19daa6b7df9", "width": 1120, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8df569a17eb586e2b0feb844c8ddd80e2c53523e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc1d0f218d319d03ff9fb045ea5a017098e1c402", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4db0e3979f4fd989e036859dfa1257d15a01f34", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0c5aa5216466749f2ffd89e4f6dda46502974b1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=92b050a7f148a6395bed48099df1cca2307178a1", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ksfkmMLrK-O0CsI43Gee_aHJNaFDz6JcvyRb6MkH6ps.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=abb37e101932d1c5791c9ad599433a01b56b311e", "width": 1080, "height": 607}], "variants": {}, "id": "FbykrjGMgm2863qufl2xVlkGdUUd4rQbUPblShEhFV4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1bhzg06", "is_robot_indexable": true, "report_reasons": null, "author": "serious_frank", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bhzg06/humble_tech_book_bundle_pipelines_and_nosql_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.humblebundle.com/books/pipelines-and-nosql-oreilly-books?hmb_source=&amp;hmb_medium=product_tile&amp;hmb_campaign=mosaic_section_1_layout_index_1_layout_type_threes_tile_index_1_c_pipelinesandnosqloreilly_bookbundle", "subreddit_subscribers": 170174, "created_utc": 1710790063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I write data engineering ETL scripts that are meant to be used in the back end for major reports in Tableau or Power BI, looker, things like that. Over the past 6 months, We have been working on this absolutely, atrociously huge Tableau back end ETL script, because the VP that owns the solution that we are making it for once it created as a table. So they want the ETL script to take a huge amount of data and put it into a table, and they want us to directly retrieve off the table. No crazy SQL inside the Power BI report. However, our data engineering manager said to heck with that, we're not doing that, we should do it a completely different way, we should use custom SQL inside the Power bi. So now, we are writing much smaller and very specific custom SQL that is focused on each and every little piece of the dashboard complete 180 from what we were doing before. So before we were creating a data Mart, basically. Now, we're just writing all the custom SQL piecemeal for everything that anyone might ever want to see. \n\n\n\nFrustrating part is my manager acts a little bit gruff about it taking so long, like what is taking you so long to do this? Why is it not done yet? Well, we've changed directions like three times now because you have this idea about what you think is best, and the VP has the idea of what they actually want, the two of you don't agree, so I did it their way, you told me to change and do it your way, now we're doing it a completely different way again. She just doesn't understand that it's really hard to determine who to listen to when there are two leaders giving instructions", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's really annoying when leaders can't make up their mind about what they want", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1birem3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710872947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I write data engineering ETL scripts that are meant to be used in the back end for major reports in Tableau or Power BI, looker, things like that. Over the past 6 months, We have been working on this absolutely, atrociously huge Tableau back end ETL script, because the VP that owns the solution that we are making it for once it created as a table. So they want the ETL script to take a huge amount of data and put it into a table, and they want us to directly retrieve off the table. No crazy SQL inside the Power BI report. However, our data engineering manager said to heck with that, we&amp;#39;re not doing that, we should do it a completely different way, we should use custom SQL inside the Power bi. So now, we are writing much smaller and very specific custom SQL that is focused on each and every little piece of the dashboard complete 180 from what we were doing before. So before we were creating a data Mart, basically. Now, we&amp;#39;re just writing all the custom SQL piecemeal for everything that anyone might ever want to see. &lt;/p&gt;\n\n&lt;p&gt;Frustrating part is my manager acts a little bit gruff about it taking so long, like what is taking you so long to do this? Why is it not done yet? Well, we&amp;#39;ve changed directions like three times now because you have this idea about what you think is best, and the VP has the idea of what they actually want, the two of you don&amp;#39;t agree, so I did it their way, you told me to change and do it your way, now we&amp;#39;re doing it a completely different way again. She just doesn&amp;#39;t understand that it&amp;#39;s really hard to determine who to listen to when there are two leaders giving instructions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1birem3", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1birem3/its_really_annoying_when_leaders_cant_make_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1birem3/its_really_annoying_when_leaders_cant_make_up/", "subreddit_subscribers": 170174, "created_utc": 1710872947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, \n\n&amp;#x200B;\n\nI am a senior data engineer in Germany and would like to try out contracting jobs (on the side of my main job) just to explore new opportunities. \n\n&amp;#x200B;\n\nI have been applying to contracting remove jobs in EU (including UK) and USA via websites like Reed, Hays, Harnham but with no luck. \n\n&amp;#x200B;\n\nDoes anyone have any experience in such setup? Would love to hear your thoughts", "author_fullname": "t2_xm0tg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you find contracting jobs? [senior DE]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bi9yt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710816737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am a senior data engineer in Germany and would like to try out contracting jobs (on the side of my main job) just to explore new opportunities. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have been applying to contracting remove jobs in EU (including UK) and USA via websites like Reed, Hays, Harnham but with no luck. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience in such setup? Would love to hear your thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bi9yt8", "is_robot_indexable": true, "report_reasons": null, "author": "elephantail", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bi9yt8/how_do_you_find_contracting_jobs_senior_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bi9yt8/how_do_you_find_contracting_jobs_senior_de/", "subreddit_subscribers": 170174, "created_utc": 1710816737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Starting a new project, I'm grappling with some debugging challenges:\n\n1. **Dim tables referencing fact tables:** Is this standard practice or a potential pattern to reconsider?\n2. **Multiple fact tables referencing other fact tables:** How do we effectively manage this complexity?\n\nSeeking practical advice: Are these situations acceptable, or should we prioritize a data model refactor within our team? Your insights would be invaluable!", "author_fullname": "t2_mbbdv7y98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Dimension and Fact Table References: Seeking Practical Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bi83x0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710811395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Starting a new project, I&amp;#39;m grappling with some debugging challenges:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Dim tables referencing fact tables:&lt;/strong&gt; Is this standard practice or a potential pattern to reconsider?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Multiple fact tables referencing other fact tables:&lt;/strong&gt; How do we effectively manage this complexity?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Seeking practical advice: Are these situations acceptable, or should we prioritize a data model refactor within our team? Your insights would be invaluable!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bi83x0", "is_robot_indexable": true, "report_reasons": null, "author": "Kindly-Screen-2557", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bi83x0/understanding_dimension_and_fact_table_references/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bi83x0/understanding_dimension_and_fact_table_references/", "subreddit_subscribers": 170174, "created_utc": 1710811395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practical Data Engineering: A Hands-On Real-Estate Project Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1bi4oww", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": "transparent", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uV26zp7PCWtK7MY6N1K57dVho0aLyS0OzFGWG5NlO_g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710802548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/sspaeti-com/practical-data-engineering/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cto0MXFFkuWS_oW9hogx2CyLOb1BoIb0TVtfPQwGQdc.jpg?auto=webp&amp;s=992c374da0b7cef563bce125b40f7dd70f1be59c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/cto0MXFFkuWS_oW9hogx2CyLOb1BoIb0TVtfPQwGQdc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc278d38d5b68c3d58fd1c83d91f3d4a5ed5d00d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cto0MXFFkuWS_oW9hogx2CyLOb1BoIb0TVtfPQwGQdc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c9c7c2427d27bbb7a3472b4e6add60124f18c80", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cto0MXFFkuWS_oW9hogx2CyLOb1BoIb0TVtfPQwGQdc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b3d352a98a4461d3372f0b5e4ccb805371c183a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/cto0MXFFkuWS_oW9hogx2CyLOb1BoIb0TVtfPQwGQdc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f9137f00a5567761222bb5535d7e204dabc16e4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/cto0MXFFkuWS_oW9hogx2CyLOb1BoIb0TVtfPQwGQdc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d31d1ad32e4fd19da504743c6205ca1bc880371e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/cto0MXFFkuWS_oW9hogx2CyLOb1BoIb0TVtfPQwGQdc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6e58b4a64203c0b621797d896f3a0ef28fa8ed7e", "width": 1080, "height": 540}], "variants": {}, "id": "4LE-hJ8pfXAPB3TmqsVS2HmP-B727Eo4P_1rtYcMipw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1bi4oww", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1bi4oww/practical_data_engineering_a_handson_realestate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/sspaeti-com/practical-data-engineering/", "subreddit_subscribers": 170174, "created_utc": 1710802548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learning Airflow for the first time. Have been using Prefect.\n\nLearned about xcoms today. The syntax for passing things seems very verbose and somewhat cumbersome, but I get it. However, the 48kb limit means xcoms have some limited application.\n\nIn researching posts, I saw on multiple occasions people stating (paraphrasing here) \"*back when Airflow was still using xcoms*\".\n\nWhat does this mean?\n\n* In airflow, can a task be a function that calls other functions that are not tasks themselves?\n* Could your task push data to something like S3 where the next task can pick it up?\n* Are xcoms still an integral part of Airflow?", "author_fullname": "t2_qhsi5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do people say xcoms are no longer the default in airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bimv59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710861874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning Airflow for the first time. Have been using Prefect.&lt;/p&gt;\n\n&lt;p&gt;Learned about xcoms today. The syntax for passing things seems very verbose and somewhat cumbersome, but I get it. However, the 48kb limit means xcoms have some limited application.&lt;/p&gt;\n\n&lt;p&gt;In researching posts, I saw on multiple occasions people stating (paraphrasing here) &amp;quot;&lt;em&gt;back when Airflow was still using xcoms&lt;/em&gt;&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;What does this mean?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;In airflow, can a task be a function that calls other functions that are not tasks themselves?&lt;/li&gt;\n&lt;li&gt;Could your task push data to something like S3 where the next task can pick it up?&lt;/li&gt;\n&lt;li&gt;Are xcoms still an integral part of Airflow?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bimv59", "is_robot_indexable": true, "report_reasons": null, "author": "NoUsernames1eft", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bimv59/why_do_people_say_xcoms_are_no_longer_the_default/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bimv59/why_do_people_say_xcoms_are_no_longer_the_default/", "subreddit_subscribers": 170174, "created_utc": 1710861874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Engineers, I am kinda starting to learn and use dbt and have used delta live tables from databricks(dlt) in the past. I am trying to understand the point of using dbt when I am already in databricks environment.\n\nCould someone who has the experience point out some of the scenarios where you found dbt more useful than using dlt. I assume dlt will be bit costlier but would love to hear your thoughts.", "author_fullname": "t2_szxdhbt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs databricks dot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bige78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710841541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Engineers, I am kinda starting to learn and use dbt and have used delta live tables from databricks(dlt) in the past. I am trying to understand the point of using dbt when I am already in databricks environment.&lt;/p&gt;\n\n&lt;p&gt;Could someone who has the experience point out some of the scenarios where you found dbt more useful than using dlt. I assume dlt will be bit costlier but would love to hear your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bige78", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum__Gold", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bige78/dbt_vs_databricks_dot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bige78/dbt_vs_databricks_dot/", "subreddit_subscribers": 170174, "created_utc": 1710841541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I have athena partitions for date like:\n\nyear=2012/month=01/day=01 and inside each folder around 30 parquet files\n\nThe schema of the parquet files does not have the columns year, month, and day, it has a single column called 'date' which is a timestamp, when I created the folders just did it by filtering on the spark df and then writing on the S3 folder. Does this affect performance in how Athena queries this data? Should I have within the .parquet files a schema with the year, month, and day? should I change my partitions to be 2012/01/01 2012/01/02 and create a column within the .parquet files called just \"actual\\_date\" and keep \"date\" timestamp? any thoughts? :) TIA!", "author_fullname": "t2_42yrzhea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Athena Partitions and .parquet schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bi1qnn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1710795935.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710795487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I have athena partitions for date like:&lt;/p&gt;\n\n&lt;p&gt;year=2012/month=01/day=01 and inside each folder around 30 parquet files&lt;/p&gt;\n\n&lt;p&gt;The schema of the parquet files does not have the columns year, month, and day, it has a single column called &amp;#39;date&amp;#39; which is a timestamp, when I created the folders just did it by filtering on the spark df and then writing on the S3 folder. Does this affect performance in how Athena queries this data? Should I have within the .parquet files a schema with the year, month, and day? should I change my partitions to be 2012/01/01 2012/01/02 and create a column within the .parquet files called just &amp;quot;actual_date&amp;quot; and keep &amp;quot;date&amp;quot; timestamp? any thoughts? :) TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1bi1qnn", "is_robot_indexable": true, "report_reasons": null, "author": "josejo9423", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bi1qnn/athena_partitions_and_parquet_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bi1qnn/athena_partitions_and_parquet_schema/", "subreddit_subscribers": 170174, "created_utc": 1710795487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Datadogs, \n\nYour expert opinion would be appreciated if you could provide me with book recommendations on Streaming systems, NRT (near-time pipelines ) and related literature.\n\n&amp;#x200B;", "author_fullname": "t2_snzbmfolo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Recommendations on Streaming Systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1birk8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710873313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Datadogs, &lt;/p&gt;\n\n&lt;p&gt;Your expert opinion would be appreciated if you could provide me with book recommendations on Streaming systems, NRT (near-time pipelines ) and related literature.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1birk8h", "is_robot_indexable": true, "report_reasons": null, "author": "loomingdale", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1birk8h/book_recommendations_on_streaming_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1birk8h/book_recommendations_on_streaming_systems/", "subreddit_subscribers": 170174, "created_utc": 1710873313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cbh6ollo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Kafka connector to send kafka topics data to 200+ destinations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_1biqsae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Dcu6VBDsnTInxOse8U-R-5-yKyByVMnBqCVSKZnCVVI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710871426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/rudderlabs/rudder-kafka-sink-connector", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?auto=webp&amp;s=2236b72c38c1ffdb3ef00bc2c4dae5fbd4a116cb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab3990f924bd9bf0da88fb79a89075e6cad33a01", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4df0cc65b132eb2a2f60895b37c4f59f705b5cd7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8847d43ea3f647be0e9a2cb39a1ebc6a8277a728", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6e6253a85bf7e130c92e6bf21615e7bf385246f8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c854fd5dd1329ce2cb94a4e60d5d3324969aeb54", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/WHKVfhj3QKTkIVEax-7bSvrfqzSVhtUTW03pN5eqW7c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=97c03bdc700f1d9114a39bb80c449226c6882b10", "width": 1080, "height": 540}], "variants": {}, "id": "HHCapiHt6RX89jBT8ceKmiW73oQ_kfiILwHJ-WwYTqg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1biqsae", "is_robot_indexable": true, "report_reasons": null, "author": "ephemeral404", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1biqsae/open_source_kafka_connector_to_send_kafka_topics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/rudderlabs/rudder-kafka-sink-connector", "subreddit_subscribers": 170174, "created_utc": 1710871426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Do you normally build APIs?\n\nI have good gasp of reading and parsing data from APIs but I have never build any. Not sure if building APIs is common for hedge fund DEs? Thank you!\n\nWhat are the common data sources where DE pull data from?  Besides files, APIs, ftps, sql servers, what else? Thank you.  I posted this yesterday but not sure why the content is no longer available. I am kind of new here. Not sure If I am breaking any rules? ", "author_fullname": "t2_9od6j04g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers working at a hedge fund? I got a couple job interviews coming and would like some insights.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bipbf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710867845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you normally build APIs?&lt;/p&gt;\n\n&lt;p&gt;I have good gasp of reading and parsing data from APIs but I have never build any. Not sure if building APIs is common for hedge fund DEs? Thank you!&lt;/p&gt;\n\n&lt;p&gt;What are the common data sources where DE pull data from?  Besides files, APIs, ftps, sql servers, what else? Thank you.  I posted this yesterday but not sure why the content is no longer available. I am kind of new here. Not sure If I am breaking any rules? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bipbf7", "is_robot_indexable": true, "report_reasons": null, "author": "Tall-Skin5800", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bipbf7/any_data_engineers_working_at_a_hedge_fund_i_got/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bipbf7/any_data_engineers_working_at_a_hedge_fund_i_got/", "subreddit_subscribers": 170174, "created_utc": 1710867845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 2 years of experiences in it and I find difficult to change a company within Europe. What are your experiences/opinions?", "author_fullname": "t2_hghk7npl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Isn't data engineering job market tough right now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bioqxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710866464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 years of experiences in it and I find difficult to change a company within Europe. What are your experiences/opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bioqxr", "is_robot_indexable": true, "report_reasons": null, "author": "Important-Respond595", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bioqxr/isnt_data_engineering_job_market_tough_right_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bioqxr/isnt_data_engineering_job_market_tough_right_now/", "subreddit_subscribers": 170174, "created_utc": 1710866464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Text to Teradata SQL with LangChain and OpenAI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1binect", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3Bt4dXoyv9LpR83xzMwbB4oMHw_w-qTJS7KF_MeLGCw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1710863226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/teradata/using-natural-language-to-query-teradata-vantagecloud-with-llms-a1f9bfa1688b", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ewc05IuLWgofqH0Yu3Pypt2IAza71uN1sIiyGmvt4Cs.jpg?auto=webp&amp;s=8656c7bc5a3298e323984d334b76a2d5db78f038", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Ewc05IuLWgofqH0Yu3Pypt2IAza71uN1sIiyGmvt4Cs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=770863f7f55dce5dca2c6ad16091235001b6ece2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Ewc05IuLWgofqH0Yu3Pypt2IAza71uN1sIiyGmvt4Cs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b8aa418d82b94af1dde1c4864f3bcf054394cbb4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Ewc05IuLWgofqH0Yu3Pypt2IAza71uN1sIiyGmvt4Cs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0a3212764ce7d06a649dc21b8f1251f58e1181a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Ewc05IuLWgofqH0Yu3Pypt2IAza71uN1sIiyGmvt4Cs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c7e85215a65fc0a9fc8a53d52ccf493d13aaf7b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Ewc05IuLWgofqH0Yu3Pypt2IAza71uN1sIiyGmvt4Cs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a81ed9f32085b686becf0b73f222ba24e2cda38b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Ewc05IuLWgofqH0Yu3Pypt2IAza71uN1sIiyGmvt4Cs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ad1b4ed91074636074036ef9a4703ef84c98d885", "width": 1080, "height": 540}], "variants": {}, "id": "oEZ5WsycoKJMTv0PRVi_gzHAW5h9BulpibxfpTP4WMY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1binect", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1binect/text_to_teradata_sql_with_langchain_and_openai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/teradata/using-natural-language-to-query-teradata-vantagecloud-with-llms-a1f9bfa1688b", "subreddit_subscribers": 170174, "created_utc": 1710863226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One of the clients we are assisting is moving from their 20 year old Teradata system to new Databricks system. While doing so they are changing the data models as well. We are tasked with mapping ~300 tables across 6 databases in Teradata that a particular department currently uses for their reporting. The idea of mapping is to map columns and tables from Teradata tables to the columns in new Databricks model and eventually report anything that is missing. Being on such first time migration engagement, I\u2019m struggling to start moving forward. Any suggestions on how i can start and push forward to resolve this problem for client ? Thanks in advance ", "author_fullname": "t2_7icx1bkq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teradata to Databricks migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bikw3k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710856664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of the clients we are assisting is moving from their 20 year old Teradata system to new Databricks system. While doing so they are changing the data models as well. We are tasked with mapping ~300 tables across 6 databases in Teradata that a particular department currently uses for their reporting. The idea of mapping is to map columns and tables from Teradata tables to the columns in new Databricks model and eventually report anything that is missing. Being on such first time migration engagement, I\u2019m struggling to start moving forward. Any suggestions on how i can start and push forward to resolve this problem for client ? Thanks in advance &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1bikw3k", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantEducational5", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bikw3k/teradata_to_databricks_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bikw3k/teradata_to_databricks_migration/", "subreddit_subscribers": 170174, "created_utc": 1710856664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working as a DE for 2 years or so and would like a degree as it'll help me get a job in germany.\nThere doesn't tend to be a degree in data engineering itself. Only cloud computing or data science/data analytics. \nAnalytics seems to be the most desirable from German companies.\n\nI want to do an open university but unsure whether to look at analytics or data science for the degree. I do have an interest in both and machine learning is a cool concept but understand that data science/ML can be extremely complex mathematically. \n\nAny advice? \n", "author_fullname": "t2_7zcn2i3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for which Data Msc in UK? Planning to move to Germany and a qualification would help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1bigye8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710843810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as a DE for 2 years or so and would like a degree as it&amp;#39;ll help me get a job in germany.\nThere doesn&amp;#39;t tend to be a degree in data engineering itself. Only cloud computing or data science/data analytics. \nAnalytics seems to be the most desirable from German companies.&lt;/p&gt;\n\n&lt;p&gt;I want to do an open university but unsure whether to look at analytics or data science for the degree. I do have an interest in both and machine learning is a cool concept but understand that data science/ML can be extremely complex mathematically. &lt;/p&gt;\n\n&lt;p&gt;Any advice? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1bigye8", "is_robot_indexable": true, "report_reasons": null, "author": "Material_Direction_1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1bigye8/recommendations_for_which_data_msc_in_uk_planning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1bigye8/recommendations_for_which_data_msc_in_uk_planning/", "subreddit_subscribers": 170174, "created_utc": 1710843810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll be working on a migration project and I have a ton of etl pipelines with 2k+ lines of sql and I was wondering if anyone knows a tool that can gate the sql script and turn it into a sort of flow diagram to understand all the tables that are being created and their relation ", "author_fullname": "t2_38po62bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turning sql pipeline into flowchart", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1big8k5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1710840826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be working on a migration project and I have a ton of etl pipelines with 2k+ lines of sql and I was wondering if anyone knows a tool that can gate the sql script and turn it into a sort of flow diagram to understand all the tables that are being created and their relation &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1big8k5", "is_robot_indexable": true, "report_reasons": null, "author": "Esteban_Rdz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1big8k5/turning_sql_pipeline_into_flowchart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1big8k5/turning_sql_pipeline_into_flowchart/", "subreddit_subscribers": 170174, "created_utc": 1710840826.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}